<!DOCTYPE html>
<!-- saved from url=(0075)https://pubmed.ncbi.nlm.nih.gov/?term=chatGPT&page=2&format=pubmed&size=200 -->
<html lang="en"><head itemscope="" itemtype="http://schema.org/WebPage" prefix="og: http://ogp.me/ns#"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <!-- Mobile properties -->
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov/">
  <link rel="preconnect" href="https://www.ncbi.nlm.nih.gov/">
  <link rel="preconnect" href="https://www.google-analytics.com/">

  
  
    <link rel="stylesheet" href="./page2_PubMed_files/output.5ecf62baa0fa.css" type="text/css">
  

  <link rel="stylesheet" href="./page2_PubMed_files/output.452c70ce66f7.css" type="text/css">

  
    
  

  
    <link rel="stylesheet" href="./page2_PubMed_files/output.97c300a159d1.css" type="text/css">
  

  


    <title>chatGPT - Search Results - PubMed</title>

  
  
  <!-- Favicons -->
  <link rel="shortcut icon" type="image/ico" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.ico">
  <link rel="icon" type="image/png" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.png">

  <!-- 192x192, as recommended for Android
  http://updates.html5rocks.com/2014/11/Support-for-theme-color-in-Chrome-39-for-Android
  -->
  <link rel="icon" type="image/png" sizes="192x192" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-192.png">

  <!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
  <link rel="apple-touch-icon-precomposed" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-57.png">
  <!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
  <link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-72.png">
  <!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
  <link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-114.png">
  <!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-144.png">


  <!-- For Pinger + Google Optimize integration (NS-820) -->
  <meta name="ncbi_sg_optimize_id" content="">

  <!-- Mobile browser address bar color -->
  <meta name="theme-color" content="#20558a">

  <!-- Preserve the Referrer when going from HTTPS to HTTP -->
  <meta name="referrer" content="origin-when-cross-origin">

  <meta name="ncbi_pinger_gtm_track" content="true">
<!-- Logging params: Pinger defaults -->

  
    <meta name="ncbi_app" content="pubmed">
  

  
    <meta name="ncbi_db" content="pubmed">
  

  
    <meta name="ncbi_phid" content="658B00010FEE1FF500003D88A124EB5A.1.m_8">
  

  
    <meta name="ncbi_pinger_stat_url" content="https://www.ncbi.nlm.nih.gov/stat">
  

  
    <meta name="log_category" content="literature">
  

  
    <meta name="ncbi_cost_center" content="pubmed">
  



  <!-- Logging params: Pinger custom -->
  
    <meta name="log_op" content="search">
  
    <meta name="log_query" content="chatGPT">
  
    <meta name="ncbi_pdid" content="searchresult">
  
    <meta name="ncbi_pageno" content="2">
  
    <meta name="log_resultcount" content="2844">
  
    <meta name="log_userterm" content="chatGPT">
  
    <meta name="log_processedquery" content="&quot;chatGPT&quot;[All Fields]">
  
    <meta name="log_filtersactive" content="False">
  
    <meta name="log_filters" content="">
  
    <meta name="ncbi_log_query" content="chatGPT">
  
    <meta name="log_proximity_search_active" content="False">
  
    <meta name="log_format" content="pubmed">
  
    <meta name="log_sortorder" content="relevance">
  
    <meta name="log_pagesize" content="200">
  
    <meta name="log_displayeduids" content="38450035,37735339,37622581,37209880,37142327,38133908,38217884,37578934,37954270,37208451,37517980,37303324,37900984,38107064,38021917,37549499,38174202,38379690,37578849,37204545,37662036,37286486,38460761,37808939,38489044,38484923,37958000,37521213,37074486,38540976,38563440,37795422,38183467,37140001,38411835,38025546,38247934,38153777,38556438,38410331,37998071,37352054,38021609,37839017,37862566,38534904,37195756,37790756,38162414,37303347,36966950,38398794,37830257,38484238,37874336,38386789,38039286,37183932,37838575,37222839,38090765,37518931,37293238,37028488,37934568,37831496,37548997,38502861,38109889,38021639,38020045,37061595,37728984,38096014,37095384,37638266,38305239,37583313,38181176,37792344,37942394,37685617,38552383,38073946,37814369,37584720,38073698,37789187,38511678,38529337,37780034,37266721,37891083,38219888,37658948,37341179,37452215,37934828,38552842,38212802,38417624,38248048,37934302,37540015,37426402,37992892,38391252,38164506,37482572,38345613,38409676,38311261,37969495,38219503,38478902,37788063,37957666,37828297,38451040,38506920,38031276,38167093,37701862,37337480,37844967,37198498,38434792,37378091,38111256,37332008,37078489,37369944,38084123,38219629,38404561,37952004,37184746,37528247,37593450,37770637,38356365,37417886,37745352,38566254,38438722,38242382,38428198,38527823,37083633,37314848,37682111,38464770,37655838,37553555,38096895,38195660,37598590,38565880,38371244,37798960,38465399,38195060,37742280,37696742,38049066,38424125,37466157,38291746,38401366,37252576,38420978,37464178,38252483,38416195,37490183,38249789,37577545,37776392,37750052,37323348,37033498,37954179,38213186,38479923,38419805,37928033,38567408,38330745,37933835,37905713,37456381,38243605,37129780,37553205,38214967,38489735,38411833,38184368,38517757,37438164">
  
    <meta name="ncbi_search_id" content="R3Cs2GC7H0x0KE8U7UASSA:deef7cbfe7e81e7152f8e0e261e5ab1a">
  
    <meta name="ncbi_adj_nav_search_id" content="gv2WXPOoExmbzYETr_th6g:fbd847f89c96214ac23b7c62d7cb721a">
  



  <!-- Social meta tags for unfurling urls -->
  
<meta name="description" content="chatGPT - Search Results - PubMed"><meta name="robots" content="noindex,follow,noarchive"><meta property="og:title" content="chatGPT - Search Results - PubMed"><meta property="og:url" content="https://pubmed.ncbi.nlm.nih.gov/?term=chatGPT&amp;page=2&amp;format=pubmed&amp;size=200"><meta property="og:description" content="chatGPT - Search Results - PubMed"><meta property="og:image" content="https://cdn.ncbi.nlm.nih.gov/pubmed/persistent/pubmed-meta-image-v2.jpg"><meta property="og:image:secure_url" content="https://cdn.ncbi.nlm.nih.gov/pubmed/persistent/pubmed-meta-image-v2.jpg"><meta property="og:type" content="website"><meta property="og:site_name" content="PubMed"><meta name="twitter:domain" content="pubmed.ncbi.nlm.nih.gov"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="chatGPT - Search Results - PubMed"><meta name="twitter:url" content="https://pubmed.ncbi.nlm.nih.gov/?term=chatGPT&amp;page=2&amp;format=pubmed&amp;size=200"><meta name="twitter:description" content="chatGPT - Search Results - PubMed"><meta name="twitter:image" content="https://cdn.ncbi.nlm.nih.gov/pubmed/persistent/pubmed-meta-image-v2.jpg">


  <!-- OpenSearch XML -->
  <link rel="search" type="application/opensearchdescription+xml" href="https://cdn.ncbi.nlm.nih.gov/pubmed/persistent/opensearch.xml" title="PubMed search">

  <!-- Disables severely broken elements when no JS -->
  <noscript>
    <link rel="stylesheet" type="text/css" href="https://cdn.ncbi.nlm.nih.gov/pubmed/09ad9aad-98d9-47ec-b2ea-fb4dba3d550d/core/no-script.css">
  </noscript>

  
    <link rel="canonical" href="https://pubmed.ncbi.nlm.nih.gov/?term=chatGPT&amp;page=2&amp;format=pubmed&amp;size=200">
  


</head>
<body>

  
  <main class="search-page" id="search-page">
    <div class="search-results" id="search-results">
      
        <pre class="search-results-chunk">PMID- 38450035
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240308
IS  - 2807-2618 (Electronic)
IS  - 2807-2618 (Linking)
VI  - 3
IP  - 1
DP  - 2023 Apr
TI  - ChatGPT applications in medical, dental, pharmacy, and public health education: A 
      descriptive study highlighting the advantages and limitations.
PG  - e103
LID - 10.52225/narra.v3i1.103 [doi]
LID - e103
AB  - Since its public release in November 2022, ChatGPT has gained a widespread 
      attention and received mixed responses in the academia. Promising applications of 
      ChatGPT in university education has been suggested; however, several concerns 
      were raised. The aim of this descriptive study was to investigate the pros and 
      cons of ChatGPT use in medical, dental, pharmacy, and public health education. 
      Based on expert panel discussion and review of the existing literature, specific 
      and concise ChatGPT prompts were constructed and the responses were generated on 
      25 February 2023. Out data suggested that in medical education, ChatGPT benefits 
      included the possibility of improving personalized learning, clinical reasoning 
      and understanding of complex medical concepts. The benefits listed in the context 
      of dental education included improved skills through step- by-step instructions 
      and interactive content, with instant feedback on student techniques. In pharmacy 
      education, the advantages included possible explanations of complex subjects and 
      the deployment of interactive tools aiding to develop skills for patient 
      counselling. In public health education, the listed benefits included providing 
      explanations and case scenarios, besides improved skills in data analysis and 
      literature review. The limitations listed based on ChatGPT-generated content were 
      common across all of the investigated healthcare disciplines and included data 
      privacy issues, risk of generating biased and inaccurate content, and the risk of 
      deterioration of critical thinking and communication skills among healthcare 
      students. The ChatGPT-generated content in the context of healthcare education 
      was deemed partially helpful by the expert panel. However, several important 
      points regarding the pros and cons of ChatGPT use in medical, dental, pharmacy 
      and public health education were missed by ChatGPT- generated content including: 
      the risk of plagiarism, copyright issues, the risk of academic dishonesty, and 
      the lack of personal and emotional interactions necessary for developing proper 
      communication skills in healthcare education. In conclusion, despite the 
      promising prospects of ChatGPT in healthcare education, several drawbacks should 
      be addressed with implementation of guidelines for proper use to ensure 
      exploiting the benefits of this innovative technology.
CI  - © 2023 The Author(s).
FAU - Sallam, Malik
AU  - Sallam M
AD  - Department of Pathology, Microbiology and Forensic Medicine, School of Medicine, 
      The University of Jordan, Amman, Jordan.
AD  - Department of Clinical Laboratories and Forensic Medicine, Jordan University 
      Hospital, Amman, Jordan.
AD  - Department of Translational Medicine, Faculty of Medicine, Lund University, 
      Malmö, Sweden.
FAU - Salim, Nesreen A
AU  - Salim NA
AD  - Department of Prosthodontic, School of Dentistry, The University of Jordan, 
      Amman, Jordan.
AD  - Department of Prosthodontic, Jordan University Hospital, Amman, Jordan.
FAU - Barakat, Muna
AU  - Barakat M
AD  - Department of Clinical Pharmacy and Therapeutics, Faculty of Pharmacy, Applied 
      Science Private University, Amman, Jordan.
FAU - Al-Tammemi, Ala'a B
AU  - Al-Tammemi AB
AD  - Migration Health Division, International Organization for Migration (IOM), The UN 
      Migration Agency, Amman, Jordan.
LA  - eng
PT  - Journal Article
DEP - 20230329
PL  - Indonesia
TA  - Narra J
JT  - Narra J
JID - 9918625888906676
PMC - PMC10914078
OTO - NOTNLM
OT  - Artificial intelligence
OT  - education
OT  - healthcare
OT  - machine learning
OT  - technology
COIS- All the authors declare that there are no conflicts of interest.
EDAT- 2024/03/07 06:43
MHDA- 2024/03/07 06:44
PMCR- 2023/03/29
CRDT- 2024/03/07 04:13
PHST- 2023/03/04 00:00 [received]
PHST- 2023/03/28 00:00 [accepted]
PHST- 2024/03/07 06:44 [medline]
PHST- 2024/03/07 06:43 [pubmed]
PHST- 2024/03/07 04:13 [entrez]
PHST- 2023/03/29 00:00 [pmc-release]
AID - NarraJ-3-e103 [pii]
AID - 10.52225/narra.v3i1.103 [doi]
PST - ppublish
SO  - Narra J. 2023 Apr;3(1):e103. doi: 10.52225/narra.v3i1.103. Epub 2023 Mar 29.

PMID- 37735339
OWN - NLM
STAT- MEDLINE
DCOM- 20240115
LR  - 20240115
IS  - 1534-6285 (Electronic)
IS  - 1527-2737 (Linking)
VI  - 25
IP  - 1
DP  - 2024 Jan
TI  - Exploring the Ethical, Legal, and Social Implications of ChatGPT in Urology.
PG  - 1-8
LID - 10.1007/s11934-023-01185-2 [doi]
AB  - PURPOSE OF THE REVIEW: ChatGPT is programmed to generate responses based on 
      pattern recognition. With this vast popularity and exponential growth, the 
      question arises of moral issues, security and legitimacy. In this review article, 
      we aim to analyze the ethical and legal implications of using ChatGPT in Urology 
      and explore potential solutions addressing these concerns. RECENT FINDINGS: There 
      are many potential applications of ChatGPT in urology, and the extent to which it 
      might improve healthcare may cause a profound shift in the way we deliver our 
      services to patients and the overall healthcare system. This encompasses 
      diagnosis and treatment planning, clinical workflow, patient education, 
      augmenting consultations, and urological research. The ethical and legal 
      considerations include patient autonomy and informed consent, privacy and 
      confidentiality, bias and fairness, human oversight and accountability, trust and 
      transparency, liability and malpractice, intellectual property rights, and 
      regulatory framework. The application of ChatGPT in urology has shown great 
      potential to improve patient care and assist urologists in various aspects of 
      clinical practice, research, and education. Complying with data security and 
      privacy regulations, and ensuring human oversight and accountability are some 
      potential solutions to these legal and ethical concerns. Overall, the benefits 
      and risks of using ChatGPT in urology must be weighed carefully, and a cautious 
      approach must be taken to ensure that its use aligns with human values and 
      advances patient care ethically and responsibly.
CI  - © 2023. The Author(s), under exclusive licence to Springer Science+Business 
      Media, LLC, part of Springer Nature.
FAU - Adhikari, Kinju
AU  - Adhikari K
AD  - Department of Urology, HCG Cancer Centre, Bangaluru, India.
FAU - Naik, Nithesh
AU  - Naik N
AD  - Department of Mechanical and Industrial Engineering, Manipal Institute of 
      Technology, Manipal Academy of Higher Education, Manipal, Karnataka, India.
FAU - Hameed, Bm Zeeshan
AU  - Hameed BZ
AD  - Department of Urology, Father Muller Medical College, Mangalore, Karnataka, 
      India.
FAU - Raghunath, S K
AU  - Raghunath SK
AD  - Department of Urology, HCG Cancer Centre, Bangaluru, India.
FAU - Somani, Bhaskar K
AU  - Somani BK
AD  - Department of Urology, University Hospital Southampton NHS Trust, Southampton, 
      SO16 6YD, UK. bhaskarsomani@yahoo.com.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230922
PL  - United States
TA  - Curr Urol Rep
JT  - Current urology reports
JID - 100900943
SB  - IM
MH  - Humans
MH  - *Urology
MH  - Confidentiality
MH  - Informed Consent
MH  - Delivery of Health Care
OTO - NOTNLM
OT  - AI-based tools
OT  - ChatGPT
OT  - Ethical implications.
OT  - Legal implications
OT  - Social implications
OT  - Urology
EDAT- 2023/09/22 06:42
MHDA- 2024/01/15 12:43
CRDT- 2023/09/22 00:23
PHST- 2023/09/05 00:00 [accepted]
PHST- 2024/01/15 12:43 [medline]
PHST- 2023/09/22 06:42 [pubmed]
PHST- 2023/09/22 00:23 [entrez]
AID - 10.1007/s11934-023-01185-2 [pii]
AID - 10.1007/s11934-023-01185-2 [doi]
PST - ppublish
SO  - Curr Urol Rep. 2024 Jan;25(1):1-8. doi: 10.1007/s11934-023-01185-2. Epub 2023 Sep 
      22.

PMID- 37622581
OWN - NLM
STAT- Publisher
LR  - 20230825
IS  - 1097-6817 (Electronic)
IS  - 0194-5998 (Linking)
DP  - 2023 Aug 25
TI  - BPPV Information on Google Versus&nbsp;AI (ChatGPT).
LID - 10.1002/ohn.506 [doi]
AB  - OBJECTIVE: To quantitatively compare online patient education materials found 
      using traditional search engines (Google) versus conversational Artificial 
      Intelligence (AI) models (ChatGPT) for benign paroxysmal positional vertigo 
      (BPPV). STUDY DESIGN: The top 30 Google search results for "benign paroxysmal 
      positional vertigo" were compared to the OpenAI conversational AI language model, 
      ChatGPT, responses for 5 common patient questions posed about BPPV in February 
      2023. Metrics included readability, quality, understandability, and 
      actionability. SETTING: Online information. METHODS: Validated online information 
      metrics including Flesch-Kincaid Grade Level (FKGL), Flesch Reading Ease (FRE), 
      DISCERN instrument score, and Patient Education Materials Assessment Tool for 
      Printed Materials were analyzed and scored by reviewers. RESULTS: Mean 
      readability scores, FKGL and FRE, for the Google webpages were 10.7 ± 2.6 and 
      46.5 ± 14.3, respectively. ChatGPT responses had a higher FKGL score of 
      13.9 ± 2.5 (P &lt; .001) and a lower FRE score of 34.9 ± 11.2 (P = .005), both 
      corresponding to lower readability. The Google webpages had a DISCERN part 2 
      score of 25.4 ± 7.5 compared to the individual ChatGPT responses with a score of 
      17.5 ± 3.9 (P = .001), and the combined ChatGPT responses with a score of 
      25.0 ± 0.9 (P = .928). The average scores of the reviewers for all ChatGPT 
      responses for accuracy were 4.19 ± 0.82 and 4.31 ± 0.67 for currency. CONCLUSION: 
      The results of this study suggest that the information on ChatGPT is more 
      difficult to read, of lower quality, and more difficult to comprehend compared to 
      information on Google searches.
CI  - © 2023 American Academy of Otolaryngology-Head and Neck Surgery Foundation.
FAU - Bellinger, Jeffrey R
AU  - Bellinger JR
AD  - Department of Otolaryngology-Head and Neck Surgery, University of Virginia School 
      of Medicine, Charlottesville, Virginia, USA.
FAU - De La Chapa, Julian S
AU  - De La Chapa JS
AD  - Department of Otolaryngology-Head and Neck Surgery, University of Virginia School 
      of Medicine, Charlottesville, Virginia, USA.
FAU - Kwak, Minhie W
AU  - Kwak MW
AD  - Department of Otolaryngology-Head and Neck Surgery, University of Virginia School 
      of Medicine, Charlottesville, Virginia, USA.
FAU - Ramos, Gabriel A
AU  - Ramos GA
AD  - Department of Otolaryngology-Head and Neck Surgery, University of Virginia School 
      of Medicine, Charlottesville, Virginia, USA.
FAU - Morrison, Daniel
AU  - Morrison D
AD  - Department of Otolaryngology-Head and Neck Surgery, University of Virginia School 
      of Medicine, Charlottesville, Virginia, USA.
FAU - Kesser, Bradley W
AU  - Kesser BW
AD  - Department of Otolaryngology-Head and Neck Surgery, University of Virginia School 
      of Medicine, Charlottesville, Virginia, USA.
LA  - eng
PT  - Journal Article
DEP - 20230825
PL  - England
TA  - Otolaryngol Head Neck Surg
JT  - Otolaryngology--head and neck surgery : official journal of American Academy of 
      Otolaryngology-Head and Neck Surgery
JID - 8508176
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - Google
OT  - artificial intelligence
OT  - benign paroxysmal positional vertigo
OT  - online information
OT  - quality
OT  - readability
OT  - understandability
EDAT- 2023/08/25 12:42
MHDA- 2023/08/25 12:42
CRDT- 2023/08/25 07:22
PHST- 2023/06/25 00:00 [received]
PHST- 2023/07/29 00:00 [accepted]
PHST- 2023/08/25 12:42 [medline]
PHST- 2023/08/25 12:42 [pubmed]
PHST- 2023/08/25 07:22 [entrez]
AID - 10.1002/ohn.506 [doi]
PST - aheadofprint
SO  - Otolaryngol Head Neck Surg. 2023 Aug 25. doi: 10.1002/ohn.506.

PMID- 37209880
OWN - NLM
STAT- MEDLINE
DCOM- 20230814
LR  - 20230814
IS  - 1527-9995 (Electronic)
IS  - 0090-4295 (Linking)
VI  - 177
DP  - 2023 Jul
TI  - ChatGPT Performance on the American Urological Association Self-assessment Study 
      Program and the Potential Influence of Artificial Intelligence in Urologic 
      Training.
PG  - 29-33
LID - S0090-4295(23)00442-9 [pii]
LID - 10.1016/j.urology.2023.05.010 [doi]
AB  - OBJECTIVE: To assess chat generative pre-trained transformer's (ChatGPT) 
      performance on&nbsp;the American&nbsp;Urological Association Self-Assessment Study Program 
      (AUA SASP) and stratify performance by question stem complexity. METHODS: 
      Questions from the 2021-2022 AUA SASP program&nbsp;were administered to ChatGPT 
      version 3 (ChatGPT-3). Questions were administered to the model utilizing a 
      standardized prompt. The answer choice selected by ChatGPT was then used to 
      answer the question stem in the AUA SASP program. ChatGPT was then prompted to 
      assign a question stem order (first, second, third) to each question. The 
      percentage of correctly answered questions was determined for each order level. 
      All responses provided by ChatGPT were qualitatively assessed for appropriate 
      rationale. RESULTS: A total of 268 questions were administered to ChatGPT. 
      ChatGPT performed better on 2021 compared to the&nbsp;2022 AUA SASP question set, 
      answering 42.3% versus 30.0% of questions correctly (P&nbsp;&lt;&nbsp;.05). Hundred percent&nbsp;of 
      answer explanations provided appropriate, relevant rationale regardless of 
      whether the answer was correct. Further stratification included assessment by 
      question order level. ChatGPT performed progressively better on the 2021 question 
      set with decreasing order levels, with first-order questions reaching 53.8% 
      (n&nbsp;=&nbsp;14). However, differences in proportions did not reach statistical 
      significance (P&nbsp;&gt;&nbsp;.05). CONCLUSION: ChatGPT answered many high-level questions 
      correctly and provided a reasonable rationale for each answer choice. While 
      ChatGPT was unable to answer numerous first-order questions, future language 
      processing model&nbsp;learning may lead to the optimization of its fund of knowledge. 
      This may lead to the utilization of artificial intelligence like ChatGPT as an 
      educational tool for urology trainees and professors.
CI  - Copyright © 2023 Elsevier Inc. All rights reserved.
FAU - Deebel, Nicholas A
AU  - Deebel NA
AD  - Department of Urology, Wake Forest University School of Medicine, Winston-Salem, 
      NC. Electronic address: ndeebel@wakehealth.edu.
FAU - Terlecki, Ryan
AU  - Terlecki R
AD  - Department of Urology, Wake Forest University School of Medicine, Winston-Salem, 
      NC. Electronic address: rterlecki@wakehealth.edu.
LA  - eng
PT  - Journal Article
DEP - 20230518
PL  - United States
TA  - Urology
JT  - Urology
JID - 0366151
SB  - IM
MH  - Humans
MH  - Artificial Intelligence
MH  - Self-Assessment
MH  - *Urologic Diseases
MH  - *Urology
MH  - Educational Status
COIS- Declaration of Competing Interest Nicholas Deebel, MD: No relevant conflict of 
      interest. Ryan Terlecki, MD: paid consultant to Boston Scientific (not relevant 
      to this manuscript).
EDAT- 2023/05/21 01:05
MHDA- 2023/08/14 06:42
CRDT- 2023/05/20 19:27
PHST- 2023/03/07 00:00 [received]
PHST- 2023/04/01 00:00 [revised]
PHST- 2023/05/09 00:00 [accepted]
PHST- 2023/08/14 06:42 [medline]
PHST- 2023/05/21 01:05 [pubmed]
PHST- 2023/05/20 19:27 [entrez]
AID - S0090-4295(23)00442-9 [pii]
AID - 10.1016/j.urology.2023.05.010 [doi]
PST - ppublish
SO  - Urology. 2023 Jul;177:29-33. doi: 10.1016/j.urology.2023.05.010. Epub 2023 May 
      18.

PMID- 37142327
OWN - NLM
STAT- MEDLINE
DCOM- 20230919
LR  - 20240320
IS  - 1742-6723 (Electronic)
IS  - 1742-6731 (Print)
IS  - 1742-6723 (Linking)
VI  - 35
IP  - 5
DP  - 2023 Oct
TI  - Generative artificial intelligence: Can ChatGPT write a quality abstract?
PG  - 809-811
LID - 10.1111/1742-6723.14233 [doi]
AB  - ChatGPT is a generative artificial intelligence chatbot which may have a role in 
      medicine and science. We investigated if the freely available version of ChatGPT 
      can produce a quality conference abstract using a fictitious but accurately 
      calculated data table as applied by a non-medically trained person. The resulting 
      abstract was well written without obvious errors and followed the abstract 
      instructions. One of the references was fictitious, known as 'hallucination'. 
      ChatGPT or similar programmes, with careful review of the product by authors, may 
      become a valuable scientific writing tool. The scientific and medical use of 
      generative artificial intelligence, however, raises many questions.
CI  - © 2023 The Authors. Emergency Medicine Australasia published by John Wiley &amp; Sons 
      Australia, Ltd on behalf of Australasian College for Emergency Medicine.
FAU - Babl, Franz E
AU  - Babl FE
AUID- ORCID: 0000-0002-1107-2187
AD  - Emergency Department, The Royal Children's Hospital, Melbourne, Victoria, 
      Australia.
AD  - Clinical Sciences, Murdoch Children's Research Institute, Melbourne, Victoria, 
      Australia.
AD  - Department of Paediatrics, Faculty of Medicine, Dentistry and Health Sciences, 
      The University of Melbourne, Melbourne, Victoria, Australia.
AD  - Department of Critical Care, Faculty of Medicine, Dentistry and Health Sciences, 
      The University of Melbourne, Melbourne, Victoria, Australia.
FAU - Babl, Maximilian P
AU  - Babl MP
AD  - Xavier College, Melbourne, Victoria, Australia.
LA  - eng
GR  - GNT2017605/National Health and Medical Research Council/
GR  - Royal Children's Hospital Foundation/
PT  - Journal Article
DEP - 20230504
PL  - Australia
TA  - Emerg Med Australas
JT  - Emergency medicine Australasia : EMA
JID - 101199824
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Medicine
MH  - Writing
PMC - PMC10946929
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - generative artificial intelligence
COIS- FEB is a section editor for Emergency Medicine Australasia. FEB and MPB are 
      related.
EDAT- 2023/05/05 00:42
MHDA- 2023/09/19 06:42
PMCR- 2024/03/18
CRDT- 2023/05/04 20:52
PHST- 2023/04/18 00:00 [received]
PHST- 2023/04/19 00:00 [accepted]
PHST- 2023/09/19 06:42 [medline]
PHST- 2023/05/05 00:42 [pubmed]
PHST- 2023/05/04 20:52 [entrez]
PHST- 2024/03/18 00:00 [pmc-release]
AID - EMM14233 [pii]
AID - 10.1111/1742-6723.14233 [doi]
PST - ppublish
SO  - Emerg Med Australas. 2023 Oct;35(5):809-811. doi: 10.1111/1742-6723.14233. Epub 
      2023 May 4.

PMID- 38133908
OWN - NLM
STAT- MEDLINE
DCOM- 20231225
LR  - 20240108
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Dec 22
TI  - Using ChatGPT for Clinical Practice and Medical Education: Cross-Sectional Survey 
      of Medical Students' and Physicians' Perceptions.
PG  - e50658
LID - 10.2196/50658 [doi]
LID - e50658
AB  - BACKGROUND: ChatGPT is a well-known large language model-based chatbot. It could 
      be used in the medical field in many aspects. However, some physicians are still 
      unfamiliar with ChatGPT and are concerned about its benefits and risks. 
      OBJECTIVE: We aim to evaluate the perception of physicians and medical students 
      toward using ChatGPT in the medical field. METHODS: A web-based questionnaire was 
      sent to medical students, interns, residents, and attending staff with questions 
      regarding their perception toward using ChatGPT in clinical practice and medical 
      education. Participants were also asked to rate their perception of ChatGPT's 
      generated response about knee osteoarthritis. RESULTS: Participants included 124 
      medical students, 46 interns, 37 residents, and 32 attending staff. After reading 
      ChatGPT's response, 132 of the 239 (55.2%) participants had a positive rating 
      about using ChatGPT for clinical practice. The proportion of positive answers was 
      significantly lower in graduated physicians (48/115, 42%) compared with medical 
      students (84/124, 68%; P&lt;.001). Participants listed a lack of a patient-specific 
      treatment plan, updated evidence, and a language barrier as ChatGPT's pitfalls. 
      Regarding using ChatGPT for medical education, the proportion of positive 
      responses was also significantly lower in graduate physicians (71/115, 62%) 
      compared to medical students (103/124, 83.1%; P&lt;.001). Participants were 
      concerned that ChatGPT's response was too superficial, might lack scientific 
      evidence, and might need expert verification. CONCLUSIONS: Medical students 
      generally had a positive perception of using ChatGPT for guiding treatment and 
      medical education, whereas graduated doctors were more cautious in this regard. 
      Nonetheless, both medical students and graduated doctors positively perceived 
      using ChatGPT for creating patient educational materials.
CI  - ©Pasin Tangadulrat, Supinya Sono, Boonsin Tangtrakulwanich. Originally published 
      in JMIR Medical Education (https://mededu.jmir.org), 22.12.2023.
FAU - Tangadulrat, Pasin
AU  - Tangadulrat P
AUID- ORCID: 0000-0003-0346-7135
AD  - Department of Orthopedics, Faculty of Medicine, Prince of Songkla University, 
      Hatyai, Thailand.
FAU - Sono, Supinya
AU  - Sono S
AUID- ORCID: 0000-0003-3145-1907
AD  - Division of Family and Preventive Medicine, Faculty of Medicine, Prince of 
      Songkla University, Hatyai, Thailand.
FAU - Tangtrakulwanich, Boonsin
AU  - Tangtrakulwanich B
AUID- ORCID: 0000-0003-0933-1669
AD  - Department of Orthopedics, Faculty of Medicine, Prince of Songkla University, 
      Hatyai, Thailand.
LA  - eng
PT  - Journal Article
DEP - 20231222
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
SB  - IM
MH  - Humans
MH  - Cross-Sectional Studies
MH  - *Students, Medical
MH  - *Education, Medical
MH  - Language
MH  - *Physicians
PMC - PMC10770783
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - acceptance
OT  - artificial intelligence
OT  - attitude
OT  - attitudes
OT  - chatbot
OT  - chatbots
OT  - conversational agent
OT  - conversational agents
OT  - intern
OT  - interns
OT  - knee osteoarthritis
OT  - medical education
OT  - medical students
OT  - opinion
OT  - opinions
OT  - perception
OT  - perceptions
OT  - perspective
OT  - perspectives
OT  - questionnaire
OT  - questionnaires
OT  - resident
OT  - residents
OT  - student
OT  - students
OT  - survey
OT  - surveys
COIS- Conflicts of Interest: None declared.
EDAT- 2023/12/22 12:42
MHDA- 2023/12/25 06:42
PMCR- 2023/12/22
CRDT- 2023/12/22 11:53
PHST- 2023/07/08 00:00 [received]
PHST- 2023/12/11 00:00 [accepted]
PHST- 2023/10/17 00:00 [revised]
PHST- 2023/12/25 06:42 [medline]
PHST- 2023/12/22 12:42 [pubmed]
PHST- 2023/12/22 11:53 [entrez]
PHST- 2023/12/22 00:00 [pmc-release]
AID - v9i1e50658 [pii]
AID - 10.2196/50658 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Dec 22;9:e50658. doi: 10.2196/50658.

PMID- 38217884
OWN - NLM
STAT- MEDLINE
DCOM- 20240115
LR  - 20240118
IS  - 1087-2981 (Electronic)
IS  - 1087-2981 (Linking)
VI  - 29
IP  - 1
DP  - 2024 Dec 31
TI  - Challenge, integration, and change: ChatGPT and future anatomical education.
PG  - 2304973
LID - 10.1080/10872981.2024.2304973 [doi]
LID - 2304973
AB  - With the vigorous development of ChatGPT and its application in the field of 
      education, a new era of the collaborative development of human and artificial 
      intelligence and the symbiosis of education has come. Integrating artificial 
      intelligence (AI) into medical education has the potential to revolutionize it. 
      Large language models, such as ChatGPT, can be used as virtual teaching aids to 
      provide students with individualized and immediate medical knowledge, and conduct 
      interactive simulation learning and detection. In this paper, we discuss the 
      application of ChatGPT in anatomy teaching and its various application levels 
      based on our own teaching experiences, and discuss the advantages and 
      disadvantages of ChatGPT in anatomy teaching. ChatGPT increases student 
      engagement and strengthens students' ability to learn independently. At the same 
      time, ChatGPT faces many challenges and limitations in medical education. Medical 
      educators must keep pace with the rapid changes in technology, taking into 
      account ChatGPT's impact on curriculum design, assessment strategies and teaching 
      methods. Discussing the application of ChatGPT in medical education, especially 
      anatomy teaching, is helpful to the effective integration and application of 
      artificial intelligence tools in medical education.
FAU - Leng, Lige
AU  - Leng L
AUID- ORCID: 0000-0002-4288-4743
AD  - Fujian Provincial Key Laboratory of Neurodegenerative Disease and Aging Research, 
      Institute of Neuroscience, School of Medicine, Xiamen University, Xiamen, Fujian, 
      P.R. China.
LA  - eng
PT  - Journal Article
DEP - 20240113
PL  - United States
TA  - Med Educ Online
JT  - Medical education online
JID - 9806550
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Educational Status
MH  - *Students
MH  - Curriculum
MH  - Learning
PMC - PMC10791098
OTO - NOTNLM
OT  - ChatGPT
OT  - anatomy
OT  - artificial intelligence
OT  - educational reform
OT  - medical education
COIS- No potential conflict of interest was reported by the author(s).
EDAT- 2024/01/14 12:42
MHDA- 2024/01/15 12:43
PMCR- 2024/01/13
CRDT- 2024/01/13 14:32
PHST- 2024/01/15 12:43 [medline]
PHST- 2024/01/14 12:42 [pubmed]
PHST- 2024/01/13 14:32 [entrez]
PHST- 2024/01/13 00:00 [pmc-release]
AID - 2304973 [pii]
AID - 10.1080/10872981.2024.2304973 [doi]
PST - ppublish
SO  - Med Educ Online. 2024 Dec 31;29(1):2304973. doi: 10.1080/10872981.2024.2304973. 
      Epub 2024 Jan 13.

PMID- 37578934
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230922
IS  - 2369-3762 (Print)
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Sep 5
TI  - Assessing Health Students' Attitudes and Usage of ChatGPT in Jordan: Validation 
      Study.
PG  - e48254
LID - 10.2196/48254 [doi]
LID - e48254
AB  - BACKGROUND: ChatGPT is a conversational large language model that has the 
      potential to revolutionize knowledge acquisition. However, the impact of this 
      technology on the quality of education is still unknown considering the risks and 
      concerns surrounding ChatGPT use. Therefore, it is necessary to assess the 
      usability and acceptability of this promising tool. As an innovative technology, 
      the intention to use ChatGPT can be studied in the context of the technology 
      acceptance model (TAM). OBJECTIVE: This study aimed to develop and validate a 
      TAM-based survey instrument called TAME-ChatGPT (Technology Acceptance Model 
      Edited to Assess ChatGPT Adoption) that could be employed to examine the 
      successful integration and use of ChatGPT in health care education. METHODS: The 
      survey tool was created based on the TAM framework. It comprised 13 items for 
      participants who heard of ChatGPT but did not use it and 23 items for 
      participants who used ChatGPT. Using a convenient sampling approach, the survey 
      link was circulated electronically among university students between February and 
      March 2023. Exploratory factor analysis (EFA) was used to assess the construct 
      validity of the survey instrument. RESULTS: The final sample comprised 458 
      respondents, the majority among them undergraduate students (n=442, 96.5%). Only 
      109 (23.8%) respondents had heard of ChatGPT prior to participation and only 55 
      (11.3%) self-reported ChatGPT use before the study. EFA analysis on the attitude 
      and usage scales showed significant Bartlett tests of sphericity scores (P&lt;.001) 
      and adequate Kaiser-Meyer-Olkin measures (0.823 for the attitude scale and 0.702 
      for the usage scale), confirming the factorability of the correlation matrices. 
      The EFA showed that 3 constructs explained a cumulative total of 69.3% variance 
      in the attitude scale, and these subscales represented perceived risks, attitude 
      to technology/social influence, and anxiety. For the ChatGPT usage scale, EFA 
      showed that 4 constructs explained a cumulative total of 72% variance in the data 
      and comprised the perceived usefulness, perceived risks, perceived ease of use, 
      and behavior/cognitive factors. All the ChatGPT attitude and usage subscales 
      showed good reliability with Cronbach α values &gt;.78 for all the deduced 
      subscales. CONCLUSIONS: The TAME-ChatGPT demonstrated good reliability, validity, 
      and usefulness in assessing health care students' attitudes toward ChatGPT. The 
      findings highlighted the importance of considering risk perceptions, usefulness, 
      ease of use, attitudes toward technology, and behavioral factors when adopting 
      ChatGPT as a tool in health care education. This information can aid the 
      stakeholders in creating strategies to support the optimal and ethical use of 
      ChatGPT and to identify the potential challenges hindering its successful 
      implementation. Future research is recommended to guide the effective adoption of 
      ChatGPT in health care education.
CI  - ©Malik Sallam, Nesreen A Salim, Muna Barakat, Kholoud Al-Mahzoum, Ala'a B 
      Al-Tammemi, Diana Malaeb, Rabih Hallit, Souheil Hallit. Originally published in 
      JMIR Medical Education (https://mededu.jmir.org), 05.09.2023.
FAU - Sallam, Malik
AU  - Sallam M
AUID- ORCID: 0000-0002-0165-9670
AD  - Department of Pathology, Microbiology and Forensic Medicine, School of Medicine, 
      The University of Jordan, Amman, Jordan.
AD  - Department of Clinical Laboratories and Forensic Medicine, Jordan University 
      Hospital, Amman, Jordan.
FAU - Salim, Nesreen A
AU  - Salim NA
AUID- ORCID: 0000-0002-5355-2269
AD  - Prosthodontic Department, School of Dentistry, The University of Jordan, Amman, 
      Jordan.
AD  - Prosthodontic Department, Jordan University Hospital, Amman, Jordan.
FAU - Barakat, Muna
AU  - Barakat M
AUID- ORCID: 0000-0002-7966-1172
AD  - Department of Clinical Pharmacy and Therapeutics, Faculty of Pharmacy, Applied 
      Science Private University, Amman, Jordan.
AD  - Middle East University Research Unit, Middle East University, Amman, Jordan.
FAU - Al-Mahzoum, Kholoud
AU  - Al-Mahzoum K
AUID- ORCID: 0009-0002-0143-7645
AD  - Department of Pathology, Microbiology and Forensic Medicine, School of Medicine, 
      The University of Jordan, Amman, Jordan.
FAU - Al-Tammemi, Ala'a B
AU  - Al-Tammemi AB
AUID- ORCID: 0000-0003-0862-0186
AD  - Migration Health Division, International Organization for Migration, The United 
      Nations Migration Agency, Amman, Jordan.
FAU - Malaeb, Diana
AU  - Malaeb D
AUID- ORCID: 0000-0002-2436-850X
AD  - College of Pharmacy, Gulf Medical University, Ajman, United Arab Emirates.
FAU - Hallit, Rabih
AU  - Hallit R
AUID- ORCID: 0000-0003-1817-6146
AD  - School of Medicine and Medical Sciences, Holy Spirit University of Kaslik, 
      Jounieh, Lebanon.
AD  - Department of Infectious Disease, Bellevue Medical Center, Mansourieh, Lebanon.
AD  - Department of Infectious Disease, Notre Dame des Secours, University Hospital 
      Center, Byblos, Lebanon.
FAU - Hallit, Souheil
AU  - Hallit S
AUID- ORCID: 0000-0001-6918-5689
AD  - School of Medicine and Medical Sciences, Holy Spirit University of Kaslik, 
      Jounieh, Lebanon.
AD  - Research Department, Psychiatric Hospital of the Cross, Jal Eddib, Lebanon.
LA  - eng
PT  - Journal Article
DEP - 20230905
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
PMC - PMC10509747
OTO - NOTNLM
OT  - KAP
OT  - artificial intelligence
OT  - education
OT  - healthcare
OT  - knowledge
OT  - machine learning
OT  - opinion
OT  - practices
OT  - survey
OT  - technology
COIS- Conflicts of Interest: None declared.
EDAT- 2023/08/14 18:42
MHDA- 2023/08/14 18:43
PMCR- 2023/09/05
CRDT- 2023/08/14 13:13
PHST- 2023/04/17 00:00 [received]
PHST- 2023/08/14 00:00 [accepted]
PHST- 2023/07/25 00:00 [revised]
PHST- 2023/08/14 18:43 [medline]
PHST- 2023/08/14 18:42 [pubmed]
PHST- 2023/08/14 13:13 [entrez]
PHST- 2023/09/05 00:00 [pmc-release]
AID - v9i1e48254 [pii]
AID - 10.2196/48254 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Sep 5;9:e48254. doi: 10.2196/48254.

PMID- 37954270
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231122
IS  - 2405-8440 (Print)
IS  - 2405-8440 (Electronic)
IS  - 2405-8440 (Linking)
VI  - 9
IP  - 11
DP  - 2023 Nov
TI  - Humans are still better than ChatGPT: Case of the IEEEXtreme competition.
PG  - e21624
LID - 10.1016/j.heliyon.2023.e21624 [doi]
LID - e21624
AB  - Since the release of ChatGPT, numerous studies have highlighted the remarkable 
      performance of ChatGPT, which often rivals or even surpasses human capabilities 
      in various tasks and domains. However, this paper presents a contrasting 
      perspective by demonstrating an instance where human performance excels in 
      typical tasks suited for ChatGPT, specifically in the domain of computer 
      programming. We utilize the IEEExtreme Challenge competition as a benchmark-a 
      prestigious, annual international programming contest encompassing a wide range 
      of problems with different complexities. To conduct a thorough evaluation, we 
      selected and executed a diverse set of 102 challenges, drawn from five distinct 
      IEEExtreme editions, using three major programming languages: Python, Java, and 
      C++. Our empirical analysis provides evidence that contrary to popular belief, 
      human programmers maintain a competitive edge over ChatGPT in certain aspects of 
      problem-solving within the programming context. In fact, we found that the 
      average score obtained by ChatGPT on the set of IEEExtreme programming problems 
      is 3.9 to 5.8 times lower than the average human score, depending on the 
      programming language. This paper elaborates on these findings, offering critical 
      insights into the limitations and potential areas of improvement for AI-based 
      language models like ChatGPT.
CI  - © 2023 The Authors.
FAU - Koubaa, Anis
AU  - Koubaa A
AD  - Robotics and Internet-of-Things Laboratory, Prince Sultan University, Riyadh 
      12435, Saudi Arabia.
FAU - Qureshi, Basit
AU  - Qureshi B
AD  - Robotics and Internet-of-Things Laboratory, Prince Sultan University, Riyadh 
      12435, Saudi Arabia.
FAU - Ammar, Adel
AU  - Ammar A
AD  - Robotics and Internet-of-Things Laboratory, Prince Sultan University, Riyadh 
      12435, Saudi Arabia.
FAU - Khan, Zahid
AU  - Khan Z
AD  - Robotics and Internet-of-Things Laboratory, Prince Sultan University, Riyadh 
      12435, Saudi Arabia.
FAU - Boulila, Wadii
AU  - Boulila W
AD  - Robotics and Internet-of-Things Laboratory, Prince Sultan University, Riyadh 
      12435, Saudi Arabia.
FAU - Ghouti, Lahouari
AU  - Ghouti L
AD  - Robotics and Internet-of-Things Laboratory, Prince Sultan University, Riyadh 
      12435, Saudi Arabia.
LA  - eng
PT  - Journal Article
DEP - 20231029
PL  - England
TA  - Heliyon
JT  - Heliyon
JID - 101672560
PMC - PMC10638003
OTO - NOTNLM
OT  - ChatGPT
OT  - Computer programming
OT  - GPT limitations
OT  - GPT performance
OT  - GPT-3.5
OT  - GPT-4
OT  - NLP
OT  - OpenAI
COIS- The authors declare that they have no known competing financial interests or 
      personal relationships that could have appeared to influence the work reported in 
      this paper.
EDAT- 2023/11/13 06:43
MHDA- 2023/11/13 06:44
PMCR- 2023/10/29
CRDT- 2023/11/13 04:28
PHST- 2023/05/27 00:00 [received]
PHST- 2023/10/06 00:00 [revised]
PHST- 2023/10/25 00:00 [accepted]
PHST- 2023/11/13 06:44 [medline]
PHST- 2023/11/13 06:43 [pubmed]
PHST- 2023/11/13 04:28 [entrez]
PHST- 2023/10/29 00:00 [pmc-release]
AID - S2405-8440(23)08832-1 [pii]
AID - e21624 [pii]
AID - 10.1016/j.heliyon.2023.e21624 [doi]
PST - epublish
SO  - Heliyon. 2023 Oct 29;9(11):e21624. doi: 10.1016/j.heliyon.2023.e21624. 
      eCollection 2023 Nov.

PMID- 37208451
OWN - NLM
STAT- MEDLINE
DCOM- 20231023
LR  - 20231023
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 51
IP  - 10
DP  - 2023 Oct
TI  - Can ChatGPT be Trusted for Consulting? Uncovering Doctor's Perceptions Using Deep 
      Learning Techniques.
PG  - 2116-2119
LID - 10.1007/s10439-023-03245-7 [doi]
AB  - Since the introduction of ChatGPT by OpenAI in late 2022, the question of whether 
      doctors can employ it for consultation has been a subject of debate. ChatGPT is a 
      deep learning model trained on a vast dataset, but concerns about the reliability 
      of its output have been a subject of debate in recent times. In this article, we 
      have employed cutting-edge bidirectional encoder representations from 
      transformers (BERT) sentiment analysis and topic modeling techniques to 
      comprehend doctors' attitudes toward using ChatGPT in consultation.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Praveen, S V
AU  - Praveen SV
AUID- ORCID: 0000-0002-1450-8839
AD  - Department of Analytics, Xavier Institute of Management and Entrepreneurship, 
      Bangalore, India. praveenscissci@gmail.com.
FAU - Vajrobol, Vajratiya
AU  - Vajrobol V
AD  - Institute of Informatics and Communication, University of Delhi-South Campus, New 
      Delhi, India.
LA  - eng
PT  - Letter
DEP - 20230519
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - *Deep Learning
MH  - Reproducibility of Results
MH  - Referral and Consultation
MH  - Electric Power Supplies
OTO - NOTNLM
OT  - Artificial Intelligence
OT  - ChatGPT
OT  - Consulting
OT  - Deep learning
OT  - Doctor
EDAT- 2023/05/20 09:42
MHDA- 2023/10/23 00:43
CRDT- 2023/05/19 23:22
PHST- 2023/05/12 00:00 [received]
PHST- 2023/05/15 00:00 [accepted]
PHST- 2023/10/23 00:43 [medline]
PHST- 2023/05/20 09:42 [pubmed]
PHST- 2023/05/19 23:22 [entrez]
AID - 10.1007/s10439-023-03245-7 [pii]
AID - 10.1007/s10439-023-03245-7 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2023 Oct;51(10):2116-2119. doi: 10.1007/s10439-023-03245-7. Epub 
      2023 May 19.

PMID- 37517980
OWN - NLM
STAT- MEDLINE
DCOM- 20230920
LR  - 20230920
IS  - 1479-666X (Print)
IS  - 1479-666X (Linking)
VI  - 21
IP  - 5
DP  - 2023 Oct
TI  - Assessing ChatGPT's ability to pass the FRCS orthopaedic part A exam: A critical 
      analysis.
PG  - 263-266
LID - S1479-666X(23)00076-8 [pii]
LID - 10.1016/j.surge.2023.07.001 [doi]
AB  - AI technology has made significant advancements in recent years, with the notable 
      development of ChatGPT in November 2022. Users have observed evidence of 
      deductive reasoning, logical thinking, and coherent thought in ChatGPT's 
      responses. This study aimed to determine if ChatGPT has the capability to pass 
      the Orthopaedic Fellow of the Royal College of Surgeons (FRCS Orth) Part A exam. 
      METHODS: To assess ChatGPT4's ability to pass the Orthopaedic FRCS Orth Part A 
      exam, a study was conducted using 240 mock FRCS Orth Part A questions. The study 
      evaluated the accuracy of ChatGPT's answers and the response time for each 
      question. Descriptive statistics were employed to analyse the chatbot's 
      performance. RESULTS: The evaluation revealed that ChatGPT4 achieved an overall 
      score of 67.5% on Part A of the exam. However, ChatGPT4 did not meet the overall 
      pass mark required for the FRCS Orth Part A exam. CONCLUSION: This study 
      demonstrates that ChatGPT was unable to pass the FRCS Orthopaedic examination. 
      Several factors contributed to this outcome, including the lack of critical or 
      high-order thinking abilities, limited clinical expertise, and the inability to 
      meet the rigorous requirements of the exam.
CI  - Copyright © 2023 Royal College of Surgeons of Edinburgh (Scottish charity number 
      SC005317) and Royal College of Surgeons in Ireland. Published by Elsevier Ltd. 
      All rights reserved.
FAU - Saad, Ahmed
AU  - Saad A
AD  - Department of Orthopedics, Royal Orthopedic Hospital, Birmingham, UK. Electronic 
      address: Ahmed.saad3@nhs.net.
FAU - Iyengar, Karthikeyan P
AU  - Iyengar KP
AD  - Department of Orthopedics, Southport and Ormskirk Hospital NHS Trust, Southport, 
      UK. Electronic address: kartikp31@hotmail.com.
FAU - Kurisunkal, Vineet
AU  - Kurisunkal V
AD  - Department of Orthopedic Oncology, Royal Orthopedic Hospital, Birmingham, UK. 
      Electronic address: vineetkurisunkal@gmail.com.
FAU - Botchu, Rajesh
AU  - Botchu R
AD  - Department of Musculoskeletal Radiology, Royal Orthopedic Hospital, Birmingham, 
      UK. Electronic address: drbrajesh@yahoo.com.
LA  - eng
PT  - Journal Article
DEP - 20230728
PL  - Scotland
TA  - Surgeon
JT  - The surgeon : journal of the Royal Colleges of Surgeons of Edinburgh and Ireland
JID - 101168329
SB  - IM
MH  - Humans
MH  - *Orthopedics
MH  - Physical Examination
MH  - *Surgeons
OTO - NOTNLM
OT  - Artificial intelligence (AI)
OT  - ChatGPT
OT  - FRCS orthopaedics
OT  - Medical exams
COIS- Declaration of competing interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2023/07/31 00:41
MHDA- 2023/09/20 06:42
CRDT- 2023/07/30 21:57
PHST- 2023/07/01 00:00 [received]
PHST- 2023/07/03 00:00 [accepted]
PHST- 2023/09/20 06:42 [medline]
PHST- 2023/07/31 00:41 [pubmed]
PHST- 2023/07/30 21:57 [entrez]
AID - S1479-666X(23)00076-8 [pii]
AID - 10.1016/j.surge.2023.07.001 [doi]
PST - ppublish
SO  - Surgeon. 2023 Oct;21(5):263-266. doi: 10.1016/j.surge.2023.07.001. Epub 2023 Jul 
      28.

PMID- 37303324
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230613
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 5
DP  - 2023 May
TI  - Proof of Concept: Using ChatGPT to Teach Emergency Physicians How to Break Bad 
      News.
PG  - e38755
LID - 10.7759/cureus.38755 [doi]
LID - e38755
AB  - Background Breaking bad news is an essential skill for practicing physicians, 
      particularly in the field of emergency medicine (EM). Patient-physician 
      communication teaching&nbsp;has previously relied on standardized patient scenarios 
      and objective structured clinical examination formats. The novel use of 
      artificial intelligence (AI) chatbot technology, such as Chat Generative 
      Pre-trained Transformer (ChatGPT), may provide an alternative role in graduate 
      medical education in this area. As a proof of concept, the author demonstrates 
      how providing detailed prompts to the AI chatbot can facilitate the design of a 
      realistic clinical scenario, enable active roleplay, and deliver effective 
      feedback to physician trainees. Methods ChatGPT-3.5 language model was utilized 
      to assist in the roleplay of breaking bad news.&nbsp;A detailed input prompt was 
      designed to outline rules of play and grading assessment via a standardized 
      scale. User inputs (physician role), chatbot outputs (patient role) and 
      ChatGPT-generated feedback were recorded. Results ChatGPT set up a realistic 
      training scenario on breaking bad news based on the initial prompt. Active 
      roleplay as a patient in an emergency department setting was accomplished, and 
      clear feedback was provided to the user through the application of the Setting 
      up, Perception, Invitation, Knowledge, Emotions with Empathy, and Strategy or 
      Summary (SPIKES) framework for breaking bad news. Conclusion The novel use of AI 
      chatbot technology to assist educators is abundant with potential.&nbsp;ChatGPT was 
      able to design an appropriate scenario, provide a means for simulated 
      patient-physician roleplay, and deliver real-time feedback to the physician user. 
      Future studies are required to expand use to a targeted group of EM physician 
      trainees and provide best practice guidelines for AI use in graduate medical 
      education.
CI  - Copyright © 2023, Webb et al.
FAU - Webb, Jeremy J
AU  - Webb JJ
AD  - Emergency Medicine, LewisGale Medical Center, Salem, USA.
AD  - School of Medicine, Edward Via College of Osteopathic Medicine, Blacksburg, USA.
LA  - eng
PT  - Journal Article
DEP - 20230509
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10250131
OTO - NOTNLM
OT  - artificial intelligence
OT  - breaking bad news
OT  - chatbot
OT  - chatgpt
OT  - machine learning
OT  - medical education
COIS- This research was supported (in whole or in part) by Hospital Corporation of 
      America (HCA) Healthcare and/or an HCA Healthcare-affiliated entity. The views 
      expressed in this manuscript represent those of the author and do not necessarily 
      represent the official views of HCA Healthcare or any of its affiliated entities.
EDAT- 2023/06/12 06:42
MHDA- 2023/06/12 06:43
PMCR- 2023/05/09
CRDT- 2023/06/12 03:53
PHST- 2023/05/08 00:00 [accepted]
PHST- 2023/06/12 06:43 [medline]
PHST- 2023/06/12 06:42 [pubmed]
PHST- 2023/06/12 03:53 [entrez]
PHST- 2023/05/09 00:00 [pmc-release]
AID - 10.7759/cureus.38755 [doi]
PST - epublish
SO  - Cureus. 2023 May 9;15(5):e38755. doi: 10.7759/cureus.38755. eCollection 2023 May.

PMID- 37900984
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231031
IS  - 2169-7574 (Print)
IS  - 2169-7574 (Electronic)
IS  - 2169-7574 (Linking)
VI  - 11
IP  - 10
DP  - 2023 Oct
TI  - Utilization of ChatGPT-4 in Plastic and Reconstructive Surgery: A Narrative 
      Review.
PG  - e5305
LID - 10.1097/GOX.0000000000005305 [doi]
LID - e5305
AB  - BACKGROUND: ChatGPT-4 (Chat Generative Pre-Trained Transformer) has demonstrated 
      remarkable capabilities in natural language processing and understanding, making 
      it a promising tool for various medical domains. This article presents a 
      comprehensive overview of the potential applications of ChatGPT-4, a cutting-edge 
      language model developed by OpenAI, in the field of plastic and reconstructive 
      surgery. METHODS: After conducting a thorough literature review, we discovered 
      pertinent articles that explore the application of ChatGPT-4 in plastic surgery. 
      By examining these findings and integrating the information with our personal 
      experience using ChatGPT-4 in the field of plastic surgery, we have produced an 
      all-encompassing narrative review. RESULTS: The narrative review focuses on three 
      main areas: clinical applications, research applications, and medical education. 
      In the clinical realm, ChatGPT-4 has the potential to streamline documentation 
      processes, improve communication, and enhance personalized patient care. It can 
      assist in generating accurate and comprehensive progress notes, operative notes, 
      surgical consent forms, on-call schedules, and consultation reports. However, it 
      is important to note that ChatGPT-4 should be used as a supportive tool and 
      should not replace human doctors. CONCLUSIONS: The potential applications of 
      ChatGPT-4 in plastic and reconstructive surgery are vast and promising. This 
      technology has the potential to revolutionize documentation, research, and 
      medical education in the field. However, it is crucial to integrate this tool 
      responsibly, considering its limitations and ensuring that human expertise 
      remains paramount.
CI  - Copyright © 2023 The Authors. Published by Wolters Kluwer Health, Inc. on behalf 
      of The American Society of Plastic Surgeons.
FAU - Aljindan, Fahad K
AU  - Aljindan FK
AD  - From the Department of Plastic Surgery, King Abdullah Medical City, Makkah, Saudi 
      Arabia.
FAU - Shawosh, Mohammed H
AU  - Shawosh MH
AD  - Division of Plastic Surgery, Department of Surgery, King Fahad Armed Forces 
      Hospital, Jeddah, Saudi Arabia.
FAU - Altamimi, Lamees
AU  - Altamimi L
AD  - From the Department of Plastic Surgery, King Abdullah Medical City, Makkah, Saudi 
      Arabia.
FAU - Arif, Sultan
AU  - Arif S
AD  - Department of Plastic Surgery and Burn Unit, Security Force Hospital, Riyadh, 
      Saudi Arabia.
AD  - Facharzt Plastic Surgery and Aesthetic Surgery, Riyadh, Saudi Arabia.
FAU - Mortada, Hatan
AU  - Mortada H
AD  - Division of Plastic Surgery, Department of Surgery, King Saud University Medical 
      City, King Saud University, Riyadh, Saudi Arabia.
AD  - Department of Plastic Surgery &amp; Burn Unit, King Saud Medical City, Riyadh, Saudi 
      Arabia.
LA  - eng
PT  - Journal Article
DEP - 20231026
PL  - United States
TA  - Plast Reconstr Surg Glob Open
JT  - Plastic and reconstructive surgery. Global open
JID - 101622231
PMC - PMC10602496
COIS- The authors have no financial interest to declare in relation to the content of 
      this article.
EDAT- 2023/10/30 06:46
MHDA- 2023/10/30 06:47
PMCR- 2023/10/26
CRDT- 2023/10/30 04:43
PHST- 2023/05/27 00:00 [received]
PHST- 2023/08/11 00:00 [accepted]
PHST- 2023/10/30 06:47 [medline]
PHST- 2023/10/30 06:46 [pubmed]
PHST- 2023/10/30 04:43 [entrez]
PHST- 2023/10/26 00:00 [pmc-release]
AID - 10.1097/GOX.0000000000005305 [doi]
PST - epublish
SO  - Plast Reconstr Surg Glob Open. 2023 Oct 26;11(10):e5305. doi: 
      10.1097/GOX.0000000000005305. eCollection 2023 Oct.

PMID- 38107064
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231219
IS  - 2234-943X (Print)
IS  - 2234-943X (Electronic)
IS  - 2234-943X (Linking)
VI  - 13
DP  - 2023
TI  - Is ChatGPT accurate and reliable in answering questions regarding head and neck 
      cancer?
PG  - 1256459
LID - 10.3389/fonc.2023.1256459 [doi]
LID - 1256459
AB  - BACKGROUND AND OBJECTIVE: Chat Generative Pre-trained Transformer (ChatGPT) is an 
      artificial intelligence (AI)-based language processing model using deep learning 
      to create human-like text dialogue. It has been a popular source of information 
      covering vast number of topics including medicine. Patient education in head and 
      neck cancer (HNC) is crucial to enhance the understanding of patients about their 
      medical condition, diagnosis, and treatment options. Therefore, this study aims 
      to examine the accuracy and reliability of ChatGPT in answering questions 
      regarding HNC. METHODS: 154 head and neck cancer-related questions were compiled 
      from sources including professional societies, institutions, patient support 
      groups, and social media. These questions were categorized into topics like basic 
      knowledge, diagnosis, treatment, recovery, operative risks, complications, 
      follow-up, and cancer prevention. ChatGPT was queried with each question, and two 
      experienced head and neck surgeons assessed each response independently for 
      accuracy and reproducibility. Responses were rated on a scale: (1) 
      comprehensive/correct, (2) incomplete/partially correct, (3) a mix of accurate 
      and inaccurate/misleading, and (4) completely inaccurate/irrelevant. 
      Discrepancies in grading were resolved by a third reviewer. Reproducibility was 
      evaluated by repeating questions and analyzing grading consistency. RESULTS: 
      ChatGPT yielded "comprehensive/correct" responses to 133/154 (86.4%) of the 
      questions whereas, rates of "incomplete/partially correct" and "mixed with 
      accurate and inaccurate data/misleading" responses were 11% and 2.6%, 
      respectively. There were no "completely inaccurate/irrelevant" responses. 
      According to category, the model provided "comprehensive/correct" answers to 
      80.6% of questions regarding "basic knowledge", 92.6% related to "diagnosis", 
      88.9% related to "treatment", 80% related to "recovery - operative risks - 
      complications - follow-up", 100% related to "cancer prevention" and 92.9% related 
      to "other". There was not any significant difference between the categories 
      regarding the grades of ChatGPT responses (p=0.88). The rate of reproducibility 
      was 94.1% (145 of 154 questions). CONCLUSION: ChatGPT generated substantially 
      accurate and reproducible information to diverse medical queries related to HNC. 
      Despite its limitations, it can be a useful source of information for both 
      patients and medical professionals. With further developments in the model, 
      ChatGPT can also play a crucial role in clinical decision support to provide the 
      clinicians with up-to-date information.
CI  - Copyright © 2023 Kuşcu, Pamuk, Sütay Süslü and Hosal.
FAU - Kuşcu, Oğuz
AU  - Kuşcu O
AD  - Department of Otorhinolaryngology, School of Medicine, Hacettepe University, 
      Ankara, Türkiye.
FAU - Pamuk, A Erim
AU  - Pamuk AE
AD  - Department of Otorhinolaryngology, School of Medicine, Hacettepe University, 
      Ankara, Türkiye.
FAU - Sütay Süslü, Nilda
AU  - Sütay Süslü N
AD  - Private Practitioner, Ankara, Türkiye.
FAU - Hosal, Sefik
AU  - Hosal S
AD  - Department of Otorhinolaryngology, School of Medicine, Atılım University, Ankara, 
      Türkiye.
LA  - eng
PT  - Journal Article
DEP - 20231201
PL  - Switzerland
TA  - Front Oncol
JT  - Frontiers in oncology
JID - 101568867
PMC - PMC10722294
OTO - NOTNLM
OT  - ChatGPT 4
OT  - artificial intelligence
OT  - chatbot
OT  - head and neck
OT  - head and neck (H&amp;N) cancer
OT  - information literacy
OT  - machine learning
OT  - natural language processing
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/12/18 06:41
MHDA- 2023/12/18 06:42
PMCR- 2023/01/01
CRDT- 2023/12/18 04:52
PHST- 2023/07/10 00:00 [received]
PHST- 2023/11/13 00:00 [accepted]
PHST- 2023/12/18 06:42 [medline]
PHST- 2023/12/18 06:41 [pubmed]
PHST- 2023/12/18 04:52 [entrez]
PHST- 2023/01/01 00:00 [pmc-release]
AID - 10.3389/fonc.2023.1256459 [doi]
PST - epublish
SO  - Front Oncol. 2023 Dec 1;13:1256459. doi: 10.3389/fonc.2023.1256459. eCollection 
      2023.

PMID- 38021917
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231201
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 10
DP  - 2023 Oct
TI  - Using ChatGPT to Predict Cancer Predisposition Genes: A Promising Tool for 
      Pediatric Oncologists.
PG  - e47594
LID - 10.7759/cureus.47594 [doi]
LID - e47594
AB  - BACKGROUND: Determining genetic susceptibility for cancer predisposition 
      syndromes (CPS) through cancer predisposition genes (CPGs) testing is critical in 
      facilitating appropriate prevention and surveillance strategies. This study 
      investigates the use of ChatGPT, a large language model, in predicting CPGs using 
      clinical notes. METHODS: Our study involved 53 patients with pathogenic CPG 
      mutations. Two kinds of clinical notes were used: the first visit note, 
      containing a thorough history and physical exam, and the genetic clinic note, 
      summarizing the patient's diagnosis and family history. We asked ChatGPT to 
      recommend CPS genes based on these notes and compared these predictions with 
      previously identified mutations. RESULTS: Rb1 was the most frequently mutated 
      gene in our cohort (34%), followed by NF1 (9.4%), TP53 (5.7%), and VHL (5.7%). 
      Out of 53 patients, 30 had genetic clinic notes of a median length of 54 words. 
      ChatGPT correctly predicted the gene in 93% of these cases. However, it failed to 
      predict EPCAM&nbsp;and VHL genes in specific patients. For the first visit notes 
      (median length: 461 words),&nbsp;ChatGPT correctly predicted the gene in 64% of these 
      cases. CONCLUSION: ChatGPT shows promise in&nbsp;predicting CPGs from clinical notes, 
      particularly genetic clinic notes. This approach may be useful in enhancing CPG 
      testing, especially in areas lacking genetic testing resources.&nbsp;With further 
      training, there is a possibility for ChatGPT to improve its predictive 
      potential&nbsp;and expand its clinical applicability. However, additional research is 
      needed to explore the full potential and applicability of ChatGPT.
CI  - Copyright © 2023, Sultan et al.
FAU - Sultan, Iyad
AU  - Sultan I
AD  - Department of Pediatrics, King Hussein Cancer Center, Amman, JOR.
FAU - Al-Abdallat, Haneen
AU  - Al-Abdallat H
AD  - Department of Medicine, University of Jordan, Amman, JOR.
FAU - Alnajjar, Zaina
AU  - Alnajjar Z
AD  - Department of Medicine, Hashemite University, Zarqa, JOR.
FAU - Ismail, Layan
AU  - Ismail L
AD  - Department of Medicine, University of Jordan, Amman, JOR.
FAU - Abukhashabeh, Razan
AU  - Abukhashabeh R
AD  - Department of Cell Therapy and Applied Genomics, King Hussein Cancer Center, 
      Amman, JOR.
FAU - Bitar, Layla
AU  - Bitar L
AD  - Department of Pediatric Oncology, King Hussein Cancer Center, Amman, JOR.
FAU - Abu Shanap, Mayada
AU  - Abu Shanap M
AD  - Department of Pediatric Oncology, King Hussein Cancer Center, Amman, JOR.
LA  - eng
PT  - Journal Article
DEP - 20231024
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10666922
OTO - NOTNLM
OT  - cancer
OT  - chatgpt
OT  - genes
OT  - oncology
OT  - pediatrics
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/11/29 18:42
MHDA- 2023/11/29 18:43
PMCR- 2023/10/24
CRDT- 2023/11/29 15:14
PHST- 2023/07/18 00:00 [accepted]
PHST- 2023/11/29 18:43 [medline]
PHST- 2023/11/29 18:42 [pubmed]
PHST- 2023/11/29 15:14 [entrez]
PHST- 2023/10/24 00:00 [pmc-release]
AID - 10.7759/cureus.47594 [doi]
PST - epublish
SO  - Cureus. 2023 Oct 24;15(10):e47594. doi: 10.7759/cureus.47594. eCollection 2023 
      Oct.

PMID- 37549499
OWN - NLM
STAT- MEDLINE
DCOM- 20230814
LR  - 20230814
IS  - 1872-8243 (Electronic)
IS  - 1386-5056 (Linking)
VI  - 177
DP  - 2023 Sep
TI  - Performance and exploration of ChatGPT in medical examination, records and 
      education in Chinese: Pave the way for medical AI.
PG  - 105173
LID - S1386-5056(23)00191-0 [pii]
LID - 10.1016/j.ijmedinf.2023.105173 [doi]
AB  - BACKGROUND: Although chat generative pre-trained transformer (ChatGPT) has made 
      several successful attempts in the medical field, most notably in answering 
      medical questions in English, no studies have evaluated ChatGPT's performance in 
      a Chinese context for a medical task. OBJECTIVE: The aim of this study was to 
      evaluate ChatGPT's ability to understand medical knowledge in Chinese, as well as 
      its potential to serve as an electronic health infrastructure for medical 
      development, by evaluating its performance in medical examinations, records, and 
      education. METHOD: The Chinese (CNMLE) and English (ENMLE) datasets of the China 
      National Medical Licensing Examination and the Chinese dataset (NEEPM) of the 
      China National Entrance Examination for Postgraduate Clinical Medicine 
      Comprehensive Ability were used to evaluate the performance of ChatGPT (GPT-3.5 
      and GPT-4). We assessed answer accuracy, verbal fluency, and the classification 
      of incorrect responses owing to hallucinations on multiple occasions. In 
      addition, we tested ChatGPT's performance on discharge summaries and group 
      learning in a Chinese context on a small scale. RESULTS: The accuracy of GPT-3.5 
      in CNMLE, ENMLE, and NEEPM was 56% (56/100), 76% (76/100), and 62% (62/100), 
      respectively, compared to that of GPT-4, which was of 84% (84/100), 86% (86/100), 
      and 82% (82/100). The verbal fluency of all the ChatGPT responses exceeded 95%. 
      Among the GPT-3.5 incorrect responses, the proportions of open-domain 
      hallucinations were 66 % (29/44), 54 % (14/24), and 63 % (24/38), whereas 
      close-domain hallucinations accounted for 34 % (15/44), 46 % (14/24), and 37 % 
      (14/38), respectively. By contrast, GPT-4 open-domain hallucinations accounted 
      for 56% (9/16), 43% (6/14), and 83% (15/18), while close-domain hallucinations 
      accounted for 44% (7/16), 57% (8/14), and 17% (3/18), respectively. In the 
      discharge summary, ChatGPT demonstrated logical coherence, however GPT-3.5 could 
      not fulfill the quality requirements, while GPT-4 met the qualification of 60% 
      (6/10). In group learning, the verbal fluency and interaction satisfaction with 
      ChatGPT were 100% (10/10). CONCLUSION: ChatGPT based on GPT-4 is at par with 
      Chinese medical practitioners who passed the CNMLE and at the standard required 
      for admission to clinical medical graduate programs in China. The GPT-4 shows 
      promising potential for discharge summarization and group learning. Additionally, 
      it shows high verbal fluency, resulting in a positive human-computer interaction 
      experience. GPT-4 significantly improves multiple capabilities and reduces 
      hallucinations compared to the previous GPT-3.5 model, with a particular leap 
      forward in the Chinese comprehension capability of medical tasks. Artificial 
      intelligence (AI) systems face the challenges of hallucinations, legal risks, and 
      ethical issues. However, we discovered ChatGPT's potential to promote medical 
      development as an electronic health infrastructure, paving the way for Medical AI 
      to become necessary.
CI  - Copyright © 2023 Elsevier B.V. All rights reserved.
FAU - Wang, Hongyan
AU  - Wang H
AD  - Department of Pain Management, Xuanwu Hospital, Capital Medical University.
FAU - Wu, WeiZhen
AU  - Wu W
AD  - Department of Anesthesia, China-Japan Union Hospital of Jilin University.
FAU - Dou, Zhi
AU  - Dou Z
AD  - Department of Pain Management, Xuanwu Hospital, Capital Medical University.
FAU - He, Liangliang
AU  - He L
AD  - Department of Pain Management, Xuanwu Hospital, Capital Medical University.
FAU - Yang, Liqiang
AU  - Yang L
AD  - Department of Pain Management, Xuanwu Hospital, Capital Medical University. 
      Electronic address: yangliqiangxwpain@outlook.com.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20230804
PL  - Ireland
TA  - Int J Med Inform
JT  - International journal of medical informatics
JID - 9711057
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - China
MH  - *Clinical Medicine
MH  - Electronics
MH  - Hallucinations
COIS- Declaration of Competing Interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2023/08/08 00:42
MHDA- 2023/08/14 06:43
CRDT- 2023/08/07 18:03
PHST- 2023/03/01 00:00 [received]
PHST- 2023/07/01 00:00 [revised]
PHST- 2023/07/08 00:00 [accepted]
PHST- 2023/08/14 06:43 [medline]
PHST- 2023/08/08 00:42 [pubmed]
PHST- 2023/08/07 18:03 [entrez]
AID - S1386-5056(23)00191-0 [pii]
AID - 10.1016/j.ijmedinf.2023.105173 [doi]
PST - ppublish
SO  - Int J Med Inform. 2023 Sep;177:105173. doi: 10.1016/j.ijmedinf.2023.105173. Epub 
      2023 Aug 4.

PMID- 38174202
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240105
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 12
DP  - 2023 Dec
TI  - Performance of ChatGPT in Board Examinations for Specialists in the Japanese 
      Ophthalmology Society.
PG  - e49903
LID - 10.7759/cureus.49903 [doi]
LID - e49903
AB  - We investigated the potential of ChatGPT in the ophthalmological field in the 
      Japanese language using board examinations for specialists in the Japanese 
      Ophthalmology Society. We tested GPT-3.5 and GPT-4-based ChatGPT on five sets of 
      past board examination problems in July 2023. Japanese text was used as the 
      prompt adopting two strategies: zero- and few-shot prompting. We compared the 
      correct answer rate of ChatGPT with that of actual examinees, and the performance 
      characteristics in 10 subspecialties were assessed. ChatGPT-3.5 and ChatGPT-4 
      correctly answered 112 (22.4%) and 229 (45.8%) out of 500 questions with simple 
      zero-shot prompting, respectively, and ChatGPT-4 correctly answered 231 (46.2%) 
      questions with few-shot prompting. The correct answer rates of ChatGPT-3.5 were 
      approximately two to three times lower than those of the actual examinees for 
      each examination set (p = 0.001). However, the correct answer rates for ChatGPT-4 
      were close to approximately 70% of those of the examinees. ChatGPT-4 had the 
      highest correct answer rate (71.4% with zero-shot prompting and 61.9% with 
      few-shot prompting) in "blepharoplasty, orbit, and ocular oncology," and the 
      lowest answer rate (30.0% with zero-shot prompting and 23.3% with few-shot 
      prompting) in "pediatric ophthalmology." We concluded that ChatGPT could be one 
      of the advanced technologies for practical tools in Japanese ophthalmology.
CI  - Copyright © 2023, Sakai et al.
FAU - Sakai, Daiki
AU  - Sakai D
AD  - Department of Ophthalmology, Kobe City Eye Hospital, Kobe, JPN.
AD  - Department of Ophthalmology, Kobe City Medical Center General Hospital, Kobe, 
      JPN.
AD  - Department of Surgery, Division of Ophthalmology, Kobe University Graduate School 
      of Medicine, Kobe, JPN.
FAU - Maeda, Tadao
AU  - Maeda T
AD  - Department of Ophthalmology, Kobe City Eye Hospital, Kobe, JPN.
FAU - Ozaki, Atsuta
AU  - Ozaki A
AD  - Department of Ophthalmology, Kobe City Eye Hospital, Kobe, JPN.
AD  - Department of Ophthalmology, Mie University Graduate School of Medicine, Tsu, 
      JPN.
FAU - Kanda, Genki N
AU  - Kanda GN
AD  - Department of Ophthalmology, Kobe City Eye Hospital, Kobe, JPN.
AD  - Laboratory for Biologically Inspired Computing, RIKEN Center for Biosystems 
      Dynamics Research, Kobe, JPN.
FAU - Kurimoto, Yasuo
AU  - Kurimoto Y
AD  - Department of Ophthalmology, Kobe City Eye Hospital, Kobe, JPN.
AD  - Department of Ophthalmology, Kobe City Medical Center General Hospital, Kobe, 
      JPN.
FAU - Takahashi, Masayo
AU  - Takahashi M
AD  - Department of Ophthalmology, Kobe City Eye Hospital, Kobe, JPN.
LA  - eng
PT  - Journal Article
DEP - 20231204
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10763518
OTO - NOTNLM
OT  - artificial intelligence
OT  - board examination
OT  - chatgpt
OT  - generative artificial intelligence
OT  - large language models
OT  - ophthalmology
COIS- The authors have declared that no competing interests exist.
EDAT- 2024/01/04 11:44
MHDA- 2024/01/04 11:45
PMCR- 2023/12/04
CRDT- 2024/01/04 04:20
PHST- 2023/12/04 00:00 [accepted]
PHST- 2024/01/04 11:45 [medline]
PHST- 2024/01/04 11:44 [pubmed]
PHST- 2024/01/04 04:20 [entrez]
PHST- 2023/12/04 00:00 [pmc-release]
AID - 10.7759/cureus.49903 [doi]
PST - epublish
SO  - Cureus. 2023 Dec 4;15(12):e49903. doi: 10.7759/cureus.49903. eCollection 2023 
      Dec.

PMID- 38379690
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240222
IS  - 0353-8109 (Print)
IS  - 1986-5988 (Electronic)
IS  - 0353-8109 (Linking)
VI  - 31
IP  - 4
DP  - 2023
TI  - Utilization of ChatGPT in Medical Education: Applications and Implications for 
      Curriculum Enhancement.
PG  - 300-305
LID - 10.5455/aim.2023.31.300-305 [doi]
AB  - BACKGROUND: The integration of artificial intelligence (AI) into medical 
      education has sparked a paradigm shift in pedagogical approaches, reshaping the 
      way medical knowledge is accessed, processed, and applied. Medical education is a 
      dynamic field that demands continuous adaptation to the evolving healthcare 
      landscape. ChatGPT, an advanced AI language model, with its natural language 
      understanding and generation capabilities, offers a multifaceted toolset that 
      enhances various aspects of medical education. OBJECTIVE: The objective of this 
      paper is to explore how ChatGPT, an advanced AI language model, is transforming 
      medical education by serving as a dynamic information resource and driving 
      curriculum reform. It aims to highlight the multifaceted uses of ChatGPT and its 
      potential to reshape the pedagogical landscape in medical education. METHODS: 
      PubMed, Scopus, Web of Science, ERIC, and Google Scholar databases were searched 
      to assess the literature that met the study objectives from 2019 to August 2023 
      with explicit inclusion and exclusion criteria. RESULTS: The results demonstrate 
      that ChatGPT's applications in medical education are diverse and encompass 
      real-time curriculum adaptation, personalized learning, and collaborative 
      learning. Its capacity to provide immediate and contextually relevant information 
      has the potential to enhance the quality of medical education significantly. 
      CONCLUSION: ChatGPT's integration into medical education represents a 
      transformative shift in educational approaches. It offers a wide range of 
      capabilities, from serving as a repository of medical knowledge to facilitating 
      collaborative learning. As medical education continues to evolve, ChatGPT emerges 
      as a powerful tool that can reshape pedagogy and drive meaningful curriculum 
      reform to meet the needs of modern healthcare practice.ChatGPT emerges as a 
      transformative tool that holds the potential to reshape the landscape of medical 
      pedagogy and drive meaningful curriculum reform.
CI  - © 2023 Yasar Ahmed.
FAU - Ahmed, Yasar
AU  - Ahmed Y
AD  - Medical Oncology Department, St Vincent's University Hospital. Ireland.
LA  - eng
PT  - Journal Article
PL  - Bosnia and Herzegovina
TA  - Acta Inform Med
JT  - Acta informatica medica : AIM : journal of the Society for Medical Informatics of 
      Bosnia &amp; Herzegovina : casopis Drustva za medicinsku informatiku BiH
JID - 101147064
PMC - PMC10875960
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - curriculum
OT  - medical education
COIS- The authors declare no conflict of interest related to this study of any kind. 
      unding Information: No funding was received for this article.
EDAT- 2023/01/01 00:00
MHDA- 2023/01/01 00:01
PMCR- 2023/01/01
CRDT- 2024/02/21 03:56
PHST- 2023/07/25 00:00 [received]
PHST- 2023/09/04 00:00 [accepted]
PHST- 2023/01/01 00:01 [medline]
PHST- 2023/01/01 00:00 [pubmed]
PHST- 2024/02/21 03:56 [entrez]
PHST- 2023/01/01 00:00 [pmc-release]
AID - AIM-31-300 [pii]
AID - 10.5455/aim.2023.31.300-305 [doi]
PST - ppublish
SO  - Acta Inform Med. 2023;31(4):300-305. doi: 10.5455/aim.2023.31.300-305.

PMID- 37578849
OWN - NLM
STAT- Publisher
LR  - 20231220
IS  - 1488-2361 (Electronic)
IS  - 0846-5371 (Linking)
DP  - 2023 Aug 14
TI  - Comparative Performance of ChatGPT and Bard in a Text-Based Radiology Knowledge 
      Assessment.
PG  - 8465371231193716
LID - 10.1177/08465371231193716 [doi]
AB  - PURPOSE: Bard by Google, a direct competitor to ChatGPT, was recently released. 
      Understanding the relative performance of these different chatbots can provide 
      important insight into their strengths and weaknesses as well as which roles they 
      are most suited to fill. In this project, we aimed to compare the most recent 
      version of ChatGPT, ChatGPT-4, and Bard by Google, in their ability to accurately 
      respond to radiology board examination practice questions. METHODS: Text-based 
      questions were collected from the 2017-2021 American College of Radiology's 
      Diagnostic Radiology In-Training (DXIT) examinations. ChatGPT-4 and Bard were 
      queried, and their comparative accuracies, response lengths, and response times 
      were documented. Subspecialty-specific performance was analyzed as well. RESULTS: 
      318 questions were included in our analysis. ChatGPT answered significantly more 
      accurately than Bard (87.11% vs 70.44%, P &lt; .0001). ChatGPT's response length was 
      significantly shorter than Bard's (935.28 ± 440.88 characters vs 1437.52 ± 415.91 
      characters, P &lt; .0001). ChatGPT's response time was significantly longer than 
      Bard's (26.79 ± 3.27 seconds vs 7.55 ± 1.88 seconds, P &lt; .0001). ChatGPT 
      performed superiorly to Bard in neuroradiology, (100.00% vs 86.21%, P = .03), 
      general &amp; physics (85.39% vs 68.54%, P &lt; .001), nuclear medicine (80.00% vs 
      56.67%, P &lt; .01), pediatric radiology (93.75% vs 68.75%, P = .03), and ultrasound 
      (100.00% vs 63.64%, P &lt; .001). In the remaining subspecialties, there were no 
      significant differences between ChatGPT and Bard's performance. CONCLUSION: 
      ChatGPT displayed superior radiology knowledge compared to Bard. While both 
      chatbots display reasonable radiology knowledge, they should be used with 
      conscious knowledge of their limitations and fallibility. Both chatbots provided 
      incorrect or illogical answer explanations and did not always address the 
      educational content of the question.
FAU - Patil, Nikhil S
AU  - Patil NS
AUID- ORCID: 0000-0003-3929-0482
AD  - Michael G. DeGroote School of Medicine, McMaster University, Hamilton, ON, 
      Canada. RINGGOLD: 62703
FAU - Huang, Ryan S
AU  - Huang RS
AUID- ORCID: 0000-0002-3404-5376
AD  - Temerty Faculty of Medicine, University of Toronto, Toronto, ON, Canada. 
      RINGGOLD: 7938
FAU - van der Pol, Christian B
AU  - van der Pol CB
AUID- ORCID: 0000-0002-1718-2619
AD  - Department of Diagnostic Imaging, Hamilton Health Sciences, Juravinski Hospital 
      and Cancer Centre, Hamilton, ON, Canada.
FAU - Larocque, Natasha
AU  - Larocque N
AUID- ORCID: 0000-0003-0449-9438
AD  - Department of Radiology, McMaster University, Hamilton, ON, Canada. RINGGOLD: 
      3710
LA  - eng
PT  - Journal Article
DEP - 20230814
PL  - United States
TA  - Can Assoc Radiol J
JT  - Canadian Association of Radiologists journal = Journal l'Association canadienne 
      des radiologistes
JID - 8812910
SB  - IM
OTO - NOTNLM
OT  - Bard
OT  - ChatGPT
OT  - Google
OT  - artificial intelligence
OT  - chatbot
OT  - radiology
COIS- Declaration of Conflicting InterestsThe author(s) declared no potential conflicts 
      of interest with respect to the research, authorship, and/or publication of this 
      article.
EDAT- 2023/08/14 18:42
MHDA- 2023/08/14 18:42
CRDT- 2023/08/14 12:22
PHST- 2023/08/14 18:42 [pubmed]
PHST- 2023/08/14 18:42 [medline]
PHST- 2023/08/14 12:22 [entrez]
AID - 10.1177/08465371231193716 [doi]
PST - aheadofprint
SO  - Can Assoc Radiol J. 2023 Aug 14:8465371231193716. doi: 10.1177/08465371231193716.

PMID- 37204545
OWN - NLM
STAT- MEDLINE
DCOM- 20230926
LR  - 20230926
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Print)
IS  - 0090-6964 (Linking)
VI  - 51
IP  - 10
DP  - 2023 Oct
TI  - AI Tackles Pandemics: ChatGPT's Game-Changing Impact on Infectious Disease 
      Control.
PG  - 2097-2099
LID - 10.1007/s10439-023-03239-5 [doi]
AB  - Unleashing the power of artificial intelligence (AI), this letter delves into the 
      potential applications of ChatGPT, a cutting-edge language model, in the 
      management and control of infectious diseases. By examining ChatGPT's 
      contributions to information dissemination, diagnosis, treatment, and research, 
      the article underscores its revolutionary impact on the field while acknowledging 
      existing limitations and envisioning future advancements for optimized medical 
      applications.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Ray, Partha Pratim
AU  - Ray PP
AD  - Sikkim University, Gangtok, India. ppray@cus.ac.in.
FAU - Majumder, Poulami
AU  - Majumder P
AD  - Maulana Abul Kalam Azad University of Technology, Kolkata, India.
LA  - eng
PT  - Letter
DEP - 20230518
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - *Artificial Intelligence
MH  - *Pandemics
MH  - Information Dissemination
PMC - PMC10196282
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Disease management
OT  - Healthcare
OT  - Infectious diseases
OT  - Natural language processing
COIS- No benefits in any form have been or will be received from a commercial party 
      related directly or indirectly to the subject of this manuscript. The author 
      declare no conflict of interest.
EDAT- 2023/05/19 13:05
MHDA- 2023/09/26 13:43
PMCR- 2023/05/18
CRDT- 2023/05/19 11:09
PHST- 2023/05/04 00:00 [received]
PHST- 2023/05/10 00:00 [accepted]
PHST- 2023/09/26 13:43 [medline]
PHST- 2023/05/19 13:05 [pubmed]
PHST- 2023/05/19 11:09 [entrez]
PHST- 2023/05/18 00:00 [pmc-release]
AID - 10.1007/s10439-023-03239-5 [pii]
AID - 3239 [pii]
AID - 10.1007/s10439-023-03239-5 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2023 Oct;51(10):2097-2099. doi: 10.1007/s10439-023-03239-5. Epub 
      2023 May 18.

PMID- 37662036
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230905
IS  - 1664-2295 (Print)
IS  - 1664-2295 (Electronic)
IS  - 1664-2295 (Linking)
VI  - 14
DP  - 2023
TI  - The utility of ChatGPT in the assessment of literature on the prevention of 
      migraine: an observational, qualitative study.
PG  - 1225223
LID - 10.3389/fneur.2023.1225223 [doi]
LID - 1225223
AB  - BACKGROUND: It is not known how large language models, such as ChatGPT, can be 
      applied toward the assessment of the efficacy of medications, including in the 
      prevention of migraine, and how it might support those claims with existing 
      medical evidence. METHODS: We queried ChatGPT-3.5 on the efficacy of 47 
      medications for the prevention of migraine and then asked it to give citations in 
      support of its assessment. ChatGPT's evaluations were then compared to their FDA 
      approval status for this indication as well as the American Academy of Neurology 
      2012 evidence-based guidelines for the prevention of migraine. The citations 
      ChatGPT generated for these evaluations were then assessed to see if they were 
      real papers and if they were relevant to the query. RESULTS: ChatGPT affirmed 
      that the 14 medications that have either received FDA approval for prevention of 
      migraine or AAN Grade A/B evidence were effective for migraine. Its assessments 
      of the other 33 medications were unreliable including suggesting possible 
      efficacy for four medications that have never been used for the prevention of 
      migraine. Critically, only 33/115 (29%) of the papers ChatGPT cited were real, 
      while 76/115 (66%) were "hallucinated" not real papers and 6/115 (5%) shared the 
      names of real papers but had not real citations. CONCLUSION: While ChatGPT 
      produced tailored answers on the efficacy of the queried medications, the results 
      were unreliable and inaccurate because of the overwhelming volume of 
      "hallucinated" articles it generated and cited.
CI  - Copyright © 2023 Moskatel and Zhang.
FAU - Moskatel, Leon S
AU  - Moskatel LS
AD  - Division of Headache and Facial Pain, Department of Neurology, Stanford 
      University, Palo Alto, CA, United States.
FAU - Zhang, Niushen
AU  - Zhang N
AD  - Division of Headache and Facial Pain, Department of Neurology, Stanford 
      University, Palo Alto, CA, United States.
LA  - eng
PT  - Journal Article
DEP - 20230817
PL  - Switzerland
TA  - Front Neurol
JT  - Frontiers in neurology
JID - 101546899
PMC - PMC10469750
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - evidence-based medicine
OT  - migraine
OT  - preventive medications
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/09/04 06:42
MHDA- 2023/09/04 06:43
PMCR- 2023/08/17
CRDT- 2023/09/04 04:35
PHST- 2023/05/18 00:00 [received]
PHST- 2023/08/07 00:00 [accepted]
PHST- 2023/09/04 06:43 [medline]
PHST- 2023/09/04 06:42 [pubmed]
PHST- 2023/09/04 04:35 [entrez]
PHST- 2023/08/17 00:00 [pmc-release]
AID - 10.3389/fneur.2023.1225223 [doi]
PST - epublish
SO  - Front Neurol. 2023 Aug 17;14:1225223. doi: 10.3389/fneur.2023.1225223. 
      eCollection 2023.

PMID- 37286486
OWN - NLM
STAT- MEDLINE
DCOM- 20230703
LR  - 20230703
IS  - 1347-4820 (Electronic)
IS  - 1346-9843 (Linking)
VI  - 87
IP  - 7
DP  - 2023 Jun 23
TI  - Evaluation of the Accuracy of ChatGPT in Answering Clinical Questions on the 
      Japanese Society of Hypertension Guidelines.
PG  - 1030-1033
LID - 10.1253/circj.CJ-23-0308 [doi]
AB  - BACKGROUND: To assist healthcare providers in interpreting guidelines, clinical 
      questions (CQ) are often included, but not always, which can make interpretation 
      difficult for non-expert clinicians. We evaluated the ability of ChatGPT to 
      accurately answer CQs on the Japanese Society of Hypertension Guidelines for the 
      Management of Hypertension (JSH 2019).Methods and Results: We conducted an 
      observational study using data from JSH 2019. The accuracy rate for CQs and 
      limited evidence-based questions of the guidelines (Qs) were evaluated. ChatGPT 
      demonstrated a higher accuracy rate for CQs than for Qs (80% vs. 36%, P value: 
      0.005). CONCLUSIONS: ChatGPT has the potential to be a valuable tool for 
      clinicians in the management of hypertension.
FAU - Kusunose, Kenya
AU  - Kusunose K
AD  - Department of Cardiovascular Medicine, Tokushima University Hospital.
AD  - Department of Cardiovascular Medicine, Nephrology, and Neurology, Graduate School 
      of Medicine, University of the Ryukyus.
FAU - Kashima, Shuichiro
AU  - Kashima S
AD  - Department of Cardiovascular Medicine, Tokushima University Hospital.
FAU - Sata, Masataka
AU  - Sata M
AD  - Department of Cardiovascular Medicine, Tokushima University Hospital.
LA  - eng
PT  - Journal Article
PT  - Observational Study
DEP - 20230607
PL  - Japan
TA  - Circ J
JT  - Circulation journal : official journal of the Japanese Circulation Society
JID - 101137683
SB  - IM
MH  - Humans
MH  - *East Asian People
MH  - Health Personnel
MH  - *Hypertension/diagnosis/drug therapy
MH  - Reproducibility of Results
MH  - Artificial Intelligence
MH  - Social Media
OTO - NOTNLM
OT  - ChatGPT
OT  - Guidelines
OT  - Hypertension
OT  - Large language models
EDAT- 2023/06/08 01:08
MHDA- 2023/06/27 06:42
CRDT- 2023/06/07 22:43
PHST- 2023/06/27 06:42 [medline]
PHST- 2023/06/08 01:08 [pubmed]
PHST- 2023/06/07 22:43 [entrez]
AID - 10.1253/circj.CJ-23-0308 [doi]
PST - ppublish
SO  - Circ J. 2023 Jun 23;87(7):1030-1033. doi: 10.1253/circj.CJ-23-0308. Epub 2023 Jun 
      7.

PMID- 38460761
OWN - NLM
STAT- Publisher
LR  - 20240313
IS  - 2666-9919 (Electronic)
IS  - 2666-9919 (Linking)
VI  - 54
IP  - 4
DP  - 2024 Mar 8
TI  - Evaluating ChatGPT ability to answer urinary tract Infection-Related questions.
PG  - 104884
LID - S2666-9919(24)00039-3 [pii]
LID - 10.1016/j.idnow.2024.104884 [doi]
AB  - INTRODUCTION: For the first time, the accuracy and proficiency of ChatGPT answers 
      on urogenital tract infection (UTIs) were evaluated. METHODS: The study aimed to 
      create two lists of questions: frequently asked questions (FAQs, public-based 
      inquiries) on relevant topics, and questions based on guideline information 
      (guideline-based inquiries). ChatGPT responses to FAQs and scientific questions 
      were scored by two urologists and an infectious disease specialist. Quality and 
      reliability of all ChatGPT answers were checked using the Global Quality Score 
      (GQS). The reproducibility of ChatGPT answers was analyzed by asking each 
      question twice. RESULTS: All in all, 96.2&nbsp;% of FAQs (75/78 inquiries) related to 
      UTIs were correctly and adequately answered by ChatGPT, and scored GQS 5. None of 
      the ChatGPT answers were classified as GQS 2 and GQS 1. Moreover, FAQs about 
      cystitis, urethritis, and epididymo-orchitis were answered by ChatGPT with 100&nbsp;% 
      accuracy (GQS 5). ChatGPT answers for EAU urological infections guidelines showed 
      that 61 (89.7&nbsp;%), 5 (7.4&nbsp;%), and 2 (2.9&nbsp;%) ChatGPT responses were scored GQS 5, 
      GQS 4, and GQS 3, respectively. None of the ChatGPT responses for EAU urological 
      infections guidelines were categorized as GQS 2 and GQS 1. Comparison of mean GQS 
      values of ChatGPT answers for FAQs and EAU urological guideline questions showed 
      that ChatGPT was similarly able to respond to both question groups (p&nbsp;=&nbsp;0.168). 
      The ChatGPT response reproducibility rate was highest for the FAQ subgroups of 
      cystitis, urethritis, and epididymo-orchitis (100&nbsp;% for each subgroup). 
      CONCLUSION: The present study showed that ChatGPT gave accurate and satisfactory 
      answers for both public-based inquiries, and EAU urological infection 
      guideline-based questions. Reproducibility of ChatGPT answers exceeded 90% for 
      both FAQs and scientific questions.
CI  - Copyright © 2024 Elsevier Masson SAS. All rights reserved.
FAU - Cakir, Hakan
AU  - Cakir H
AD  - Department of Urology, Fulya Acibadem Hospital, Istanbul, Turkey.
FAU - Caglar, Ufuk
AU  - Caglar U
AD  - Department of Urology, Haseki Training and Research Hospital, Istanbul, Turkey.
FAU - Sekkeli, Sami
AU  - Sekkeli S
AD  - Department of Urology, Haseki Training and Research Hospital, Istanbul, Turkey. 
      Electronic address: samisekkeli@yandex.com.
FAU - Zerdali, Esra
AU  - Zerdali E
AD  - Department of Infectious Diseases and Clinical Microbiology, Haseki Training and 
      Research Hospital, Istanbul, Turkey.
FAU - Sarilar, Omer
AU  - Sarilar O
AD  - Department of Urology, Haseki Training and Research Hospital, Istanbul, Turkey.
FAU - Yildiz, Oguzhan
AU  - Yildiz O
AD  - Department of Urology, Haseki Training and Research Hospital, Istanbul, Turkey.
FAU - Ozgor, Faruk
AU  - Ozgor F
AD  - Department of Urology, Haseki Training and Research Hospital, Istanbul, Turkey.
LA  - eng
PT  - Journal Article
DEP - 20240308
PL  - France
TA  - Infect Dis Now
JT  - Infectious diseases now
JID - 101775152
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Guideline
OT  - Infection
OT  - Urinary tract infection
COIS- Declaration of Competing Interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2024/03/10 00:42
MHDA- 2024/03/10 00:42
CRDT- 2024/03/09 19:17
PHST- 2024/01/10 00:00 [received]
PHST- 2024/02/20 00:00 [revised]
PHST- 2024/03/05 00:00 [accepted]
PHST- 2024/03/10 00:42 [pubmed]
PHST- 2024/03/10 00:42 [medline]
PHST- 2024/03/09 19:17 [entrez]
AID - S2666-9919(24)00039-3 [pii]
AID - 10.1016/j.idnow.2024.104884 [doi]
PST - aheadofprint
SO  - Infect Dis Now. 2024 Mar 8;54(4):104884. doi: 10.1016/j.idnow.2024.104884.

PMID- 37808939
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231031
IS  - 2228-6497 (Print)
IS  - 2228-6497 (Electronic)
IS  - 2228-6497 (Linking)
VI  - 13
IP  - 3
DP  - 2023
TI  - Exploring the role of ChatGPT in patient care (diagnosis and treatment) and 
      medical research: A systematic review.
PG  - 183-191
LID - 10.34172/hpp.2023.22 [doi]
AB  - BACKGROUND: ChatGPT is an artificial intelligence based tool developed by OpenAI 
      (California, USA). This systematic review examines the potential of ChatGPT in 
      patient care and its role in medical research. METHODS: The systematic review was 
      done according to the PRISMA guidelines. Embase, Scopus, PubMed and Google 
      Scholar data bases were searched. We also searched preprint data bases. Our 
      search was aimed to identify all kinds of publications, without any restrictions, 
      on ChatGPT and its application in medical research, medical publishing and 
      patient care. We used search term "ChatGPT". We reviewed all kinds of 
      publications including original articles, reviews, editorial/ commentaries, and 
      even letter to the editor. Each selected records were analysed using ChatGPT and 
      responses generated were compiled in a table. The word table was transformed in 
      to a PDF and was further analysed using ChatPDF. RESULTS: We reviewed full texts 
      of 118 articles. ChatGPT can assist with patient enquiries, note writing, 
      decision-making, trial enrolment, data management, decision support, research 
      support, and patient education. But the solutions it offers are usually 
      insufficient and contradictory, raising questions about their originality, 
      privacy, correctness, bias, and legality. Due to its lack of human-like 
      qualities, ChatGPT's legitimacy as an author is questioned when used for academic 
      writing. ChatGPT generated contents have concerns with bias and possible 
      plagiarism. CONCLUSION: Although it can help with patient treatment and research, 
      there are issues with accuracy, authorship, and bias. ChatGPT can serve as a 
      "clinical assistant" and be a help in research and scholarly writing.
CI  - © 2023 The Author(s).
FAU - Garg, Ravindra Kumar
AU  - Garg RK
AUID- ORCID: 0000-0003-0044-7083
AD  - Department of Neurology, King George's Medical University, Lucknow, India.
FAU - Urs, Vijeth L
AU  - Urs VL
AD  - Department of Neurology, King George's Medical University, Lucknow, India.
FAU - Agarwal, Akshay Anand
AU  - Agarwal AA
AD  - Department of Surgery, King George's Medical University, Lucknow, India.
FAU - Chaudhary, Sarvesh Kumar
AU  - Chaudhary SK
AD  - Department of Neurology, King George's Medical University, Lucknow, India.
FAU - Paliwal, Vimal
AU  - Paliwal V
AD  - Department of Neurology, Sanjay Gandhi Institute of Medical Sciences, Lucknow, 
      India.
FAU - Kar, Sujita Kumar
AU  - Kar SK
AD  - Department of Psychiatry, King George's Medical University, Lucknow, India.
LA  - eng
PT  - Systematic Review
DEP - 20230911
PL  - Iran
TA  - Health Promot Perspect
JT  - Health promotion perspectives
JID - 101580052
PMC - PMC10558973
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Authorship
OT  - Machine learning
OT  - Publishing
OT  - Scholarly
COIS- None.
EDAT- 2023/10/09 06:41
MHDA- 2023/10/09 06:42
PMCR- 2023/09/11
CRDT- 2023/10/09 05:48
PHST- 2023/06/14 00:00 [received]
PHST- 2023/07/06 00:00 [accepted]
PHST- 2023/10/09 06:42 [medline]
PHST- 2023/10/09 06:41 [pubmed]
PHST- 2023/10/09 05:48 [entrez]
PHST- 2023/09/11 00:00 [pmc-release]
AID - 10.34172/hpp.2023.22 [doi]
PST - epublish
SO  - Health Promot Perspect. 2023 Sep 11;13(3):183-191. doi: 10.34172/hpp.2023.22. 
      eCollection 2023.

PMID- 38489044
OWN - NLM
STAT- Publisher
LR  - 20240315
IS  - 1432-0932 (Electronic)
IS  - 0940-6719 (Linking)
DP  - 2024 Mar 15
TI  - ChatGPT versus NASS clinical guidelines for degenerative spondylolisthesis: a 
      comparative analysis.
LID - 10.1007/s00586-024-08198-6 [doi]
AB  - BACKGROUND CONTEXT: Clinical guidelines, developed in concordance with the 
      literature, are often used to guide surgeons' clinical decision making. Recent 
      advancements of large language models and artificial intelligence (AI) in the 
      medical field come with exciting potential. OpenAI's generative AI model, known 
      as ChatGPT, can quickly synthesize information and generate responses grounded in 
      medical literature, which may prove to be a useful tool in clinical 
      decision-making for spine care. The current literature has yet to investigate the 
      ability of ChatGPT to assist clinical decision making with regard to degenerative 
      spondylolisthesis. PURPOSE: The study aimed to compare ChatGPT's concordance with 
      the recommendations set forth by The North American Spine Society (NASS) Clinical 
      Guideline for the Diagnosis and Treatment of Degenerative Spondylolisthesis and 
      assess ChatGPT's accuracy within the context of the most recent literature. 
      METHODS: ChatGPT-3.5 and 4.0 was prompted with questions from the NASS Clinical 
      Guideline for the Diagnosis and Treatment of Degenerative Spondylolisthesis and 
      graded its recommendations as "concordant" or "nonconcordant" relative to those 
      put forth by NASS. A response was considered "concordant" when ChatGPT generated 
      a recommendation that accurately reproduced all major points made in the NASS 
      recommendation. Any responses with a grading of "nonconcordant" were further 
      stratified into two subcategories: "Insufficient" or "Over-conclusive," to 
      provide further insight into grading rationale. Responses between GPT-3.5 and 4.0 
      were compared using Chi-squared tests. RESULTS: ChatGPT-3.5 answered 13 of NASS's 
      28 total clinical questions in concordance with NASS's guidelines (46.4%). 
      Categorical breakdown is as follows: Definitions and Natural History (1/1, 100%), 
      Diagnosis and Imaging (1/4, 25%), Outcome Measures for Medical Intervention and 
      Surgical Treatment (0/1, 0%), Medical and Interventional Treatment (4/6, 66.7%), 
      Surgical Treatment (7/14, 50%), and Value of Spine Care (0/2, 0%). When NASS 
      indicated there was sufficient evidence to offer a clear recommendation, 
      ChatGPT-3.5 generated a concordant response 66.7% of the time (6/9). However, 
      ChatGPT-3.5's concordance dropped to 36.8% when asked clinical questions that 
      NASS did not provide a clear recommendation on (7/19). A further breakdown of 
      ChatGPT-3.5's nonconcordance with the guidelines revealed that a vast majority of 
      its inaccurate recommendations were due to them being "over-conclusive" (12/15, 
      80%), rather than "insufficient" (3/15, 20%). ChatGPT-4.0 answered 19 (67.9%) of 
      the 28 total questions in concordance with NASS guidelines (P = 0.177). When NASS 
      indicated there was sufficient evidence to offer a clear recommendation, 
      ChatGPT-4.0 generated a concordant response 66.7% of the time (6/9). 
      ChatGPT-4.0's concordance held up at 68.4% when asked clinical questions that 
      NASS did not provide a clear recommendation on (13/19, P = 0.104). CONCLUSIONS: 
      This study sheds light on the duality of LLM applications within clinical 
      settings: one of accuracy and utility in some contexts versus inaccuracy and risk 
      in others. ChatGPT was concordant for most clinical questions NASS offered 
      recommendations for. However, for questions NASS did not offer best practices, 
      ChatGPT generated answers that were either too general or inconsistent with the 
      literature, and even fabricated data/citations. Thus, clinicians should exercise 
      extreme caution when attempting to consult ChatGPT for clinical recommendations, 
      taking care to ensure its reliability within the context of recent literature.
CI  - © 2024. The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, 
      part of Springer Nature.
FAU - Ahmed, Wasil
AU  - Ahmed W
AD  - Icahn School of Medicine at Mount Sinai, New York, NY, USA.
FAU - Saturno, Michael
AU  - Saturno M
AD  - Icahn School of Medicine at Mount Sinai, New York, NY, USA.
FAU - Rajjoub, Rami
AU  - Rajjoub R
AD  - Icahn School of Medicine at Mount Sinai, New York, NY, USA.
FAU - Duey, Akiro H
AU  - Duey AH
AD  - Icahn School of Medicine at Mount Sinai, New York, NY, USA.
FAU - Zaidat, Bashar
AU  - Zaidat B
AD  - Icahn School of Medicine at Mount Sinai, New York, NY, USA.
FAU - Hoang, Timothy
AU  - Hoang T
AD  - Icahn School of Medicine at Mount Sinai, New York, NY, USA.
FAU - Restrepo Mejia, Mateo
AU  - Restrepo Mejia M
AD  - Icahn School of Medicine at Mount Sinai, New York, NY, USA.
FAU - Gallate, Zachary S
AU  - Gallate ZS
AD  - Icahn School of Medicine at Mount Sinai, New York, NY, USA.
FAU - Shrestha, Nancy
AU  - Shrestha N
AD  - Chicago Medical School at Rosalind Franklin University, North Chicago, IL, USA.
FAU - Tang, Justin
AU  - Tang J
AD  - Icahn School of Medicine at Mount Sinai, New York, NY, USA.
FAU - Zapolsky, Ivan
AU  - Zapolsky I
AD  - Department of Orthopedics, Icahn School of Medicine at Mount Sinai, One Gustave 
      L. Levy Place, New York, NY, 10029, USA.
FAU - Kim, Jun S
AU  - Kim JS
AD  - Department of Orthopedics, Icahn School of Medicine at Mount Sinai, One Gustave 
      L. Levy Place, New York, NY, 10029, USA.
FAU - Cho, Samuel K
AU  - Cho SK
AUID- ORCID: 0000-0001-7511-2486
AD  - Department of Orthopedics, Icahn School of Medicine at Mount Sinai, One Gustave 
      L. Levy Place, New York, NY, 10029, USA. Samuel.Cho@mountsinai.org.
LA  - eng
PT  - Journal Article
DEP - 20240315
PL  - Germany
TA  - Eur Spine J
JT  - European spine journal : official publication of the European Spine Society, the 
      European Spinal Deformity Society, and the European Section of the Cervical Spine 
      Research Society
JID - 9301980
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Clinical guidelines
OT  - Degenerative spondylolisthesis
OT  - Large language models
OT  - Spine
EDAT- 2024/03/15 18:42
MHDA- 2024/03/15 18:42
CRDT- 2024/03/15 12:14
PHST- 2023/09/19 00:00 [received]
PHST- 2024/02/17 00:00 [accepted]
PHST- 2024/02/01 00:00 [revised]
PHST- 2024/03/15 18:42 [medline]
PHST- 2024/03/15 18:42 [pubmed]
PHST- 2024/03/15 12:14 [entrez]
AID - 10.1007/s00586-024-08198-6 [pii]
AID - 10.1007/s00586-024-08198-6 [doi]
PST - aheadofprint
SO  - Eur Spine J. 2024 Mar 15. doi: 10.1007/s00586-024-08198-6.

PMID- 38484923
OWN - NLM
STAT- Publisher
LR  - 20240314
IS  - 1526-3231 (Electronic)
IS  - 0749-8063 (Linking)
DP  - 2024 Mar 12
TI  - At Present, ChatGPT Cannot be Relied Upon to Answer Patient Questions and 
      Requires Physician Expertise to Interpret Answers for Patients.
LID - S0749-8063(24)00194-4 [pii]
LID - 10.1016/j.arthro.2024.02.039 [doi]
AB  - ChatGPT is designed to provide accurate and reliable information to the best of 
      its abilities based on the data input and knowledge available. Thus, ChatGPT is 
      being studied as a patient information tool. This artificial intelligence (AI) 
      tool has been shown to frequently provide technically correct information, but 
      with limitations. ChatGPT provides different answers to similar questions based 
      on the prompts, and patients may not have expertise in prompting ChattPT to 
      elicit a best answer. (Prompting large language models has been shown to be a 
      skill that can improve). Of greater concern, ChatGPT fails to provide sources or 
      references for its answers. At present ChatGPT cannot be relied upon to address 
      patient questions; in the future, ChatGPT will improve. Today, AI requires 
      physician expertise to interpret AI answers for patients.
CI  - Copyright © 2024. Published by Elsevier Inc.
FAU - Hurley, Eoghan T
AU  - Hurley ET
AD  - Duke University, Durham, NC, USA. Electronic address: eoghan.hurley@duke.edu.
FAU - Crook, Bryan S
AU  - Crook BS
AD  - Duke University, Durham, NC, USA.
FAU - Dickens, Jonathan F
AU  - Dickens JF
AD  - Duke University, Durham, NC, USA.
LA  - eng
PT  - Editorial
DEP - 20240312
PL  - United States
TA  - Arthroscopy
JT  - Arthroscopy : the journal of arthroscopic &amp; related surgery : official 
      publication of the Arthroscopy Association of North America and the International 
      Arthroscopy Association
JID - 8506498
SB  - IM
EDAT- 2024/03/15 00:43
MHDA- 2024/03/15 00:43
CRDT- 2024/03/14 20:27
PHST- 2024/02/25 00:00 [received]
PHST- 2024/02/28 00:00 [accepted]
PHST- 2024/03/15 00:43 [medline]
PHST- 2024/03/15 00:43 [pubmed]
PHST- 2024/03/14 20:27 [entrez]
AID - S0749-8063(24)00194-4 [pii]
AID - 10.1016/j.arthro.2024.02.039 [doi]
PST - aheadofprint
SO  - Arthroscopy. 2024 Mar 12:S0749-8063(24)00194-4. doi: 
      10.1016/j.arthro.2024.02.039.

PMID- 37958000
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231117
IS  - 2227-9032 (Print)
IS  - 2227-9032 (Electronic)
IS  - 2227-9032 (Linking)
VI  - 11
IP  - 21
DP  - 2023 Oct 30
TI  - Performance of ChatGPT on Registered Nurse License Exam in Taiwan: A Descriptive 
      Study.
LID - 10.3390/healthcare11212855 [doi]
LID - 2855
AB  - (1) Background: AI (artificial intelligence) chatbots have been widely applied. 
      ChatGPT could enhance individual learning capabilities and clinical reasoning 
      skills and facilitate students' understanding of complex concepts in healthcare 
      education. There is currently less emphasis on its application in nursing 
      education. The application of ChatGPT in nursing education needs to be verified. 
      (2) Methods: A descriptive study was used to analyze the scores of ChatGPT on the 
      registered nurse license exam (RNLE) in 2022~2023, and to explore the response 
      and explanations of ChatGPT. The process of data measurement encompassed input 
      sourcing, encoding methods, and statistical analysis. (3) Results: ChatGPT 
      promptly responded within seconds. The average score of four exams was around 
      51.6 to 63.75 by ChatGPT, and it passed the RNLE in 2022 1st and 2023 2nd. 
      However, ChatGPT may generate misleading or inaccurate explanations, or it could 
      lead to hallucination; confusion or misunderstanding about complicated scenarios; 
      and languages bias. (4) Conclusions: ChatGPT may have the potential to assist 
      with nursing education because of its advantages. It is recommended to integrate 
      ChatGPT into different nursing courses, to assess its limitations and 
      effectiveness through a variety of tools and methods.
FAU - Huang, Huiman
AU  - Huang H
AUID- ORCID: 0000-0003-4378-176X
AD  - School of Nursing, College of Nursing, Tzu Chi University of Science and 
      Technology, Hualien 970302, Taiwan.
LA  - eng
PT  - Journal Article
DEP - 20231030
PL  - Switzerland
TA  - Healthcare (Basel)
JT  - Healthcare (Basel, Switzerland)
JID - 101666525
PMC - PMC10649156
OTO - NOTNLM
OT  - artificial intelligence
OT  - nursing graduate
OT  - registered nurse
COIS- The authors declare no conflict of interest.
EDAT- 2023/11/14 06:42
MHDA- 2023/11/14 06:43
PMCR- 2023/10/30
CRDT- 2023/11/14 02:05
PHST- 2023/09/24 00:00 [received]
PHST- 2023/10/17 00:00 [revised]
PHST- 2023/10/27 00:00 [accepted]
PHST- 2023/11/14 06:43 [medline]
PHST- 2023/11/14 06:42 [pubmed]
PHST- 2023/11/14 02:05 [entrez]
PHST- 2023/10/30 00:00 [pmc-release]
AID - healthcare11212855 [pii]
AID - healthcare-11-02855 [pii]
AID - 10.3390/healthcare11212855 [doi]
PST - epublish
SO  - Healthcare (Basel). 2023 Oct 30;11(21):2855. doi: 10.3390/healthcare11212855.

PMID- 37521213
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230801
IS  - 2229-5178 (Print)
IS  - 2249-5673 (Electronic)
IS  - 2229-5178 (Linking)
VI  - 14
IP  - 4
DP  - 2023 Jul-Aug
TI  - Using ChatGPT for Writing Articles for Patients' Education for Dermatological 
      Diseases: A Pilot Study.
PG  - 482-486
LID - 10.4103/idoj.idoj_72_23 [doi]
AB  - BACKGROUND: Patients' education is a vital strategy for understanding a disease 
      by patients and proper management of the condition. Physicians and academicians 
      frequently make customized education materials for their patients. An artificial 
      intelligence (AI)-based writer can help them write an article. Chat Generative 
      Pre-Trained Transformer (ChatGPT) is a conversational language model developed by 
      OpenAI (openai.com). The model can generate human-like responses. OBJECTIVE: We 
      aimed to evaluate the generated text from ChatGPT for its suitability in 
      patients' education. MATERIALS AND METHODS: We asked the ChatGPT to list common 
      dermatological diseases. It provided a list of 14 diseases. We used the disease 
      names to converse with the application with disease-specific input (e.g., write a 
      patient education guide on acne). The text was copied for checking the number of 
      words, readability, and text similarity by software. The text's accuracy was 
      checked by a dermatologist following the structure of observed learning outcomes 
      (SOLO) taxonomy. For the readability ease score, we compared the observed value 
      with a score of 30. For the similarity index, we compared the observed value with 
      15% and tested it with a one-sample t-test. RESULTS: The ChatGPT generated a 
      paragraph of text of 377.43 ± 60.85 words for a patient education guide on skin 
      diseases. The average text reading ease score was 46.94 ± 8.23 (P &lt; 0.0001), and 
      it indicates that this level of text can easily be understood by a high-school 
      student to a newly joined college student. The text similarity index was higher 
      (27.07 ± 11.46%, P = 0.002) than the expected limit of 15%. The text had a 
      "relational" level of accuracy according to the SOLO taxonomy. CONCLUSION: In its 
      current form, ChatGPT can generate a paragraph of text for patients' educational 
      purposes that can be easily understood. However, the similarity index is high. 
      Hence, doctors should be cautious when using the text generated by ChatGPT and 
      must check for text similarity before using it.
CI  - Copyright: © 2023 Indian Dermatology Online Journal.
FAU - Mondal, Himel
AU  - Mondal H
AD  - Department of Physiology, All India Institute of Medical Sciences, Deoghar, 
      Jharkhand, India.
FAU - Mondal, Shaikat
AU  - Mondal S
AD  - Department of Physiology, Raiganj Government Medical College and Hospital, West 
      Bengal, India.
FAU - Podder, Indrashis
AU  - Podder I
AD  - Department of Dermatology, College of Medicine and Sagore Dutta Hospital, 
      Kolkata, West Bengal, India.
LA  - eng
PT  - Journal Article
DEP - 20230628
PL  - India
TA  - Indian Dermatol Online J
JT  - Indian dermatology online journal
JID - 101586880
PMC - PMC10373821
OTO - NOTNLM
OT  - Article
OT  - ChatGPT
OT  - artificial intelligence
OT  - dermatologists
OT  - software
COIS- There are no conflicts of interest.
EDAT- 2023/07/31 06:43
MHDA- 2023/07/31 06:44
PMCR- 2023/06/28
CRDT- 2023/07/31 05:04
PHST- 2023/01/24 00:00 [received]
PHST- 2023/04/09 00:00 [revised]
PHST- 2023/04/16 00:00 [accepted]
PHST- 2023/07/31 06:44 [medline]
PHST- 2023/07/31 06:43 [pubmed]
PHST- 2023/07/31 05:04 [entrez]
PHST- 2023/06/28 00:00 [pmc-release]
AID - IDOJ-14-482 [pii]
AID - 10.4103/idoj.idoj_72_23 [doi]
PST - epublish
SO  - Indian Dermatol Online J. 2023 Jun 28;14(4):482-486. doi: 
      10.4103/idoj.idoj_72_23. eCollection 2023 Jul-Aug.

PMID- 37074486
OWN - NLM
STAT- MEDLINE
DCOM- 20230512
LR  - 20230525
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Print)
IS  - 0090-6964 (Linking)
VI  - 51
IP  - 6
DP  - 2023 Jun
TI  - Potential Use of Artificial Intelligence in Infectious Disease: Take ChatGPT as 
      an Example.
PG  - 1130-1135
LID - 10.1007/s10439-023-03203-3 [doi]
AB  - Over the past month, a new AI model called Chatbot Generative Pre-trained 
      Transformer (ChatGPT), has received enormous attention in the media and 
      scientific communities due to its ability to process and respond to commands in a 
      humanistic fashion. As reported, five days after its launch, the number of 
      registered users of ChatGPT exceeded one million, and its monthly active users 
      had exceeded 100 million two months later, making it the most rapidly growing 
      consumer application in history. The advent of ChatGPT has further brought about 
      new ideas and challenges in the realm of infectious disease. In view of this, in 
      order to evaluate the potential use of ChatGPT in clinical practice and 
      scientific research of infectious disease, we conducted a brief online survey by 
      using the publicly available ChatGPT webpage. Also, the present study also talks 
      about the relevant social and ethical issues related to this program.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Cheng, Kunming
AU  - Cheng K
AD  - Department of Intensive Care Unit, The Second Affiliated Hospital of Zhengzhou 
      University, Zhengzhou, Henan, China.
FAU - Li, Zhiyong
AU  - Li Z
AD  - Department of Orthopedics, Baodi Clinical College of Tianjin Medical University, 
      Tianjin, China.
FAU - He, Yongbin
AU  - He Y
AD  - School of Sport Medicine and Rehabilitation, Beijing Sport University, Beijing, 
      China.
AD  - University of North Carolina at Chapel Hill, Chapel Hill, NC, USA.
FAU - Guo, Qiang
AU  - Guo Q
AD  - Department of Orthopedics, Baodi Clinical College of Tianjin Medical University, 
      Tianjin, China.
FAU - Lu, Yanqiu
AU  - Lu Y
AD  - Department of Intensive Care Unit, The Second Affiliated Hospital of Zhengzhou 
      University, Zhengzhou, Henan, China. yanqiul@163.com.
FAU - Gu, Shuqin
AU  - Gu S
AD  - Duke Human Vaccine Institute, Duke University Medical Center, Durham, NC, USA. 
      shuqin.gu@duke.edu.
FAU - Wu, Haiyang
AU  - Wu H
AD  - Department of Graduate School, Tianjin Medical University, Tianjin, China. 
      wuhaiyang2021@tmu.edu.cn.
AD  - Duke Molecular Physiology Institute, Duke University School of Medicine, Durham, 
      NC, USA. wuhaiyang2021@tmu.edu.cn.
LA  - eng
PT  - Letter
DEP - 20230419
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Software
MH  - *Communicable Diseases
MH  - Electric Power Supplies
PMC - PMC10116900
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Chatbots
OT  - Infectious disease
COIS- The authors declare no conflict of interest.
EDAT- 2023/04/19 12:42
MHDA- 2023/05/12 07:06
PMCR- 2023/04/20
CRDT- 2023/04/19 11:17
PHST- 2023/04/04 00:00 [received]
PHST- 2023/04/05 00:00 [accepted]
PHST- 2023/05/12 07:06 [medline]
PHST- 2023/04/19 12:42 [pubmed]
PHST- 2023/04/19 11:17 [entrez]
PHST- 2023/04/20 00:00 [pmc-release]
AID - 10.1007/s10439-023-03203-3 [pii]
AID - 3203 [pii]
AID - 10.1007/s10439-023-03203-3 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2023 Jun;51(6):1130-1135. doi: 10.1007/s10439-023-03203-3. Epub 
      2023 Apr 19.

PMID- 38540976
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240330
IS  - 2075-4426 (Print)
IS  - 2075-4426 (Electronic)
IS  - 2075-4426 (Linking)
VI  - 14
IP  - 3
DP  - 2024 Feb 22
TI  - Personalized Medicine Transformed: ChatGPT's Contribution to Continuous Renal 
      Replacement Therapy Alarm Management in Intensive Care Units.
LID - 10.3390/jpm14030233 [doi]
LID - 233
AB  - The accurate interpretation of CRRT machine alarms is crucial in the intensive 
      care setting. ChatGPT, with its advanced natural language processing 
      capabilities, has emerged as a tool that is evolving and advancing in its ability 
      to assist with healthcare information. This study is designed to evaluate the 
      accuracy of the ChatGPT-3.5 and ChatGPT-4 models in addressing queries related to 
      CRRT alarm troubleshooting. This study consisted of two rounds of ChatGPT-3.5 and 
      ChatGPT-4 responses to address 50 CRRT machine alarm questions that were 
      carefully selected by two nephrologists in intensive care. Accuracy was 
      determined by comparing the model responses to predetermined answer keys provided 
      by critical care nephrologists, and consistency was determined by comparing 
      outcomes across the two rounds. The accuracy rate of ChatGPT-3.5 was 86% and 84%, 
      while the accuracy rate of ChatGPT-4 was 90% and 94% in the first and second 
      rounds, respectively. The agreement between the first and second rounds of 
      ChatGPT-3.5 was 84% with a Kappa statistic of 0.78, while the agreement of 
      ChatGPT-4 was 92% with a Kappa statistic of 0.88. Although ChatGPT-4 tended to 
      provide more accurate and consistent responses than ChatGPT-3.5, there was no 
      statistically significant difference between the accuracy and agreement rate 
      between ChatGPT-3.5 and -4. ChatGPT-4 had higher accuracy and consistency but did 
      not achieve statistical significance. While these findings are encouraging, there 
      is still potential for further development to achieve even greater reliability. 
      This advancement is essential for ensuring the highest-quality patient care and 
      safety standards in managing CRRT machine-related issues.
FAU - Sheikh, Mohammad S
AU  - Sheikh MS
AUID- ORCID: 0009-0006-9388-8505
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
FAU - Thongprayoon, Charat
AU  - Thongprayoon C
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
FAU - Qureshi, Fawad
AU  - Qureshi F
AUID- ORCID: 0000-0003-3387-4882
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
FAU - Suppadungsuk, Supawadee
AU  - Suppadungsuk S
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
AD  - Chakri Naruebodindra Medical Institute, Faculty of Medicine Ramathibodi Hospital, 
      Mahidol University, Samut Prakan 10540, Thailand.
FAU - Kashani, Kianoush B
AU  - Kashani KB
AUID- ORCID: 0000-0003-2184-3683
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
AD  - Division of Pulmonary and Critical Care Medicine, Department of Medicine, Mayo 
      Clinic, Rochester, MN 55902, USA.
FAU - Miao, Jing
AU  - Miao J
AUID- ORCID: 0000-0003-0642-9740
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
FAU - Craici, Iasmina M
AU  - Craici IM
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
FAU - Cheungpasitporn, Wisit
AU  - Cheungpasitporn W
AUID- ORCID: 0000-0001-9954-9711
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
LA  - eng
PT  - Journal Article
DEP - 20240222
PL  - Switzerland
TA  - J Pers Med
JT  - Journal of personalized medicine
JID - 101602269
PMC - PMC10971480
OTO - NOTNLM
OT  - CKRT
OT  - CRRT
OT  - CRRT alarm
OT  - ChatGPT
OT  - NLP
OT  - artificial intelligence
OT  - chatbot
OT  - clinical decision support systems
OT  - continuous kidney replacement therapy
OT  - continuous renal replacement therapy
OT  - critical care
OT  - intensive care technology
OT  - natural language processing
OT  - nephrology
COIS- The authors declare no conflicts of interest.
EDAT- 2024/03/28 06:44
MHDA- 2024/03/28 06:45
PMCR- 2024/02/22
CRDT- 2024/03/28 01:10
PHST- 2024/01/21 00:00 [received]
PHST- 2024/02/19 00:00 [revised]
PHST- 2024/02/20 00:00 [accepted]
PHST- 2024/03/28 06:45 [medline]
PHST- 2024/03/28 06:44 [pubmed]
PHST- 2024/03/28 01:10 [entrez]
PHST- 2024/02/22 00:00 [pmc-release]
AID - jpm14030233 [pii]
AID - jpm-14-00233 [pii]
AID - 10.3390/jpm14030233 [doi]
PST - epublish
SO  - J Pers Med. 2024 Feb 22;14(3):233. doi: 10.3390/jpm14030233.

PMID- 38563440
OWN - NLM
STAT- Publisher
LR  - 20240402
IS  - 1942-7522 (Electronic)
IS  - 0145-5613 (Linking)
DP  - 2024 Apr 2
TI  - Can ChatGPT Replace an Otolaryngologist in Guiding Parents on Tonsillectomy?
PG  - 1455613241230841
LID - 10.1177/01455613241230841 [doi]
AB  - Background: ChatGPT is an artificial intelligence tool, which utilizes machine 
      learning to analyze and generate human-like text. The user-friendly accessibility 
      of this tool enables patients conveniently access medical information without 
      intricate terminology challenges. The objective of this study was to assess the 
      accuracy of ChatGPT in providing insights into indications and management of 
      complications after tonsillectomy, a common pediatric otolaryngology procedure. 
      Methods: The responses generated by ChatGPT were compared to the "Clinical 
      practice guidelines: tonsillectomy in children-executive summary" developed by 
      the American Academy of Otolaryngology-Head and Neck Surgery Foundation 
      (AAO-HNSF). An assessment was carried out by presenting predetermined questions 
      regarding indications and complications post tonsillectomy to ChatGPT, followed 
      by a comparison of its responses with the established guideline by 2 
      otolaryngology experts. The responses of both parties were reviewed by the senior 
      author. Results: A total of 16 responses generated by ChatGPT were assessed. 
      After a comprehensive review, it was concluded that 15 out of 16 (93.8%) 
      responses demonstrated a high degree of reliability and accuracy, closely 
      adhering to the standard established by the AAO-HNSF guideline. Conclusion: The 
      results validate the potential of using ChatGPT to enhance healthcare delivery 
      making guidelines more accessible to patients while also emphasizing the 
      importance of ensuring the provision of accurate and reliable medical advice to 
      patients.
FAU - Moise, Alexander
AU  - Moise A
AUID- ORCID: 0000-0001-9438-1788
AD  - Faculty of Medicine and Health Sciences, McGill University, Montreal, QC, Canada.
FAU - Centomo-Bozzo, Adam
AU  - Centomo-Bozzo A
AD  - Faculty of Dental Medicine and Oral Health Sciences, McGill University, Montreal, 
      QC, Canada.
FAU - Orishchak, Ostap
AU  - Orishchak O
AD  - Department of Pediatric Otolaryngology, Montreal Children's Hospital, Montreal, 
      QC, Canada.
FAU - Alnoury, Mohammed K
AU  - Alnoury MK
AUID- ORCID: 0000-0001-9222-8501
AD  - Department of Otolaryngology-Head and Neck Surgery, King Abdulaziz University, 
      Jeddah, Saudi Arabia.
FAU - Daniel, Sam J
AU  - Daniel SJ
AD  - Department of Pediatric Otolaryngology, Montreal Children's Hospital, Montreal, 
      QC, Canada.
LA  - eng
PT  - Journal Article
DEP - 20240402
PL  - United States
TA  - Ear Nose Throat J
JT  - Ear, nose, &amp; throat journal
JID - 7701817
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - OpenAI
OT  - artificial intelligence
OT  - otolaryngology
OT  - tonsillectomy
COIS- Declaration of Conflicting InterestsThe author(s) declared no potential conflicts 
      of interest with respect to the research, authorship, and/or publication of this 
      article.
EDAT- 2024/04/02 12:45
MHDA- 2024/04/02 12:45
CRDT- 2024/04/02 08:03
PHST- 2024/04/02 12:45 [medline]
PHST- 2024/04/02 12:45 [pubmed]
PHST- 2024/04/02 08:03 [entrez]
AID - 10.1177/01455613241230841 [doi]
PST - aheadofprint
SO  - Ear Nose Throat J. 2024 Apr 2:1455613241230841. doi: 10.1177/01455613241230841.

PMID- 37795422
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231006
IS  - 2296-858X (Print)
IS  - 2296-858X (Electronic)
IS  - 2296-858X (Linking)
VI  - 10
DP  - 2023
TI  - Evaluating the performance of ChatGPT-4 on the United Kingdom Medical Licensing 
      Assessment.
PG  - 1240915
LID - 10.3389/fmed.2023.1240915 [doi]
LID - 1240915
AB  - INTRODUCTION: Recent developments in artificial intelligence large language 
      models (LLMs), such as ChatGPT, have allowed for the understanding and generation 
      of human-like text. Studies have found LLMs abilities to perform well in various 
      examinations including law, business and medicine. This study aims to evaluate 
      the performance of ChatGPT in the United Kingdom Medical Licensing Assessment 
      (UKMLA). METHODS: Two publicly available UKMLA papers consisting of 200 
      single-best-answer (SBA) questions were screened. Nine SBAs were omitted as they 
      contained images that were not suitable for input. Each question was assigned a 
      specialty based on the UKMLA content map published by the General Medical 
      Council. A total of 191 SBAs were inputted in ChatGPT-4 through three attempts 
      over the course of 3 weeks (once per week). RESULTS: ChatGPT scored 74.9% 
      (143/191), 78.0% (149/191) and 75.6% (145/191) on three attempts, respectively. 
      The average of all three attempts was 76.3% (437/573) with a 95% confidence 
      interval of (74.46% and 78.08%). ChatGPT answered 129 SBAs correctly and 32 SBAs 
      incorrectly on all three attempts. On three attempts, ChatGPT performed well in 
      mental health (8/9 SBAs), cancer (11/14 SBAs) and cardiovascular (10/13 SBAs). On 
      three attempts, ChatGPT did not perform well in clinical haematology (3/7 SBAs), 
      endocrine and metabolic (2/5 SBAs) and gastrointestinal including liver (3/10 
      SBAs). Regarding to response consistency, ChatGPT provided correct answers 
      consistently in 67.5% (129/191) of SBAs but provided incorrect answers 
      consistently in 12.6% (24/191) and inconsistent response in 19.9% (38/191) of 
      SBAs, respectively. DISCUSSION AND CONCLUSION: This study suggests ChatGPT 
      performs well in the UKMLA. There may be a potential correlation between 
      specialty performance. LLMs ability to correctly answer SBAs suggests that it 
      could be utilised as a supplementary learning tool in medical education with 
      appropriate medical educator supervision.
CI  - Copyright © 2023 Lai, Wu, Hsu and Kan.
FAU - Lai, U Hin
AU  - Lai UH
AD  - Sandwell and West Birmingham NHS Trust, West Bromwich, United Kingdom.
AD  - Aston Medical School, Birmingham, United Kingdom.
FAU - Wu, Keng Sam
AU  - Wu KS
AD  - Sandwell and West Birmingham NHS Trust, West Bromwich, United Kingdom.
AD  - University Hospitals Birmingham NHS Trust, Birmingham, United Kingdom.
FAU - Hsu, Ting-Yu
AU  - Hsu TY
AD  - Aston Medical School, Birmingham, United Kingdom.
AD  - University Hospitals Birmingham NHS Trust, Birmingham, United Kingdom.
FAU - Kan, Jessie Kai Ching
AU  - Kan JKC
AD  - Aston Medical School, Birmingham, United Kingdom.
AD  - Worcestershire Acute Hospitals NHS Trust, Worcester, United Kingdom.
LA  - eng
PT  - Journal Article
DEP - 20230919
PL  - Switzerland
TA  - Front Med (Lausanne)
JT  - Frontiers in medicine
JID - 101648047
PMC - PMC10547055
OTO - NOTNLM
OT  - ChatGPT
OT  - Medical Licensing Examination
OT  - United Kingdom Medical Licensing Assessment
OT  - assessment
OT  - examination
OT  - medical education
OT  - medicine
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/10/05 06:43
MHDA- 2023/10/05 06:44
PMCR- 2023/09/19
CRDT- 2023/10/05 04:11
PHST- 2023/06/15 00:00 [received]
PHST- 2023/08/30 00:00 [accepted]
PHST- 2023/10/05 06:44 [medline]
PHST- 2023/10/05 06:43 [pubmed]
PHST- 2023/10/05 04:11 [entrez]
PHST- 2023/09/19 00:00 [pmc-release]
AID - 10.3389/fmed.2023.1240915 [doi]
PST - epublish
SO  - Front Med (Lausanne). 2023 Sep 19;10:1240915. doi: 10.3389/fmed.2023.1240915. 
      eCollection 2023.

PMID- 38183467
OWN - NLM
STAT- Publisher
LR  - 20240106
IS  - 1435-702X (Electronic)
IS  - 0721-832X (Linking)
DP  - 2024 Jan 6
TI  - Diagnostic capabilities of ChatGPT in ophthalmology.
LID - 10.1007/s00417-023-06363-z [doi]
AB  - PURPOSE: The purpose of this study is to assess the diagnostic accuracy of 
      ChatGPT in the field of ophthalmology. METHODS: This is a retrospective cohort 
      study conducted in one academic tertiary medical center. We reviewed data of 
      patients admitted to the ophthalmology department from 06/2022 to 01/2023. We 
      then created two clinical cases for each patient. The first case is according to 
      the medical history alone (Hx). The second case includes an addition of the 
      clinical examination (Hx and Ex). For each case, we asked for the three most 
      likely diagnoses from ChatGPT, residents, and attendings. Then, we compared the 
      accuracy rates (at least one correct diagnosis) of all groups. Additionally, we 
      evaluated the total duration for completing the assignment between the groups. 
      RESULTS: ChatGPT, residents, and attendings evaluated 126 cases from 63 patients 
      (history only or history and exam findings for each patient). ChatGPT achieved a 
      significantly lower accurate diagnosis rate (54%) in the Hx, as compared to the 
      residents (75%; p &lt; 0.01) and attendings (71%; p &lt; 0.01). After adding the 
      clinical examination findings, the diagnosis rate of ChatGPT was 68%, whereas for 
      the residents and the attendings, it increased to 94% (p &lt; 0.01) and 86% 
      (p &lt; 0.01), respectively. ChatGPT was 4 to 5 times faster than the attendings and 
      residents. CONCLUSIONS AND RELEVANCE: ChatGPT showed low diagnostic rates in 
      ophthalmology cases compared to residents and attendings based on patient history 
      alone or with additional clinical examination findings. However, ChatGPT 
      completed the task faster than the physicians.
CI  - © 2024. The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, 
      part of Springer Nature.
FAU - Shemer, Asaf
AU  - Shemer A
AUID- ORCID: 0000-0002-4366-5438
AD  - Department of Ophthalmology, Shamir Medical Center (Formerly Assaf-Harofeh), 
      Tzrifin, Israel. ShemerAsafMD@gmail.com.
AD  - Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel. 
      ShemerAsafMD@gmail.com.
FAU - Cohen, Michal
AU  - Cohen M
AD  - Department of Ophthalmology, Shamir Medical Center (Formerly Assaf-Harofeh), 
      Tzrifin, Israel.
AD  - Faculty of Health Science, Ben-Gurion University of the Negev, South District, 
      Beer-Sheva, Israel.
FAU - Altarescu, Aya
AU  - Altarescu A
AD  - Department of Ophthalmology, Shamir Medical Center (Formerly Assaf-Harofeh), 
      Tzrifin, Israel.
AD  - Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel.
FAU - Atar-Vardi, Maya
AU  - Atar-Vardi M
AD  - Department of Ophthalmology, Shamir Medical Center (Formerly Assaf-Harofeh), 
      Tzrifin, Israel.
AD  - Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel.
FAU - Hecht, Idan
AU  - Hecht I
AD  - Department of Ophthalmology, Shamir Medical Center (Formerly Assaf-Harofeh), 
      Tzrifin, Israel.
AD  - Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel.
FAU - Dubinsky-Pertzov, Biana
AU  - Dubinsky-Pertzov B
AD  - Department of Ophthalmology, Shamir Medical Center (Formerly Assaf-Harofeh), 
      Tzrifin, Israel.
AD  - Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel.
FAU - Shoshany, Nadav
AU  - Shoshany N
AD  - Department of Ophthalmology, Shamir Medical Center (Formerly Assaf-Harofeh), 
      Tzrifin, Israel.
AD  - Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel.
FAU - Zmujack, Sigal
AU  - Zmujack S
AD  - Department of Ophthalmology, Shamir Medical Center (Formerly Assaf-Harofeh), 
      Tzrifin, Israel.
AD  - Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel.
FAU - Or, Lior
AU  - Or L
AD  - Department of Ophthalmology, Shamir Medical Center (Formerly Assaf-Harofeh), 
      Tzrifin, Israel.
AD  - Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel.
FAU - Einan-Lifshitz, Adi
AU  - Einan-Lifshitz A
AD  - Department of Ophthalmology, Shamir Medical Center (Formerly Assaf-Harofeh), 
      Tzrifin, Israel.
AD  - Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel.
FAU - Pras, Eran
AU  - Pras E
AD  - Department of Ophthalmology, Shamir Medical Center (Formerly Assaf-Harofeh), 
      Tzrifin, Israel.
AD  - Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel.
AD  - The Matlow's Ophthalmo-Genetics Laboratory, Department of Ophthalmology, Shamir 
      Medical Center (Formerly Assaf-Harofeh), Tzrifin, Israel.
LA  - eng
PT  - Journal Article
DEP - 20240106
PL  - Germany
TA  - Graefes Arch Clin Exp Ophthalmol
JT  - Graefe's archive for clinical and experimental ophthalmology = Albrecht von 
      Graefes Archiv fur klinische und experimentelle Ophthalmologie
JID - 8205248
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Diagnosis
OT  - Ophthalmology
OT  - Residents
EDAT- 2024/01/07 06:42
MHDA- 2024/01/07 06:42
CRDT- 2024/01/06 11:05
PHST- 2023/06/28 00:00 [received]
PHST- 2023/12/23 00:00 [accepted]
PHST- 2023/12/04 00:00 [revised]
PHST- 2024/01/07 06:42 [medline]
PHST- 2024/01/07 06:42 [pubmed]
PHST- 2024/01/06 11:05 [entrez]
AID - 10.1007/s00417-023-06363-z [pii]
AID - 10.1007/s00417-023-06363-z [doi]
PST - aheadofprint
SO  - Graefes Arch Clin Exp Ophthalmol. 2024 Jan 6. doi: 10.1007/s00417-023-06363-z.

PMID- 37140001
OWN - NLM
STAT- MEDLINE
DCOM- 20231120
LR  - 20240116
IS  - 1527-330X (Electronic)
IS  - 1090-820X (Linking)
VI  - 43
IP  - 12
DP  - 2023 Nov 16
TI  - ChatGPT Is Equivalent to First-Year Plastic Surgery Residents: Evaluation of 
      ChatGPT on the Plastic Surgery In-Service Examination.
PG  - NP1085-NP1089
LID - 10.1093/asj/sjad130 [doi]
AB  - BACKGROUND: ChatGPT is an artificial intelligence language model developed and 
      released by OpenAI (San Francisco, CA) in late 2022. OBJECTIVES: The aim of this 
      study was to evaluate the performance of ChatGPT on the Plastic Surgery 
      In-Service Examination and to compare it to residents' performance nationally. 
      METHODS: The Plastic Surgery In-Service Examinations from 2018 to 2022 were used 
      as a question source. For each question, the stem and all multiple-choice options 
      were imported into ChatGPT. The 2022 examination was used to compare the 
      performance of ChatGPT to plastic surgery residents nationally. RESULTS: In 
      total, 1129 questions were included in the final analysis and ChatGPT answered 
      630 (55.8%) of these correctly. ChatGPT scored the highest on the 2021 exam 
      (60.1%) and on the comprehensive section (58.7%). There were no significant 
      differences regarding questions answered correctly among exam years or among the 
      different exam sections. ChatGPT answered 57% of questions correctly on the 2022 
      exam. When compared to the performance of plastic surgery residents in 2022, 
      ChatGPT would rank in the 49th percentile for first-year integrated plastic 
      surgery residents, 13th percentile for second-year residents, 5th percentile for 
      third- and fourth-year residents, and 0th percentile for fifth- and sixth-year 
      residents. CONCLUSIONS: ChatGPT performs at the level of a first-year resident on 
      the Plastic Surgery In-Service Examination. However, it performed poorly when 
      compared with residents in more advanced years of training. Although ChatGPT has 
      many undeniable benefits and potential uses in the field of healthcare and 
      medical education, it will require additional research to assess its efficacy.
CI  - © The Author(s) 2023. Published by Oxford University Press on behalf of The 
      Aesthetic Society. All rights reserved. For permissions, please e-mail: 
      journals.permissions@oup.com.
FAU - Humar, Pooja
AU  - Humar P
FAU - Asaad, Malke
AU  - Asaad M
AUID- ORCID: 0000-0002-2313-1973
FAU - Bengur, Fuat Baris
AU  - Bengur FB
FAU - Nguyen, Vu
AU  - Nguyen V
LA  - eng
PT  - Journal Article
PL  - England
TA  - Aesthet Surg J
JT  - Aesthetic surgery journal
JID - 9707469
SB  - IM
EIN - Aesthet Surg J. 2023 Sep 29;:. PMID: 37772448
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Surgery, Plastic
MH  - Physical Examination
EDAT- 2023/05/04 12:41
MHDA- 2023/11/20 06:55
CRDT- 2023/05/04 07:03
PHST- 2023/11/20 06:55 [medline]
PHST- 2023/05/04 12:41 [pubmed]
PHST- 2023/05/04 07:03 [entrez]
AID - 7151262 [pii]
AID - 10.1093/asj/sjad130 [doi]
PST - ppublish
SO  - Aesthet Surg J. 2023 Nov 16;43(12):NP1085-NP1089. doi: 10.1093/asj/sjad130.

PMID- 38411835
OWN - NLM
STAT- In-Process
LR  - 20240403
IS  - 1557-900X (Electronic)
IS  - 0892-7790 (Linking)
VI  - 38
IP  - 4
DP  - 2024 Apr
TI  - Evaluation of ChatGPT for Patient Counseling in Kidney Stone Clinic: A 
      Prospective Study.
PG  - 377-383
LID - 10.1089/end.2023.0571 [doi]
AB  - Introduction: The potential of large language models (LLMs) is to improve the 
      clinical workflow and to make patient care efficient. We prospectively evaluated 
      the performance of the LLM ChatGPT as a patient counseling tool in the urology 
      stone clinic and validated the generated responses with those of urologists. 
      Methods: We collected 61 questions from 12 kidney stone patients and prompted 
      those to ChatGPT and a panel of experienced urologists (Level 1). Subsequently, 
      the blinded responses of urologists and ChatGPT were presented to two expert 
      urologists (Level 2) for comparative evaluation on preset domains: accuracy, 
      relevance, empathy, completeness, and practicality. All responses were rated on a 
      Likert scale of 1 to 10 for psychometric response evaluation. The mean difference 
      in the scores given by the urologists (Level 2) was analyzed and interrater 
      reliability (IRR) for the level of agreement in the responses between the 
      urologists (Level 2) was analyzed by Cohen's kappa. Results: The mean differences 
      in average scores between the responses from ChatGPT and urologists showed 
      significant differences in accuracy (p &lt; 0.001), empathy (p &lt; 0.001), 
      completeness (p &lt; 0.001), and practicality (p &lt; 0.001), except for the relevance 
      domain (p = 0.051), with ChatGPT's responses being rated higher. The IRR analysis 
      revealed significant agreement only in the empathy domain [k = 0.163, 
      (0.059-0.266)]. Conclusion: We believe the introduction of ChatGPT in the 
      clinical workflow could further optimize the information provided to patients in 
      a busy stone clinic. In this preliminary study, ChatGPT supplemented the answers 
      provided by the urologists, adding value to the conversation. However, in its 
      current state, it is still not ready to be a direct source of authentic 
      information for patients. We recommend its use as a source to build a 
      comprehensive Frequently Asked Questions bank as a prelude to developing an LLM 
      Chatbot for patient counseling.
FAU - Javid, Mohamed
AU  - Javid M
AD  - Department of Urology, Chengalpattu Medical College, Chengalpattu, Tamil Nadu, 
      India.
FAU - Bhandari, Mahendra
AU  - Bhandari M
AD  - Vattikuti Urology Institute, Henry Ford Hospital, Detroit, Michigan, USA.
FAU - Parameshwari, P
AU  - Parameshwari P
AD  - Department of Community Medicine, Chengalpattu Medical College, Chengalpattu, 
      Tamil Nadu, India.
FAU - Reddiboina, Madhu
AU  - Reddiboina M
AD  - RediMinds, Inc., Southfield, Michigan, USA.
FAU - Prasad, Srikala
AU  - Prasad S
AD  - Department of Urology, Chengalpattu Medical College, Chengalpattu, Tamil Nadu, 
      India.
LA  - eng
PT  - Journal Article
DEP - 20240227
PL  - United States
TA  - J Endourol
JT  - Journal of endourology
JID - 8807503
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - large language models
OT  - patient queries
OT  - renal stone disease
EDAT- 2024/02/27 12:45
MHDA- 2024/02/27 12:45
CRDT- 2024/02/27 11:12
PHST- 2024/02/27 12:45 [pubmed]
PHST- 2024/02/27 12:45 [medline]
PHST- 2024/02/27 11:12 [entrez]
AID - 10.1089/end.2023.0571 [doi]
PST - ppublish
SO  - J Endourol. 2024 Apr;38(4):377-383. doi: 10.1089/end.2023.0571. Epub 2024 Feb 27.

PMID- 38025546
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231201
IS  - 2090-0724 (Print)
IS  - 2090-0732 (Electronic)
IS  - 2090-0724 (Linking)
VI  - 2023
DP  - 2023
TI  - Comparison of Answers between ChatGPT and Human Dieticians to Common Nutrition 
      Questions.
PG  - 5548684
LID - 10.1155/2023/5548684 [doi]
LID - 5548684
AB  - BACKGROUND: More people than ever seek nutrition information from online sources. 
      The chatbot ChatGPT has seen staggering popularity since its inception and may 
      become a resource for information in nutrition. However, the adequacy of ChatGPT 
      to answer questions in the field of nutrition has not been investigated. Thus, 
      the aim of this research was to investigate the competency of ChatGPT in 
      answering common nutrition questions. METHODS: Dieticians were asked to provide 
      their most commonly asked nutrition questions and their own answers to them. We 
      then asked the same questions to ChatGPT and sent both sets of answers to other 
      dieticians (N = 18) or nutritionists and experts in the domain of each question 
      (N = 9) to be graded based on scientific correctness, actionability, and 
      comprehensibility. The grades were also averaged to give an overall score, and 
      group means of the answers to each question were compared using permutation 
      tests. RESULTS: The overall grades for ChatGPT were higher than those from the 
      dieticians for the overall scores in five of the eight questions we received. 
      ChatGPT also had higher grades on five occasions for scientific correctness, four 
      for actionability, and five for comprehensibility. In contrast, none of the 
      answers from the dieticians had a higher average score than ChatGPT for any of 
      the questions, both overall and for each of the grading components. CONCLUSIONS: 
      Our results suggest that ChatGPT can be used to answer nutrition questions that 
      are frequently asked to dieticians and provide encouraging support for the role 
      of chatbots in offering nutrition support.
CI  - Copyright © 2023 Daniel Kirk et al.
FAU - Kirk, Daniel
AU  - Kirk D
AUID- ORCID: 0000-0001-7738-7686
AD  - Division of Human Nutrition and Health, Wageningen University &amp; Research, Helix, 
      Stippeneng 4, Wageningen 6708 WE, Netherlands.
AD  - Department of Twin Research and Genetic Epidemiology, King's College London, St 
      Thomas' Hospital Campus, 4th Floor South Wing Block D, Westminster Bridge Rd, 
      London SE1 7EH, UK.
FAU - van Eijnatten, Elise
AU  - van Eijnatten E
AUID- ORCID: 0000-0002-2591-0583
AD  - Division of Human Nutrition and Health, Wageningen University &amp; Research, Helix, 
      Stippeneng 4, Wageningen 6708 WE, Netherlands.
FAU - Camps, Guido
AU  - Camps G
AUID- ORCID: 0000-0002-3136-8671
AD  - Division of Human Nutrition and Health, Wageningen University &amp; Research, Helix, 
      Stippeneng 4, Wageningen 6708 WE, Netherlands.
AD  - OnePlanet Research Center, Plus Ultra II, Bronland 10, Wageningen 6708 WE, 
      Netherlands.
LA  - eng
PT  - Journal Article
DEP - 20231107
PL  - United States
TA  - J Nutr Metab
JT  - Journal of nutrition and metabolism
JID - 101526296
PMC - PMC10645493
COIS- The authors declare that they have no conflicts of interest.
EDAT- 2023/11/29 18:41
MHDA- 2023/11/29 18:42
PMCR- 2023/11/07
CRDT- 2023/11/29 16:32
PHST- 2023/07/10 00:00 [received]
PHST- 2023/10/11 00:00 [revised]
PHST- 2023/10/12 00:00 [accepted]
PHST- 2023/11/29 18:42 [medline]
PHST- 2023/11/29 18:41 [pubmed]
PHST- 2023/11/29 16:32 [entrez]
PHST- 2023/11/07 00:00 [pmc-release]
AID - 10.1155/2023/5548684 [doi]
PST - epublish
SO  - J Nutr Metab. 2023 Nov 7;2023:5548684. doi: 10.1155/2023/5548684. eCollection 
      2023.

PMID- 38247934
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240128
IS  - 2306-5354 (Print)
IS  - 2306-5354 (Electronic)
IS  - 2306-5354 (Linking)
VI  - 11
IP  - 1
DP  - 2024 Jan 6
TI  - ChatGPT in Occupational Medicine: A Comparative Study with Human Experts.
LID - 10.3390/bioengineering11010057 [doi]
LID - 57
AB  - The objective of this study is to evaluate ChatGPT's accuracy and reliability in 
      answering complex medical questions related to occupational health and explore 
      the implications and limitations of AI in occupational health medicine. The study 
      also provides recommendations for future research in this area and informs 
      decision-makers about AI's impact on healthcare. A group of physicians was 
      enlisted to create a dataset of questions and answers on Italian occupational 
      medicine legislation. The physicians were divided into two teams, and each team 
      member was assigned a different subject area. ChatGPT was used to generate 
      answers for each question, with/without legislative context. The two teams then 
      evaluated human and AI-generated answers blind, with each group reviewing the 
      other group's work. Occupational physicians outperformed ChatGPT in generating 
      accurate questions on a 5-point Likert score, while the answers provided by 
      ChatGPT with access to legislative texts were comparable to those of professional 
      doctors. Still, we found that users tend to prefer answers generated by humans, 
      indicating that while ChatGPT is useful, users still value the opinions of 
      occupational medicine professionals.
FAU - Padovan, Martina
AU  - Padovan M
AUID- ORCID: 0000-0001-8461-1527
AD  - Department of Translational Research and New Technologies in Medicine and 
      Surgery, University of Pisa, 56126 Pisa, Italy.
FAU - Cosci, Bianca
AU  - Cosci B
AD  - Department of Translational Research and New Technologies in Medicine and 
      Surgery, University of Pisa, 56126 Pisa, Italy.
FAU - Petillo, Armando
AU  - Petillo A
AD  - Department of Translational Research and New Technologies in Medicine and 
      Surgery, University of Pisa, 56126 Pisa, Italy.
FAU - Nerli, Gianluca
AU  - Nerli G
AD  - Department of Translational Research and New Technologies in Medicine and 
      Surgery, University of Pisa, 56126 Pisa, Italy.
FAU - Porciatti, Francesco
AU  - Porciatti F
AD  - Department of Translational Research and New Technologies in Medicine and 
      Surgery, University of Pisa, 56126 Pisa, Italy.
FAU - Scarinci, Sergio
AU  - Scarinci S
AD  - Department of Translational Research and New Technologies in Medicine and 
      Surgery, University of Pisa, 56126 Pisa, Italy.
FAU - Carlucci, Francesco
AU  - Carlucci F
AD  - Department of Translational Research and New Technologies in Medicine and 
      Surgery, University of Pisa, 56126 Pisa, Italy.
FAU - Dell'Amico, Letizia
AU  - Dell'Amico L
AD  - Department of Translational Research and New Technologies in Medicine and 
      Surgery, University of Pisa, 56126 Pisa, Italy.
FAU - Meliani, Niccolò
AU  - Meliani N
AD  - Department of Translational Research and New Technologies in Medicine and 
      Surgery, University of Pisa, 56126 Pisa, Italy.
FAU - Necciari, Gabriele
AU  - Necciari G
AD  - Department of Translational Research and New Technologies in Medicine and 
      Surgery, University of Pisa, 56126 Pisa, Italy.
FAU - Lucisano, Vincenzo Carmelo
AU  - Lucisano VC
AD  - Department of Translational Research and New Technologies in Medicine and 
      Surgery, University of Pisa, 56126 Pisa, Italy.
FAU - Marino, Riccardo
AU  - Marino R
AD  - Department of Translational Research and New Technologies in Medicine and 
      Surgery, University of Pisa, 56126 Pisa, Italy.
FAU - Foddis, Rudy
AU  - Foddis R
AUID- ORCID: 0000-0003-1330-3863
AD  - Department of Translational Research and New Technologies in Medicine and 
      Surgery, University of Pisa, 56126 Pisa, Italy.
FAU - Palla, Alessandro
AU  - Palla A
AUID- ORCID: 0009-0005-9253-7191
AD  - Intel Corporation, Santa Clara, CA 95054, USA.
LA  - eng
PT  - Journal Article
DEP - 20240106
PL  - Switzerland
TA  - Bioengineering (Basel)
JT  - Bioengineering (Basel, Switzerland)
JID - 101676056
PMC - PMC10813435
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - digital health
OT  - health promotion
OT  - large language model
OT  - occupational health and safety
COIS- The authors declare no conflict of interest.
EDAT- 2024/01/22 06:42
MHDA- 2024/01/22 06:43
PMCR- 2024/01/06
CRDT- 2024/01/22 04:34
PHST- 2023/12/07 00:00 [received]
PHST- 2024/01/01 00:00 [revised]
PHST- 2024/01/04 00:00 [accepted]
PHST- 2024/01/22 06:43 [medline]
PHST- 2024/01/22 06:42 [pubmed]
PHST- 2024/01/22 04:34 [entrez]
PHST- 2024/01/06 00:00 [pmc-release]
AID - bioengineering11010057 [pii]
AID - bioengineering-11-00057 [pii]
AID - 10.3390/bioengineering11010057 [doi]
PST - epublish
SO  - Bioengineering (Basel). 2024 Jan 6;11(1):57. doi: 10.3390/bioengineering11010057.

PMID- 38153777
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240114
IS  - 2561-326X (Electronic)
IS  - 2561-326X (Linking)
VI  - 7
DP  - 2023 Dec 28
TI  - Exploring the Potential of ChatGPT-4 in Predicting Refractive Surgery 
      Categorizations: Comparative Study.
PG  - e51798
LID - 10.2196/51798 [doi]
LID - e51798
AB  - BACKGROUND: Refractive surgery research aims to optimally precategorize patients 
      by their suitability for various types of surgery. Recent advances have led to 
      the development of artificial intelligence-powered algorithms, including machine 
      learning approaches, to assess risks and enhance workflow. Large language models 
      (LLMs) like ChatGPT-4 (OpenAI LP) have emerged as potential general artificial 
      intelligence tools that can assist across various disciplines, possibly including 
      refractive surgery decision-making. However, their actual capabilities in 
      precategorizing refractive surgery patients based on real-world parameters remain 
      unexplored. OBJECTIVE: This exploratory study aimed to validate ChatGPT-4's 
      capabilities in precategorizing refractive surgery patients based on commonly 
      used clinical parameters. The goal was to assess whether ChatGPT-4's performance 
      when categorizing batch inputs is comparable to those made by a refractive 
      surgeon. A simple binary set of categories (patient suitable for laser refractive 
      surgery or not) as well as a more detailed set were compared. METHODS: Data from 
      100 consecutive patients from a refractive clinic were anonymized and analyzed. 
      Parameters included age, sex, manifest refraction, visual acuity, and various 
      corneal measurements and indices from Scheimpflug imaging. This study compared 
      ChatGPT-4's performance with a clinician's categorizations using Cohen κ 
      coefficient, a chi-square test, a confusion matrix, accuracy, precision, recall, 
      F(1)-score, and receiver operating characteristic area under the curve. RESULTS: 
      A statistically significant noncoincidental accordance was found between 
      ChatGPT-4 and the clinician's categorizations with a Cohen κ coefficient of 0.399 
      for 6 categories (95% CI 0.256-0.537) and 0.610 for binary categorization (95% CI 
      0.372-0.792). The model showed temporal instability and response variability, 
      however. The chi-square test on 6 categories indicated an association between the 
      2 raters' distributions (χ²(5)=94.7, P&lt;.001). Here, the accuracy was 0.68, 
      precision 0.75, recall 0.68, and F(1)-score 0.70. For 2 categories, the accuracy 
      was 0.88, precision 0.88, recall 0.88, F(1)-score 0.88, and area under the curve 
      0.79. CONCLUSIONS: This study revealed that ChatGPT-4 exhibits potential as a 
      precategorization tool in refractive surgery, showing promising agreement with 
      clinician categorizations. However, its main limitations include, among others, 
      dependency on solely one human rater, small sample size, the instability and 
      variability of ChatGPT's (OpenAI LP) output between iterations and 
      nontransparency of the underlying models. The results encourage further 
      exploration into the application of LLMs like ChatGPT-4 in health care, 
      particularly in decision-making processes that require understanding vast 
      clinical data. Future research should focus on defining the model's accuracy with 
      prompt and vignette standardization, detecting confounding factors, and comparing 
      to other versions of ChatGPT-4 and other LLMs to pave the way for larger-scale 
      validation and real-world implementation.
CI  - ©Aleksandar Ćirković, Toam Katz. Originally published in JMIR Formative Research 
      (https://formative.jmir.org), 28.12.2023.
FAU - Ćirković, Aleksandar
AU  - Ćirković A
AUID- ORCID: 0000-0002-2122-5175
AD  - Care Vision Germany, Ltd, Nuremberg, Germany.
FAU - Katz, Toam
AU  - Katz T
AUID- ORCID: 0000-0002-3160-0231
AD  - Department of Ophthalmology, University Medical Center Hamburg-Eppendorf, 
      Hamburg, Germany.
LA  - eng
PT  - Journal Article
DEP - 20231228
PL  - Canada
TA  - JMIR Form Res
JT  - JMIR formative research
JID - 101726394
PMC - PMC10784977
OTO - NOTNLM
OT  - AI-powered algorithm
OT  - ChatGPT
OT  - ChatGPT-4
OT  - artificial intelligence
OT  - categorization
OT  - clinical
OT  - data analysis
OT  - decision support systems
OT  - decision-making
OT  - eHealth
OT  - health informatics
OT  - large language model
OT  - machine learning
OT  - medical decision-making
OT  - ophthalmology
OT  - predictive modeling
OT  - refractive surgery
OT  - refractive surgical procedures
OT  - risk assessment
COIS- Conflicts of Interest: None declared.
EDAT- 2023/12/28 12:41
MHDA- 2023/12/28 12:42
PMCR- 2023/12/28
CRDT- 2023/12/28 11:53
PHST- 2023/08/14 00:00 [received]
PHST- 2023/12/04 00:00 [accepted]
PHST- 2023/11/01 00:00 [revised]
PHST- 2023/12/28 12:42 [medline]
PHST- 2023/12/28 12:41 [pubmed]
PHST- 2023/12/28 11:53 [entrez]
PHST- 2023/12/28 00:00 [pmc-release]
AID - v7i1e51798 [pii]
AID - 10.2196/51798 [doi]
PST - epublish
SO  - JMIR Form Res. 2023 Dec 28;7:e51798. doi: 10.2196/51798.

PMID- 38556438
OWN - NLM
STAT- Publisher
LR  - 20240331
IS  - 1878-7452 (Electronic)
IS  - 1878-7452 (Linking)
DP  - 2024 Mar 30
TI  - Evaluating The Role of ChatGPT as a Study Aid in Medical Education in Surgery.
LID - S1931-7204(24)00052-7 [pii]
LID - 10.1016/j.jsurg.2024.01.014 [doi]
AB  - OBJECTIVE: Our aim was to assess how ChatGPT compares to Google search in 
      assisting medical students during their surgery clerkships. DESIGN: We conducted 
      a crossover study where participants were asked to complete 2 standardized 
      assessments on different general surgery topics before and after they used either 
      Google search or ChatGPT. SETTING: The study was conducted at the Perelman School 
      of Medicine at the University of Pennsylvania (PSOM) in Philadelphia, 
      Pennsylvania. PARTICIPANTS: 19 third-year medical students participated in our 
      study. RESULTS: The baseline (preintervention) performance of participants on 
      both quizzes did not differ between the Google search and ChatGPT groups 
      (p = 0.728). Students overall performed better postintervention and the 
      difference in test scores was statistically significant for both the Google group 
      (p &lt; 0.001) and the ChatGPT group (p = 0.01). The mean percent increase in test 
      scores pre- and postintervention was higher in the Google group at 11% vs. 10% in 
      the ChatGPT group, but this difference was not statistically significant 
      (p = 0.87). Similarly, there was no statistically significant difference in 
      postintervention scores on both assessments between the 2 groups (p = 0.508). 
      Postassessment surveys revealed that all students (100%) have known about ChatGPT 
      before, and 47% have previously used it for various purposes. On a scale of 1 to 
      10 with 1 being the lowest and 10 being the highest, the feasibility of ChatGPT 
      and its usefulness in finding answers were rated as 8.4 and 6.6 on average, 
      respectively. When asked to rate the likelihood of using ChatGPT in their surgery 
      rotation, the answers ranged between 1 and 3 ("Unlikely" 47%), 4 to 6 
      ("intermediate" 26%), and 7 to 10 ("likely" 26%). CONCLUSION: Our results show 
      that even though ChatGPT was comparable to Google search in finding answers 
      pertaining to surgery questions, many students were reluctant to use ChatGPT for 
      learning purposes during their surgery clerkship.
CI  - Copyright © 2024 Association of Program Directors in Surgery. Published by 
      Elsevier Inc. All rights reserved.
FAU - Araji, Tarek
AU  - Araji T
AD  - Hospital of the University of Pennsylvania, Department of Surgery, Philadelphia, 
      Pennsylvania.
FAU - Brooks, Ari D
AU  - Brooks AD
AD  - Hospital of the University of Pennsylvania, Department of Surgery, Philadelphia, 
      Pennsylvania. Electronic address: Ari.Brooks@pennmedicine.upenn.edu.
LA  - eng
PT  - Journal Article
DEP - 20240330
PL  - United States
TA  - J Surg Educ
JT  - Journal of surgical education
JID - 101303204
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - Google search
OT  - Surgical assessments
OT  - Surgical clinical rotation
OT  - Surgical education
EDAT- 2024/04/01 00:42
MHDA- 2024/04/01 00:42
CRDT- 2024/03/31 21:57
PHST- 2023/09/20 00:00 [received]
PHST- 2024/01/15 00:00 [revised]
PHST- 2024/01/25 00:00 [accepted]
PHST- 2024/04/01 00:42 [medline]
PHST- 2024/04/01 00:42 [pubmed]
PHST- 2024/03/31 21:57 [entrez]
AID - S1931-7204(24)00052-7 [pii]
AID - 10.1016/j.jsurg.2024.01.014 [doi]
PST - aheadofprint
SO  - J Surg Educ. 2024 Mar 30:S1931-7204(24)00052-7. doi: 10.1016/j.jsurg.2024.01.014.

PMID- 38410331
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240229
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 16
IP  - 1
DP  - 2024 Jan
TI  - ChatGPT for Academic Purposes: Survey Among Undergraduate Healthcare Students in 
      Malaysia.
PG  - e53032
LID - 10.7759/cureus.53032 [doi]
LID - e53032
AB  - BACKGROUND: The impact of generative artificial intelligence-based Chatbots&nbsp;on 
      medical education, particularly in Southeast Asia, is understudied regarding 
      healthcare students' perceptions of its academic utility. Sociodemographic 
      profiles and educational strategies influence prospective healthcare 
      practitioners' attitudes toward AI tools. AIM AND OBJECTIVES: This study aimed to 
      assess healthcare university students' knowledge, attitude, and practice 
      regarding ChatGPT for academic purposes. It explored chatbot usage frequency, 
      purposes, satisfaction levels, and associations between age, gender, and ChatGPT 
      variables. METHODOLOGY: Four hundred forty-three undergraduate students at a 
      Malaysian tertiary healthcare institute participated, revealing varying awareness 
      levels of ChatGPT's academic utility. Despite concerns about accuracy, ethics, 
      and dependency, participants generally held positive attitudes toward ChatGPT in 
      academics. RESULTS: Multiple logistic regression highlighted associations between 
      demographics, knowledge, attitude, and academic ChatGPT use. MBBS students were 
      significantly more likely to use ChatGPT for academics than BDS and FIS students. 
      Final-year students exhibited the highest likelihood of academic ChatGPT use. 
      Higher knowledge and positive attitudes correlated with increased academic usage. 
      Most users (45.8%) employed ChatGPT to aid specific assignment sections while 
      completing most work independently. Some did not use it (41.1%), while others 
      heavily relied on it (9.3%). Users also employed it for various purposes, from 
      generating questions to understanding concepts. Thematic analysis of responses 
      showed students' concerns about data accuracy, plagiarism, ethical issues, and 
      dependency on ChatGPT for academic tasks. CONCLUSION: This study aids in creating 
      guidelines for implementing GAI chatbots in healthcare education, emphasizing 
      benefits, and risks, and informing AI developers and educators about ChatGPT's 
      potential in academia.
CI  - Copyright © 2024, George Pallivathukal et al.
FAU - George Pallivathukal, Renjith
AU  - George Pallivathukal R
AD  - Oral Pathology and Oral Biology, Manipal University College Malaysia, Melaka, 
      MYS.
FAU - Kyaw Soe, Htoo Htoo
AU  - Kyaw Soe HH
AD  - Community Medicine, Manipal University College Malaysia, Melaka, MYS.
FAU - Donald, Preethy Mary
AU  - Donald PM
AD  - Oral Medicine and Oral Radiology, Manipal University College Malaysia, Melaka, 
      MYS.
FAU - Samson, Renu Sarah
AU  - Samson RS
AD  - Orthodontics, Manipal University College Malaysia, Melaka, MYS.
FAU - Hj Ismail, Abdul Rashid
AU  - Hj Ismail AR
AD  - Community Dentistry, Manipal University College Malaysia, Melaka, MYS.
LA  - eng
PT  - Journal Article
DEP - 20240127
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10895383
OTO - NOTNLM
OT  - chatgpt
OT  - generative artificial intelligence
OT  - healthcare education
OT  - kap
OT  - medical students
OT  - undergraduate
COIS- The authors have declared that no competing interests exist.
EDAT- 2024/02/27 06:45
MHDA- 2024/02/27 06:46
PMCR- 2024/01/27
CRDT- 2024/02/27 03:37
PHST- 2024/01/27 00:00 [accepted]
PHST- 2024/02/27 06:46 [medline]
PHST- 2024/02/27 06:45 [pubmed]
PHST- 2024/02/27 03:37 [entrez]
PHST- 2024/01/27 00:00 [pmc-release]
AID - 10.7759/cureus.53032 [doi]
PST - epublish
SO  - Cureus. 2024 Jan 27;16(1):e53032. doi: 10.7759/cureus.53032. eCollection 2024 
      Jan.

PMID- 37998071
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231126
IS  - 2254-9625 (Electronic)
IS  - 2174-8144 (Print)
IS  - 2174-8144 (Linking)
VI  - 13
IP  - 11
DP  - 2023 Nov 9
TI  - Drivers and Consequences of ChatGPT Use in Higher Education: Key Stakeholder 
      Perspectives.
PG  - 2599-2614
LID - 10.3390/ejihpe13110181 [doi]
AB  - The incorporation of artificial intelligence (AI) into education has heralded a 
      transformative era in the way students learn and faculties teach. Among the 
      burgeoning array of AI tools, ChatGPT stands out as a versatile and powerful 
      resource. Developed by OpenAI, ChatGPT is an AI-driven conversational model that 
      generates human-like responses. This research draws on the Constructivism 
      Learning Theory to uncover the key drivers pushing higher education students to 
      use ChatGPT for academic purposes, and the multifaceted consequences it brings to 
      the academic environment, by integrating the perspectives of key stakeholders: 
      students, faculty, and education experts/leaders. The key findings of in-depth, 
      face-to-face, interviews with key stakeholders revealed 12 main drivers that 
      motivate students and their faculty to use ChatGPT mainly for learning purposes. 
      However, the findings identified the multifaceted (six positive and another six 
      negative) consequences of using ChatGPT for academic purposes. Recommendations 
      for mitigating the negative consequences of ChatGPT were discussed with key 
      stakeholders, particularly education experts/leaders, who were more concerned 
      about using ChatGPT for academic reasons. The research reveals that higher 
      education institutions should establish clear guidelines as a part of higher 
      education policy, supplemented with training sessions for students and their 
      faculty, about the responsible use of ChatGPT for academic purposes to mitigate 
      any ethical concerns.
FAU - Hasanein, Ahmed M
AU  - Hasanein AM
AUID- ORCID: 0000-0002-0664-9017
AD  - College of Business Administration, King Faisal University, Al-Ahsa P.O. Box 400, 
      Saudi Arabia.
AD  - Faculty of Tourism and Hotel Management, Helwan University, Cairo P.O. Box 12612, 
      Egypt.
FAU - Sobaih, Abu Elnasr E
AU  - Sobaih AEE
AUID- ORCID: 0000-0002-2730-689X
AD  - College of Business Administration, King Faisal University, Al-Ahsa P.O. Box 400, 
      Saudi Arabia.
AD  - Faculty of Tourism and Hotel Management, Helwan University, Cairo P.O. Box 12612, 
      Egypt.
LA  - eng
GR  - GRANT4379/This research was funded by the Deanship of Scientific Research, Vice 
      Presidency for Graduate Studies and Scientific Research, King Faisal University, 
      Saudi Arabia/
PT  - Journal Article
DEP - 20231109
PL  - Switzerland
TA  - Eur J Investig Health Psychol Educ
JT  - European journal of investigation in health, psychology and education
JID - 101751466
PMC - PMC10670526
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - chatbot
OT  - consequences
OT  - drivers
OT  - higher education
OT  - holistic perspective
COIS- The authors declare no conflict of interest.
EDAT- 2023/11/24 12:43
MHDA- 2023/11/24 12:44
PMCR- 2023/11/09
CRDT- 2023/11/24 09:33
PHST- 2023/10/04 00:00 [received]
PHST- 2023/10/28 00:00 [revised]
PHST- 2023/11/07 00:00 [accepted]
PHST- 2023/11/24 12:44 [medline]
PHST- 2023/11/24 12:43 [pubmed]
PHST- 2023/11/24 09:33 [entrez]
PHST- 2023/11/09 00:00 [pmc-release]
AID - ejihpe13110181 [pii]
AID - ejihpe-13-00181 [pii]
AID - 10.3390/ejihpe13110181 [doi]
PST - epublish
SO  - Eur J Investig Health Psychol Educ. 2023 Nov 9;13(11):2599-2614. doi: 
      10.3390/ejihpe13110181.

PMID- 37352054
OWN - NLM
STAT- MEDLINE
DCOM- 20230626
LR  - 20230927
IS  - 1536-5964 (Electronic)
IS  - 0025-7974 (Print)
IS  - 0025-7974 (Linking)
VI  - 102
IP  - 25
DP  - 2023 Jun 23
TI  - Assessing ChatGPT's capacity for clinical decision support in pediatrics: A 
      comparative study with pediatricians using KIDMAP of Rasch analysis.
PG  - e34068
LID - 10.1097/MD.0000000000034068 [doi]
LID - e34068
AB  - BACKGROUND: The application of large language models in clinical decision support 
      (CDS) is an area that warrants further investigation. ChatGPT, a prominent large 
      language models developed by OpenAI, has shown promising performance across 
      various domains. However, there is limited research evaluating its use 
      specifically in pediatric clinical decision-making. This study aimed to assess 
      ChatGPT's potential as a CDS tool in pediatrics by evCDSaluating its performance 
      on 8 common clinical symptom prompts. Study objectives were to answer the 2 
      research questions: the ChatGPT's overall grade in a range from A (high) to E 
      (low) compared to a normal sample and the difference in assessment of ChatGPT 
      between 2 pediatricians. METHODS: We compared ChatGPT's responses to 8 items 
      related to clinical symptoms commonly encountered by pediatricians. Two 
      pediatricians independently assessed the answers provided by ChatGPT in an 
      open-ended format. The scoring system ranged from 0 to 100, which was then 
      transformed into 5 ordinal categories. We simulated 300 virtual students with a 
      normal distribution to provide scores on items based on Rasch rating scale model 
      and their difficulties in a range between -2 to 2.5 logits. Two visual 
      presentations (Wright map and KIDMAP) were generated to answer the 2 research 
      questions outlined in the objectives of the study. RESULTS: The 2 pediatricians' 
      assessments indicated that ChatGPT's overall performance corresponded to a grade 
      of C in a range from A to E, with average scores of -0.89 logits and 0.90 logits 
      (=log odds), respectively. The assessments revealed a significant difference in 
      performance between the 2 pediatricians (P &lt; .05), with scores of -0.89 (SE = 
      0.37) and 0.90 (SE = 0.41) in log odds units (logits in Rasch analysis). 
      CONCLUSION: This study demonstrates the feasibility of utilizing ChatGPT as a CDS 
      tool for patients presenting with common pediatric symptoms. The findings suggest 
      that ChatGPT has the potential to enhance clinical workflow and aid in 
      responsible clinical decision-making. Further exploration and refinement of 
      ChatGPT's capabilities in pediatric care can potentially contribute to improved 
      healthcare outcomes and patient management.
CI  - Copyright © 2023 the Author(s). Published by Wolters Kluwer Health, Inc.
FAU - Kao, Hsu-Ju
AU  - Kao HJ
AD  - Department of Internal Medicine, Chi Mei Medical Center, Chiali, Taiwan.
FAU - Chien, Tsair-Wei
AU  - Chien TW
AD  - Department of Medical Research, Chi-Mei Medical Center, Tainan, Taiwan.
FAU - Wang, Wen-Chung
AU  - Wang WC
AD  - The Education University of Hong Kong, Hong Kong, China.
FAU - Chou, Willy
AU  - Chou W
AUID- ORCID: 0000-0002-1132-9341
AD  - Department of Physical Medicine and Rehabilitation, Chi Mei Medical Center, 
      Tainan, Taiwan.
AD  - Department of Physical Medicine and Rehabilitation, Chung San Medical University 
      Hospital, Taichung, Taiwan.
FAU - Chow, Julie Chi
AU  - Chow JC
AUID- ORCID: 0000-0003-3150-4917
AD  - Department of Pediatrics, Chi Mei Medical Center, Tainan, Taiwan.
AD  - Department of Pediatrics, School of Medicine, College of Medicine, Taipei Medical 
      University, Taipei, Taiwan.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Medicine (Baltimore)
JT  - Medicine
JID - 2985248R
SB  - IM
MH  - Humans
MH  - Child
MH  - *Decision Support Systems, Clinical
MH  - Pediatricians
MH  - Delivery of Health Care
MH  - Software
MH  - *Pediatrics
PMC - PMC10289633
COIS- The authors have no funding and conflicts of interest to disclose.
EDAT- 2023/06/23 19:11
MHDA- 2023/06/26 06:42
PMCR- 2023/06/23
CRDT- 2023/06/23 12:33
PHST- 2023/06/26 06:42 [medline]
PHST- 2023/06/23 19:11 [pubmed]
PHST- 2023/06/23 12:33 [entrez]
PHST- 2023/06/23 00:00 [pmc-release]
AID - 00005792-202306230-00035 [pii]
AID - 10.1097/MD.0000000000034068 [doi]
PST - ppublish
SO  - Medicine (Baltimore). 2023 Jun 23;102(25):e34068. doi: 
      10.1097/MD.0000000000034068.

PMID- 38021609
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231201
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 10
DP  - 2023 Oct
TI  - A Novel Approach: Evaluating ChatGPT's Utility for the Management of Thyroid 
      Nodules.
PG  - e47576
LID - 10.7759/cureus.47576 [doi]
LID - e47576
AB  - Background and objective Artificial intelligence (AI) applications such as Chat 
      Generative Pre-Trained Transformer (ChatGPT)&nbsp;created by OpenAI, which represent 
      the revolutionary aspects of today's technology, have benefitted&nbsp;professionals in 
      many fields and society at large. In this study, we aimed to assess how effective 
      is ChatGPT in helping both the patient and the physician manage thyroid nodules, 
      a very common pathology. Methods Fifty-five questions frequently asked by 
      patients were identified and asked to ChatGPT. Subsequently, three cases of 
      thyroid nodules were progressively presented to ChatGPT. The answers to patient 
      questions&nbsp;were scored for correctness and reliability by two endocrinologists. As 
      for the cases, diagnostic and therapeutic approaches provided by ChatGPT were 
      analyzed and scored by two endocrinologists for correctness, safety, and 
      usability. The responses were evaluated by using&nbsp;7-point Likert-type scales 
      designed by us. Results The answers&nbsp;to&nbsp;patient questions were found to be mostly 
      correct and reliable by both raters (Rater #1: 6.47 ± 0.50 and 6.27 ± 0.52; Rater 
      #2: 6.18 ± 0.92 and 6.09 ± 0.96). Regarding the management of cases, ChatGPT's 
      approach was found to be largely correct, safe, and usable by Rater #1, while 
      Rater #2 evaluated the approaches as partially or mostly correct, safe, and 
      usable. Conclusion Based on our findings, ChatGPT can be used as an informative 
      and reliable resource for managing patients with thyroid nodules. While it is not 
      suitable to be used as a primary resource for physicians, it has the potential to 
      be a helpful and supportive tool.
CI  - Copyright © 2023, Köroğlu et al.
FAU - Köroğlu, Ekin Y
AU  - Köroğlu EY
AD  - Endocrinology and Metabolism, Ankara City Hospital, Ankara, TUR.
FAU - Fakı, Sevgül
AU  - Fakı S
AD  - Endocrinology and Metabolism, Ankara City Hospital, Ankara, TUR.
FAU - Beştepe, Nagihan
AU  - Beştepe N
AD  - Endocrinology and Metabolism, Ankara City Hospital, Ankara, TUR.
FAU - Tam, Abbas A
AU  - Tam AA
AD  - Endocrinology and Metabolism, Ankara Yıldırım Beyazıt University School of 
      Medicine, Ankara, TUR.
FAU - Çuhacı Seyrek, Neslihan
AU  - Çuhacı Seyrek N
AD  - Endocrinology and Metabolism, Ankara Yıldırım Beyazıt University School of 
      Medicine, Ankara, TUR.
FAU - Topaloglu, Oya
AU  - Topaloglu O
AD  - Endocrinology and Metabolism, Ankara Yıldırım Beyazıt University School of 
      Medicine, Ankara, TUR.
FAU - Ersoy, Reyhan
AU  - Ersoy R
AD  - Endocrinology and Metabolism, Ankara Yıldırım Beyazıt University School of 
      Medicine, Ankara, TUR.
FAU - Cakir, Bekir
AU  - Cakir B
AD  - Endocrinology and Metabolism, Ankara Yıldırım Beyazıt University School of 
      Medicine, Ankara, TUR.
LA  - eng
PT  - Journal Article
DEP - 20231024
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10666652
OTO - NOTNLM
OT  - artificial intelligence
OT  - chatgpt
OT  - thyroid
OT  - thyroid cancer
OT  - thyroid nodule
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/11/29 18:42
MHDA- 2023/11/29 18:43
PMCR- 2023/10/24
CRDT- 2023/11/29 15:09
PHST- 2023/10/24 00:00 [accepted]
PHST- 2023/11/29 18:43 [medline]
PHST- 2023/11/29 18:42 [pubmed]
PHST- 2023/11/29 15:09 [entrez]
PHST- 2023/10/24 00:00 [pmc-release]
AID - 10.7759/cureus.47576 [doi]
PST - epublish
SO  - Cureus. 2023 Oct 24;15(10):e47576. doi: 10.7759/cureus.47576. eCollection 2023 
      Oct.

PMID- 37839017
OWN - NLM
STAT- MEDLINE
DCOM- 20240226
LR  - 20240227
IS  - 1466-187X (Electronic)
IS  - 0142-159X (Linking)
VI  - 46
IP  - 3
DP  - 2024 Mar
TI  - ChatGPT-4: An assessment of an upgraded artificial intelligence chatbot in the 
      United States Medical Licensing Examination.
PG  - 366-372
LID - 10.1080/0142159X.2023.2249588 [doi]
AB  - PURPOSE: ChatGPT-4 is an upgraded version of an artificial intelligence chatbot. 
      The performance of ChatGPT-4 on the United States Medical Licensing Examination 
      (USMLE) has not been independently characterized. We aimed to assess the 
      performance of ChatGPT-4 at responding to USMLE Step 1, Step 2CK, and Step 3 
      practice questions. METHOD: Practice multiple-choice questions for the USMLE Step 
      1, Step 2CK, and Step 3 were compiled. Of 376 available questions, 319 (85%) were 
      analyzed by ChatGPT-4 on March 21(st), 2023. Our primary outcome was the 
      performance of ChatGPT-4 for the practice USMLE Step 1, Step 2CK, and Step 3 
      examinations, measured as the proportion of multiple-choice questions answered 
      correctly. Our secondary outcomes were the mean length of questions and responses 
      provided by ChatGPT-4. RESULTS: ChatGPT-4 responded to 319 text-based 
      multiple-choice questions from USMLE practice test material. ChatGPT-4 answered 
      82 of 93 (88%) questions correctly on USMLE Step 1, 91 of 106 (86%) on Step 2CK, 
      and 108 of 120 (90%) on Step 3. ChatGPT-4 provided explanations for all 
      questions. ChatGPT-4 spent 30.8 ± 11.8 s on average responding to practice 
      questions for USMLE Step 1, 23.0 ± 9.4 s per question for Step 2CK, and 
      23.1 ± 8.3 s per question for Step 3. The mean length of practice USMLE 
      multiple-choice questions that were answered correctly and incorrectly by 
      ChatGPT-4 was similar (difference = 17.48 characters, SE = 59.75, 
      95%CI = [-100.09,135.04], t = 0.29, p = 0.77). The mean length of ChatGPT-4's 
      correct responses to practice questions was significantly shorter than the mean 
      length of incorrect responses (difference = 79.58 characters, SE = 35.42, 
      95%CI = [9.89,149.28], t = 2.25, p = 0.03). CONCLUSIONS: ChatGPT-4 answered a 
      remarkably high proportion of practice questions correctly for USMLE 
      examinations. ChatGPT-4 performed substantially better at USMLE practice 
      questions than previous models of the same AI chatbot.
FAU - Mihalache, Andrew
AU  - Mihalache A
AD  - Temerty Faculty of Medicine, University of Toronto, Toronto, Ontario, Canada.
FAU - Huang, Ryan S
AU  - Huang RS
AD  - Temerty Faculty of Medicine, University of Toronto, Toronto, Ontario, Canada.
FAU - Popovic, Marko M
AU  - Popovic MM
AD  - Department of Ophthalmology and Vision Sciences, University of Toronto, Toronto, 
      Ontario, Canada.
FAU - Muni, Rajeev H
AU  - Muni RH
AD  - Department of Ophthalmology and Vision Sciences, University of Toronto, Toronto, 
      Ontario, Canada.
AD  - Department of Ophthalmology, St. Michael's Hospital/Unity Health Toronto, 
      Toronto, Ontario, Canada.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20231015
PL  - England
TA  - Med Teach
JT  - Medical teacher
JID - 7909593
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Software
MH  - Licensure
MH  - Physical Examination
OTO - NOTNLM
OT  - United States medical licensing examination
OT  - artificial intelligence
OT  - chatgpt-4
OT  - natural language processing
EDAT- 2023/10/15 18:41
MHDA- 2024/02/26 06:45
CRDT- 2023/10/15 15:10
PHST- 2024/02/26 06:45 [medline]
PHST- 2023/10/15 18:41 [pubmed]
PHST- 2023/10/15 15:10 [entrez]
AID - 10.1080/0142159X.2023.2249588 [doi]
PST - ppublish
SO  - Med Teach. 2024 Mar;46(3):366-372. doi: 10.1080/0142159X.2023.2249588. Epub 2023 
      Oct 15.

PMID- 37862566
OWN - NLM
STAT- Publisher
LR  - 20231020
IS  - 1466-187X (Electronic)
IS  - 0142-159X (Linking)
DP  - 2023 Oct 20
TI  - An explorative assessment of ChatGPT as an aid in medical education: Use it with 
      caution.
PG  - 1-8
LID - 10.1080/0142159X.2023.2271159 [doi]
AB  - OBJECTIVE: To explore the use of ChatGPT by educators and students in a medical 
      school setting. METHOD: This study used the public version of ChatGPT launched by 
      OpenAI on November 30, 2022 (https://openai.com/blog/chatgpt/). We employed 
      prompts to ask ChatGPT to 1) generate a content outline for a session on the 
      topics of cholesterol, lipoproteins, and hyperlipidemia for medical students; 2) 
      produce a list of learning objectives for the session; and 3) write assessment 
      questions with and without clinical vignettes related to the identified learning 
      objectives. We assessed the responses by ChatGPT for accuracy and reliability to 
      determine the potential of the chatbot as an aid to educators and as a 
      "know-it-all" medical information provider for students. RESULTS: ChatGPT can 
      function as an aid to educators, but it is not yet suitable as a reliable 
      information resource for educators and medical students. CONCLUSION: ChatGPT can 
      be a useful tool to assist medical educators in drafting course and session 
      content outlines and create assessment questions. At the same time, caution must 
      be taken as ChatGPT is prone to providing incorrect information; expert oversight 
      and caution are necessary to ensure the information generated is accurate and 
      beneficial to students. Therefore, it is premature for medical students to use 
      the current version of ChatGPT as a "know-it-all" information provider. In the 
      future, medical educators should work with programming experts to explore and 
      grow the full potential of AI in medical education.
FAU - Han, Zhiyong
AU  - Han Z
AD  - Department of Medical Sciences, Hackensack Meridian School of Medicine, Nutley, 
      NJ, USA.
FAU - Battaglia, Fortunato
AU  - Battaglia F
AD  - Department of Medical Sciences, Hackensack Meridian School of Medicine, Nutley, 
      NJ, USA.
FAU - Udaiyar, Abinav
AU  - Udaiyar A
AD  - Department of Medical Sciences, Hackensack Meridian School of Medicine, Nutley, 
      NJ, USA.
FAU - Fooks, Allen
AU  - Fooks A
AD  - Department of Medical Sciences, Hackensack Meridian School of Medicine, Nutley, 
      NJ, USA.
FAU - Terlecky, Stanley R
AU  - Terlecky SR
AD  - Department of Medical Sciences, Hackensack Meridian School of Medicine, Nutley, 
      NJ, USA.
LA  - eng
PT  - Journal Article
DEP - 20231020
PL  - England
TA  - Med Teach
JT  - Medical teacher
JID - 7909593
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - Medical education
EDAT- 2023/10/20 18:45
MHDA- 2023/10/20 18:45
CRDT- 2023/10/20 14:52
PHST- 2023/10/20 18:45 [medline]
PHST- 2023/10/20 18:45 [pubmed]
PHST- 2023/10/20 14:52 [entrez]
AID - 10.1080/0142159X.2023.2271159 [doi]
PST - aheadofprint
SO  - Med Teach. 2023 Oct 20:1-8. doi: 10.1080/0142159X.2023.2271159.

PMID- 38534904
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240329
IS  - 2254-9625 (Electronic)
IS  - 2174-8144 (Print)
IS  - 2174-8144 (Linking)
VI  - 14
IP  - 3
DP  - 2024 Mar 8
TI  - ChatGPT's Response Consistency: A Study on Repeated Queries of Medical 
      Examination Questions.
PG  - 657-668
LID - 10.3390/ejihpe14030043 [doi]
AB  - (1) Background: As the field of artificial intelligence (AI) evolves, tools like 
      ChatGPT are increasingly integrated into various domains of medicine, including 
      medical education and research. Given the critical nature of medicine, it is of 
      paramount importance that AI tools offer a high degree of reliability in the 
      information they provide. (2) Methods: A total of n = 450 medical examination 
      questions were manually entered into ChatGPT thrice, each for ChatGPT 3.5 and 
      ChatGPT 4. The responses were collected, and their accuracy and consistency were 
      statistically analyzed throughout the series of entries. (3) Results: ChatGPT 4 
      displayed a statistically significantly improved accuracy with 85.7% compared to 
      that of 57.7% of ChatGPT 3.5 (p &lt; 0.001). Furthermore, ChatGPT 4 was more 
      consistent, correctly answering 77.8% across all rounds, a significant increase 
      from the 44.9% observed from ChatGPT 3.5 (p &lt; 0.001). (4) Conclusions: The 
      findings underscore the increased accuracy and dependability of ChatGPT 4 in the 
      context of medical education and potential clinical decision making. Nonetheless, 
      the research emphasizes the indispensable nature of human-delivered healthcare 
      and the vital role of continuous assessment in leveraging AI in medicine.
FAU - Funk, Paul F
AU  - Funk PF
AUID- ORCID: 0009-0000-4316-4249
AD  - Department of Otorhinolaryngology, Head and Neck Surgery, University Hospital 
      Jena, Friedrich Schiller University Jena, Am Klinikum 1, 07747 Jena, Germany.
FAU - Hoch, Cosima C
AU  - Hoch CC
AUID- ORCID: 0000-0002-3875-7389
AD  - Department of Otolaryngology, Head and Neck Surgery, School of Medicine and 
      Health, Technical University of Munich (TUM), Ismaningerstrasse 22, 81675 Munich, 
      Germany.
FAU - Knoedler, Samuel
AU  - Knoedler S
AD  - Department of Plastic Surgery and Hand Surgery, Klinikum Rechts der Isar, 
      Technical University of Munich (TUM), Ismaningerstrasse 22, 81675 Munich, 
      Germany.
FAU - Knoedler, Leonard
AU  - Knoedler L
AD  - Division of Plastic and Reconstructive Surgery, Massachusetts General Hospital, 
      Harvard Medical School, 55 Fruit Street, Boston, MA 02114, USA.
FAU - Cotofana, Sebastian
AU  - Cotofana S
AD  - Department of Dermatology, Erasmus Medical Centre, Dr. Molewaterplein 40, 3015 GD 
      Rotterdam, The Netherlands.
AD  - Centre for Cutaneous Research, Blizard Institute, Queen Mary University of 
      London, Mile End Road, London E1 4NS, UK.
AD  - Department of Plastic and Reconstructive Surgery, Guangdong Second Provincial 
      General Hospital, Guangzhou 510317, China.
FAU - Sofo, Giuseppe
AU  - Sofo G
AD  - Instituto Ivo Pitanguy, Hospital Santa Casa de Misericórdia Rio de Janeiro, 
      Pontifícia Universidade Católica do Rio de Janeiro, Rio de Janeiro 20020-022, 
      Brazil.
FAU - Bashiri Dezfouli, Ali
AU  - Bashiri Dezfouli A
AD  - Department of Otolaryngology, Head and Neck Surgery, School of Medicine and 
      Health, Technical University of Munich (TUM), Ismaningerstrasse 22, 81675 Munich, 
      Germany.
FAU - Wollenberg, Barbara
AU  - Wollenberg B
AUID- ORCID: 0000-0002-3062-459X
AD  - Department of Otolaryngology, Head and Neck Surgery, School of Medicine and 
      Health, Technical University of Munich (TUM), Ismaningerstrasse 22, 81675 Munich, 
      Germany.
FAU - Guntinas-Lichius, Orlando
AU  - Guntinas-Lichius O
AUID- ORCID: 0000-0001-9671-0784
AD  - Department of Otorhinolaryngology, Head and Neck Surgery, University Hospital 
      Jena, Friedrich Schiller University Jena, Am Klinikum 1, 07747 Jena, Germany.
FAU - Alfertshofer, Michael
AU  - Alfertshofer M
AD  - Department of Plastic Surgery and Hand Surgery, Klinikum Rechts der Isar, 
      Technical University of Munich (TUM), Ismaningerstrasse 22, 81675 Munich, 
      Germany.
AD  - Department of Oromaxillofacial Surgery, Ludwig-Maximilians University Munich, 
      Lindwurmstraße 2A, 80337 Munich, Germany.
LA  - eng
PT  - Journal Article
DEP - 20240308
PL  - Switzerland
TA  - Eur J Investig Health Psychol Educ
JT  - European journal of investigation in health, psychology and education
JID - 101751466
PMC - PMC10969490
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - indecisiveness
OT  - medical state examination questions
OT  - response consistency
COIS- The authors declare no conflicts of interest.
EDAT- 2024/03/27 12:49
MHDA- 2024/03/27 12:50
PMCR- 2024/03/08
CRDT- 2024/03/27 09:28
PHST- 2024/02/12 00:00 [received]
PHST- 2024/03/05 00:00 [revised]
PHST- 2024/03/07 00:00 [accepted]
PHST- 2024/03/27 12:50 [medline]
PHST- 2024/03/27 12:49 [pubmed]
PHST- 2024/03/27 09:28 [entrez]
PHST- 2024/03/08 00:00 [pmc-release]
AID - ejihpe14030043 [pii]
AID - ejihpe-14-00043 [pii]
AID - 10.3390/ejihpe14030043 [doi]
PST - epublish
SO  - Eur J Investig Health Psychol Educ. 2024 Mar 8;14(3):657-668. doi: 
      10.3390/ejihpe14030043.

PMID- 37195756
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230603
IS  - 2292-9495 (Electronic)
IS  - 2292-9495 (Linking)
VI  - 10
DP  - 2023 May 17
TI  - User Intentions to Use ChatGPT for Self-Diagnosis and Health-Related Purposes: 
      Cross-sectional Survey Study.
PG  - e47564
LID - 10.2196/47564 [doi]
LID - e47564
AB  - BACKGROUND: With the rapid advancement of artificial intelligence (AI) 
      technologies, AI-powered chatbots, such as Chat Generative Pretrained Transformer 
      (ChatGPT), have emerged as potential tools for various applications, including 
      health care. However, ChatGPT is not specifically designed for health care 
      purposes, and its use for self-diagnosis raises concerns regarding its adoption's 
      potential risks and benefits. Users are increasingly inclined to use ChatGPT for 
      self-diagnosis, necessitating a deeper understanding of the factors driving this 
      trend. OBJECTIVE: This study aims to investigate the factors influencing users' 
      perception of decision-making processes and intentions to use ChatGPT for 
      self-diagnosis and to explore the implications of these findings for the safe and 
      effective integration of AI chatbots in health care. METHODS: A cross-sectional 
      survey design was used, and data were collected from 607 participants. The 
      relationships between performance expectancy, risk-reward appraisal, 
      decision-making, and intention to use ChatGPT for self-diagnosis were analyzed 
      using partial least squares structural equation modeling (PLS-SEM). RESULTS: Most 
      respondents were willing to use ChatGPT for self-diagnosis (n=476, 78.4%). The 
      model demonstrated satisfactory explanatory power, accounting for 52.4% of the 
      variance in decision-making and 38.1% in the intent to use ChatGPT for 
      self-diagnosis. The results supported all 3 hypotheses: The higher performance 
      expectancy of ChatGPT (β=.547, 95% CI 0.474-0.620) and positive risk-reward 
      appraisals (β=.245, 95% CI 0.161-0.325) were positively associated with the 
      improved perception of decision-making outcomes among users, and enhanced 
      perception of decision-making processes involving ChatGPT positively impacted 
      users' intentions to use the technology for self-diagnosis (β=.565, 95% CI 
      0.498-0.628). CONCLUSIONS: Our research investigated factors influencing users' 
      intentions to use ChatGPT for self-diagnosis and health-related purposes. Even 
      though the technology is not specifically designed for health care, people are 
      inclined to use ChatGPT in health care contexts. Instead of solely focusing on 
      discouraging its use for health care purposes, we advocate for improving the 
      technology and adapting it for suitable health care applications. Our study 
      highlights the importance of collaboration among AI developers, health care 
      providers, and policy makers in ensuring AI chatbots' safe and responsible use in 
      health care. By understanding users' expectations and decision-making processes, 
      we can develop AI chatbots, such as ChatGPT, that are tailored to human needs, 
      providing reliable and verified health information sources. This approach not 
      only enhances health care accessibility but also improves health literacy and 
      awareness. As the field of AI chatbots in health care continues to evolve, future 
      research should explore the long-term effects of using AI chatbots for 
      self-diagnosis and investigate their potential integration with other digital 
      health interventions to optimize patient care and outcomes. In doing so, we can 
      ensure that AI chatbots, including ChatGPT, are designed and implemented to 
      safeguard users' well-being and support positive health outcomes in health care 
      settings.
CI  - ©Yeganeh Shahsavar, Avishek Choudhury. Originally published in JMIR Human Factors 
      (https://humanfactors.jmir.org), 17.05.2023.
FAU - Shahsavar, Yeganeh
AU  - Shahsavar Y
AUID- ORCID: 0000-0003-3422-7257
AD  - Industrial and Management Systems Engineering, Benjamin M Statler College of 
      Engineering and Mineral Resources, West Virginia University, Morgantown, WV, 
      United States.
FAU - Choudhury, Avishek
AU  - Choudhury A
AUID- ORCID: 0000-0002-5342-0709
AD  - Industrial and Management Systems Engineering, Benjamin M Statler College of 
      Engineering and Mineral Resources, West Virginia University, Morgantown, WV, 
      United States.
LA  - eng
PT  - Journal Article
DEP - 20230517
PL  - Canada
TA  - JMIR Hum Factors
JT  - JMIR human factors
JID - 101666561
PMC - PMC10233444
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - behavioral intention
OT  - chatbots
OT  - decision-making
OT  - health care
OT  - human factors
OT  - integrated diagnostics
OT  - integration
OT  - policy
OT  - self-diagnosis
OT  - use
OT  - users
OT  - willingness
COIS- Conflicts of Interest: None declared.
EDAT- 2023/05/17 13:09
MHDA- 2023/05/17 13:10
PMCR- 2023/05/17
CRDT- 2023/05/17 11:54
PHST- 2023/03/24 00:00 [received]
PHST- 2023/05/09 00:00 [accepted]
PHST- 2023/04/24 00:00 [revised]
PHST- 2023/05/17 13:10 [medline]
PHST- 2023/05/17 13:09 [pubmed]
PHST- 2023/05/17 11:54 [entrez]
PHST- 2023/05/17 00:00 [pmc-release]
AID - v10i1e47564 [pii]
AID - 10.2196/47564 [doi]
PST - epublish
SO  - JMIR Hum Factors. 2023 May 17;10:e47564. doi: 10.2196/47564.

PMID- 37790756
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231005
IS  - 2234-943X (Print)
IS  - 2234-943X (Electronic)
IS  - 2234-943X (Linking)
VI  - 13
DP  - 2023
TI  - Benchmarking ChatGPT-4 on a radiation oncology in-training exam and Red Journal 
      Gray Zone cases: potentials and challenges for ai-assisted medical education and 
      decision making in radiation oncology.
PG  - 1265024
LID - 10.3389/fonc.2023.1265024 [doi]
LID - 1265024
AB  - PURPOSE: The potential of large language models in medicine for education and 
      decision-making purposes has been demonstrated as they have achieved decent 
      scores on medical exams such as the United States Medical Licensing Exam (USMLE) 
      and the MedQA exam. This work aims to evaluate the performance of ChatGPT-4 in 
      the specialized field of radiation oncology. METHODS: The 38th American College 
      of Radiology (ACR) radiation oncology in-training (TXIT) exam and the 2022 Red 
      Journal Gray Zone cases are used to benchmark the performance of ChatGPT-4. The 
      TXIT exam contains 300 questions covering various topics of radiation oncology. 
      The 2022 Gray Zone collection contains 15 complex clinical cases. RESULTS: For 
      the TXIT exam, ChatGPT-3.5 and ChatGPT-4 have achieved the scores of 62.05% and 
      78.77%, respectively, highlighting the advantage of the latest ChatGPT-4 model. 
      Based on the TXIT exam, ChatGPT-4's strong and weak areas in radiation oncology 
      are identified to some extent. Specifically, ChatGPT-4 demonstrates better 
      knowledge of statistics, CNS &amp; eye, pediatrics, biology, and physics than 
      knowledge of bone &amp; soft tissue and gynecology, as per the ACR knowledge domain. 
      Regarding clinical care paths, ChatGPT-4 performs better in diagnosis, prognosis, 
      and toxicity than brachytherapy and dosimetry. It lacks proficiency in in-depth 
      details of clinical trials. For the Gray Zone cases, ChatGPT-4 is able to suggest 
      a personalized treatment approach to each case with high correctness and 
      comprehensiveness. Importantly, it provides novel treatment aspects for many 
      cases, which are not suggested by any human experts. CONCLUSION: Both evaluations 
      demonstrate the potential of ChatGPT-4 in medical education for the general 
      public and cancer patients, as well as the potential to aid clinical 
      decision-making, while acknowledging its limitations in certain domains. Owing to 
      the risk of hallucinations, it is essential to verify the content generated by 
      models such as ChatGPT for accuracy.
CI  - Copyright © 2023 Huang, Gomaa, Semrau, Haderlein, Lettmaier, Weissmann, Grigo, 
      Tkhayat, Frey, Gaipl, Distel, Maier, Fietkau, Bert and Putz.
FAU - Huang, Yixing
AU  - Huang Y
AD  - Department of Radiation Oncology, University Hospital Erlangen, 
      Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany.
AD  - Comprehensive Cancer Center Erlangen-EMN (CCC ER-EMN), Erlangen, Germany.
FAU - Gomaa, Ahmed
AU  - Gomaa A
AD  - Department of Radiation Oncology, University Hospital Erlangen, 
      Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany.
AD  - Comprehensive Cancer Center Erlangen-EMN (CCC ER-EMN), Erlangen, Germany.
FAU - Semrau, Sabine
AU  - Semrau S
AD  - Department of Radiation Oncology, University Hospital Erlangen, 
      Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany.
AD  - Comprehensive Cancer Center Erlangen-EMN (CCC ER-EMN), Erlangen, Germany.
FAU - Haderlein, Marlen
AU  - Haderlein M
AD  - Department of Radiation Oncology, University Hospital Erlangen, 
      Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany.
AD  - Comprehensive Cancer Center Erlangen-EMN (CCC ER-EMN), Erlangen, Germany.
FAU - Lettmaier, Sebastian
AU  - Lettmaier S
AD  - Department of Radiation Oncology, University Hospital Erlangen, 
      Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany.
AD  - Comprehensive Cancer Center Erlangen-EMN (CCC ER-EMN), Erlangen, Germany.
FAU - Weissmann, Thomas
AU  - Weissmann T
AD  - Department of Radiation Oncology, University Hospital Erlangen, 
      Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany.
AD  - Comprehensive Cancer Center Erlangen-EMN (CCC ER-EMN), Erlangen, Germany.
FAU - Grigo, Johanna
AU  - Grigo J
AD  - Department of Radiation Oncology, University Hospital Erlangen, 
      Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany.
AD  - Comprehensive Cancer Center Erlangen-EMN (CCC ER-EMN), Erlangen, Germany.
FAU - Tkhayat, Hassen Ben
AU  - Tkhayat HB
AD  - Department of Radiation Oncology, University Hospital Erlangen, 
      Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany.
AD  - Pattern Recognition Lab, Friedrich-Alexander-Universität Erlangen-Nürnberg, 
      Erlangen, Germany.
FAU - Frey, Benjamin
AU  - Frey B
AD  - Department of Radiation Oncology, University Hospital Erlangen, 
      Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany.
AD  - Comprehensive Cancer Center Erlangen-EMN (CCC ER-EMN), Erlangen, Germany.
FAU - Gaipl, Udo
AU  - Gaipl U
AD  - Department of Radiation Oncology, University Hospital Erlangen, 
      Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany.
AD  - Comprehensive Cancer Center Erlangen-EMN (CCC ER-EMN), Erlangen, Germany.
FAU - Distel, Luitpold
AU  - Distel L
AD  - Department of Radiation Oncology, University Hospital Erlangen, 
      Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany.
AD  - Comprehensive Cancer Center Erlangen-EMN (CCC ER-EMN), Erlangen, Germany.
FAU - Maier, Andreas
AU  - Maier A
AD  - Pattern Recognition Lab, Friedrich-Alexander-Universität Erlangen-Nürnberg, 
      Erlangen, Germany.
FAU - Fietkau, Rainer
AU  - Fietkau R
AD  - Department of Radiation Oncology, University Hospital Erlangen, 
      Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany.
AD  - Comprehensive Cancer Center Erlangen-EMN (CCC ER-EMN), Erlangen, Germany.
FAU - Bert, Christoph
AU  - Bert C
AD  - Department of Radiation Oncology, University Hospital Erlangen, 
      Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany.
AD  - Comprehensive Cancer Center Erlangen-EMN (CCC ER-EMN), Erlangen, Germany.
FAU - Putz, Florian
AU  - Putz F
AD  - Department of Radiation Oncology, University Hospital Erlangen, 
      Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany.
AD  - Comprehensive Cancer Center Erlangen-EMN (CCC ER-EMN), Erlangen, Germany.
LA  - eng
PT  - Journal Article
DEP - 20230914
PL  - Switzerland
TA  - Front Oncol
JT  - Frontiers in oncology
JID - 101568867
PMC - PMC10543650
OTO - NOTNLM
OT  - Gray Zone
OT  - artificial intelligence
OT  - clinical decision support (CDS)
OT  - large language model
OT  - natural language processing
OT  - radiotherapy
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/10/04 06:43
MHDA- 2023/10/04 06:44
PMCR- 2023/01/01
CRDT- 2023/10/04 04:10
PHST- 2023/07/21 00:00 [received]
PHST- 2023/08/23 00:00 [accepted]
PHST- 2023/10/04 06:44 [medline]
PHST- 2023/10/04 06:43 [pubmed]
PHST- 2023/10/04 04:10 [entrez]
PHST- 2023/01/01 00:00 [pmc-release]
AID - 10.3389/fonc.2023.1265024 [doi]
PST - epublish
SO  - Front Oncol. 2023 Sep 14;13:1265024. doi: 10.3389/fonc.2023.1265024. eCollection 
      2023.

PMID- 38162414
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240210
IS  - 2374-2895 (Print)
IS  - 2374-2895 (Electronic)
IS  - 2374-2895 (Linking)
VI  - 11
IP  - 1
DP  - 2024 Jan-Mar
TI  - ChatGPT 3.5 fails to write appropriate multiple choice practice exam questions.
PG  - 100099
LID - 10.1016/j.acpath.2023.100099 [doi]
LID - 100099
AB  - Artificial intelligence (AI) may have a profound impact on traditional teaching 
      in academic settings. Multiple concerns have been raised, especially related to 
      using ChatGPT for creating de novo essays. However, AI programs such as ChatGPT 
      may augment teaching techniques. In this article, we used ChatGPT 3.5 to create 
      60 multiple choice questions. Author written text was uploaded and ChatGPT asked 
      to create multiple choice questions with an explanation for the correct answer 
      and explanations for the incorrect answers. Unfortunately, ChatGPT only generated 
      correct questions and answers with explanations in 32&nbsp;% of the questions (19 out 
      of 60). In many instances, ChatGPT failed to provide an explanation for the 
      incorrect answers. An additional 25&nbsp;% of the questions had answers that were 
      either wrong or misleading. A grade of 32&nbsp;% would be considered failing in most 
      courses. Despite these issues, instructors may still find ChatGPT useful for 
      creating practice exams with explanations-with the caveat that extensive editing 
      may be required.
CI  - © 2023 The Authors.
FAU - Ngo, Alexander
AU  - Ngo A
AD  - Department of Pathology &amp; Laboratory Medicine, Boston University Chobanian and 
      Avidesian School of Medicine, Boston MA, USA.
FAU - Gupta, Saumya
AU  - Gupta S
AD  - Department of Pathology &amp; Laboratory Medicine, Boston University Chobanian and 
      Avidesian School of Medicine, Boston MA, USA.
FAU - Perrine, Oliver
AU  - Perrine O
AD  - Department of Pathology &amp; Laboratory Medicine, Boston University Chobanian and 
      Avidesian School of Medicine, Boston MA, USA.
FAU - Reddy, Rithik
AU  - Reddy R
AD  - Department of Pathology &amp; Laboratory Medicine, Boston University Chobanian and 
      Avidesian School of Medicine, Boston MA, USA.
FAU - Ershadi, Sherry
AU  - Ershadi S
AD  - Department of Pathology &amp; Laboratory Medicine, Boston University Chobanian and 
      Avidesian School of Medicine, Boston MA, USA.
FAU - Remick, Daniel
AU  - Remick D
AD  - Department of Pathology &amp; Laboratory Medicine, Boston University Chobanian and 
      Avidesian School of Medicine, Boston MA, USA.
LA  - eng
GR  - R01 GM098308/GM/NIGMS NIH HHS/United States
GR  - R21 AI147168/AI/NIAID NIH HHS/United States
PT  - Journal Article
DEP - 20231219
PL  - United States
TA  - Acad Pathol
JT  - Academic pathology
JID - 101698648
PMC - PMC10753050
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Education
OT  - Immunology
OT  - Pathology
COIS- The senior author, Daniel Remick, M.D., is a member of the Editorial Board for 
      Academic Pathology. No other conflicts of interest exist.
EDAT- 2024/01/02 11:41
MHDA- 2024/01/02 11:42
PMCR- 2023/12/19
CRDT- 2024/01/01 04:20
PHST- 2023/07/06 00:00 [received]
PHST- 2023/09/05 00:00 [revised]
PHST- 2023/10/29 00:00 [accepted]
PHST- 2024/01/02 11:42 [medline]
PHST- 2024/01/02 11:41 [pubmed]
PHST- 2024/01/01 04:20 [entrez]
PHST- 2023/12/19 00:00 [pmc-release]
AID - S2374-2895(23)00031-3 [pii]
AID - 100099 [pii]
AID - 10.1016/j.acpath.2023.100099 [doi]
PST - epublish
SO  - Acad Pathol. 2023 Dec 19;11(1):100099. doi: 10.1016/j.acpath.2023.100099. 
      eCollection 2024 Jan-Mar.

PMID- 37303347
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230613
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 5
DP  - 2023 May
TI  - Exploring ChatGPT's Potential in Facilitating Adaptation of Clinical Guidelines: 
      A Case Study of Diabetic Ketoacidosis Guidelines.
PG  - e38784
LID - 10.7759/cureus.38784 [doi]
LID - e38784
AB  - Background This study aimed to evaluate the efficacy of ChatGPT, an advanced 
      natural language processing model, in adapting and synthesizing clinical 
      guidelines for diabetic ketoacidosis (DKA) by comparing and contrasting different 
      guideline sources. Methodology We employed a comprehensive comparison approach 
      and examined three reputable guideline sources: Diabetes Canada Clinical Practice 
      Guidelines Expert Committee (2018), Emergency Management of Hyperglycaemia in 
      Primary Care, and Joint British Diabetes Societies (JBDS) 02 The Management of 
      Diabetic Ketoacidosis in Adults. Data extraction focused on diagnostic criteria, 
      risk factors, signs and symptoms, investigations, and treatment recommendations. 
      We compared the synthesized guidelines generated by ChatGPT and identified any 
      misreporting or non-reporting errors. Results ChatGPT was capable of generating a 
      comprehensive table comparing the guidelines. However, multiple recurrent errors, 
      including misreporting and non-reporting errors, were identified, rendering the 
      results unreliable. Additionally, inconsistencies were observed in the repeated 
      reporting of data. The study highlights the limitations of using ChatGPT for the 
      adaptation of clinical guidelines without expert human intervention. Conclusions 
      Although ChatGPT demonstrates the potential for the synthesis of clinical 
      guidelines, the presence of multiple recurrent errors and inconsistencies 
      underscores the need for expert human intervention and validation. Future 
      research should focus on improving the accuracy and reliability of ChatGPT, as 
      well as exploring its potential applications in other areas of clinical practice 
      and guideline development.
CI  - Copyright © 2023, Hamed et al.
FAU - Hamed, Ehab
AU  - Hamed E
AD  - Qatar University Health Center, Primary Health Care Corporation, Doha, QAT.
FAU - Eid, Ahmad
AU  - Eid A
AD  - Umm Slal Health Center, Primary Health Care Corporation, Doha, QAT.
FAU - Alberry, Medhat
AU  - Alberry M
AD  - Fetal Medicine, Sidra Medicine, Doha, QAT.
LA  - eng
PT  - Journal Article
DEP - 20230509
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10249915
OTO - NOTNLM
OT  - ai chatbot
OT  - artificial intelligence
OT  - chatgpt
OT  - clinical guidelines
OT  - evidence-based medicine
OT  - evidence-based recommendations
OT  - healthcare management
OT  - healthcare technology
OT  - medical informatics
OT  - prompt design
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/06/12 06:42
MHDA- 2023/06/12 06:43
PMCR- 2023/05/09
CRDT- 2023/06/12 03:53
PHST- 2023/05/09 00:00 [accepted]
PHST- 2023/06/12 06:43 [medline]
PHST- 2023/06/12 06:42 [pubmed]
PHST- 2023/06/12 03:53 [entrez]
PHST- 2023/05/09 00:00 [pmc-release]
AID - 10.7759/cureus.38784 [doi]
PST - epublish
SO  - Cureus. 2023 May 9;15(5):e38784. doi: 10.7759/cureus.38784. eCollection 2023 May.

PMID- 36966950
OWN - NLM
STAT- MEDLINE
DCOM- 20230925
LR  - 20230926
IS  - 2468-7855 (Electronic)
IS  - 2468-7855 (Linking)
VI  - 124
IP  - 5
DP  - 2023 Oct
TI  - The role of using ChatGPT AI in writing medical scientific articles.
PG  - 101456
LID - S2468-7855(23)00078-2 [pii]
LID - 10.1016/j.jormas.2023.101456 [doi]
AB  - The use of artificial intelligence (AI) in medical research is on the rise. This 
      article explores the role of using ChatGPT, a language model developed by OpenAI, 
      in writing medical scientific articles. The material and methods used included a 
      comparative analysis of medical scientific articles produced with and without the 
      use of ChatGPT. The results suggest that the use of ChatGPT can be a useful tool 
      for scientists to increase the production of higher quality medical scientific 
      articles, but it is important to note that AI cannot fully replace human authors. 
      In conclusion, scientists should consider ChatGPT as an additional tool to 
      produce higher quality medical scientific articles more quickly.
CI  - Copyright © 2023 Elsevier Masson SAS. All rights reserved.
FAU - Benichou, L
AU  - Benichou L
AD  - Service de chirurgie maxillo-faciale et stomatologie, Groupe Hospitalier Paris 
      St-Joseph, 185 rue Raymond Losserand 75014 Paris, France. Electronic address: 
      lbenichou@ghpsj.fr.
CN  - ChatGPT
AD  - OpenAI, 3180 18th St, San Francisco, CA 94110, États-Unis.
LA  - eng
PT  - Journal Article
DEP - 20230324
PL  - France
TA  - J Stomatol Oral Maxillofac Surg
JT  - Journal of stomatology, oral and maxillofacial surgery
JID - 101701089
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Writing
MH  - Language
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Medical research
OT  - Medical scientific articles
COIS- Declaration of Competing Interest The authors declare no conflicts of interest.
EDAT- 2023/03/27 06:00
MHDA- 2023/09/25 06:42
CRDT- 2023/03/26 20:26
PHST- 2023/02/15 00:00 [received]
PHST- 2023/03/15 00:00 [revised]
PHST- 2023/03/23 00:00 [accepted]
PHST- 2023/09/25 06:42 [medline]
PHST- 2023/03/27 06:00 [pubmed]
PHST- 2023/03/26 20:26 [entrez]
AID - S2468-7855(23)00078-2 [pii]
AID - 10.1016/j.jormas.2023.101456 [doi]
PST - ppublish
SO  - J Stomatol Oral Maxillofac Surg. 2023 Oct;124(5):101456. doi: 
      10.1016/j.jormas.2023.101456. Epub 2023 Mar 24.

PMID- 38398794
OWN - NLM
STAT- MEDLINE
DCOM- 20240226
LR  - 20240227
IS  - 2072-6643 (Electronic)
IS  - 2072-6643 (Linking)
VI  - 16
IP  - 4
DP  - 2024 Feb 6
TI  - Is ChatGPT an Effective Tool for Providing Dietary Advice?
LID - 10.3390/nu16040469 [doi]
LID - 469
AB  - The chatbot Chat Generative Pretrained Transformer (ChatGPT) is becoming 
      increasingly popular among patients for searching health-related information. 
      Prior studies have raised concerns regarding accuracy in offering nutritional 
      advice. We investigated in November 2023 ChatGPT's potential as a tool for 
      providing nutritional guidance in relation to different non-communicable diseases 
      (NCDs). First, the dietary advice given by ChatGPT (version 3.5) for various NCDs 
      was compared with guidelines; then, the chatbot's capacity to manage a complex 
      case with several diseases was investigated. A panel of nutrition experts 
      assessed ChatGPT's responses. Overall, ChatGPT offered clear advice, with 
      appropriateness of responses ranging from 55.5% (sarcopenia) to 73.3% (NAFLD). 
      Only two recommendations (one for obesity, one for non-alcoholic-fatty-liver 
      disease) contradicted guidelines. A single suggestion for T2DM was found to be 
      "unsupported", while many recommendations for various NCDs were deemed to be "not 
      fully matched" to the guidelines despite not directly contradicting them. 
      However, when the chatbot handled overlapping conditions, limitations emerged, 
      resulting in some contradictory or inappropriate advice. In conclusion, although 
      ChatGPT exhibited a reasonable accuracy in providing general dietary advice for 
      NCDs, its efficacy decreased in complex situations necessitating customized 
      strategies; therefore, the chatbot is currently unable to replace a healthcare 
      professional's consultation.
FAU - Ponzo, Valentina
AU  - Ponzo V
AD  - Department of Medical Sciences, University of Torino, 10126 Torino, Italy.
FAU - Goitre, Ilaria
AU  - Goitre I
AD  - Department of Medical Sciences, University of Torino, 10126 Torino, Italy.
FAU - Favaro, Enrica
AU  - Favaro E
AD  - Department of Medical Sciences, University of Torino, 10126 Torino, Italy.
FAU - Merlo, Fabio Dario
AU  - Merlo FD
AD  - Dietetic and Clinical Nutrition Unit, Città della Salute e della Scienza Hospital 
      of Torino, 10126 Torino, Italy.
FAU - Mancino, Maria Vittoria
AU  - Mancino MV
AD  - Dietetic and Clinical Nutrition Unit, Città della Salute e della Scienza Hospital 
      of Torino, 10126 Torino, Italy.
FAU - Riso, Sergio
AU  - Riso S
AUID- ORCID: 0000-0001-8798-1224
AD  - Dietetic and Clinical Nutrition Unit, Azienda Ospedaliero-Universitaria Maggiore 
      della Carità of Novara, 28100 Novara, Italy.
FAU - Bo, Simona
AU  - Bo S
AUID- ORCID: 0000-0001-6862-8628
AD  - Department of Medical Sciences, University of Torino, 10126 Torino, Italy.
AD  - Dietetic and Clinical Nutrition Unit, Città della Salute e della Scienza Hospital 
      of Torino, 10126 Torino, Italy.
LA  - eng
PT  - Journal Article
DEP - 20240206
PL  - Switzerland
TA  - Nutrients
JT  - Nutrients
JID - 101521595
RN  - EC 2.3.1.6 (Choline O-Acetyltransferase)
SB  - IM
MH  - Humans
MH  - Health Education
MH  - Choline O-Acetyltransferase
MH  - Health Facilities
MH  - *Non-alcoholic Fatty Liver Disease
MH  - *Noncommunicable Diseases/prevention &amp; control
PMC - PMC10892804
OTO - NOTNLM
OT  - ChatGPT
OT  - dietary advice
OT  - guidelines
OT  - non-communicable diseases (NCDs)
COIS- The authors declare no conflicts of interest.
EDAT- 2024/02/24 11:43
MHDA- 2024/02/26 06:45
PMCR- 2024/02/06
CRDT- 2024/02/24 01:15
PHST- 2024/01/08 00:00 [received]
PHST- 2024/01/30 00:00 [revised]
PHST- 2024/02/03 00:00 [accepted]
PHST- 2024/02/26 06:45 [medline]
PHST- 2024/02/24 11:43 [pubmed]
PHST- 2024/02/24 01:15 [entrez]
PHST- 2024/02/06 00:00 [pmc-release]
AID - nu16040469 [pii]
AID - nutrients-16-00469 [pii]
AID - 10.3390/nu16040469 [doi]
PST - epublish
SO  - Nutrients. 2024 Feb 6;16(4):469. doi: 10.3390/nu16040469.

PMID- 37830257
OWN - NLM
STAT- Publisher
LR  - 20231013
IS  - 1898-018X (Electronic)
IS  - 1898-018X (Linking)
DP  - 2023 Oct 13
TI  - Reshaping medical education: Performance of ChatGPT on a PES medical examination.
LID - 10.5603/cj.97517 [doi]
AB  - BACKGROUND: We are currently experiencing a third digital revolution driven by 
      artificial intelligence (AI), and the emergence of new chat generative 
      pre-trained transformer (ChatGPT) represents a significant technological 
      advancement with profound implications for global society, especially in the 
      field of education. METHODS: The aim of this study was to see how well ChatGPT 
      performed on medical school exams and to highlight how it might change medical 
      education and practice. Recently, OpenAI's ChatGPT (OpenAI, San Francisco; GPT-4 
      May 24 Version) was put to the test against a significant Polish medical 
      specialization licensing exam (PES), and the results are in. The version of 
      ChatGPT-4 used in this study was the most up-to-date model at the time of 
      publication (GPT-4). ChatGPT answered questions from June 28, 2023, to June 30, 
      2023. RESULTS: ChatGPT demonstrates notable advancements in natural language 
      processing models on the tasks of medical question answering. In June 2023, the 
      performance of ChatGPT was assessed based on its ability to answer a set of 120 
      questions, where it achieved a correct response rate of 67.1%, accurately 
      responding to 80 questions. CONCLUSIONS: ChatGPT may be used as an assistance 
      tool in medical education. While ChatGPT can serve as a valuable tool in medical 
      education, it cannot fully replace human expertise and knowledge due to its 
      inherent limitations.
FAU - Wójcik, Simona
AU  - Wójcik S
AD  - LUX MED Llc, Warsaw, Poland.
FAU - Rulkiewicz, Anna
AU  - Rulkiewicz A
AD  - LUX MED Llc, Warsaw, Poland.
FAU - Pruszczyk, Piotr
AU  - Pruszczyk P
AUID- ORCID: 0000-0002-9768-0000
AD  - Department of Internal Medicine and Cardiology with The Center for Diagnosis and 
      Treatment of Thromboembolism, Medical University of Warsaw, Poland.
FAU - Lisik, Wojciech
AU  - Lisik W
AUID- ORCID: 0000-0003-3020-3979
AD  - Department of General and Transplantation Surgery, Medical University of Warsaw, 
      Poland.
FAU - Poboży, Marcin
AU  - Poboży M
AD  - Cichowski Pobozy Healthcare Facility, Maciejowice, Poland.
FAU - Domienik-Karłowicz, Justyna
AU  - Domienik-Karłowicz J
AUID- ORCID: 0000-0001-6122-9755
AD  - Department of Internal Medicine and Cardiology with The Center for Diagnosis and 
      Treatment of Thromboembolism, Medical University of Warsaw, Poland. 
      jdomienik@tlen.pl.
AD  - LUX MED Llc, Warsaw, Poland. jdomienik@tlen.pl.
LA  - eng
PT  - Journal Article
DEP - 20231013
PL  - Poland
TA  - Cardiol J
JT  - Cardiology journal
JID - 101392712
SB  - IM
OTO - NOTNLM
OT  - AI in medicine
OT  - ChatGPT
OT  - artificial intelligence
OT  - health IT
OT  - innovations
OT  - language processing
OT  - medical education
OT  - virtual teaching assistant
EDAT- 2023/10/13 06:45
MHDA- 2023/10/13 06:45
CRDT- 2023/10/13 05:31
PHST- 2023/09/20 00:00 [received]
PHST- 2023/10/03 00:00 [accepted]
PHST- 2023/10/13 06:45 [medline]
PHST- 2023/10/13 06:45 [pubmed]
PHST- 2023/10/13 05:31 [entrez]
AID - VM/OJS/J/97517 [pii]
AID - 10.5603/cj.97517 [doi]
PST - aheadofprint
SO  - Cardiol J. 2023 Oct 13. doi: 10.5603/cj.97517.

PMID- 38484238
OWN - NLM
STAT- MEDLINE
DCOM- 20240318
LR  - 20240318
IS  - 2771-1897 (Electronic)
IS  - 2771-1897 (Linking)
VI  - 30
IP  - 3
DP  - 2024 Mar 1
TI  - Evaluation of ChatGPT for Pelvic Floor Surgery Counseling.
PG  - 245-250
LID - 10.1097/SPV.0000000000001459 [doi]
AB  - IMPORTANCE: Large language models are artificial intelligence applications that 
      can comprehend and produce human-like text and language. ChatGPT is one such 
      model. Recent advances have increased interest in the utility of large language 
      models in medicine. Urogynecology counseling is complex and time-consuming. 
      Therefore, we evaluated ChatGPT as a potential adjunct for patient counseling. 
      OBJECTIVE: Our primary objective was to compare the accuracy and completeness of 
      ChatGPT responses to information in standard patient counseling leaflets 
      regarding common urogynecological procedures. STUDY DESIGN: Seven 
      urogynecologists compared the accuracy and completeness of ChatGPT responses to 
      standard patient leaflets using 5-point Likert scales with a score of 3 being 
      "equally accurate" and "equally complete," and a score of 5 being "much more 
      accurate" and much more complete, respectively. This was repeated 3 months later 
      to evaluate the consistency of ChatGPT. Additional analysis of the 
      understandability and actionability was completed by 2 authors using the Patient 
      Education Materials Assessment Tool. Analysis was primarily descriptive. First 
      and second ChatGPT queries were compared with the Wilcoxon signed rank test. 
      RESULTS: The median (interquartile range) accuracy was 3 (2-3) and completeness 3 
      (2-4) for the first ChatGPT query and 3 (3-3) and 4 (3-4), respectively, for the 
      second query. Accuracy and completeness were significantly higher in the second 
      query (P &lt; 0.01). Understandability and actionability of ChatGPT responses were 
      lower than the standard leaflets. CONCLUSIONS: ChatGPT is similarly accurate and 
      complete when compared with standard patient information leaflets for common 
      urogynecological procedures. Large language models may be a helpful adjunct to 
      direct patient-provider counseling. Further research to determine the efficacy 
      and patient satisfaction of ChatGPT for patient counseling is needed.
CI  - Copyright © 2024 American Urogynecologic Society. All rights reserved.
FAU - Johnson, Colin M
AU  - Johnson CM
AD  - From the Division of Urogynecology and Reconstructive Pelvic Surgery, Department 
      of Obstetrics and Gynecology.
FAU - Bradley, Catherine S
AU  - Bradley CS
AD  - From the Division of Urogynecology and Reconstructive Pelvic Surgery, Department 
      of Obstetrics and Gynecology.
FAU - Kenne, Kimberly A
AU  - Kenne KA
AD  - From the Division of Urogynecology and Reconstructive Pelvic Surgery, Department 
      of Obstetrics and Gynecology.
FAU - Rabice, Sarah
AU  - Rabice S
AD  - From the Division of Urogynecology and Reconstructive Pelvic Surgery, Department 
      of Obstetrics and Gynecology.
FAU - Takacs, Elizabeth
AU  - Takacs E
AD  - Department of Urology, University of Iowa Hospitals and Clinics, Iowa City, IA.
FAU - Vollstedt, Annah
AU  - Vollstedt A
AD  - Department of Urology, University of Iowa Hospitals and Clinics, Iowa City, IA.
FAU - Kowalski, Joseph T
AU  - Kowalski JT
AD  - From the Division of Urogynecology and Reconstructive Pelvic Surgery, Department 
      of Obstetrics and Gynecology.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Urogynecology (Phila)
JT  - Urogynecology (Philadelphia, Pa.)
JID - 9918452588006676
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Pelvic Floor/surgery
MH  - Counseling
MH  - Language
MH  - *Medicine
COIS- Conflicts of Interest: E.T. is a Medtronic clinical trial investigator. C.S.B. is 
      AUGS travel support–Board of Directors; Elsevier–travel support and honorarium 
      for editorial activities and royalties–textbook; ABOG–travel support and 
      honorarium, Urogynecology Division member, examiner The other authors have 
      declared they have no conflicts of interest.
EDAT- 2024/03/14 18:42
MHDA- 2024/03/18 06:44
CRDT- 2024/03/14 16:13
PHST- 2024/03/18 06:44 [medline]
PHST- 2024/03/14 18:42 [pubmed]
PHST- 2024/03/14 16:13 [entrez]
AID - 02273501-202403000-00011 [pii]
AID - 10.1097/SPV.0000000000001459 [doi]
PST - ppublish
SO  - Urogynecology (Phila). 2024 Mar 1;30(3):245-250. doi: 
      10.1097/SPV.0000000000001459.

PMID- 37874336
OWN - NLM
STAT- MEDLINE
DCOM- 20240104
LR  - 20240301
IS  - 1434-4726 (Electronic)
IS  - 0937-4477 (Linking)
VI  - 281
IP  - 1
DP  - 2024 Jan
TI  - ChatGPT performance in laryngology and head and neck surgery: a clinical 
      case-series.
PG  - 319-333
LID - 10.1007/s00405-023-08282-5 [doi]
AB  - OBJECTIVES: To study the performance of ChatGPT in the management of laryngology 
      and head and neck (LHN) cases. METHODS: History and clinical examination of 
      patients consulting at the Otolaryngology-Head and Neck Surgery department were 
      presented to ChatGPT, which was interrogated for differential diagnosis, 
      management, and treatment. The ChatGPT performance was assessed by two blinded 
      board-certified otolaryngologists using the following items of a composite score 
      and the Ottawa Clinic Assessment Tool: differential diagnosis; additional 
      examination; and treatment options. The complexity of clinical cases was 
      evaluated with the Amsterdam Clinical Challenge Scale test. RESULTS: Forty 
      clinical cases were submitted to ChatGPT, accounting for 14 (35%), 12 (30%), and 
      14 (35%) easy, moderate and difficult cases, respectively. ChatGPT indicated a 
      significant higher number of additional examinations compared to practitioners 
      (p = 0.001). There was a significant agreement between practitioners and ChatGPT 
      for the indication of some common examinations (audiometry, ultrasonography, 
      biopsy, gastrointestinal endoscopy or videofluoroscopy). ChatGPT never indicated 
      some important additional examinations (PET-CT, voice quality assessment, or 
      impedance-pH monitoring). ChatGPT reported highest performance in the proposition 
      of the primary (90%) or the most plausible differential diagnoses (65%), and the 
      therapeutic options (60-68%). The ChatGPT performance in the indication of 
      additional examinations was lowest. CONCLUSIONS: ChatGPT is a promising 
      adjunctive tool in LHN practice, providing extensive documentation about 
      disease-related additional examinations, differential diagnoses, and treatments. 
      The ChatGPT is more efficient in diagnosis and treatment, rather than in the 
      selection of the most adequate additional examination.
CI  - © 2023. The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, 
      part of Springer Nature.
FAU - Lechien, Jerome R
AU  - Lechien JR
AUID- ORCID: 0000-0002-0845-0845
AD  - Research Committee of Young Otolaryngologists of the International Federation of 
      Otorhinolaryngological Socities (IFOS), Paris, France. 
      Jerome.Lechien@umons.ac.be.
AD  - Division of Laryngology and Broncho-Esophagology, Department of 
      Otolaryngology-Head Neck Surgery, UMONS Research Institute for Health Sciences 
      and Technology, EpiCURA Hospital, University of Mons (UMons), Mons, Belgium. 
      Jerome.Lechien@umons.ac.be.
AD  - Department of Otorhinolaryngology and Head and Neck Surgery, School of Medicine, 
      UFR Simone Veil, Foch Hospital, Université Versailles Saint-Quentin-en-Yvelines 
      (Paris Saclay University), Paris, France. Jerome.Lechien@umons.ac.be.
AD  - Department of Otorhinolaryngology and Head and Neck Surgery, CHU Saint-Pierre, 
      Brussels, Belgium. Jerome.Lechien@umons.ac.be.
AD  - Polyclinique Elsan de Poitiers, Poitiers, France. Jerome.Lechien@umons.ac.be.
AD  - Department of Human Anatomy and Experimental Oncology, Faculty of Medicine, UMONS 
      Research Institute for Health Sciences and Technology, Avenue du Champ de Mars, 
      6, 7000, Mons, Belgium. Jerome.Lechien@umons.ac.be.
FAU - Georgescu, Bianca M
AU  - Georgescu BM
AD  - Division of Laryngology and Broncho-Esophagology, Department of 
      Otolaryngology-Head Neck Surgery, UMONS Research Institute for Health Sciences 
      and Technology, EpiCURA Hospital, University of Mons (UMons), Mons, Belgium.
FAU - Hans, Stephane
AU  - Hans S
AD  - Research Committee of Young Otolaryngologists of the International Federation of 
      Otorhinolaryngological Socities (IFOS), Paris, France.
AD  - Department of Otorhinolaryngology and Head and Neck Surgery, School of Medicine, 
      UFR Simone Veil, Foch Hospital, Université Versailles Saint-Quentin-en-Yvelines 
      (Paris Saclay University), Paris, France.
FAU - Chiesa-Estomba, Carlos M
AU  - Chiesa-Estomba CM
AD  - Research Committee of Young Otolaryngologists of the International Federation of 
      Otorhinolaryngological Socities (IFOS), Paris, France.
AD  - Department of Otorhinolaryngology-Head &amp; Neck Surgery, Donostia University 
      Hospital-Biodonostia Research Institute, St. Sebastian, Spain.
LA  - eng
PT  - Journal Article
DEP - 20231024
PL  - Germany
TA  - Eur Arch Otorhinolaryngol
JT  - European archives of oto-rhino-laryngology : official journal of the European 
      Federation of Oto-Rhino-Laryngological Societies (EUFOS) : affiliated with the 
      German Society for Oto-Rhino-Laryngology - Head and Neck Surgery
JID - 9002937
SB  - IM
MH  - Humans
MH  - *Positron Emission Tomography Computed Tomography
MH  - *Otolaryngology
MH  - Otolaryngologists
MH  - Biopsy
MH  - Diagnosis, Differential
OTO - NOTNLM
OT  - Artificial
OT  - ChatGPT
OT  - Comparison
OT  - Diagnosis
OT  - Head neck
OT  - Intelligence
OT  - Laryngology
OT  - Laryngopharyngeal
OT  - Otolaryngology
OT  - Reflux
OT  - Surgery
OT  - Treatment
OT  - Voice
EDAT- 2023/10/24 12:42
MHDA- 2024/01/04 11:44
CRDT- 2023/10/24 11:04
PHST- 2023/07/16 00:00 [received]
PHST- 2023/10/06 00:00 [accepted]
PHST- 2024/01/04 11:44 [medline]
PHST- 2023/10/24 12:42 [pubmed]
PHST- 2023/10/24 11:04 [entrez]
AID - 10.1007/s00405-023-08282-5 [pii]
AID - 10.1007/s00405-023-08282-5 [doi]
PST - ppublish
SO  - Eur Arch Otorhinolaryngol. 2024 Jan;281(1):319-333. doi: 
      10.1007/s00405-023-08282-5. Epub 2023 Oct 24.

PMID- 38386789
OWN - NLM
STAT- MEDLINE
DCOM- 20240226
LR  - 20240322
IS  - 1677-6119 (Electronic)
IS  - 1677-5538 (Print)
IS  - 1677-5538 (Linking)
VI  - 50
IP  - 2
DP  - 2024 Mar-Apr
TI  - Use of ChatGPT in Urology and its Relevance in Clinical Practice: Is it useful?
PG  - 192-198
LID - 10.1590/S1677-5538.IBJU.2023.0570 [doi]
AB  - PURPOUSE: One of the many artificial intelligence based tools that has gained 
      popularity is the Chat-Generative Pre-Trained Transformer (ChatGPT). Due to its 
      popularity, incorrect information provided by ChatGPT will have an impact on 
      patient misinformation. Furthermore, it may cause misconduct as ChatGPT can 
      mislead physicians on the decision-making pathway. Therefore, the aim of this 
      study is to evaluate the accuracy and reproducibility of ChatGPT answers 
      regarding urological diagnoses. MATERIALS AND METHODS: ChatGPT 3.5 version was 
      used. The questions asked for the program involved Primary Megaureter (pMU), 
      Enuresis and Vesicoureteral Reflux (VUR). There were three queries for each 
      topic. The queries were inserted twice, and both responses were recorded to 
      examine the reproducibility of ChatGPT's answers. Afterwards, both answers were 
      combined. Finally, those rwere evaluated qualitatively by a board of three 
      specialists. A descriptive analysis was performed. RESULTS AND CONCLUSION: 
      ChatGPT simulated general knowledge on the researched topics. Regarding Enuresis, 
      the provided definition was partially correct, as the generic response allowed 
      for misinterpretation. For VUR, the response was considered appropriate. For pMU 
      it was partially correct, lacking essential aspects of its definition such as the 
      diameter of the dilatation of the ureter. Unnecessary exams were suggested, for 
      Enuresis and pMU. Regarding the treatment of the conditions mentioned, it 
      specified treatments for Enuresis that are ineffective, such as bladder training. 
      Therefore, ChatGPT responses present a combination of accurate information, but 
      also incomplete, ambiguous and, occasionally, misleading details.
CI  - Copyright® by the International Brazilian Journal of Urology.
FAU - Braga, Antonio Vitor Nascimento Martinelli
AU  - Braga AVNM
AD  - Centro de Distúrbios Urinários Infantis (CEDIMI), Escola Bahiana de Medicina e 
      Saúde Pública, Salvador, BA, Brasil.
FAU - Nunes, Noel Charlles
AU  - Nunes NC
AD  - Centro de Distúrbios Urinários Infantis (CEDIMI), Escola Bahiana de Medicina e 
      Saúde Pública, Salvador, BA, Brasil.
FAU - Santos, Emanoel Nascimento
AU  - Santos EN
AD  - Centro de Distúrbios Urinários Infantis (CEDIMI), Escola Bahiana de Medicina e 
      Saúde Pública, Salvador, BA, Brasil.
FAU - Veiga, Maria Luiza
AU  - Veiga ML
AD  - Centro de Distúrbios Urinários Infantis (CEDIMI), Escola Bahiana de Medicina e 
      Saúde Pública, Salvador, BA, Brasil.
FAU - Braga, Ana Aparecida Nascimento Martinelli
AU  - Braga AANM
AD  - Centro de Distúrbios Urinários Infantis (CEDIMI), Escola Bahiana de Medicina e 
      Saúde Pública, Salvador, BA, Brasil.
FAU - de Abreu, Glicia Estevam
AU  - de Abreu GE
AD  - Centro de Distúrbios Urinários Infantis (CEDIMI), Escola Bahiana de Medicina e 
      Saúde Pública, Salvador, BA, Brasil.
FAU - de Bessa, Jose Júnior
AU  - de Bessa J Júnior
AD  - Faculdade de Medicina, Universidade Estadual de Feira de Santana, Feira de 
      Santana, BA, Brasil.
FAU - Braga, Luis Henrique
AU  - Braga LH
AD  - McMaster University, Hamilton, Ontario, Canada.
FAU - Kirsch, Andrew J
AU  - Kirsch AJ
AD  - Pediatric Urology, Children's Healthcare of Atlanta and Emory University School 
      of Medicine, Atlanta, GA, United States.
FAU - Barroso, Ubirajara Júnior
AU  - Barroso U Júnior
AD  - Centro de Distúrbios Urinários Infantis (CEDIMI), Escola Bahiana de Medicina e 
      Saúde Pública, Salvador, BA, Brasil.
LA  - eng
PT  - Journal Article
PL  - Brazil
TA  - Int Braz J Urol
JT  - International braz j urol : official journal of the Brazilian Society of Urology
JID - 101158091
SB  - IM
MH  - Humans
MH  - *Urology
MH  - Artificial Intelligence
MH  - Reproducibility of Results
MH  - *Nocturnal Enuresis
MH  - *Physicians
PMC - PMC10953603
OTO - NOTNLM
OT  - Cakut [Supplementary Concept]
OT  - Urology
OT  - Vesico-Ureteral Reflux
COIS- None declared.
EDAT- 2024/02/22 18:42
MHDA- 2024/02/26 06:45
PMCR- 2024/03/18
CRDT- 2024/02/22 14:27
PHST- 2023/11/16 00:00 [received]
PHST- 2023/11/30 00:00 [accepted]
PHST- 2024/02/26 06:45 [medline]
PHST- 2024/02/22 18:42 [pubmed]
PHST- 2024/02/22 14:27 [entrez]
PHST- 2024/03/18 00:00 [pmc-release]
AID - IBJU20230570 [pii]
AID - S1677-5538.IBJU.2023.0570 [pii]
AID - 10.1590/S1677-5538.IBJU.2023.0570 [doi]
PST - ppublish
SO  - Int Braz J Urol. 2024 Mar-Apr;50(2):192-198. doi: 
      10.1590/S1677-5538.IBJU.2023.0570.

PMID- 38039286
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231205
IS  - 2767-3170 (Electronic)
IS  - 2767-3170 (Linking)
VI  - 2
IP  - 12
DP  - 2023 Dec
TI  - How does ChatGPT-4 preform on non-English national medical licensing examination? 
      An evaluation in Chinese language.
PG  - e0000397
LID - 10.1371/journal.pdig.0000397 [doi]
LID - e0000397
AB  - ChatGPT, an artificial intelligence (AI) system powered by large-scale language 
      models, has garnered significant interest in healthcare. Its performance 
      dependent on the quality and quantity of training data available for a specific 
      language, with the majority of it being in English. Therefore, its effectiveness 
      in processing the Chinese language, which has fewer data available, warrants 
      further investigation. This study aims to assess the of ChatGPT's ability in 
      medical education and clinical decision-making within the Chinese context. We 
      utilized a dataset from the Chinese National Medical Licensing Examination (NMLE) 
      to assess ChatGPT-4's proficiency in medical knowledge in Chinese. Performance 
      indicators, including score, accuracy, and concordance (confirmation of answers 
      through explanation), were employed to evaluate ChatGPT's effectiveness in both 
      original and encoded medical questions. Additionally, we translated the original 
      Chinese questions into English to explore potential avenues for improvement. 
      ChatGPT scored 442/600 for original questions in Chinese, surpassing the passing 
      threshold of 360/600. However, ChatGPT demonstrated reduced accuracy in 
      addressing open-ended questions, with an overall accuracy rate of 47.7%. Despite 
      this, ChatGPT displayed commendable consistency, achieving a 75% concordance rate 
      across all case analysis questions. Moreover, translating Chinese case analysis 
      questions into English yielded only marginal improvements in ChatGPT's 
      performance (p = 0.728). ChatGPT exhibits remarkable precision and reliability 
      when handling the NMLE in Chinese. Translation of NMLE questions from Chinese to 
      English does not yield an improvement in ChatGPT's performance.
CI  - Copyright: © 2023 Fang et al. This is an open access article distributed under 
      the terms of the Creative Commons Attribution License, which permits unrestricted 
      use, distribution, and reproduction in any medium, provided the original author 
      and source are credited.
FAU - Fang, Changchang
AU  - Fang C
AD  - Department of Endocrine, the Second Affiliated Hospital of Nanchang University, 
      Jiangxi, China.
AD  - Queen Mary College, Nanchang University, Jiangxi, China.
FAU - Wu, Yuting
AU  - Wu Y
AD  - Department of Endocrine, the Second Affiliated Hospital of Nanchang University, 
      Jiangxi, China.
FAU - Fu, Wanying
AU  - Fu W
AD  - Department of Endocrine, the Second Affiliated Hospital of Nanchang University, 
      Jiangxi, China.
AD  - Queen Mary College, Nanchang University, Jiangxi, China.
FAU - Ling, Jitao
AU  - Ling J
AD  - Department of Endocrine, the Second Affiliated Hospital of Nanchang University, 
      Jiangxi, China.
FAU - Wang, Yue
AU  - Wang Y
AD  - Department of Cardiology, Sun Yat-sen Memorial Hospital of Sun Yat-sen 
      University, Guangzhou, China.
AD  - Guangdong Province Key Laboratory of Arrhythmia and Electrophysiology, Guangzhou, 
      China.
FAU - Liu, Xiaolin
AU  - Liu X
AD  - Department of Cardiology, Sun Yat-sen Memorial Hospital of Sun Yat-sen 
      University, Guangzhou, China.
AD  - Guangdong Province Key Laboratory of Arrhythmia and Electrophysiology, Guangzhou, 
      China.
FAU - Jiang, Yuan
AU  - Jiang Y
AD  - Department of Cardiology, Sun Yat-sen Memorial Hospital of Sun Yat-sen 
      University, Guangzhou, China.
AD  - Guangdong Province Key Laboratory of Arrhythmia and Electrophysiology, Guangzhou, 
      China.
FAU - Wu, Yifan
AU  - Wu Y
AD  - Department of Endocrine, the Second Affiliated Hospital of Nanchang University, 
      Jiangxi, China.
FAU - Chen, Yixuan
AU  - Chen Y
AD  - Department of Endocrine, the Second Affiliated Hospital of Nanchang University, 
      Jiangxi, China.
FAU - Zhou, Jing
AU  - Zhou J
AD  - Department of Endocrine, the Second Affiliated Hospital of Nanchang University, 
      Jiangxi, China.
FAU - Zhu, Zhichen
AU  - Zhu Z
AD  - Department of Endocrine, the Second Affiliated Hospital of Nanchang University, 
      Jiangxi, China.
FAU - Yan, Zhiwei
AU  - Yan Z
AD  - Provincial University Key Laboratory of Sport and Health Science, School of 
      Physical Education and Sport Sciences, Fujian Normal University, Fuzhou, China.
FAU - Yu, Peng
AU  - Yu P
AD  - Department of Endocrine, the Second Affiliated Hospital of Nanchang University, 
      Jiangxi, China.
AD  - Institute for the Study of Endocrinology and Metabolism in Jiangxi, the Second 
      Affiliated Hospital of Nanchang University, Jiangxi, China.
FAU - Liu, Xiao
AU  - Liu X
AUID- ORCID: 0000-0001-8252-3435
AD  - Department of Cardiology, Sun Yat-sen Memorial Hospital of Sun Yat-sen 
      University, Guangzhou, China.
AD  - Guangdong Province Key Laboratory of Arrhythmia and Electrophysiology, Guangzhou, 
      China.
AD  - Institute for the Study of Endocrinology and Metabolism in Jiangxi, the Second 
      Affiliated Hospital of Nanchang University, Jiangxi, China.
LA  - eng
PT  - Journal Article
DEP - 20231201
PL  - United States
TA  - PLOS Digit Health
JT  - PLOS digital health
JID - 9918335064206676
PMC - PMC10691691
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/12/01 18:42
MHDA- 2023/12/01 18:43
PMCR- 2023/12/01
CRDT- 2023/12/01 13:33
PHST- 2023/05/05 00:00 [received]
PHST- 2023/10/23 00:00 [accepted]
PHST- 2023/12/01 18:43 [medline]
PHST- 2023/12/01 18:42 [pubmed]
PHST- 2023/12/01 13:33 [entrez]
PHST- 2023/12/01 00:00 [pmc-release]
AID - PDIG-D-23-00175 [pii]
AID - 10.1371/journal.pdig.0000397 [doi]
PST - epublish
SO  - PLOS Digit Health. 2023 Dec 1;2(12):e0000397. doi: 10.1371/journal.pdig.0000397. 
      eCollection 2023 Dec.

PMID- 37183932
OWN - NLM
STAT- MEDLINE
DCOM- 20230621
LR  - 20240109
IS  - 1466-187X (Electronic)
IS  - 0142-159X (Linking)
VI  - 45
IP  - 7
DP  - 2023 Jul
TI  - Medical Teacher's first ChatGPT's referencing hallucinations: Lessons for 
      editors, reviewers, and teachers.
PG  - 673-675
LID - 10.1080/0142159X.2023.2208731 [doi]
AB  - Students' inappropriate use of ChatGPT is a concern. There is also, however, the 
      potential for academics to use ChatGPT inappropriately. After explaining 
      ChatGPT's "hallucinations" regarding citing and referencing, this commentary 
      illustrates the problem by describing the detection of the first known Medical 
      Teacher submission using ChatGPT inappropriately, the lessons that can be drawn 
      from it for journal editors, reviewers, and teachers, and then the wider 
      implications if this problem is left unchecked.
FAU - Masters, Ken
AU  - Masters K
AUID- ORCID: 0000-0003-3425-5020
AD  - Sultan Qaboos University, Sultanate of Oman.
LA  - eng
PT  - Journal Article
DEP - 20230515
PL  - England
TA  - Med Teach
JT  - Medical teacher
JID - 7909593
SB  - IM
CIN - Med Teach. 2023 Dec;45(12):1438. PMID: 37590117
MH  - Humans
MH  - *Teaching
MH  - *Artificial Intelligence
OTO - NOTNLM
OT  - ChatGPT
OT  - Ethics
OT  - GPT-4
OT  - artificial intelligence
OT  - hallucinations
OT  - medical education
EDAT- 2023/05/15 13:06
MHDA- 2023/06/15 06:42
CRDT- 2023/05/15 06:43
PHST- 2023/06/15 06:42 [medline]
PHST- 2023/05/15 13:06 [pubmed]
PHST- 2023/05/15 06:43 [entrez]
AID - 10.1080/0142159X.2023.2208731 [doi]
PST - ppublish
SO  - Med Teach. 2023 Jul;45(7):673-675. doi: 10.1080/0142159X.2023.2208731. Epub 2023 
      May 15.

PMID- 37838575
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20231204
LR  - 20231204
IS  - 1875-2128 (Electronic)
IS  - 1875-2128 (Linking)
VI  - 116
IP  - 12
DP  - 2023 Dec
TI  - Relevance of medical information obtained from ChatGPT: Comment.
PG  - 602
LID - S1875-2136(23)00175-4 [pii]
LID - 10.1016/j.acvd.2023.09.003 [doi]
FAU - Wiwanitkit, Viroj
AU  - Wiwanitkit V
AD  - Chandigarh University, Chandigarh, India; Joesph Ayobabalola, University, 
      Ikeji-Arakeji, Nigeria. Electronic address: wviroj@yahoo.com.
LA  - eng
PT  - Letter
DEP - 20231004
PL  - Netherlands
TA  - Arch Cardiovasc Dis
JT  - Archives of cardiovascular diseases
JID - 101465655
SB  - IM
OTO - NOTNLM
OT  - Cardiovascular
OT  - ChatGPT
OT  - Education
EDAT- 2023/10/15 05:46
MHDA- 2023/10/15 05:47
CRDT- 2023/10/14 22:02
PHST- 2023/09/18 00:00 [received]
PHST- 2023/09/20 00:00 [accepted]
PHST- 2023/10/15 05:47 [medline]
PHST- 2023/10/15 05:46 [pubmed]
PHST- 2023/10/14 22:02 [entrez]
AID - S1875-2136(23)00175-4 [pii]
AID - 10.1016/j.acvd.2023.09.003 [doi]
PST - ppublish
SO  - Arch Cardiovasc Dis. 2023 Dec;116(12):602. doi: 10.1016/j.acvd.2023.09.003. Epub 
      2023 Oct 4.

PMID- 37222839
OWN - NLM
STAT- MEDLINE
DCOM- 20231103
LR  - 20231115
IS  - 1432-0711 (Electronic)
IS  - 0932-0067 (Linking)
VI  - 308
IP  - 6
DP  - 2023 Dec
TI  - Exploring the use of ChatGPT in OBGYN: a bibliometric analysis of the first 
      ChatGPT-related publications.
PG  - 1785-1789
LID - 10.1007/s00404-023-07081-x [doi]
AB  - PURPOSE: Little is known about the scientific literature regarding the new 
      revolutionary tool, ChatGPT. We aim to perform a bibliometric analysis to 
      identify ChatGPT-related publications in obstetrics and gynecology (OBGYN). STUDY 
      DESIGN: A bibliometric study through PubMed database. We mined all 
      ChatGPT-related publications using the search term "ChatGPT". Bibliometric data 
      were obtained from the iCite database. We performed a descriptive analysis. We 
      further compared IF among publications describing a study vs. other publications. 
      RESULTS: Overall, 42 ChatGPT-related publications were published across 26 
      different journals during 69&nbsp;days. Most publications were editorials (52%) and 
      news/briefing (22%), with only one (2%) research article identified. Five (12%) 
      publications described a study performed. No ChatGPT-related publications in 
      OBGYN were found. The leading journal by the number of publications was Nature 
      (24%), followed by Lancet Digital Health and Radiology (7%, for both). The main 
      subjects of publications were ChatGPT's scientific writing quality (26%) and a 
      description of ChatGPT (26%) followed by tested performance of ChatGPT (14%), 
      authorship and ethical issues (10% for both topics).In a comparison of 
      publications describing a study performed (n = 5) vs. other publications 
      (n = 37), mean IF was lower in the study-publications (mean 6.25 ± 0 vs. 
      25.4 ± 21.6, p &lt; .001). CONCLUSIONS: The study highlights main trends in 
      ChatGPT-related publications. OBGYN is yet to be represented in this literature.
CI  - © 2023. The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, 
      part of Springer Nature.
FAU - Levin, Gabriel
AU  - Levin G
AUID- ORCID: 0000-0003-1282-5379
AD  - The Department of Gynecologic Oncology, Hadassah-Hebrew University Medical 
      Center, Jerusalem, Israel. levin.gaby@gmail.com.
AD  - Lady Davis Institute for Cancer Research, Jewish General Hospital, McGill 
      University, Quebec, Canada. levin.gaby@gmail.com.
FAU - Brezinov, Yoav
AU  - Brezinov Y
AD  - Experimental Surgery, McGill University, Quebec, Canada.
FAU - Meyer, Raanan
AU  - Meyer R
AD  - Division of Minimally Invasive Gynecologic Surgery, Department of Obstetrics and 
      Gynecology, Cedars Sinai Medical Center, Los Angeles, CA, USA.
AD  - The Dr. Pinchas Bornstein Talpiot Medical Leadership Program, Sheba Medical 
      Center, Tel Hashomer, Ramat-Gan, Israel.
LA  - eng
PT  - Journal Article
DEP - 20230524
PL  - Germany
TA  - Arch Gynecol Obstet
JT  - Archives of gynecology and obstetrics
JID - 8710213
SB  - IM
MH  - Humans
MH  - Bibliometrics
MH  - Databases, Factual
MH  - *Gynecology
MH  - *Obstetrics
MH  - Publications
MH  - Artificial Intelligence
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Bibliometrics
OT  - ChatGPT
OT  - OBGYN literature
OT  - Research
EDAT- 2023/05/24 13:08
MHDA- 2023/10/23 00:42
CRDT- 2023/05/24 11:23
PHST- 2023/03/29 00:00 [received]
PHST- 2023/05/08 00:00 [accepted]
PHST- 2023/10/23 00:42 [medline]
PHST- 2023/05/24 13:08 [pubmed]
PHST- 2023/05/24 11:23 [entrez]
AID - 10.1007/s00404-023-07081-x [pii]
AID - 10.1007/s00404-023-07081-x [doi]
PST - ppublish
SO  - Arch Gynecol Obstet. 2023 Dec;308(6):1785-1789. doi: 10.1007/s00404-023-07081-x. 
      Epub 2023 May 24.

PMID- 38090765
OWN - NLM
STAT- MEDLINE
DCOM- 20231216
LR  - 20231216
IS  - 2152-2723 (Electronic)
IS  - 2152-2715 (Linking)
VI  - 26
IP  - 12
DP  - 2023 Dec
TI  - Exploring the Impact of ChatGPT Literacy on User Satisfaction: The Mediating Role 
      of User Motivations.
PG  - 913-918
LID - 10.1089/cyber.2023.0312 [doi]
AB  - The introduction of chat generative pretrained transformer (ChatGPT), the fastest 
      growing large language model, has changed the landscape of artificial 
      intelligence-human interaction in everyday life. As the social influence of 
      ChatGPT increases, competencies in it become important life skills. This study 
      aims to explore the determinants of ChatGPT user satisfaction to provide 
      practical implications by suggesting a significant independent variable and 
      mediators between the independent variable and user satisfaction. To this end, 
      this study recruited 822 college students with prior experience using ChatGPT 
      (407 males and 415 females) and conducted an online survey. We tested the effects 
      of ChatGPT literacy on user satisfaction and the mediating roles of different 
      motives (i.e., information and knowledge acquisition and entertainment and 
      leisure) in the relationship between ChatGPT literacy and user satisfaction. The 
      results suggest that ChatGPT literacy significantly increases user satisfaction 
      and that information and knowledge acquisition and entertainment and leisure 
      partially mediate the relationship between the effect of ChatGPT literacy and 
      user satisfaction. The results may have implications for large language model 
      developers and practitioners, such as educators.
FAU - Lee, Seyoung
AU  - Lee S
AUID- ORCID: 0000-0001-8048-1796
AD  - Department of Media and Communication, Sungkyunkwan University, Jongno-Gu, South 
      Korea.
FAU - Park, Gain
AU  - Park G
AUID- ORCID: 0000-0002-3767-8320
AD  - Department of Journalism and Media Studies, New Mexico State University, Las 
      Cruces, New Mexico, USA.
LA  - eng
PT  - Journal Article
DEP - 20231122
PL  - United States
TA  - Cyberpsychol Behav Soc Netw
JT  - Cyberpsychology, behavior and social networking
JID - 101528721
SB  - IM
MH  - Female
MH  - Male
MH  - Humans
MH  - *Literacy
MH  - *Motivation
MH  - Artificial Intelligence
MH  - Language
MH  - Students
OTO - NOTNLM
OT  - ChatGPT
OT  - ChatGPT literacy
OT  - artificial intelligence
OT  - large language model
OT  - user motivation
OT  - user satisfaction
EDAT- 2023/12/13 18:42
MHDA- 2023/12/17 09:42
CRDT- 2023/12/13 13:17
PHST- 2023/12/17 09:42 [medline]
PHST- 2023/12/13 18:42 [pubmed]
PHST- 2023/12/13 13:17 [entrez]
AID - 10.1089/cyber.2023.0312 [doi]
PST - ppublish
SO  - Cyberpsychol Behav Soc Netw. 2023 Dec;26(12):913-918. doi: 
      10.1089/cyber.2023.0312. Epub 2023 Nov 22.

PMID- 37518931
OWN - NLM
STAT- MEDLINE
DCOM- 20230801
LR  - 20230801
IS  - 0300-5283 (Print)
IS  - 0300-5283 (Linking)
VI  - 78
IP  - 4
DP  - 2023 Jul
TI  - A Tête-à-tête with ChatGPT on the impact of artificial intelligence in medical 
      education.
PG  - 547-549
AB  - Chat Generative Pre-Trained Transformer (ChatGPT) is an artificial intelligence 
      (AI) language model developed by OpenAI. It is trained to process vast amounts of 
      text and engage in human-like conversational interaction with users. Being 
      accessible by all, it is widely used and its capabilities range from language 
      translation, summarising long texts and creative writing. This article explores 
      the potential role of ChatGPT in medical education and the possible concerns 
      about the misuse of this technology through a conversation with ChatGPT itself 
      via text prompts. The implications of this technology in medical education as 
      told by ChatGPT are interesting and seemingly helpful for both the students and 
      the tutors. However, this could be a double-edged sword considering the risks of 
      compromised students' integrity and concerns of over-reliance. This also calls 
      for counter strategies and policies in place to mitigate these risks.
FAU - Vignesh, R
AU  - Vignesh R
AD  - Universiti Kuala Lumpur, Royal College of Medicine Perak, Faculty of Medicine, 
      Preclinical Department, Ipoh, Malaysia. vignesh@unikl.edu.my.
FAU - Pradeep, P
AU  - Pradeep P
AD  - Universiti Kuala Lumpur, Royal College of Medicine Perak, Faculty of Medicine, 
      Preclinical Department, Ipoh, Malaysia.
FAU - Balakrishnan, P
AU  - Balakrishnan P
AD  - Saveetha Institute of Medical and Technical Sciences (SIMATS), Saveetha Dental 
      College and Hospitals, Centre for Infectious Diseases, Department of 
      Microbiology, Chennai, India.
LA  - eng
PT  - Journal Article
PL  - Malaysia
TA  - Med J Malaysia
JT  - The Medical journal of Malaysia
JID - 0361547
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Education, Medical
MH  - Students
EDAT- 2023/07/31 06:43
MHDA- 2023/08/01 06:45
CRDT- 2023/07/31 00:12
PHST- 2023/08/01 06:45 [medline]
PHST- 2023/07/31 06:43 [pubmed]
PHST- 2023/07/31 00:12 [entrez]
PST - ppublish
SO  - Med J Malaysia. 2023 Jul;78(4):547-549.

PMID- 37293238
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230612
IS  - 2624-8212 (Electronic)
IS  - 2624-8212 (Linking)
VI  - 6
DP  - 2023
TI  - Human-like problem-solving abilities in large language models using ChatGPT.
PG  - 1199350
LID - 10.3389/frai.2023.1199350 [doi]
LID - 1199350
AB  - BACKGROUNDS: The field of Artificial Intelligence (AI) has seen a major shift in 
      recent years due to the development of new Machine Learning (ML) models such as 
      Generative Pre-trained Transformer (GPT). GPT has achieved previously unheard-of 
      levels of accuracy in most computerized language processing tasks and their 
      chat-based variations. AIM: The aim of this study was to investigate the 
      problem-solving abilities of ChatGPT using two sets of verbal insight problems, 
      with a known performance level established by a sample of human participants. 
      MATERIALS AND METHODS: A total of 30 problems labeled as "practice problems" and 
      "transfer problems" were administered to ChatGPT. ChatGPT's answers received a 
      score of "0" for each incorrectly answered problem and a score of "1" for each 
      correct response. The highest possible score for both the practice and transfer 
      problems was 15 out of 15. The solution rate for each problem (based on a sample 
      of 20 subjects) was used to assess and compare the performance of ChatGPT with 
      that of human subjects. RESULTS: The study highlighted that ChatGPT can be 
      trained in out-of-the-box thinking and demonstrated potential in solving verbal 
      insight problems. The global performance of ChatGPT equalled the most probable 
      outcome for the human sample in both practice problems and transfer problems as 
      well as upon their combination. Additionally, ChatGPT answer combinations were 
      among the 5% of most probable outcomes for the human sample both when considering 
      practice problems and pooled problem sets. These findings demonstrate that 
      ChatGPT performance on both set of problems was in line with the mean rate of 
      success of human subjects, indicating that it performed reasonably well. 
      CONCLUSIONS: The use of transformer architecture and self-attention in ChatGPT 
      may have helped to prioritize inputs while predicting, contributing to its 
      potential in verbal insight problem-solving. ChatGPT has shown potential in 
      solving insight problems, thus highlighting the importance of incorporating AI 
      into psychological research. However, it is acknowledged that there are still 
      open challenges. Indeed, further research is required to fully understand AI's 
      capabilities and limitations in verbal problem-solving.
CI  - Copyright © 2023 Orrù, Piarulli, Conversano and Gemignani.
FAU - Orrù, Graziella
AU  - Orrù G
AD  - Department of Surgical, Medical, Molecular and Critical Area Pathology, 
      University of Pisa, Pisa, Italy.
FAU - Piarulli, Andrea
AU  - Piarulli A
AD  - Department of Surgical, Medical, Molecular and Critical Area Pathology, 
      University of Pisa, Pisa, Italy.
FAU - Conversano, Ciro
AU  - Conversano C
AD  - Department of Surgical, Medical, Molecular and Critical Area Pathology, 
      University of Pisa, Pisa, Italy.
FAU - Gemignani, Angelo
AU  - Gemignani A
AD  - Department of Surgical, Medical, Molecular and Critical Area Pathology, 
      University of Pisa, Pisa, Italy.
LA  - eng
PT  - Journal Article
DEP - 20230524
PL  - Switzerland
TA  - Front Artif Intell
JT  - Frontiers in artificial intelligence
JID - 101770551
PMC - PMC10244637
OTO - NOTNLM
OT  - AI
OT  - Artificial Intelligence
OT  - ChatGPT
OT  - NLP
OT  - machine learning
OT  - problem-solving
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/06/09 06:42
MHDA- 2023/06/09 06:43
PMCR- 2023/05/24
CRDT- 2023/06/09 04:32
PHST- 2023/04/06 00:00 [received]
PHST- 2023/05/09 00:00 [accepted]
PHST- 2023/06/09 06:43 [medline]
PHST- 2023/06/09 06:42 [pubmed]
PHST- 2023/06/09 04:32 [entrez]
PHST- 2023/05/24 00:00 [pmc-release]
AID - 10.3389/frai.2023.1199350 [doi]
PST - epublish
SO  - Front Artif Intell. 2023 May 24;6:1199350. doi: 10.3389/frai.2023.1199350. 
      eCollection 2023.

PMID- 37028488
OWN - NLM
STAT- MEDLINE
DCOM- 20230814
LR  - 20230816
IS  - 1937-5913 (Electronic)
IS  - 1542-0124 (Linking)
VI  - 28
DP  - 2023 Apr
TI  - Readership awareness series - Paper 4: Chatbots and ChatGPT - Ethical 
      considerations in scientific publications.
PG  - 153-154
LID - S1542-0124(23)00027-7 [pii]
LID - 10.1016/j.jtos.2023.04.001 [doi]
FAU - Ali, Mohammad Javed
AU  - Ali MJ
FAU - Djalilian, Ali
AU  - Djalilian A
LA  - eng
PT  - Editorial
DEP - 20230406
PL  - United States
TA  - Ocul Surf
JT  - The ocular surface
JID - 101156063
SB  - IM
MH  - *Publishing
MH  - *Authorship
OTO - NOTNLM
OT  - Authorship
OT  - ChatGPT
OT  - Chatbot
OT  - Ethics
OT  - Publication
OT  - Scientific
COIS- Declaration of competing interest None.
EDAT- 2023/04/08 06:00
MHDA- 2023/08/14 06:43
CRDT- 2023/04/07 19:24
PHST- 2023/03/17 00:00 [received]
PHST- 2023/04/03 00:00 [accepted]
PHST- 2023/08/14 06:43 [medline]
PHST- 2023/04/08 06:00 [pubmed]
PHST- 2023/04/07 19:24 [entrez]
AID - S1542-0124(23)00027-7 [pii]
AID - 10.1016/j.jtos.2023.04.001 [doi]
PST - ppublish
SO  - Ocul Surf. 2023 Apr;28:153-154. doi: 10.1016/j.jtos.2023.04.001. Epub 2023 Apr 6.

PMID- 37934568
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231124
IS  - 2369-3762 (Print)
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Nov 7
TI  - Assessing the Performance of ChatGPT in Medical Biochemistry Using Clinical Case 
      Vignettes: Observational Study.
PG  - e47191
LID - 10.2196/47191 [doi]
LID - e47191
AB  - BACKGROUND: ChatGPT has gained global attention recently owing to its high 
      performance in generating a wide range of information and retrieving any kind of 
      data instantaneously. ChatGPT has also been tested for the United States Medical 
      Licensing Examination (USMLE) and has successfully cleared it. Thus, its 
      usability in medical education is now one of the key discussions worldwide. 
      OBJECTIVE: The objective of this study is to evaluate the performance of ChatGPT 
      in medical biochemistry using clinical case vignettes. METHODS: The performance 
      of ChatGPT was evaluated in medical biochemistry using 10 clinical case 
      vignettes. Clinical case vignettes were randomly selected and inputted in ChatGPT 
      along with the response options. We tested the responses for each clinical case 
      twice. The answers generated by ChatGPT were saved and checked using our 
      reference material. RESULTS: ChatGPT generated correct answers for 4 questions on 
      the first attempt. For the other cases, there were differences in responses 
      generated by ChatGPT in the first and second attempts. In the second attempt, 
      ChatGPT provided correct answers for 6 questions and incorrect answers for 4 
      questions out of the 10 cases that were used. But, to our surprise, for case 3, 
      different answers were obtained with multiple attempts. We believe this to have 
      happened owing to the complexity of the case, which involved addressing various 
      critical medical aspects related to amino acid metabolism in a balanced approach. 
      CONCLUSIONS: According to the findings of our study, ChatGPT may not be 
      considered an accurate information provider for application in medical education 
      to improve learning and assessment. However, our study was limited by a small 
      sample size (10 clinical case vignettes) and the use of the publicly available 
      version of ChatGPT (version 3.5). Although artificial intelligence (AI) has the 
      capability to transform medical education, we emphasize the validation of such 
      data produced by such AI systems for correctness and dependability before it 
      could be implemented in practice.
CI  - ©Krishna Mohan Surapaneni. Originally published in JMIR Medical Education 
      (https://mededu.jmir.org), 07.11.2023.
FAU - Surapaneni, Krishna Mohan
AU  - Surapaneni KM
AUID- ORCID: 0000-0002-5204-5708
AD  - Panimalar Medical College Hospital &amp; Research Institute, Chennai, India.
LA  - eng
PT  - Journal Article
DEP - 20231107
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
PMC - PMC10664016
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - biochemistry
OT  - case scenario
OT  - case study
OT  - chatbot
OT  - computer generated
OT  - medical Biochemistry
OT  - medical education
OT  - medical exam
OT  - medical examination
COIS- Conflicts of Interest: None declared.
EDAT- 2023/11/07 12:46
MHDA- 2023/11/07 12:47
PMCR- 2023/11/07
CRDT- 2023/11/07 11:53
PHST- 2023/03/11 00:00 [received]
PHST- 2023/09/21 00:00 [accepted]
PHST- 2023/05/29 00:00 [revised]
PHST- 2023/11/07 12:47 [medline]
PHST- 2023/11/07 12:46 [pubmed]
PHST- 2023/11/07 11:53 [entrez]
PHST- 2023/11/07 00:00 [pmc-release]
AID - v9i1e47191 [pii]
AID - 10.2196/47191 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Nov 7;9:e47191. doi: 10.2196/47191.

PMID- 37831496
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231030
IS  - 2561-326X (Electronic)
IS  - 2561-326X (Linking)
VI  - 7
DP  - 2023 Oct 13
TI  - Accuracy of ChatGPT on Medical Questions in the National Medical Licensing 
      Examination in Japan: Evaluation Study.
PG  - e48023
LID - 10.2196/48023 [doi]
LID - e48023
AB  - BACKGROUND: ChatGPT (OpenAI) has gained considerable attention because of its 
      natural and intuitive responses. ChatGPT sometimes writes plausible-sounding but 
      incorrect or nonsensical answers, as stated by OpenAI as a limitation. However, 
      considering that ChatGPT is an interactive AI that has been trained to reduce the 
      output of unethical sentences, the reliability of the training data is high and 
      the usefulness of the output content is promising. Fortunately, in March 2023, a 
      new version of ChatGPT, GPT-4, was released, which, according to internal 
      evaluations, was expected to increase the likelihood of producing factual 
      responses by 40% compared with its predecessor, GPT-3.5. The usefulness of this 
      version of ChatGPT in English is widely appreciated. It is also increasingly 
      being evaluated as a system for obtaining medical information in languages other 
      than English. Although it does not reach a passing score on the national medical 
      examination in Chinese, its accuracy is expected to gradually improve. Evaluation 
      of ChatGPT with Japanese input is limited, although there have been reports on 
      the accuracy of ChatGPT's answers to clinical questions regarding the Japanese 
      Society of Hypertension guidelines and on the performance of the National Nursing 
      Examination. OBJECTIVE: The objective of this study is to evaluate whether 
      ChatGPT can provide accurate diagnoses and medical knowledge for Japanese input. 
      METHODS: Questions from the National Medical Licensing Examination (NMLE) in 
      Japan, administered by the Japanese Ministry of Health, Labour and Welfare in 
      2022, were used. All 400 questions were included. Exclusion criteria were figures 
      and tables that ChatGPT could not recognize; only text questions were extracted. 
      We instructed GPT-3.5 and GPT-4 to input the Japanese questions as they were and 
      to output the correct answers for each question. The output of ChatGPT was 
      verified by 2 general practice physicians. In case of discrepancies, they were 
      checked by another physician to make a final decision. The overall performance 
      was evaluated by calculating the percentage of correct answers output by GPT-3.5 
      and GPT-4. RESULTS: Of the 400 questions, 292 were analyzed. Questions containing 
      charts, which are not supported by ChatGPT, were excluded. The correct response 
      rate for GPT-4 was 81.5% (237/292), which was significantly higher than the rate 
      for GPT-3.5, 42.8% (125/292). Moreover, GPT-4 surpassed the passing standard 
      (&gt;72%) for the NMLE, indicating its potential as a diagnostic and therapeutic 
      decision aid for physicians. CONCLUSIONS: GPT-4 reached the passing standard for 
      the NMLE in Japan, entered in Japanese, although it is limited to written 
      questions. As the accelerated progress in the past few months has shown, the 
      performance of the AI will improve as the large language model continues to learn 
      more, and it may well become a decision support system for medical professionals 
      by providing more accurate information.
CI  - ©Yasutaka Yanagita, Daiki Yokokawa, Shun Uchida, Junsuke Tawara, Masatomi 
      Ikusaka. Originally published in JMIR Formative Research 
      (https://formative.jmir.org), 13.10.2023.
FAU - Yanagita, Yasutaka
AU  - Yanagita Y
AUID- ORCID: 0000-0002-9213-8247
AD  - Department of General Medicine, Chiba University Hospital, Chiba, Japan.
FAU - Yokokawa, Daiki
AU  - Yokokawa D
AUID- ORCID: 0000-0003-0944-8664
AD  - Department of General Medicine, Chiba University Hospital, Chiba, Japan.
FAU - Uchida, Shun
AU  - Uchida S
AUID- ORCID: 0000-0003-3408-9763
AD  - Department of General Medicine, Chiba University Hospital, Chiba, Japan.
FAU - Tawara, Junsuke
AU  - Tawara J
AUID- ORCID: 0000-0002-7842-5047
AD  - Department of Internal Medicine, Sanmu Medical Center, Chiba, Japan.
FAU - Ikusaka, Masatomi
AU  - Ikusaka M
AUID- ORCID: 0000-0002-9760-5596
AD  - Department of General Medicine, Chiba University Hospital, Chiba, Japan.
LA  - eng
PT  - Journal Article
DEP - 20231013
PL  - Canada
TA  - JMIR Form Res
JT  - JMIR formative research
JID - 101726394
PMC - PMC10612006
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - GPT-4
OT  - Japanese
OT  - NMLE
OT  - National Medical Licensing Examination
OT  - artificial intelligence
COIS- Conflicts of Interest: None declared.
EDAT- 2023/10/13 12:44
MHDA- 2023/10/13 12:45
PMCR- 2023/10/13
CRDT- 2023/10/13 11:53
PHST- 2023/04/09 00:00 [received]
PHST- 2023/10/03 00:00 [accepted]
PHST- 2023/06/21 00:00 [revised]
PHST- 2023/10/13 12:45 [medline]
PHST- 2023/10/13 12:44 [pubmed]
PHST- 2023/10/13 11:53 [entrez]
PHST- 2023/10/13 00:00 [pmc-release]
AID - v7i1e48023 [pii]
AID - 10.2196/48023 [doi]
PST - epublish
SO  - JMIR Form Res. 2023 Oct 13;7:e48023. doi: 10.2196/48023.

PMID- 37548997
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230824
IS  - 2369-3762 (Print)
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Aug 7
TI  - Performance of ChatGPT on the Situational Judgement Test-A Professional 
      Dilemmas-Based Examination for Doctors in the United Kingdom.
PG  - e48978
LID - 10.2196/48978 [doi]
LID - e48978
AB  - BACKGROUND: ChatGPT is a large language model that has performed well on 
      professional examinations in the fields of medicine, law, and business. However, 
      it is unclear how ChatGPT would perform on an examination assessing 
      professionalism and situational judgement for doctors. OBJECTIVE: We evaluated 
      the performance of ChatGPT on the Situational Judgement Test (SJT): a national 
      examination taken by all final-year medical students in the United Kingdom. This 
      examination is designed to assess attributes such as communication, teamwork, 
      patient safety, prioritization skills, professionalism, and ethics. METHODS: All 
      questions from the UK Foundation Programme Office's (UKFPO's) 2023 SJT practice 
      examination were inputted into ChatGPT. For each question, ChatGPT's answers and 
      rationales were recorded and assessed on the basis of the official UK Foundation 
      Programme Office scoring template. Questions were categorized into domains of 
      Good Medical Practice on the basis of the domains referenced in the rationales 
      provided in the scoring sheet. Questions without clear domain links were screened 
      by reviewers and assigned one or multiple domains. ChatGPT's overall performance, 
      as well as its performance across the domains of Good Medical Practice, was 
      evaluated. RESULTS: Overall, ChatGPT performed well, scoring 76% on the SJT but 
      scoring full marks on only a few questions (9%), which may reflect possible flaws 
      in ChatGPT's situational judgement or inconsistencies in the reasoning across 
      questions (or both) in the examination itself. ChatGPT demonstrated consistent 
      performance across the 4 outlined domains in Good Medical Practice for doctors. 
      CONCLUSIONS: Further research is needed to understand the potential applications 
      of large language models, such as ChatGPT, in medical education for standardizing 
      questions and providing consistent rationales for examinations assessing 
      professionalism and ethics.
CI  - ©Robin J Borchert, Charlotte R Hickman, Jack Pepys, Timothy J Sadler. Originally 
      published in JMIR Medical Education (https://mededu.jmir.org), 07.08.2023.
FAU - Borchert, Robin J
AU  - Borchert RJ
AUID- ORCID: 0000-0002-4673-9746
AD  - Department of Radiology, University of Cambridge, Cambridge, United Kingdom.
AD  - Department of Radiology, Addenbrooke's Hospital, Cambridge University Hospitals 
      NHS Foundation Trust, Cambridge, United Kingdom.
FAU - Hickman, Charlotte R
AU  - Hickman CR
AUID- ORCID: 0000-0003-3228-1479
AD  - Department of General Medicine, Lister Hospital, East and North Hertfordshire NHS 
      Trust, Stevenage, United Kingdom.
FAU - Pepys, Jack
AU  - Pepys J
AUID- ORCID: 0000-0002-1441-0145
AD  - Department of Biomedical Sciences, Humanitas University, Milan, Italy.
FAU - Sadler, Timothy J
AU  - Sadler TJ
AUID- ORCID: 0000-0003-3710-3137
AD  - Department of Radiology, Addenbrooke's Hospital, Cambridge University Hospitals 
      NHS Foundation Trust, Cambridge, United Kingdom.
LA  - eng
PT  - Journal Article
DEP - 20230807
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
PMC - PMC10442724
OTO - NOTNLM
OT  - ChatGPT
OT  - SJT
OT  - Situational Judgement Test
OT  - artificial intelligence
OT  - chatbot
OT  - communication
OT  - exam
OT  - examination
OT  - judgement
OT  - language model
OT  - language models
OT  - medical education
OT  - reasoning
COIS- Conflicts of Interest: None declared.
EDAT- 2023/08/07 13:10
MHDA- 2023/08/07 13:11
PMCR- 2023/08/07
CRDT- 2023/08/07 11:53
PHST- 2023/05/16 00:00 [received]
PHST- 2023/07/25 00:00 [accepted]
PHST- 2023/06/30 00:00 [revised]
PHST- 2023/08/07 13:11 [medline]
PHST- 2023/08/07 13:10 [pubmed]
PHST- 2023/08/07 11:53 [entrez]
PHST- 2023/08/07 00:00 [pmc-release]
AID - v9i1e48978 [pii]
AID - 10.2196/48978 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Aug 7;9:e48978. doi: 10.2196/48978.

PMID- 38502861
OWN - NLM
STAT- Publisher
LR  - 20240319
IS  - 1743-9159 (Electronic)
IS  - 1743-9159 (Linking)
DP  - 2024 Mar 19
TI  - ChatGPT in medicine: prospects and challenges: a review article.
LID - 10.1097/JS9.0000000000001312 [doi]
AB  - It has been a year since the launch of Chat Generator Pre-Trained Transformer 
      (ChatGPT), a generative artificial intelligence (AI) program. The introduction of 
      this cross-generational product initially brought a huge shock to people with its 
      incredible potential, and then aroused increasing concerns among people. In the 
      field of medicine, researchers have extensively explored the possible 
      applications of ChatGPT and achieved numerous satisfactory results. However, 
      opportunities and issues always come together. Problems have also been exposed 
      during the applications of ChatGPT, requiring cautious handling, thorough 
      consideration and further guidelines for safe use. Here, we summarized the 
      potential applications of ChatGPT in the medical field, including revolutionizing 
      healthcare consultation, assisting patient management and treatment, transforming 
      medical education and facilitating clinical research. Meanwhile, we also 
      enumerated researchers' concerns arising along with its broad and satisfactory 
      applications. As it is irreversible that AI will gradually permeate every aspect 
      of modern life, we hope that this review can not only promote people's 
      understanding of the potential applications of ChatGPT in the future, but also 
      remind them to be more cautious about this "Pandora's Box" in the medical field. 
      It is necessary to establish normative guidelines for its safe use in the medical 
      field as soon as possible.
CI  - Copyright © 2024 The Author(s). Published by Wolters Kluwer Health, Inc.
FAU - Tan, Songtao
AU  - Tan S
AD  - Plastic Surgery Hospital, Chinese Academy of Medical Sciences and Peking Union 
      Medical College, Shijingshan, Beijing 100144, China.
FAU - Xin, Xin
AU  - Xin X
FAU - Wu, Di
AU  - Wu D
LA  - eng
PT  - Journal Article
DEP - 20240319
PL  - United States
TA  - Int J Surg
JT  - International journal of surgery (London, England)
JID - 101228232
SB  - IM
EDAT- 2024/03/19 18:42
MHDA- 2024/03/19 18:42
CRDT- 2024/03/19 15:23
PHST- 2024/01/23 00:00 [received]
PHST- 2024/02/26 00:00 [accepted]
PHST- 2024/03/19 18:42 [medline]
PHST- 2024/03/19 18:42 [pubmed]
PHST- 2024/03/19 15:23 [entrez]
AID - 01279778-990000000-01226 [pii]
AID - 10.1097/JS9.0000000000001312 [doi]
PST - aheadofprint
SO  - Int J Surg. 2024 Mar 19. doi: 10.1097/JS9.0000000000001312.

PMID- 38109889
OWN - NLM
STAT- Publisher
LR  - 20231218
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Linking)
DP  - 2023 Dec 18
TI  - Benchmarking the symptom-checking capabilities of ChatGPT for a broad range of 
      diseases.
LID - ocad245 [pii]
LID - 10.1093/jamia/ocad245 [doi]
AB  - OBJECTIVE: This study evaluates ChatGPT's symptom-checking accuracy across a 
      broad range of diseases using the Mayo Clinic Symptom Checker patient service as 
      a benchmark. METHODS: We prompted ChatGPT with symptoms of 194 distinct diseases. 
      By comparing its predictions with expectations, we calculated a relative 
      comparative score (RCS) to gauge accuracy. RESULTS: ChatGPT's GPT-4 model 
      achieved an average RCS of 78.8%, outperforming the GPT-3.5-turbo by 10.5%. Some 
      specialties scored above 90%. DISCUSSION: The test set, although extensive, was 
      not exhaustive. Future studies should include a more comprehensive disease 
      spectrum. CONCLUSION: ChatGPT exhibits high accuracy in symptom checking for a 
      broad range of diseases, showcasing its potential as a medical training tool in 
      learning health systems to enhance care quality and address health disparities.
CI  - © The Author(s) 2023. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association. All rights reserved. For permissions, 
      please email: journals.permissions@oup.com.
FAU - Chen, Anjun
AU  - Chen A
AUID- ORCID: 0000-0003-4209-8301
AD  - Health Sciences, ELHS Institute, Palo Alto, CA 94306, United States.
AD  - LHS Tech Forum Initiative, Learning Health Community, Palo Alto, CA 94306, United 
      States.
FAU - Chen, Drake O
AU  - Chen DO
AD  - LHS Tech Forum Initiative, Learning Health Community, Palo Alto, CA 94306, United 
      States.
FAU - Tian, Lu
AU  - Tian L
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA 94305, 
      United States.
LA  - eng
PT  - Journal Article
DEP - 20231218
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - benchmarking
OT  - learning health system
OT  - medical training
OT  - symptom checking
EDAT- 2023/12/19 00:41
MHDA- 2023/12/19 00:41
CRDT- 2023/12/18 18:44
PHST- 2023/08/21 00:00 [received]
PHST- 2023/11/17 00:00 [revised]
PHST- 2023/12/04 00:00 [accepted]
PHST- 2023/12/19 00:41 [medline]
PHST- 2023/12/19 00:41 [pubmed]
PHST- 2023/12/18 18:44 [entrez]
AID - 7477862 [pii]
AID - 10.1093/jamia/ocad245 [doi]
PST - aheadofprint
SO  - J Am Med Inform Assoc. 2023 Dec 18:ocad245. doi: 10.1093/jamia/ocad245.

PMID- 38021639
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231201
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 10
DP  - 2023 Oct
TI  - Is ChatGPT's Knowledge and Interpretative Ability Comparable to First 
      Professional MBBS (Bachelor of Medicine, Bachelor of Surgery) Students of India 
      in Taking a Medical Biochemistry Examination?
PG  - e47329
LID - 10.7759/cureus.47329 [doi]
LID - e47329
AB  - Introduction ChatGPT is a large language model (LLM)-based chatbot that uses 
      natural language processing to create humanlike conversational dialogue. It has 
      created a significant impact on the entire global landscape, especially in 
      sectors like finance and banking, e-commerce, education, legal, human resources 
      (HR), and recruitment since its inception. There have been multiple ongoing 
      controversies regarding the seamless integration of ChatGPT with the healthcare 
      system because of its factual accuracy, lack of experience, lack of clarity, 
      expertise, and above all, lack of empathy. Our study seeks to compare ChatGPT's 
      knowledge and interpretative abilities with those of first-year medical students 
      in India in the subject of medical biochemistry. Materials and methods A total of 
      79 questions (40 multiple choice questions and 39 subjective questions) of 
      medical biochemistry were set for Phase 1, block II term examination. Chat GPT 
      was enrolled as the 101st student in the class. The questions were entered into 
      ChatGPT's interface and responses were noted. The response time for the 
      multiple-choice questions (MCQs) asked was also noted. The answers given by 
      ChatGPT&nbsp;and 100 students of the class were checked by two subject experts, and 
      marks were given according to the quality of answers. Marks obtained by the AI 
      chatbot were compared with the marks obtained by the students. Results ChatGPT 
      scored 140 marks out of 200 and outperformed almost all the students and ranked 
      fifth in the class. It scored very well in information-based MCQs (92%) and 
      descriptive logical reasoning (80%), whereas performed poorly in descriptive 
      clinical scenario-based questions (52%). In terms of time taken to respond&nbsp;to the 
      MCQs, it took significantly more time to answer&nbsp;logical reasoning MCQs than 
      simple information-based MCQs (3.10±0.882 sec vs. 2.02±0.477 sec, p&lt;0.005). 
      Conclusions ChatGPT was able to outperform almost all the students in the subject 
      of medical biochemistry. If the ethical issues are dealt with efficiently, these 
      LLMs&nbsp;have a huge potential to be used in teaching and learning methods of modern 
      medicine by&nbsp;students successfully.
CI  - Copyright © 2023, Ghosh et al.
FAU - Ghosh, Abhra
AU  - Ghosh A
AD  - Biochemistry, Dayanand Medical College and Hospital, Ludhiana, IND.
FAU - Maini Jindal, Nandita
AU  - Maini Jindal N
AD  - Biochemistry, Dayanand Medical College and Hospital, Ludhiana, IND.
FAU - Gupta, Vikram K
AU  - Gupta VK
AD  - Community Medicine, Dayanand Medical College, Ludhiana, IND.
FAU - Bansal, Ekta
AU  - Bansal E
AD  - Biochemistry, Dayanand Medical College and Hospital, Ludhiana, IND.
FAU - Kaur Bajwa, Navjot
AU  - Kaur Bajwa N
AD  - Biochemistry, Dayanand Medical College and Hospital, Ludhiana, IND.
FAU - Sett, Abhishek
AU  - Sett A
AD  - Healthcare, Deloitte Consulting US India Pvt Ltd, Bangalore, IND.
LA  - eng
PT  - Journal Article
DEP - 20231019
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10657167
OTO - NOTNLM
OT  - ai-based education
OT  - artificial intelligence
OT  - chatgpt
OT  - medical biochemistry
OT  - medical education
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/11/29 18:41
MHDA- 2023/11/29 18:42
PMCR- 2023/10/19
CRDT- 2023/11/29 15:09
PHST- 2023/10/19 00:00 [accepted]
PHST- 2023/11/29 18:42 [medline]
PHST- 2023/11/29 18:41 [pubmed]
PHST- 2023/11/29 15:09 [entrez]
PHST- 2023/10/19 00:00 [pmc-release]
AID - 10.7759/cureus.47329 [doi]
PST - epublish
SO  - Cureus. 2023 Oct 19;15(10):e47329. doi: 10.7759/cureus.47329. eCollection 2023 
      Oct.

PMID- 38020045
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231201
IS  - 2473-974X (Electronic)
IS  - 2473-974X (Linking)
VI  - 7
IP  - 4
DP  - 2023 Oct-Dec
TI  - Evaluating the Current Ability of ChatGPT to Assist in Professional 
      Otolaryngology Education.
PG  - e94
LID - 10.1002/oto2.94 [doi]
LID - e94
AB  - OBJECTIVE: To quantify ChatGPT's concordance with expert Otolaryngologists when 
      posed with high-level questions that require blending rote memorization and 
      critical thinking. STUDY DESIGN: Cross-sectional survey. SETTING: OpenAI's 
      ChatGPT-3.5 Platform. METHODS: Two board-certified otolaryngologists (HZ, RS) 
      input 2 sets of 30 text-based questions (open-ended and single-answer 
      multiple-choice) into the ChatGPT-3.5 model. Responses were rated on a scale 
      (correct, partially correct, incorrect) by each Otolaryngologist working 
      simultaneously with the AI model. Interrater agreement percentage was based on 
      binomial distribution for calculating the 95% confidence intervals and performing 
      significance tests. Statistical significance was defined as P &lt; .05 for 2-sided 
      tests. RESULTS: In testing open-ended questions, the ChatGPT model had 56.7% of 
      initially answering questions with complete accuracy, and 86.7% chance of answer 
      with some accuracy (corrected agreement = 80.1%; P &lt; .001). For repeat questions, 
      ChatGPT improved to 73.3% with complete accuracy and 96.7% with some accuracy 
      (corrected agreement = 88.8%; P &lt; .001). For multiple-choice questions, the 
      ChatGPT model performed substantially worse (43.3% correct). CONCLUSION: ChatGPT 
      currently does not provide reliably accurate responses to sophisticated questions 
      in Otolaryngology. Professional societies must be aware of the potential of this 
      tool and prevent unscrupulous use during test-taking situations and consider 
      guidelines for clinical scenarios. Expert clinical oversight is still necessary 
      for myriad use cases (eg, hallucination).
CI  - © 2023 The Authors. OTO Open published by Wiley Periodicals LLC on behalf of 
      American Academy of Otolaryngology–Head and Neck Surgery Foundation.
FAU - Zalzal, Habib G
AU  - Zalzal HG
AUID- ORCID: 0000-0002-0777-977X
AD  - Division of Otolaryngology-Head and Neck Surgery Children's National Hospital 
      Washington District of Columbia USA.
FAU - Cheng, Jenhao
AU  - Cheng J
AD  - Quality, Safety, Analytics Children's National Hospital Washington District of 
      Columbia USA.
FAU - Shah, Rahul K
AU  - Shah RK
AD  - Division of Otolaryngology-Head and Neck Surgery Children's National Hospital 
      Washington District of Columbia USA.
LA  - eng
PT  - Journal Article
DEP - 20231122
PL  - United States
TA  - OTO Open
JT  - OTO open
JID - 101717942
PMC - PMC10663981
OTO - NOTNLM
OT  - ChatGPT
OT  - OpenAI
OT  - artificial intelligence
OT  - continuing medical education
OT  - large language model
OT  - machine learning
OT  - maintenance of certification
COIS- None.
EDAT- 2023/11/29 18:42
MHDA- 2023/11/29 18:43
PMCR- 2023/11/22
CRDT- 2023/11/29 14:38
PHST- 2023/08/28 00:00 [received]
PHST- 2023/10/11 00:00 [revised]
PHST- 2023/11/04 00:00 [accepted]
PHST- 2023/11/29 18:43 [medline]
PHST- 2023/11/29 18:42 [pubmed]
PHST- 2023/11/29 14:38 [entrez]
PHST- 2023/11/22 00:00 [pmc-release]
AID - OTO294 [pii]
AID - 10.1002/oto2.94 [doi]
PST - epublish
SO  - OTO Open. 2023 Nov 22;7(4):e94. doi: 10.1002/oto2.94. eCollection 2023 Oct-Dec.

PMID- 37061595
OWN - NLM
STAT- MEDLINE
DCOM- 20230615
LR  - 20230615
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 51
IP  - 7
DP  - 2023 Jul
TI  - ChatGPT and the Future of Health Policy Analysis: Potential and Pitfalls of Using 
      ChatGPT in Policymaking.
PG  - 1357-1359
LID - 10.1007/s10439-023-03204-2 [doi]
AB  - Scholars increasingly rely on new artificial intelligence models for convenience 
      and simple access to necessities due to the rapid evolution of scientific 
      literature and technology. The invention of ChatGPT by OpenAI stands out as a key 
      example of how significant advances in large language model technology have 
      recently changed the field of artificial intelligence (AI). Since ChatGPT's 
      development, it has been tested by multiple sectors on various topics to see how 
      well it functions in a natural and conversational mode. The crucial question is 
      how much ChatGPT can influence global health policy analysis. In this article, 
      the researcher briefly explains ChatGPT's potential and the difficulties that 
      users, such as researchers or policymakers, may continue to face.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Sifat, Ridwan Islam
AU  - Sifat RI
AUID- ORCID: 0000-0001-9897-0870
AD  - School of Public Policy, University of Maryland, Baltimore County, Baltimore, MD, 
      21250, USA. rsifat1@umbc.edu.
LA  - eng
PT  - Letter
DEP - 20230415
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - *Artificial Intelligence
MH  - *Policy Making
MH  - Health Policy
MH  - Technology
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Global health policy
OT  - Policymaking
EDAT- 2023/04/16 06:00
MHDA- 2023/06/15 06:41
CRDT- 2023/04/15 23:18
PHST- 2023/04/06 00:00 [received]
PHST- 2023/04/11 00:00 [accepted]
PHST- 2023/06/15 06:41 [medline]
PHST- 2023/04/16 06:00 [pubmed]
PHST- 2023/04/15 23:18 [entrez]
AID - 10.1007/s10439-023-03204-2 [pii]
AID - 10.1007/s10439-023-03204-2 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2023 Jul;51(7):1357-1359. doi: 10.1007/s10439-023-03204-2. Epub 
      2023 Apr 15.

PMID- 37728984
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231007
IS  - 2368-7959 (Print)
IS  - 2368-7959 (Electronic)
IS  - 2368-7959 (Linking)
VI  - 10
DP  - 2023 Sep 20
TI  - Suicide Risk Assessments Through the Eyes of ChatGPT-3.5 Versus ChatGPT-4: 
      Vignette Study.
PG  - e51232
LID - 10.2196/51232 [doi]
LID - e51232
AB  - BACKGROUND: ChatGPT, a linguistic artificial intelligence (AI) model engineered 
      by OpenAI, offers prospective contributions to mental health professionals. 
      Although having significant theoretical implications, ChatGPT's practical 
      capabilities, particularly regarding suicide prevention, have not yet been 
      substantiated. OBJECTIVE: The study's aim was to evaluate ChatGPT's ability to 
      assess suicide risk, taking into consideration 2 discernable factors-perceived 
      burdensomeness and thwarted belongingness-over a 2-month period. In addition, we 
      evaluated whether ChatGPT-4 more accurately evaluated suicide risk than did 
      ChatGPT-3.5. METHODS: ChatGPT was tasked with assessing a vignette that depicted 
      a hypothetical patient exhibiting differing degrees of perceived burdensomeness 
      and thwarted belongingness. The assessments generated by ChatGPT were 
      subsequently contrasted with standard evaluations rendered by mental health 
      professionals. Using both ChatGPT-3.5 and ChatGPT-4 (May 24, 2023), we executed 3 
      evaluative procedures in June and July 2023. Our intent was to scrutinize 
      ChatGPT-4's proficiency in assessing various facets of suicide risk in relation 
      to the evaluative abilities of both mental health professionals and an earlier 
      version of ChatGPT-3.5 (March 14 version). RESULTS: During the period of June and 
      July 2023, we found that the likelihood of suicide attempts as evaluated by 
      ChatGPT-4 was similar to the norms of mental health professionals (n=379) under 
      all conditions (average Z score of 0.01). Nonetheless, a pronounced discrepancy 
      was observed regarding the assessments performed by ChatGPT-3.5 (May version), 
      which markedly underestimated the potential for suicide attempts, in comparison 
      to the assessments carried out by the mental health professionals (average Z 
      score of -0.83). The empirical evidence suggests that ChatGPT-4's evaluation of 
      the incidence of suicidal ideation and psychache was higher than that of the 
      mental health professionals (average Z score of 0.47 and 1.00, respectively). 
      Conversely, the level of resilience as assessed by both ChatGPT-4 and ChatGPT-3.5 
      (both versions) was observed to be lower in comparison to the assessments offered 
      by mental health professionals (average Z score of -0.89 and -0.90, 
      respectively). CONCLUSIONS: The findings suggest that ChatGPT-4 estimates the 
      likelihood of suicide attempts in a manner akin to evaluations provided by 
      professionals. In terms of recognizing suicidal ideation, ChatGPT-4 appears to be 
      more precise. However, regarding psychache, there was an observed overestimation 
      by ChatGPT-4, indicating a need for further research. These results have 
      implications regarding ChatGPT-4's potential to support gatekeepers, patients, 
      and even mental health professionals' decision-making. Despite the clinical 
      potential, intensive follow-up studies are necessary to establish the use of 
      ChatGPT-4's capabilities in clinical practice. The finding that ChatGPT-3.5 
      frequently underestimates suicide risk, especially in severe cases, is 
      particularly troubling. It indicates that ChatGPT may downplay one's actual 
      suicide risk level.
CI  - ©Inbar Levkovich, Zohar Elyoseph. Originally published in JMIR Mental Health 
      (https://mental.jmir.org), 20.09.2023.
FAU - Levkovich, Inbar
AU  - Levkovich I
AUID- ORCID: 0000-0003-1582-3889
AD  - Oranim Academic College, Faculty of Graduate Studies, Kiryat Tivon, Israel.
FAU - Elyoseph, Zohar
AU  - Elyoseph Z
AUID- ORCID: 0000-0002-5717-4074
AD  - Department of Psychology and Educational Counseling, The Center for 
      Psychobiological Research, Max Stern Yezreel Valley College, Emek Yezreel, 
      Israel.
AD  - Department of Brain Sciences, Faculty of Medicine, Imperial College London, 
      London, United Kingdom.
LA  - eng
PT  - Journal Article
DEP - 20230920
PL  - Canada
TA  - JMIR Ment Health
JT  - JMIR mental health
JID - 101658926
PMC - PMC10551796
OTO - NOTNLM
OT  - ChatGPT
OT  - NLP
OT  - artificial intelligence
OT  - assessment
OT  - assessments
OT  - diagnosis
OT  - mental
OT  - natural language processing
OT  - psychological
OT  - psychological assessment
OT  - risk
OT  - risk assessment
OT  - self-harm
OT  - suicidal
OT  - suicide
OT  - suicide risk
OT  - text vignette
OT  - vignette
OT  - vignettes
COIS- Conflicts of Interest: None declared.
EDAT- 2023/09/20 18:42
MHDA- 2023/09/20 18:43
PMCR- 2023/09/20
CRDT- 2023/09/20 12:17
PHST- 2023/07/25 00:00 [received]
PHST- 2023/08/24 00:00 [accepted]
PHST- 2023/08/22 00:00 [revised]
PHST- 2023/09/20 18:43 [medline]
PHST- 2023/09/20 18:42 [pubmed]
PHST- 2023/09/20 12:17 [entrez]
PHST- 2023/09/20 00:00 [pmc-release]
AID - v10i1e51232 [pii]
AID - 10.2196/51232 [doi]
PST - epublish
SO  - JMIR Ment Health. 2023 Sep 20;10:e51232. doi: 10.2196/51232.

PMID- 38096014
OWN - NLM
STAT- MEDLINE
DCOM- 20231216
LR  - 20240110
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 25
DP  - 2023 Dec 14
TI  - Potential and Limitations of ChatGPT 3.5 and 4.0 as a Source of COVID-19 
      Information: Comprehensive Comparative Analysis of Generative and Authoritative 
      Information.
PG  - e49771
LID - 10.2196/49771 [doi]
LID - e49771
AB  - BACKGROUND: The COVID-19 pandemic, caused by the SARS-CoV-2 virus, has 
      necessitated reliable and authoritative information for public guidance. The 
      World Health Organization (WHO) has been a primary source of such information, 
      disseminating it through a question and answer format on its official website. 
      Concurrently, ChatGPT 3.5 and 4.0, a deep learning-based natural language 
      generation system, has shown potential in generating diverse text types based on 
      user input. OBJECTIVE: This study evaluates the accuracy of COVID-19 information 
      generated by ChatGPT 3.5 and 4.0, assessing its potential as a supplementary 
      public information source during the pandemic. METHODS: We extracted 487 
      COVID-19-related questions from the WHO's official website and used ChatGPT 3.5 
      and 4.0 to generate corresponding answers. These generated answers were then 
      compared against the official WHO responses for evaluation. Two clinical experts 
      scored the generated answers on a scale of 0-5 across 4 dimensions-accuracy, 
      comprehensiveness, relevance, and clarity-with higher scores indicating better 
      performance in each dimension. The WHO responses served as the reference for this 
      assessment. Additionally, we used the BERT (Bidirectional Encoder Representations 
      from Transformers) model to generate similarity scores (0-1) between the 
      generated and official answers, providing a dual validation mechanism. RESULTS: 
      The mean (SD) scores for ChatGPT 3.5-generated answers were 3.47 (0.725) for 
      accuracy, 3.89 (0.719) for comprehensiveness, 4.09 (0.787) for relevance, and 
      3.49 (0.809) for clarity. For ChatGPT 4.0, the mean (SD) scores were 4.15 
      (0.780), 4.47 (0.641), 4.56 (0.600), and 4.09 (0.698), respectively. All 
      differences were statistically significant (P&lt;.001), with ChatGPT 4.0 
      outperforming ChatGPT 3.5. The BERT model verification showed mean (SD) 
      similarity scores of 0.83 (0.07) for ChatGPT 3.5 and 0.85 (0.07) for ChatGPT 4.0 
      compared with the official WHO answers. CONCLUSIONS: ChatGPT 3.5 and 4.0 can 
      generate accurate and relevant COVID-19 information to a certain extent. However, 
      compared with official WHO responses, gaps and deficiencies exist. Thus, users of 
      ChatGPT 3.5 and 4.0 should also reference other reliable information sources to 
      mitigate potential misinformation risks. Notably, ChatGPT 4.0 outperformed 
      ChatGPT 3.5 across all evaluated dimensions, a finding corroborated by BERT model 
      validation.
CI  - ©Guoyong Wang, Kai Gao, Qianyang Liu, Yuxin Wu, Kaijun Zhang, Wei Zhou, Chunbao 
      Guo. Originally published in the Journal of Medical Internet Research 
      (https://www.jmir.org), 14.12.2023.
FAU - Wang, Guoyong
AU  - Wang G
AUID- ORCID: 0000-0002-8224-7706
AD  - Children's Hospital, Chongqing Medical University, Chongqing, China.
AD  - Women and Children's Hospital, Chongqing Medical University, Chongqing, China.
FAU - Gao, Kai
AU  - Gao K
AUID- ORCID: 0000-0002-9132-3096
AD  - Guangzhou Women and Children's Medical Center, Guangzhou Medical University, 
      Guangzhou, China.
FAU - Liu, Qianyang
AU  - Liu Q
AUID- ORCID: 0009-0007-8405-7395
AD  - Women and Children's Hospital, Chongqing Medical University, Chongqing, China.
FAU - Wu, Yuxin
AU  - Wu Y
AUID- ORCID: 0000-0002-9334-9820
AD  - Children's Hospital, Chongqing Medical University, Chongqing, China.
FAU - Zhang, Kaijun
AU  - Zhang K
AUID- ORCID: 0000-0002-1490-775X
AD  - Children's Hospital, Chongqing Medical University, Chongqing, China.
FAU - Zhou, Wei
AU  - Zhou W
AUID- ORCID: 0000-0001-7795-3166
AD  - Women and Children's Hospital, Chongqing Medical University, Chongqing, China.
FAU - Guo, Chunbao
AU  - Guo C
AUID- ORCID: 0000-0001-5121-9377
AD  - Women and Children's Hospital, Chongqing Medical University, Chongqing, China.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20231214
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - *COVID-19
MH  - SARS-CoV-2
MH  - Pandemics
MH  - Language
MH  - World Health Organization
PMC - PMC10755661
OTO - NOTNLM
OT  - AI
OT  - COVID-19
OT  - ChatGPT 3.5
OT  - ChatGPT 4.0
OT  - artificial intelligence
OT  - information retrieval
OT  - pandemic
OT  - public health
COIS- Conflicts of Interest: None declared.
EDAT- 2023/12/14 12:42
MHDA- 2023/12/17 09:43
PMCR- 2023/12/14
CRDT- 2023/12/14 11:54
PHST- 2023/06/08 00:00 [received]
PHST- 2023/11/16 00:00 [accepted]
PHST- 2023/10/01 00:00 [revised]
PHST- 2023/12/17 09:43 [medline]
PHST- 2023/12/14 12:42 [pubmed]
PHST- 2023/12/14 11:54 [entrez]
PHST- 2023/12/14 00:00 [pmc-release]
AID - v25i1e49771 [pii]
AID - 10.2196/49771 [doi]
PST - epublish
SO  - J Med Internet Res. 2023 Dec 14;25:e49771. doi: 10.2196/49771.

PMID- 37095384
OWN - NLM
STAT- MEDLINE
DCOM- 20231023
LR  - 20240205
IS  - 1432-5241 (Electronic)
IS  - 0364-216X (Print)
IS  - 0364-216X (Linking)
VI  - 47
IP  - 5
DP  - 2023 Oct
TI  - Aesthetic Surgery Advice and Counseling from Artificial Intelligence: A 
      Rhinoplasty Consultation with ChatGPT.
PG  - 1985-1993
LID - 10.1007/s00266-023-03338-7 [doi]
AB  - BACKGROUND: ChatGPT is an open-source artificial large language model that uses 
      deep learning to produce human-like text dialogue. This observational study 
      evaluated the ability of ChatGPT to provide informative and accurate responses to 
      a set of hypothetical questions designed to simulate an initial consultation 
      about rhinoplasty. METHODS: Nine questions were prompted to ChatGPT on 
      rhinoplasty. The questions were sourced from a checklist published by the 
      American Society of Plastic Surgeons, and the responses were assessed for 
      accessibility, informativeness, and accuracy by Specialist Plastic Surgeons with 
      extensive experience in rhinoplasty. RESULTS: ChatGPT was able to provide 
      coherent and easily comprehensible answers to the questions posed, demonstrating 
      its understanding of natural language in a health-specific context. The responses 
      emphasized the importance of an individualized approach, particularly in 
      aesthetic plastic surgery. However, the study also highlighted ChatGPT's 
      limitations in providing more detailed or personalized advice. CONCLUSION: 
      Overall, the results suggest that ChatGPT has the potential to provide valuable 
      information to patients in a medical context, particularly in situations where 
      patients may be hesitant to seek advice from medical professionals or where 
      access to medical advice is limited. However, further research is needed to 
      determine the scope and limitations of AI language models in this domain and to 
      assess the potential benefits and risks associated with their use. LEVEL OF 
      EVIDENCE V: Observational study under respected authorities. This journal 
      requires that authors assign a level of evidence to each article. For a full 
      description of these Evidence-Based Medicine ratings, please refer to the Table 
      of Contents or the online Instructions to Authors www.springer.com/00266 .
CI  - © 2023. Crown.
FAU - Xie, Yi
AU  - Xie Y
AD  - Department of Plastic Surgery, Peninsula Health, Melbourne, Victoria, 3199, 
      Australia.
FAU - Seth, Ishith
AU  - Seth I
AUID- ORCID: 0000-0001-5444-8925
AD  - Department of Plastic Surgery, Peninsula Health, Melbourne, Victoria, 3199, 
      Australia. ishithseth1@gmail.com.
AD  - Faculty of Medicine, Monash University, Melbourne, Victoria, 3004, Australia. 
      ishithseth1@gmail.com.
FAU - Hunter-Smith, David J
AU  - Hunter-Smith DJ
AD  - Department of Plastic Surgery, Peninsula Health, Melbourne, Victoria, 3199, 
      Australia.
AD  - Faculty of Medicine, Monash University, Melbourne, Victoria, 3004, Australia.
FAU - Rozen, Warren M
AU  - Rozen WM
AD  - Department of Plastic Surgery, Peninsula Health, Melbourne, Victoria, 3199, 
      Australia.
AD  - Faculty of Medicine, Monash University, Melbourne, Victoria, 3004, Australia.
FAU - Ross, Richard
AU  - Ross R
AD  - Department of Plastic Surgery, Peninsula Health, Melbourne, Victoria, 3199, 
      Australia.
FAU - Lee, Matthew
AU  - Lee M
AD  - Department of Plastic Surgery, Peninsula Health, Melbourne, Victoria, 3199, 
      Australia.
LA  - eng
PT  - Journal Article
PT  - Observational Study
DEP - 20230424
PL  - United States
TA  - Aesthetic Plast Surg
JT  - Aesthetic plastic surgery
JID - 7701756
SB  - IM
CIN - Aesthetic Plast Surg. 2023 Oct;47(5):2203-2204. PMID: 37212874
CIN - Aesthetic Plast Surg. 2023 Oct;47(5):2211-2212. PMID: 37256297
MH  - Humans
MH  - *Rhinoplasty
MH  - Artificial Intelligence
MH  - *Surgery, Plastic
MH  - Counseling
MH  - Esthetics
MH  - Referral and Consultation
PMC - PMC10581928
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Chatbot
OT  - Rhinoplasty
COIS- The authors declare that they have no conflicts of interest to disclose.
EDAT- 2023/04/25 00:41
MHDA- 2023/10/23 12:43
PMCR- 2023/04/24
CRDT- 2023/04/24 11:31
PHST- 2023/03/11 00:00 [received]
PHST- 2023/03/23 00:00 [accepted]
PHST- 2023/10/23 12:43 [medline]
PHST- 2023/04/25 00:41 [pubmed]
PHST- 2023/04/24 11:31 [entrez]
PHST- 2023/04/24 00:00 [pmc-release]
AID - 10.1007/s00266-023-03338-7 [pii]
AID - 3338 [pii]
AID - 10.1007/s00266-023-03338-7 [doi]
PST - ppublish
SO  - Aesthetic Plast Surg. 2023 Oct;47(5):1985-1993. doi: 10.1007/s00266-023-03338-7. 
      Epub 2023 Apr 24.

PMID- 37638266
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230829
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 8
DP  - 2023 Aug
TI  - Exploring the Potential and Limitations of Chat Generative Pre-trained 
      Transformer (ChatGPT) in Generating Board-Style Dermatology Questions: A 
      Qualitative Analysis.
PG  - e43717
LID - 10.7759/cureus.43717 [doi]
LID - e43717
AB  - This article investigates the limitations of Chat Generative Pre-trained 
      Transformer (ChatGPT), a language model developed by OpenAI, as a study tool in 
      dermatology. The study utilized ChatPDF, an application that integrates PDF files 
      with ChatGPT, to generate American Board of Dermatology Applied Exam 
      (ABD-AE)-style questions from continuing medical education articles from the 
      Journal of the American Board of Dermatology. A qualitative analysis of the 
      questions was conducted by two board-certified dermatologists, assessing 
      accuracy, complexity, and clarity. Out of 40 questions generated, only 16 (40%) 
      were deemed accurate and appropriate for ABD-AE study preparation. The remaining 
      questions exhibited limitations, including low complexity, lack of clarity, and 
      inaccuracies. The findings highlight the challenges faced by ChatGPT in 
      understanding the domain-specific knowledge required in dermatology. Moreover, 
      the model's inability to comprehend the context and generate high-quality 
      distractor options, as well as the absence of image generation capabilities, 
      further hinders its usefulness. The study emphasizes that while ChatGPT may aid 
      in generating simple questions, it cannot replace the expertise of dermatologists 
      and medical educators in developing high-quality, board-style questions that 
      effectively evaluate candidates' knowledge and reasoning abilities.
CI  - Copyright © 2023, Ayub et al.
FAU - Ayub, Ibraheim
AU  - Ayub I
AD  - Dermatology, A.T. Still University School of Osteopathic Medicine, Mesa, USA.
FAU - Hamann, Dathan
AU  - Hamann D
AD  - Dermatology, Dermatology Residency, HonorHealth, Scottsdale, USA.
FAU - Hamann, Carsten R
AU  - Hamann CR
AD  - Dermatology, HonorHealth Dermatology Residency, Scottsdale, USA.
AD  - Dermatology, Dartmouth-Hitchcock Medical Center, Lebanon, USA.
FAU - Davis, Matthew J
AU  - Davis MJ
AD  - Dermatology, Dartmouth-Hitchcock Medical Center, Lebanon, USA.
LA  - eng
PT  - Journal Article
DEP - 20230818
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10450251
OTO - NOTNLM
OT  - artificial intelligence in medicine
OT  - chatgpt
OT  - dermatology
OT  - medical education
OT  - multiple-choice questions
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/08/28 06:42
MHDA- 2023/08/28 06:43
PMCR- 2023/08/18
CRDT- 2023/08/28 05:02
PHST- 2023/08/17 00:00 [accepted]
PHST- 2023/08/28 06:43 [medline]
PHST- 2023/08/28 06:42 [pubmed]
PHST- 2023/08/28 05:02 [entrez]
PHST- 2023/08/18 00:00 [pmc-release]
AID - 10.7759/cureus.43717 [doi]
PST - epublish
SO  - Cureus. 2023 Aug 18;15(8):e43717. doi: 10.7759/cureus.43717. eCollection 2023 
      Aug.

PMID- 38305239
OWN - NLM
STAT- Publisher
LR  - 20240202
IS  - 1360-046X (Electronic)
IS  - 0268-8697 (Linking)
DP  - 2024 Feb 2
TI  - Can ChatGPT outperform a neurosurgical trainee? A prospective comparative study.
PG  - 1-10
LID - 10.1080/02688697.2024.2308222 [doi]
AB  - PURPOSE: This study aimed to compare the performance of ChatGPT, a large language 
      model (LLM), with human neurosurgical applicants in a neurosurgical national 
      selection interview, to assess the potential of artificial intelligence (AI) and 
      LLMs in healthcare and provide insights into their integration into the field. 
      METHODS: In a prospective comparative study, a set of neurosurgical national 
      selection-style interview questions were asked to eight human participants and 
      ChatGPT in an online interview. All participants were doctors currently 
      practicing in the UK who had applied for a neurosurgical National Training 
      Number. Interviews were recorded, anonymised, and scored by three neurosurgical 
      consultants with experience as interviewers for national selection. Answers 
      provided by ChatGPT were used as a template for a virtual interview. Interview 
      transcripts were subsequently scored by neurosurgical consultants using criteria 
      utilised in real national selection interviews. Overall interview score and 
      subdomain scores were compared between human participants and ChatGPT. RESULTS: 
      For overall score, ChatGPT fell behind six human competitors and did not achieve 
      a mean score higher than any individuals who achieved training positions. Several 
      factors, including factual inaccuracies and deviations from expected structure 
      and style may have contributed to ChatGPT's underperformance. CONCLUSIONS: LLMs 
      such as ChatGPT have huge potential for integration in healthcare. However, this 
      study emphasises the need for further development to address limitations and 
      challenges. While LLMs have not surpassed human performance yet, collaboration 
      between humans and AI systems holds promise for the future of healthcare.
FAU - Williams, Simon C
AU  - Williams SC
AUID- ORCID: 0000-0003-1770-1797
AD  - Department of Neurosurgery, St George's University Hospital, London, UK.
AD  - Wellcome/EPSRC Centre for Interventional and Surgical Sciences, University 
      College London, London, UK.
FAU - Starup-Hansen, Joachim
AU  - Starup-Hansen J
AD  - Wellcome/EPSRC Centre for Interventional and Surgical Sciences, University 
      College London, London, UK.
AD  - Department of Neurosurgery, National Hospital for Neurology and Neurosurgery, 
      London, UK.
FAU - Funnell, Jonathan P
AU  - Funnell JP
AD  - Department of Neurosurgery, St George's University Hospital, London, UK.
AD  - Wellcome/EPSRC Centre for Interventional and Surgical Sciences, University 
      College London, London, UK.
FAU - Hanrahan, John Gerrard
AU  - Hanrahan JG
AD  - Wellcome/EPSRC Centre for Interventional and Surgical Sciences, University 
      College London, London, UK.
AD  - Department of Neurosurgery, National Hospital for Neurology and Neurosurgery, 
      London, UK.
FAU - Valetopoulou, Alexandra
AU  - Valetopoulou A
AD  - Department of Neurosurgery, Imperial College Healthcare NHS Trust, London, UK.
FAU - Singh, Navneet
AU  - Singh N
AUID- ORCID: 0000-0001-8800-1961
AD  - Department of Neurosurgery, St George's University Hospital, London, UK.
FAU - Sinha, Saurabh
AU  - Sinha S
AD  - Department of Neurosurgery, Sheffield Teaching Hospitals, Sheffield, UK.
FAU - Muirhead, William R
AU  - Muirhead WR
AD  - Wellcome/EPSRC Centre for Interventional and Surgical Sciences, University 
      College London, London, UK.
AD  - Department of Neurosurgery, National Hospital for Neurology and Neurosurgery, 
      London, UK.
FAU - Marcus, Hani J
AU  - Marcus HJ
AD  - Wellcome/EPSRC Centre for Interventional and Surgical Sciences, University 
      College London, London, UK.
AD  - Department of Neurosurgery, National Hospital for Neurology and Neurosurgery, 
      London, UK.
LA  - eng
PT  - Journal Article
DEP - 20240202
PL  - England
TA  - Br J Neurosurg
JT  - British journal of neurosurgery
JID - 8800054
SB  - IM
OTO - NOTNLM
OT  - AI
OT  - Artificial intelligence
OT  - ChatGPT
OT  - healthcare
OT  - large language model
OT  - natural language processing
OT  - neurosurgery
EDAT- 2024/02/02 12:43
MHDA- 2024/02/02 12:43
CRDT- 2024/02/02 09:23
PHST- 2024/02/02 12:43 [medline]
PHST- 2024/02/02 12:43 [pubmed]
PHST- 2024/02/02 09:23 [entrez]
AID - 10.1080/02688697.2024.2308222 [doi]
PST - aheadofprint
SO  - Br J Neurosurg. 2024 Feb 2:1-10. doi: 10.1080/02688697.2024.2308222.

PMID- 37583313
OWN - NLM
STAT- Publisher
LR  - 20240221
IS  - 1748-5460 (Electronic)
IS  - 0022-2151 (Linking)
DP  - 2023 Aug 16
TI  - The role of ChatGPT in enhancing ENT surgical training - a trainees' perspective.
PG  - 1-7
LID - 10.1017/S0022215123001354 [doi]
AB  - OBJECTIVE: ChatGPT, developed by Open AI (November 2022) is a powerful artificial 
      intelligence language model, designed to produce human-like text from 
      user-written prompts. Prompts must give context-specific information to produce 
      valuable responses. Otolaryngology is a specialist field that sees limited 
      exposure during undergraduate and postgraduate education. Additionally, 
      otolaryngology trainees have seen a reduction in learning opportunities since the 
      coronavirus disease 2019 pandemic. METHOD: This article aims to give guidance on 
      optimising the ChatGPT system in the context of education for otolaryngology by 
      reviewing barriers to otolaryngology education and suggesting ways that ChatGPT 
      can overcome them by providing examples using the authors' experience. RESULTS: 
      Overall, the authors saw that ChatGPT demonstrated some useful qualities, 
      particularly with regards to assistance with communication skills and 
      individualised patient responses. CONCLUSION: Although ChatGPT cannot replace 
      traditional mentorship and practical surgical experience, it can serve as an 
      invaluable supplementary resource to education in otolaryngology.
FAU - Brennan, Laura
AU  - Brennan L
AUID- ORCID: 0009-0007-4722-0747
AD  - Department of ENT, St Michaels Hospital, University Hospitals Bristol and Weston, 
      Bristol, UK.
FAU - Balakumar, Ramkishan
AU  - Balakumar R
AD  - Department of ENT, St Michaels Hospital, University Hospitals Bristol and Weston, 
      Bristol, UK.
FAU - Bennett, Warren
AU  - Bennett W
AD  - Department of ENT, St Michaels Hospital, University Hospitals Bristol and Weston, 
      Bristol, UK.
LA  - eng
PT  - Journal Article
DEP - 20230816
PL  - England
TA  - J Laryngol Otol
JT  - The Journal of laryngology and otology
JID - 8706896
SB  - IM
OTO - NOTNLM
OT  - AI (artificial intelligence)
OT  - medical education
OT  - otolaryngology
OT  - training
EDAT- 2023/08/16 06:43
MHDA- 2023/08/16 06:43
CRDT- 2023/08/16 03:09
PHST- 2023/08/16 06:43 [pubmed]
PHST- 2023/08/16 06:43 [medline]
PHST- 2023/08/16 03:09 [entrez]
AID - S0022215123001354 [pii]
AID - 10.1017/S0022215123001354 [doi]
PST - aheadofprint
SO  - J Laryngol Otol. 2023 Aug 16:1-7. doi: 10.1017/S0022215123001354.

PMID- 38181176
OWN - NLM
STAT- MEDLINE
DCOM- 20240216
LR  - 20240329
IS  - 2152-2723 (Electronic)
IS  - 2152-2715 (Linking)
VI  - 27
IP  - 2
DP  - 2024 Feb
TI  - ChatGPT: Artificial Intelligence as a Potential Tool for Parents Seeking 
      Information About Autism.
PG  - 135-148
LID - 10.1089/cyber.2023.0202 [doi]
AB  - Autism Spectrum Disorder has seen a drastic increase in prevalence over the past 
      two decades, along with discourse rife with debates and misinformation. This 
      discourse has primarily taken place online, the main source of information for 
      parents seeking information about autism. One potential tool for navigating 
      information is ChatGPT-4, an artificial intelligence question and answer-style 
      communication program. Although ChatGPT shows great promise, no empirical work 
      has evaluated its viability as a tool for providing information about autism to 
      caregivers. The current study evaluated answers provided by ChatGPT, including 
      basic information about autism, myths/misconceptions, and resources. Our results 
      suggested that ChatGPT was largely correct, concise, and clear, but did not 
      provide much actionable advice, which was further limited by inaccurate 
      references and hyperlinks. The authors conclude that ChatGPT-4 is a viable tool 
      for parents seeking accurate information about autism, with opportunities for 
      improvement in actionability and reference accuracy.
FAU - McFayden, Tyler C
AU  - McFayden TC
AUID- ORCID: 0000-0001-8942-1562
AD  - Carolina Institute for Developmental Disabilities, University of North Carolina 
      at Chapel Hill, Carrboro, North Carolina, USA.
FAU - Bristol, Stephanie
AU  - Bristol S
AUID- ORCID: 0000-0002-2611-5290
AD  - Department of Health Sciences, University of North Carolina at Chapel Hill, 
      Chapel Hill, North Carolina, USA.
FAU - Putnam, Orla
AU  - Putnam O
AUID- ORCID: 0000-0002-2215-0021
AD  - Department of Health Sciences, University of North Carolina at Chapel Hill, 
      Chapel Hill, North Carolina, USA.
FAU - Harrop, Clare
AU  - Harrop C
AUID- ORCID: 0000-0003-3381-3473
AD  - Department of Health Sciences, University of North Carolina at Chapel Hill, 
      Chapel Hill, North Carolina, USA.
AD  - UNC TEACCH Autism Program, University of North Carolina at Chapel Hill, Carrboro, 
      North Carolina, USA.
LA  - eng
GR  - P50 HD103573/HD/NICHD NIH HHS/United States
GR  - T32 HD040127/HD/NICHD NIH HHS/United States
PT  - Journal Article
DEP - 20240105
PL  - United States
TA  - Cyberpsychol Behav Soc Netw
JT  - Cyberpsychology, behavior and social networking
JID - 101528721
SB  - IM
MH  - Humans
MH  - *Autistic Disorder
MH  - *Autism Spectrum Disorder
MH  - Artificial Intelligence
MH  - Information Seeking Behavior
MH  - Parents
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - autism spectrum disorder
OT  - misinformation
EDAT- 2024/01/05 18:41
MHDA- 2024/02/16 06:43
CRDT- 2024/01/05 14:43
PHST- 2024/02/16 06:43 [medline]
PHST- 2024/01/05 18:41 [pubmed]
PHST- 2024/01/05 14:43 [entrez]
AID - 10.1089/cyber.2023.0202 [doi]
PST - ppublish
SO  - Cyberpsychol Behav Soc Netw. 2024 Feb;27(2):135-148. doi: 
      10.1089/cyber.2023.0202. Epub 2024 Jan 5.

PMID- 37792344
OWN - NLM
STAT- MEDLINE
DCOM- 20240222
LR  - 20240222
IS  - 2768-3613 (Electronic)
IS  - 2768-3605 (Linking)
VI  - 30
IP  - 2
DP  - 2024 Feb
TI  - Can ChatGPT Provide Quality Information on Integrative Oncology? A Brief Report.
PG  - 196-205
LID - 10.1089/jicm.2023.0290 [doi]
AB  - This short report evaluated the accuracy and quality of information provided by 
      ChatGPT regarding the use of complementary and integrative medicine for cancer. 
      Using the QUality Evaluation Scoring Tool, a panel of 12 reviewers assessed 
      ChatGPT's responses to 8 questions. The study found that ChatGPT provided 
      moderate-quality responses that were relatively unbiased and not misleading. 
      However, the chatbot's inability to reference specific scientific studies was a 
      significant limitation. Patients with cancer should not rely on ChatGPT for 
      clinical advice until further systematic validation. Future studies should 
      examine how patients perceive ChatGPT's information and its impact on 
      communication with health care professionals.
FAU - Lam, Chun Sing
AU  - Lam CS
AD  - School of Pharmacy, Faculty of Medicine, Faculty of Medicine, The Chinese 
      University of Hong Kong, Hong Kong, China.
FAU - Hua, Rong
AU  - Hua R
AD  - School of Pharmacy, Faculty of Medicine, Faculty of Medicine, The Chinese 
      University of Hong Kong, Hong Kong, China.
FAU - Koon, Ho Kee
AU  - Koon HK
AD  - School of Chinese Medicine, and Faculty of Medicine, The Chinese University of 
      Hong Kong, Hong Kong, China.
FAU - Zhou, Keary Rui
AU  - Zhou KR
AD  - School of Pharmacy, Faculty of Medicine, Faculty of Medicine, The Chinese 
      University of Hong Kong, Hong Kong, China.
FAU - Lam, Teddy Tai Ning
AU  - Lam TTN
AD  - School of Pharmacy, Faculty of Medicine, Faculty of Medicine, The Chinese 
      University of Hong Kong, Hong Kong, China.
FAU - Lee, Chui Ping
AU  - Lee CP
AD  - School of Pharmacy, Faculty of Medicine, Faculty of Medicine, The Chinese 
      University of Hong Kong, Hong Kong, China.
FAU - Lin, Wai Ling
AU  - Lin WL
AD  - School of Chinese Medicine, and Faculty of Medicine, The Chinese University of 
      Hong Kong, Hong Kong, China.
FAU - Wong, Cho Lee
AU  - Wong CL
AD  - The Nethersole School of Nursing, Faculty of Medicine, The Chinese University of 
      Hong Kong, Hong Kong, China.
FAU - Lau, Yat Ming
AU  - Lau YM
AD  - Department of Medical Oncology, The Kinghorn Cancer Centre, St Vincent's 
      Hospital, Sydney, Australia.
FAU - Loong, Herbert Ho-Fung
AU  - Loong HH
AD  - Department of Clinical Oncology and The Chinese University of Hong Kong, Hong 
      Kong, China.
FAU - Chung, Vincent Chi-Ho
AU  - Chung VC
AUID- ORCID: 0000-0002-5947-4492
AD  - School of Chinese Medicine, and Faculty of Medicine, The Chinese University of 
      Hong Kong, Hong Kong, China.
AD  - Jockey Club School of Public Health and Primary Care, Faculty of Medicine, The 
      Chinese University of Hong Kong, Hong Kong, China.
FAU - Cheung, Yin Ting
AU  - Cheung YT
AUID- ORCID: 0000-0001-9874-8938
AD  - School of Pharmacy, Faculty of Medicine, Faculty of Medicine, The Chinese 
      University of Hong Kong, Hong Kong, China.
AD  - Hong Kong Hub of Paediatric Excellence, The Chinese University of Hong Kong, Hong 
      Kong, China.
LA  - eng
PT  - Journal Article
DEP - 20231004
PL  - United States
TA  - J Integr Complement Med
JT  - Journal of integrative and complementary medicine
JID - 9918283075806676
SB  - IM
MH  - Humans
MH  - *Integrative Oncology
MH  - Communication
MH  - Health Personnel
MH  - *Integrative Medicine
MH  - *Neoplasms/therapy
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - cancer
OT  - complementary medicine
OT  - integrative medicine
OT  - integrative oncology
EDAT- 2023/10/04 12:44
MHDA- 2024/02/22 06:42
CRDT- 2023/10/04 11:33
PHST- 2024/02/22 06:42 [medline]
PHST- 2023/10/04 12:44 [pubmed]
PHST- 2023/10/04 11:33 [entrez]
AID - 10.1089/jicm.2023.0290 [doi]
PST - ppublish
SO  - J Integr Complement Med. 2024 Feb;30(2):196-205. doi: 10.1089/jicm.2023.0290. 
      Epub 2023 Oct 4.

PMID- 37942394
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231110
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 10
DP  - 2023 Oct
TI  - How Efficient Is ChatGPT in Accessing Accurate and Quality Health-Related 
      Information?
PG  - e46662
LID - 10.7759/cureus.46662 [doi]
LID - e46662
AB  - Background and objective The field of artificial intelligence (AI) is advancing 
      at a rapid pace, impacting all aspects of human life. Chat Generative Pre-trained 
      Transformer (ChatGPT), which represents one of AI's most recent and remarkable 
      achievements, has garnered significant attention and popularity in the academic 
      community. ChatGPT, a language model-based chatbot developed by OpenAI, responds 
      quickly and provides answers to the questions put to it. This chatbot has the 
      ability to gather content from a variety of sources&nbsp;on the internet. However, its 
      success in providing correct information has not yet been comprehensively 
      analyzed. In light of this, this study aimed to engage in a comparative content 
      analysis of health-related information provided by ChatGPT and a few selected 
      websites. Methods We performed a qualitative analysis of data obtained from 
      various information sources by using the DISCERN score and the&nbsp;Journal of 
      the&nbsp;American Medical Association (JAMA) benchmark criteria. In addition, 
      readability levels of the content were measured by using the Flesch-Kincaid grade 
      level, Gunning Fog Index, and&nbsp;Simple Measure of Gobbledygook (SMOG) index. 
      Results Based on our findings, there was no statistically significant difference 
      between the websites and ChatGPT in DISCERN scores. However, the JAMA score was 
      statistically significantly higher for websites. With regard to the 
      Flesch-Kincaid grade level, Gunning Fog Index, and SMOG index values,&nbsp;the data 
      obtained from the websites had higher readability. Conclusion Although AI is 
      starting to play a significant role in our everyday lives, it has yet to surpass 
      traditional methods of accessing information in terms of readability and 
      reliability.
CI  - Copyright © 2023, Ulusoy et al.
FAU - Ulusoy, Ibrahim
AU  - Ulusoy I
AD  - Department of Orthopaedics and Traumatology, Selahaddin Eyyübi State Hospital, 
      Diyarbakır, TUR.
FAU - Yılmaz, Mehmet
AU  - Yılmaz M
AD  - Department of Orthopaedics and Traumatology, Gaziantep 25 Aralık State Hospital, 
      Gaziantep, TUR.
FAU - Kıvrak, Aybars
AU  - Kıvrak A
AD  - Department of Orthopaedics and Traumatology, Avrupa Hospital, Adana, TUR.
LA  - eng
PT  - Journal Article
DEP - 20231007
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10628365
OTO - NOTNLM
OT  - chatgpt
OT  - discern
OT  - health information
OT  - jama
OT  - website
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/11/09 06:42
MHDA- 2023/11/09 06:43
PMCR- 2023/10/07
CRDT- 2023/11/09 04:28
PHST- 2023/10/07 00:00 [accepted]
PHST- 2023/11/09 06:43 [medline]
PHST- 2023/11/09 06:42 [pubmed]
PHST- 2023/11/09 04:28 [entrez]
PHST- 2023/10/07 00:00 [pmc-release]
AID - 10.7759/cureus.46662 [doi]
PST - epublish
SO  - Cureus. 2023 Oct 7;15(10):e46662. doi: 10.7759/cureus.46662. eCollection 2023 
      Oct.

PMID- 37685617
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230911
IS  - 2077-0383 (Print)
IS  - 2077-0383 (Electronic)
IS  - 2077-0383 (Linking)
VI  - 12
IP  - 17
DP  - 2023 Aug 25
TI  - Examining the Validity of ChatGPT in Identifying Relevant Nephrology Literature: 
      Findings and Implications.
LID - 10.3390/jcm12175550 [doi]
LID - 5550
AB  - Literature reviews are valuable for summarizing and evaluating the available 
      evidence in various medical fields, including nephrology. However, identifying 
      and exploring the potential sources requires focus and time devoted to literature 
      searching for clinicians and researchers. ChatGPT is a novel artificial 
      intelligence (AI) large language model (LLM) renowned for its exceptional ability 
      to generate human-like responses across various tasks. However, whether ChatGPT 
      can effectively assist medical professionals in identifying relevant literature 
      is unclear. Therefore, this study aimed to assess the effectiveness of ChatGPT in 
      identifying references to literature reviews in nephrology. We keyed the prompt 
      "Please provide the references in Vancouver style and their links in recent 
      literature on… name of the topic" into ChatGPT-3.5 (03/23 Version). We selected 
      all the results provided by ChatGPT and assessed them for existence, relevance, 
      and author/link correctness. We recorded each resource's citations, authors, 
      title, journal name, publication year, digital object identifier (DOI), and link. 
      The relevance and correctness of each resource were verified by searching on 
      Google Scholar. Of the total 610 references in the nephrology literature, only 
      378 (62%) of the references provided by ChatGPT existed, while 31% were 
      fabricated, and 7% of citations were incomplete references. Notably, only 122 
      (20%) of references were authentic. Additionally, 256 (68%) of the links in the 
      references were found to be incorrect, and the DOI was inaccurate in 206 (54%) of 
      the references. Moreover, among those with a link provided, the link was correct 
      in only 20% of cases, and 3% of the references were irrelevant. Notably, an 
      analysis of specific topics in electrolyte, hemodialysis, and kidney stones found 
      that &gt;60% of the references were inaccurate or misleading, with less reliable 
      authorship and links provided by ChatGPT. Based on our findings, the use of 
      ChatGPT as a sole resource for identifying references to literature reviews in 
      nephrology is not recommended. Future studies could explore ways to improve AI 
      language models' performance in identifying relevant nephrology literature.
FAU - Suppadungsuk, Supawadee
AU  - Suppadungsuk S
AUID- ORCID: 0000-0003-1597-2411
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
AD  - Chakri Naruebodindra Medical Institute, Faculty of Medicine Ramathibodi Hospital, 
      Mahidol University, Samut Prakan 10540, Thailand.
FAU - Thongprayoon, Charat
AU  - Thongprayoon C
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
FAU - Krisanapan, Pajaree
AU  - Krisanapan P
AUID- ORCID: 0000-0002-2888-881X
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
AD  - Division of Nephrology, Thammasat University Hospital, Pathum Thani 12120, 
      Thailand.
FAU - Tangpanithandee, Supawit
AU  - Tangpanithandee S
AUID- ORCID: 0000-0001-6103-2338
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
AD  - Chakri Naruebodindra Medical Institute, Faculty of Medicine Ramathibodi Hospital, 
      Mahidol University, Samut Prakan 10540, Thailand.
FAU - Garcia Valencia, Oscar
AU  - Garcia Valencia O
AUID- ORCID: 0000-0003-0186-9448
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
FAU - Miao, Jing
AU  - Miao J
AUID- ORCID: 0000-0003-0642-9740
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
FAU - Mekraksakit, Poemlarp
AU  - Mekraksakit P
AUID- ORCID: 0000-0002-2127-2529
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
FAU - Kashani, Kianoush
AU  - Kashani K
AUID- ORCID: 0000-0003-2184-3683
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
FAU - Cheungpasitporn, Wisit
AU  - Cheungpasitporn W
AUID- ORCID: 0000-0001-9954-9711
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
LA  - eng
PT  - Journal Article
DEP - 20230825
PL  - Switzerland
TA  - J Clin Med
JT  - Journal of clinical medicine
JID - 101606588
PMC - PMC10488525
OTO - NOTNLM
OT  - ChatGPT
OT  - accuracy
OT  - nephrology literature
OT  - references
OT  - reliability
COIS- The authors declare no conflict of interest.
EDAT- 2023/09/09 11:44
MHDA- 2023/09/09 11:45
PMCR- 2023/08/25
CRDT- 2023/09/09 01:08
PHST- 2023/06/29 00:00 [received]
PHST- 2023/08/21 00:00 [revised]
PHST- 2023/08/24 00:00 [accepted]
PHST- 2023/09/09 11:45 [medline]
PHST- 2023/09/09 11:44 [pubmed]
PHST- 2023/09/09 01:08 [entrez]
PHST- 2023/08/25 00:00 [pmc-release]
AID - jcm12175550 [pii]
AID - jcm-12-05550 [pii]
AID - 10.3390/jcm12175550 [doi]
PST - epublish
SO  - J Clin Med. 2023 Aug 25;12(17):5550. doi: 10.3390/jcm12175550.

PMID- 38552383
OWN - NLM
STAT- Publisher
LR  - 20240329
IS  - 1873-4499 (Electronic)
IS  - 0899-7071 (Linking)
VI  - 109
DP  - 2024 Mar 2
TI  - Even with ChatGPT, race matters.
PG  - 110113
LID - S0899-7071(24)00043-3 [pii]
LID - 10.1016/j.clinimag.2024.110113 [doi]
AB  - BACKGROUND: Applications of large language models such as ChatGPT are 
      increasingly being studied. Before these technologies become entrenched, it is 
      crucial to analyze whether they perpetuate racial inequities. METHODS: We asked 
      Open AI's ChatGPT-3.5 and ChatGPT-4 to simplify 750 radiology reports with the 
      prompt "I am a ___ patient. Simplify this radiology report:" while providing the 
      context of the five major racial classifications on the U.S. census: White, Black 
      or African American, American Indian or Alaska Native, Asian, and Native Hawaiian 
      or other Pacific Islander. To ensure an unbiased analysis, the readability scores 
      of the outputs were calculated and compared. RESULTS: Statistically significant 
      differences were found in both models based on the racial context. For 
      ChatGPT-3.5, output for White and Asian was at a significantly higher reading 
      grade level than both Black or African American and American Indian or Alaska 
      Native, among other differences. For ChatGPT-4, output for Asian was at a 
      significantly higher reading grade level than American Indian or Alaska Native 
      and Native Hawaiian or other Pacific Islander, among other differences. 
      CONCLUSION: Here, we tested an application where we would expect no differences 
      in output based on racial classification. Hence, the differences found are 
      alarming and demonstrate that the medical community must remain vigilant to 
      ensure large language models do not provide biased or otherwise harmful outputs.
CI  - Copyright © 2024 Elsevier Inc. All rights reserved.
FAU - Amin, Kanhai S
AU  - Amin KS
AD  - Yale College, New Haven, CT, USA.
FAU - Forman, Howard P
AU  - Forman HP
AD  - Department of Radiology and Biomedical Imaging, Yale School of Medicine, New 
      Haven, CT, USA.
FAU - Davis, Melissa A
AU  - Davis MA
AD  - Department of Radiology and Biomedical Imaging, Yale School of Medicine, New 
      Haven, CT, USA. Electronic address: melissa.a.davis@yale.edu.
LA  - eng
PT  - Journal Article
DEP - 20240302
PL  - United States
TA  - Clin Imaging
JT  - Clinical imaging
JID - 8911831
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - Health equity
OT  - Implicit bias
OT  - Large language models
OT  - Radiology report
COIS- Declaration of competing interest None.
EDAT- 2024/03/30 11:45
MHDA- 2024/03/30 11:45
CRDT- 2024/03/29 19:08
PHST- 2023/11/03 00:00 [received]
PHST- 2024/02/15 00:00 [revised]
PHST- 2024/02/24 00:00 [accepted]
PHST- 2024/03/30 11:45 [medline]
PHST- 2024/03/30 11:45 [pubmed]
PHST- 2024/03/29 19:08 [entrez]
AID - S0899-7071(24)00043-3 [pii]
AID - 10.1016/j.clinimag.2024.110113 [doi]
PST - aheadofprint
SO  - Clin Imaging. 2024 Mar 2;109:110113. doi: 10.1016/j.clinimag.2024.110113.

PMID- 38073946
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231211
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 11
DP  - 2023 Nov
TI  - Potential Use of ChatGPT for Patient Information in Periodontology: A Descriptive 
      Pilot Study.
PG  - e48518
LID - 10.7759/cureus.48518 [doi]
LID - e48518
AB  - Objectives The aim of this study is to evaluate the accuracy and completeness of 
      the answers given by Chat Generative Pre-trained Transformer (ChatGPT) (OpenAI 
      OpCo, LLC, San Francisco, CA),&nbsp;to the most frequently asked questions on 
      different topics in the field of periodontology. Methods The 10 most frequently 
      asked questions by patients about seven different topics (periodontal diseases, 
      peri-implant diseases, tooth sensitivity, gingival recessions, halitosis, dental 
      implants, and periodontal surgery) in periodontology were created by ChatGPT. To 
      obtain responses, a set of 70 questions was submitted to ChatGPT, with an 
      allocation of 10 questions per subject. The responses that were documented were 
      assessed using two distinct Likert scales by professionals specializing in the 
      subject of periodontology. The accuracy of the responses was rated on a Likert 
      scale ranging from one to six, while the completeness of the responses was rated 
      on a scale ranging from one to three. Results The median accuracy score for all 
      responses was six, while the completeness score was two. The mean scores for 
      accuracy and completeness were 5.50 ± 0.23 and 2.34 ± 0.24, respectively. It was 
      observed that ChatGPT's responses to the most frequently asked questions by 
      patients for information purposes in periodontology were at least "nearly 
      completely correct" in terms of accuracy and "adequate" in terms of completeness. 
      There was a statistically significant difference between subjects in terms of 
      accuracy and completeness (P&lt;0.05). The highest and lowest accuracy scores were 
      peri-implant diseases and gingival recession, respectively, while the highest and 
      lowest completeness scores were gingival recession and dental implants, 
      respectively. Conclusions The utilization of large language models has become 
      increasingly prevalent, extending its applicability to patients within the 
      healthcare domain. While ChatGPT may not offer absolute precision and 
      comprehensive results without expert supervision, it is apparent that those 
      within the field of periodontology can utilize it as an informational resource, 
      albeit acknowledging the potential for inaccuracies.
CI  - Copyright © 2023, Babayiğit et al.
FAU - Babayiğit, Osman
AU  - Babayiğit O
AD  - Department of Periodontology, Necmettin Erbakan University, Faculty of Dentistry, 
      Konya, TUR.
FAU - Tastan Eroglu, Zeynep
AU  - Tastan Eroglu Z
AD  - Department of Periodontology, Necmettin Erbakan University, Faculty of Dentistry, 
      Konya, TUR.
FAU - Ozkan Sen, Dilek
AU  - Ozkan Sen D
AD  - Department of Periodontology, Necmettin Erbakan University, Faculty of Dentistry, 
      Konya, TUR.
FAU - Ucan Yarkac, Fatma
AU  - Ucan Yarkac F
AD  - Department of Periodontology, Necmettin Erbakan University, Faculty of Dentistry, 
      Konya, TUR.
LA  - eng
PT  - Journal Article
DEP - 20231108
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10708896
OTO - NOTNLM
OT  - artificial intelligence in dentistry
OT  - chat generative pre-trained transformer
OT  - chatgpt
OT  - dental care
OT  - large language models (llms)
OT  - oral medicine and periodontology
OT  - patient information
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/12/11 06:45
MHDA- 2023/12/11 06:46
PMCR- 2023/11/08
CRDT- 2023/12/11 05:37
PHST- 2023/11/08 00:00 [accepted]
PHST- 2023/12/11 06:46 [medline]
PHST- 2023/12/11 06:45 [pubmed]
PHST- 2023/12/11 05:37 [entrez]
PHST- 2023/11/08 00:00 [pmc-release]
AID - 10.7759/cureus.48518 [doi]
PST - epublish
SO  - Cureus. 2023 Nov 8;15(11):e48518. doi: 10.7759/cureus.48518. eCollection 2023 
      Nov.

PMID- 37814369
OWN - NLM
STAT- MEDLINE
DCOM- 20231216
LR  - 20231216
IS  - 1365-2591 (Electronic)
IS  - 0143-2885 (Linking)
VI  - 57
IP  - 1
DP  - 2024 Jan
TI  - Unveiling the ChatGPT phenomenon: Evaluating the consistency and accuracy of 
      endodontic question answers.
PG  - 108-113
LID - 10.1111/iej.13985 [doi]
AB  - AIM: Chatbot Generative Pre-trained Transformer (ChatGPT) is a generative 
      artificial intelligence (AI) software based on large language models (LLMs), 
      designed to simulate human conversations and generate novel content based on the 
      training data it has been exposed to. The aim of this study was to evaluate the 
      consistency and accuracy of ChatGPT-generated answers to clinical questions in 
      endodontics, compared to answers provided by human experts. METHODOLOGY: 
      Ninety-one dichotomous (yes/no) questions were designed and categorized into 
      three levels of difficulty. Twenty questions were randomly selected from each 
      difficulty level. Sixty answers were generated by ChatGPT for each question. Two 
      endodontic experts independently answered the 60 questions. Statistical analysis 
      was performed using the SPSS program to calculate the consistency and accuracy of 
      the answers generated by ChatGPT compared to the experts. Confidence intervals 
      (95%) and standard deviations were used to estimate variability. RESULTS: The 
      answers generated by ChatGPT showed high consistency (85.44%). No significant 
      differences in consistency were found based on question difficulty. In terms of 
      answer accuracy, ChatGPT achieved an average accuracy of 57.33%. However, 
      significant differences in accuracy were observed based on question difficulty, 
      with lower accuracy for easier questions. CONCLUSIONS: Currently, ChatGPT is not 
      capable of replacing dentists in clinical decision-making. As ChatGPT's 
      performance improves through deep learning, it is expected to become more useful 
      and effective in the field of endodontics. However, careful attention and ongoing 
      evaluation are needed to ensure its accuracy, reliability and safety in 
      endodontics.
CI  - © 2023 The Authors. International Endodontic Journal published by John Wiley &amp; 
      Sons Ltd on behalf of British Endodontic Society.
FAU - Suárez, Ana
AU  - Suárez A
AUID- ORCID: 0000-0003-2448-6669
AD  - Department of Pre-Clinic Dentistry, School of Biomedical Sciences, Universidad 
      Europea de Madrid, Madrid, Spain.
FAU - Díaz-Flores García, Víctor
AU  - Díaz-Flores García V
AUID- ORCID: 0000-0001-6141-0546
AD  - Department of Pre-Clinic Dentistry, School of Biomedical Sciences, Universidad 
      Europea de Madrid, Madrid, Spain.
FAU - Algar, Juan
AU  - Algar J
AD  - Department of Clinical Dentistry, School of Biomedical Sciences, Universidad 
      Europea de Madrid, Madrid, Spain.
FAU - Gómez Sánchez, Margarita
AU  - Gómez Sánchez M
AUID- ORCID: 0000-0002-8305-6354
AD  - Department of Pre-Clinic Dentistry, School of Biomedical Sciences, Universidad 
      Europea de Madrid, Madrid, Spain.
FAU - Llorente de Pedro, María
AU  - Llorente de Pedro M
AD  - Department of Pre-Clinic Dentistry, School of Biomedical Sciences, Universidad 
      Europea de Madrid, Madrid, Spain.
FAU - Freire, Yolanda
AU  - Freire Y
AUID- ORCID: 0000-0002-0727-777X
AD  - Department of Pre-Clinic Dentistry, School of Biomedical Sciences, Universidad 
      Europea de Madrid, Madrid, Spain.
LA  - eng
PT  - Journal Article
DEP - 20231009
PL  - England
TA  - Int Endod J
JT  - International endodontic journal
JID - 8004996
MH  - Humans
MH  - *Artificial Intelligence
MH  - Reproducibility of Results
MH  - *Software
MH  - Clinical Decision-Making
MH  - Dental Care
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - chatbot
OT  - dentistry
OT  - endodontics
OT  - large language models
EDAT- 2023/10/10 00:42
MHDA- 2023/12/17 09:44
CRDT- 2023/10/09 23:52
PHST- 2023/09/26 00:00 [revised]
PHST- 2023/09/03 00:00 [received]
PHST- 2023/09/27 00:00 [accepted]
PHST- 2023/12/17 09:44 [medline]
PHST- 2023/10/10 00:42 [pubmed]
PHST- 2023/10/09 23:52 [entrez]
AID - 10.1111/iej.13985 [doi]
PST - ppublish
SO  - Int Endod J. 2024 Jan;57(1):108-113. doi: 10.1111/iej.13985. Epub 2023 Oct 9.

PMID- 37584720
OWN - NLM
STAT- Publisher
LR  - 20231003
IS  - 1279-8517 (Electronic)
IS  - 0930-1038 (Print)
IS  - 0930-1038 (Linking)
VI  - 45
IP  - 10
DP  - 2023 Oct
TI  - The potential role of ChatGPT and artificial intelligence in anatomy education: a 
      conversation with ChatGPT.
PG  - 1321-1329
LID - 10.1007/s00276-023-03229-1 [doi]
AB  - PURPOSE: A recent study published in the JMIR Med Educ Journal explored the 
      potential impact of the Generative Pre-Train (ChatGPT), a generative language 
      model, on medical education, research, and practice. In the present study, an 
      interview with ChatGPT was conducted to determine its capabilities and potential 
      for use in anatomy education (AE) and anatomy research (AR). METHODS: The study 
      involved 18 questions asked of ChatGPT after obtaining an online subscription to 
      the 4th edition. The questions were randomly selected and evaluated based on 
      accuracy, relevance, and comprehensiveness. RESULTS: The ChatGPT provided 
      accurate and well-structured anatomical descriptions, including clinical 
      relevance and relationships between structures. The chatbot also offered concise 
      summaries of chapters and helpful advice on anatomical terminology, even with 
      complex terms. However, when it came to anatomical variants and their clinical 
      significance, the chatbot's replies were inadequate unless variants were 
      systematically classified into types. ChatGPT-4 generated multiple-choice quizzes 
      and matching questions of varying difficulty levels, as well as summaries of 
      articles when presented with text. However, the chatbot recognized its 
      limitations in terms of accuracy, as did the authors&nbsp;of the current&nbsp;study. 
      CONCLUSION: ChatGPT-4 can be a valuable interactive educational tool for students 
      in the field of anatomy, encouraging engagement and further questions. However, 
      it cannot replace the critical role of educators and should be used as a 
      complementary tool. Future research should establish guidelines for ChatGPT's 
      optimal use and application in medical education.
CI  - © 2023. The Author(s).
FAU - Totlis, Trifon
AU  - Totlis T
AUID- ORCID: 0000-0001-5729-7755
AD  - Department of Anatomy and Surgical Anatomy, School of Medicine, Faculty of Health 
      Sciences, Aristotle University of Thessaloniki, 54124, Thessaloniki, Greece. 
      totlis@auth.gr.
FAU - Natsis, Konstantinos
AU  - Natsis K
AUID- ORCID: 0000-0002-3077-1784
AD  - Department of Anatomy and Surgical Anatomy, School of Medicine, Faculty of Health 
      Sciences, Aristotle University of Thessaloniki, 54124, Thessaloniki, Greece.
FAU - Filos, Dimitrios
AU  - Filos D
AD  - Laboratory of Computing, Medical Informatics and Biomedical-Imaging Technologies, 
      School of Medicine, Aristotle University of Thessaloniki, Thessaloniki, Greece.
FAU - Ediaroglou, Vasilios
AU  - Ediaroglou V
AD  - Department of Anatomy and Surgical Anatomy, School of Medicine, Faculty of Health 
      Sciences, Aristotle University of Thessaloniki, 54124, Thessaloniki, Greece.
FAU - Mantzou, Nikolaos
AU  - Mantzou N
AD  - Department of Anatomy and Surgical Anatomy, School of Medicine, Faculty of Health 
      Sciences, Aristotle University of Thessaloniki, 54124, Thessaloniki, Greece.
FAU - Duparc, Fabrice
AU  - Duparc F
AUID- ORCID: 0000-0002-7131-7692
AD  - Department of Anatomy, Faculty of Medicine-Pharmacy, University of 
      Rouen-Normandy, 22 Boulevard Gambetta, 76183, Rouen, France.
FAU - Piagkou, Maria
AU  - Piagkou M
AUID- ORCID: 0000-0002-4831-8005
AD  - Department of Anatomy, School of Medicine, Faculty of Health Sciences, National 
      and Kapodistrian University of Athens, Athens, Greece.
LA  - eng
PT  - Journal Article
DEP - 20230816
PL  - Germany
TA  - Surg Radiol Anat
JT  - Surgical and radiologic anatomy : SRA
JID - 8608029
SB  - IM
PMC - PMC10533609
OTO - NOTNLM
OT  - Anatomy education
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Generative language models
OT  - Medical education
COIS- The authors have no competing interests to declare that are relevant to the 
      content of this article.
EDAT- 2023/08/16 12:42
MHDA- 2023/08/16 12:42
PMCR- 2023/08/16
CRDT- 2023/08/16 11:05
PHST- 2023/07/04 00:00 [received]
PHST- 2023/08/01 00:00 [accepted]
PHST- 2023/08/16 12:42 [pubmed]
PHST- 2023/08/16 12:42 [medline]
PHST- 2023/08/16 11:05 [entrez]
PHST- 2023/08/16 00:00 [pmc-release]
AID - 10.1007/s00276-023-03229-1 [pii]
AID - 3229 [pii]
AID - 10.1007/s00276-023-03229-1 [doi]
PST - ppublish
SO  - Surg Radiol Anat. 2023 Oct;45(10):1321-1329. doi: 10.1007/s00276-023-03229-1. 
      Epub 2023 Aug 16.

PMID- 38073698
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231211
IS  - 2307-8960 (Print)
IS  - 2307-8960 (Electronic)
IS  - 2307-8960 (Linking)
VI  - 11
IP  - 32
DP  - 2023 Nov 16
TI  - Potential and limitations of ChatGPT and generative artificial intelligence in 
      medical safety education.
PG  - 7935-7939
LID - 10.12998/wjcc.v11.i32.7935 [doi]
AB  - The primary objectives of medical safety education are to provide the public with 
      essential knowledge about medications and to foster a scientific approach to drug 
      usage. The era of using artificial intelligence to revolutionize medical safety 
      education has already dawned, and ChatGPT and other generative artificial 
      intelligence models have immense potential in this domain. Notably, they offer a 
      wealth of knowledge, anonymity, continuous availability, and personalized 
      services. However, the practical implementation of generative artificial 
      intelligence models such as ChatGPT in medical safety education still faces 
      several challenges, including concerns about the accuracy of information, legal 
      responsibilities, and ethical obligations. Moving forward, it is crucial to 
      intelligently upgrade ChatGPT by leveraging the strengths of existing medical 
      practices. This task involves further integrating the model with real-life 
      scenarios and proactively addressing ethical and security issues with the 
      ultimate goal of providing the public with comprehensive, convenient, efficient, 
      and personalized medical services.
CI  - ©The Author(s) 2023. Published by Baishideng Publishing Group Inc. All rights 
      reserved.
FAU - Wang, Xin
AU  - Wang X
AD  - School of Education, Tianjin University, Tianjin 300350, China.
FAU - Liu, Xin-Qiao
AU  - Liu XQ
AD  - School of Education, Tianjin University, Tianjin 300350, China. 
      xinqiaoliu@pku.edu.cn.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - World J Clin Cases
JT  - World journal of clinical cases
JID - 101618806
PMC - PMC10698415
OTO - NOTNLM
OT  - ChatGPT
OT  - Generative artificial intelligence
OT  - Limitation
OT  - Medical safety education
OT  - Potential
COIS- Conflict-of-interest statement: The authors declare no conflict of interests.
EDAT- 2023/12/11 06:45
MHDA- 2023/12/11 06:46
PMCR- 2023/11/16
CRDT- 2023/12/11 05:35
PHST- 2023/08/07 00:00 [received]
PHST- 2023/09/21 00:00 [revised]
PHST- 2023/11/02 00:00 [accepted]
PHST- 2023/12/11 06:46 [medline]
PHST- 2023/12/11 06:45 [pubmed]
PHST- 2023/12/11 05:35 [entrez]
PHST- 2023/11/16 00:00 [pmc-release]
AID - 10.12998/wjcc.v11.i32.7935 [doi]
PST - ppublish
SO  - World J Clin Cases. 2023 Nov 16;11(32):7935-7939. doi: 
      10.12998/wjcc.v11.i32.7935.

PMID- 37789187
OWN - NLM
STAT- Publisher
LR  - 20231003
IS  - 1554-3528 (Electronic)
IS  - 1554-351X (Linking)
DP  - 2023 Oct 3
TI  - The impact of ChatGPT on human data collection: A case study involving typicality 
      norming data.
LID - 10.3758/s13428-023-02235-w [doi]
AB  - Tools like ChatGPT, which allow people to unlock the potential of large language 
      models (LLMs), have taken the world by storm. ChatGPT's ability to produce 
      written output of remarkable quality has inspired, or forced, academics to 
      consider its consequences for both research and education. In particular, the 
      question of what constitutes authorship, and how to evaluate (scientific) 
      contributions has received a lot of attention. However, its impact on (online) 
      human data collection has mostly flown under the radar. The current paper 
      examines how ChatGPT can be (mis)used in the context of generating norming data. 
      We found that ChatGPT is able to produce sensible output, resembling that of 
      human participants, for a typicality rating task. Moreover, the test-retest 
      reliability of ChatGPT's ratings was similar to that of human participants tested 
      1&nbsp;day apart. We discuss the relevance of these findings in the context of 
      (online) human data collection, focusing both on opportunities (e.g., (risk-)free 
      pilot data) and challenges (e.g., data fabrication).
CI  - © 2023. The Author(s).
FAU - Heyman, Tom
AU  - Heyman T
AUID- ORCID: 0000-0003-0565-441X
AD  - Methodology and Statistics Unit, Institute of Psychology, Leiden University, 
      Wassenaarseweg 52, 2333, AK Leiden, The Netherlands. 
      t.d.p.heyman@fsw.leidenuniv.nl.
FAU - Heyman, Geert
AU  - Heyman G
AD  - Nokia Bell Labs Antwerp, Copernicuslaan 50, 2018, Antwerpen, Belgium.
LA  - eng
PT  - Journal Article
DEP - 20231003
PL  - United States
TA  - Behav Res Methods
JT  - Behavior research methods
JID - 101244316
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - Human data collection
OT  - Large language models
OT  - Typicality
EDAT- 2023/10/04 00:42
MHDA- 2023/10/04 00:42
CRDT- 2023/10/03 23:37
PHST- 2023/09/01 00:00 [accepted]
PHST- 2023/10/04 00:42 [medline]
PHST- 2023/10/04 00:42 [pubmed]
PHST- 2023/10/03 23:37 [entrez]
AID - 10.3758/s13428-023-02235-w [pii]
AID - 10.3758/s13428-023-02235-w [doi]
PST - aheadofprint
SO  - Behav Res Methods. 2023 Oct 3. doi: 10.3758/s13428-023-02235-w.

PMID- 38511678
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240327
IS  - 2149-2042 (Print)
IS  - 2149-4606 (Electronic)
IS  - 2149-4606 (Linking)
VI  - 39
IP  - 1
DP  - 2024 Mar 21
TI  - Is ChatGPT an Accurate and Reliable Source of Information for Patients with 
      Vaccine and Statin Hesitancy?
PG  - 1-7
LID - 10.4274/MMJ.galenos.2024.03154 [doi]
AB  - OBJECTIVE: Chat Generative Pre-trained Transformer (ChatGPT) is an artificial 
      intelligence (AI) language model that is trained to respond to questions across a 
      wide range of topics. Our aim is to elucidate whether it would be beneficial for 
      patients who are hesitant about vaccines and statins to use ChatGPT. METHODS: 
      This cross-sectional and observational study was conducted from March 2 to March 
      30, 2023, using OpenAI ChatGPT-3.5. ChatGPT provided responses to 7 questions 
      related to vaccine and statin hesitancy. The same questions were also directed at 
      physicians. Both the answers from ChatGPT and the physicians were assessed for 
      accuracy, clarity, and conciseness by experts in cardiology, internal medicine, 
      and microbiology, who possessed a minimum of 30 years of professional experience. 
      Responses were rated on a scale of 0-4, and the ChatGPT's average score was 
      compared with that of physicians using the Mann-Whitney U test. RESULTS: The mean 
      scores of ChatGPT (3.78±0.36) and physicians (3.65±0.57) were similar 
      (Mann-Whitney U test p=0.33). The mean scores of ChatGPT were 3.85±0.34 for 
      vaccination and 3.68±0.35 for statin use. The mean scores of physicians were 
      3.73±0.51 for vaccination and 3.58±0.61 for statin use. There was no 
      statistically significant difference between the mean scores of ChatGPT and 
      physicians for both vaccine and statin use (p=0.403 for vaccination, p=0.678 for 
      statin). ChatGPT did not consider sources of conspiratorial information on 
      vaccines and statins. CONCLUSIONS: This study suggests that ChatGPT can be a 
      valuable source of information for guiding patients with vaccine and statin 
      hesitancy.
CI  - Copyright© 2024 The Author. Published by Galenos Publishing House on behalf of 
      Istanbul Medeniyet University Faculty of Medicine.
FAU - Torun, Cundullah
AU  - Torun C
AUID- ORCID: 0000-0003-4933-7635
AD  - Istanbul Goztepe Prof. Dr. Suleyman Yalcin City Hospital, Clinic of Internal 
      Medicine, Istanbul, Turkey.
FAU - Sarmis, Abdurrahman
AU  - Sarmis A
AUID- ORCID: 0000-0002-8156-6633
AD  - Istanbul Goztepe Prof. Dr. Suleyman Yalcin City Hospital, Clinic of Microbiology, 
      Istanbul, Turkey.
FAU - Oguz, Aytekin
AU  - Oguz A
AUID- ORCID: 0000-0002-2595-5167
AD  - Istanbul Goztepe Prof. Dr. Suleyman Yalcin City Hospital, Clinic of Internal 
      Medicine, Istanbul, Turkey.
LA  - eng
PT  - Journal Article
PL  - Turkey
TA  - Medeni Med J
JT  - Medeniyet medical journal
JID - 101676811
PMC - PMC10961658
OTO - NOTNLM
OT  - Primary prevention
OT  - artificial intelligence
OT  - medication hesitancy
COIS- Conflict of Interest: The authors have no conflict of interest to declare.
EDAT- 2024/03/21 12:48
MHDA- 2024/03/21 12:49
PMCR- 2024/03/21
CRDT- 2024/03/21 07:57
PHST- 2024/03/21 12:49 [medline]
PHST- 2024/03/21 12:48 [pubmed]
PHST- 2024/03/21 07:57 [entrez]
PHST- 2024/03/21 00:00 [pmc-release]
AID - 64744 [pii]
AID - 10.4274/MMJ.galenos.2024.03154 [doi]
PST - ppublish
SO  - Medeni Med J. 2024 Mar 21;39(1):1-7. doi: 10.4274/MMJ.galenos.2024.03154.

PMID- 38529337
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240327
IS  - 2333-794X (Electronic)
IS  - 2333-794X (Linking)
VI  - 11
DP  - 2024
TI  - ChatGPT Yields a Passing Score on a Pediatric Board Preparatory Exam but Raises 
      Red Flags.
PG  - 2333794X241240327
LID - 10.1177/2333794X241240327 [doi]
LID - 2333794X241240327
AB  - OBJECTIVES: We aimed to evaluate the performance of a publicly-available online 
      artificial intelligence program (OpenAI's ChatGPT-3.5 and -4.0, August 3 
      versions) on a pediatric board preparatory examination, 2021 and 2022 PREP(®) 
      Self-Assessment, American Academy of Pediatrics (AAP). METHODS: We entered 245 
      questions and answer choices from the Pediatrics 2021 PREP(®) Self-Assessment and 
      247 questions and answer choices from the Pediatrics 2022 PREP(®) Self-Assessment 
      into OpenAI's ChatGPT-3.5 and ChatGPT-4.0, August 3 versions, in September 2023. 
      The ChatGPT-3.5 and 4.0 scores were compared with the advertised passing scores 
      (70%+) for the PREP(®) exams and the average scores (74.09%) and (75.71%) for all 
      10 715 and 6825 first-time human test takers. RESULTS: For the AAP 2021 and 2022 
      PREP(®) Self-Assessments, ChatGPT-3.5 answered 143 of 243 (58.85%) and 137 of 247 
      (55.46%) questions correctly on a single attempt. ChatGPT-4.0 answered 193 of 243 
      (79.84%) and 208 of 247 (84.21%) questions correctly. CONCLUSION: Using a 
      publicly-available online chatbot to answer pediatric board preparatory 
      examination questions yielded a passing score but demonstrated significant 
      limitations in the chatbot's ability to assess some complex medical situations in 
      children, posing a potential risk to this vulnerable population.
CI  - © The Author(s) 2024.
FAU - Le, Mindy
AU  - Le M
AD  - University of Florida College of Medicine, Gainesville, FL, USA.
FAU - Davis, Michael
AU  - Davis M
AUID- ORCID: 0000-0001-5585-727X
AD  - University of Florida College of Medicine, Gainesville, FL, USA.
LA  - eng
PT  - Journal Article
DEP - 20240324
PL  - United States
TA  - Glob Pediatr Health
JT  - Global pediatric health
JID - 101670224
PMC - PMC10962030
OTO - NOTNLM
OT  - ChatGPT
OT  - pediatrics
COIS- The author(s) declared no potential conflicts of interest with respect to the 
      research, authorship, and/or publication of this article.
EDAT- 2024/03/26 06:45
MHDA- 2024/03/26 06:46
PMCR- 2024/03/24
CRDT- 2024/03/26 03:43
PHST- 2023/11/19 00:00 [received]
PHST- 2024/01/28 00:00 [revised]
PHST- 2024/03/04 00:00 [accepted]
PHST- 2024/03/26 06:46 [medline]
PHST- 2024/03/26 06:45 [pubmed]
PHST- 2024/03/26 03:43 [entrez]
PHST- 2024/03/24 00:00 [pmc-release]
AID - 10.1177_2333794X241240327 [pii]
AID - 10.1177/2333794X241240327 [doi]
PST - epublish
SO  - Glob Pediatr Health. 2024 Mar 24;11:2333794X241240327. doi: 
      10.1177/2333794X241240327. eCollection 2024.

PMID- 37780034
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231004
IS  - 2382-1205 (Print)
IS  - 2382-1205 (Electronic)
IS  - 2382-1205 (Linking)
VI  - 10
DP  - 2023 Jan-Dec
TI  - Examining the Threat of ChatGPT to the Validity of Short Answer Assessments in an 
      Undergraduate Medical Program.
PG  - 23821205231204178
LID - 10.1177/23821205231204178 [doi]
LID - 23821205231204178
AB  - OBJECTIVES: ChatGPT is an artificial intelligence model that can interpret 
      free-text prompts and return detailed, human-like responses across a wide domain 
      of subjects. This study evaluated the extent of the threat posed by ChatGPT to 
      the validity of short-answer assessment problems used to examine pre-clerkship 
      medical students in our undergraduate medical education program. METHODS: Forty 
      problems used in prior student assessments were retrieved and stratified by 
      levels of Bloom's Taxonomy. Thirty of these problems were submitted to 
      ChatGPT-3.5. For the remaining 10 problems, we retrieved past minimally passing 
      student responses. Six tutors graded each of the 40 responses. Comparison of 
      performance between student-generated and ChatGPT-generated answers aggregated as 
      a whole and grouped by Bloom's levels of cognitive reasoning, was done using 
      t-tests, ANOVA, Cronbach's alpha, and Cohen's d. Scores for ChatGPT-generated 
      responses were also compared to historical class average performance. RESULTS: 
      ChatGPT-generated responses received a mean score of 3.29 out of 5 (n = 30, 95% 
      CI 2.93-3.65) compared to 2.38 for a group of students meeting minimum passing 
      marks (n = 10, 95% CI 1.94-2.82), representing higher performance (P = .008, 
      η(2) = 0.169), but was outperformed by historical class average scores on the 
      same 30 problems (mean 3.67, P = .018) when including all past responses 
      regardless of student performance level. There was no statistically significant 
      trend in performance across domains of Bloom's Taxonomy. CONCLUSION: While 
      ChatGPT was able to pass short answer assessment problems spanning the 
      pre-clerkship curriculum, it outperformed only underperforming students. We 
      remark that tutors in several cases were convinced that ChatGPT-produced 
      responses were produced by students. Risks to assessment validity include 
      uncertainty in identifying struggling students and inability to intervene in a 
      timely manner. The performance of ChatGPT on problems requiring increasing 
      demands of cognitive reasoning warrants further research.
CI  - © The Author(s) 2023.
FAU - Morjaria, Leo
AU  - Morjaria L
AD  - Michael G. DeGroote School of Medicine, McMaster University, Hamilton, Ontario, 
      Canada. RINGGOLD: 12362
FAU - Burns, Levi
AU  - Burns L
AD  - Michael G. DeGroote School of Medicine, McMaster University, Hamilton, Ontario, 
      Canada. RINGGOLD: 12362
FAU - Bracken, Keyna
AU  - Bracken K
AUID- ORCID: 0000-0002-4512-6067
AD  - Michael G. DeGroote School of Medicine, McMaster University, Hamilton, Ontario, 
      Canada. RINGGOLD: 12362
AD  - McMaster Education Research, Innovation and Theory (MERIT) Program, McMaster 
      University, Hamilton, Ontario, Canada. RINGGOLD: 3710
FAU - Ngo, Quang N
AU  - Ngo QN
AD  - Michael G. DeGroote School of Medicine, McMaster University, Hamilton, Ontario, 
      Canada. RINGGOLD: 12362
AD  - McMaster Education Research, Innovation and Theory (MERIT) Program, McMaster 
      University, Hamilton, Ontario, Canada. RINGGOLD: 3710
FAU - Lee, Mark
AU  - Lee M
AD  - McMaster Education Research, Innovation and Theory (MERIT) Program, McMaster 
      University, Hamilton, Ontario, Canada. RINGGOLD: 3710
FAU - Levinson, Anthony J
AU  - Levinson AJ
AD  - Michael G. DeGroote School of Medicine, McMaster University, Hamilton, Ontario, 
      Canada. RINGGOLD: 12362
FAU - Smith, John
AU  - Smith J
AD  - Michael G. DeGroote School of Medicine, McMaster University, Hamilton, Ontario, 
      Canada. RINGGOLD: 12362
FAU - Thompson, Penelope
AU  - Thompson P
AD  - Michael G. DeGroote School of Medicine, McMaster University, Hamilton, Ontario, 
      Canada. RINGGOLD: 12362
FAU - Sibbald, Matthew
AU  - Sibbald M
AD  - Michael G. DeGroote School of Medicine, McMaster University, Hamilton, Ontario, 
      Canada. RINGGOLD: 12362
AD  - McMaster Education Research, Innovation and Theory (MERIT) Program, McMaster 
      University, Hamilton, Ontario, Canada. RINGGOLD: 3710
LA  - eng
PT  - Journal Article
DEP - 20230928
PL  - United States
TA  - J Med Educ Curric Dev
JT  - Journal of medical education and curricular development
JID - 101690298
PMC - PMC10540597
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - medical student
OT  - pre-clerkship
OT  - short answer assessment
OT  - undergraduate
COIS- The authors declared no potential conflicts of interest with respect to the 
      research, authorship, and/or publication of this article.
EDAT- 2023/10/02 06:42
MHDA- 2023/10/02 06:43
PMCR- 2023/09/28
CRDT- 2023/10/02 04:21
PHST- 2023/05/17 00:00 [received]
PHST- 2023/09/01 00:00 [accepted]
PHST- 2023/10/02 06:43 [medline]
PHST- 2023/10/02 06:42 [pubmed]
PHST- 2023/10/02 04:21 [entrez]
PHST- 2023/09/28 00:00 [pmc-release]
AID - 10.1177_23821205231204178 [pii]
AID - 10.1177/23821205231204178 [doi]
PST - epublish
SO  - J Med Educ Curric Dev. 2023 Sep 28;10:23821205231204178. doi: 
      10.1177/23821205231204178. eCollection 2023 Jan-Dec.

PMID- 37266721
OWN - NLM
STAT- Publisher
LR  - 20231024
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 51
IP  - 11
DP  - 2023 Nov
TI  - The Impact of ChatGPT on the Nursing Profession: Revolutionizing Patient Care and 
      Education.
PG  - 2351-2352
LID - 10.1007/s10439-023-03262-6 [doi]
AB  - The nursing field has undergone notable changes over time and is projected to 
      undergo further modifications in the future, owing to the advent of sophisticated 
      technologies and growing healthcare needs. The advent of ChatGPT, an AI-powered 
      language model, is expected to exert a significant influence on the nursing 
      profession, specifically in the domains of patient care and instruction. The 
      present article delves into the ramifications of ChatGPT within the nursing 
      domain and accentuates its capacity and constraints to transform the discipline.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Ahmed, Sirwan Khalid
AU  - Ahmed SK
AUID- ORCID: 0000-0002-8361-0546
AD  - , Kurdistan Region, 46012, Iraq. sirwan.k.ahmed@gmail.com.
LA  - eng
PT  - Letter
DEP - 20230602
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Limitation
OT  - Nursing education
OT  - Nursing practice
EDAT- 2023/06/02 13:16
MHDA- 2023/06/02 13:16
CRDT- 2023/06/02 11:10
PHST- 2023/05/24 00:00 [received]
PHST- 2023/05/26 00:00 [accepted]
PHST- 2023/06/02 13:16 [pubmed]
PHST- 2023/06/02 13:16 [medline]
PHST- 2023/06/02 11:10 [entrez]
AID - 10.1007/s10439-023-03262-6 [pii]
AID - 10.1007/s10439-023-03262-6 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2023 Nov;51(11):2351-2352. doi: 10.1007/s10439-023-03262-6. Epub 
      2023 Jun 2.

PMID- 37891083
OWN - NLM
STAT- MEDLINE
DCOM- 20240305
LR  - 20240312
IS  - 1535-6302 (Electronic)
IS  - 0363-0188 (Linking)
VI  - 53
IP  - 2
DP  - 2024 Mar-Apr
TI  - Analysis of ChatGPT publications in radiology: Literature so far.
PG  - 215-225
LID - S0363-0188(23)00166-4 [pii]
LID - 10.1067/j.cpradiol.2023.10.013 [doi]
AB  - OBJECTIVE: To perform a detailed qualitative and quantitative analysis of the 
      published literature on ChatGPT and radiology in the nine months since its public 
      release, detailing the scope of the work in the short timeframe. METHODS: A 
      systematic literature search was carried out of the MEDLINE, EMBASE databases 
      through August 15, 2023 for articles that were focused on ChatGPT and 
      imaging/radiology. Articles were classified into original research and 
      reviews/perspectives. Quantitative analysis was carried out by two experienced 
      radiologists using objective scoring systems for evaluating original and 
      non-original research. RESULTS: 51 articles were published involving ChatGPT and 
      radiology/imaging dating from 26 Jan 2023 to the last article published on 14 Aug 
      2023. 23 articles were original research while the rest included 
      reviews/perspectives or brief communications. For quantitative analysis scored by 
      two readers, we included 23 original research and 17 non-original research 
      articles (after excluding 11 letters as responses to previous articles). Mean 
      score for original research was 3.20 out of 5 (across five questions), while mean 
      score for non-original research was 1.17 out of 2 (across six questions). Mean 
      score grading performance of ChatGPT in original research was 3.20 out of five 
      (across two questions). DISCUSSION: While it is early days for ChatGPT and its 
      impact in radiology, there has already been a plethora of articles talking about 
      the multifaceted nature of the tool and how it can impact every aspect of 
      radiology from patient education, pre-authorization, protocol selection, 
      generating differentials, to structuring radiology reports. Most articles show 
      impressive performance of ChatGPT which can only improve with more research and 
      improvements in the tool itself. There have also been several articles which have 
      highlighted the limitations of ChatGPT in its current iteration, which will allow 
      radiologists and researchers to improve these areas.
CI  - Copyright © 2023. Published by Elsevier Inc.
FAU - Bera, Kaustav
AU  - Bera K
AD  - Department of Radiology, University Hospitals Cleveland Medical Center, 11000 
      Euclid Avenue, Cleveland, OH, 44106, USA. Electronic address: kxb413@case.edu.
FAU - O'Connor, Gregory
AU  - O'Connor G
AD  - Department of Radiology, University Hospitals Cleveland Medical Center, 11000 
      Euclid Avenue, Cleveland, OH, 44106, USA.
FAU - Jiang, Sirui
AU  - Jiang S
AD  - Department of Radiology, University Hospitals Cleveland Medical Center, 11000 
      Euclid Avenue, Cleveland, OH, 44106, USA.
FAU - Tirumani, Sree Harsha
AU  - Tirumani SH
AD  - Department of Radiology, University Hospitals Cleveland Medical Center, 11000 
      Euclid Avenue, Cleveland, OH, 44106, USA.
FAU - Ramaiya, Nikhil
AU  - Ramaiya N
AD  - Department of Radiology, University Hospitals Cleveland Medical Center, 11000 
      Euclid Avenue, Cleveland, OH, 44106, USA.
LA  - eng
PT  - Journal Article
DEP - 20231020
PL  - United States
TA  - Curr Probl Diagn Radiol
JT  - Current problems in diagnostic radiology
JID - 7607123
SB  - IM
MH  - Diagnostic Imaging
MH  - *Publications
MH  - Radiography
MH  - *Radiology
MH  - *Artificial Intelligence
EDAT- 2023/10/28 11:42
MHDA- 2024/03/05 06:44
CRDT- 2023/10/27 22:57
PHST- 2023/09/19 00:00 [received]
PHST- 2023/10/18 00:00 [accepted]
PHST- 2024/03/05 06:44 [medline]
PHST- 2023/10/28 11:42 [pubmed]
PHST- 2023/10/27 22:57 [entrez]
AID - S0363-0188(23)00166-4 [pii]
AID - 10.1067/j.cpradiol.2023.10.013 [doi]
PST - ppublish
SO  - Curr Probl Diagn Radiol. 2024 Mar-Apr;53(2):215-225. doi: 
      10.1067/j.cpradiol.2023.10.013. Epub 2023 Oct 20.

PMID- 38219888
OWN - NLM
STAT- MEDLINE
DCOM- 20240308
LR  - 20240308
IS  - 1879-176X (Electronic)
IS  - 0300-5712 (Linking)
VI  - 142
DP  - 2024 Mar
TI  - Can ChatGPT identify predatory biomedical and dental journals? A cross-sectional 
      content analysis.
PG  - 104840
LID - S0300-5712(24)00010-1 [pii]
LID - 10.1016/j.jdent.2024.104840 [doi]
AB  - OBJECTIVES: To assess whether ChatGPT can help to identify predatory biomedical 
      and dental journals, analyze the content of its responses and compare the 
      frequency of positive and negative indicators provided by ChatGPT concerning 
      predatory and legitimate journals. METHODS: Four-hundred predatory and legitimate 
      biomedical and dental journals were selected from four sources: Beall's list, 
      unsolicited emails, the Web of Science (WOS) journal list and the Directory of 
      Open Access Journals (DOAJ). ChatGPT was asked to determine journal legitimacy. 
      Journals were classified into legitimate or predatory. Pearson's Chi-squared test 
      and logistic regression were conducted. Two machine learning algorithms 
      determined the most influential criteria on the correct classification of 
      journals. RESULTS: The data were categorized under 10 criteria with the most 
      frequently coded criteria being the transparency of processes and policies. 
      ChatGPT correctly classified predatory and legitimate journals in 92.5&nbsp;% and 71&nbsp;% 
      of the sample, respectively. The accuracy of ChatGPT responses was 0.82. ChatGPT 
      also demonstrated a high level of sensitivity (0.93). Additionally, the model 
      exhibited a specificity of 0.71, accurately identifying true negatives. A highly 
      significant association between ChatGPT verdicts and the classification based on 
      known sources was observed (P &lt;0.001). ChatGPT was 30.2 times more likely to 
      correctly classify a predatory journal (95&nbsp;% confidence interval: 16.9-57.43, 
      p-value: &lt;0.001). CONCLUSIONS: ChatGPT can accurately distinguish predatory and 
      legitimate journals with a high level of accuracy. While some false positive 
      (29&nbsp;%) and false negative (7.5&nbsp;%) results were observed, it may be reasonable to 
      harness ChatGPT to assist with the identification of predatory journals. CLINICAL 
      SIGNIFICANCE STATEMENT: ChatGPT may effectively distinguish between predatory and 
      legitimate journals, with accuracy rates of 92.5&nbsp;% and 71&nbsp;%, respectively. The 
      potential utility of large-scale language models in exposing predatory 
      publications is worthy of further consideration.
CI  - Copyright © 2024 Elsevier Ltd. All rights reserved.
FAU - Al-Moghrabi, Dalya
AU  - Al-Moghrabi D
AD  - Department of Preventive Dental Sciences, College of Dentistry, Princess Nourah 
      bint Abdulrahman University, P.O. Box: 84428 Airport Road, Riyadh 11671, Saudi 
      Arabia. Electronic address: dhalmoghrabi@pnu.edu.sa.
FAU - Abu Arqub, Sarah
AU  - Abu Arqub S
AD  - Department of Orthodontics, University of Florida, Gainesville, FL, USA.
FAU - Maroulakos, Michael P
AU  - Maroulakos MP
AD  - Division of Public and Child Dental Health, Dublin Dental School and Hospital, 
      Dublin, Ireland.
FAU - Pandis, Nikolaos
AU  - Pandis N
AD  - Department of Orthodontics and Dentofacial Orthopedics, Medical Faculty, Dental 
      School, University of Bern, Bern, Switzerland.
FAU - Fleming, Padhraig S
AU  - Fleming PS
AD  - Division of Public and Child Dental Health, Dublin Dental School and Hospital, 
      Dublin, Ireland.
LA  - eng
PT  - Journal Article
DEP - 20240112
PL  - England
TA  - J Dent
JT  - Journal of dentistry
JID - 0354422
SB  - IM
MH  - Cross-Sectional Studies
MH  - *Periodicals as Topic
OTO - NOTNLM
OT  - Editorial policies
OT  - Ethics in publication
OT  - Medical ethics
OT  - Open access publishing
OT  - Scientific publishing
OT  - Transparency
COIS- Declaration of competing interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2024/01/15 00:42
MHDA- 2024/03/08 06:43
CRDT- 2024/01/14 19:35
PHST- 2023/12/07 00:00 [received]
PHST- 2024/01/09 00:00 [revised]
PHST- 2024/01/11 00:00 [accepted]
PHST- 2024/03/08 06:43 [medline]
PHST- 2024/01/15 00:42 [pubmed]
PHST- 2024/01/14 19:35 [entrez]
AID - S0300-5712(24)00010-1 [pii]
AID - 10.1016/j.jdent.2024.104840 [doi]
PST - ppublish
SO  - J Dent. 2024 Mar;142:104840. doi: 10.1016/j.jdent.2024.104840. Epub 2024 Jan 12.

PMID- 37658948
OWN - NLM
STAT- MEDLINE
DCOM- 20240110
LR  - 20240110
IS  - 1573-2584 (Electronic)
IS  - 0301-1623 (Linking)
VI  - 56
IP  - 1
DP  - 2024 Jan
TI  - Evaluating the performance of ChatGPT in answering questions related to 
      urolithiasis.
PG  - 17-21
LID - 10.1007/s11255-023-03773-0 [doi]
AB  - PURPOSE: ChatGPT is an artificial intelligence (AI) program with natural language 
      processing. We analyzed ChatGPT's knowledge about urolithiasis whether it can be 
      used to inform patients about urolithiasis. METHODS: Frequently asked questions 
      (FAQs) about urolithiasis on the websites of urological associations and 
      hospitals were analyzed. Also, strong recommendation-level information was 
      gathered from the urolithiasis section of the European Association of Urology 
      (EAU) 2022 Guidelines. All questions were asked in order in ChatGPT August 3rd 
      version. All answers were evaluated separately by two specialist urologists and 
      scored between 1 and 4, where 1: completely correct, 2: correct but inadequate, 
      3: a mix of correct and misleading information, and 4: completely incorrect. 
      RESULTS: Of the FAQs, 94.6% were answered completely correctly. No question was 
      answered completely incorrectly. All questions about general, diagnosis, and 
      ureteral stones were graded as 1. Of the 60 questions prepared according to the 
      EAU guideline recommendations, 50 (83.3%) were evaluated as grade 1, and 8 
      (13.3%) and 2 (3.3%) as grade 3. All questions related to general, diagnostic, 
      renal calculi, ureteral calculi, and metabolic evaluation received the same 
      answer the second time they were asked. CONCLUSION: Our findings demonstrated 
      that ChatGPT accurately and satisfactorily answered more than 95% of the 
      questions about urolithiasis. We conclude that applying ChatGPT in urology 
      clinics under the supervision of urologists can help patients and their families 
      to have better understanding on urolithiasis diagnosis and treatment.
CI  - © 2023. The Author(s), under exclusive licence to Springer Nature B.V.
FAU - Cakir, Hakan
AU  - Cakir H
AUID- ORCID: 0009-0003-7341-8360
AD  - Department of Urology, Fulya Acibadem Hospital, Sisli, Istanbul, Turkey. 
      hakancakirmd@gmail.com.
FAU - Caglar, Ufuk
AU  - Caglar U
AD  - Department of Urology, Haseki Training and Research Hospital, Istanbul, Turkey.
FAU - Yildiz, Oguzhan
AU  - Yildiz O
AD  - Department of Urology, Haseki Training and Research Hospital, Istanbul, Turkey.
FAU - Meric, Arda
AU  - Meric A
AD  - Department of Urology, Haseki Training and Research Hospital, Istanbul, Turkey.
FAU - Ayranci, Ali
AU  - Ayranci A
AD  - Department of Urology, Haseki Training and Research Hospital, Istanbul, Turkey.
FAU - Ozgor, Faruk
AU  - Ozgor F
AD  - Department of Urology, Haseki Training and Research Hospital, Istanbul, Turkey.
LA  - eng
PT  - Journal Article
DEP - 20230902
PL  - Netherlands
TA  - Int Urol Nephrol
JT  - International urology and nephrology
JID - 0262521
SB  - IM
MH  - Humans
MH  - Artificial Intelligence
MH  - *Urolithiasis/diagnosis
MH  - *Ureteral Calculi
MH  - *Kidney Calculi
MH  - Hospitals
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Patient knowledge
OT  - Urolithiasis
EDAT- 2023/09/04 01:22
MHDA- 2024/01/10 06:42
CRDT- 2023/09/02 11:06
PHST- 2023/08/12 00:00 [received]
PHST- 2023/08/26 00:00 [accepted]
PHST- 2024/01/10 06:42 [medline]
PHST- 2023/09/04 01:22 [pubmed]
PHST- 2023/09/02 11:06 [entrez]
AID - 10.1007/s11255-023-03773-0 [pii]
AID - 10.1007/s11255-023-03773-0 [doi]
PST - ppublish
SO  - Int Urol Nephrol. 2024 Jan;56(1):17-21. doi: 10.1007/s11255-023-03773-0. Epub 
      2023 Sep 2.

PMID- 37341179
OWN - NLM
STAT- Publisher
LR  - 20231024
IS  - 1546-3141 (Electronic)
IS  - 0361-803X (Linking)
VI  - 221
IP  - 5
DP  - 2023 Nov
TI  - Use of ChatGPT, GPT-4, and Bard to Improve Readability of ChatGPT's Answers to 
      Common Questions About Lung Cancer and Lung Cancer Screening.
PG  - 701-704
LID - 10.2214/AJR.23.29622 [doi]
FAU - Haver, Hana L
AU  - Haver HL
AD  - University of Maryland School of Medicine, Baltimore, MD.
FAU - Lin, Cheng Ting
AU  - Lin CT
AD  - Johns Hopkins University School of Medicine, Baltimore, MD.
FAU - Sirajuddin, Arlene
AU  - Sirajuddin A
AD  - NIH, Bethesda, MD.
FAU - Yi, Paul H
AU  - Yi PH
AD  - University of Maryland School of Medicine, Johns Hopkins University, Baltimore, 
      MD.
AD  - University of Maryland, College Park, MD.
FAU - Jeudy, Jean
AU  - Jeudy J
AD  - University of Maryland School of Medicine, Baltimore, MD, 
      jjeudy@som.umaryland.edu.
LA  - eng
PT  - Journal Article
DEP - 20230621
PL  - United States
TA  - AJR Am J Roentgenol
JT  - AJR. American journal of roentgenology
JID - 7708173
SB  - IM
OAB - ChatGPT’s responses to questions about lung cancer and LCS, although deemed 
      clinically appropriate by cardiothoracic radiologists, were difficult to read. 
      Simplified responses from three LLMs (ChatGPT, GPT-4, and Bard) had improved 
      reading ease and readability (in terms of U.S. grade levels). However, some 
      simplified responses were no longer clinically appropriate.
OABL- eng
EDAT- 2023/06/21 13:04
MHDA- 2023/06/21 13:04
CRDT- 2023/06/21 06:53
PHST- 2023/06/21 13:04 [pubmed]
PHST- 2023/06/21 13:04 [medline]
PHST- 2023/06/21 06:53 [entrez]
AID - 10.2214/AJR.23.29622 [doi]
PST - ppublish
SO  - AJR Am J Roentgenol. 2023 Nov;221(5):701-704. doi: 10.2214/AJR.23.29622. Epub 
      2023 Jun 21.

PMID- 37452215
OWN - NLM
STAT- MEDLINE
DCOM- 20240214
LR  - 20240214
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 52
IP  - 3
DP  - 2024 Mar
TI  - The Role of ChatGPT in Medical Research: Progress and Limitations.
PG  - 458-461
LID - 10.1007/s10439-023-03311-0 [doi]
AB  - Advancements in AI have resulted in the development of sophisticated language 
      models like ChatGPT, which can generate human-like text. While ChatGPT is useful 
      for clarifying concepts and providing basic guidance, it has limitations. It 
      lacks the ability to provide the latest scientific information and access 
      original medical databases. Studies have shown that ChatGPT's text can be 
      robotic, shallow, and lacking a human touch. It has also been found to provide 
      misleading or inaccurate information. Researchers and medical professionals 
      should be aware of these limitations and not solely rely on ChatGPT for complex 
      tasks. The human element and real-world experiences are indispensable in science, 
      and consulting experts is advisable for reliable insights.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Ashraf, Hamza
AU  - Ashraf H
AUID- ORCID: 0009-0007-9121-6091
AD  - Allama Iqbal Medical College, Lahore, Punjab, Pakistan. monsterguzura@gmail.com.
FAU - Ashfaq, Haider
AU  - Ashfaq H
AUID- ORCID: 0009-0002-4372-9929
AD  - Allama Iqbal Medical College, Lahore, Punjab, Pakistan.
LA  - eng
PT  - Letter
DEP - 20230714
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - Humans
MH  - *Biomedical Research
MH  - Databases, Factual
MH  - *Robotics
MH  - Touch
MH  - *Touch Perception
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGpt
OT  - Medical research
EDAT- 2023/07/15 10:42
MHDA- 2024/02/12 15:42
CRDT- 2023/07/14 23:29
PHST- 2023/07/03 00:00 [received]
PHST- 2023/07/06 00:00 [accepted]
PHST- 2024/02/12 15:42 [medline]
PHST- 2023/07/15 10:42 [pubmed]
PHST- 2023/07/14 23:29 [entrez]
AID - 10.1007/s10439-023-03311-0 [pii]
AID - 10.1007/s10439-023-03311-0 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2024 Mar;52(3):458-461. doi: 10.1007/s10439-023-03311-0. Epub 
      2023 Jul 14.

PMID- 37934828
OWN - NLM
STAT- MEDLINE
DCOM- 20240201
LR  - 20240209
IS  - 1938-808X (Electronic)
IS  - 1040-2446 (Linking)
VI  - 99
IP  - 2
DP  - 2024 Feb 1
TI  - Examining ChatGPT Performance on USMLE Sample Items and Implications for 
      Assessment.
PG  - 192-197
LID - 10.1097/ACM.0000000000005549 [doi]
AB  - PURPOSE: In late 2022 and early 2023, reports that ChatGPT could pass the United 
      States Medical Licensing Examination (USMLE) generated considerable excitement, 
      and media response suggested ChatGPT has credible medical knowledge. This report 
      analyzes the extent to which an artificial intelligence (AI) agent's performance 
      on these sample items can generalize to performance on an actual USMLE 
      examination and an illustration is given using ChatGPT. METHOD: As with earlier 
      investigations, analyses were based on publicly available USMLE sample items. 
      Each item was submitted to ChatGPT (version 3.5) 3 times to evaluate stability. 
      Responses were scored following rules that match operational practice, and a 
      preliminary analysis explored the characteristics of items that ChatGPT answered 
      correctly. The study was conducted between February and March 2023. RESULTS: For 
      the full sample of items, ChatGPT scored above 60% correct except for one 
      replication for Step 3. Response success varied across replications for 76 items 
      (20%). There was a modest correspondence with item difficulty wherein ChatGPT was 
      more likely to respond correctly to items found easier by examinees. ChatGPT 
      performed significantly worse ( P &lt; .001) on items relating to practice-based 
      learning. CONCLUSIONS: Achieving 60% accuracy is an approximate indicator of 
      meeting the passing standard, requiring statistical adjustments for comparison. 
      Hence, this assessment can only suggest consistency with the passing standards 
      for Steps 1 and 2 Clinical Knowledge, with further limitations in extrapolating 
      this inference to Step 3. These limitations are due to variances in item 
      difficulty and exclusion of the simulation component of Step 3 from the 
      evaluation-limitations that would apply to any AI system evaluated on the Step 3 
      sample items. It is crucial to note that responses from large language models 
      exhibit notable variations when faced with repeated inquiries, underscoring the 
      need for expert validation to ensure their utility as a learning tool.
CI  - Copyright © 2023 The Author(s). Published by Wolters Kluwer Health, Inc. on 
      behalf of the Association of American Medical Colleges.
FAU - Yaneva, Victoria
AU  - Yaneva V
FAU - Baldwin, Peter
AU  - Baldwin P
FAU - Jurich, Daniel P
AU  - Jurich DP
FAU - Swygert, Kimberly
AU  - Swygert K
FAU - Clauser, Brian E
AU  - Clauser BE
LA  - eng
PT  - Journal Article
DEP - 20231107
PL  - United States
TA  - Acad Med
JT  - Academic medicine : journal of the Association of American Medical Colleges
JID - 8904605
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Computer Simulation
MH  - *Knowledge
MH  - Language
MH  - Learning
EDAT- 2023/11/07 18:42
MHDA- 2024/02/01 06:43
CRDT- 2023/11/07 14:13
PHST- 2024/02/01 06:43 [medline]
PHST- 2023/11/07 18:42 [pubmed]
PHST- 2023/11/07 14:13 [entrez]
AID - 00001888-202402000-00024 [pii]
AID - 10.1097/ACM.0000000000005549 [doi]
PST - ppublish
SO  - Acad Med. 2024 Feb 1;99(2):192-197. doi: 10.1097/ACM.0000000000005549. Epub 2023 
      Nov 7.

PMID- 38552842
OWN - NLM
STAT- Publisher
LR  - 20240329
IS  - 2468-1210 (Electronic)
IS  - 2468-1210 (Linking)
DP  - 2024 Mar 27
TI  - ChatGPT Earns American Board Certification in Hand Surgery.
PG  - 101688
LID - S2468-1229(24)00065-3 [pii]
LID - 10.1016/j.hansur.2024.101688 [doi]
AB  - PURPOSE: Artificial Intelligence (AI), and specifically ChatGPT, has shown 
      potential in healthcare, yet its performance in specialized medical examinations 
      such as the Orthopaedic Surgery In-Training Examination and European Board Hand 
      Surgery diploma has been inconsistent. This study aims to evaluate the capability 
      of ChatGPT-4 to pass the American Hand Surgery Certifying Examination. METHODS: 
      ChatGPT-4 was tested on the 2019 American Society for Surgery of the Hand (ASSH) 
      Self-Assessment Exam. All 200 questions available online 
      (https://onlinecme.assh.org) were retrieved. All media-containing questions were 
      flagged and carefully reviewed. Eight media-containing questions were excluded as 
      they either relied purely on videos or could not be rationalized from the 
      presented information. Descriptive statistics were used to summarize the 
      performance (% correct) of ChatGPT-4. The ASSH report was used to compare 
      ChatGPT-4's performance to that of the 322 physicians who completed the 2019 ASSH 
      self-assessment. RESULTS: ChatGPT-4 answered 192 questions with an overall score 
      of 61.98%. Performance on media-containing questions was 55.56%, while on 
      non-media questions it was 65.83%, with no statistical difference in performance 
      based on media inclusion. Despite scoring below the average physician's 
      performance, ChatGPT-4 outperformed in the 'vascular' section with 81.82%. Its 
      performance was lower in the 'bone and joint' (48.54%) and 'neuromuscular' 
      (56.25%) sections. CONCLUSIONS: ChatGPT-4 achieved a good overall score of 
      61.98%. This AI language model demonstrates significant capability in processing 
      and answering specialized medical examination questions, albeit with room for 
      improvement in areas requiring complex clinical judgment and nuanced 
      interpretation. ChatGPT-4's proficiency is influenced by the structure and 
      language of the examination, with no replacement for the depth of trained medical 
      specialists. This study underscores the supportive role of AI in medical 
      education and clinical decision-making while highlighting the current limitations 
      in nuanced fields such as hand surgery.
CI  - Copyright © 2024. Published by Elsevier Masson SAS.
FAU - Ghanem, Diane
AU  - Ghanem D
AD  - Department of Orthopaedic Surgery, The Johns Hopkins Hospital, Baltimore, MD, 
      USA. Electronic address: dghanem1@jh.edu.
FAU - Nassar, Joseph
AU  - Nassar J
AD  - Faculty of Medicine, American University of Beirut, Lebanon.
FAU - El Bachour, Joseph
AU  - El Bachour J
AD  - Faculty of Medicine, American University of Beirut, Lebanon.
FAU - Hanna, Tammam
AU  - Hanna T
AD  - Department of Orthopaedic Surgery and Rehabilitation, Texas Tech University 
      Health Sciences Center, Lubbock, TX, USA.
LA  - eng
PT  - Journal Article
DEP - 20240327
PL  - France
TA  - Hand Surg Rehabil
JT  - Hand surgery &amp; rehabilitation
JID - 101681801
SB  - IM
OTO - NOTNLM
OT  - Artificial Intelligence
OT  - ChatGPT
OT  - Hand Board Examination
OT  - Hand Surgery
OT  - Language Model
OT  - Orthopaedic Surgery
EDAT- 2024/03/30 11:46
MHDA- 2024/03/30 11:46
CRDT- 2024/03/29 20:27
PHST- 2024/03/11 00:00 [received]
PHST- 2024/03/21 00:00 [revised]
PHST- 2024/03/23 00:00 [accepted]
PHST- 2024/03/30 11:46 [medline]
PHST- 2024/03/30 11:46 [pubmed]
PHST- 2024/03/29 20:27 [entrez]
AID - S2468-1229(24)00065-3 [pii]
AID - 10.1016/j.hansur.2024.101688 [doi]
PST - aheadofprint
SO  - Hand Surg Rehabil. 2024 Mar 27:101688. doi: 10.1016/j.hansur.2024.101688.

PMID- 38212802
OWN - NLM
STAT- MEDLINE
DCOM- 20240115
LR  - 20240115
IS  - 1472-6920 (Electronic)
IS  - 1472-6920 (Linking)
VI  - 24
IP  - 1
DP  - 2024 Jan 11
TI  - ChatGPT sits the DFPH exam: large language model performance and potential to 
      support public health learning.
PG  - 57
LID - 10.1186/s12909-024-05042-9 [doi]
LID - 57
AB  - BACKGROUND: Artificial intelligence-based large language models, like ChatGPT, 
      have been rapidly assessed for both risks and potential in health-related 
      assessment and learning. However, their applications in public health 
      professional exams have not yet been studied. We evaluated the performance of 
      ChatGPT in part of the Faculty of Public Health's Diplomat exam (DFPH). METHODS: 
      ChatGPT was provided with a bank of 119 publicly available DFPH question parts 
      from past papers. Its performance was assessed by two active DFPH examiners. The 
      degree of insight and level of understanding apparently displayed by ChatGPT was 
      also assessed. RESULTS: ChatGPT passed 3 of 4 papers, surpassing the current pass 
      rate. It performed best on questions relating to research methods. Its answers 
      had a high floor. Examiners identified ChatGPT answers with 73.6% accuracy and 
      human answers with 28.6% accuracy. ChatGPT provided a mean of 3.6 unique insights 
      per question and appeared to demonstrate a required level of learning on 71.4% of 
      occasions. CONCLUSIONS: Large language models have rapidly increasing potential 
      as a learning tool in public health education. However, their factual fallibility 
      and the difficulty of distinguishing their responses from that of humans pose 
      potential threats to teaching and learning.
CI  - © 2024. The Author(s).
FAU - Davies, Nathan P
AU  - Davies NP
AD  - Nottingham Centre for Public Health and Epidemiology, University of Nottingham, 
      Nottingham City Hospital, Hucknall Rd, Nottingham, NG5 1PB, England. 
      Nathan.davies@nottingham.ac.uk.
FAU - Wilson, Robert
AU  - Wilson R
AD  - NHS England, Seaton House, City Link, London Road, Nottingham, NG2 4LA, England.
FAU - Winder, Madeleine S
AU  - Winder MS
AD  - Nottingham Centre for Public Health and Epidemiology, University of Nottingham, 
      Nottingham City Hospital, Hucknall Rd, Nottingham, NG5 1PB, England.
FAU - Tunster, Simon J
AU  - Tunster SJ
AD  - Nottingham Centre for Public Health and Epidemiology, University of Nottingham, 
      Nottingham City Hospital, Hucknall Rd, Nottingham, NG5 1PB, England.
FAU - McVicar, Kathryn
AU  - McVicar K
AD  - Nottingham Centre for Public Health and Epidemiology, University of Nottingham, 
      Nottingham City Hospital, Hucknall Rd, Nottingham, NG5 1PB, England.
FAU - Thakrar, Shivan
AU  - Thakrar S
AD  - Leicester City Council, Public Health, 115 Charles Street, Leicester, LE1 1FZ, 
      England.
FAU - Williams, Joe
AU  - Williams J
AD  - School of Health and Related Research (ScHARR), The University of Sheffield, 30 
      Regent St, Sheffield, S1 4DA, England.
FAU - Reid, Allan
AU  - Reid A
AD  - NHS England, Seaton House, City Link, London Road, Nottingham, NG2 4LA, England.
LA  - eng
PT  - Journal Article
DEP - 20240111
PL  - England
TA  - BMC Med Educ
JT  - BMC medical education
JID - 101088679
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Public Health
MH  - Health Education
MH  - Learning
MH  - Language
PMC - PMC10782695
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Examination
OT  - Public health
OT  - Theory
COIS- The authors declare no competing interests.
EDAT- 2024/01/12 00:42
MHDA- 2024/01/15 12:43
PMCR- 2024/01/11
CRDT- 2024/01/11 23:39
PHST- 2023/10/26 00:00 [received]
PHST- 2024/01/06 00:00 [accepted]
PHST- 2024/01/15 12:43 [medline]
PHST- 2024/01/12 00:42 [pubmed]
PHST- 2024/01/11 23:39 [entrez]
PHST- 2024/01/11 00:00 [pmc-release]
AID - 10.1186/s12909-024-05042-9 [pii]
AID - 5042 [pii]
AID - 10.1186/s12909-024-05042-9 [doi]
PST - epublish
SO  - BMC Med Educ. 2024 Jan 11;24(1):57. doi: 10.1186/s12909-024-05042-9.

PMID- 38417624
OWN - NLM
STAT- Publisher
LR  - 20240323
IS  - 1878-8769 (Electronic)
IS  - 1878-8750 (Linking)
DP  - 2024 Feb 28
TI  - Will ChatGPT be Able to Replace a Spine Surgeon in the Clinical Setting?
LID - S1878-8750(24)00314-0 [pii]
LID - 10.1016/j.wneu.2024.02.101 [doi]
AB  - OBJECTIVE: This study evaluates ChatGPT's performance in diagnosing and managing 
      spinal pathologies. METHODS: Patients underwent evaluation by two spine surgeons 
      (and the case was discussed and a consensus was reached) and ChatGPT. Patient 
      data, including demographics, symptoms, and available imaging reports, were 
      collected using a standardized form. This information was then processed by 
      ChatGPT for diagnosis and management recommendations. The study assessed 
      ChatGPT's diagnostic and management accuracy through descriptive statistics, 
      comparing its performance to that of experienced spine specialists. RESULTS: A 
      total of 97 patients with various spinal pathologies participated in the study, 
      with a gender distribution of 40 males and 57 females. ChatGPT achieved a 70% 
      diagnostic accuracy rate and provided suitable management recommendations for 95% 
      of patients. However, it struggled with certain pathologies, misdiagnosing 100% 
      of vertebral trauma and facet joint syndrome, 40% of spondylolisthesis, stenosis, 
      and scoliosis, and 22% of disc-related pathologies. Furthermore, ChatGPT's 
      management recommendations were poor in 53% of cases, often failing to suggest 
      the most appropriate treatment options and occasionally providing incomplete 
      advice. CONCLUSIONS: While helpful in the medical field, ChatGPT falls short in 
      providing reliable management recommendations, with a 30% misdiagnosis rate and 
      53% mismanagement rate in our study. Its limitations, including reliance on 
      outdated data and the inability to interactively gather patient information, must 
      be acknowledged. Surgeons should use ChatGPT cautiously as a supplementary tool 
      rather than a substitute for their clinical expertise, as the complexities of 
      healthcare demand human judgment and interaction.
CI  - Copyright © 2024 Elsevier Inc. All rights reserved.
FAU - Chalhoub, Ralph
AU  - Chalhoub R
AD  - Saint Joseph University, Faculty of medicine, Beirut, Lebanon.
FAU - Mouawad, Antoine
AU  - Mouawad A
AD  - Saint Joseph University, Faculty of medicine, Beirut, Lebanon.
FAU - Aoun, Marven
AU  - Aoun M
AD  - Saint Joseph University, Faculty of medicine, Beirut, Lebanon.
FAU - Daher, Mohammad
AU  - Daher M
AD  - Saint Joseph University, Faculty of medicine, Beirut, Lebanon; Department of 
      Orthopedic Surgery, Brown University, Providence, Rhode Island, USA.
FAU - El-Sett, Pierre
AU  - El-Sett P
AD  - Saint Joseph University, Faculty of medicine, Beirut, Lebanon; Department of 
      Orthopedic Surgery, Hotel Dieu de France Hospital, Beirut, Lebanon.
FAU - Kreichati, Gaby
AU  - Kreichati G
AD  - Saint Joseph University, Faculty of medicine, Beirut, Lebanon; Department of 
      Orthopedic Surgery, Hotel Dieu de France Hospital, Beirut, Lebanon.
FAU - Kharrat, Khalil
AU  - Kharrat K
AD  - Saint Joseph University, Faculty of medicine, Beirut, Lebanon; Department of 
      Orthopedic Surgery, Hotel Dieu de France Hospital, Beirut, Lebanon.
FAU - Sebaaly, Amer
AU  - Sebaaly A
AD  - Saint Joseph University, Faculty of medicine, Beirut, Lebanon; Department of 
      Orthopedic Surgery, Hotel Dieu de France Hospital, Beirut, Lebanon. Electronic 
      address: amersebaaly@hotmail.com.
LA  - eng
PT  - Journal Article
DEP - 20240228
PL  - United States
TA  - World Neurosurg
JT  - World neurosurgery
JID - 101528275
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Spine surgery
EDAT- 2024/02/29 00:42
MHDA- 2024/02/29 00:42
CRDT- 2024/02/28 19:16
PHST- 2023/11/14 00:00 [received]
PHST- 2024/02/17 00:00 [revised]
PHST- 2024/02/19 00:00 [accepted]
PHST- 2024/02/29 00:42 [pubmed]
PHST- 2024/02/29 00:42 [medline]
PHST- 2024/02/28 19:16 [entrez]
AID - S1878-8750(24)00314-0 [pii]
AID - 10.1016/j.wneu.2024.02.101 [doi]
PST - aheadofprint
SO  - World Neurosurg. 2024 Feb 28:S1878-8750(24)00314-0. doi: 
      10.1016/j.wneu.2024.02.101.

PMID- 38248048
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240128
IS  - 2075-4418 (Print)
IS  - 2075-4418 (Electronic)
IS  - 2075-4418 (Linking)
VI  - 14
IP  - 2
DP  - 2024 Jan 12
TI  - ChatGPT's Accuracy on Magnetic Resonance Imaging Basics: Characteristics and 
      Limitations Depending on the Question Type.
LID - 10.3390/diagnostics14020171 [doi]
LID - 171
AB  - Our study aimed to assess the accuracy and limitations of ChatGPT in the domain 
      of MRI, focused on evaluating ChatGPT's performance in answering simple knowledge 
      questions and specialized multiple-choice questions related to MRI. A two-step 
      approach was used to evaluate ChatGPT. In the first step, 50 simple MRI-related 
      questions were asked, and ChatGPT's answers were categorized as correct, 
      partially correct, or incorrect by independent researchers. In the second step, 
      75 multiple-choice questions covering various MRI topics were posed, and the 
      answers were similarly categorized. The study utilized Cohen's kappa coefficient 
      for assessing interobserver agreement. ChatGPT demonstrated high accuracy in 
      answering straightforward MRI questions, with over 85% classified as correct. 
      However, its performance varied significantly across multiple-choice questions, 
      with accuracy rates ranging from 40% to 66.7%, depending on the topic. This 
      indicated a notable gap in its ability to handle more complex, specialized 
      questions requiring deeper understanding and context. In conclusion, this study 
      critically evaluates the accuracy of ChatGPT in addressing questions related to 
      Magnetic Resonance Imaging (MRI), highlighting its potential and limitations in 
      the healthcare sector, particularly in radiology. Our findings demonstrate that 
      ChatGPT, while proficient in responding to straightforward MRI-related questions, 
      exhibits variability in its ability to accurately answer complex multiple-choice 
      questions that require more profound, specialized knowledge of MRI. This 
      discrepancy underscores the nuanced role AI can play in medical education and 
      healthcare decision-making, necessitating a balanced approach to its application.
FAU - Lee, Kyu-Hong
AU  - Lee KH
AUID- ORCID: 0000-0003-1069-0810
AD  - Department of Radiology, Inha University College of Medicine, Incheon 22212, 
      Republic of Korea.
FAU - Lee, Ro-Woon
AU  - Lee RW
AUID- ORCID: 0000-0002-8678-8059
AD  - Department of Radiology, Inha University College of Medicine, Incheon 22212, 
      Republic of Korea.
LA  - eng
PT  - Journal Article
DEP - 20240112
PL  - Switzerland
TA  - Diagnostics (Basel)
JT  - Diagnostics (Basel, Switzerland)
JID - 101658402
PMC - PMC10814518
OTO - NOTNLM
OT  - ChatGPT
OT  - MCQ
OT  - MRI
COIS- The authors declare no conflict of interest.
EDAT- 2024/01/22 06:43
MHDA- 2024/01/22 06:44
PMCR- 2024/01/12
CRDT- 2024/01/22 04:35
PHST- 2023/12/04 00:00 [received]
PHST- 2024/01/04 00:00 [revised]
PHST- 2024/01/11 00:00 [accepted]
PHST- 2024/01/22 06:44 [medline]
PHST- 2024/01/22 06:43 [pubmed]
PHST- 2024/01/22 04:35 [entrez]
PHST- 2024/01/12 00:00 [pmc-release]
AID - diagnostics14020171 [pii]
AID - diagnostics-14-00171 [pii]
AID - 10.3390/diagnostics14020171 [doi]
PST - epublish
SO  - Diagnostics (Basel). 2024 Jan 12;14(2):171. doi: 10.3390/diagnostics14020171.

PMID- 37934302
OWN - NLM
STAT- MEDLINE
DCOM- 20231216
LR  - 20231216
IS  - 1573-6555 (Electronic)
IS  - 0090-6905 (Linking)
VI  - 52
IP  - 6
DP  - 2023 Dec
TI  - A Cross Sectional Study of ChatGPT in Translation: Magnitude of Use, Attitudes, 
      and Uncertainties.
PG  - 2937-2954
LID - 10.1007/s10936-023-10031-y [doi]
AB  - This preliminary cross-sectional study, focusing on Artificial Intelligence (AI), 
      aimed to assess the impact of ChatGPT on translation within an Arab context. It 
      primarily explored the attitudes of a sample of translation teachers and students 
      through semi-structured interviews and projective techniques. Data collection 
      included gathering information about the advantages and challenges that ChatGPT, 
      in comparison to Google Translate, had introduced to the field of translation and 
      translation teaching. The results indicated that nearly all the participants were 
      satisfied with ChatGPT. The results also revealed that most students preferred 
      ChatGPT over Google Translate, while most teachers favored Google Translate. The 
      study also found that the participants recognized both positive and negative 
      aspects of using ChatGPT in translation. Findings also indicated that ChatGPT, as 
      a recent AI-based translation-related technology, is more valuable for mechanical 
      processes of writing and editing translated texts than for tasks requiring 
      judgment, such as fine-tuning and double-checking. While it offers various 
      advantages, AI also presents new challenges that educators and stakeholders need 
      to address accordingly.
CI  - © 2023. The Author(s), under exclusive licence to Springer Science+Business 
      Media, LLC, part of Springer Nature.
FAU - Sahari, Yousef
AU  - Sahari Y
AD  - University of Bisha, Bisha, Saudi Arabia.
FAU - Al-Kadi, Abdu M Talib
AU  - Al-Kadi AMT
AD  - Ibb University, Ibb, Yemen.
FAU - Ali, Jamal Kaid Mohammed
AU  - Ali JKM
AUID- ORCID: 0000-0003-3079-5580
AD  - University of Bisha, Bisha, Saudi Arabia. jgmali@ub.edu.sa.
LA  - eng
PT  - Journal Article
DEP - 20231107
PL  - United States
TA  - J Psycholinguist Res
JT  - Journal of psycholinguistic research
JID - 0333506
SB  - IM
MH  - Humans
MH  - Cross-Sectional Studies
MH  - *Artificial Intelligence
MH  - *Judgment
MH  - Arabs
MH  - Students
OTO - NOTNLM
OT  - Arab Context
OT  - Artificial Intelligence (AI)
OT  - Attitudes
OT  - ChatGPT
OT  - Translation
EDAT- 2023/11/07 12:46
MHDA- 2023/12/17 09:45
CRDT- 2023/11/07 11:08
PHST- 2023/10/25 00:00 [accepted]
PHST- 2023/12/17 09:45 [medline]
PHST- 2023/11/07 12:46 [pubmed]
PHST- 2023/11/07 11:08 [entrez]
AID - 10.1007/s10936-023-10031-y [pii]
AID - 10.1007/s10936-023-10031-y [doi]
PST - ppublish
SO  - J Psycholinguist Res. 2023 Dec;52(6):2937-2954. doi: 10.1007/s10936-023-10031-y. 
      Epub 2023 Nov 7.

PMID- 37540015
OWN - NLM
STAT- Publisher
LR  - 20230804
IS  - 1365-2230 (Electronic)
IS  - 0307-6938 (Linking)
DP  - 2023 Aug 4
TI  - An original study of ChatGPT-3.5 and ChatGPT-4 Dermatological Knowledge Level 
      based on the Dermatology Specialty Certificate Examinations.
LID - llad255 [pii]
LID - 10.1093/ced/llad255 [doi]
AB  - BACKGROUND: The global use of artificial intelligence has the potential to 
      revolutionize the healthcare industry. Despite the fact that artificial 
      intelligence is becoming more popular, there is still a lack of evidence on its 
      use in dermatology. OBJECTIVE: The study aimed to determine the capacity of 
      ChatGPT-3.5 and ChatGPT-4 to support dermatological knowledge and clinical 
      decision-making in medical practice. METHODS: Three dermatology specialty 
      certificate tests, in English and Polish, consisting of 120 single-best-answer, 
      multiple-choice format questions each, were used to assess ChatGPT-3.5 and 
      ChatGPT-4 performance. RESULTS: ChatGPT-4 exceeded the 60% pass rate in every 
      performed test, with a minimum of 80% and 70% correct answers for the English and 
      Polish versions, respectively. ChatGPT-4 performed significantly better on each 
      exam (p&lt;0.01), regardless of the language, compared to ChatGPT-3.5. Furthermore, 
      ChatGPT-4 answered clinical picture-type questions with an average accuracy of 
      92.98% and 84.21% for English and Polish questions respectively. The difference 
      between the tests in Polish and English did not turn out to be significant but 
      still, ChatGPT-3.5 and ChatGPT-4 in English performed better overall than in 
      Polish by an average of 8 percentage points for each test. Incorrect ChatGPT 
      answers were highly correlated with a lower difficulty index, which denotes 
      questions with higher difficulty in most of the tests. (p&lt;0.05). CONCLUSION: The 
      dermatological knowledge level of ChatGPT was high, with a significantly better 
      performance of ChatGPT-4 than ChatGPT-3.5. Although the use of ChatGPT will not 
      replace the doctor's final decision, physicians should support artificial 
      intelligence development in dermatology to raise the standards of medical care.
CI  - © The Author(s) 2023. Published by Oxford University Press on behalf of British 
      Association of Dermatologists. All rights reserved. For permissions, please 
      e-mail: journals.permissions@oup.com.
FAU - Lewandowski, Miłosz
AU  - Lewandowski M
AUID- ORCID: 0000-0002-3561-5705
AD  - Department of Dermatology, Venereology and Allergology, Faculty of Medicine, 
      Medical University of Gdansk, Smoluchowskiego 17, 80-214 Gdansk, Poland.
FAU - Łukowicz, Paweł
AU  - Łukowicz P
AD  - Division of Biostatistics and Neural Networks, Medical University of Gdansk, 
      Debinki 1, 80-211 Gdansk, Poland.
FAU - Świetlik, Dariusz
AU  - Świetlik D
AD  - Division of Biostatistics and Neural Networks, Medical University of Gdansk, 
      Debinki 1, 80-211 Gdansk, Poland.
FAU - Barańska-Rybak, Wioletta
AU  - Barańska-Rybak W
AD  - Department of Dermatology, Venereology and Allergology, Faculty of Medicine, 
      Medical University of Gdansk, Smoluchowskiego 17, 80-214 Gdansk, Poland.
LA  - eng
PT  - Journal Article
DEP - 20230804
PL  - England
TA  - Clin Exp Dermatol
JT  - Clinical and experimental dermatology
JID - 7606847
SB  - IM
EDAT- 2023/08/04 13:10
MHDA- 2023/08/04 13:10
CRDT- 2023/08/04 09:02
PHST- 2023/05/17 00:00 [received]
PHST- 2023/07/17 00:00 [revised]
PHST- 2023/08/02 00:00 [accepted]
PHST- 2023/08/04 13:10 [medline]
PHST- 2023/08/04 13:10 [pubmed]
PHST- 2023/08/04 09:02 [entrez]
AID - 7237242 [pii]
AID - 10.1093/ced/llad255 [doi]
PST - aheadofprint
SO  - Clin Exp Dermatol. 2023 Aug 4:llad255. doi: 10.1093/ced/llad255.

PMID- 37426402
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230718
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 7
DP  - 2023 Jul
TI  - Transforming Medical Education: Assessing the Integration of ChatGPT Into Faculty 
      Workflows at a Caribbean Medical School.
PG  - e41399
LID - 10.7759/cureus.41399 [doi]
LID - e41399
AB  - INTRODUCTION: ChatGPT is a Large Language Model (LLM) which allows for natural 
      language processing and interactions with users in a conversational style. Since 
      its release in 2022, it has had a significant impact in many occupational fields, 
      including medical education. We sought to gain insight into the extent and type 
      of usage of ChatGPT at a Caribbean medical school, the American University of 
      Antigua College of Medicine (AUA). METHODS: We administered a questionnaire to 87 
      full-time faculty at the school via email. We quantified and made graphical 
      representations of the results via Qualtrics Experience Management software 
      (QualtricsXM, Qualtrics, Provo, UT). Survey results were investigated using bar 
      graph comparisons of absolute numbers and percentages for various categories 
      related to ChatGPT usage, and descriptive statistics for Likert scale questions. 
      RESULTS: We found an estimated 33% of faculty were currently using ChatGPT. There 
      was broad acceptance of the program by those who were using it and most believed 
      it should be an option for students. The primary task ChatGPT was being used for 
      was multiple choice question (MCQ) generation. The primary concern faculty had 
      was incorrect information being included in ChatGPT output. CONCLUSION: ChatGPT 
      has been quickly adopted by a subset of the college faculty, demonstrating its 
      growing acceptance. Given the level of approval expressed about the program, we 
      believe ChatGPT will continue to form an important and expanding part of faculty 
      workflows at AUA and in medical education in general.
CI  - Copyright © 2023, Cross et al.
FAU - Cross, Joseph
AU  - Cross J
AD  - Biochemistry, Cell Biology &amp; Genetics, American University of Antigua, St. 
      John's, ATG.
AD  - Microbial Pathogenesis and Immunology, Texas A&amp;M College of Medicine, College 
      Station, USA.
FAU - Robinson, Raymond
AU  - Robinson R
AD  - Clinical Sciences, American University of Antigua, St. John's, ATG.
FAU - Devaraju, Sumanth
AU  - Devaraju S
AD  - Family Medicine, American University of Antigua, St. John's, ATG.
FAU - Vaughans, Andrea
AU  - Vaughans A
AD  - Medical Education and Simulation, American University of Antigua, St. John's, 
      ATG.
FAU - Hood, Ricardo
AU  - Hood R
AD  - Clinical Sciences, American University of Antigua, St. John's, ATG.
FAU - Kayalackakom, Tarron
AU  - Kayalackakom T
AD  - Medical Education and Simulation, American University of Antigua, St. John's, 
      ATG.
FAU - Honnavar, Prasanna
AU  - Honnavar P
AD  - Microbiology, American University of Antigua, St. John's, ATG.
FAU - Naik, Sheetal
AU  - Naik S
AD  - Physiology, American University of Antigua, St. John's, ATG.
FAU - Sebastian, Roopa
AU  - Sebastian R
AD  - Biochemistry, Cell Biology &amp; Genetics, American University of Antigua, St. 
      John's, ATG.
LA  - eng
PT  - Journal Article
DEP - 20230705
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10328790
OTO - NOTNLM
OT  - artificial intelligence
OT  - chatgpt
OT  - medical education
OT  - medical faculty
OT  - survey
OT  - virtual assistant
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/07/10 06:42
MHDA- 2023/07/10 06:43
PMCR- 2023/07/05
CRDT- 2023/07/10 05:09
PHST- 2023/07/05 00:00 [accepted]
PHST- 2023/07/10 06:43 [medline]
PHST- 2023/07/10 06:42 [pubmed]
PHST- 2023/07/10 05:09 [entrez]
PHST- 2023/07/05 00:00 [pmc-release]
AID - 10.7759/cureus.41399 [doi]
PST - epublish
SO  - Cureus. 2023 Jul 5;15(7):e41399. doi: 10.7759/cureus.41399. eCollection 2023 Jul.

PMID- 37992892
OWN - NLM
STAT- Publisher
LR  - 20231202
IS  - 0003-4509 (Print)
IS  - 0003-4509 (Linking)
DP  - 2023 Nov 20
TI  - Assessing the applicability and appropriateness of ChatGPT in answering clinical 
      pharmacy questions.
LID - S0003-4509(23)00140-2 [pii]
LID - 10.1016/j.pharma.2023.11.001 [doi]
AB  - OBJECTIVES: Clinical pharmacists rely on different scientific references to 
      ensure appropriate, safe, and cost-effective drug use. Tools based on artificial 
      intelligence (AI) such as ChatGPT (Generative Pre-trained Transformer) could 
      offer valuable support. The objective of this study was to assess ChatGPT's 
      capacity to correctly respond to clinical pharmacy questions asked by healthcare 
      professionals in our university hospital. MATERIAL AND METHODS: ChatGPT's 
      capacity to respond correctly to the last 100&nbsp;consecutive questions recorded in 
      our clinical pharmacy database was assessed. Questions were copied from our 
      FileMaker Pro database and pasted into ChatGPT March 14 version online platform. 
      The generated answers were then copied verbatim into an Excel file. Two blinded 
      clinical pharmacists reviewed all the questions and the answers given by the 
      software. In case of disagreements, a third blinded pharmacist intervened to 
      decide. RESULTS: Documentation-related issues (n=36) and drug administration mode 
      (n=30) were preponderantly recorded. Among 69 applicable questions, the rate of 
      correct answers varied from 30 to 57.1% depending on questions type with a global 
      rate of 44.9%. Regarding inappropriate answers (n=38), 20 were incorrect, 18 gave 
      no answers and 8 were incomplete with 8 answers belonging to 2 different 
      categories. No better answers than the pharmacists were observed. CONCLUSIONS: 
      ChatGPT demonstrated a mitigated performance in answering clinical pharmacy 
      questions. It should not replace human expertise as a high rate of inappropriate 
      answers was highlighted. Future studies should focus on the optimization of 
      ChatGPT for specific clinical pharmacy questions and explore the potential 
      benefits and limitations of integrating this technology into clinical practice.
CI  - Copyright © 2023 Académie Nationale de Pharmacie. Published by Elsevier Masson 
      SAS. All rights reserved.
FAU - Fournier, A
AU  - Fournier A
AD  - Service of Pharmacy, Centre Hospitalier Universitaire Vaudois (CHUV), Lausanne, 
      Switzerland.
FAU - Fallet, C
AU  - Fallet C
AD  - Service of Pharmacy, Centre Hospitalier Universitaire Vaudois (CHUV), Lausanne, 
      Switzerland.
FAU - Sadeghipour, F
AU  - Sadeghipour F
AD  - Service of Pharmacy, Centre Hospitalier Universitaire Vaudois (CHUV), Lausanne, 
      Switzerland; School of Pharmaceutical Sciences, University of Geneva, University 
      of Lausanne, Geneva, Switzerland; Center for Research and Innovation in Clinical 
      Pharmaceutical Sciences, Lausanne University Hospital and University of Lausanne, 
      Lausanne, Switzerland.
FAU - Perrottet, N
AU  - Perrottet N
AD  - Service of Pharmacy, Centre Hospitalier Universitaire Vaudois (CHUV), Lausanne, 
      Switzerland; School of Pharmaceutical Sciences, University of Geneva, University 
      of Lausanne, Geneva, Switzerland. Electronic address: Nancy.Perrottet@chuv.ch.
LA  - eng
PT  - Journal Article
DEP - 20231120
PL  - France
TA  - Ann Pharm Fr
JT  - Annales pharmaceutiques francaises
JID - 2985176R
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Clinical pharmacy
OT  - Grands modèles de langage
OT  - Healthcare professionals’ issues
OT  - Intelligence artificielle
OT  - Large language models
OT  - Pharmacie clinique
OT  - Questions fréquentes des professionnels de la santé
EDAT- 2023/11/23 00:42
MHDA- 2023/11/23 00:42
CRDT- 2023/11/22 19:29
PHST- 2023/08/28 00:00 [received]
PHST- 2023/11/16 00:00 [revised]
PHST- 2023/11/16 00:00 [accepted]
PHST- 2023/11/23 00:42 [pubmed]
PHST- 2023/11/23 00:42 [medline]
PHST- 2023/11/22 19:29 [entrez]
AID - S0003-4509(23)00140-2 [pii]
AID - 10.1016/j.pharma.2023.11.001 [doi]
PST - aheadofprint
SO  - Ann Pharm Fr. 2023 Nov 20:S0003-4509(23)00140-2. doi: 
      10.1016/j.pharma.2023.11.001.

PMID- 38391252
OWN - NLM
STAT- Publisher
LR  - 20240223
IS  - 2724-5772 (Electronic)
IS  - 2724-5683 (Linking)
DP  - 2024 Feb 23
TI  - Is ChatGPT knowledgeable of acute coronary syndromes and pertinent European 
      Society of Cardiology Guidelines?
LID - 10.23736/S2724-5683.24.06517-7 [doi]
AB  - BACKGROUND: Advancements in artificial intelligence are being seen in multiple 
      fields, including medicine, and this trend is likely to continue going forward. 
      To analyze the accuracy and reproducibility of ChatGPT answers about acute 
      coronary syndromes (ACS). METHODS: The questions asked to ChatGPT were prepared 
      in two categories. A list of frequently asked questions (FAQs) created from 
      inquiries asked by the public and while preparing the scientific question list, 
      2023 European Society of Cardiology (ESC) Guidelines for the management of ACS 
      and ESC Clinical Practice Guidelines were used. Accuracy and reproducibility of 
      ChatGPT responses about ACS were evaluated by two cardiologists with ten years of 
      experience using Global Quality Score (GQS). RESULTS: Eventually, 72 FAQs related 
      to ACS met the study inclusion criteria. In total, 65 (90.3%) ChatGPT answers 
      scored GQS 5, which indicated highest accuracy and proficiency. None of the 
      ChatGPT responses to FAQs about ACS scored GQS 1. In addition, highest accuracy 
      and reliability of ChatGPT answers was obtained for the prevention and lifestyle 
      section with GQS 5 for 19 (95%) answers, and GQS 4 for 1 (5%) answer. In 
      contrast, accuracy and proficiency of ChatGPT answers were lowest for the 
      treatment and management section. Moreover, 68 (88.3%) ChatGPT responses for 
      guideline based questions scored GQS 5. Reproducibility of ChatGPT answers was 
      94.4% for FAQs and 90.9% for ESC guidelines questions. CONCLUSIONS: This study 
      shows for the first time that ChatGPT can give accurate and sufficient responses 
      to more than 90% of FAQs about ACS. In addition, proficiency and correctness of 
      ChatGPT answers about questions depending on ESC guidelines was also substantial.
FAU - Gurbuz, Dogac C
AU  - Gurbuz DC
AD  - Department of Cardiology, Gurlife Hospital, Eskisehir, Türkiye - 
      dogaccaglargurbuz@gmail.com.
FAU - Varis, Eser
AU  - Varis E
AD  - Department of Cardiology, Private Hospital, Istanbul, Türkiye.
LA  - eng
PT  - Journal Article
DEP - 20240223
PL  - Italy
TA  - Minerva Cardiol Angiol
JT  - Minerva cardiology and angiology
JID - 101776555
SB  - IM
EDAT- 2024/02/23 12:44
MHDA- 2024/02/23 12:44
CRDT- 2024/02/23 09:17
PHST- 2024/02/23 12:44 [medline]
PHST- 2024/02/23 12:44 [pubmed]
PHST- 2024/02/23 09:17 [entrez]
AID - S2724-5683.24.06517-7 [pii]
AID - 10.23736/S2724-5683.24.06517-7 [doi]
PST - aheadofprint
SO  - Minerva Cardiol Angiol. 2024 Feb 23. doi: 10.23736/S2724-5683.24.06517-7.

PMID- 38164506
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240103
IS  - 1177-5467 (Print)
IS  - 1177-5483 (Electronic)
IS  - 1177-5467 (Linking)
VI  - 17
DP  - 2023
TI  - The Utility of ChatGPT in Diabetic Retinopathy Risk Assessment: A Comparative 
      Study with Clinical Diagnosis.
PG  - 4021-4031
LID - 10.2147/OPTH.S435052 [doi]
AB  - PURPOSE: To evaluate the ability of an artificial intelligence (AI) model, 
      ChatGPT, in predicting the diabetic retinopathy (DR) risk. METHODS: This 
      retrospective observational study utilized an anonymized dataset of 111 patients 
      with diabetes who underwent a comprehensive eye examination along with clinical 
      and biochemical assessments. Clinical and biochemical data along with and without 
      central subfield thickness (CST) values of the macula from OCT were uploaded to 
      ChatGPT-4, and the response from the ChatGPT was compared to the clinical DR 
      diagnosis made by an ophthalmologist. RESULTS: The study assessed the consistency 
      of responses provided by ChatGPT, yielding an Intraclass Correlation Coefficient 
      (ICC) value of 0.936 (95% CI, 0.913-0.954, p &lt; 0.001) (with CST) and 0.915 (95% 
      CI, 0.706-0.846, p &lt; 0.001) (without CST), both situations indicated excellent 
      reliability. The sensitivity and specificity of ChatGPT in predicting the DR 
      cases were evaluated. The results revealed a sensitivity of 67% with CST and 73% 
      without CST. The specificity was 68% with CST and 54% without CST. However, 
      Cohen's kappa revealed only a fair agreement between ChatGPT predictions and 
      clinical DR status in both situations, with CST (kappa = 0.263, p = 0.005) and 
      without CST (kappa = 0.351, p &lt; 0.001). CONCLUSION: This study suggests that 
      ChatGPT has the potential of a preliminary DR screening tool with further 
      optimization needed for clinical use.
CI  - © 2023 Raghu et al.
FAU - Raghu, Keerthana
AU  - Raghu K
AD  - Shri Bhagwan Mahavir Vitreoretinal Services, Sankara Nethralaya, Chennai, Tamil 
      Nadu, India.
FAU - S, Tamilselvi
AU  - S T
AD  - Centre for Health Care Advancement, Innovation, and Research Department, Vellore 
      Institute of Technology, Chennai, Tamil Nadu, India.
FAU - S Devishamani, Chitralekha
AU  - S Devishamani C
AD  - Shri Bhagwan Mahavir Vitreoretinal Services, Sankara Nethralaya, Chennai, Tamil 
      Nadu, India.
FAU - M, Suchetha
AU  - M S
AD  - Centre for Health Care Advancement, Innovation, and Research Department, Vellore 
      Institute of Technology, Chennai, Tamil Nadu, India.
FAU - Rajalakshmi, Ramachandran
AU  - Rajalakshmi R
AUID- ORCID: 0000-0002-7063-6026
AD  - Department of Diabetology, Ophthalmology and Epidemiology, Madras Diabetes 
      Research Foundation &amp; Dr. Mohan's Diabetes Specialities Centre, Chennai, Tamil 
      Nadu, India.
FAU - Raman, Rajiv
AU  - Raman R
AD  - Shri Bhagwan Mahavir Vitreoretinal Services, Sankara Nethralaya, Chennai, Tamil 
      Nadu, India.
LA  - eng
PT  - Journal Article
DEP - 20231228
PL  - New Zealand
TA  - Clin Ophthalmol
JT  - Clinical ophthalmology (Auckland, N.Z.)
JID - 101321512
PMC - PMC10758156
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - diabetes
OT  - diabetic retinopathy
COIS- No conflicting relationship exists for any author.
EDAT- 2024/01/03 05:36
MHDA- 2024/01/03 05:37
PMCR- 2023/12/28
CRDT- 2024/01/02 03:46
PHST- 2023/08/11 00:00 [received]
PHST- 2023/11/22 00:00 [accepted]
PHST- 2024/01/03 05:37 [medline]
PHST- 2024/01/03 05:36 [pubmed]
PHST- 2024/01/02 03:46 [entrez]
PHST- 2023/12/28 00:00 [pmc-release]
AID - 435052 [pii]
AID - 10.2147/OPTH.S435052 [doi]
PST - epublish
SO  - Clin Ophthalmol. 2023 Dec 28;17:4021-4031. doi: 10.2147/OPTH.S435052. eCollection 
      2023.

PMID- 37482572
OWN - NLM
STAT- Publisher
LR  - 20230723
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
DP  - 2023 Jul 23
TI  - The First Months of Life of ChatGPT and Its Impact in Healthcare: A Bibliometric 
      Analysis of the Current Literature.
LID - 10.1007/s10439-023-03325-8 [doi]
AB  - We aimed to evaluate current trends and future directions in the field of AI 
      research since ChatGPT was launched. We performed a bibliometric analysis of the 
      literature published during the first 7 months of the life of ChatGPT since its 
      introduction, updated to July 1st, 2023. Seven hundred and twenty-four (724) 
      articles were retrieved. This analysis highlights a significant increase in 
      publications exploring ChatGPT use across various medical disciplines, indicating 
      its expanding relevance in healthcare. A decline proportion of studies focusing 
      on ethical considerations was observed. Simultaneously, there was a steady 
      increase in studies focused on the exploration of possible applications of 
      ChatGPT. As ChatGPT applications continue to expand, ongoing vigilance and 
      collaborative efforts to optimize ChatGPT performance are essential in harnessing 
      the benefits while mitigating the risks of AI use in healthcare.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Alessandri-Bonetti, Mario
AU  - Alessandri-Bonetti M
AUID- ORCID: 0000-0002-5506-8323
AD  - Department of Plastic Surgery, University of Pittsburgh Medical Center, 1350 
      Locust Street, G103, Pittsburgh, PA, 15213, USA.
FAU - Liu, Hilary Y
AU  - Liu HY
AD  - Department of Plastic Surgery, University of Pittsburgh Medical Center, 1350 
      Locust Street, G103, Pittsburgh, PA, 15213, USA.
FAU - Giorgino, Riccardo
AU  - Giorgino R
AD  - Department of Orthopedics, IRCCS Istituto Ortopedico Galeazzi, Milan, Italy.
FAU - Nguyen, Vu T
AU  - Nguyen VT
AD  - Department of Plastic Surgery, University of Pittsburgh Medical Center, 1350 
      Locust Street, G103, Pittsburgh, PA, 15213, USA.
FAU - Egro, Francesco M
AU  - Egro FM
AUID- ORCID: 0000-0003-1536-7713
AD  - Department of Plastic Surgery, University of Pittsburgh Medical Center, 1350 
      Locust Street, G103, Pittsburgh, PA, 15213, USA. francescoegro@gmail.com.
AD  - Department of Plastic Surgery, University of Pittsburgh Medical Center, 3550 
      Terrace Street 6B Scaife Hall, Pittsburgh, PA, 15261, USA. 
      francescoegro@gmail.com.
LA  - eng
PT  - Letter
DEP - 20230723
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Bibliometric analysis
OT  - ChatGPT
OT  - Deep learning
OT  - Natural language processing
EDAT- 2023/07/24 00:41
MHDA- 2023/07/24 00:41
CRDT- 2023/07/23 23:06
PHST- 2023/07/12 00:00 [received]
PHST- 2023/07/14 00:00 [accepted]
PHST- 2023/07/24 00:41 [medline]
PHST- 2023/07/24 00:41 [pubmed]
PHST- 2023/07/23 23:06 [entrez]
AID - 10.1007/s10439-023-03325-8 [pii]
AID - 10.1007/s10439-023-03325-8 [doi]
PST - aheadofprint
SO  - Ann Biomed Eng. 2023 Jul 23. doi: 10.1007/s10439-023-03325-8.

PMID- 38345613
OWN - NLM
STAT- MEDLINE
DCOM- 20240318
LR  - 20240402
IS  - 1434-4726 (Electronic)
IS  - 0937-4477 (Linking)
VI  - 281
IP  - 4
DP  - 2024 Apr
TI  - Exploring the role of ChatGPT in clinical decision-making in otorhinolaryngology: 
      a ChatGPT designed study.
PG  - 2023-2030
LID - 10.1007/s00405-024-08498-z [doi]
AB  - PURPOSE: Since the beginning of 2023, ChatGPT emerged as a hot topic in 
      healthcare research. The potential to be a valuable tool in clinical practice is 
      compelling, particularly in improving clinical decision support by helping 
      physicians to make clinical decisions based on the best medical knowledge 
      available. We aim to investigate ChatGPT's ability to identify, diagnose and 
      manage patients with otorhinolaryngology-related symptoms. METHODS: A 
      prospective, cross-sectional study was designed based on an idea suggested by 
      ChatGPT to assess the level of agreement between ChatGPT and five 
      otorhinolaryngologists (ENTs) in 20 reality-inspired clinical cases. The clinical 
      cases were presented to the chatbot on two different occasions (ChatGPT-1 and 
      ChatGPT-2) to assess its temporal stability. RESULTS: The mean score of ChatGPT-1 
      was 4.4 (SD 1.2; min 1, max 5) and of ChatGPT-2 was 4.15 (SD 1.3; min 1, max 5), 
      while the ENTs mean score was 4.91 (SD 0.3; min 3, max 5). The Mann-Whitney U 
      test revealed a statistically significant difference (p &lt; 0.001) between both 
      ChatGPT's and the ENTs's score. ChatGPT-1 and ChatGPT-2 gave different answers in 
      five occasions. CONCLUSIONS: Artificial intelligence will be an important 
      instrument in clinical decision-making in the near future and ChatGPT is the most 
      promising chatbot so far. Despite needing further development to be used with 
      safety, there is room for improvement and potential to aid otorhinolaryngology 
      residents and specialists in making the most correct decision for the patient.
CI  - © 2024. The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, 
      part of Springer Nature.
FAU - Teixeira-Marques, Francisco
AU  - Teixeira-Marques F
AUID- ORCID: 0000-0002-3621-2203
AD  - Department of Otorhinolaryngology, Centro Hospitalar de Vila Nova de 
      Gaia/Espinho, Gaia (Porto), Portugal. marquesjfrancisco@gmail.com.
FAU - Medeiros, Nuno
AU  - Medeiros N
AD  - Department of Otorhinolaryngology, Centro Hospitalar de Vila Nova de 
      Gaia/Espinho, Gaia (Porto), Portugal.
FAU - Nazaré, Francisco
AU  - Nazaré F
AD  - Department of Otorhinolaryngology, Centro Hospitalar de Vila Nova de 
      Gaia/Espinho, Gaia (Porto), Portugal.
FAU - Alves, Sandra
AU  - Alves S
AD  - Department of Otorhinolaryngology, Centro Hospitalar de Vila Nova de 
      Gaia/Espinho, Gaia (Porto), Portugal.
FAU - Lima, Nuno
AU  - Lima N
AD  - Department of Otorhinolaryngology, Centro Hospitalar de Vila Nova de 
      Gaia/Espinho, Gaia (Porto), Portugal.
FAU - Ribeiro, Leandro
AU  - Ribeiro L
AD  - Department of Otorhinolaryngology, Centro Hospitalar de Vila Nova de 
      Gaia/Espinho, Gaia (Porto), Portugal.
FAU - Gama, Rita
AU  - Gama R
AD  - Department of Otorhinolaryngology, Centro Hospitalar de Vila Nova de 
      Gaia/Espinho, Gaia (Porto), Portugal.
FAU - Oliveira, Pedro
AU  - Oliveira P
AD  - Department of Otorhinolaryngology, Centro Hospitalar de Vila Nova de 
      Gaia/Espinho, Gaia (Porto), Portugal.
LA  - eng
PT  - Journal Article
DEP - 20240212
PL  - Germany
TA  - Eur Arch Otorhinolaryngol
JT  - European archives of oto-rhino-laryngology : official journal of the European 
      Federation of Oto-Rhino-Laryngological Societies (EUFOS) : affiliated with the 
      German Society for Oto-Rhino-Laryngology - Head and Neck Surgery
JID - 9002937
SB  - IM
MH  - Humans
MH  - Artificial Intelligence
MH  - Cross-Sectional Studies
MH  - Prospective Studies
MH  - Clinical Decision-Making
MH  - *Otolaryngology
MH  - *Surgeons
OTO - NOTNLM
OT  - AI (artificial intelligence)
OT  - Chat-GPT
OT  - Clinical decision support
OT  - Otorhinolaryngology
EDAT- 2024/02/12 15:43
MHDA- 2024/03/18 06:44
CRDT- 2024/02/12 11:04
PHST- 2023/11/04 00:00 [received]
PHST- 2024/01/23 00:00 [accepted]
PHST- 2024/03/18 06:44 [medline]
PHST- 2024/02/12 15:43 [pubmed]
PHST- 2024/02/12 11:04 [entrez]
AID - 10.1007/s00405-024-08498-z [pii]
AID - 10.1007/s00405-024-08498-z [doi]
PST - ppublish
SO  - Eur Arch Otorhinolaryngol. 2024 Apr;281(4):2023-2030. doi: 
      10.1007/s00405-024-08498-z. Epub 2024 Feb 12.

PMID- 38409676
OWN - NLM
STAT- Publisher
LR  - 20240227
IS  - 2380-0194 (Electronic)
IS  - 2380-0186 (Linking)
DP  - 2024 Feb 20
TI  - ChatGPT as a Source of Patient Information for Lumbar Spinal Fusion and 
      Laminectomy: A Comparative Analysis Against Google Web Search.
LID - 10.1097/BSD.0000000000001582 [doi]
AB  - STUDY DESIGN: Retrospective Observational Study. OBJECTIVE: The objective of this 
      study was to assess the utility of ChatGPT, an artificial intelligence chatbot, 
      in providing patient information for lumbar spinal fusion and lumbar laminectomy 
      in comparison with the Google search engine. SUMMARY OF BACKGROUND DATA: ChatGPT, 
      an artificial intelligence chatbot with seemingly unlimited functionality, may 
      present an alternative to a Google web search for patients seeking information 
      about medical questions. With widespread misinformation and suboptimal quality of 
      online health information, it is imperative to assess ChatGPT as a resource for 
      this purpose. METHODS: The first 10 frequently asked questions (FAQs) related to 
      the search terms "lumbar spinal fusion" and "lumbar laminectomy" were extracted 
      from Google and ChatGPT. Responses to shared questions were compared regarding 
      length and readability, using the Flesch Reading Ease score and Flesch-Kincaid 
      Grade Level. Numerical FAQs from Google were replicated in ChatGPT. RESULTS: Two 
      of 10 (20%) questions for both lumbar spinal fusion and lumbar laminectomy were 
      asked similarly between ChatGPT and Google. Compared with Google, ChatGPT's 
      responses were lengthier (340.0 vs. 159.3 words) and of lower readability (Flesch 
      Reading Ease score: 34.0 vs. 58.2; Flesch-Kincaid grade level: 11.6 vs. 8.8). 
      Subjectively, we evaluated these responses to be accurate and adequately 
      nonspecific. Each response concluded with a recommendation to discuss further 
      with a health care provider. Over half of the numerical questions from Google 
      produced a varying or nonnumerical response in ChatGPT. CONCLUSIONS: FAQs and 
      responses regarding lumbar spinal fusion and lumbar laminectomy were highly 
      variable between Google and ChatGPT. While ChatGPT may be able to produce 
      relatively accurate responses in select questions, its role remains as a 
      supplement or starting point to a consultation with a physician, not as a 
      replacement, and should be taken with caution until its functionality can be 
      validated.
CI  - Copyright © 2024 Wolters Kluwer Health, Inc. All rights reserved.
FAU - Nian, Patrick P
AU  - Nian PP
AD  - Departments of Orthopaedic Surgery, SUNY Downstate Health Sciences University, 
      College of Medicine, Brooklyn, NY.
FAU - Saleet, Jayson
AU  - Saleet J
AD  - Boston University School of Medicine, Boston, MA.
FAU - Magruder, Matthew
AU  - Magruder M
AD  - Maimonides Medical Center, Brooklyn, NY.
FAU - Wellington, Ian J
AU  - Wellington IJ
AD  - University of Connecticut, Farmington, CT.
FAU - Choueka, Jack
AU  - Choueka J
AD  - Maimonides Medical Center, Brooklyn, NY.
FAU - Houten, John K
AU  - Houten JK
AD  - Department of Neurosurgery, Icahn School of Medicine at Mount Sinai, New York, 
      NY.
FAU - Saleh, Ahmed
AU  - Saleh A
AD  - Maimonides Medical Center, Brooklyn, NY.
FAU - Razi, Afshin E
AU  - Razi AE
AD  - Maimonides Medical Center, Brooklyn, NY.
FAU - Ng, Mitchell K
AU  - Ng MK
AD  - Maimonides Medical Center, Brooklyn, NY.
LA  - eng
PT  - Journal Article
DEP - 20240220
PL  - United States
TA  - Clin Spine Surg
JT  - Clinical spine surgery
JID - 101675083
SB  - IM
COIS- The authors declare no conflict of interest.
EDAT- 2024/02/27 06:45
MHDA- 2024/02/27 06:45
CRDT- 2024/02/27 00:25
PHST- 2023/09/28 00:00 [received]
PHST- 2024/01/22 00:00 [accepted]
PHST- 2024/02/27 06:45 [medline]
PHST- 2024/02/27 06:45 [pubmed]
PHST- 2024/02/27 00:25 [entrez]
AID - 01933606-990000000-00265 [pii]
AID - 10.1097/BSD.0000000000001582 [doi]
PST - aheadofprint
SO  - Clin Spine Surg. 2024 Feb 20. doi: 10.1097/BSD.0000000000001582.

PMID- 38311261
OWN - NLM
STAT- Publisher
LR  - 20240311
IS  - 1526-3231 (Electronic)
IS  - 0749-8063 (Linking)
DP  - 2024 Feb 2
TI  - ChatGPT Provides Unsatisfactory Responses to Frequently Asked Questions Regarding 
      Anterior Cruciate Ligament Reconstruction.
LID - S0749-8063(24)00061-6 [pii]
LID - 10.1016/j.arthro.2024.01.017 [doi]
AB  - PURPOSE: To determine whether the free online artificial intelligence platform 
      ChatGPT could accurately, adequately, and appropriately answer questions 
      regarding anterior cruciate ligament (ACL) reconstruction surgery. METHODS: A 
      list of 10 questions about ACL surgery was created based on a review of 
      frequently asked questions that appeared on websites of various orthopaedic 
      institutions. Each question was separately entered into ChatGPT (version 3.5), 
      and responses were recorded, scored, and graded independently by 3 authors. The 
      reading level of the ChatGPT response was calculated using the WordCalc software 
      package, and readability was assessed using the Flesch-Kincaid grade level, 
      Simple Measure of Gobbledygook index, Coleman-Liau index, Gunning fog index, and 
      automated readability index. RESULTS: Of the 10 frequently asked questions 
      entered into ChatGPT, 6 were deemed as unsatisfactory and requiring substantial 
      clarification; 1, as adequate and requiring moderate clarification; 1, as 
      adequate and requiring minor clarification; and 2, as satisfactory and requiring 
      minimal clarification. The mean DISCERN score was 41 (inter-rater reliability, 
      0.721), indicating the responses to the questions were average. According to the 
      readability assessments, a full understanding of the ChatGPT responses required 
      13.4 years of education, which corresponds to the reading level of a college 
      sophomore. CONCLUSIONS: Most of the ChatGPT-generated responses were outdated and 
      failed to provide an adequate foundation for patients' understanding regarding 
      their injury and treatment options. The reading level required to understand the 
      responses was too advanced for some patients, leading to potential 
      misunderstanding and misinterpretation of information. ChatGPT lacks the ability 
      to differentiate and prioritize information that is presented to patients. 
      CLINICAL RELEVANCE: Recognizing the shortcomings in artificial intelligence 
      platforms may equip surgeons to better set expectations and provide support for 
      patients considering and preparing for ACL reconstruction.
CI  - Copyright © 2024 Arthroscopy Association of North America. Published by Elsevier 
      Inc. All rights reserved.
FAU - Johns, William L
AU  - Johns WL
AD  - Rothman Orthopaedic Institute, Thomas Jefferson University Hospital, 
      Philadelphia, Pennsylvania, U.S.A.
FAU - Martinazzi, Brandon J
AU  - Martinazzi BJ
AD  - Rothman Orthopaedic Institute, Thomas Jefferson University Hospital, 
      Philadelphia, Pennsylvania, U.S.A.. Electronic address: 
      brandon.martinazzi@rothmanortho.com.
FAU - Miltenberg, Benjamin
AU  - Miltenberg B
AD  - Rothman Orthopaedic Institute, Thomas Jefferson University Hospital, 
      Philadelphia, Pennsylvania, U.S.A.
FAU - Nam, Hannah H
AU  - Nam HH
AD  - Penn State College of Medicine, Hershey, Pennsylvania, U.S.A.
FAU - Hammoud, Sommer
AU  - Hammoud S
AD  - Rothman Orthopaedic Institute, Thomas Jefferson University Hospital, 
      Philadelphia, Pennsylvania, U.S.A.
LA  - eng
PT  - Journal Article
DEP - 20240202
PL  - United States
TA  - Arthroscopy
JT  - Arthroscopy : the journal of arthroscopic &amp; related surgery : official 
      publication of the Arthroscopy Association of North America and the International 
      Arthroscopy Association
JID - 8506498
SB  - IM
COIS- Disclosure The authors report the following potential conflicts of interest or 
      sources of funding: S.H. is a consultant for Arthrex, outside the submitted work, 
      and is on the Perry Initiative Board of Directors. Full ICMJE author disclosure 
      forms are available for this article online, as supplementary material.
EDAT- 2024/02/05 00:42
MHDA- 2024/02/05 00:42
CRDT- 2024/02/04 19:33
PHST- 2023/08/23 00:00 [received]
PHST- 2024/01/01 00:00 [revised]
PHST- 2024/01/08 00:00 [accepted]
PHST- 2024/02/05 00:42 [pubmed]
PHST- 2024/02/05 00:42 [medline]
PHST- 2024/02/04 19:33 [entrez]
AID - S0749-8063(24)00061-6 [pii]
AID - 10.1016/j.arthro.2024.01.017 [doi]
PST - aheadofprint
SO  - Arthroscopy. 2024 Feb 2:S0749-8063(24)00061-6. doi: 10.1016/j.arthro.2024.01.017.

PMID- 37969495
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231117
IS  - 2666-6383 (Electronic)
IS  - 2666-6383 (Linking)
VI  - 7
IP  - 6
DP  - 2023 Nov
TI  - Breaking barriers: can ChatGPT compete with a shoulder and elbow specialist in 
      diagnosis and management?
PG  - 2534-2541
LID - 10.1016/j.jseint.2023.07.018 [doi]
AB  - BACKGROUND: ChatGPT is an artificial intelligence (AI) language processing model 
      that uses deep learning to generate human-like responses to natural language 
      inputs. Its potential use in health care has raised questions and several studies 
      have assessed its effectiveness in writing articles, clinical reasoning, and 
      solving complex questions. This study aims to investigate ChatGPT's capabilities 
      and implications in diagnosing and managing patients with new shoulder and elbow 
      complaints in a private clinical setting to provide insights into its potential 
      use as a diagnostic tool for patients and a first consultation resource for 
      primary physicians. METHODS: In a private clinical setting, patients were 
      assessed by ChatGPT after being seen by a shoulder and elbow specialist for 
      shoulder and elbow symptoms. To be assessed by the AI model, a research fellow 
      filled out a standardized form (including age, gender, major comorbidities, 
      symptoms and the localization, natural history, and duration, any associated 
      symptoms or movement deficit, aggravating/relieving factors, and x-ray/imaging 
      report if present). This form was submitted through the ChatGPT portal and the AI 
      model was asked for a diagnosis and best management modality. RESULTS: A total of 
      29 patients with 15 males and 14 females, were included in this study. The AI 
      model was able to correctly choose the diagnosis and management in 93% (27/29) 
      and 83% (24/29) of the patients, respectively. Furthermore, of the remaining 24 
      patients that were managed correctly, ChatGPT did not specify the appropriate 
      management in 6 patients and chose only one management in 5 patients, where both 
      were applicable and dependent on the patient's choice. Therefore, 55% of 
      ChatGPT's management was poor. CONCLUSION: ChatGPT made a worthy opponent; 
      however, it will not be able to replace in its current form a shoulder and elbow 
      specialist in diagnosing and treating patients for many reasons such as 
      misdiagnosis, poor management, lack of empathy and interactions with patients, 
      its dependence on magnetic resonance imaging reports, and its lack of new 
      knowledge.
CI  - © 2023 The Authors.
FAU - Daher, Mohammad
AU  - Daher M
AD  - Hotel Dieu de France, Beirut, Lebanon.
FAU - Koa, Jonathan
AU  - Koa J
AD  - Rothman Institute/Thomas Jefferson Medical Center, Philadelphia, PA, USA.
FAU - Boufadel, Peter
AU  - Boufadel P
AD  - Rothman Institute/Thomas Jefferson Medical Center, Philadelphia, PA, USA.
FAU - Singh, Jaspal
AU  - Singh J
AD  - Rothman Institute/Thomas Jefferson Medical Center, Philadelphia, PA, USA.
FAU - Fares, Mohamad Y
AU  - Fares MY
AD  - Rothman Institute/Thomas Jefferson Medical Center, Philadelphia, PA, USA.
FAU - Abboud, Joseph A
AU  - Abboud JA
AD  - Rothman Institute/Thomas Jefferson Medical Center, Philadelphia, PA, USA.
LA  - eng
PT  - Journal Article
DEP - 20230904
PL  - United States
TA  - JSES Int
JT  - JSES international
JID - 101763461
PMC - PMC10638599
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Diagnosis and management
OT  - Empathy
OT  - Orthopedics
OT  - Shoulder and elbow surgery
EDAT- 2023/11/16 06:45
MHDA- 2023/11/16 06:46
PMCR- 2023/09/04
CRDT- 2023/11/16 04:22
PHST- 2023/11/16 06:46 [medline]
PHST- 2023/11/16 06:45 [pubmed]
PHST- 2023/11/16 04:22 [entrez]
PHST- 2023/09/04 00:00 [pmc-release]
AID - S2666-6383(23)00212-8 [pii]
AID - 10.1016/j.jseint.2023.07.018 [doi]
PST - epublish
SO  - JSES Int. 2023 Sep 4;7(6):2534-2541. doi: 10.1016/j.jseint.2023.07.018. 
      eCollection 2023 Nov.

PMID- 38219503
OWN - NLM
STAT- MEDLINE
DCOM- 20240221
LR  - 20240221
IS  - 1873-5223 (Electronic)
IS  - 1471-5953 (Linking)
VI  - 75
DP  - 2024 Feb
TI  - The ChatGPT effect and transforming nursing education with generative AI: 
      Discussion paper.
PG  - 103888
LID - S1471-5953(24)00017-9 [pii]
LID - 10.1016/j.nepr.2024.103888 [doi]
AB  - AIM: The aim of this study is to present the possibilities of nurse education in 
      the use of the Chat Generative Pre-training Transformer (ChatGPT) tool to support 
      the documentation process. BACKGROUND: The success of the nursing process is 
      based on the accuracy of nursing diagnoses, which also determine nursing 
      interventions and nursing outcomes. Educating nurses in the use of artificial 
      intelligence in the nursing process can significantly reduce the time nurses 
      spend on documentation. DESIGN: Discussion paper. METHODS: We used a case study 
      from Train4Health in the field of preventive care to demonstrate the potential of 
      using Generative Pre-training Transformer (ChatGPT) to educate nurses in 
      documenting the nursing process using generative artificial intelligence. Based 
      on the case study, we entered a description of the patient's condition into 
      Generative Pre-training Transformer (ChatGPT) and asked questions about nursing 
      diagnoses, nursing interventions and nursing outcomes. We further synthesized 
      these results. RESULTS: In the process of educating nurses about the nursing 
      process and nursing diagnosis, Generative Pre-training Transformer (ChatGPT) can 
      present potential patient problems to nurses and guide them through the process 
      from taking a medical history, setting nursing diagnoses and planning goals and 
      interventions. Generative Pre-training Transformer (ChatGPT) returned appropriate 
      nursing diagnoses, but these were not in line with the North American Nursing 
      Diagnosis Association - International (NANDA-I) classification as requested. Of 
      all the nursing diagnoses provided, only one was consistent with the most recent 
      version of the North American Nursing Diagnosis Association - International 
      (NANDA-I). Generative Pre-training Transformer (ChatGPT) is still not specific 
      enough for nursing diagnoses, resulting in incorrect answers in several cases. 
      CONCLUSIONS: Using Generative Pre-training Transformer (ChatGPT) to educate 
      nurses and support the documentation process is time-efficient, but it still 
      requires a certain level of human critical-thinking and fact-checking.
CI  - Copyright © 2024 Elsevier Ltd. All rights reserved.
FAU - Gosak, Lucija
AU  - Gosak L
AD  - Faculty of Health Sciences, University of Maribor,&nbsp;Maribor 2000,&nbsp;Slovenia. 
      Electronic address: lucija.gosak2@um.si.
FAU - Pruinelli, Lisiane
AU  - Pruinelli L
AD  - College of Nursing and College of Medicine, University of 
      Florida,&nbsp;Gainesville,&nbsp;FL,&nbsp;USA. Electronic address: lisianepruinelli@ufl.edu.
FAU - Topaz, Maxim
AU  - Topaz M
AD  - Columbia University School of Nursing,&nbsp;New York City,&nbsp;NY,&nbsp;USA. Electronic 
      address: mt3315@cumc.columbia.edu.
FAU - Štiglic, Gregor
AU  - Štiglic G
AD  - Faculty of Health Sciences, University of Maribor,&nbsp;Maribor 2000,&nbsp;Slovenia; 
      Faculty of Electrical Engineering and Computer Science, University of 
      Maribor,&nbsp;Maribor 2000,&nbsp;Slovenia; Usher Institute, University of 
      Edinburgh,&nbsp;Edinburgh EH8 9YL,&nbsp;UK. Electronic address: gregor.stiglic@um.si.
LA  - eng
PT  - Journal Article
DEP - 20240110
PL  - Scotland
TA  - Nurse Educ Pract
JT  - Nurse education in practice
JID - 101090848
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Education, Nursing
MH  - Nursing Diagnosis
MH  - Documentation
MH  - Educational Status
OTO - NOTNLM
OT  - Artificial Intelligence
OT  - ChatGPT
OT  - Documentation
OT  - Education
OT  - Nursing
OT  - Nursing Diagnosis
COIS- Declaration of Competing Interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2024/01/15 00:42
MHDA- 2024/02/21 11:16
CRDT- 2024/01/14 18:12
PHST- 2023/11/05 00:00 [received]
PHST- 2023/12/10 00:00 [revised]
PHST- 2023/12/23 00:00 [accepted]
PHST- 2024/02/21 11:16 [medline]
PHST- 2024/01/15 00:42 [pubmed]
PHST- 2024/01/14 18:12 [entrez]
AID - S1471-5953(24)00017-9 [pii]
AID - 10.1016/j.nepr.2024.103888 [doi]
PST - ppublish
SO  - Nurse Educ Pract. 2024 Feb;75:103888. doi: 10.1016/j.nepr.2024.103888. Epub 2024 
      Jan 10.

PMID- 38478902
OWN - NLM
STAT- Publisher
LR  - 20240313
IS  - 1466-187X (Electronic)
IS  - 0142-159X (Linking)
DP  - 2024 Mar 13
TI  - ChatGPT to generate clinical vignettes for teaching and multiple-choice questions 
      for assessment: A randomized controlled experiment.
PG  - 1-7
LID - 10.1080/0142159X.2024.2327477 [doi]
AB  - AIM: This study aimed to evaluate the real-life performance of clinical vignettes 
      and multiple-choice questions generated by using ChatGPT. METHODS: This was a 
      randomized controlled study in an evidence-based medicine training program. We 
      randomly assigned seventy-four medical students to two groups. The ChatGPT group 
      received ill-defined cases generated by ChatGPT, while the control group received 
      human-written cases. At the end of the training, they evaluated the cases by 
      rating 10 statements using a Likert scale. They also answered 15 multiple-choice 
      questions (MCQs) generated by ChatGPT. The case evaluations of the two groups 
      were compared. Some psychometric characteristics (item difficulty and 
      point-biserial correlations) of the test were also reported. RESULTS: None of the 
      scores in 10 statements regarding the cases showed a significant difference 
      between the ChatGPT group and the control group (p &gt; .05). In the test, only six 
      MCQs had acceptable levels (higher than 0.30) of point-biserial correlation, and 
      five items could be considered acceptable in classroom settings. CONCLUSIONS: The 
      results showed that the quality of the vignettes are comparable to those created 
      by human authors, and some multiple-questions have acceptable psychometric 
      characteristics. ChatGPT has potential in generating clinical vignettes for 
      teaching and MCQs for assessment in medical education.
FAU - Coşkun, Özlem
AU  - Coşkun Ö
AUID- ORCID: 0000-0001-8716-1584
AD  - Department of Medical Education and Informatics, Gazi University, Ankara, Turkey.
FAU - Kıyak, Yavuz Selim
AU  - Kıyak YS
AUID- ORCID: 0000-0002-5026-3234
AD  - Department of Medical Education and Informatics, Gazi University, Ankara, Turkey.
FAU - Budakoğlu, Işıl İrem
AU  - Budakoğlu Iİ
AUID- ORCID: 0000-0003-1517-3169
AD  - Department of Medical Education and Informatics, Gazi University, Ankara, Turkey.
LA  - eng
PT  - Journal Article
DEP - 20240313
PL  - England
TA  - Med Teach
JT  - Medical teacher
JID - 7909593
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - automatic item generation
OT  - clinical vignette
OT  - medical education
EDAT- 2024/03/13 18:47
MHDA- 2024/03/13 18:47
CRDT- 2024/03/13 16:53
PHST- 2024/03/13 18:47 [medline]
PHST- 2024/03/13 18:47 [pubmed]
PHST- 2024/03/13 16:53 [entrez]
AID - 10.1080/0142159X.2024.2327477 [doi]
PST - aheadofprint
SO  - Med Teach. 2024 Mar 13:1-7. doi: 10.1080/0142159X.2024.2327477.

PMID- 37788063
OWN - NLM
STAT- MEDLINE
DCOM- 20231023
LR  - 20240210
IS  - 2291-5222 (Electronic)
IS  - 2291-5222 (Linking)
VI  - 11
DP  - 2023 Oct 3
TI  - Comparison of Diagnostic and Triage Accuracy of Ada Health and WebMD Symptom 
      Checkers, ChatGPT, and Physicians for Patients in an Emergency Department: 
      Clinical Data Analysis Study.
PG  - e49995
LID - 10.2196/49995 [doi]
LID - e49995
AB  - BACKGROUND: Diagnosis is a core component of effective health care, but 
      misdiagnosis is common and can put patients at risk. Diagnostic decision support 
      systems can play a role in improving diagnosis by physicians and other health 
      care workers. Symptom checkers (SCs) have been designed to improve diagnosis and 
      triage (ie, which level of care to seek) by patients. OBJECTIVE: The aim of this 
      study was to evaluate the performance of the new large language model ChatGPT 
      (versions 3.5 and 4.0), the widely used WebMD SC, and an SC developed by Ada 
      Health in the diagnosis and triage of patients with urgent or emergent clinical 
      problems compared with the final emergency department (ED) diagnoses and 
      physician reviews. METHODS: We used previously collected, deidentified, 
      self-report data from 40 patients presenting to an ED for care who used the Ada 
      SC to record their symptoms prior to seeing the ED physician. Deidentified data 
      were entered into ChatGPT versions 3.5 and 4.0 and WebMD by a research assistant 
      blinded to diagnoses and triage. Diagnoses from all 4 systems were compared with 
      the previously abstracted final diagnoses in the ED as well as with diagnoses and 
      triage recommendations from three independent board-certified ED physicians who 
      had blindly reviewed the self-report clinical data from Ada. Diagnostic accuracy 
      was calculated as the proportion of the diagnoses from ChatGPT, Ada SC, WebMD SC, 
      and the independent physicians that matched at least one ED diagnosis (stratified 
      as top 1 or top 3). Triage accuracy was calculated as the number of 
      recommendations from ChatGPT, WebMD, or Ada that agreed with at least 2 of the 
      independent physicians or were rated "unsafe" or "too cautious." RESULTS: 
      Overall, 30 and 37 cases had sufficient data for diagnostic and triage analysis, 
      respectively. The rate of top-1 diagnosis matches for Ada, ChatGPT 3.5, ChatGPT 
      4.0, and WebMD was 9 (30%), 12 (40%), 10 (33%), and 12 (40%), respectively, with 
      a mean rate of 47% for the physicians. The rate of top-3 diagnostic matches for 
      Ada, ChatGPT 3.5, ChatGPT 4.0, and WebMD was 19 (63%), 19 (63%), 15 (50%), and 17 
      (57%), respectively, with a mean rate of 69% for physicians. The distribution of 
      triage results for Ada was 62% (n=23) agree, 14% unsafe (n=5), and 24% (n=9) too 
      cautious; that for ChatGPT 3.5 was 59% (n=22) agree, 41% (n=15) unsafe, and 0% 
      (n=0) too cautious; that for ChatGPT 4.0 was 76% (n=28) agree, 22% (n=8) unsafe, 
      and 3% (n=1) too cautious; and that for WebMD was 70% (n=26) agree, 19% (n=7) 
      unsafe, and 11% (n=4) too cautious. The unsafe triage rate for ChatGPT 3.5 (41%) 
      was significantly higher (P=.009) than that of Ada (14%). CONCLUSIONS: ChatGPT 
      3.5 had high diagnostic accuracy but a high unsafe triage rate. ChatGPT 4.0 had 
      the poorest diagnostic accuracy, but a lower unsafe triage rate and the highest 
      triage agreement with the physicians. The Ada and WebMD SCs performed better 
      overall than ChatGPT. Unsupervised patient use of ChatGPT for diagnosis and 
      triage is not recommended without improvements to triage accuracy and extensive 
      clinical evaluation.
CI  - ©Hamish Fraser, Daven Crossland, Ian Bacher, Megan Ranney, Tracy Madsen, Ross 
      Hilliard. Originally published in JMIR mHealth and uHealth 
      (https://mhealth.jmir.org), 03.10.2023.
FAU - Fraser, Hamish
AU  - Fraser H
AUID- ORCID: 0000-0003-4383-2854
AD  - Brown Center for Biomedical Informatics, The Warren Alpert Medical School of 
      Brown University, Providence, RI, United States.
AD  - Department of Health Services, Policy and Practice, Brown University School of 
      Public Health, Providence, RI, United States.
FAU - Crossland, Daven
AU  - Crossland D
AUID- ORCID: 0009-0004-8878-5718
AD  - Brown Center for Biomedical Informatics, The Warren Alpert Medical School of 
      Brown University, Providence, RI, United States.
AD  - Department of Epidemiology, Brown University School of Public Health, Providence, 
      RI, United States.
FAU - Bacher, Ian
AU  - Bacher I
AUID- ORCID: 0000-0003-2383-3411
AD  - Brown Center for Biomedical Informatics, The Warren Alpert Medical School of 
      Brown University, Providence, RI, United States.
FAU - Ranney, Megan
AU  - Ranney M
AUID- ORCID: 0000-0002-8450-9642
AD  - School of Public Health, Yale University, New Haven, CT, United States.
FAU - Madsen, Tracy
AU  - Madsen T
AUID- ORCID: 0000-0001-5101-0776
AD  - Department of Epidemiology, Brown University School of Public Health, Providence, 
      RI, United States.
AD  - Department of Emergency Medicine, The Warren Alpert Medical School of Brown 
      University, Providence, RI, United States.
FAU - Hilliard, Ross
AU  - Hilliard R
AUID- ORCID: 0000-0003-0187-8096
AD  - Department of Internal Medicine, Maine Medical Center, Portland, ME, United 
      States.
LA  - eng
GR  - K23 HL140081/HL/NHLBI NIH HHS/United States
GR  - P20 GM139664/GM/NIGMS NIH HHS/United States
GR  - R01 HS029513/HS/AHRQ HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PT  - Research Support, Non-U.S. Gov't
PT  - Research Support, U.S. Gov't, P.H.S.
DEP - 20231003
PL  - Canada
TA  - JMIR Mhealth Uhealth
JT  - JMIR mHealth and uHealth
JID - 101624439
SB  - IM
MH  - Humans
MH  - *Triage/methods
MH  - Emergency Service, Hospital
MH  - *Physicians
MH  - Health Personnel
MH  - Self Report
PMC - PMC10582809
OTO - NOTNLM
OT  - ChatGPT
OT  - ChatGPT-3.5
OT  - ChatGPT-4.0
OT  - LLM
OT  - accuracy
OT  - app
OT  - application
OT  - diagnose
OT  - diagnosis
OT  - emergency
OT  - emergency patient
OT  - language model
OT  - machine learning
OT  - self-diagnose
OT  - self-diagnosis
OT  - symptom checker
OT  - triage
COIS- Conflicts of Interest: None declared.
EDAT- 2023/10/03 12:42
MHDA- 2023/10/23 01:18
PMCR- 2023/10/03
CRDT- 2023/10/03 11:54
PHST- 2023/06/16 00:00 [received]
PHST- 2023/08/25 00:00 [accepted]
PHST- 2023/08/17 00:00 [revised]
PHST- 2023/10/23 01:18 [medline]
PHST- 2023/10/03 12:42 [pubmed]
PHST- 2023/10/03 11:54 [entrez]
PHST- 2023/10/03 00:00 [pmc-release]
AID - v11i1e49995 [pii]
AID - 10.2196/49995 [doi]
PST - epublish
SO  - JMIR Mhealth Uhealth. 2023 Oct 3;11:e49995. doi: 10.2196/49995.

PMID- 37957666
OWN - NLM
STAT- MEDLINE
DCOM- 20231115
LR  - 20231116
IS  - 1472-6920 (Electronic)
IS  - 1472-6920 (Linking)
VI  - 23
IP  - 1
DP  - 2023 Nov 13
TI  - Assessment of the capacity of ChatGPT as a self-learning tool in medical 
      pharmacology: a study using MCQs.
PG  - 864
LID - 10.1186/s12909-023-04832-x [doi]
LID - 864
AB  - BACKGROUND: ChatGPT is a large language model developed by OpenAI that exhibits a 
      remarkable ability to simulate human speech. This investigation attempts to 
      evaluate the potential of ChatGPT as a standalone self-learning tool, with 
      specific attention on its efficacy in answering multiple-choice questions (MCQs) 
      and providing credible rationale for its responses. METHODS: The study used 78 
      test items from the Korean Comprehensive Basic Medical Sciences Examination 
      (K-CBMSE) for years 2019 to 2021. 78 test items translated from Korean to English 
      with four lead-in prompts per item resulted in a total of 312 MCQs. The MCQs were 
      submitted to ChatGPT and the responses were analyzed for correctness, 
      consistency, and relevance. RESULTS: ChatGPT responded with an overall accuracy 
      of 76.0%. Compared to its performance on recall and interpretation questions, the 
      model performed poorly on problem-solving questions. ChatGPT offered correct 
      rationales for 77.8% (182/234) of the responses, with errors primarily arising 
      from faulty information and flawed reasoning. In terms of references, ChatGPT 
      provided incorrect citations for 69.7% (191/274) of the responses. While the 
      veracity of reference paragraphs could not be ascertained, 77.0% (47/61) were 
      deemed pertinent and accurate with respect to the answer key. CONCLUSION: The 
      current version of ChatGPT has limitations in accurately answering MCQs and 
      generating correct and relevant rationales, particularly when it comes to 
      referencing. To avoid possible threats such as spreading inaccuracies and 
      decreasing critical thinking skills, ChatGPT should be used with supervision.
CI  - © 2023. The Author(s).
FAU - Choi, Woong
AU  - Choi W
AD  - Department of Pharmacology, College of Medicine, Chungbuk National University, 
      Cheongju, Chungbuk, 28644, Korea. wchoi@chungbuk.ac.kr.
LA  - eng
PT  - Journal Article
DEP - 20231113
PL  - England
TA  - BMC Med Educ
JT  - BMC medical education
JID - 101088679
SB  - IM
MH  - Humans
MH  - Language
MH  - *Learning
MH  - Mental Recall
MH  - *Problem Solving
MH  - *Artificial Intelligence
MH  - *Pharmacology, Clinical/education
PMC - PMC10644619
OTO - NOTNLM
OT  - ChatGPT
OT  - Large language model
OT  - Multiple-choice questions
OT  - Performance
OT  - Rationale
OT  - Referencing
OT  - Self-directed learning
COIS- The authors declare no competing interests.
EDAT- 2023/11/14 06:42
MHDA- 2023/11/15 06:43
PMCR- 2023/11/13
CRDT- 2023/11/14 00:10
PHST- 2023/03/02 00:00 [received]
PHST- 2023/11/01 00:00 [accepted]
PHST- 2023/11/15 06:43 [medline]
PHST- 2023/11/14 06:42 [pubmed]
PHST- 2023/11/14 00:10 [entrez]
PHST- 2023/11/13 00:00 [pmc-release]
AID - 10.1186/s12909-023-04832-x [pii]
AID - 4832 [pii]
AID - 10.1186/s12909-023-04832-x [doi]
PST - epublish
SO  - BMC Med Educ. 2023 Nov 13;23(1):864. doi: 10.1186/s12909-023-04832-x.

PMID- 37828297
OWN - NLM
STAT- Publisher
LR  - 20231012
IS  - 1432-1084 (Electronic)
IS  - 0938-7994 (Linking)
DP  - 2023 Oct 13
TI  - Evaluating the reliability of ChatGPT as a tool for imaging test referral: a 
      comparative study with a clinical decision support system.
LID - 10.1007/s00330-023-10230-0 [doi]
AB  - OBJECTIVES: As the technology continues to evolve and advance, we can expect to 
      see artificial intelligence (AI) being used in increasingly sophisticated ways to 
      make a diagnosis and decisions such as suggesting the most appropriate imaging 
      referrals. We aim to explore whether Chat Generative Pretrained Transformer 
      (ChatGPT) can provide accurate imaging referrals for clinical use that are at 
      least as good as the ESR iGuide. METHODS: A comparative study was conducted in a 
      tertiary hospital. Data was collected from 97 consecutive cases that were 
      admitted to the emergency department with abdominal complaints. We compared the 
      imaging test referral recommendations suggested by the ESR iGuide and the ChatGPT 
      and analyzed cases of disagreement. In addition, we selected cases where ChatGPT 
      recommended a chest abdominal pelvis (CAP) CT (n&nbsp;= 66), and asked four 
      specialists to grade the appropriateness of the referral. RESULTS: ChatGPT 
      recommendations were consistent with the recommendations provided by the ESR 
      iGuide. No statistical differences were found between the appropriateness of 
      referrals by age or gender. Using a sub-analysis of CAP cases, a high agreement 
      between ChatGPT and the specialists was found. Cases of disagreement (12.4%) were 
      further analyzed and presented themes of vague recommendations such as "it would 
      be advisable" and "this would help to rule out." CONCLUSIONS: ChatGPT's ability 
      to guide the selection of appropriate tests may be comparable to some degree with 
      the ESR iGuide. Features such as the clinical, ethical, and regulatory 
      implications are still warranted and need to be addressed prior to clinical 
      implementation. Further studies are needed to confirm these findings. CLINICAL 
      RELEVANCE STATEMENT: The article explores the potential of using advanced 
      language models, such as ChatGPT, in healthcare as a CDS for selecting 
      appropriate imaging tests. Using ChatGPT can improve the efficiency of the 
      decision-making process KEY POINTS: • ChatGPT recommendations were highly 
      consistent with the recommendations provided by the ESR iGuide. • ChatGPT's 
      ability in guiding the selection of appropriate tests may be comparable to some 
      degree with ESR iGuide's.
CI  - © 2023. The Author(s), under exclusive licence to European Society of Radiology.
FAU - Rosen, Shani
AU  - Rosen S
AD  - Department of Health Technology and Policy Evaluation, Gertner Institute for 
      Epidemiology and Health Policy, Institute of Epidemiology &amp; Health Policy 
      Research, Sheba Medical Center, Tel HaShomer, Ramat-Gan, Israel.
AD  - Nursing Department, School of Health Sciences, Sackler Faculty of Medicine, Tel 
      Aviv University, Tel Aviv, Israel.
FAU - Saban, Mor
AU  - Saban M
AUID- ORCID: 0000-0001-6869-0907
AD  - Nursing Department, School of Health Sciences, Sackler Faculty of Medicine, Tel 
      Aviv University, Tel Aviv, Israel. morsaban1@tauex.tau.ac.il.
LA  - eng
PT  - Journal Article
DEP - 20231013
PL  - Germany
TA  - Eur Radiol
JT  - European radiology
JID - 9114774
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - ESR iGuide
OT  - Imaging
EDAT- 2023/10/13 00:43
MHDA- 2023/10/13 00:43
CRDT- 2023/10/12 23:34
PHST- 2023/02/15 00:00 [received]
PHST- 2023/08/01 00:00 [accepted]
PHST- 2023/07/28 00:00 [revised]
PHST- 2023/10/13 00:43 [medline]
PHST- 2023/10/13 00:43 [pubmed]
PHST- 2023/10/12 23:34 [entrez]
AID - 10.1007/s00330-023-10230-0 [pii]
AID - 10.1007/s00330-023-10230-0 [doi]
PST - aheadofprint
SO  - Eur Radiol. 2023 Oct 13. doi: 10.1007/s00330-023-10230-0.

PMID- 38451040
OWN - NLM
STAT- Publisher
LR  - 20240307
IS  - 1520-6777 (Electronic)
IS  - 0733-2467 (Linking)
DP  - 2024 Mar 7
TI  - Conformity of ChatGPT recommendations with the AUA/SUFU guideline on 
      postprostatectomy urinary incontinence.
LID - 10.1002/nau.25442 [doi]
AB  - INTRODUCTION: Artificial intelligence (AI) shows immense potential in medicine 
      and Chat generative pretrained transformer (ChatGPT) has been used for different 
      purposes in the field. However, it may not match the complexity and nuance of 
      certain medical scenarios. This study evaluates the accuracy of ChatGPT 3.5 and 4 
      in providing recommendations regarding the management of postprostatectomy 
      urinary incontinence (PPUI), considering The Incontinence After Prostate 
      Treatment: AUA/SUFU Guideline as the best practice benchmark. MATERIALS AND 
      METHODS: A set of questions based on the AUA/SUFU Guideline was prepared. Queries 
      included 10 conceptual questions and 10 case-based questions. All questions were 
      open and entered into the ChatGPT with a recommendation to limit the answer to 
      200 words, for greater objectivity. Responses were graded as correct (1 point); 
      partially correct (0.5 point), or incorrect (0 point). Performances of versions 
      3.5 and 4 of ChatGPT were analyzed overall and separately for the conceptual and 
      the case-based questions. RESULTS: ChatGPT 3.5 scored 11.5 out of 20 points 
      (57.5% accuracy), while ChatGPT 4 scored 18 (90.0%; p = 0.031). In the conceptual 
      questions, ChatGPT 3.5 provided accurate answers to six questions along with one 
      partially correct response and three incorrect answers, with a final score of 
      6.5. In contrast, ChatGPT 4 provided correct answers to eight questions and 
      partially correct answers to two questions, scoring 9.0. In the case-based 
      questions, ChatGPT 3.5 scored 5.0, while ChatGPT 4 scored 9.0. The domains where 
      ChatGPT performed worst were evaluation, treatment options, surgical 
      complications, and special situations. CONCLUSION: ChatGPT 4 demonstrated 
      superior performance compared to ChatGPT 3.5 in providing recommendations for the 
      management of PPUI, using the AUA/SUFU Guideline as a benchmark. Continuous 
      monitoring is essential for evaluating the development and precision of 
      AI-generated medical information.
CI  - © 2024 Wiley Periodicals LLC.
FAU - Pinto, Vicktor B P
AU  - Pinto VBP
AUID- ORCID: 0000-0001-6545-5696
AD  - Division of Urology, University of Sao Paulo School of Medicine, Sao Paulo, 
      Brazil.
FAU - de Azevedo, Matheus F
AU  - de Azevedo MF
AD  - Division of Urology, University of Sao Paulo School of Medicine, Sao Paulo, 
      Brazil.
FAU - Wroclawski, Marcelo L
AU  - Wroclawski ML
AD  - Division of Urology, ABC Medical School, Sao Paulo, Brazil.
AD  - Department of Urology, Albert Einstein Jewish Hospital, Sao Paulo, Brazil.
AD  - Department of Urologic Oncology, BP-a Beneficência Portuguesa de São Paulo, Sao 
      Paulo, Brazil.
FAU - Gentile, Guilherme
AU  - Gentile G
AD  - Division of Urology, University of Sao Paulo School of Medicine, Sao Paulo, 
      Brazil.
FAU - Jesus, Vinicius L M
AU  - Jesus VLM
AD  - Division of Urology, University of Sao Paulo School of Medicine, Sao Paulo, 
      Brazil.
FAU - de Bessa Junior, Jose
AU  - de Bessa Junior J
AUID- ORCID: 0000-0003-4833-4889
AD  - Department of Surgery, State University of Feira de Santana, Bahia, Brazil.
FAU - Nahas, William C
AU  - Nahas WC
AD  - Division of Urology, University of Sao Paulo School of Medicine, Sao Paulo, 
      Brazil.
FAU - Sacomani, Carlos A R
AU  - Sacomani CAR
AD  - Innovation and Information Technology Sector, AC Camargo Cancer Hospital, Sao 
      Paulo, Brazil.
FAU - Sandhu, Jaspreet S
AU  - Sandhu JS
AD  - Department of Surgery/Urology, Memorial Sloan Kettering Cancer Center, New York, 
      New York, USA.
FAU - Gomes, Cristiano M
AU  - Gomes CM
AUID- ORCID: 0000-0002-8486-4003
AD  - Division of Urology, University of Sao Paulo School of Medicine, Sao Paulo, 
      Brazil.
LA  - eng
PT  - Journal Article
DEP - 20240307
PL  - United States
TA  - Neurourol Urodyn
JT  - Neurourology and urodynamics
JID - 8303326
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - prostatectomy
OT  - urinary incontinence
OT  - urology
EDAT- 2024/03/07 12:42
MHDA- 2024/03/07 12:42
CRDT- 2024/03/07 08:45
PHST- 2024/02/24 00:00 [revised]
PHST- 2023/12/30 00:00 [received]
PHST- 2024/02/27 00:00 [accepted]
PHST- 2024/03/07 12:42 [medline]
PHST- 2024/03/07 12:42 [pubmed]
PHST- 2024/03/07 08:45 [entrez]
AID - 10.1002/nau.25442 [doi]
PST - aheadofprint
SO  - Neurourol Urodyn. 2024 Mar 7. doi: 10.1002/nau.25442.

PMID- 38506920
OWN - NLM
STAT- MEDLINE
DCOM- 20240321
LR  - 20240321
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 10
DP  - 2024 Mar 20
TI  - Incorporating ChatGPT in Medical Informatics Education: Mixed Methods Study on 
      Student Perceptions and Experiential Integration Proposals.
PG  - e51151
LID - 10.2196/51151 [doi]
AB  - BACKGROUND: The integration of artificial intelligence (AI) technologies, such as 
      ChatGPT, in the educational landscape has the potential to enhance the learning 
      experience of medical informatics students and prepare them for using AI in 
      professional settings. The incorporation of AI in classes aims to develop 
      critical thinking by encouraging students to interact with ChatGPT and critically 
      analyze the responses generated by the chatbot. This approach also helps students 
      develop important skills in the field of biomedical and health informatics to 
      enhance their interaction with AI tools. OBJECTIVE: The aim of the study is to 
      explore the perceptions of students regarding the use of ChatGPT as a learning 
      tool in their educational context and provide professors with examples of prompts 
      for incorporating ChatGPT into their teaching and learning activities, thereby 
      enhancing the educational experience for students in medical informatics courses. 
      METHODS: This study used a mixed methods approach to gain insights from students 
      regarding the use of ChatGPT in education. To accomplish this, a structured 
      questionnaire was applied to evaluate students' familiarity with ChatGPT, gauge 
      their perceptions of its use, and understand their attitudes toward its use in 
      academic and learning tasks. Learning outcomes of 2 courses were analyzed to 
      propose ChatGPT's incorporation in master's programs in medicine and medical 
      informatics. RESULTS: The majority of students expressed satisfaction with the 
      use of ChatGPT in education, finding it beneficial for various purposes, 
      including generating academic content, brainstorming ideas, and rewriting text. 
      While some participants raised concerns about potential biases and the need for 
      informed use, the overall perception was positive. Additionally, the study 
      proposed integrating ChatGPT into 2 specific courses in the master's programs in 
      medicine and medical informatics. The incorporation of ChatGPT was envisioned to 
      enhance student learning experiences and assist in project planning, programming 
      code generation, examination preparation, workflow exploration, and technical 
      interview preparation, thus advancing medical informatics education. In medical 
      teaching, it will be used as an assistant for simplifying the explanation of 
      concepts and solving complex problems, as well as for generating clinical 
      narratives and patient simulators. CONCLUSIONS: The study's valuable insights 
      into medical faculty students' perspectives and integration proposals for ChatGPT 
      serve as an informative guide for professors aiming to enhance medical 
      informatics education. The research delves into the potential of ChatGPT, 
      emphasizes the necessity of collaboration in academic environments, identifies 
      subject areas with discernible benefits, and underscores its transformative role 
      in fostering innovative and engaging learning experiences. The envisaged 
      proposals hold promise in empowering future health care professionals to work in 
      the rapidly evolving era of digital health care.
CI  - ©Sabrina Magalhães Araujo, Ricardo Cruz-Correia. Originally published in JMIR 
      Medical Education (https://mededu.jmir.org), 20.03.2024.
FAU - Magalhães Araujo, Sabrina
AU  - Magalhães Araujo S
AUID- ORCID: 0000-0003-1443-2106
AD  - Center for Health Technology and Services Research, Faculty of Medicine, 
      University of Porto, Porto, Portugal.
FAU - Cruz-Correia, Ricardo
AU  - Cruz-Correia R
AUID- ORCID: 0000-0002-3764-5158
AD  - Center for Health Technology and Services Research, Faculty of Medicine, 
      University of Porto, Porto, Portugal.
AD  - Department of Community Medicine, Information and Decision Sciences, Faculty of 
      Medicine, University of Porto, Porto, Portugal.
AD  - Working Group Education, European Federation for Medical Informatics, Le 
      Mont-sur-Lausanne, Switzerland.
LA  - eng
PT  - Journal Article
DEP - 20240320
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
SB  - IM
MH  - Humans
MH  - Artificial Intelligence
MH  - Educational Status
MH  - *Medical Informatics
MH  - *Students, Medical
MH  - Faculty, Medical
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - artificial intelligence
OT  - education
OT  - generative language model
OT  - medical informatics
EDAT- 2024/03/20 12:42
MHDA- 2024/03/21 12:43
CRDT- 2024/03/20 11:54
PHST- 2023/07/27 00:00 [received]
PHST- 2023/11/10 00:00 [accepted]
PHST- 2023/09/29 00:00 [revised]
PHST- 2024/03/21 12:43 [medline]
PHST- 2024/03/20 12:42 [pubmed]
PHST- 2024/03/20 11:54 [entrez]
AID - v10i1e51151 [pii]
AID - 10.2196/51151 [doi]
PST - epublish
SO  - JMIR Med Educ. 2024 Mar 20;10:e51151. doi: 10.2196/51151.

PMID- 38031276
OWN - NLM
STAT- MEDLINE
DCOM- 20240129
LR  - 20240304
IS  - 1536-481X (Electronic)
IS  - 1057-0829 (Linking)
VI  - 33
IP  - 2
DP  - 2024 Feb 1
TI  - Can ChatGPT Aid Clinicians in Educating Patients on the Surgical Management of 
      Glaucoma?
PG  - 94-100
LID - 10.1097/IJG.0000000000002338 [doi]
AB  - PRCIS: ChatGPT can help health care providers automate the quality assessment of 
      online health information, but it does not produce easier-to-understand responses 
      compared with existing online health information. PURPOSE: To compare the 
      readability of ChatGPT-generated health information about glaucoma surgery to 
      existing material online and to evaluate ChatGPT's ability to analyze the quality 
      of information found online about glaucoma surgery. METHODS: ChatGPT was asked to 
      create patient handouts on glaucoma surgery using 7 independent prompts, aiming 
      to generate sixth grade level reading material. Existing patient-targeted online 
      health information about glaucoma surgery was selected from the top 50 search 
      results of 3 search engines, excluding advertisements, blog posts, information 
      intended for health professionals, irrelevant content, and duplicate links. Four 
      validated tools were used to assess readability, and the readability of the 
      ChatGPT-generated material was compared with the readability of existing online 
      information. The DISCERN instrument was used for the quality assessment of online 
      materials. The DISCERN instrument was also programmed to use ChatGPT to evaluate 
      its ability to analyze quality. R software and descriptive statistics were used 
      for data analysis. RESULTS: Thirty-five webpages were included. There was no 
      difference between the reading level of online webpages (12th grade) and the 
      reading level of ChatGPT-generated responses (11th grade), despite the ChatGPT 
      prompts asking for simple language and a sixth grade reading level. The quality 
      of health content was "fair," with only 5 resources receiving an "excellent" 
      score. ChatGPT scored the quality of health resources with high precision ( r 
      =0.725). CONCLUSIONS: Patient-targeted information on glaucoma surgery is beyond 
      the reading level of the average patient, therefore at risk of not being 
      understood, and is of subpar quality, per DISCERN tool scoring. ChatGPT did not 
      generate documents at a lower reading level as prompted, but this tool can aid in 
      automating the time-consuming and subjective process of quality assessment.
CI  - Copyright © 2023 Wolters Kluwer Health, Inc. All rights reserved.
FAU - Kianian, Reza
AU  - Kianian R
AD  - Department of Ophthalmology, Stein Eye Institute, David Geffen School of 
      Medicine, University of California Los Angeles.
FAU - Sun, Deyu
AU  - Sun D
AD  - Department of Ophthalmology, Stein Eye Institute, David Geffen School of 
      Medicine, University of California Los Angeles.
FAU - Giaconi, JoAnn
AU  - Giaconi J
AD  - Department of Ophthalmology, Stein Eye Institute, David Geffen School of 
      Medicine, University of California Los Angeles.
AD  - Department of Surgery, Veterans Health Administration of Greater Los Angeles, Los 
      Angeles, CA.
LA  - eng
PT  - Journal Article
DEP - 20231124
PL  - United States
TA  - J Glaucoma
JT  - Journal of glaucoma
JID - 9300903
SB  - IM
MH  - Humans
MH  - *Intraocular Pressure
MH  - *Glaucoma/surgery
MH  - Comprehension
MH  - Software
COIS- Disclosure: The authors declare no conflict of interest.
EDAT- 2023/11/30 06:43
MHDA- 2024/01/29 06:42
CRDT- 2023/11/30 00:13
PHST- 2023/05/13 00:00 [received]
PHST- 2023/11/10 00:00 [accepted]
PHST- 2024/01/29 06:42 [medline]
PHST- 2023/11/30 06:43 [pubmed]
PHST- 2023/11/30 00:13 [entrez]
AID - 00061198-990000000-00318 [pii]
AID - 10.1097/IJG.0000000000002338 [doi]
PST - ppublish
SO  - J Glaucoma. 2024 Feb 1;33(2):94-100. doi: 10.1097/IJG.0000000000002338. Epub 2023 
      Nov 24.

PMID- 38167093
OWN - NLM
STAT- MEDLINE
DCOM- 20240105
LR  - 20240116
IS  - 1749-799X (Electronic)
IS  - 1749-799X (Linking)
VI  - 19
IP  - 1
DP  - 2024 Jan 3
TI  - Assessing ChatGPT's orthopedic in-service training exam performance and 
      applicability in the field.
PG  - 27
LID - 10.1186/s13018-023-04467-0 [doi]
LID - 27
AB  - BACKGROUND: ChatGPT has gained widespread attention for its ability to understand 
      and provide human-like responses to inputs. However, few works have focused on 
      its use in Orthopedics. This study assessed ChatGPT's performance on the 
      Orthopedic In-Service Training Exam (OITE) and evaluated its decision-making 
      process to determine whether adoption as a resource in the field is practical. 
      METHODS: ChatGPT's performance on three OITE exams was evaluated through 
      inputting multiple choice questions. Questions were classified by their 
      orthopedic subject area. Yearly, OITE technical reports were used to gauge scores 
      against resident physicians. ChatGPT's rationales were compared with testmaker 
      explanations using six different groups denoting answer accuracy and logic 
      consistency. Variables were analyzed using contingency table construction and 
      Chi-squared analyses. RESULTS: Of 635 questions, 360 were useable as inputs 
      (56.7%). ChatGPT-3.5 scored 55.8%, 47.7%, and 54% for the years 2020, 2021, and 
      2022, respectively. Of 190 correct outputs, 179 provided a consistent logic 
      (94.2%). Of 170 incorrect outputs, 133 provided an inconsistent logic (78.2%). 
      Significant associations were found between test topic and correct answer 
      (p = 0.011), and type of logic used and tested topic (p =  &lt; 0.001). Basic 
      Science and Sports had adjusted residuals greater than 1.96. Basic Science and 
      correct, no logic; Basic Science and incorrect, inconsistent logic; Sports and 
      correct, no logic; and Sports and incorrect, inconsistent logic; had adjusted 
      residuals greater than 1.96. CONCLUSIONS: Based on annual OITE technical reports 
      for resident physicians, ChatGPT-3.5 performed around the PGY-1 level. When 
      answering correctly, it displayed congruent reasoning with testmakers. When 
      answering incorrectly, it exhibited some understanding of the correct answer. It 
      outperformed in Basic Science and Sports, likely due to its ability to output 
      rote facts. These findings suggest that it lacks the fundamental capabilities to 
      be a comprehensive tool in Orthopedic Surgery in its current form. LEVEL OF 
      EVIDENCE: II.
CI  - © 2023. The Author(s).
FAU - Jain, Neil
AU  - Jain N
AUID- ORCID: 0000-0002-3452-2988
AD  - Department of Orthopedic Surgery, Texas Tech University Health Sciences Center 
      Lubbock, 3601 4th St, Lubbock, TX, 79430, USA. Neil.Jain@ttuhsc.edu.
FAU - Gottlich, Caleb
AU  - Gottlich C
AD  - Department of Orthopedic Surgery, Texas Tech University Health Sciences Center 
      Lubbock, 3601 4th St, Lubbock, TX, 79430, USA.
FAU - Fisher, John
AU  - Fisher J
AD  - Department of Orthopedic Surgery, Texas Tech University Health Sciences Center 
      Lubbock, 3601 4th St, Lubbock, TX, 79430, USA.
FAU - Campano, Dominic
AU  - Campano D
AD  - Department of Orthopedic Surgery, Texas Tech University Health Sciences Center 
      Lubbock, 3601 4th St, Lubbock, TX, 79430, USA.
FAU - Winston, Travis
AU  - Winston T
AD  - Department of Orthopedic Surgery, Texas Tech University Health Sciences Center 
      Lubbock, 3601 4th St, Lubbock, TX, 79430, USA.
LA  - eng
PT  - Journal Article
DEP - 20240103
PL  - England
TA  - J Orthop Surg Res
JT  - Journal of orthopaedic surgery and research
JID - 101265112
SB  - IM
MH  - Humans
MH  - *Orthopedic Procedures
MH  - *Orthopedics
MH  - *Sports
PMC - PMC10762835
OTO - NOTNLM
OT  - ChatGPT
OT  - General Orthopedics
OT  - Machine Learning
OT  - OITE
OT  - Resident Education
COIS- The authors declare that they have no competing interests.
EDAT- 2024/01/04 01:18
MHDA- 2024/01/05 06:43
PMCR- 2024/01/03
CRDT- 2024/01/03 09:31
PHST- 2023/08/28 00:00 [received]
PHST- 2023/12/12 00:00 [accepted]
PHST- 2024/01/05 06:43 [medline]
PHST- 2024/01/04 01:18 [pubmed]
PHST- 2024/01/03 09:31 [entrez]
PHST- 2024/01/03 00:00 [pmc-release]
AID - 10.1186/s13018-023-04467-0 [pii]
AID - 4467 [pii]
AID - 10.1186/s13018-023-04467-0 [doi]
PST - epublish
SO  - J Orthop Surg Res. 2024 Jan 3;19(1):27. doi: 10.1186/s13018-023-04467-0.

PMID- 37701862
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230914
IS  - 2475-4757 (Electronic)
IS  - 2475-4757 (Linking)
VI  - 15
IP  - 2
DP  - 2023 Jul
TI  - Improved Performance of ChatGPT-4 on the OKAP Examination: A Comparative Study 
      with ChatGPT-3.5.
PG  - e184-e187
LID - 10.1055/s-0043-1774399 [doi]
AB  - Introduction:  This study aims to evaluate the performance of ChatGPT-4, an 
      advanced artificial intelligence (AI) language model, on the Ophthalmology 
      Knowledge Assessment Program (OKAP) examination compared to its predecessor, 
      ChatGPT-3.5. Methods:  Both models were tested on 180 OKAP practice questions 
      covering various ophthalmology subject categories. Results:  ChatGPT-4 
      significantly outperformed ChatGPT-3.5 (81% vs. 57%; p &lt;0.001), indicating 
      improvements in medical knowledge assessment. Discussion:  The superior 
      performance of ChatGPT-4 suggests potential applicability in ophthalmologic 
      education and clinical decision support systems. Future research should focus on 
      refining AI models, ensuring a balanced representation of fundamental and 
      specialized knowledge, and determining the optimal method of integrating AI into 
      medical education and practice.
CI  - The Author(s). This is an open access article published by Thieme under the terms 
      of the Creative Commons Attribution-NonDerivative-NonCommercial License, 
      permitting copying and reproduction so long as the original work is given 
      appropriate credit. Contents may not be used for commercial purposes, or adapted, 
      remixed, transformed or built upon. ( 
      https://creativecommons.org/licenses/by-nc-nd/4.0/ ).
FAU - Teebagy, Sean
AU  - Teebagy S
AUID- ORCID: 0000-0002-6304-9608
AD  - Department of Ophthalmology and Visual Sciences, UMass Chan Medical School, 
      Worcester, Massachusetts.
FAU - Colwell, Lauren
AU  - Colwell L
AD  - Department of Ophthalmology and Visual Sciences, UMass Chan Medical School, 
      Worcester, Massachusetts.
FAU - Wood, Emma
AU  - Wood E
AD  - Department of Ophthalmology and Visual Sciences, UMass Chan Medical School, 
      Worcester, Massachusetts.
FAU - Yaghy, Antonio
AU  - Yaghy A
AD  - Department of Ophthalmology and Visual Sciences, UMass Chan Medical School, 
      Worcester, Massachusetts.
FAU - Faustina, Misha
AU  - Faustina M
AUID- ORCID: 0000-0003-3140-4406
AD  - Department of Ophthalmology and Visual Sciences, UMass Chan Medical School, 
      Worcester, Massachusetts.
LA  - eng
PT  - Journal Article
DEP - 20230911
PL  - United States
TA  - J Acad Ophthalmol (2017)
JT  - Journal of academic ophthalmology (2017)
JID - 101731829
PMC - PMC10495224
OTO - NOTNLM
OT  - ChatGPT
OT  - OKAP
OT  - Ophthalmology Knowledge Assessment Program
OT  - artificial intelligence
OT  - medical education
COIS- Conflict of Interest None declared.
EDAT- 2023/09/13 06:42
MHDA- 2023/09/13 06:43
PMCR- 2023/09/01
CRDT- 2023/09/13 04:14
PHST- 2023/04/13 00:00 [received]
PHST- 2023/08/10 00:00 [accepted]
PHST- 2023/09/13 06:43 [medline]
PHST- 2023/09/13 06:42 [pubmed]
PHST- 2023/09/13 04:14 [entrez]
PHST- 2023/09/01 00:00 [pmc-release]
AID - JAO-425 [pii]
AID - 10.1055/s-0043-1774399 [doi]
PST - epublish
SO  - J Acad Ophthalmol (2017). 2023 Sep 11;15(2):e184-e187. doi: 
      10.1055/s-0043-1774399. eCollection 2023 Jul.

PMID- 37337480
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230621
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 5
DP  - 2023 May
TI  - High Rates of Fabricated and Inaccurate References in ChatGPT-Generated Medical 
      Content.
PG  - e39238
LID - 10.7759/cureus.39238 [doi]
LID - e39238
AB  - Background The availability of large language models such as Chat Generative 
      Pre-trained Transformer (ChatGPT, OpenAI) has enabled individuals from diverse 
      backgrounds to access medical information. However, concerns exist about the 
      accuracy of ChatGPT responses and the references used to generate medical 
      content. Methods This observational study investigated the authenticity and 
      accuracy of references in medical articles generated by ChatGPT. ChatGPT-3.5 
      generated 30 short medical papers, each with at least three references, based on 
      standardized prompts encompassing various topics and therapeutic areas. Reference 
      authenticity and accuracy were verified by searching Medline, Google Scholar, and 
      the Directory of Open Access Journals. The authenticity and accuracy 
      of&nbsp;individual ChatGPT-generated reference elements were also determined. Results 
      Overall, 115 references were generated by ChatGPT, with a mean of 3.8±1.1 per 
      paper. Among these references, 47% were fabricated, 46% were authentic but 
      inaccurate, and only 7% were authentic and accurate. The likelihood of fabricated 
      references significantly differed based on prompt variations; yet the frequency 
      of authentic and accurate references remained low in all cases.&nbsp;Among the seven 
      components evaluated for each reference, an incorrect PMID number was most 
      common, listed in 93% of papers. Incorrect volume (64%), page numbers (64%), and 
      year of publication (60%) were the next most frequent errors. The mean number of 
      inaccurate components was 4.3±2.8 out of seven per reference. Conclusions The 
      findings of this study emphasize the need for caution when seeking medical 
      information on ChatGPT since most of the references provided were found to be 
      fabricated or inaccurate. Individuals are advised to verify medical information 
      from reliable sources and avoid relying solely on artificial 
      intelligence-generated content.
CI  - Copyright © 2023, Bhattacharyya et al.
FAU - Bhattacharyya, Mehul
AU  - Bhattacharyya M
AD  - Clinical Research, Miller Scientific, Johnson City, USA.
FAU - Miller, Valerie M
AU  - Miller VM
AD  - Leadership, University of the Cumberlands, Williamsburg, USA.
FAU - Bhattacharyya, Debjani
AU  - Bhattacharyya D
AD  - Education, University of Massachusetts Lowell, Lowell, USA.
FAU - Miller, Larry E
AU  - Miller LE
AD  - Clinical Research, Miller Scientific, Johnson City, USA.
LA  - eng
PT  - Journal Article
DEP - 20230519
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10277170
OTO - NOTNLM
OT  - artificial intelligence
OT  - chatgpt
OT  - large language model
OT  - machine learning
OT  - references
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/06/20 06:42
MHDA- 2023/06/20 06:43
PMCR- 2023/05/19
CRDT- 2023/06/20 02:25
PHST- 2023/05/18 00:00 [accepted]
PHST- 2023/06/20 06:43 [medline]
PHST- 2023/06/20 06:42 [pubmed]
PHST- 2023/06/20 02:25 [entrez]
PHST- 2023/05/19 00:00 [pmc-release]
AID - 10.7759/cureus.39238 [doi]
PST - epublish
SO  - Cureus. 2023 May 19;15(5):e39238. doi: 10.7759/cureus.39238. eCollection 2023 
      May.

PMID- 37844967
OWN - NLM
STAT- MEDLINE
DCOM- 20231023
LR  - 20231023
IS  - 2009-8774 (Electronic)
IS  - 2305-6983 (Print)
IS  - 2305-6983 (Linking)
VI  - 11
IP  - 4
DP  - 2023 Sep
TI  - Identifying depression and its determinants upon initiating treatment: ChatGPT 
      versus primary care physicians.
LID - 10.1136/fmch-2023-002391 [doi]
LID - e002391
AB  - OBJECTIVE: To compare evaluations of depressive episodes and suggested treatment 
      protocols generated by Chat Generative Pretrained Transformer (ChatGPT)-3 and 
      ChatGPT-4 with the recommendations of primary care physicians. METHODS: Vignettes 
      were input to the ChatGPT interface. These vignettes focused primarily on 
      hypothetical patients with symptoms of depression during initial consultations. 
      The creators of these vignettes meticulously designed eight distinct versions in 
      which they systematically varied patient attributes (sex, socioeconomic status 
      (blue collar worker or white collar worker) and depression severity (mild or 
      severe)). Each variant was subsequently introduced into ChatGPT-3.5 and 
      ChatGPT-4. Each vignette was repeated 10 times to ensure consistency and 
      reliability of the ChatGPT responses. RESULTS: For mild depression, ChatGPT-3.5 
      and ChatGPT-4 recommended psychotherapy in 95.0% and 97.5% of cases, 
      respectively. Primary care physicians, however, recommended psychotherapy in only 
      4.3% of cases. For severe cases, ChatGPT favoured an approach that combined 
      psychotherapy, while primary care physicians recommended a combined approach. The 
      pharmacological recommendations of ChatGPT-3.5 and ChatGPT-4 showed a preference 
      for exclusive use of antidepressants (74% and 68%, respectively), in contrast 
      with primary care physicians, who typically recommended a mix of antidepressants 
      and anxiolytics/hypnotics (67.4%). Unlike primary care physicians, ChatGPT showed 
      no gender or socioeconomic biases in its recommendations. CONCLUSION: ChatGPT-3.5 
      and ChatGPT-4 aligned well with accepted guidelines for managing mild and severe 
      depression, without showing the gender or socioeconomic biases observed among 
      primary care physicians. Despite the suggested potential benefit of using 
      atificial intelligence (AI) chatbots like ChatGPT to enhance clinical decision 
      making, further research is needed to refine AI recommendations for severe cases 
      and to consider potential risks and ethical issues.
CI  - © Author(s) (or their employer(s)) 2023. Re-use permitted under CC BY-NC. No 
      commercial re-use. See rights and permissions. Published by BMJ.
FAU - Levkovich, Inbar
AU  - Levkovich I
AUID- ORCID: 0000-0002-5717-4074
AD  - Oranim Academic College, Tivon, Israel inbar.lev2@gmail.com.
FAU - Elyoseph, Zohar
AU  - Elyoseph Z
AD  - Department of Psychology and Educational Counseling, Max Stern Academic College 
      Of Emek Yezreel, Emek Yezreel, Israel.
AD  - Department of Brain Sciences, Imperial College London, London, UK.
LA  - eng
PT  - Journal Article
PL  - England
TA  - Fam Med Community Health
JT  - Family medicine and community health
JID - 101700650
RN  - 0 (Anti-Anxiety Agents)
RN  - EC 2.3.1.6 (Choline O-Acetyltransferase)
RN  - 0 (Antidepressive Agents)
SB  - IM
MH  - Humans
MH  - Depression/drug therapy
MH  - *Physicians, Primary Care
MH  - Reproducibility of Results
MH  - *Anti-Anxiety Agents
MH  - Choline O-Acetyltransferase
MH  - Antidepressive Agents/therapeutic use
PMC - PMC10582915
OTO - NOTNLM
OT  - Depression
OT  - Family Health
OT  - Family Practice
OT  - General Practice
OT  - Mental Health
COIS- Competing interests: None declared.
EDAT- 2023/10/17 00:42
MHDA- 2023/10/23 01:18
PMCR- 2023/10/16
CRDT- 2023/10/16 20:53
PHST- 2023/10/23 01:18 [medline]
PHST- 2023/10/17 00:42 [pubmed]
PHST- 2023/10/16 20:53 [entrez]
PHST- 2023/10/16 00:00 [pmc-release]
AID - fmch-2023-002391 [pii]
AID - 10.1136/fmch-2023-002391 [doi]
PST - ppublish
SO  - Fam Med Community Health. 2023 Sep;11(4):e002391. doi: 10.1136/fmch-2023-002391.

PMID- 37198498
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230520
IS  - 2524-4442 (Electronic)
IS  - 2096-496X (Print)
IS  - 2524-4442 (Linking)
VI  - 6
IP  - 1
DP  - 2023 May 18
TI  - Translating radiology reports into plain language using ChatGPT and GPT-4 with 
      prompt learning: results, limitations, and potential.
PG  - 9
LID - 10.1186/s42492-023-00136-5 [doi]
LID - 9
AB  - The large language model called ChatGPT has drawn extensively attention because 
      of its human-like expression and reasoning abilities. In this study, we 
      investigate the feasibility of using ChatGPT in experiments on translating 
      radiology reports into plain language for patients and healthcare providers so 
      that they are educated for improved healthcare. Radiology reports from 62 
      low-dose chest computed tomography lung cancer screening scans and 76 brain 
      magnetic resonance imaging metastases screening scans were collected in the first 
      half of February for this study. According to the evaluation by radiologists, 
      ChatGPT can successfully translate radiology reports into plain language with an 
      average score of 4.27 in the five-point system with 0.08 places of information 
      missing and 0.07 places of misinformation. In terms of the suggestions provided 
      by ChatGPT, they are generally relevant such as keeping following-up with doctors 
      and closely monitoring any symptoms, and for about 37% of 138 cases in total 
      ChatGPT offers specific suggestions based on findings in the report. ChatGPT also 
      presents some randomness in its responses with occasionally over-simplified or 
      neglected information, which can be mitigated using a more detailed prompt. 
      Furthermore, ChatGPT results are compared with a newly released large model 
      GPT-4, showing that GPT-4 can significantly improve the quality of translated 
      reports. Our results show that it is feasible to utilize large language models in 
      clinical education, and further efforts are needed to address limitations and 
      maximize their potential.
CI  - © 2023. The Author(s).
FAU - Lyu, Qing
AU  - Lyu Q
AUID- ORCID: 0000-0002-9824-0170
AD  - Department of Radiology, Wake Forest University School of Medicine, 
      Winston-Salem, NC 27103, United States.
FAU - Tan, Josh
AU  - Tan J
AD  - Department of Radiology, Wake Forest University School of Medicine, 
      Winston-Salem, NC 27103, United States.
FAU - Zapadka, Michael E
AU  - Zapadka ME
AD  - Department of Radiology, Wake Forest University School of Medicine, 
      Winston-Salem, NC 27103, United States.
FAU - Ponnatapura, Janardhana
AU  - Ponnatapura J
AD  - Department of Radiology, Wake Forest University School of Medicine, 
      Winston-Salem, NC 27103, United States.
FAU - Niu, Chuang
AU  - Niu C
AD  - Biomedical Imaging Center, Rensselaer Polytechnic Institute, Troy, NY 12180, 
      United States.
FAU - Myers, Kyle J
AU  - Myers KJ
AD  - Puente Solutions LLC, Phoenix, AZ 85065, United States. drkylejmyers@gmail.com.
FAU - Wang, Ge
AU  - Wang G
AD  - Biomedical Imaging Center, Rensselaer Polytechnic Institute, Troy, NY 12180, 
      United States. wangg6@rpi.edu.
FAU - Whitlow, Christopher T
AU  - Whitlow CT
AD  - Department of Radiology, Wake Forest University School of Medicine, 
      Winston-Salem, NC 27103, United States. cwhitlow@wakehealth.edu.
LA  - eng
PT  - Journal Article
DEP - 20230518
PL  - Germany
TA  - Vis Comput Ind Biomed Art
JT  - Visual computing for industry, biomedicine, and art
JID - 101759975
PMC - PMC10192466
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Large language model
OT  - Patient education
OT  - Radiology report
COIS- The authors declare that they have no competing interests.
EDAT- 2023/05/18 01:07
MHDA- 2023/05/18 01:08
PMCR- 2023/05/18
CRDT- 2023/05/17 23:33
PHST- 2023/03/29 00:00 [received]
PHST- 2023/05/03 00:00 [accepted]
PHST- 2023/05/18 01:08 [medline]
PHST- 2023/05/18 01:07 [pubmed]
PHST- 2023/05/17 23:33 [entrez]
PHST- 2023/05/18 00:00 [pmc-release]
AID - 10.1186/s42492-023-00136-5 [pii]
AID - 136 [pii]
AID - 10.1186/s42492-023-00136-5 [doi]
PST - epublish
SO  - Vis Comput Ind Biomed Art. 2023 May 18;6(1):9. doi: 10.1186/s42492-023-00136-5.

PMID- 38434792
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240305
IS  - 2055-2076 (Print)
IS  - 2055-2076 (Electronic)
IS  - 2055-2076 (Linking)
VI  - 10
DP  - 2024 Jan-Dec
TI  - Performance of ChatGPT on the National Korean Occupational Therapy Licensing 
      Examination.
PG  - 20552076241236635
LID - 10.1177/20552076241236635 [doi]
LID - 20552076241236635
AB  - BACKGROUND: ChatGPT is an artificial intelligence-based large language model 
      (LLM). ChatGPT has been widely applied in medicine, but its application in 
      occupational therapy has been lacking. OBJECTIVE: This study examined the 
      accuracy of ChatGPT on the National Korean Occupational Therapy Licensing 
      Examination (NKOTLE) and investigated its potential for application in the field 
      of occupational therapy. METHODS: ChatGPT 3.5 was used during the five years of 
      the NKOTLE with Korean prompts. Multiple choice questions were entered manually 
      by three dependent encoders, and scored according to the number of correct 
      answers. RESULTS: During the most recent five years, ChatGPT did not achieve a 
      passing score of 60% accuracy and exhibited interrater agreement of 0.6 or 
      higher. CONCLUSION: ChatGPT could not pass the NKOTLE but demonstrated a high 
      level of agreement between raters. Even though the potential of ChatGPT to pass 
      the NKOTLE is currently inadequate, it performed very close to the passing level 
      even with only Korean prompts.
CI  - © The Author(s) 2024.
FAU - Lee, Si-An
AU  - Lee SA
AUID- ORCID: 0009-0004-5597-9778
AD  - Department of ICT convergence, The Graduate School, Soonchunhyang University, 
      Asan, Republic of Korea. RINGGOLD: 37969
FAU - Heo, Seoyoon
AU  - Heo S
AD  - Department of Occupational Therapy, Kyungbok University, Namyangju, Republic of 
      Korea.
FAU - Park, Jin-Hyuck
AU  - Park JH
AUID- ORCID: 0000-0002-0222-8901
AD  - Department of Occupational Therapy, College of Medical Science, Soonchunhyang 
      University, Asan, Republic of Korea. RINGGOLD: 37969
LA  - eng
PT  - Journal Article
DEP - 20240229
PL  - United States
TA  - Digit Health
JT  - Digital health
JID - 101690863
PMC - PMC10908230
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - large language models
OT  - licensing examination
OT  - occupational therapy
COIS- The author(s) declared no potential conflicts of interest with respect to the 
      research, authorship, and/or publication of this article.
EDAT- 2024/03/04 06:50
MHDA- 2024/03/04 06:51
PMCR- 2024/02/29
CRDT- 2024/03/04 04:51
PHST- 2024/02/14 00:00 [accepted]
PHST- 2024/03/04 06:51 [medline]
PHST- 2024/03/04 06:50 [pubmed]
PHST- 2024/03/04 04:51 [entrez]
PHST- 2024/02/29 00:00 [pmc-release]
AID - 10.1177_20552076241236635 [pii]
AID - 10.1177/20552076241236635 [doi]
PST - epublish
SO  - Digit Health. 2024 Feb 29;10:20552076241236635. doi: 10.1177/20552076241236635. 
      eCollection 2024 Jan-Dec.

PMID- 37378091
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230701
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 5
DP  - 2023 May
TI  - The Readiness of ChatGPT to Write Scientific Case Reports Independently: A 
      Comparative Evaluation Between Human and Artificial Intelligence.
PG  - e39386
LID - 10.7759/cureus.39386 [doi]
LID - e39386
AB  - The use of artificial intelligence (AI) in scientific publishing has gained 
      increased attention, and one AI tool that has been the subject of much discussion 
      is&nbsp;ChatGPT. It is a large language&nbsp;model&nbsp;(LLM) built on the OpenAI platform that 
      aims to emulate human-like writing and continually improves through user 
      interactions. In this paper, ChatGPT's performance was assessed in medical 
      publishing by comparing it to a case report written by oral and maxillofacial 
      radiologists. ChatGPT was tasked with writing a case report based on a drafted 
      report written by the authors in five different prompts.&nbsp;The&nbsp;findings of this 
      study highlight issues related to the accuracy, completeness, and readability of 
      the generated text. These results have significant implications for the future 
      use of AI in scientific publishing and suggest&nbsp;that in the current iteration of 
      ChatGPT, scientific information must be revised by an expert.
CI  - Copyright © 2023, Buholayka et al.
FAU - Buholayka, Maryam
AU  - Buholayka M
AD  - Oral and Maxillofacial Radiology, University of Connecticut Health, Farmington, 
      USA.
AD  - Department of Biomedical Sciences, Imam Abdulrahman Bin Faisal University, 
      Dammam, SAU.
FAU - Zouabi, Rama
AU  - Zouabi R
AD  - Oral and Maxillofacial Radiology, University of Connecticut Health, Farmington, 
      USA.
FAU - Tadinada, Aditya
AU  - Tadinada A
AD  - Oral and Maxillofacial Radiology, University of Connecticut Health, Farmington, 
      USA.
LA  - eng
PT  - Journal Article
DEP - 20230523
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10292135
OTO - NOTNLM
OT  - artificial hallucination
OT  - artificial intelligence
OT  - case report
OT  - chatgpt
OT  - scientific writing and artificial intelligence
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/06/28 13:09
MHDA- 2023/06/28 13:10
PMCR- 2023/05/23
CRDT- 2023/06/28 09:28
PHST- 2023/05/23 00:00 [accepted]
PHST- 2023/06/28 13:10 [medline]
PHST- 2023/06/28 13:09 [pubmed]
PHST- 2023/06/28 09:28 [entrez]
PHST- 2023/05/23 00:00 [pmc-release]
AID - 10.7759/cureus.39386 [doi]
PST - epublish
SO  - Cureus. 2023 May 23;15(5):e39386. doi: 10.7759/cureus.39386. eCollection 2023 
      May.

PMID- 38111256
OWN - NLM
STAT- MEDLINE
DCOM- 20240201
LR  - 20240217
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 10
DP  - 2024 Jan 31
TI  - Evaluation of ChatGPT's Real-Life Implementation in Undergraduate Dental 
      Education: Mixed Methods Study.
PG  - e51344
LID - 10.2196/51344 [doi]
LID - e51344
AB  - BACKGROUND: The recent artificial intelligence tool ChatGPT seems to offer a 
      range of benefits in academic education while also raising concerns. Relevant 
      literature encompasses issues of plagiarism and academic dishonesty, as well as 
      pedagogy and educational affordances; yet, no real-life implementation of ChatGPT 
      in the educational process has been reported to our knowledge so far. OBJECTIVE: 
      This mixed methods study aimed to evaluate the implementation of ChatGPT in the 
      educational process, both quantitatively and qualitatively. METHODS: In March 
      2023, a total of 77 second-year dental students of the European University Cyprus 
      were divided into 2 groups and asked to compose a learning assignment on 
      "Radiation Biology and Radiation Protection in the Dental Office," working 
      collaboratively in small subgroups, as part of the educational semester program 
      of the Dentomaxillofacial Radiology module. Careful planning ensured a seamless 
      integration of ChatGPT, addressing potential challenges. One group searched the 
      internet for scientific resources to perform the task and the other group used 
      ChatGPT for this purpose. Both groups developed a PowerPoint (Microsoft Corp) 
      presentation based on their research and presented it in class. The ChatGPT group 
      students additionally registered all interactions with the language model during 
      the prompting process and evaluated the final outcome; they also answered an 
      open-ended evaluation questionnaire, including questions on their learning 
      experience. Finally, all students undertook a knowledge examination on the topic, 
      and the grades between the 2 groups were compared statistically, whereas the 
      free-text comments of the questionnaires were thematically analyzed. RESULTS: Out 
      of the 77 students, 39 were assigned to the ChatGPT group and 38 to the 
      literature research group. Seventy students undertook the multiple choice 
      question knowledge examination, and examination grades ranged from 5 to 10 on the 
      0-10 grading scale. The Mann-Whitney U test showed that students of the ChatGPT 
      group performed significantly better (P=.045) than students of the literature 
      research group. The evaluation questionnaires revealed the benefits (human-like 
      interface, immediate response, and wide knowledge base), the limitations (need 
      for rephrasing the prompts to get a relevant answer, general content, false 
      citations, and incapability to provide images or videos), and the prospects (in 
      education, clinical practice, continuing education, and research) of ChatGPT. 
      CONCLUSIONS: Students using ChatGPT for their learning assignments performed 
      significantly better in the knowledge examination than their fellow students who 
      used the literature research methodology. Students adapted quickly to the 
      technological environment of the language model, recognized its opportunities and 
      limitations, and used it creatively and efficiently. Implications for practice: 
      the study underscores the adaptability of students to technological innovations 
      including ChatGPT and its potential to enhance educational outcomes. Educators 
      should consider integrating ChatGPT into curriculum design; awareness programs 
      are warranted to educate both students and educators about the limitations of 
      ChatGPT, encouraging critical engagement and responsible use.
CI  - ©Argyro Kavadella, Marco Antonio Dias da Silva, Eleftherios G Kaklamanos, 
      Vasileios Stamatopoulos, Kostis Giannakopoulos. Originally published in JMIR 
      Medical Education (https://mededu.jmir.org), 31.01.2024.
FAU - Kavadella, Argyro
AU  - Kavadella A
AUID- ORCID: 0009-0003-0560-8373
AD  - School of Dentistry, European University Cyprus, Nicosia, Cyprus.
FAU - Dias da Silva, Marco Antonio
AU  - Dias da Silva MA
AUID- ORCID: 0000-0002-2774-4769
AD  - Research Group of Teleducation and Teledentistry, Federal University of Campina 
      Grande, Campina Grande, Brazil.
FAU - Kaklamanos, Eleftherios G
AU  - Kaklamanos EG
AUID- ORCID: 0000-0002-0513-5110
AD  - School of Dentistry, European University Cyprus, Nicosia, Cyprus.
AD  - School of Dentistry, Aristotle University of Thessaloniki, Thessaloniki, Greece.
AD  - Mohammed Bin Rashid University of Medicine and Health Sciences, Dubai, United 
      Arab Emirates.
FAU - Stamatopoulos, Vasileios
AU  - Stamatopoulos V
AUID- ORCID: 0000-0002-9044-796X
AD  - Information Management Systems Institute, ATHENA Research and Innovation Center, 
      Athens, Greece.
FAU - Giannakopoulos, Kostis
AU  - Giannakopoulos K
AUID- ORCID: 0000-0001-7008-7306
AD  - School of Dentistry, European University Cyprus, Nicosia, Cyprus.
LA  - eng
PT  - Journal Article
DEP - 20240131
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Students
MH  - Educational Status
MH  - Learning
MH  - Education, Dental
PMC - PMC10867750
OTO - NOTNLM
OT  - AI pedagogy
OT  - ChatGPT
OT  - LLM
OT  - artificial Intelligence
OT  - dental education
OT  - dental students
OT  - dentistry
OT  - higher education
OT  - large language models
OT  - learning assignments
OT  - natural language processing
OT  - university
COIS- Conflicts of Interest: None declared.
EDAT- 2023/12/19 06:42
MHDA- 2024/02/01 06:43
PMCR- 2024/01/31
CRDT- 2023/12/19 02:23
PHST- 2023/07/28 00:00 [received]
PHST- 2023/12/11 00:00 [accepted]
PHST- 2023/10/28 00:00 [revised]
PHST- 2024/02/01 06:43 [medline]
PHST- 2023/12/19 06:42 [pubmed]
PHST- 2023/12/19 02:23 [entrez]
PHST- 2024/01/31 00:00 [pmc-release]
AID - v10i1e51344 [pii]
AID - 10.2196/51344 [doi]
PST - epublish
SO  - JMIR Med Educ. 2024 Jan 31;10:e51344. doi: 10.2196/51344.

PMID- 37332008
OWN - NLM
STAT- MEDLINE
DCOM- 20240125
LR  - 20240204
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 52
IP  - 2
DP  - 2024 Feb
TI  - Revolutionary Potential of ChatGPT in Constructing Intelligent Clinical Decision 
      Support Systems.
PG  - 125-129
LID - 10.1007/s10439-023-03288-w [doi]
AB  - Recently, Chatbot Generative Pre-trained Transformer (ChatGPT) is recognized as a 
      promising clinical decision support system (CDSS) in the medical field owing to 
      its advanced text analysis capabilities and interactive design. However, ChatGPT 
      primarily focuses on learning text semantics rather than learning complex data 
      structures and conducting real-time data analysis, which typically necessitate 
      the development of intelligent CDSS employing specialized machine learning 
      algorithms. Although ChatGPT cannot directly execute specific algorithms, it aids 
      in algorithm design for intelligent CDSS at the textual level. In this study, 
      besides discussing the types of CDSS and their relationship with ChatGPT, we 
      mainly investigate the benefits and drawbacks of employing ChatGPT as an 
      auxiliary design tool for intelligent CDSS. Our findings indicate that by 
      collaborating with human expertise, ChatGPT has the potential to revolutionize 
      the development of robust and effective intelligent CDSS.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Liao, Zhiqiang
AU  - Liao Z
AUID- ORCID: 0000-0002-4030-1364
AD  - Department of Electrical Engineering and Information Systems, Graduate School of 
      Engineering, The University of Tokyo, Tokyo, 113-8656, Japan. 
      liao@bioxide.t.u-tokyo.ac.jp.
FAU - Wang, Jian
AU  - Wang J
AD  - Department of Orthopaedics, Qilu Hospital of Shandong University, Jinan, 250012, 
      People's Republic of China.
FAU - Shi, Zhuozheng
AU  - Shi Z
AD  - Department of Bioengineering, Graduate School of Engineering, The University of 
      Tokyo, Tokyo, 113-8656, Japan.
FAU - Lu, Lintao
AU  - Lu L
AD  - Department of Orthopaedics, Qilu Hospital of Shandong University, Jinan, 250012, 
      People's Republic of China. lulintao@mail.sdu.edu.cn.
AD  - Department of Orthopaedics, Qilu Hospital of Shandong University Dezhou Hospital, 
      Dezhou, 253000, People's Republic of China. lulintao@mail.sdu.edu.cn.
FAU - Tabata, Hitoshi
AU  - Tabata H
AD  - Department of Electrical Engineering and Information Systems, Graduate School of 
      Engineering, The University of Tokyo, Tokyo, 113-8656, Japan.
AD  - Department of Bioengineering, Graduate School of Engineering, The University of 
      Tokyo, Tokyo, 113-8656, Japan.
LA  - eng
PT  - Letter
DEP - 20230618
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - Humans
MH  - *Decision Support Systems, Clinical
MH  - Software
MH  - Algorithms
MH  - Electric Power Supplies
MH  - Machine Learning
OTO - NOTNLM
OT  - ChatGPT
OT  - Clinical decision support systems
OT  - Large language model
OT  - Machine learning
EDAT- 2023/06/19 00:42
MHDA- 2024/01/25 06:43
CRDT- 2023/06/18 23:35
PHST- 2023/06/08 00:00 [received]
PHST- 2023/06/13 00:00 [accepted]
PHST- 2024/01/25 06:43 [medline]
PHST- 2023/06/19 00:42 [pubmed]
PHST- 2023/06/18 23:35 [entrez]
AID - 10.1007/s10439-023-03288-w [pii]
AID - 10.1007/s10439-023-03288-w [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2024 Feb;52(2):125-129. doi: 10.1007/s10439-023-03288-w. Epub 
      2023 Jun 18.

PMID- 37078489
OWN - NLM
STAT- MEDLINE
DCOM- 20240208
LR  - 20240208
IS  - 1488-2361 (Electronic)
IS  - 0846-5371 (Linking)
VI  - 75
IP  - 1
DP  - 2024 Feb
TI  - Accuracy of Information and References Using ChatGPT-3 for Retrieval of Clinical 
      Radiological Information.
PG  - 69-73
LID - 10.1177/08465371231171125 [doi]
AB  - Purpose: To assess the accuracy of answers provided by ChatGPT-3 when prompted 
      with questions from the daily routine of radiologists and to evaluate the text 
      response when ChatGPT-3 was prompted to provide references for a given answer. 
      Methods: ChatGPT-3 (San Francisco, OpenAI) is an artificial intelligence chatbot 
      based on a large language model (LLM) that has been designed to generate 
      human-like text. A total of 88 questions were submitted to ChatGPT-3 using 
      textual prompt. These 88 questions were equally dispersed across 8 subspecialty 
      areas of radiology. The responses provided by ChatGPT-3 were assessed for 
      correctness by cross-checking them with peer-reviewed, PubMed-listed references. 
      In addition, the references provided by ChatGPT-3 were evaluated for 
      authenticity. Results: A total of 59 of 88 responses (67%) to radiological 
      questions were correct, while 29 responses (33%) had errors. Out of 343 
      references provided, only 124 references (36.2%) were available through internet 
      search, while 219 references (63.8%) appeared to be generated by ChatGPT-3. When 
      examining the 124 identified references, only 47 references (37.9%) were 
      considered to provide enough background to correctly answer 24 questions (37.5%). 
      Conclusion: In this pilot study, ChatGPT-3 provided correct responses to 
      questions from the daily clinical routine of radiologists in only about two 
      thirds, while the remainder of responses contained errors. The majority of 
      provided references were not found and only a minority of the provided references 
      contained the correct information to answer the question. Caution is advised when 
      using ChatGPT-3 to retrieve radiological information.
FAU - Wagner, Matthias W
AU  - Wagner MW
AUID- ORCID: 0000-0001-6501-839X
AD  - Department of Diagnostic Imaging, Division of Neuroradiology, The Hospital for 
      Sick Children, Toronto, Canada. RINGGOLD: 7979
AD  - Department of Medical Imaging, University of Toronto, Toronto, Canada. RINGGOLD: 
      12366
FAU - Ertl-Wagner, Birgit B
AU  - Ertl-Wagner BB
AD  - Department of Diagnostic Imaging, Division of Neuroradiology, The Hospital for 
      Sick Children, Toronto, Canada. RINGGOLD: 7979
AD  - Department of Medical Imaging, University of Toronto, Toronto, Canada. RINGGOLD: 
      12366
LA  - eng
PT  - Journal Article
DEP - 20230420
PL  - United States
TA  - Can Assoc Radiol J
JT  - Canadian Association of Radiologists journal = Journal l'Association canadienne 
      des radiologistes
JID - 8812910
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Pilot Projects
MH  - *Radiology
MH  - Radiography
MH  - Radiologists
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - decision support
OT  - large language models
OT  - radiology
COIS- Declaration of Conflicting InterestsThe author(s) declared no potential conflicts 
      of interest with respect to the research, authorship, and/or publication of this 
      article.
EDAT- 2023/04/20 13:41
MHDA- 2024/02/08 06:43
CRDT- 2023/04/20 06:54
PHST- 2024/02/08 06:43 [medline]
PHST- 2023/04/20 13:41 [pubmed]
PHST- 2023/04/20 06:54 [entrez]
AID - 10.1177/08465371231171125 [doi]
PST - ppublish
SO  - Can Assoc Radiol J. 2024 Feb;75(1):69-73. doi: 10.1177/08465371231171125. Epub 
      2023 Apr 20.

PMID- 37369944
OWN - NLM
STAT- MEDLINE
DCOM- 20240214
LR  - 20240214
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 52
IP  - 3
DP  - 2024 Mar
TI  - Advancing the Production of Clinical Medical Devices Through ChatGPT.
PG  - 441-445
LID - 10.1007/s10439-023-03300-3 [doi]
AB  - As a recently popular large language model, Chatbot Generative Pre-trained 
      Transformer (ChatGPT) is highly valued in the field of clinical medicine. Due to 
      the limited understanding of the potential impact of ChatGPT on the manufacturing 
      side of clinical medical devices, we aim to fill this gap through this article. 
      We elucidate the classification of medical devices and explore the positive 
      contributions of ChatGPT in various aspects of medical device design, 
      optimization, and improvement. However, limitations such as the potential for 
      misinterpretation of user intent, lack of personal experience, and the need for 
      human supervision should be taken into consideration. Striking a balance between 
      ChatGPT and human expertise can ensure the safety, quality, and compliance of 
      medical devices. This work contributes to the advancement of ChatGPT in the 
      medical device manufacturing industry and highlights the synergistic relationship 
      between artificial intelligence and human involvement in healthcare.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Li, Siqi
AU  - Li S
AD  - Advanced Research Center, GD Midea Equipment Co., Ltd, Foshan, 528000, China.
FAU - Guo, Zheng
AU  - Guo Z
AUID- ORCID: 0009-0005-5060-5571
AD  - Orthopedics Department of The Sixth Affiliated Hospital, School of Medicine, 
      South China University of Technology, Foshan, 528042, China. 
      guozheng98@mail.sdu.edu.cn.
FAU - Zang, Xuehui
AU  - Zang X
AD  - Orthopedics Department of The Sixth Affiliated Hospital, School of Medicine, 
      South China University of Technology, Foshan, 528042, China. 
      lyzangxh@scut.edu.cn.
LA  - eng
PT  - Letter
DEP - 20230627
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Software
MH  - Electric Power Supplies
MH  - Equipment Design
MH  - Manufacturing Industry
OTO - NOTNLM
OT  - ChatGPT
OT  - Clinical medical devices
OT  - Large language model
OT  - Manufacturing engineering
EDAT- 2023/06/28 01:06
MHDA- 2024/02/12 15:42
CRDT- 2023/06/27 23:32
PHST- 2023/06/19 00:00 [received]
PHST- 2023/06/22 00:00 [accepted]
PHST- 2024/02/12 15:42 [medline]
PHST- 2023/06/28 01:06 [pubmed]
PHST- 2023/06/27 23:32 [entrez]
AID - 10.1007/s10439-023-03300-3 [pii]
AID - 10.1007/s10439-023-03300-3 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2024 Mar;52(3):441-445. doi: 10.1007/s10439-023-03300-3. Epub 
      2023 Jun 27.

PMID- 38084123
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231212
IS  - 1178-2390 (Print)
IS  - 1178-2390 (Electronic)
IS  - 1178-2390 (Linking)
VI  - 16
DP  - 2023
TI  - Are Different Versions of ChatGPT's Ability Comparable to the Clinical Diagnosis 
      Presented in Case Reports? A Descriptive Study.
PG  - 3825-3831
LID - 10.2147/JMDH.S441790 [doi]
AB  - OBJECTIVE: ChatGPT, an advanced language model developed by OpenAI, holds the 
      opportunity to bring about a transformation in the processing of clinical 
      decision-making within the realm of medicine. Despite the growing popularity of 
      research related on ChatGPT, there is a paucity of research assessing its 
      appropriateness for clinical decision support. Our study delved into ChatGPT's 
      ability to respond in accordance with the diagnoses found in case reports, with 
      the intention of serving as a reference for clinical decision-making. METHODS: We 
      included 147 case reports from the Chinese Medical Association Journal Database 
      that generated primary and secondary diagnoses covering various diseases. Each 
      question was independently posed three times to both GPT-3.5 and GPT-4.0, 
      respectively. The results were analyzed regarding ChatGPT's mean scores and 
      accuracy types. RESULTS: GPT-4.0 displayed moderate accuracy in primary 
      diagnoses. With the increasing number of input, a corresponding enhancement in 
      the accuracy of ChatGPT's outputs became evident. Notably, autoimmune diseases 
      comprised the largest proportion of case reports, and the mean score for primary 
      diagnosis exhibited statistically significant differences in autoimmune diseases. 
      CONCLUSION: Our finding suggested that the potential practicality in utilizing 
      ChatGPT for clinical decision-making. To enhance the accuracy of ChatGPT, it is 
      necessary to integrate it with the existing electronic health record system in 
      the future.
CI  - © 2023 Chen et al.
FAU - Chen, Jingfang
AU  - Chen J
AUID- ORCID: 0000-0001-8389-7703
AD  - Faculty of Medicine, Macau University of Science and Technology, Macau, People's 
      Republic of China.
AD  - Department of Research and Teaching, the Third People's Hospital of Shenzhen, 
      Shenzhen, People's Republic of China.
AD  - Hengyang Medical School, School of Nursing, University of South China, Hengyang, 
      People's Republic of China.
FAU - Liu, Linlin
AU  - Liu L
AD  - Hengyang Medical School, School of Nursing, University of South China, Hengyang, 
      People's Republic of China.
FAU - Ruan, Shujin
AU  - Ruan S
AD  - Hengyang Medical School, School of Nursing, University of South China, Hengyang, 
      People's Republic of China.
FAU - Li, Mengjun
AU  - Li M
AD  - Hengyang Medical School, School of Nursing, University of South China, Hengyang, 
      People's Republic of China.
FAU - Yin, Chengliang
AU  - Yin C
AUID- ORCID: 0000-0001-8262-5749
AD  - Faculty of Medicine, Macau University of Science and Technology, Macau, People's 
      Republic of China.
LA  - eng
PT  - Journal Article
DEP - 20231206
PL  - New Zealand
TA  - J Multidiscip Healthc
JT  - Journal of multidisciplinary healthcare
JID - 101512691
PMC - PMC10710805
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - case reports
OT  - clinical decision support systems
COIS- The authors report no conflicts of interest in this work.
EDAT- 2023/12/12 06:42
MHDA- 2023/12/12 06:43
PMCR- 2023/12/06
CRDT- 2023/12/12 03:35
PHST- 2023/09/23 00:00 [received]
PHST- 2023/11/26 00:00 [accepted]
PHST- 2023/12/12 06:43 [medline]
PHST- 2023/12/12 06:42 [pubmed]
PHST- 2023/12/12 03:35 [entrez]
PHST- 2023/12/06 00:00 [pmc-release]
AID - 441790 [pii]
AID - 10.2147/JMDH.S441790 [doi]
PST - epublish
SO  - J Multidiscip Healthc. 2023 Dec 6;16:3825-3831. doi: 10.2147/JMDH.S441790. 
      eCollection 2023.

PMID- 38219629
OWN - NLM
STAT- Publisher
LR  - 20240114
IS  - 1532-818X (Electronic)
IS  - 0196-0709 (Linking)
VI  - 45
IP  - 3
DP  - 2024 Jan 9
TI  - Artificial intelligence and ChatGPT: An otolaryngology patient's ally or foe?
PG  - 104220
LID - S0196-0709(24)00006-1 [pii]
LID - 10.1016/j.amjoto.2024.104220 [doi]
AB  - BACKGROUND: As artificial intelligence (AI) is integrating into the healthcare 
      sphere, there is a need to evaluate its effectiveness in the various 
      subspecialties of medicine, including otolaryngology. Our study intends to 
      provide a cursory review of ChatGPT's diagnostic capability, ability to convey 
      pathophysiology in simple terms, accuracy in providing management 
      recommendations, and appropriateness in follow up and post-operative 
      recommendations in common otolaryngologic conditions. METHODS: Adenotonsillectomy 
      (T&amp;A), tympanoplasty (TP), endoscopic sinus surgery (ESS), parotidectomy (PT), 
      and total laryngectomy (TL) were substituted for the word procedure in the 
      following five questions and input into ChatGPT version 3.5: "How do I know if I 
      need (procedure)," "What are treatment alternatives to (procedure)," "What are 
      the risks of (procedure)," "How is a (procedure) performed," and "What is the 
      recovery process for (procedure)?" Two independent study members analyzed the 
      output and discrepancies were reviewed, discussed, and reconciled between study 
      members. RESULTS: In terms of management recommendations, ChatGPT was able to 
      give generalized statements of evaluation, need for intervention, and the basics 
      of the procedure without major aberrant errors or risks of safety. ChatGPT was 
      successful in providing appropriate treatment alternatives in all procedures 
      tested. When queried for methodology, risks, and procedural steps, ChatGPT lacked 
      precision in the description of procedural steps, missed key surgical details, 
      and did not accurately provide all major risks of each procedure. In terms of the 
      recovery process, ChatGPT showed promise in T&amp;A, TP, ESS, and PT but struggled in 
      the complexity of TL, stating the patient could speak immediately after surgery 
      without speech therapy. CONCLUSIONS: ChatGPT accurately demonstrated the need for 
      intervention, management recommendations, and treatment alternatives in common 
      ENT procedures. However, ChatGPT was not able to replace an otolaryngologist's 
      clinical reasoning necessary to discuss procedural methodology, risks, and the 
      recovery process in complex procedures. As AI becomes further integrated into 
      healthcare, there is a need to continue to explore its indications, evaluate its 
      limits, and refine its use to the otolaryngologist's advantage.
CI  - Copyright © 2024 Elsevier Inc. All rights reserved.
FAU - Langlie, Jake
AU  - Langlie J
AD  - University of Miami Miller School of Medicine, Miami, FL 33136, United States of 
      America.
FAU - Kamrava, Brandon
AU  - Kamrava B
AD  - Department of Otolaryngology, University of Miami Health System, Miami, FL 33136, 
      United States of America.
FAU - Pasick, Luke J
AU  - Pasick LJ
AD  - Department of Otolaryngology, University of Miami Health System, Miami, FL 33136, 
      United States of America.
FAU - Mei, Christine
AU  - Mei C
AD  - Department of Otolaryngology, University of Miami Health System, Miami, FL 33136, 
      United States of America.
FAU - Hoffer, Michael E
AU  - Hoffer ME
AD  - Department of Otolaryngology, University of Miami Health System, Miami, FL 33136, 
      United States of America; Department of Neurosurgery, University of Miami Health 
      System, Miami, FL 33136, United States of America. Electronic address: 
      michael.hoffer@miami.edu.
LA  - eng
PT  - Journal Article
DEP - 20240109
PL  - United States
TA  - Am J Otolaryngol
JT  - American journal of otolaryngology
JID - 8000029
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - ENT
OT  - Otolaryngology
COIS- Declaration of competing interest The authors declare no conflict of interest 
      regarding the article.
EDAT- 2024/01/15 00:42
MHDA- 2024/01/15 00:42
CRDT- 2024/01/14 18:16
PHST- 2023/12/20 00:00 [received]
PHST- 2024/01/01 00:00 [accepted]
PHST- 2024/01/15 00:42 [medline]
PHST- 2024/01/15 00:42 [pubmed]
PHST- 2024/01/14 18:16 [entrez]
AID - S0196-0709(24)00006-1 [pii]
AID - 10.1016/j.amjoto.2024.104220 [doi]
PST - aheadofprint
SO  - Am J Otolaryngol. 2024 Jan 9;45(3):104220. doi: 10.1016/j.amjoto.2024.104220.

PMID- 38404561
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240311
IS  - 2641-7413 (Electronic)
IS  - 2641-7413 (Linking)
VI  - 7
IP  - 1
DP  - 2024
TI  - ChatGPT to Enhance Learning in Dental Education at a Historically Black Medical 
      College.
PG  - 8-14
LID - 10.26502/droh.0069 [doi]
AB  - The recent rise of powerful large language model (LLM)-based AI tools, 
      exemplified by ChatGPT and Bard, poses a great challenge to contemporary dental 
      education. It simultaneously offers a unique resource that potentially 
      complements today's teaching and learning, where existing widely available 
      learning resources have often fallen short. Although the LLM tools will shape 
      both the clinical and educational aspects of dentistry profoundly, the didactic 
      curricula, which primarily rely on lecture-based courses where instructors impart 
      knowledge through presentations and discussions, need to be upgraded urgently. In 
      this paper, we used dental course materials, syllabi, and textbooks adopted 
      currently in the School of Dentistry (SOD) at Meharry Medical College to assess 
      the potential utility and effectiveness of ChatGPT in dental education. We 
      collected the responses of the chatbot to questions as well as students' 
      interactions with it for assessment. Our results showed that ChatGPT can assist 
      in dental essay writing and generate relevant content for dental students, in 
      addition to other benefits. The limitations of ChatGPT were also discussed in the 
      paper.
FAU - Rahad, Khandoker
AU  - Rahad K
AD  - Department of Computer Science &amp; Data Science, School of Applied Computational 
      Sciences, Meharry Medical College, Nashville, TN, USA.
FAU - Martin, Kianna
AU  - Martin K
AD  - Department of ODS &amp; Research, School of Dentistry, Meharry Medical College, 
      Nashville, TN, USA.
FAU - Amugo, Ihunna
AU  - Amugo I
AD  - Department of ODS &amp; Research, School of Dentistry, Meharry Medical College, 
      Nashville, TN, USA.
FAU - Ferguson, Shania
AU  - Ferguson S
AD  - Department of ODS &amp; Research, School of Dentistry, Meharry Medical College, 
      Nashville, TN, USA.
FAU - Curtis, Angela
AU  - Curtis A
AD  - Department of ODS &amp; Research, School of Dentistry, Meharry Medical College, 
      Nashville, TN, USA.
FAU - Davis, Anniya
AU  - Davis A
AD  - Department of ODS &amp; Research, School of Dentistry, Meharry Medical College, 
      Nashville, TN, USA.
FAU - Gangula, Pandu
AU  - Gangula P
AD  - Department of ODS &amp; Research, School of Dentistry, Meharry Medical College, 
      Nashville, TN, USA.
FAU - Wang, Qingguo
AU  - Wang Q
AD  - Department of Computer Science &amp; Data Science, School of Applied Computational 
      Sciences, Meharry Medical College, Nashville, TN, USA.
LA  - eng
GR  - OT2 OD032581/OD/NIH HHS/United States
GR  - U01 DE033241/DE/NIDCR NIH HHS/United States
GR  - U54 MD007586/MD/NIMHD NIH HHS/United States
PT  - Journal Article
DEP - 20240125
PL  - United States
TA  - Dent Res Oral Health
JT  - Dental research and oral health
JID - 9918300788606676
UOF - Res Sq. 2023 Dec 29;:. PMID: 37986988
PMC - PMC10887427
MID - NIHMS1962961
OTO - NOTNLM
OT  - ChatGPT
OT  - Dental Education
OT  - Dentistry
OT  - Large language model
OT  - Student Learning
EDAT- 2024/02/26 06:45
MHDA- 2024/02/26 06:46
PMCR- 2024/02/23
CRDT- 2024/02/26 04:28
PHST- 2024/02/26 06:46 [medline]
PHST- 2024/02/26 06:45 [pubmed]
PHST- 2024/02/26 04:28 [entrez]
PHST- 2024/02/23 00:00 [pmc-release]
AID - 10.26502/droh.0069 [doi]
PST - ppublish
SO  - Dent Res Oral Health. 2024;7(1):8-14. doi: 10.26502/droh.0069. Epub 2024 Jan 25.

PMID- 37952004
OWN - NLM
STAT- MEDLINE
DCOM- 20240401
LR  - 20240401
IS  - 1573-8744 (Electronic)
IS  - 1567-567X (Linking)
VI  - 51
IP  - 2
DP  - 2024 Apr
TI  - Evaluation of prompt engineering strategies for pharmacokinetic data analysis 
      with the ChatGPT large language model.
PG  - 101-108
LID - 10.1007/s10928-023-09892-6 [doi]
AB  - To systematically assess the ChatGPT large language model on diverse tasks 
      relevant to pharmacokinetic data analysis. ChatGPT was evaluated with 
      prototypical tasks related to report writing, code generation, non-compartmental 
      analysis, and pharmacokinetic word problems. The writing task consisted of 
      writing an introduction for this paper from a draft title. The coding tasks 
      consisted of generating R code for semi-logarithmic graphing of 
      concentration-time profiles and calculating area under the curve and area under 
      the moment curve from time zero to infinity. Pharmacokinetics word problems on 
      single intravenous, extravascular bolus, and multiple dosing were taken from a 
      pharmacokinetics textbook. Chain-of-thought and problem separation were assessed 
      as prompt engineering strategies when errors occurred. ChatGPT showed 
      satisfactory performance on the report writing, code generation tasks and 
      provided accurate information on the principles and methods underlying 
      pharmacokinetic data analysis. However, ChatGPT had high error rates in numerical 
      calculations involving exponential functions. The outputs generated by ChatGPT 
      were not reproducible: the precise content of the output was variable albeit not 
      necessarily erroneous for different instances of the same prompt. Incorporation 
      of prompt engineering strategies reduced but did not eliminate errors in 
      numerical calculations. ChatGPT has the potential to become a powerful 
      productivity tool for writing, knowledge encapsulation, and coding tasks in 
      pharmacokinetic data analysis. The poor accuracy of ChatGPT in numerical 
      calculations require resolution before it can be reliably used for PK and 
      pharmacometrics data analysis.
CI  - © 2023. The Author(s), under exclusive licence to Springer Science+Business 
      Media, LLC, part of Springer Nature.
FAU - Shin, Euibeom
AU  - Shin E
AD  - Department of Pharmaceutical Sciences, University at Buffalo, The State 
      University of New York, 355 Pharmacy, Buffalo, NY, 14214-8033, USA.
FAU - Ramanathan, Murali
AU  - Ramanathan M
AD  - Department of Pharmaceutical Sciences, University at Buffalo, The State 
      University of New York, 355 Pharmacy, Buffalo, NY, 14214-8033, USA. 
      murali@buffalo.edu.
LA  - eng
PT  - Journal Article
DEP - 20231111
PL  - United States
TA  - J Pharmacokinet Pharmacodyn
JT  - Journal of pharmacokinetics and pharmacodynamics
JID - 101096520
SB  - IM
MH  - Administration, Intravenous
MH  - *Data Analysis
MH  - Injections, Intravenous
MH  - *Language
OTO - NOTNLM
OT  - Bioavailability
OT  - ChatGPT
OT  - Drug development
OT  - Graphing
OT  - PK/PD
OT  - Pharmacokinetics
OT  - Prompt engineering
EDAT- 2023/11/12 00:42
MHDA- 2024/04/01 06:42
CRDT- 2023/11/11 23:31
PHST- 2023/09/18 00:00 [received]
PHST- 2023/10/11 00:00 [accepted]
PHST- 2024/04/01 06:42 [medline]
PHST- 2023/11/12 00:42 [pubmed]
PHST- 2023/11/11 23:31 [entrez]
AID - 10.1007/s10928-023-09892-6 [pii]
AID - 10.1007/s10928-023-09892-6 [doi]
PST - ppublish
SO  - J Pharmacokinet Pharmacodyn. 2024 Apr;51(2):101-108. doi: 
      10.1007/s10928-023-09892-6. Epub 2023 Nov 11.

PMID- 37184746
OWN - NLM
STAT- MEDLINE
DCOM- 20230926
LR  - 20230926
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 51
IP  - 10
DP  - 2023 Oct
TI  - Revolutionizing Chronic Obstructive Pulmonary Disease Care with the Open AI 
      Application: ChatGPT.
PG  - 2100-2102
LID - 10.1007/s10439-023-03238-6 [doi]
AB  - Chronic Obstructive Pulmonary Disease (COPD) is one of the major and leading 
      threats to human being. To cope with this health challenge, several studies have 
      been undertaken in the literature. However, COPD is not paid close attention to 
      eliminate it entirely. The current study aims to examine the role of ChatGPT 
      application to bring improvement in controlling and managing COPD in patients. 
      ChatGPT is used to give prompt answers of text-based questions in a variety of 
      fields. It has potential role in knowing the symptoms of COPD, and letting 
      individuals to modify their life styles. ChatGPT suggests medications for COPD 
      individuals based on the established medical guidelines. Compared to the 
      literature, ChatGPT provides a comprehensive list of COPD test and evaluation 
      methods. ChatGPT has the potential to help physicians to take decisions in 
      diagnosing, treating, and managing COPD among individuals in its upcoming 
      versions. More researches can be conducted to identify the limits of ChatGPT 
      application in future works.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Hasnain, Muhammad
AU  - Hasnain M
AD  - Department of Computer Science, Lahore Leads University, Lahore, Pakistan. 
      drhasnain.it@leads.edu.pk.
FAU - Hayat, Asad
AU  - Hayat A
AD  - Department of Computer Science, Lahore Leads University, Lahore, Pakistan.
FAU - Hussain, Akbar
AU  - Hussain A
AD  - Department of Information Technology, Lahore Leads University, Lahore, Pakistan.
LA  - eng
PT  - Letter
DEP - 20230515
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - Humans
MH  - *Quality of Life
MH  - *Pulmonary Disease, Chronic Obstructive/diagnosis/drug therapy
OTO - NOTNLM
OT  - COPD tests
OT  - Medication
OT  - Pulmonary rehabilitation
EDAT- 2023/05/15 13:06
MHDA- 2023/09/26 13:42
CRDT- 2023/05/15 11:16
PHST- 2023/05/07 00:00 [received]
PHST- 2023/05/10 00:00 [accepted]
PHST- 2023/09/26 13:42 [medline]
PHST- 2023/05/15 13:06 [pubmed]
PHST- 2023/05/15 11:16 [entrez]
AID - 10.1007/s10439-023-03238-6 [pii]
AID - 10.1007/s10439-023-03238-6 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2023 Oct;51(10):2100-2102. doi: 10.1007/s10439-023-03238-6. Epub 
      2023 May 15.

PMID- 37528247
OWN - NLM
STAT- MEDLINE
DCOM- 20231009
LR  - 20231018
IS  - 1573-2584 (Electronic)
IS  - 0301-1623 (Linking)
VI  - 55
IP  - 11
DP  - 2023 Nov
TI  - The utility of the ChatGPT artificial intelligence tool for patient education and 
      enquiry in robotic radical prostatectomy.
PG  - 2717-2732
LID - 10.1007/s11255-023-03729-4 [doi]
AB  - OBJECTIVES: To assess the ChatGPT (Open AI) artificial intelligence platform's 
      utility and accuracy as a patient education tool in robotic-assisted radical 
      prostatectomy. MATERIALS AND METHODS: The ChatGPT 3.5 interface ( 
      https://chat.openai.com/chat ) was interrogated and asked the 14 questions 
      related to the frequency of complications of robotic-assisted radical 
      prostatectomy as listed on British Association of Urological Surgeons (BAUS) 
      patient information leaflet "Robotic-Assisted Laparoscopic Radical 
      Prostatectomy)" published July 2021. The AI's responses to each question were 
      tabulated, and compared alongside the official figures quoted from the BAUS 
      information leaflet. A global assessment of the AI's response was also made for 
      accuracy and relevance to patients. RESULTS: Of the 14 questions asked, 11/14 
      (78.6%) of ChatGPT's quoted figures were considered concordant and comparable to 
      those quoted by the BAUS patient information leaflet. 13/14 (92.9%) of ChatGPT's 
      responses were globally assessed to contain accurate information, appropriate, 
      and pertinent to a patient's potential enquiry. CONCLUSION: ChatGPT is a powerful 
      tool and is able to generate accurate and helpful information for patients 
      seeking information regarding urological procedures and their potential 
      complications. It is not, however, infallible, and urologists should remain 
      vigilant in their patient interactions to any potential misinformation a patient 
      may have gathered from it in their personal research prior to surgery.
CI  - © 2023. The Author(s), under exclusive licence to Springer Nature B.V.
FAU - Gabriel, Joseph
AU  - Gabriel J
AD  - Department of Urology, University Hospitals Sussex NHS Foundation Trust, Princess 
      Royal Hospital, Haywards Heath, UK. joseph.gabriel@nhs.net.
FAU - Shafik, Lidia
AU  - Shafik L
AD  - Surrey and Sussex Healthcare NHS Trust, Redhill, UK.
FAU - Alanbuki, Ammar
AU  - Alanbuki A
AD  - Department of Urology, University Hospitals Sussex NHS Foundation Trust, Princess 
      Royal Hospital, Haywards Heath, UK.
FAU - Larner, Tim
AU  - Larner T
AD  - Department of Urology, University Hospitals Sussex NHS Foundation Trust, Princess 
      Royal Hospital, Haywards Heath, UK.
LA  - eng
PT  - Journal Article
DEP - 20230802
PL  - Netherlands
TA  - Int Urol Nephrol
JT  - International urology and nephrology
JID - 0262521
SB  - IM
MH  - Male
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Robotic Surgical Procedures
MH  - Patient Education as Topic
MH  - Prostatectomy
MH  - Urologists
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Consent
OT  - Patient education
OT  - Robotic prostatectomy
EDAT- 2023/08/02 01:07
MHDA- 2023/10/09 06:42
CRDT- 2023/08/01 23:29
PHST- 2023/06/27 00:00 [received]
PHST- 2023/07/25 00:00 [accepted]
PHST- 2023/10/09 06:42 [medline]
PHST- 2023/08/02 01:07 [pubmed]
PHST- 2023/08/01 23:29 [entrez]
AID - 10.1007/s11255-023-03729-4 [pii]
AID - 10.1007/s11255-023-03729-4 [doi]
PST - ppublish
SO  - Int Urol Nephrol. 2023 Nov;55(11):2717-2732. doi: 10.1007/s11255-023-03729-4. 
      Epub 2023 Aug 2.

PMID- 37593450
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230823
IS  - 1664-0640 (Print)
IS  - 1664-0640 (Electronic)
IS  - 1664-0640 (Linking)
VI  - 14
DP  - 2023
TI  - Beyond human expertise: the promise and limitations of ChatGPT in suicide risk 
      assessment.
PG  - 1213141
LID - 10.3389/fpsyt.2023.1213141 [doi]
LID - 1213141
AB  - ChatGPT, an artificial intelligence language model developed by OpenAI, holds the 
      potential for contributing to the field of mental health. Nevertheless, although 
      ChatGPT theoretically shows promise, its clinical abilities in suicide 
      prevention, a significant mental health concern, have yet to be demonstrated. To 
      address this knowledge gap, this study aims to compare ChatGPT's assessments of 
      mental health indicators to those of mental health professionals in a 
      hypothetical case study that focuses on suicide risk assessment. Specifically, 
      ChatGPT was asked to evaluate a text vignette describing a hypothetical patient 
      with varying levels of perceived burdensomeness and thwarted belongingness. The 
      ChatGPT assessments were compared to the norms of mental health professionals. 
      The results indicated that ChatGPT rated the risk of suicide attempts lower than 
      did the mental health professionals in all conditions. Furthermore, ChatGPT rated 
      mental resilience lower than the norms in most conditions. These results imply 
      that gatekeepers, patients or even mental health professionals who rely on 
      ChatGPT for evaluating suicidal risk or as a complementary tool to improve 
      decision-making may receive an inaccurate assessment that underestimates the 
      actual suicide risk.
CI  - Copyright © 2023 Elyoseph and Levkovich.
FAU - Elyoseph, Zohar
AU  - Elyoseph Z
AD  - Department of Psychology and Educational Counseling, The Center for 
      Psychobiological Research, Max Stern Yezreel Valley College, Emek Yezreel, 
      Israel.
AD  - Department of Brain Sciences, Faculty of Medicine, Imperial College London, 
      London, United Kingdom.
FAU - Levkovich, Inbar
AU  - Levkovich I
AD  - Faculty of Graduate Studies, Oranim Academic College, Kiryat Tiv'on, Israel.
LA  - eng
PT  - Journal Article
DEP - 20230801
PL  - Switzerland
TA  - Front Psychiatry
JT  - Frontiers in psychiatry
JID - 101545006
PMC - PMC10427505
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - diagnosis
OT  - psychological assessment
OT  - risk assessment
OT  - suicide risk
OT  - text vignette
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.All claims expressed in this article are solely those of the 
      authors and do not necessarily represent those of their affiliated organizations, 
      or those of the publisher, the editors and the reviewers. Any product that may be 
      evaluated in this article, or claim that may be made by its manufacturer, is not 
      guaranteed or endorsed by the publisher.
EDAT- 2023/08/18 06:43
MHDA- 2023/08/18 06:44
PMCR- 2023/08/01
CRDT- 2023/08/18 03:54
PHST- 2023/04/28 00:00 [received]
PHST- 2023/07/19 00:00 [accepted]
PHST- 2023/08/18 06:44 [medline]
PHST- 2023/08/18 06:43 [pubmed]
PHST- 2023/08/18 03:54 [entrez]
PHST- 2023/08/01 00:00 [pmc-release]
AID - 10.3389/fpsyt.2023.1213141 [doi]
PST - epublish
SO  - Front Psychiatry. 2023 Aug 1;14:1213141. doi: 10.3389/fpsyt.2023.1213141. 
      eCollection 2023.

PMID- 37770637
OWN - NLM
STAT- Publisher
LR  - 20230928
IS  - 1432-5241 (Electronic)
IS  - 0364-216X (Linking)
DP  - 2023 Sep 28
TI  - Exploring the Potential of ChatGPT-4 in Responding to Common Questions About 
      Abdominoplasty: An AI-Based Case Study of a Plastic Surgery Consultation.
LID - 10.1007/s00266-023-03660-0 [doi]
AB  - BACKGROUND: With the increasing integration of artificial intelligence (AI) in 
      health care, AI chatbots like ChatGPT-4 are being used to deliver health 
      information. OBJECTIVES: This study aimed to assess the capability of ChatGPT-4 
      in answering common questions related to abdominoplasty, evaluating its potential 
      as an adjunctive tool in patient education and preoperative consultation. 
      METHODS: A variety of common questions about abdominoplasty were submitted to 
      ChatGPT-4. These questions were sourced from a question list provided by the 
      American Society of Plastic Surgery to ensure their relevance and 
      comprehensiveness. An experienced plastic surgeon meticulously evaluated the 
      responses generated by ChatGPT-4 in terms of informational depth, response 
      articulation, and competency to determine the proficiency of the AI in providing 
      patient-centered information. RESULTS: The study showed that ChatGPT-4 can give 
      clear answers, making it useful for answering common queries. However, it 
      struggled with personalized advice and sometimes provided incorrect or outdated 
      references. Overall, ChatGPT-4 can effectively share abdominoplasty information, 
      which may help patients better understand the procedure. Despite these positive 
      findings, the AI needs more refinement, especially in providing personalized and 
      accurate information, to fully meet patient education needs in plastic surgery. 
      CONCLUSIONS: Although ChatGPT-4 shows promise as a resource for patient 
      education, continuous improvements and rigorous checks are essential for its 
      beneficial integration into healthcare settings. The study emphasizes the need 
      for further research, particularly focused on improving the personalization and 
      accuracy of AI responses. LEVEL OF EVIDENCE V: This journal requires that authors 
      assign a level of evidence to each article. For a full description of these 
      Evidence-Based Medicine ratings, please refer to the Table of Contents or the 
      online Instructions to Authors www.springer.com/00266 .
CI  - © 2023. Springer Science+Business Media, LLC, part of Springer Nature and 
      International Society of Aesthetic Plastic Surgery.
FAU - Li, Wenbo
AU  - Li W
AD  - Department of Nursing, Jinzhou Medical University, Jinzhou, 121001, China.
FAU - Chen, Junjiang
AU  - Chen J
AD  - Department of Burn Plastic and Medical Aesthetic Surgery, The First Affiliated 
      Hospital, Jinzhou Medical University, Jinzhou, China.
FAU - Chen, Fengmin
AU  - Chen F
AD  - Department of Colorectal Surgery, The First Affiliated Hospital, Jinzhou Medical 
      University, Jinzhou, China.
FAU - Liang, Jiaqing
AU  - Liang J
AD  - Department of Nursing, Jinzhou Medical University, Jinzhou, 121001, China.
FAU - Yu, Hongyu
AU  - Yu H
AD  - Department of Nursing, Jinzhou Medical University, Jinzhou, 121001, China. 
      15840040053@163.com.
LA  - eng
PT  - Journal Article
DEP - 20230928
PL  - United States
TA  - Aesthetic Plast Surg
JT  - Aesthetic plastic surgery
JID - 7701756
SB  - IM
OTO - NOTNLM
OT  - Abdominoplasty
OT  - Artificial intelligence
OT  - ChatGPT
OT  - ChatGPT-4
OT  - Chatbot
EDAT- 2023/09/29 00:42
MHDA- 2023/09/29 00:42
CRDT- 2023/09/28 23:35
PHST- 2023/07/12 00:00 [received]
PHST- 2023/09/06 00:00 [accepted]
PHST- 2023/09/29 00:42 [medline]
PHST- 2023/09/29 00:42 [pubmed]
PHST- 2023/09/28 23:35 [entrez]
AID - 10.1007/s00266-023-03660-0 [pii]
AID - 10.1007/s00266-023-03660-0 [doi]
PST - aheadofprint
SO  - Aesthetic Plast Surg. 2023 Sep 28. doi: 10.1007/s00266-023-03660-0.

PMID- 38356365
OWN - NLM
STAT- Publisher
LR  - 20240215
IS  - 1930-7837 (Electronic)
IS  - 0022-0337 (Linking)
DP  - 2024 Feb 15
TI  - Artificial intelligence: ChatGPT as a disruptive didactic strategy in dental 
      education.
LID - 10.1002/jdd.13485 [doi]
AB  - PURPOSE: To evaluate the influence of ChatGPT on academic tasks performed by 
      undergraduate dental students. METHOD: Fifty-five participants completed 
      scientific writing assignments. First, ChatGPT was utilized; subsequently, a 
      conventional method involving the search of scientific articles was employed. 
      Each task was preceded by a 30-min training session. The assignments were 
      reviewed by professors, and an anonymous questionnaire was administered to the 
      students regarding the usefulness of ChatGPT. Data were analyzed by Mann-Whitney 
      U-test. RESULTS: Final scores and scores for the criteria of utilization of 
      evidence, evaluation of arguments, and generation of alternatives achieved higher 
      values through the traditional method than with ChatGPT (p&nbsp;=&nbsp;0.019, 0.042, 0.017, 
      and &lt;0.001, respectively). No differences were found between the two methods for 
      the remaining criteria (p&nbsp;&gt;&nbsp;0.05). A total of 64.29% of the students found 
      ChatGPT useful, 33.33% found it very useful, and 3.38% not very useful. Regarding 
      its application in further academic activities, 54.76% considered it useful, 
      40.48% found it very useful, and 4.76% not very useful. A total of 61.90% of the 
      participants indicated that ChatGPT contributed to over 25% of their 
      productivity, while 11.9% perceived it contributed to less than 15%. Concerning 
      the relevance of having known ChatGPT for academic tasks, 50% found it opportune, 
      45.24% found it very opportune, 2.38% were unsure, and the same percentage 
      thought it is inopportune. All students provided positive feedback. CONCLUSION: 
      Dental students highly valued the experience of using ChatGPT for academic tasks. 
      Nonetheless, the traditional method of searching for scientific articles yield 
      higher scores.
CI  - © 2024 American Dental Education Association.
FAU - Saravia-Rojas, Miguel Ángel
AU  - Saravia-Rojas MÁ
AD  - School of Dentistry, University of Cayetano Heredia, Lima, Peru.
FAU - Camarena-Fonseca, Alexandra Rosy
AU  - Camarena-Fonseca AR
AD  - School of Dentistry, University of Cayetano Heredia, Lima, Peru.
FAU - León-Manco, Roberto
AU  - León-Manco R
AD  - School of Dentistry, University of Cayetano Heredia, Lima, Peru.
FAU - Geng-Vivanco, Rocio
AU  - Geng-Vivanco R
AUID- ORCID: 0000-0003-0584-9401
AD  - Department of Dental Materials and Prosthodontics, Ribeirão Preto School of 
      Dentistry, University of São Paulo, Ribeirão Preto, SP, Brazil.
LA  - eng
PT  - Journal Article
DEP - 20240215
PL  - United States
TA  - J Dent Educ
JT  - Journal of dental education
JID - 8000150
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - dental education
EDAT- 2024/02/15 06:42
MHDA- 2024/02/15 06:42
CRDT- 2024/02/15 03:16
PHST- 2023/12/22 00:00 [revised]
PHST- 2023/10/09 00:00 [received]
PHST- 2024/01/20 00:00 [accepted]
PHST- 2024/02/15 06:42 [medline]
PHST- 2024/02/15 06:42 [pubmed]
PHST- 2024/02/15 03:16 [entrez]
AID - 10.1002/jdd.13485 [doi]
PST - aheadofprint
SO  - J Dent Educ. 2024 Feb 15. doi: 10.1002/jdd.13485.

PMID- 37417886
OWN - NLM
STAT- MEDLINE
DCOM- 20231116
LR  - 20240222
IS  - 1524-4040 (Electronic)
IS  - 0148-396X (Linking)
VI  - 93
IP  - 6
DP  - 2023 Dec 1
TI  - Exploring the Intersection of Artificial Intelligence and Neurosurgery: Let us be 
      Cautious With ChatGPT.
PG  - 1366-1373
LID - 10.1227/neu.0000000000002598 [doi]
AB  - BACKGROUND AND OBJECTIVES: ChatGPT is a novel natural language processing 
      artificial intelligence (AI) module where users enter any question or command and 
      receive a single text response within seconds. As AI becomes more accessible, 
      patients may begin to use it as a resource for medical information and advice. 
      This is the first study to assess the neurosurgical information that is provided 
      by ChatGPT. METHODS: ChatGPT was accessed in January 2023, and prompts were 
      created requesting treatment information for 40 common neurosurgical conditions. 
      Quantitative characteristics were collected, and four independent reviewers 
      evaluated the responses using the DISCERN tool. Prompts were compared against the 
      American Association of Neurological Surgeons (AANS) "For Patients" webpages. 
      RESULTS: ChatGPT returned text organized in paragraph and bullet-point lists. 
      ChatGPT responses were shorter (mean 270.1 ± 41.9 words; AANS webpage 1634.5 ± 
      891.3 words) but more difficult to read (mean Flesch-Kincaid score 32.4 ± 6.7; 
      AANS webpage 37.1 ± 7.0). ChatGPT output was found to be of "fair" quality (mean 
      DISCERN score 44.2 ± 4.1) and significantly inferior to the "good" overall 
      quality of the AANS patient website (57.7 ± 4.4). ChatGPT was poor in providing 
      references/resources and describing treatment risks. ChatGPT provided 177 
      references, of which 68.9% were inaccurate and 33.9% were completely falsified. 
      CONCLUSION: ChatGPT is an adaptive resource for neurosurgical information but has 
      shortcomings that limit the quality of its responses, including poor readability, 
      lack of references, and failure to fully describe treatment options. Hence, 
      patients and providers should remain wary of the provided content. As ChatGPT or 
      other AI search algorithms continue to improve, they may become a reliable 
      alternative for medical information.
CI  - Copyright © Congress of Neurological Surgeons 2023. All rights reserved.
FAU - Mishra, Akash
AU  - Mishra A
AUID- ORCID: 0000-0002-5617-9009
AD  - Department of Neurological Surgery, Donald and Barbara Zucker School of Medicine 
      at Hofstra/Northwell, Lake Success , New York , USA.
FAU - Begley, Sabrina L
AU  - Begley SL
FAU - Chen, Adrian
AU  - Chen A
FAU - Rob, Moontahinaz
AU  - Rob M
FAU - Pelcher, Isabelle
AU  - Pelcher I
FAU - Ward, Max
AU  - Ward M
FAU - Schulder, Michael
AU  - Schulder M
LA  - eng
PT  - Journal Article
DEP - 20230707
PL  - United States
TA  - Neurosurgery
JT  - Neurosurgery
JID - 7802914
SB  - IM
MH  - Humans
MH  - *Neurosurgery
MH  - Artificial Intelligence
MH  - Neurosurgical Procedures
MH  - Neurosurgeons
MH  - Algorithms
EDAT- 2023/07/07 13:04
MHDA- 2023/11/16 06:45
CRDT- 2023/07/07 10:02
PHST- 2023/02/23 00:00 [received]
PHST- 2023/05/14 00:00 [accepted]
PHST- 2023/11/16 06:45 [medline]
PHST- 2023/07/07 13:04 [pubmed]
PHST- 2023/07/07 10:02 [entrez]
AID - 00006123-202312000-00019 [pii]
AID - 10.1227/neu.0000000000002598 [doi]
PST - ppublish
SO  - Neurosurgery. 2023 Dec 1;93(6):1366-1373. doi: 10.1227/neu.0000000000002598. Epub 
      2023 Jul 7.

PMID- 37745352
OWN - NLM
STAT- Publisher
LR  - 20230926
DP  - 2023 Sep 7
TI  - Fact Check: Assessing the Response of ChatGPT to Alzheimer's Disease Statements 
      with Varying Degrees of Misinformation.
LID - 2023.09.04.23294917 [pii]
LID - 10.1101/2023.09.04.23294917 [doi]
AB  - BACKGROUND: There are many myths regarding Alzheimer's disease (AD) that have 
      been circulated on the Internet, each exhibiting varying degrees of accuracy, 
      inaccuracy, and misinformation. Large language models such as ChatGPT, may be a 
      useful tool to help assess these myths for veracity and inaccuracy. However, they 
      can induce misinformation as well. The objective of this study is to assess 
      ChatGPT's ability to identify and address AD myths with reliable information. 
      METHODS: We conducted a cross-sectional study of clinicians' evaluation of 
      ChatGPT (GPT 4.0)'s responses to 20 selected AD myths. We prompted ChatGPT to 
      express its opinion on each myth and then requested it to rephrase its 
      explanation using a simplified language that could be more readily understood by 
      individuals with a middle school education. We implemented a survey using Redcap 
      to determine the degree to which clinicians agreed with the accuracy of each 
      ChatGPT's explanation and the degree to which the simplified rewriting was 
      readable and retained the message of the original. We also collected their 
      explanation on any disagreement with ChatGPT's responses. We used five 
      Likert-type scale with a score ranging from -2 to 2 to quantify clinicians' 
      agreement in each aspect of the evaluation. RESULTS: The clinicians (n=11) were 
      generally satisfied with ChatGPT's explanations, with a mean (SD) score of 
      1.0(±0.3) across the 20 myths. While ChatGPT correctly identified that all the 20 
      myths were inaccurate, some clinicians disagreed with its explanations on 7 of 
      the myths.Overall, 9 of the 11 professionals either agreed or strongly agreed 
      that ChatGPT has the potential to provide meaningful explanations of certain 
      myths. CONCLUSIONS: The majority of surveyed healthcare professionals 
      acknowledged the potential value of ChatGPT in mitigating AD misinformation. 
      However, the need for more refined and detailed explanations of the disease's 
      mechanisms and treatments was highlighted.
FAU - Huang, Sean S
AU  - Huang SS
AD  - Department of Medicine, Division of Geriatrics, Vanderbilt University Medical 
      Center, Nashville, TN, USA.
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, TN, USA.
FAU - Song, Qingyuan
AU  - Song Q
AD  - Department of Computer Science, Vanderbilt University, Nashville, TN, USA.
FAU - Beiting, Kimberly J
AU  - Beiting KJ
AD  - Department of Medicine, Division of Geriatrics, Vanderbilt University Medical 
      Center, Nashville, TN, USA.
FAU - Duggan, Maria C
AU  - Duggan MC
AD  - Department of Medicine, Division of Geriatrics, Vanderbilt University Medical 
      Center, Nashville, TN, USA.
AD  - Geriatric Research Education and Clinical Center (GRECC), Department of Veteran 
      Affairs, Tennessee Valley Healthcare System, Nashville, TN, USA.
FAU - Hines, Kristin
AU  - Hines K
AD  - Department of Medicine, Division of Geriatrics, Vanderbilt University Medical 
      Center, Nashville, TN, USA.
FAU - Murff, Harvey
AU  - Murff H
AD  - Department of Medicine, Division of Geriatrics, Vanderbilt University Medical 
      Center, Nashville, TN, USA.
FAU - Leung, Vania
AU  - Leung V
AD  - Department of Academic Internal Medicine and Geriatrics, University of Illinois 
      at Chicago, Chicago, IL, USA.
FAU - Powers, James
AU  - Powers J
AD  - Department of Medicine, Division of Geriatrics, Vanderbilt University Medical 
      Center, Nashville, TN, USA.
AD  - Geriatric Research Education and Clinical Center (GRECC), Department of Veteran 
      Affairs, Tennessee Valley Healthcare System, Nashville, TN, USA.
FAU - Harvey, T S
AU  - Harvey TS
AD  - Department of Anthropology, Vanderbilt University, Nashville, TN, USA.
FAU - Malin, Bradley
AU  - Malin B
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, TN, USA.
AD  - Department of Computer Science, Vanderbilt University, Nashville, TN, USA.
AD  - Department of Biostatistics, Vanderbilt University Medical Center, Nashville, TN, 
      USA.
FAU - Yin, Zhijun
AU  - Yin Z
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, TN, USA.
AD  - Department of Computer Science, Vanderbilt University, Nashville, TN, USA.
LA  - eng
PT  - Preprint
DEP - 20230907
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
PMC - PMC10515299
OTO - NOTNLM
OT  - Alzheimer’s Disease
OT  - ChatGPT
OT  - Large Language Models
OT  - Misinformation
COIS- Conflict of Interest: There are no conflicts of interest to disclose.
EDAT- 2023/09/25 06:42
MHDA- 2023/09/25 06:42
PMCR- 2023/09/22
CRDT- 2023/09/25 05:00
PHST- 2023/09/25 06:42 [medline]
PHST- 2023/09/25 06:42 [pubmed]
PHST- 2023/09/25 05:00 [entrez]
PHST- 2023/09/22 00:00 [pmc-release]
AID - 2023.09.04.23294917 [pii]
AID - 10.1101/2023.09.04.23294917 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2023 Sep 7:2023.09.04.23294917. doi: 
      10.1101/2023.09.04.23294917.

PMID- 38566254
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240402
IS  - 2234-0726 (Print)
IS  - 2234-0726 (Linking)
VI  - 36
IP  - 1
DP  - 2024 Apr 2
TI  - Evaluating the accuracy and relevance of ChatGPT responses to frequently asked 
      questions regarding total knee replacement.
PG  - 15
LID - 10.1186/s43019-024-00218-5 [doi]
AB  - BACKGROUND: Chat Generative Pretrained Transformer (ChatGPT), a generative 
      artificial intelligence chatbot, may have broad applications in healthcare 
      delivery and patient education due to its ability to provide human-like responses 
      to a wide range of patient queries. However, there is limited evidence regarding 
      its ability to provide reliable and useful information on orthopaedic procedures. 
      This study seeks to evaluate the accuracy and relevance of responses provided by 
      ChatGPT to frequently asked questions (FAQs) regarding total knee replacement 
      (TKR). METHODS: A list of 50 clinically-relevant FAQs regarding TKR was collated. 
      Each question was individually entered as a prompt to ChatGPT (version 3.5), and 
      the first response generated was recorded. Responses were then reviewed by two 
      independent orthopaedic surgeons and graded on a Likert scale for their factual 
      accuracy and relevance. These responses were then classified into accurate versus 
      inaccurate and relevant versus irrelevant responses using preset thresholds on 
      the Likert scale. RESULTS: Most responses were accurate, while all responses were 
      relevant. Of the 50 FAQs, 44/50 (88%) of ChatGPT responses were classified as 
      accurate, achieving a mean Likert grade of 4.6/5 for factual accuracy. On the 
      other hand, 50/50 (100%) of responses were classified as relevant, achieving a 
      mean Likert grade of 4.9/5 for relevance. CONCLUSION: ChatGPT performed well in 
      providing accurate and relevant responses to FAQs regarding TKR, demonstrating 
      great potential as a tool for patient education. However, it is not infallible 
      and can occasionally provide inaccurate medical information. Patients and 
      clinicians intending to utilize this technology should be mindful of its 
      limitations and ensure adequate supervision and verification of information 
      provided.
CI  - © 2024. The Author(s).
FAU - Zhang, Siyuan
AU  - Zhang S
AUID- ORCID: 0000-0002-7622-3388
AD  - Department of Orthopaedic Surgery, National University Health System, Level 11, 
      NUHS Tower Block, 1E Kent Ridge Road, Singapore, 119228, Singapore. 
      siyuan.zhang@mohh.com.sg.
FAU - Liau, Zi Qiang Glen
AU  - Liau ZQG
AD  - Department of Orthopaedic Surgery, National University Health System, Level 11, 
      NUHS Tower Block, 1E Kent Ridge Road, Singapore, 119228, Singapore.
FAU - Tan, Kian Loong Melvin
AU  - Tan KLM
AD  - Department of Orthopaedic Surgery, National University Health System, Level 11, 
      NUHS Tower Block, 1E Kent Ridge Road, Singapore, 119228, Singapore.
FAU - Chua, Wei Liang
AU  - Chua WL
AD  - Department of Orthopaedic Surgery, National University Health System, Level 11, 
      NUHS Tower Block, 1E Kent Ridge Road, Singapore, 119228, Singapore.
LA  - eng
PT  - Journal Article
DEP - 20240402
PL  - England
TA  - Knee Surg Relat Res
JT  - Knee surgery &amp; related research
JID - 101575761
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Chatbot
OT  - Large language model
OT  - Total knee arthroplasty
OT  - Total knee replacement
EDAT- 2024/04/03 00:44
MHDA- 2024/04/03 00:45
CRDT- 2024/04/02 23:55
PHST- 2024/01/02 00:00 [received]
PHST- 2024/03/12 00:00 [accepted]
PHST- 2024/04/03 00:45 [medline]
PHST- 2024/04/03 00:44 [pubmed]
PHST- 2024/04/02 23:55 [entrez]
AID - 10.1186/s43019-024-00218-5 [pii]
AID - 10.1186/s43019-024-00218-5 [doi]
PST - epublish
SO  - Knee Surg Relat Res. 2024 Apr 2;36(1):15. doi: 10.1186/s43019-024-00218-5.

PMID- 38438722
OWN - NLM
STAT- Publisher
LR  - 20240308
IS  - 1348-4214 (Electronic)
IS  - 0916-9636 (Linking)
DP  - 2024 Mar 4
TI  - Comparing ChatGPT and Bing, in response to the Home Blood Pressure Monitoring 
      (HBPM) knowledge checklist.
LID - 10.1038/s41440-024-01624-8 [doi]
AB  - High blood pressure is one of the major public health problems that is prevalent 
      worldwide. Due to the rapid increase in the number of users of artificial 
      intelligence tools such as ChatGPT and Bing, it is expected that patients will 
      use these tools as a source of information to obtain information about high blood 
      pressure. The purpose of this study is to check the accuracy, completeness, and 
      reproducibility of answers provided by ChatGPT and Bing to the knowledge 
      questionnaire of blood pressure control at home. In this study, ChatGPT and 
      Bing's responses to the HBPM 10-question knowledge checklist on blood pressure 
      measurement were independently reviewed by three cardiologists. The mean accuracy 
      rating of ChatGPT was 5.96 (SD = 0.17) indicating the responses were highly 
      accurate overall, with the vast majority receiving the top score. The mean 
      accuracy and completeness of ChatGPT were 5.96 (SD = 0.17) and 2.93 (SD = 0.25) 
      and in Bing were 5.31 (SD = 0.67), and 2.13 (SD = 0.53) Respectively. Due to the 
      expansion of artificial intelligence applications, patients can use new tools 
      such as ChatGPT and Bing to search for information and at the same time can trust 
      the information obtained. we found that the answers obtained from ChatGPT are 
      reliable and valuable for patients, while Bing is also considered a powerful 
      tool, it has more limitations than ChatGPT, and the answers should be interpreted 
      with caution.
CI  - © 2024. The Author(s), under exclusive licence to The Japanese Society of 
      Hypertension.
FAU - Niko, Michaeel Motaghi
AU  - Niko MM
AD  - Student Research Committee, Fasa University of Medical Sciences, Fasa, Iran.
FAU - Karbasi, Zahra
AU  - Karbasi Z
AUID- ORCID: 0000-0002-7658-4124
AD  - Department of Health Information Sciences, Faculty of Management and Medical 
      Information Sciences, Kerman University of Medical Sciences, Kerman, Iran.
FAU - Kazemi, Maryam
AU  - Kazemi M
AD  - Noncommunicable Diseases Research Center, Fasa University of Medical Sciences, 
      Fasa, Iran.
FAU - Zahmatkeshan, Maryam
AU  - Zahmatkeshan M
AUID- ORCID: 0000-0003-4090-391X
AD  - Noncommunicable Diseases Research Center, Fasa University of Medical Sciences, 
      Fasa, Iran. m.zahmatkeshan@fums.ac.ir.
AD  - School of Allied Medical Sciences, Fasa University of Medical Sciences, Fasa, 
      Iran. m.zahmatkeshan@fums.ac.ir.
LA  - eng
PT  - Journal Article
DEP - 20240304
PL  - England
TA  - Hypertens Res
JT  - Hypertension research : official journal of the Japanese Society of Hypertension
JID - 9307690
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Bing
OT  - ChatGPT
OT  - HBPM
OT  - blood pressure
EDAT- 2024/03/05 00:45
MHDA- 2024/03/05 00:45
CRDT- 2024/03/04 23:36
PHST- 2023/11/29 00:00 [received]
PHST- 2024/01/27 00:00 [accepted]
PHST- 2024/01/23 00:00 [revised]
PHST- 2024/03/05 00:45 [pubmed]
PHST- 2024/03/05 00:45 [medline]
PHST- 2024/03/04 23:36 [entrez]
AID - 10.1038/s41440-024-01624-8 [pii]
AID - 10.1038/s41440-024-01624-8 [doi]
PST - aheadofprint
SO  - Hypertens Res. 2024 Mar 4. doi: 10.1038/s41440-024-01624-8.

PMID- 38242382
OWN - NLM
STAT- MEDLINE
DCOM- 20240205
LR  - 20240205
IS  - 1095-9130 (Electronic)
IS  - 1046-2023 (Linking)
VI  - 222
DP  - 2024 Feb
TI  - Comprehensive evaluation of molecule property prediction with ChatGPT.
PG  - 133-141
LID - S1046-2023(24)00023-9 [pii]
LID - 10.1016/j.ymeth.2024.01.004 [doi]
AB  - The versatility of ChatGPT in performing a diverse range of tasks has elicited 
      considerable interest on its potential applications within professional fields. 
      Taking drug discovery as a testbed, this paper provides a comprehensive 
      evaluation of ChatGPT's ability on molecule property prediction. The study 
      focuses on three aspects: 1) Effects of different prompt settings, where we 
      investigate the impact of varying prompts on the prediction outcomes of ChatGPT; 
      2) Comprehensive evaluation on molecule property prediction, where we conduct a 
      comprehensive evaluation on 53 ADMET-related endpoints; 3) Analysis of ChatGPT's 
      potential and limitations, where we make comparisons with models tailored for 
      molecule property prediction, thus gaining a more accurate understanding of 
      ChatGPT's capabilities and limitations in this area. Through comprehensive 
      evaluation, we find that 1) With appropriate prompt settings, ChatGPT can attain 
      satisfactory prediction outcomes that are competitive with specialized models 
      designed for those tasks. 2) Prompt settings significantly affect ChatGPT's 
      performance. Among all prompt settings, the strategy of selecting examples in 
      few-shot has the greatest impact on results. Scaffold sampling greatly 
      outperforms random sampling. 3) The capacity of ChatGPT to accomplish 
      high-precision predictions is significantly influenced by the quality of examples 
      provided, which may constrain its practical applicability in real-world 
      scenarios. This work highlights ChatGPT's potential and limitations on molecule 
      property prediction, which we hope can inspire future design and evaluation of 
      Large Language Models within scientific domains.
CI  - Copyright © 2024 Elsevier Inc. All rights reserved.
FAU - Cai, Xibao
AU  - Cai X
AD  - Department of Computer Science, Hunan University, China. Electronic address: 
      dalecai@hnu.edu.cn.
FAU - Lai, Houtim
AU  - Lai H
AD  - Tencent AI Lab, China.
FAU - Wang, Xing
AU  - Wang X
AD  - Tencent AI Lab, China.
FAU - Wang, Longyue
AU  - Wang L
AD  - Tencent AI Lab, China. Electronic address: vincentwang0229@gmail.com.
FAU - Liu, Wei
AU  - Liu W
AD  - Tencent AI Lab, China.
FAU - Wang, Yijun
AU  - Wang Y
AD  - Department of Computer Science, Hunan University, China. Electronic address: 
      wyjun@hnu.edu.cn.
FAU - Wang, Zixu
AU  - Wang Z
AD  - University of Tsukuba, Japan.
FAU - Cao, Dongsheng
AU  - Cao D
AD  - Xiangya School of Pharmaceutical Sciences, Central South University, China.
FAU - Zeng, Xiangxiang
AU  - Zeng X
AD  - Department of Computer Science, Hunan University, China.
LA  - eng
PT  - Journal Article
DEP - 20240117
PL  - United States
TA  - Methods
JT  - Methods (San Diego, Calif.)
JID - 9426302
SB  - IM
MH  - *Drug Discovery
MH  - *Research Design
OTO - NOTNLM
OT  - ChatGPT
OT  - Evaluation
OT  - Few-shot
OT  - Molecule property prediction
OT  - Prompt
COIS- Declaration of Competing Interest The authors declare no competing interests.
EDAT- 2024/01/20 05:42
MHDA- 2024/02/05 06:43
CRDT- 2024/01/19 19:18
PHST- 2023/09/21 00:00 [received]
PHST- 2023/12/23 00:00 [revised]
PHST- 2024/01/13 00:00 [accepted]
PHST- 2024/02/05 06:43 [medline]
PHST- 2024/01/20 05:42 [pubmed]
PHST- 2024/01/19 19:18 [entrez]
AID - S1046-2023(24)00023-9 [pii]
AID - 10.1016/j.ymeth.2024.01.004 [doi]
PST - ppublish
SO  - Methods. 2024 Feb;222:133-141. doi: 10.1016/j.ymeth.2024.01.004. Epub 2024 Jan 
      17.

PMID- 38428198
OWN - NLM
STAT- Publisher
LR  - 20240301
IS  - 1532-2831 (Electronic)
IS  - 1078-8174 (Linking)
VI  - 30
IP  - 3
DP  - 2024 Feb 29
TI  - Harnessing ChatGPT dialogues to address claustrophobia in MRI - A radiographers' 
      education perspective.
PG  - 737-744
LID - S1078-8174(24)00052-X [pii]
LID - 10.1016/j.radi.2024.02.015 [doi]
AB  - INTRODUCTION: The healthcare sector invests significantly in communication skills 
      training, but not always with satisfactory results. Recently, generative Large 
      Language Models, have shown promising results in medical education. This study 
      aims to use ChatGPT to simulate radiographer-patient conversations about the 
      critical moment of claustrophobia management during MRI, exploring how Artificial 
      Intelligence can improve radiographers' communication skills. METHODS: This study 
      exploits specifically designed prompts on ChatGPT-3.5 and ChatGPT-4 to generate 
      simulated conversations between virtual claustrophobic patients and six 
      radiographers with varying levels of work experience focusing on their 
      differences in model size and language generation capabilities. Success rates and 
      responses were analysed. The methods of radiographers in convincing virtual 
      patients to undergo MRI despite claustrophobia were also evaluated. RESULTS: A 
      total of 60 simulations were conducted, achieving a success rate of 96.7% 
      (58/60). ChatGPT-3.5 exhibited errors in 40% (12/30) of the simulations, while 
      ChatGPT-4 showed no errors. In terms of radiographers' communication during the 
      simulations, out of 164 responses, 70.2% (115/164) were categorized as 
      "Supportive Instructions," followed by "Music Therapy" at 18.3% (30/164). Experts 
      mainly used "Supportive Instructions" (82.2%, 51/62) and "Breathing Techniques" 
      (9.7%, 6/62). Intermediate participants favoured "Music Therapy" (26%, 13/50), 
      while Beginner participants frequently utilized "Mild Sedation" (15.4%, 8/52). 
      CONCLUSION: The simulation of clinical scenarios via ChatGPT proves valuable in 
      assessing and testing radiographers' communication skills, especially in managing 
      claustrophobic patients during MRI. This pilot study highlights the potential of 
      ChatGPT in preclinical training, recognizing different training needs at 
      different levels of professional experience. IMPLICATIONS FOR PRACTICE: This 
      study is relevant in radiography practice, where AI is increasingly widespread, 
      as it explores a new way to improve the training of radiographers.
CI  - Copyright © 2024 The Author(s). Published by Elsevier Ltd.. All rights reserved.
FAU - Bonfitto, G R
AU  - Bonfitto GR
AD  - Department of Information Engineering, University of Brescia, Via Branze 38, 
      25123 Brescia, Italy; IRCCS Ospedale San Raffaele, Via Olgettina 60, 20132 
      Milano, Italy. Electronic address: giuseppe.bonfitto@unibs.it.
FAU - Roletto, A
AU  - Roletto A
AD  - Department of Mechanical and Industrial Engineering, Università degli Studi di 
      Brescia, Via Branze 38, 25123 Brescia, Italy; IRCCS Ospedale San Raffaele, Via 
      Olgettina 60, 20132 Milano, Italy. Electronic address: andrea.roletto@unibs.it.
FAU - Savardi, M
AU  - Savardi M
AD  - Department of Medical and Surgical Specialties, Radiological Sciences, and Public 
      Health, University of Brescia, Viale Europa 11, 25121, Brescia, Italy. Electronic 
      address: mattia.savardi@unibs.it.
FAU - Fasulo, S V
AU  - Fasulo SV
AD  - IRCCS Ospedale San Raffaele, Via Olgettina 60, 20132 Milano, Italy. Electronic 
      address: fasulo.simone@hsr.it.
FAU - Catania, D
AU  - Catania D
AD  - IRCCS Ospedale San Raffaele, Via Olgettina 60, 20132 Milano, Italy. Electronic 
      address: catania.diego@hsr.it.
FAU - Signoroni, A
AU  - Signoroni A
AD  - Department of Medical and Surgical Specialties, Radiological Sciences, and Public 
      Health, University of Brescia, Viale Europa 11, 25121, Brescia, Italy. Electronic 
      address: alberto.signoroni@unibs.it.
LA  - eng
PT  - Journal Article
DEP - 20240229
PL  - Netherlands
TA  - Radiography (Lond)
JT  - Radiography (London, England : 1995)
JID - 9604102
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - Claustrophobia
OT  - Generative AI
OT  - Magnetic resonance imaging
OT  - Simulation: radiographer
COIS- Conflict of interest statement All authors of this manuscript declare no 
      relationships with any companies whose products or services may be related to the 
      subject matter of the article.
EDAT- 2024/03/02 10:43
MHDA- 2024/03/02 10:43
CRDT- 2024/03/01 18:07
PHST- 2023/12/29 00:00 [received]
PHST- 2024/02/19 00:00 [revised]
PHST- 2024/02/20 00:00 [accepted]
PHST- 2024/03/02 10:43 [medline]
PHST- 2024/03/02 10:43 [pubmed]
PHST- 2024/03/01 18:07 [entrez]
AID - S1078-8174(24)00052-X [pii]
AID - 10.1016/j.radi.2024.02.015 [doi]
PST - aheadofprint
SO  - Radiography (Lond). 2024 Feb 29;30(3):737-744. doi: 10.1016/j.radi.2024.02.015.

PMID- 38527823
OWN - NLM
STAT- MEDLINE
DCOM- 20240327
LR  - 20240327
IS  - 1544-1717 (Electronic)
IS  - 1544-1709 (Linking)
VI  - 22
IP  - 2
DP  - 2024 Mar-Apr
TI  - Quality, Accuracy, and Bias in ChatGPT-Based Summarization of Medical Abstracts.
PG  - 113-120
LID - 10.1370/afm.3075 [doi]
AB  - PURPOSE: Worldwide clinical knowledge is expanding rapidly, but physicians have 
      sparse time to review scientific literature. Large language models (eg, Chat 
      Generative Pretrained Transformer [ChatGPT]), might help summarize and prioritize 
      research articles to review. However, large language models sometimes 
      "hallucinate" incorrect information. METHODS: We evaluated ChatGPT's ability to 
      summarize 140 peer-reviewed abstracts from 14 journals. Physicians rated the 
      quality, accuracy, and bias of the ChatGPT summaries. We also compared human 
      ratings of relevance to various areas of medicine to ChatGPT relevance ratings. 
      RESULTS: ChatGPT produced summaries that were 70% shorter (mean abstract length 
      of 2,438 characters decreased to 739 characters). Summaries were nevertheless 
      rated as high quality (median score 90, interquartile range [IQR] 87.0-92.5; 
      scale 0-100), high accuracy (median 92.5, IQR 89.0-95.0), and low bias (median 0, 
      IQR 0-7.5). Serious inaccuracies and hallucinations were uncommon. Classification 
      of the relevance of entire journals to various fields of medicine closely 
      mirrored physician classifications (nonlinear standard error of the regression 
      [SER] 8.6 on a scale of 0-100). However, relevance classification for individual 
      articles was much more modest (SER 22.3). CONCLUSIONS: Summaries generated by 
      ChatGPT were 70% shorter than mean abstract length and were characterized by high 
      quality, high accuracy, and low bias. Conversely, ChatGPT had modest ability to 
      classify the relevance of articles to medical specialties. We suggest that 
      ChatGPT can help family physicians accelerate review of the scientific literature 
      and have developed software (pyJournalWatch) to support this application. 
      Life-critical medical decisions should remain based on full, critical, and 
      thoughtful evaluation of the full text of research articles in context with 
      clinical guidelines.
CI  - © 2024 Annals of Family Medicine, Inc.
FAU - Hake, Joel
AU  - Hake J
AD  - Department of Family Medicine and Community Health, University of Kansas Medical 
      Center, Kansas City, Kansas.
FAU - Crowley, Miles
AU  - Crowley M
AD  - Department of Family Medicine and Community Health, University of Kansas Medical 
      Center, Kansas City, Kansas.
FAU - Coy, Allison
AU  - Coy A
AD  - Department of Family Medicine and Community Health, University of Kansas Medical 
      Center, Kansas City, Kansas.
FAU - Shanks, Denton
AU  - Shanks D
AD  - Department of Family Medicine and Community Health, University of Kansas Medical 
      Center, Kansas City, Kansas.
FAU - Eoff, Aundria
AU  - Eoff A
AD  - Department of Family Medicine and Community Health, University of Kansas Medical 
      Center, Kansas City, Kansas.
FAU - Kirmer-Voss, Kalee
AU  - Kirmer-Voss K
AD  - Department of Family Medicine and Community Health, University of Kansas Medical 
      Center, Kansas City, Kansas.
FAU - Dhanda, Gurpreet
AU  - Dhanda G
AD  - Department of Family Medicine and Community Health, University of Kansas Medical 
      Center, Kansas City, Kansas.
FAU - Parente, Daniel J
AU  - Parente DJ
AD  - Department of Family Medicine and Community Health, University of Kansas Medical 
      Center, Kansas City, Kansas dparente@kumc.edu.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Ann Fam Med
JT  - Annals of family medicine
JID - 101167762
SB  - IM
MH  - Humans
MH  - *Medicine
MH  - Physicians, Family
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - bias
OT  - critical assessment of scientific literature
OT  - large language models
OT  - primary care research
OT  - text analysis
OT  - text mining
EDAT- 2024/03/26 00:42
MHDA- 2024/03/27 06:44
CRDT- 2024/03/25 21:23
PHST- 2023/04/21 00:00 [received]
PHST- 2023/10/13 00:00 [revised]
PHST- 2023/11/17 00:00 [accepted]
PHST- 2024/03/27 06:44 [medline]
PHST- 2024/03/26 00:42 [pubmed]
PHST- 2024/03/25 21:23 [entrez]
AID - 22/2/113 [pii]
AID - 10.1370/afm.3075 [doi]
PST - ppublish
SO  - Ann Fam Med. 2024 Mar-Apr;22(2):113-120. doi: 10.1370/afm.3075.

PMID- 37083633
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231106
IS  - 2369-3762 (Print)
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Apr 21
TI  - Trialling a Large Language Model (ChatGPT) in General Practice With the Applied 
      Knowledge Test: Observational Study Demonstrating Opportunities and Limitations 
      in Primary Care.
PG  - e46599
LID - 10.2196/46599 [doi]
LID - e46599
AB  - BACKGROUND: Large language models exhibiting human-level performance in 
      specialized tasks are emerging; examples include Generative Pretrained 
      Transformer 3.5, which underlies the processing of ChatGPT. Rigorous trials are 
      required to understand the capabilities of emerging technology, so that 
      innovation can be directed to benefit patients and practitioners. OBJECTIVE: 
      Here, we evaluated the strengths and weaknesses of ChatGPT in primary care using 
      the Membership of the Royal College of General Practitioners Applied Knowledge 
      Test (AKT) as a medium. METHODS: AKT questions were sourced from a web-based 
      question bank and 2 AKT practice papers. In total, 674 unique AKT questions were 
      inputted to ChatGPT, with the model's answers recorded and compared to correct 
      answers provided by the Royal College of General Practitioners. Each question was 
      inputted twice in separate ChatGPT sessions, with answers on repeated trials 
      compared to gauge consistency. Subject difficulty was gauged by referring to 
      examiners' reports from 2018 to 2022. Novel explanations from ChatGPT-defined as 
      information provided that was not inputted within the question or multiple answer 
      choices-were recorded. Performance was analyzed with respect to subject, 
      difficulty, question source, and novel model outputs to explore ChatGPT's 
      strengths and weaknesses. RESULTS: Average overall performance of ChatGPT was 
      60.17%, which is below the mean passing mark in the last 2 years (70.42%). 
      Accuracy differed between sources (P=.04 and .06). ChatGPT's performance varied 
      with subject category (P=.02 and .02), but variation did not correlate with 
      difficulty (Spearman ρ=-0.241 and -0.238; P=.19 and .20). The proclivity of 
      ChatGPT to provide novel explanations did not affect accuracy (P&gt;.99 and .23). 
      CONCLUSIONS: Large language models are approaching human expert-level 
      performance, although further development is required to match the performance of 
      qualified primary care physicians in the AKT. Validated high-performance models 
      may serve as assistants or autonomous clinical tools to ameliorate the general 
      practice workforce crisis.
CI  - ©Arun James Thirunavukarasu, Refaat Hassan, Shathar Mahmood, Rohan Sanghera, Kara 
      Barzangi, Mohanned El Mukashfi, Sachin Shah. Originally published in JMIR Medical 
      Education (https://mededu.jmir.org), 21.04.2023.
FAU - Thirunavukarasu, Arun James
AU  - Thirunavukarasu AJ
AUID- ORCID: 0000-0001-8968-4768
AD  - University of Cambridge School of Clinical Medicine, Cambridge, United Kingdom.
FAU - Hassan, Refaat
AU  - Hassan R
AUID- ORCID: 0000-0002-3054-1161
AD  - University of Cambridge School of Clinical Medicine, Cambridge, United Kingdom.
FAU - Mahmood, Shathar
AU  - Mahmood S
AUID- ORCID: 0009-0008-4209-1306
AD  - University of Cambridge School of Clinical Medicine, Cambridge, United Kingdom.
FAU - Sanghera, Rohan
AU  - Sanghera R
AUID- ORCID: 0000-0001-6370-8426
AD  - University of Cambridge School of Clinical Medicine, Cambridge, United Kingdom.
FAU - Barzangi, Kara
AU  - Barzangi K
AUID- ORCID: 0009-0009-0327-1221
AD  - University of Cambridge School of Clinical Medicine, Cambridge, United Kingdom.
FAU - El Mukashfi, Mohanned
AU  - El Mukashfi M
AUID- ORCID: 0009-0001-8158-0216
AD  - University of Cambridge School of Clinical Medicine, Cambridge, United Kingdom.
FAU - Shah, Sachin
AU  - Shah S
AUID- ORCID: 0009-0008-2470-6143
AD  - Attenborough Surgery, Bushey Medical Centre, Bushey, United Kingdom.
LA  - eng
PT  - Journal Article
DEP - 20230421
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
PMC - PMC10163403
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - artificial intelligence
OT  - chatbot
OT  - decision support techniques
OT  - deep learning
OT  - family medicine
OT  - general practice
OT  - large language model
OT  - natural language processing
OT  - primary care
COIS- Conflicts of Interest: None declared.
EDAT- 2023/04/21 18:42
MHDA- 2023/04/21 18:43
PMCR- 2023/04/21
CRDT- 2023/04/21 14:44
PHST- 2023/02/20 00:00 [received]
PHST- 2023/04/11 00:00 [accepted]
PHST- 2023/03/31 00:00 [revised]
PHST- 2023/04/21 18:43 [medline]
PHST- 2023/04/21 18:42 [pubmed]
PHST- 2023/04/21 14:44 [entrez]
PHST- 2023/04/21 00:00 [pmc-release]
AID - v9i1e46599 [pii]
AID - 10.2196/46599 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Apr 21;9:e46599. doi: 10.2196/46599.

PMID- 37314848
OWN - NLM
STAT- MEDLINE
DCOM- 20230616
LR  - 20230714
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 25
DP  - 2023 Jun 14
TI  - Investigating the Impact of User Trust on the Adoption and Use of ChatGPT: Survey 
      Analysis.
PG  - e47184
LID - 10.2196/47184 [doi]
LID - e47184
AB  - BACKGROUND: ChatGPT (Chat Generative Pre-trained Transformer) has gained 
      popularity for its ability to generate human-like responses. It is essential to 
      note that overreliance or blind trust in ChatGPT, especially in high-stakes 
      decision-making contexts, can have severe consequences. Similarly, lacking trust 
      in the technology can lead to underuse, resulting in missed opportunities. 
      OBJECTIVE: This study investigated the impact of users' trust in ChatGPT on their 
      intent and actual use of the technology. Four hypotheses were tested: (1) users' 
      intent to use ChatGPT increases with their trust in the technology; (2) the 
      actual use of ChatGPT increases with users' intent to use the technology; (3) the 
      actual use of ChatGPT increases with users' trust in the technology; and (4) 
      users' intent to use ChatGPT can partially mediate the effect of trust in the 
      technology on its actual use. METHODS: This study distributed a web-based survey 
      to adults in the United States who actively use ChatGPT (version 3.5) at least 
      once a month between February 2023 through March 2023. The survey responses were 
      used to develop 2 latent constructs: Trust and Intent to Use, with Actual Use 
      being the outcome variable. The study used partial least squares structural 
      equation modeling to evaluate and test the structural model and hypotheses. 
      RESULTS: In the study, 607 respondents completed the survey. The primary uses of 
      ChatGPT were for information gathering (n=219, 36.1%), entertainment (n=203, 
      33.4%), and problem-solving (n=135, 22.2%), with a smaller number using it for 
      health-related queries (n=44, 7.2%) and other activities (n=6, 1%). Our model 
      explained 50.5% and 9.8% of the variance in Intent to Use and Actual Use, 
      respectively, with path coefficients of 0.711 and 0.221 for Trust on Intent to 
      Use and Actual Use, respectively. The bootstrapped results failed to reject all 4 
      null hypotheses, with Trust having a significant direct effect on both Intent to 
      Use (β=0.711, 95% CI 0.656-0.764) and Actual Use (β=0.302, 95% CI 0.229-0.374). 
      The indirect effect of Trust on Actual Use, partially mediated by Intent to Use, 
      was also significant (β=0.113, 95% CI 0.001-0.227). CONCLUSIONS: Our results 
      suggest that trust is critical to users' adoption of ChatGPT. It remains crucial 
      to highlight that ChatGPT was not initially designed for health care 
      applications. Therefore, an overreliance on it for health-related advice could 
      potentially lead to misinformation and subsequent health risks. Efforts must be 
      focused on improving the ChatGPT's ability to distinguish between queries that it 
      can safely handle and those that should be redirected to human experts (health 
      care professionals). Although risks are associated with excessive trust in 
      artificial intelligence-driven chatbots such as ChatGPT, the potential risks can 
      be reduced by advocating for shared accountability and fostering collaboration 
      between developers, subject matter experts, and human factors researchers.
CI  - ©Avishek Choudhury, Hamid Shamszare. Originally published in the Journal of 
      Medical Internet Research (https://www.jmir.org), 14.06.2023.
FAU - Choudhury, Avishek
AU  - Choudhury A
AUID- ORCID: 0000-0002-5342-0709
AD  - Industrial and Management Systems Engineering, Benjamin M. Statler College of 
      Engineering and Mineral Resources, West Virginia University, Morgantown, WV, 
      United States.
FAU - Shamszare, Hamid
AU  - Shamszare H
AUID- ORCID: 0009-0007-7786-3452
AD  - Industrial and Management Systems Engineering, Benjamin M. Statler College of 
      Engineering and Mineral Resources, West Virginia University, Morgantown, WV, 
      United States.
LA  - eng
PT  - Journal Article
DEP - 20230614
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Adult
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Trust
MH  - Health Personnel
MH  - Intention
MH  - Surveys and Questionnaires
PMC - PMC10337387
OTO - NOTNLM
OT  - AI policy
OT  - ChatGPT
OT  - adoption
OT  - artificial intelligence
OT  - behavioral intention
OT  - chatbot
OT  - human factors
OT  - intent
OT  - shared accountability
OT  - survey
OT  - technology adoption
OT  - trust
OT  - trust in AI
COIS- Conflicts of Interest: None declared.
EDAT- 2023/06/14 13:07
MHDA- 2023/06/16 06:42
PMCR- 2023/06/14
CRDT- 2023/06/14 11:53
PHST- 2023/03/10 00:00 [received]
PHST- 2023/05/25 00:00 [accepted]
PHST- 2023/04/19 00:00 [revised]
PHST- 2023/06/16 06:42 [medline]
PHST- 2023/06/14 13:07 [pubmed]
PHST- 2023/06/14 11:53 [entrez]
PHST- 2023/06/14 00:00 [pmc-release]
AID - v25i1e47184 [pii]
AID - 10.2196/47184 [doi]
PST - epublish
SO  - J Med Internet Res. 2023 Jun 14;25:e47184. doi: 10.2196/47184.

PMID- 37682111
OWN - NLM
STAT- Publisher
LR  - 20231012
IS  - 1367-4811 (Electronic)
IS  - 1367-4803 (Print)
IS  - 1367-4803 (Linking)
VI  - 39
IP  - 9
DP  - 2023 Sep 2
TI  - An extensive benchmark study on biomedical text generation and mining with 
      ChatGPT.
LID - 10.1093/bioinformatics/btad557 [doi]
LID - btad557
AB  - MOTIVATION: In recent years, the development of natural language process (NLP) 
      technologies and deep learning hardware has led to significant improvement in 
      large language models (LLMs). The ChatGPT, the state-of-the-art LLM built on 
      GPT-3.5 and GPT-4, shows excellent capabilities in general language understanding 
      and reasoning. Researchers also tested the GPTs on a variety of NLP-related tasks 
      and benchmarks and got excellent results. With exciting performance on daily 
      chat, researchers began to explore the capacity of ChatGPT on expertise that 
      requires professional education for human and we are interested in the biomedical 
      domain. RESULTS: To evaluate the performance of ChatGPT on biomedical-related 
      tasks, this article presents a comprehensive benchmark study on the use of 
      ChatGPT for biomedical corpus, including article abstracts, clinical trials 
      description, biomedical questions, and so on. Typical NLP tasks like named entity 
      recognization, relation extraction, sentence similarity, question and answering, 
      and document classification are included. Overall, ChatGPT got a BLURB score of 
      58.50 while the state-of-the-art model had a score of 84.30. Through a series of 
      experiments, we demonstrated the effectiveness and versatility of ChatGPT in 
      biomedical text understanding, reasoning and generation, and the limitation of 
      ChatGPT build on GPT-3.5. AVAILABILITY AND IMPLEMENTATION: All the datasets are 
      available from BLURB benchmark https://microsoft.github.io/BLURB/index.html. The 
      prompts are described in the article.
CI  - © The Author(s) 2023. Published by Oxford University Press.
FAU - Chen, Qijie
AU  - Chen Q
AUID- ORCID: 0000-0003-0661-652X
AD  - AIDD, Mindrank AI Ltd, Zhejiang 310000, China.
FAU - Sun, Haotong
AU  - Sun H
AD  - AIDD, Mindrank AI Ltd, Zhejiang 310000, China.
FAU - Liu, Haoyang
AU  - Liu H
AD  - College of Life Sciences, Nankai University, Tianjin 300071, China.
AD  - Guangzhou Laboratory, GuangDong 510005, China.
FAU - Jiang, Yinghui
AU  - Jiang Y
AD  - AIDD, Mindrank AI Ltd, Zhejiang 310000, China.
FAU - Ran, Ting
AU  - Ran T
AD  - Guangzhou Laboratory, GuangDong 510005, China.
FAU - Jin, Xurui
AU  - Jin X
AD  - AIDD, Mindrank AI Ltd, Zhejiang 310000, China.
FAU - Xiao, Xianglu
AU  - Xiao X
AD  - AIDD, Mindrank AI Ltd, Zhejiang 310000, China.
FAU - Lin, Zhimin
AU  - Lin Z
AD  - AIDD, Mindrank AI Ltd, Zhejiang 310000, China.
FAU - Chen, Hongming
AU  - Chen H
AD  - Guangzhou Laboratory, GuangDong 510005, China.
FAU - Niu, Zhangmin
AU  - Niu Z
AUID- ORCID: 0000-0002-7009-946X
AD  - AIDD, Mindrank AI Ltd, Zhejiang 310000, China.
AD  - National Heart and Lung Institute, Imperial College London, London, United 
      Kingdom.
LA  - eng
PT  - Journal Article
PL  - England
TA  - Bioinformatics
JT  - Bioinformatics (Oxford, England)
JID - 9808944
SB  - IM
PMC - PMC10562950
COIS- None declared.
EDAT- 2023/09/08 12:42
MHDA- 2023/09/08 12:42
PMCR- 2023/09/08
CRDT- 2023/09/08 10:13
PHST- 2023/04/24 00:00 [received]
PHST- 2023/08/09 00:00 [revised]
PHST- 2023/09/06 00:00 [accepted]
PHST- 2023/09/08 12:42 [pubmed]
PHST- 2023/09/08 12:42 [medline]
PHST- 2023/09/08 10:13 [entrez]
PHST- 2023/09/08 00:00 [pmc-release]
AID - 7264174 [pii]
AID - btad557 [pii]
AID - 10.1093/bioinformatics/btad557 [doi]
PST - ppublish
SO  - Bioinformatics. 2023 Sep 2;39(9):btad557. doi: 10.1093/bioinformatics/btad557.

PMID- 38464770
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240312
IS  - 2220-3206 (Print)
IS  - 2220-3206 (Electronic)
IS  - 2220-3206 (Linking)
VI  - 14
IP  - 2
DP  - 2024 Feb 19
TI  - Using ChatGPT to promote college students' participation in physical activities 
      and its effect on mental health.
PG  - 330-333
LID - 10.5498/wjp.v14.i2.330 [doi]
AB  - As one of the most famous large language models, ChatGPT has great potential for 
      application in physical education. It can provide personalized exercise plans, a 
      variety of exercise options, and interactive support. The integration of ChatGPT 
      into the teaching process can promote college students' participation in physical 
      activities and improve their mental health while expanding the traditional 
      teaching environment and promoting the reform of traditional teaching methods. 
      However, the application of ChatGPT faces challenges and obstacles in physical 
      education. To make full use of ChatGPT in physical education, it can be combined 
      with wearable devices and sports equipment to enhance the efficiency of 
      interactions with users. Relevant policies are urgently needed to avoid the 
      improper use of users' data.
CI  - ©The Author(s) 2024. Published by Baishideng Publishing Group Inc. All rights 
      reserved.
FAU - Zhang, Yi-Fan
AU  - Zhang YF
AD  - School of Education, Tianjin University, Tianjin 300350, China.
FAU - Liu, Xin-Qiao
AU  - Liu XQ
AD  - School of Education, Tianjin University, Tianjin 300350, China. 
      xinqiaoliu@pku.edu.cn.
LA  - eng
PT  - Journal Article
DEP - 20240219
PL  - United States
TA  - World J Psychiatry
JT  - World journal of psychiatry
JID - 101610480
PMC - PMC10921293
OTO - NOTNLM
OT  - ChatGPT
OT  - College students
OT  - Mental health
OT  - Physical education
COIS- Conflict-of-interest statement: The authors declare no conflict of interests.
EDAT- 2024/03/11 06:43
MHDA- 2024/03/11 06:44
PMCR- 2024/02/19
CRDT- 2024/03/11 04:41
PHST- 2023/09/12 00:00 [received]
PHST- 2023/12/19 00:00 [revised]
PHST- 2024/01/23 00:00 [accepted]
PHST- 2024/03/11 06:44 [medline]
PHST- 2024/03/11 06:43 [pubmed]
PHST- 2024/03/11 04:41 [entrez]
PHST- 2024/02/19 00:00 [pmc-release]
AID - 10.5498/wjp.v14.i2.330 [doi]
PST - epublish
SO  - World J Psychiatry. 2024 Feb 19;14(2):330-333. doi: 10.5498/wjp.v14.i2.330. 
      eCollection 2024 Feb 19.

PMID- 37655838
OWN - NLM
STAT- MEDLINE
DCOM- 20240215
LR  - 20240215
IS  - 1879-3479 (Electronic)
IS  - 0020-7292 (Linking)
VI  - 164
IP  - 3
DP  - 2024 Mar
TI  - Performance of ChatGPT in French language Parcours d'Accès Spécifique Santé test 
      and in OBGYN.
PG  - 959-963
LID - 10.1002/ijgo.15083 [doi]
AB  - OBJECTIVES: To evaluate the performance of ChatGPT in a French medical school 
      entrance examination. METHODS: A cross-sectional study using a consecutive sample 
      of text-based multiple-choice practice questions for the Parcours d'Accès 
      Spécifique Santé. ChatGPT answered questions in French. We compared performance 
      of ChatGPT in obstetrics and gynecology (OBGYN) and in the whole test. RESULTS: 
      Overall, 885 questions were evaluated. The mean test score was 34.0% (306; 
      maximal score of 900). The performance of ChatGPT was 33.0% (292 correct answers, 
      885 questions). The performance of ChatGPT was lower in biostatistics 
      (13.3% ± 19.7%) than in anatomy (34.2% ± 17.9%; P = 0.037) and also lower than in 
      histology and embryology (40.0% ± 18.5%; P = 0.004). The OBGYN part had 290 
      questions. There was no difference in the test scores and the performance of 
      ChatGPT in OBGYN versus the whole entrance test (P = 0.76 vs P = 0.10, 
      respectively). CONCLUSIONS: ChatGPT answered one-third of questions correctly in 
      the French test preparation. The performance in OBGYN was similar.
CI  - © 2023 The Authors. International Journal of Gynecology &amp; Obstetrics published by 
      John Wiley &amp; Sons Ltd on behalf of International Federation of Gynecology and 
      Obstetrics.
FAU - Guigue, Paul-Adrien
AU  - Guigue PA
AD  - University Claude Bernard Lyon I, Lyon, France.
AD  - Lady Davis Institute for Cancer Research, Jewish General Hospital, McGill 
      University, Montreal, Quebec, Canada.
FAU - Meyer, Raanan
AU  - Meyer R
AD  - Department of Obstetrics and Gynecology, Chaim Sheba Medical Center, Ramat-Gan, 
      Israel.
AD  - Faculty of Medicine, Tel-Aviv University, Tel-Aviv, Israel.
AD  - Cedar-Sinai Medical Center, Los Angeles, California, USA.
FAU - Thivolle-Lioux, Gaetan
AU  - Thivolle-Lioux G
AD  - University Claude Bernard Lyon I, Lyon, France.
AD  - Centre de Recherche en Cancérologie de Lyon (CRCL), Lyon, France.
FAU - Brezinov, Yoav
AU  - Brezinov Y
AD  - Lady Davis Institute for Cancer Research, Jewish General Hospital, McGill 
      University, Montreal, Quebec, Canada.
FAU - Levin, Gabriel
AU  - Levin G
AUID- ORCID: 0000-0003-1282-5379
AD  - Lady Davis Institute for Cancer Research, Jewish General Hospital, McGill 
      University, Montreal, Quebec, Canada.
AD  - The Department of Gynecologic Oncology, Hadassah Medical Center, Faculty of 
      Medicine, Hebrew University of Jerusalem, Jerusalem, Israel.
LA  - eng
PT  - Journal Article
DEP - 20230901
PL  - United States
TA  - Int J Gynaecol Obstet
JT  - International journal of gynaecology and obstetrics: the official organ of the 
      International Federation of Gynaecology and Obstetrics
JID - 0210174
SB  - IM
MH  - Female
MH  - Pregnancy
MH  - Humans
MH  - Cross-Sectional Studies
MH  - *Gynecology
MH  - *Obstetrics
MH  - Biometry
MH  - Language
OTO - NOTNLM
OT  - ChatGPT
OT  - French
OT  - OBGYN
OT  - large language models
OT  - performance
OT  - test
EDAT- 2023/09/01 12:42
MHDA- 2024/02/15 06:43
CRDT- 2023/09/01 08:33
PHST- 2023/08/06 00:00 [revised]
PHST- 2023/05/07 00:00 [received]
PHST- 2023/08/17 00:00 [accepted]
PHST- 2024/02/15 06:43 [medline]
PHST- 2023/09/01 12:42 [pubmed]
PHST- 2023/09/01 08:33 [entrez]
AID - 10.1002/ijgo.15083 [doi]
PST - ppublish
SO  - Int J Gynaecol Obstet. 2024 Mar;164(3):959-963. doi: 10.1002/ijgo.15083. Epub 
      2023 Sep 1.

PMID- 37553555
OWN - NLM
STAT- Publisher
LR  - 20230808
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
DP  - 2023 Aug 8
TI  - Sailing the Seven Seas: A Multinational Comparison of ChatGPT's Performance on 
      Medical Licensing Examinations.
LID - 10.1007/s10439-023-03338-3 [doi]
AB  - PURPOSE: The use of AI-powered technology, particularly OpenAI's ChatGPT, holds 
      significant potential to reshape healthcare and medical education. Despite 
      existing studies on the performance of ChatGPT in medical licensing examinations 
      across different nations, a comprehensive, multinational analysis using rigorous 
      methodology is currently lacking. Our study sought to address this gap by 
      evaluating the performance of ChatGPT on six different national medical licensing 
      exams and investigating the relationship between test question length and 
      ChatGPT's accuracy. METHODS: We manually inputted a total of 1,800 test questions 
      (300 each from US, Italian, French, Spanish, UK, and Indian medical licensing 
      examination) into ChatGPT, and recorded the accuracy of its responses. RESULTS: 
      We found significant variance in ChatGPT's test accuracy across different 
      countries, with the highest accuracy seen in the Italian examination (73% correct 
      answers) and the lowest in the French examination (22% correct answers). 
      Interestingly, question length correlated with ChatGPT's performance in the 
      Italian and French state examinations only. In addition, the study revealed that 
      questions requiring multiple correct answers, as seen in the French examination, 
      posed a greater challenge to ChatGPT. CONCLUSION: Our findings underscore the 
      need for future research to further delineate ChatGPT's strengths and limitations 
      in medical test-taking across additional countries and to develop guidelines to 
      prevent AI-assisted cheating in medical examinations.
CI  - © 2023. The Author(s).
FAU - Alfertshofer, Michael
AU  - Alfertshofer M
AD  - Division of Hand, Plastic and Aesthetic Surgery, Ludwig-Maximilians University 
      Munich, Ziemssenstrasse 5, 80336, Munich, Germany. m.alfertshofer@campus.lmu.de.
FAU - Hoch, Cosima C
AU  - Hoch CC
AD  - Department of Otolaryngology, Head and Neck Surgery, School of Medicine, 
      Technical University of Munich (TUM), Ismaningerstrasse 22, 81675, Munich, 
      Germany.
FAU - Funk, Paul F
AU  - Funk PF
AD  - Department of Otolaryngology, Head and Neck Surgery, University Hospital Jena, 
      Friedrich Schiller University Jena, Am Klinikum 1, 07747, Jena, Germany.
FAU - Hollmann, Katharina
AU  - Hollmann K
AD  - Department of Pathology, Massachusetts General Hospital, Harvard Medical School, 
      55 Fruit St, Boston, MA, 02114, USA.
FAU - Wollenberg, Barbara
AU  - Wollenberg B
AD  - Department of Otolaryngology, Head and Neck Surgery, School of Medicine, 
      Technical University of Munich (TUM), Ismaningerstrasse 22, 81675, Munich, 
      Germany.
FAU - Knoedler, Samuel
AU  - Knoedler S
AD  - Department of Plastic, Hand and Reconstructive Surgery, University Hospital 
      Regensburg, Franz-Josef-Strauss-Allee 11, 93053, Regensburg, Germany.
FAU - Knoedler, Leonard
AU  - Knoedler L
AD  - Department of Plastic, Hand and Reconstructive Surgery, University Hospital 
      Regensburg, Franz-Josef-Strauss-Allee 11, 93053, Regensburg, Germany.
LA  - eng
PT  - Letter
DEP - 20230808
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Clinical decision-making
OT  - Medical education
OT  - Medical licensing exams
OT  - OpenAI
EDAT- 2023/08/09 01:05
MHDA- 2023/08/09 01:05
CRDT- 2023/08/08 23:30
PHST- 2023/07/26 00:00 [received]
PHST- 2023/07/28 00:00 [accepted]
PHST- 2023/08/09 01:05 [medline]
PHST- 2023/08/09 01:05 [pubmed]
PHST- 2023/08/08 23:30 [entrez]
AID - 10.1007/s10439-023-03338-3 [pii]
AID - 10.1007/s10439-023-03338-3 [doi]
PST - aheadofprint
SO  - Ann Biomed Eng. 2023 Aug 8. doi: 10.1007/s10439-023-03338-3.

PMID- 38096895
OWN - NLM
STAT- MEDLINE
DCOM- 20231216
LR  - 20231219
IS  - 1975-5937 (Electronic)
IS  - 1975-5937 (Linking)
VI  - 20
DP  - 2023
TI  - Medical students' patterns of using ChatGPT as a feedback tool and perceptions of 
      ChatGPT in a Leadership and Communication course in Korea: a cross-sectional 
      study.
PG  - 29
LID - 10.3352/jeehp.2023.20.29 [doi]
LID - 29
AB  - PURPOSE: This study aimed to analyze patterns of using ChatGPT before and after 
      group activities and to explore medical students' perceptions of ChatGPT as a 
      feedback tool in the classroom. METHODS: The study included 99 2nd-year 
      pre-medical students who participated in a "Leadership and Communication" course 
      from March to June 2023. Students engaged in both individual and group activities 
      related to negotiation strategies. ChatGPT was used to provide feedback on their 
      solutions. A survey was administered to assess students' perceptions of ChatGPT's 
      feedback, its use in the classroom, and the strengths and challenges of ChatGPT 
      from May 17 to 19, 2023. RESULTS: The students responded by indicating that 
      ChatGPT's feedback was helpful, and revised and resubmitted their group answers 
      in various ways after receiving feedback. The majority of respondents expressed 
      agreement with the use of ChatGPT during class. The most common response 
      concerning the appropriate context of using ChatGPT's feedback was "after the 
      first round of discussion, for revisions." There was a significant difference in 
      satisfaction with ChatGPT's feedback, including correctness, usefulness, and 
      ethics, depending on whether or not ChatGPT was used during class, but there was 
      no significant difference according to gender or whether students had previous 
      experience with ChatGPT. The strongest advantages were "providing answers to 
      questions" and "summarizing information," and the worst disadvantage was 
      "producing information without supporting evidence." CONCLUSION: The students 
      were aware of the advantages and disadvantages of ChatGPT, and they had a 
      positive attitude toward using ChatGPT in the classroom.
FAU - Park, Janghee
AU  - Park J
AD  - Department of Medical Education, Soonchunhyang University College of Medicine, 
      Cheonan, Korea.
LA  - eng
GR  - Soonchunhyang University Research Fund/
PT  - Journal Article
DEP - 20231110
PL  - Korea (South)
TA  - J Educ Eval Health Prof
JT  - Journal of educational evaluation for health professions
JID - 101490061
SB  - IM
MH  - Humans
MH  - *Students, Medical
MH  - Cross-Sectional Studies
MH  - Feedback
MH  - Leadership
MH  - Communication
MH  - Republic of Korea
PMC - PMC10725745
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Feedback
OT  - Leadership
OT  - Medical students
OT  - Republic of Korea
COIS- Conflict of interest No potential conflict of interest relevant to this article 
      was reported.
EDAT- 2023/12/15 00:43
MHDA- 2023/12/17 09:43
PMCR- 2023/11/10
CRDT- 2023/12/14 18:56
PHST- 2023/09/22 00:00 [received]
PHST- 2023/10/29 00:00 [accepted]
PHST- 2023/12/17 09:43 [medline]
PHST- 2023/12/15 00:43 [pubmed]
PHST- 2023/12/14 18:56 [entrez]
PHST- 2023/11/10 00:00 [pmc-release]
AID - jeehp.2023.20.29 [pii]
AID - jeehp-20-29 [pii]
AID - 10.3352/jeehp.2023.20.29 [doi]
PST - ppublish
SO  - J Educ Eval Health Prof. 2023;20:29. doi: 10.3352/jeehp.2023.20.29. Epub 2023 Nov 
      10.

PMID- 38195660
OWN - NLM
STAT- MEDLINE
DCOM- 20240111
LR  - 20240112
IS  - 2045-2322 (Electronic)
IS  - 2045-2322 (Linking)
VI  - 14
IP  - 1
DP  - 2024 Jan 9
TI  - Humans create more novelty than ChatGPT when asked to retell a story.
PG  - 875
LID - 10.1038/s41598-023-50229-7 [doi]
LID - 875
AB  - We compare how humans retell stories to how ChatGPT retells stories in chains of 
      three retellings by different people or different accounts on ChatGPT. ChatGPT 
      provides competent summaries of the original narrative texts in one step of 
      retelling. In subsequent retellings few additional changes occur. Human 
      retellers, by contrast, reduce the original text incrementally and by creating 
      55-60% of novel words and concepts (synsets) at each iteration. The retellings by 
      both ChatGPT and humans show very stable emotion ratings, which is a puzzle for 
      human retellers given the high degree of novel inventions across retellings. 
      ChatGPT maintains more nouns, adjectives, and prepositions and also uses language 
      later acquired in life, while humans use more verbs, adverbs, and negations and 
      use language acquired at a younger age. The results reveal that spontaneous 
      retelling by humans involves ongoing creativity, anchored by emotions, beyond the 
      default probabilistic wording of large language models such as ChatGPT.
CI  - © 2024. The Author(s).
FAU - Breithaupt, Fritz
AU  - Breithaupt F
AD  - Cognitive Science Program, Indiana University Bloomington, 1001 E 10th St, 
      Bloomington, IN, 47405, USA. fbreitha@indiana.edu.
AD  - Germanic Studies, Indiana University Bloomington, 355 N. Eagleson, Bloomington, 
      IN, 47405, USA. fbreitha@indiana.edu.
FAU - Otenen, Ege
AU  - Otenen E
AD  - Cognitive Science Program, Indiana University Bloomington, 1001 E 10th St, 
      Bloomington, IN, 47405, USA.
AD  - Center for Complex Networks and Systems Research, Luddy School of Informatics, 
      Computing, and Engineering, Indiana University Bloomington, 901 E 10th St, 
      Bloomington, IN, 47405, USA.
FAU - Wright, Devin R
AU  - Wright DR
AD  - Cognitive Science Program, Indiana University Bloomington, 1001 E 10th St, 
      Bloomington, IN, 47405, USA.
AD  - Center for Complex Networks and Systems Research, Luddy School of Informatics, 
      Computing, and Engineering, Indiana University Bloomington, 901 E 10th St, 
      Bloomington, IN, 47405, USA.
FAU - Kruschke, John K
AU  - Kruschke JK
AD  - Cognitive Science Program, Indiana University Bloomington, 1001 E 10th St, 
      Bloomington, IN, 47405, USA.
AD  - Department of Psychological and Brain Sciences, Indiana University Bloomington, 
      1101 E 10th St, Bloomington, IN, 47405, USA.
FAU - Li, Ying
AU  - Li Y
AD  - Key Laboratory of Behavioral Science, Institute of Psychology, Chinese Academy of 
      Sciences, 16 Lincui Road, 100101, Beijing, China.
FAU - Tan, Yiyan
AU  - Tan Y
AD  - Cognitive Science Program, Indiana University Bloomington, 1001 E 10th St, 
      Bloomington, IN, 47405, USA.
AD  - Department of Psychological and Brain Sciences, Indiana University Bloomington, 
      1101 E 10th St, Bloomington, IN, 47405, USA.
LA  - eng
PT  - Journal Article
DEP - 20240109
PL  - England
TA  - Sci Rep
JT  - Scientific reports
JID - 101563288
SB  - IM
MH  - Humans
MH  - *Emotions
MH  - *Language
MH  - Maintenance
MH  - Narration
PMC - PMC10776760
COIS- The authors declare no competing interests.
EDAT- 2024/01/10 00:42
MHDA- 2024/01/11 07:43
PMCR- 2024/01/09
CRDT- 2024/01/09 23:47
PHST- 2023/10/05 00:00 [received]
PHST- 2023/12/17 00:00 [accepted]
PHST- 2024/01/11 07:43 [medline]
PHST- 2024/01/10 00:42 [pubmed]
PHST- 2024/01/09 23:47 [entrez]
PHST- 2024/01/09 00:00 [pmc-release]
AID - 10.1038/s41598-023-50229-7 [pii]
AID - 50229 [pii]
AID - 10.1038/s41598-023-50229-7 [doi]
PST - epublish
SO  - Sci Rep. 2024 Jan 9;14(1):875. doi: 10.1038/s41598-023-50229-7.

PMID- 37598590
OWN - NLM
STAT- MEDLINE
DCOM- 20230925
LR  - 20231130
IS  - 1878-0539 (Electronic)
IS  - 1748-6815 (Linking)
VI  - 85
DP  - 2023 Oct
TI  - Dr. ChatGPT will see you now: How do Google and ChatGPT compare in answering 
      patient questions on breast reconstruction?
PG  - 488-497
LID - S1748-6815(23)00445-X [pii]
LID - 10.1016/j.bjps.2023.07.039 [doi]
FAU - Liu, Hilary Y
AU  - Liu HY
AD  - Department of Plastic Surgery, University of Pittsburgh Medical Center, 1350 
      Locust Street, G103, Pittsburgh, PA 15213, United States.
FAU - Alessandri Bonetti, Mario
AU  - Alessandri Bonetti M
AD  - Department of Plastic Surgery, University of Pittsburgh Medical Center, 1350 
      Locust Street, G103, Pittsburgh, PA 15213, United States.
FAU - Jeong, Tiffany
AU  - Jeong T
AD  - Department of Plastic Surgery, University of Pittsburgh Medical Center, 1350 
      Locust Street, G103, Pittsburgh, PA 15213, United States.
FAU - Pandya, Sumaarg
AU  - Pandya S
AD  - Department of Plastic Surgery, University of Pittsburgh Medical Center, 1350 
      Locust Street, G103, Pittsburgh, PA 15213, United States.
FAU - Nguyen, Vu T
AU  - Nguyen VT
AD  - Department of Plastic Surgery, University of Pittsburgh Medical Center, 1350 
      Locust Street, G103, Pittsburgh, PA 15213, United States.
FAU - Egro, Francesco M
AU  - Egro FM
AD  - Department of Plastic Surgery, University of Pittsburgh Medical Center, 1350 
      Locust Street, G103, Pittsburgh, PA 15213, United States. Electronic address: 
      francescoegro@gmail.com.
LA  - eng
PT  - Journal Article
DEP - 20230727
PL  - Netherlands
TA  - J Plast Reconstr Aesthet Surg
JT  - Journal of plastic, reconstructive &amp; aesthetic surgery : JPRAS
JID - 101264239
SB  - IM
CIN - J Plast Reconstr Aesthet Surg. 2023 Nov;86:269-270. PMID: 37797373
MH  - Humans
MH  - *Search Engine
MH  - *Mammaplasty
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Breast
OT  - Breast reconstruction
OT  - ChatGPT
OT  - Google
OT  - Patient education
COIS- Declaration of Competing Interest The authors declare that they have no conflicts 
      of interest to disclose.
EDAT- 2023/08/21 00:41
MHDA- 2023/09/25 06:42
CRDT- 2023/08/20 18:07
PHST- 2023/07/07 00:00 [received]
PHST- 2023/07/16 00:00 [accepted]
PHST- 2023/09/25 06:42 [medline]
PHST- 2023/08/21 00:41 [pubmed]
PHST- 2023/08/20 18:07 [entrez]
AID - S1748-6815(23)00445-X [pii]
AID - 10.1016/j.bjps.2023.07.039 [doi]
PST - ppublish
SO  - J Plast Reconstr Aesthet Surg. 2023 Oct;85:488-497. doi: 
      10.1016/j.bjps.2023.07.039. Epub 2023 Jul 27.

PMID- 38565880
OWN - NLM
STAT- In-Process
LR  - 20240402
IS  - 2045-2322 (Electronic)
IS  - 2045-2322 (Linking)
VI  - 14
IP  - 1
DP  - 2024 Apr 2
TI  - Effects of ChatGPT's AI capabilities and human-like traits on spreading 
      information in work environments.
PG  - 7806
LID - 10.1038/s41598-024-57977-0 [doi]
AB  - The rapid proliferation and integration of AI chatbots in office environments, 
      specifically the advanced AI model ChatGPT, prompts an examination of how its 
      features and updates impact knowledge processes, satisfaction, and word-of-mouth 
      (WOM) among office workers. This study investigates the determinants of WOM among 
      office workers who are users of ChatGPT. We adopted a quantitative approach, 
      utilizing a stratified random sampling technique to collect data from a diverse 
      group of office workers experienced in using ChatGPT. The hypotheses were 
      rigorously tested through Structural Equation Modeling (SEM) using the SmartPLS 
      4. The results revealed that system updates, memorability, and non-language 
      barrier attributes of ChatGPT significantly enhanced knowledge acquisition and 
      application. Additionally, the human-like personality traits of ChatGPT 
      significantly increased both utilitarian value and satisfaction. Furthermore, the 
      study showed that knowledge acquisition and application led to a significant 
      increase in utilitarian value and satisfaction, which subsequently increased WOM. 
      Age had a positive influence on WOM, while gender had no significant impact. The 
      findings provide theoretical contributions by expanding our understanding of AI 
      chatbots' role in knowledge processes, satisfaction, and WOM, particularly among 
      office workers.
CI  - © 2024. The Author(s).
FAU - Jo, Hyeon
AU  - Jo H
AUID- ORCID: 0000-0001-7442-4736
AD  - Headquarters, HJ Institute of Technology and Management, 71 Jungdong-ro 39, 
      Bucheon-si, Gyeonggi-do, 14721, Republic of Korea.
FAU - Park, Do-Hyung
AU  - Park DH
AUID- ORCID: 0000-0002-7278-5228
AD  - Graduate School of Business IT, Kookmin University, 77, Jeongneung-ro, 
      Seongbuk-gu, Seoul, 02707, Republic of Korea. dohyungpark@kookmin.ac.kr.
LA  - eng
GR  - NRF-2020R1A2C1006001/Ministry of Education of the Republic of Korea/
GR  - NRF-2020R1A2C1006001/National Research Foundation of Korea/
PT  - Journal Article
DEP - 20240402
PL  - England
TA  - Sci Rep
JT  - Scientific reports
JID - 101563288
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - Knowledge Acquisition
OT  - Knowledge Application
OT  - Office Workers
OT  - Word-of-Mouth
EDAT- 2024/04/03 00:44
MHDA- 2024/04/03 00:44
CRDT- 2024/04/02 23:32
PHST- 2023/10/06 00:00 [received]
PHST- 2024/03/23 00:00 [accepted]
PHST- 2024/04/03 00:44 [medline]
PHST- 2024/04/03 00:44 [pubmed]
PHST- 2024/04/02 23:32 [entrez]
AID - 10.1038/s41598-024-57977-0 [pii]
AID - 10.1038/s41598-024-57977-0 [doi]
PST - epublish
SO  - Sci Rep. 2024 Apr 2;14(1):7806. doi: 10.1038/s41598-024-57977-0.

PMID- 38371244
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240220
IS  - 2055-2076 (Print)
IS  - 2055-2076 (Electronic)
IS  - 2055-2076 (Linking)
VI  - 10
DP  - 2024 Jan-Dec
TI  - Performance of ChatGPT on Stage 1 of the Taiwanese medical licensing exam.
PG  - 20552076241233144
LID - 10.1177/20552076241233144 [doi]
LID - 20552076241233144
AB  - INTRODUCTION: Since its release by OpenAI in November 2022, numerous studies have 
      subjected ChatGPT to various tests to evaluate its performance in medical exams. 
      The objective of this study is to evaluate ChatGPT's accuracy and logical 
      reasoning across all 10 subjects featured in Stage 1 of Senior Professional and 
      Technical Examinations for Medical Doctors (SPTEMD) in Taiwan, with questions 
      that encompass both Chinese and English. METHODS: In this study, we tested 
      ChatGPT-4 to complete SPTEMD Stage 1. The model was presented with 
      multiple-choice questions extracted from three separate tests conducted in 
      February 2022, July 2022, and February 2023. These questions encompass 10 
      subjects, namely biochemistry and molecular biology, anatomy, embryology and 
      developmental biology, histology, physiology, microbiology and immunology, 
      parasitology, pharmacology, pathology, and public health. Subsequently, we 
      analyzed the model's accuracy for each subject. RESULT: In all three tests, 
      ChatGPT achieved scores surpassing the 60% passing threshold, resulting in an 
      overall average score of 87.8%. Notably, its best performance was in 
      biochemistry, where it garnered an average score of 93.8%. Conversely, the 
      performance of the generative pre-trained transformer (GPT)-4 assistant on 
      anatomy, parasitology, and embryology was not as good. In addition, its scores 
      were highly variable in embryology and parasitology. CONCLUSION: ChatGPT has the 
      potential to facilitate not only exam preparation but also improve the 
      accessibility of medical education and support continuous education for medical 
      professionals. In conclusion, this study has demonstrated ChatGPT's potential 
      competence across various subjects within the SPTEMD Stage 1 and suggests that it 
      could be a helpful tool for learning and exam preparation for medical students 
      and professionals.
CI  - © The Author(s) 2024.
FAU - Huang, Chao-Hsiung
AU  - Huang CH
AD  - School of Medicine, China Medical University, Taichung. RINGGOLD: 541380
FAU - Hsiao, Han-Jung
AU  - Hsiao HJ
AD  - Artificial Intelligence Center, China Medical University Hospital, China Medical 
      University, Taichung. RINGGOLD: 541380
FAU - Yeh, Pei-Chun
AU  - Yeh PC
AD  - Artificial Intelligence Center, China Medical University Hospital, China Medical 
      University, Taichung. RINGGOLD: 541380
FAU - Wu, Kuo-Chen
AU  - Wu KC
AD  - Artificial Intelligence Center, China Medical University Hospital, China Medical 
      University, Taichung. RINGGOLD: 541380
AD  - Graduate Institute of Biomedical Electronics and Bioinformatics, National Taiwan 
      University, Taipei.
FAU - Kao, Chia-Hung
AU  - Kao CH
AUID- ORCID: 0000-0002-6368-3676
AD  - Artificial Intelligence Center, China Medical University Hospital, China Medical 
      University, Taichung. RINGGOLD: 541380
AD  - Graduate Institute of Biomedical Sciences, School of Medicine, College of 
      Medicine, China Medical University, Taichung.
AD  - Department of Nuclear Medicine and PET Center, China Medical University Hospital, 
      Taichung. RINGGOLD: 38020
AD  - Department of Bioinformatics and Medical Engineering, Asia University, Taichung.
LA  - eng
PT  - Journal Article
DEP - 20240216
PL  - United States
TA  - Digit Health
JT  - Digital health
JID - 101690863
PMC - PMC10874144
OTO - NOTNLM
OT  - ChatGPT
OT  - OpenAI
OT  - Taiwanese medical licensing exam
OT  - artificial intelligence
OT  - educational measurement
COIS- The authors declared no potential conflicts of interest with respect to the 
      research, authorship, and/or publication of this article.
EDAT- 2024/02/19 06:44
MHDA- 2024/02/19 06:45
PMCR- 2024/02/16
CRDT- 2024/02/19 04:22
PHST- 2023/08/15 00:00 [received]
PHST- 2024/01/25 00:00 [accepted]
PHST- 2024/02/19 06:45 [medline]
PHST- 2024/02/19 06:44 [pubmed]
PHST- 2024/02/19 04:22 [entrez]
PHST- 2024/02/16 00:00 [pmc-release]
AID - 10.1177_20552076241233144 [pii]
AID - 10.1177/20552076241233144 [doi]
PST - epublish
SO  - Digit Health. 2024 Feb 16;10:20552076241233144. doi: 10.1177/20552076241233144. 
      eCollection 2024 Jan-Dec.

PMID- 37798960
OWN - NLM
STAT- Publisher
LR  - 20231221
IS  - 1932-2968 (Electronic)
IS  - 1932-2968 (Linking)
DP  - 2023 Oct 5
TI  - The Scientific Knowledge of Bard and ChatGPT in Endocrinology, Diabetes, and 
      Diabetes Technology: Multiple-Choice Questions Examination-Based Performance.
PG  - 19322968231203987
LID - 10.1177/19322968231203987 [doi]
AB  - BACKGROUND: The present study aimed to investigate the knowledge level of Bard 
      and ChatGPT in the areas of endocrinology, diabetes, and diabetes technology 
      through a multiple-choice question (MCQ) examination format. METHODS: Initially, 
      a 100-MCQ bank was established based on MCQs in endocrinology, diabetes, and 
      diabetes technology. The MCQs were created from physiology, medical textbooks, 
      and academic examination pools in the areas of endocrinology, diabetes, and 
      diabetes technology and academic examination pools. The study team members 
      analyzed the MCQ contents to ensure that they were related to the endocrinology, 
      diabetes, and diabetes technology. The number of MCQs from endocrinology was 50, 
      and that from diabetes and science technology was also 50. The knowledge level of 
      Google's Bard and ChatGPT was assessed with an MCQ-based examination. RESULTS: In 
      the endocrinology examination section, ChatGPT obtained 29 marks (correct 
      responses) of 50 (58%), and Bard obtained a similar score of 29 of 50 (58%). 
      However, in the diabetes technology examination section, ChatGPT obtained 23 
      marks of 50 (46%), and Bard obtained 20 marks of 50 (40%). Overall, in the entire 
      three-part examination, ChatGPT obtained 52 marks of 100 (52%), and Bard obtained 
      49 marks of 100 (49%). ChatGPT obtained slightly more marks than Bard. However, 
      both ChatGPT and Bard did not achieve satisfactory scores in endocrinology or 
      diabetes/technology of at least 60%. CONCLUSIONS: The overall MCQ-based 
      performance of ChatGPT was slightly better than that of Google's Bard. However, 
      both ChatGPT and Bard did not achieve appropriate scores in endocrinology and 
      diabetes/diabetes technology. The study indicates that Bard and ChatGPT have the 
      potential to facilitate medical students and faculty in academic medical 
      education settings, but both artificial intelligence tools need more updated 
      information in the fields of endocrinology, diabetes, and diabetes technology.
FAU - Meo, Sultan Ayoub
AU  - Meo SA
AUID- ORCID: 0000-0001-9820-1852
AD  - Department of Physiology, College of Medicine, King Saud University, Riyadh, 
      Saudi Arabia.
FAU - Al-Khlaiwi, Thamir
AU  - Al-Khlaiwi T
AD  - Department of Physiology, College of Medicine, King Saud University, Riyadh, 
      Saudi Arabia.
FAU - AbuKhalaf, Abdulelah Adnan
AU  - AbuKhalaf AA
AUID- ORCID: 0000-0001-8194-0560
AD  - College of Medicine, King Saud University, Riyadh, Saudi Arabia.
FAU - Meo, Anusha Sultan
AU  - Meo AS
AUID- ORCID: 0000-0001-5213-3233
AD  - The School of Medicine, Medical Sciences and Nutrition, University of Aberdeen, 
      Aberdeen, UK.
FAU - Klonoff, David C
AU  - Klonoff DC
AUID- ORCID: 0000-0001-6394-6862
AD  - Diabetes Research Institute, Mills-Peninsula Medical Center, San Mateo, CA, USA.
LA  - eng
PT  - Journal Article
DEP - 20231005
PL  - United States
TA  - J Diabetes Sci Technol
JT  - Journal of diabetes science and technology
JID - 101306166
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - Google’s board
OT  - diabetes technology
OT  - endocrinology
OT  - intellect level
OT  - knowledge
COIS- Declaration of Conflicting InterestsThe author(s) declared no potential conflicts 
      of interest with respect to the research, authorship, and/or publication of this 
      article.
EDAT- 2023/10/06 06:43
MHDA- 2023/10/06 06:43
CRDT- 2023/10/06 02:33
PHST- 2023/10/06 06:43 [pubmed]
PHST- 2023/10/06 06:43 [medline]
PHST- 2023/10/06 02:33 [entrez]
AID - 10.1177/19322968231203987 [doi]
PST - aheadofprint
SO  - J Diabetes Sci Technol. 2023 Oct 5:19322968231203987. doi: 
      10.1177/19322968231203987.

PMID- 38465399
OWN - NLM
STAT- Publisher
LR  - 20240311
IS  - 2194-802X (Electronic)
IS  - 2194-802X (Linking)
DP  - 2024 Mar 12
TI  - Can ChatGPT-4 evaluate whether a differential diagnosis list contains the correct 
      diagnosis as accurately as a physician?
LID - 10.1515/dx-2024-0027 [doi]
AB  - OBJECTIVES: The potential of artificial intelligence (AI) chatbots, particularly 
      the fourth-generation chat generative pretrained transformer (ChatGPT-4), in 
      assisting with medical diagnosis is an emerging research area. While there has 
      been significant emphasis on creating lists of differential diagnoses, it is not 
      yet clear how well AI chatbots can evaluate whether the final diagnosis is 
      included in these lists. This short communication aimed to assess the accuracy of 
      ChatGPT-4 in evaluating lists of differential diagnosis compared to medical 
      professionals' assessments. METHODS: We used ChatGPT-4 to evaluate whether the 
      final diagnosis was included in the top 10 differential diagnosis lists created 
      by physicians, ChatGPT-3, and ChatGPT-4, using clinical vignettes. Eighty-two 
      clinical vignettes were used, comprising 52 complex case reports published by the 
      authors from the department and 30 mock cases of common diseases created by 
      physicians from the same department. We compared the agreement between ChatGPT-4 
      and the physicians on whether the final diagnosis was included in the top 10 
      differential diagnosis lists using the kappa coefficient. RESULTS: Three sets of 
      differential diagnoses were evaluated for each of the 82 cases, resulting in a 
      total of 246 lists. The agreement rate between ChatGPT-4 and physicians was 236 
      out of 246 (95.9 %), with a kappa coefficient of 0.86, indicating very good 
      agreement. CONCLUSIONS: ChatGPT-4 demonstrated very good agreement with 
      physicians in evaluating whether the final diagnosis should be included in the 
      differential diagnosis lists.
CI  - © 2024 Walter de Gruyter GmbH, Berlin/Boston.
FAU - Mizuta, Kazuya
AU  - Mizuta K
AD  - Department of Diagnostic and Generalist Medicine, Dokkyo Medical University 12756 
      , Simotsuga-gun, Japan.
FAU - Hirosawa, Takanobu
AU  - Hirosawa T
AUID- ORCID: 0000-0002-3573-8203
AD  - Department of Diagnostic and Generalist Medicine, Dokkyo Medical University 12756 
      , Simotsuga-gun, Japan.
FAU - Harada, Yukinori
AU  - Harada Y
AD  - Department of Diagnostic and Generalist Medicine, Dokkyo Medical University 12756 
      , Simotsuga-gun, Japan.
FAU - Shimizu, Taro
AU  - Shimizu T
AD  - Department of Diagnostic and Generalist Medicine, Dokkyo Medical University 12756 
      , Simotsuga-gun, Japan.
LA  - eng
PT  - Journal Article
DEP - 20240312
PL  - Germany
TA  - Diagnosis (Berl)
JT  - Diagnosis (Berlin, Germany)
JID - 101654734
SB  - IM
OTO - NOTNLM
OT  - clinical decision supporting system
OT  - diagnosis
OT  - diagnostic excellence
OT  - generative artificial intelligence
OT  - large language model
OT  - natural language processing
EDAT- 2024/03/11 06:42
MHDA- 2024/03/11 06:42
CRDT- 2024/03/11 04:52
PHST- 2024/02/09 00:00 [received]
PHST- 2024/02/22 00:00 [accepted]
PHST- 2024/03/11 06:42 [medline]
PHST- 2024/03/11 06:42 [pubmed]
PHST- 2024/03/11 04:52 [entrez]
AID - dx-2024-0027 [pii]
AID - 10.1515/dx-2024-0027 [doi]
PST - aheadofprint
SO  - Diagnosis (Berl). 2024 Mar 12. doi: 10.1515/dx-2024-0027.

PMID- 38195060
OWN - NLM
STAT- Publisher
LR  - 20240109
IS  - 1945-7103 (Electronic)
IS  - 0003-3219 (Linking)
DP  - 2024 Jan 10
TI  - Content analysis of AI-generated (ChatGPT) responses concerning orthodontic clear 
      aligners.
LID - 10.2319/071123-484.1 [doi]
AB  - OBJECTIVES: To assess the accuracy of ChatGPT answers concerning orthodontic 
      clear aligners. MATERIALS AND METHODS: A cross-sectional content analysis of 
      ChatGPT generated responses to queries related to clear aligner treatment (CAT) 
      was undertaken. A total of 111 questions were generated by three orthodontists 
      based on a set of predefined domains and subdomains. The artificial intelligence 
      (AI)-generated (ChatGPT) answers were extracted and their accuracy was determined 
      independently by five orthodontists. The accuracy of answers was assessed using a 
      prepiloted four-point scale scoring rubric. Descriptive statistics were 
      performed. RESULTS: The total mean accuracy score for the entire set was 2.6 ± 
      1.1. It was noted that 58% of the AI-generated answers were scored as objectively 
      true, 18% were selected facts, 9% were minimal facts, and 15% were false. False 
      claims included the ability of CAT to reduce the need for orthognathic surgery 
      (4.0 ± 0.0), improve airway function (3.8 ± 0.5), achieve root parallelism (3.6 ± 
      0.5), alleviate sleep apnea (3.8 ± 0.5), and produce more stable results compared 
      to fixed appliances (3.8 ± 0.5). CONCLUSIONS: The overall level of accuracy of 
      ChatGPT responses to questions concerning CAT was suboptimal and lacked citations 
      to relevant literature. Ability of the software to offer current and precise 
      information was limited. Therefore, clinicians and patients must be mindful of 
      false claims and relevant facts omitted in the answers generated by ChatGPT.
CI  - © 0000 by The EH Angle Education and Research Foundation, Inc.
FAU - Abu Arqub, Sarah
AU  - Abu Arqub S
FAU - Al-Moghrabi, Dalya
AU  - Al-Moghrabi D
FAU - Allareddy, Veerasathpurush
AU  - Allareddy V
FAU - Upadhyay, Madhur
AU  - Upadhyay M
FAU - Vaid, Nikhilesh
AU  - Vaid N
FAU - Yadav, Sumit
AU  - Yadav S
LA  - eng
PT  - Journal Article
DEP - 20240110
PL  - United States
TA  - Angle Orthod
JT  - The Angle orthodontist
JID - 0370550
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Clear aligners
OT  - Content validity
EDAT- 2024/01/10 00:42
MHDA- 2024/01/10 00:42
CRDT- 2024/01/09 19:13
PHST- 2023/07/01 00:00 [received]
PHST- 2023/11/01 00:00 [accepted]
PHST- 2024/01/10 00:42 [medline]
PHST- 2024/01/10 00:42 [pubmed]
PHST- 2024/01/09 19:13 [entrez]
AID - 498154 [pii]
AID - 10.2319/071123-484.1 [doi]
PST - aheadofprint
SO  - Angle Orthod. 2024 Jan 10. doi: 10.2319/071123-484.1.

PMID- 37742280
OWN - NLM
STAT- MEDLINE
DCOM- 20240119
LR  - 20240201
IS  - 1437-160X (Electronic)
IS  - 0172-8172 (Print)
IS  - 0172-8172 (Linking)
VI  - 44
IP  - 2
DP  - 2024 Feb
TI  - Diagnostic accuracy of a large language model in rheumatology: comparison of 
      physician and ChatGPT-4.
PG  - 303-306
LID - 10.1007/s00296-023-05464-6 [doi]
AB  - Pre-clinical studies suggest that large language models (i.e., ChatGPT) could be 
      used in the diagnostic process to distinguish inflammatory rheumatic (IRD) from 
      other diseases. We therefore aimed to assess the diagnostic accuracy of ChatGPT-4 
      in comparison to rheumatologists. For the analysis, the data set of Gräf et al. 
      (2022) was used. Previous patient assessments were analyzed using ChatGPT-4 and 
      compared to rheumatologists' assessments. ChatGPT-4 listed the correct diagnosis 
      comparable often to rheumatologists as the top diagnosis 35% vs 39% (p = 0.30); 
      as well as among the top 3 diagnoses, 60% vs 55%, (p = 0.38). In IRD-positive 
      cases, ChatGPT-4 provided the top diagnosis in 71% vs 62% in the rheumatologists' 
      analysis. Correct diagnosis was among the top 3 in 86% (ChatGPT-4) vs 74% 
      (rheumatologists). In non-IRD cases, ChatGPT-4 provided the correct top diagnosis 
      in 15% vs 27% in the rheumatologists' analysis. Correct diagnosis was among the 
      top 3 in non-IRD cases in 46% of the ChatGPT-4 group vs 45% in the 
      rheumatologists group. If only the first suggestion for diagnosis was considered, 
      ChatGPT-4 correctly classified 58% of cases as IRD compared to 56% of the 
      rheumatologists (p = 0.52). ChatGPT-4 showed a slightly higher accuracy for the 
      top 3 overall diagnoses compared to rheumatologist's assessment. ChatGPT-4 was 
      able to provide the correct differential diagnosis in a relevant number of cases 
      and achieved better sensitivity to detect IRDs than rheumatologist, at the cost 
      of lower specificity. The pilot results highlight the potential of this new 
      technology as a triage tool for the diagnosis of IRD.
CI  - © 2023. The Author(s).
FAU - Krusche, Martin
AU  - Krusche M
AUID- ORCID: 0000-0002-0582-7790
AD  - Division of Rheumatology and Systemic Inflammatory Diseases, University Hospital 
      Hamburg-Eppendorf (UKE), Hamburg, Germany. m.krusche@uke.de.
FAU - Callhoff, Johnna
AU  - Callhoff J
AUID- ORCID: 0000-0002-3923-2728
AD  - Epidemiology Unit, German Rheumatism Research Centre, Berlin, Germany.
AD  - Institute for Social Medicine, Epidemiology and Health Economics, Charité 
      Universitätsmedizin, Berlin, Germany.
FAU - Knitza, Johannes
AU  - Knitza J
AUID- ORCID: 0000-0001-9695-0657
AD  - Institute of Digital Medicine, University Hospital of Giessen and Marburg, 
      Philipps University Marburg, Marburg, Germany.
AD  - Université Grenoble Alpes, AGEIS, Grenoble, France.
FAU - Ruffer, Nikolas
AU  - Ruffer N
AUID- ORCID: 0000-0001-8394-969X
AD  - Division of Rheumatology and Systemic Inflammatory Diseases, University Hospital 
      Hamburg-Eppendorf (UKE), Hamburg, Germany.
LA  - eng
PT  - Journal Article
DEP - 20230924
PL  - Germany
TA  - Rheumatol Int
JT  - Rheumatology international
JID - 8206885
SB  - IM
MH  - Humans
MH  - *Rheumatology
MH  - Rheumatologists
PMC - PMC10796566
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Diagnostic process
OT  - Large language models
OT  - Rheumatology
OT  - Triage
EDAT- 2023/09/24 18:41
MHDA- 2024/01/19 06:42
PMCR- 2023/09/24
CRDT- 2023/09/24 15:09
PHST- 2023/08/21 00:00 [received]
PHST- 2023/09/07 00:00 [accepted]
PHST- 2024/01/19 06:42 [medline]
PHST- 2023/09/24 18:41 [pubmed]
PHST- 2023/09/24 15:09 [entrez]
PHST- 2023/09/24 00:00 [pmc-release]
AID - 10.1007/s00296-023-05464-6 [pii]
AID - 5464 [pii]
AID - 10.1007/s00296-023-05464-6 [doi]
PST - ppublish
SO  - Rheumatol Int. 2024 Feb;44(2):303-306. doi: 10.1007/s00296-023-05464-6. Epub 2023 
      Sep 24.

PMID- 37696742
OWN - NLM
STAT- Publisher
LR  - 20231014
IS  - 1934-8150 (Electronic)
IS  - 1551-7411 (Linking)
VI  - 19
IP  - 12
DP  - 2023 Dec
TI  - Assessing the accuracy and consistency of ChatGPT in clinical pharmacy 
      management: A preliminary analysis with clinical pharmacy experts worldwide.
PG  - 1590-1594
LID - S1551-7411(23)00365-0 [pii]
LID - 10.1016/j.sapharm.2023.08.012 [doi]
AB  - BACKGROUND: ChatGPT conversation system has ushered in a revolutionary new era of 
      information retrieval and stands as one of the fastest-growing platforms. 
      Clinical pharmacy, as a dynamic discipline, necessitates an advanced 
      comprehension of drugs and diseases. The process of decision-making in clinical 
      pharmacy demands accuracy and consistency in medical information, as it directly 
      affects patient safety. OBJECTIVE: The objective was to evaluate ChatGPT's 
      accuracy and consistency in managing pharmacotherapy cases across multiple time 
      points. Additionally, input was gathered from global clinical pharmacy experts, 
      and the agreement between ChatGPT's responses and those of clinical pharmacy 
      experts worldwide was assessed. METHODS: A set of 20 cases of pharmacotherapy was 
      entered into ChatGPT at three different time points. Reliability analysis was 
      performed using inter-rater reliability to measure the accuracy of the output 
      generated by ChatGPT at each time point. Test-retest reliability was performed to 
      measure the consistency of the output generated by ChatGPT across the three time 
      points. Pharmacy expert performance was evaluated, and the overall results were 
      compared. RESULTS: ChatGPT achieved a hit rate of 70.83% at week 1, 79.2% at week 
      3, and 75% at week 5. The percent agreement between weeks 1 and 3 was 79.2%, 
      whereas it was 87.5% between weeks 3 and 5, and 83.3% between weeks 1 and 5. In 
      contrast, accuracy rates among clinical pharmacy experts showed considerable 
      variation according to their geographic location. The highest agreement between 
      clinical pharmacist responses and ChatGPT responses was observed at the last time 
      point examined. CONCLUSIONS: Overall, the analysis suggested that ChatGPT is 
      capable of generating clinically relevant pharmaceutical information, albeit with 
      some variation in accuracy and consistency. It should be noted that clinical 
      pharmacy experts worldwide may provide varying degrees of accuracy depending on 
      their expertise. This study highlights the potential of AI chatbots in clinical 
      pharmacy.
CI  - Copyright © 2023 Elsevier Inc. All rights reserved.
FAU - Al-Dujaili, Zahraa
AU  - Al-Dujaili Z
AD  - College of Pharmacy, American University of Iraq - Baghdad (AUIB), Baghdad, Iraq.
FAU - Omari, Sarah
AU  - Omari S
AD  - Department of Epidemiology and Population Health, American University of Beirut 
      (AUB), Beirut, Lebanon.
FAU - Pillai, Jey
AU  - Pillai J
AD  - College of Pharmacy, American University of Iraq - Baghdad (AUIB), Baghdad, Iraq.
FAU - Al Faraj, Achraf
AU  - Al Faraj A
AD  - College of Pharmacy, American University of Iraq - Baghdad (AUIB), Baghdad, Iraq. 
      Electronic address: achraf.alfaraj@gmail.com.
LA  - eng
PT  - Journal Article
DEP - 20230907
PL  - United States
TA  - Res Social Adm Pharm
JT  - Research in social &amp; administrative pharmacy : RSAP
JID - 101231974
SB  - IM
OTO - NOTNLM
OT  - AI chatbot
OT  - ChatGPT
OT  - Clinical pharmacy
OT  - Decision making
OT  - Pharmacotherapy
COIS- Declaration of competing interest None.
EDAT- 2023/09/12 00:42
MHDA- 2023/09/12 00:42
CRDT- 2023/09/11 21:58
PHST- 2023/07/13 00:00 [received]
PHST- 2023/08/30 00:00 [revised]
PHST- 2023/08/30 00:00 [accepted]
PHST- 2023/09/12 00:42 [pubmed]
PHST- 2023/09/12 00:42 [medline]
PHST- 2023/09/11 21:58 [entrez]
AID - S1551-7411(23)00365-0 [pii]
AID - 10.1016/j.sapharm.2023.08.012 [doi]
PST - ppublish
SO  - Res Social Adm Pharm. 2023 Dec;19(12):1590-1594. doi: 
      10.1016/j.sapharm.2023.08.012. Epub 2023 Sep 7.

PMID- 38049066
OWN - NLM
STAT- MEDLINE
DCOM- 20240318
LR  - 20240318
IS  - 1544-3450 (Electronic)
IS  - 1086-5802 (Linking)
VI  - 64
IP  - 2
DP  - 2024 Mar-Apr
TI  - Effectiveness of ChatGPT in clinical pharmacy and the role of artificial 
      intelligence in medication therapy management.
PG  - 422-428.e8
LID - S1544-3191(23)00384-9 [pii]
LID - 10.1016/j.japh.2023.11.023 [doi]
AB  - BACKGROUND: The use of artificial intelligence (AI) to optimize medication 
      therapy management (MTM) in identifying drug interactions may potentially improve 
      MTM efficiency. ChatGPT, an AI language model, may be applied to identify 
      medication interventions by integrating patient and drug databases. ChatGPT has 
      been shown to be effective in other areas of clinical medicine, from diagnosis to 
      patient management. However, ChatGPT's ability to manage MTM related activities 
      is little known. OBJECTIVES: To evaluate the effectiveness of ChatGPT in MTM 
      services in simple, complex, and very complex cases to understand AI 
      contributions in MTM. METHODS: Two clinical pharmacists rated and validated the 
      difficulty of patient cases from simple, complex, and very complex. ChatGPT's 
      response to the cases was assessed based on 3 criteria: the ability to identify 
      drug interactions, precision in recommending alternatives, and appropriateness in 
      devising management plans. Two clinical pharmacists validated the accuracy of 
      ChatGPT's responses and compared them to actual answers for each complexity 
      level. RESULTS: ChatGPT 4.0 accurately solved 39 out of 39 (100 %) patient cases. 
      ChatGPT successfully identified drug interactions, provided therapy 
      recommendations and formulated general management plans, but it did not recommend 
      specific dosages. Results suggest it can assist pharmacists in formulating MTM 
      plans to improve overall efficiency. CONCLUSION: The application of ChatGPT in 
      MTM has the potential to enhance patient safety and involvement, lower healthcare 
      costs, and assist healthcare providers in medication management and identifying 
      drug interactions. Future pharmacists can utilize AI models such as ChatGPT to 
      improve patient care. The future of the pharmacy profession will depend on how 
      the field responds to the changing need for patient care optimized by AI and 
      automation.
CI  - Copyright © 2023 American Pharmacists Association®. Published by Elsevier Inc. 
      All rights reserved.
FAU - Roosan, Don
AU  - Roosan D
FAU - Padua, Pauline
AU  - Padua P
FAU - Khan, Raiyan
AU  - Khan R
FAU - Khan, Hasiba
AU  - Khan H
FAU - Verzosa, Claudia
AU  - Verzosa C
FAU - Wu, Yanting
AU  - Wu Y
LA  - eng
PT  - Journal Article
DEP - 20231202
PL  - United States
TA  - J Am Pharm Assoc (2003)
JT  - Journal of the American Pharmacists Association : JAPhA
JID - 101176252
SB  - IM
MH  - Humans
MH  - Medication Therapy Management
MH  - Artificial Intelligence
MH  - *Pharmacy Service, Hospital
MH  - *Pharmacy
MH  - Pharmacists
COIS- Disclosure The authors declare no relevant conflicts of interest or financial 
      relationships.
EDAT- 2023/12/05 00:42
MHDA- 2024/03/18 06:42
CRDT- 2023/12/04 19:26
PHST- 2023/04/23 00:00 [received]
PHST- 2023/10/27 00:00 [revised]
PHST- 2023/11/27 00:00 [accepted]
PHST- 2024/03/18 06:42 [medline]
PHST- 2023/12/05 00:42 [pubmed]
PHST- 2023/12/04 19:26 [entrez]
AID - S1544-3191(23)00384-9 [pii]
AID - 10.1016/j.japh.2023.11.023 [doi]
PST - ppublish
SO  - J Am Pharm Assoc (2003). 2024 Mar-Apr;64(2):422-428.e8. doi: 
      10.1016/j.japh.2023.11.023. Epub 2023 Dec 2.

PMID- 38424125
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240303
IS  - 2045-2322 (Electronic)
IS  - 2045-2322 (Linking)
VI  - 14
IP  - 1
DP  - 2024 Feb 29
TI  - Empirical assessment of ChatGPT's answering capabilities in natural science and 
      engineering.
PG  - 4998
LID - 10.1038/s41598-024-54936-7 [doi]
LID - 4998
AB  - ChatGPT is a powerful language model from OpenAI that is arguably able to 
      comprehend and generate text. ChatGPT is expected to greatly impact society, 
      research, and education. An essential step to understand ChatGPT's expected 
      impact is to study its domain-specific answering capabilities. Here, we perform a 
      systematic empirical assessment of its abilities to answer questions across the 
      natural science and engineering domains. We collected 594 questions on natural 
      science and engineering topics from 198 faculty members across five faculties at 
      Delft University of Technology. After collecting the answers from ChatGPT, the 
      participants assessed the quality of the answers using a systematic scheme. Our 
      results show that the answers from ChatGPT are, on average, perceived as "mostly 
      correct". Two major trends are that the rating of the ChatGPT answers 
      significantly decreases (i) as the educational level of the question increases 
      and (ii) as we evaluate skills beyond scientific knowledge, e.g., critical 
      attitude.
CI  - © 2024. The Author(s).
FAU - Schulze Balhorn, Lukas
AU  - Schulze Balhorn L
AD  - Delft University of Technology, Delft, The Netherlands.
FAU - Weber, Jana M
AU  - Weber JM
AD  - Delft University of Technology, Delft, The Netherlands.
FAU - Buijsman, Stefan
AU  - Buijsman S
AD  - Delft University of Technology, Delft, The Netherlands.
FAU - Hildebrandt, Julian R
AU  - Hildebrandt JR
AD  - Human-Computer Interaction Center, Chair of Communication Science, RWTH Aachen 
      University, Aachen, Germany.
FAU - Ziefle, Martina
AU  - Ziefle M
AD  - Human-Computer Interaction Center, Chair of Communication Science, RWTH Aachen 
      University, Aachen, Germany.
FAU - Schweidtmann, Artur M
AU  - Schweidtmann AM
AD  - Delft University of Technology, Delft, The Netherlands. 
      a.schweidtmann@tudelft.nl.
LA  - eng
PT  - Journal Article
DEP - 20240229
PL  - England
TA  - Sci Rep
JT  - Scientific reports
JID - 101563288
SB  - IM
PMC - PMC10904823
COIS- The authors declare no competing interests.
EDAT- 2024/03/01 01:27
MHDA- 2024/03/01 01:28
PMCR- 2024/02/29
CRDT- 2024/02/29 23:20
PHST- 2023/10/02 00:00 [received]
PHST- 2024/02/19 00:00 [accepted]
PHST- 2024/03/01 01:28 [medline]
PHST- 2024/03/01 01:27 [pubmed]
PHST- 2024/02/29 23:20 [entrez]
PHST- 2024/02/29 00:00 [pmc-release]
AID - 10.1038/s41598-024-54936-7 [pii]
AID - 54936 [pii]
AID - 10.1038/s41598-024-54936-7 [doi]
PST - epublish
SO  - Sci Rep. 2024 Feb 29;14(1):4998. doi: 10.1038/s41598-024-54936-7.

PMID- 37466157
OWN - NLM
STAT- MEDLINE
DCOM- 20230925
LR  - 20230925
IS  - 1469-0756 (Electronic)
IS  - 0032-5473 (Linking)
VI  - 99
IP  - 1176
DP  - 2023 Sep 21
TI  - The impact of Chat Generative Pre-trained Transformer (ChatGPT) on medical 
      education.
PG  - 1125-1127
LID - 10.1093/postmj/qgad058 [doi]
AB  - Artificial intelligence (AI) in medicine is developing rapidly. The advent of 
      Chat Generative Pre-trained Transformer (ChatGPT) has taken the world by storm 
      with its potential uses and efficiencies. However, technology leaders, 
      researchers, educators, and policy makers have also sounded the alarm on its 
      potential harms and unintended consequences. AI will increasingly find its way 
      into medicine and is a force of both disruption and innovation. We discuss the 
      potential benefits and limitations of this new league of technology and how 
      medical educators have to develop skills and curricula to best harness this 
      innovative power.
CI  - © The Author(s) 2023. Published by Oxford University Press on behalf of 
      Postgraduate Medical Journal. All rights reserved. For Permissions, please email: 
      journals.permissions@oup.com.
FAU - Heng, Jonathan J Y
AU  - Heng JJY
AD  - Yong Loo Lin School of Medicine, National University of Singapore, 117597, 
      Singapore.
FAU - Teo, Desmond B
AU  - Teo DB
AD  - Chronic and Fast Programmes, Alexandra Hospital, 159964, Singapore.
FAU - Tan, L F
AU  - Tan LF
AUID- ORCID: 0000-0003-1232-9308
AD  - Healthy Ageing Programme, Alexandra Hospital, 159964, Singapore.
LA  - eng
PT  - Journal Article
PL  - England
TA  - Postgrad Med J
JT  - Postgraduate medical journal
JID - 0234135
SB  - IM
MH  - Humans
MH  - Artificial Intelligence
MH  - *Education, Medical
MH  - *Medicine
MH  - Curriculum
MH  - Research Personnel
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - medical education
EDAT- 2023/07/19 13:06
MHDA- 2023/09/25 06:43
CRDT- 2023/07/19 07:03
PHST- 2023/05/10 00:00 [received]
PHST- 2023/05/25 00:00 [revised]
PHST- 2023/06/01 00:00 [accepted]
PHST- 2023/09/25 06:43 [medline]
PHST- 2023/07/19 13:06 [pubmed]
PHST- 2023/07/19 07:03 [entrez]
AID - 7225901 [pii]
AID - 10.1093/postmj/qgad058 [doi]
PST - ppublish
SO  - Postgrad Med J. 2023 Sep 21;99(1176):1125-1127. doi: 10.1093/postmj/qgad058.

PMID- 38291746
OWN - NLM
STAT- Publisher
LR  - 20240131
IS  - 2586-6583 (Print)
IS  - 2586-6591 (Linking)
DP  - 2024 Jan 31
TI  - Use of ChatGPT for determining Clinical and Surgical Treatment of Lumbar Disc 
      Herniation with Radiculopathy : A NASS Guideline Comparison.
LID - 10.14245/ns.2347052.526 [doi]
AB  - BACKGROUND: Large language models like ChatGPT have found success in various 
      sectors, but their application in the medical field remains limited. This study 
      aimed to assess the feasibility of using ChatGPT to provide accurate medical 
      information to patients, specifically evaluating how well ChatGPT versions 3.5 
      and 4.0 aligned with the 2012 North American Spine Society's (NASS) guidelines 
      for Lumbar Disk Herniation with Radiculopathy. METHODS: ChatGPT's responses to 
      questions based on the NASS guidelines were analyzed for accuracy. Three new 
      categories-over-conclusiveness, supplementary information, and 
      incompleteness-were introduced to deepen the analysis. Over-conclusiveness 
      referred to recommendations not mentioned in the NASS guidelines, supplementary 
      information denoted additional relevant details, and incompleteness indicated 
      omitted crucial information from the NASS guidelines. RESULTS: Out of 29 clinical 
      guidelines evaluated, ChatGPT 3.5 demonstrated accuracy in 15 (52%) responses, 
      while ChatGPT 4.0 achieved accuracy in 17 (59%) responses. ChatGPT 3.5 was 
      over-conclusive in 14 (48%) responses, while ChatGPT 4.0 exhibited 
      over-conclusiveness in 13 (45%) responses. Additionally, ChatGPT 3.5 provided 
      supplementary information in 24 (83%) responses, and ChatGPT 4.0 provided 
      supplemental information in 27 (93%) responses. In terms of incompleteness, 
      ChatGPT 3.5 displayed this in 11 (38%) responses, while ChatGPT 4.0 showed 
      incompleteness in 8 (23%) responses. CONCLUSION: ChatGPT shows promise for 
      clinical decision-making, but both patients and healthcare providers should 
      exercise caution to ensure safety and quality of care. While these results are 
      encouraging, further research is necessary to validate the use of large language 
      models in clinical settings.
FAU - Restrepo Mejia, Mateo
AU  - Restrepo Mejia M
AD  - Department of Orthopedic Surgery, Icahn School of Medicine at Mount Sinai, New 
      York, NY.
FAU - Arroyave, Juan Sebastian
AU  - Arroyave JS
AD  - Department of Orthopedic Surgery, Icahn School of Medicine at Mount Sinai, New 
      York, NY.
FAU - Saturno, Michael
AU  - Saturno M
AD  - Department of Orthopedic Surgery, Icahn School of Medicine at Mount Sinai, New 
      York, NY.
FAU - Mazudie Ndjonko, Laura Chelsea
AU  - Mazudie Ndjonko LC
AD  - Department of Orthopedic Surgery, Icahn School of Medicine at Mount Sinai, New 
      York, NY.
FAU - Zaidat, Bashar
AU  - Zaidat B
AD  - Department of Orthopedic Surgery, Icahn School of Medicine at Mount Sinai, New 
      York, NY.
FAU - Rajjoub, Rami
AU  - Rajjoub R
AD  - Department of Orthopedic Surgery, Icahn School of Medicine at Mount Sinai, New 
      York, NY.
FAU - Ahmed, Wasil
AU  - Ahmed W
AD  - Department of Orthopedic Surgery, Icahn School of Medicine at Mount Sinai, New 
      York, NY.
FAU - Zapolsky, Ivan
AU  - Zapolsky I
AD  - Department of Orthopedic Surgery, Icahn School of Medicine at Mount Sinai, New 
      York, NY.
FAU - Cho, Samuel K
AU  - Cho SK
AD  - Department of Orthopedic Surgery, Icahn School of Medicine at Mount Sinai, New 
      York, NY.
LA  - eng
PT  - Journal Article
DEP - 20240131
PL  - Korea (South)
TA  - Neurospine
JT  - Neurospine
JID - 101724936
OTO - NOTNLM
OT  - Artificial Intelligence
OT  - ChatGPT
OT  - Lumbar Disk Herniation with Radiculopathy
OT  - North American Spine Society Guidelines
OT  - Qualitative Study
EDAT- 2024/01/31 06:42
MHDA- 2024/01/31 06:42
CRDT- 2024/01/31 01:32
PHST- 2023/10/13 00:00 [received]
PHST- 2023/12/11 00:00 [accepted]
PHST- 2024/01/31 06:42 [medline]
PHST- 2024/01/31 06:42 [pubmed]
PHST- 2024/01/31 01:32 [entrez]
AID - ns.2347052.526 [pii]
AID - 10.14245/ns.2347052.526 [doi]
PST - aheadofprint
SO  - Neurospine. 2024 Jan 31. doi: 10.14245/ns.2347052.526.

PMID- 38401366
OWN - NLM
STAT- Publisher
LR  - 20240224
IS  - 1873-491X (Electronic)
IS  - 0020-7489 (Linking)
VI  - 153
DP  - 2024 Feb 8
TI  - Assessing question characteristic influences on ChatGPT's performance and 
      response-explanation consistency: Insights from Taiwan's Nursing Licensing Exam.
PG  - 104717
LID - S0020-7489(24)00029-4 [pii]
LID - 10.1016/j.ijnurstu.2024.104717 [doi]
AB  - BACKGROUND: Investigates the integration of an artificial intelligence tool, 
      specifically ChatGPT, in nursing education, addressing its effectiveness in exam 
      preparation and self-assessment. OBJECTIVE: This study aims to evaluate the 
      performance of ChatGPT, one of the most promising artificial intelligence-driven 
      linguistic understanding tools in answering question banks for nursing licensing 
      examination preparation. It further analyzes question characteristics that might 
      impact the accuracy of ChatGPT-generated answers and examines its reliability 
      through human expert reviews. DESIGN: Cross-sectional survey comparing 
      ChatGPT-generated answers and their explanations. SETTING: 400 questions from 
      Taiwan's 2022 Nursing Licensing Exam. METHODS: The study analyzed 400 questions 
      from five distinct subjects of Taiwan's 2022 Nursing Licensing Exam using the 
      ChatGPT model which provided answers and in-depth explanations for each question. 
      The impact of various question characteristics, such as type and cognitive level, 
      on the accuracy of the ChatGPT-generated responses was assessed using logistic 
      regression analysis. Additionally, human experts evaluated the explanations for 
      each question, comparing them with the ChatGPT-generated answers to determine 
      consistency. RESULTS: ChatGPT exhibited overall accuracy at 80.75 % for Taiwan's 
      National Nursing Exam, which passes the exam. The accuracy of ChatGPT-generated 
      answers diverged significantly across test subjects, demonstrating a hierarchy 
      ranging from General Medicine at 88.75 %, Medical-Surgical Nursing at 80.0 %, 
      Psychology and Community Nursing at 70.0 %, Obstetrics and Gynecology Nursing at 
      67.5 %, down to Basic Nursing at 63.0 %. ChatGPT had a higher probability of 
      eliciting incorrect responses for questions with certain characteristics, notably 
      those with clinical vignettes [odds ratio 2.19, 95 % confidence interval 
      1.24-3.87, P = 0.007] and complex multiple-choice questions [odds ratio 2.37, 
      95 % confidence interval 1.00-5.60, P = 0.049]. Furthermore, 14.25 % of 
      ChatGPT-generated answers were inconsistent with their explanations, leading to a 
      reduction in the overall accuracy to 74 %. CONCLUSIONS: This study reveals the 
      ChatGPT's capabilities and limitations in nursing exam preparation, underscoring 
      its potential as an auxiliary educational tool. It highlights the model's varied 
      performance across different question types and notable inconsistencies between 
      its answers and explanations. The study contributes significantly to the 
      understanding of artificial intelligence in learning environments, guiding the 
      future development of more effective and reliable artificial intelligence-based 
      educational technologies. TWEETABLE ABSTRACT: New study reveals ChatGPT's 
      potential and challenges in nursing education: Achieves 80.75 % accuracy in exam 
      prep but faces hurdles with complex questions and logical consistency. 
      #AIinNursing #AIinEducation #NursingExams #ChatGPT.
CI  - Copyright © 2024 Elsevier Ltd. All rights reserved.
FAU - Su, Mei-Chin
AU  - Su MC
AD  - Department of Nursing, Taipei Veterans General Hospital, Taipei, Taiwan.
FAU - Lin, Li-En
AU  - Lin LE
AD  - Big Data Center, Taipei Veterans General Hospital, Taipei, Taiwan.
FAU - Lin, Li-Hwa
AU  - Lin LH
AD  - Department of Nursing, Taipei Veterans General Hospital, Taipei, Taiwan; 
      Institute of Community Health Care, College of Nursing, National Yang Ming Chiao 
      Tung University, Taipei, Taiwan.
FAU - Chen, Yu-Chun
AU  - Chen YC
AD  - Big Data Center, Taipei Veterans General Hospital, Taipei, Taiwan; Institute of 
      Hospital and Health Care Administration, National Yang-Ming Chiao-Tung 
      University, Taipei, Taiwan; School of Medicine, National Yang-Ming Chiao-Tung 
      University, Taipei, Taiwan; Department of Family Medicine, Taipei Veterans 
      General Hospital, Taipei, Taiwan. Electronic address: yuchn.chen@gmail.com.
LA  - eng
PT  - Journal Article
DEP - 20240208
PL  - England
TA  - Int J Nurs Stud
JT  - International journal of nursing studies
JID - 0400675
SB  - IM
OTO - NOTNLM
OT  - Accuracy
OT  - Artificial intelligence language understanding tools
OT  - ChatGPT
OT  - ChatGPT-generated answers
OT  - Clinical vignettes
OT  - Consistency
OT  - Human-verification of explanations
OT  - Nursing license exam
OT  - Question bank
OT  - Question cognitive level
OT  - Question type
COIS- Declaration of Competing Interest The authors declared no conflicts of interest.
EDAT- 2024/02/25 00:42
MHDA- 2024/02/25 00:42
CRDT- 2024/02/24 18:10
PHST- 2023/08/13 00:00 [received]
PHST- 2024/01/25 00:00 [revised]
PHST- 2024/02/02 00:00 [accepted]
PHST- 2024/02/25 00:42 [medline]
PHST- 2024/02/25 00:42 [pubmed]
PHST- 2024/02/24 18:10 [entrez]
AID - S0020-7489(24)00029-4 [pii]
AID - 10.1016/j.ijnurstu.2024.104717 [doi]
PST - aheadofprint
SO  - Int J Nurs Stud. 2024 Feb 8;153:104717. doi: 10.1016/j.ijnurstu.2024.104717.

PMID- 37252576
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230531
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 4
DP  - 2023 Apr
TI  - A Case Study Demonstrating Applications of ChatGPT in the Clinical Management of 
      Treatment-Resistant Schizophrenia.
PG  - e38166
LID - 10.7759/cureus.38166 [doi]
LID - e38166
AB  - Chat Generative Pre-trained Transformer, also known as ChatGPT, is a new 
      artificial intelligence (AI) program that responds to user inquiry with discourse 
      resembling human language. The range of ChatGPT capabilities caught the interest 
      of the medical world after it demonstrated its ability to pass medical boards 
      examinations. In this case report, we present the clinical treatment of a 
      22-year-old male diagnosed with treatment-resistant schizophrenia (TRS) and 
      compare the medical management suggested by ChatGPT to current standards of care 
      in order to assess the program's ability to identify the disorder, evaluate 
      potential medical and psychiatric work-up, and develop a treatment plan 
      addressing the distinct nuances of our patient. In our inquiry with ChatGPT, we 
      found that it can accurately identify our patient as having TRS and order 
      appropriate tests to methodically rule out alternative causes of acute psychosis. 
      Furthermore, the AI program suggests pharmacologic treatment options including 
      clozapine with adjuvant medications, and nonpharmacologic treatment options 
      including electroconvulsive therapy (ECT), repetitive transcranial magnetic 
      stimulation (rTMS), and psychotherapy which align with current standards of care. 
      Lastly, ChatGPT provides a comprehensive list of side effects associated with 
      antipsychotics and mood stabilizers used to treat TRS. We found both potential 
      for and limitations in the clinical application of ChatGPT to assist in the 
      assessment and management of complex medical conditions. Overall, ChatGPT may 
      serve as a powerful tool to organize medical data in a meaningful and palatable 
      format for medical professionals to reference during patient care.
CI  - Copyright © 2023, Galido et al.
FAU - Galido, Pearl Valentine
AU  - Galido PV
AD  - Medicine, College of Osteopathic Medicine of the Pacific, Western University of 
      Health Sciences, Pomona, USA.
FAU - Butala, Saloni
AU  - Butala S
AD  - Medicine, College of Osteopathic Medicine of the Pacific, Western University of 
      Health Sciences, Pomona, USA.
FAU - Chakerian, Meg
AU  - Chakerian M
AD  - Medicine, College of Osteopathic Medicine of the Pacific, Western University of 
      Health Sciences, Pomona, USA.
FAU - Agustines, Davin
AU  - Agustines D
AD  - Psychiatry, Olive View-University of California Los Angeles Medical Center, 
      Sylmar, USA.
LA  - eng
PT  - Case Reports
DEP - 20230426
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10219639
OTO - NOTNLM
OT  - antipsychotics
OT  - artificial intelligence in medicine
OT  - chatgpt
OT  - psychosis
OT  - standard of care
OT  - treatment-resistant schizophrenia
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/05/30 13:07
MHDA- 2023/05/30 13:08
PMCR- 2023/04/26
CRDT- 2023/05/30 11:55
PHST- 2023/04/24 00:00 [accepted]
PHST- 2023/05/30 13:08 [medline]
PHST- 2023/05/30 13:07 [pubmed]
PHST- 2023/05/30 11:55 [entrez]
PHST- 2023/04/26 00:00 [pmc-release]
AID - 10.7759/cureus.38166 [doi]
PST - epublish
SO  - Cureus. 2023 Apr 26;15(4):e38166. doi: 10.7759/cureus.38166. eCollection 2023 
      Apr.

PMID- 38420978
OWN - NLM
STAT- MEDLINE
DCOM- 20240301
LR  - 20240301
IS  - 1565-1088 (Print)
VI  - 26
IP  - 2
DP  - 2024 Feb
TI  - Performance of ChatGPT in Israeli Hebrew Internal Medicine National Residency 
      Exam.
PG  - 86-88
AB  - BACKGROUND: Completing internal medicine specialty training in Israel involves 
      passing the Israel National Internal Medicine Exam (Shlav Aleph), a challenging 
      multiple-choice test. multiple-choice test. Chat generative pre-trained 
      transformer (ChatGPT) 3.5, a language model, is increasingly used for exam 
      preparation. OBJECTIVES: To assess the ability of ChatGPT 3.5 to pass the Israel 
      National Internal Medicine Exam in Hebrew. METHODS: Using the 2023 Shlav Aleph 
      exam questions, ChatGPT received prompts in Hebrew. Textual questions were 
      analyzed after the appeal, comparing its answers to the official key. RESULTS: 
      ChatGPT 3.5 correctly answered 36.6% of the 133 analyzed questions, with 
      consistent performance across topics, except for challenges in nephrology and 
      biostatistics. CONCLUSIONS: While ChatGPT 3.5 has excelled in English medical 
      exams, its performance in the Hebrew Shlav Aleph was suboptimal. Factors include 
      limited training data in Hebrew, translation complexities, and unique language 
      structures. Further investigation is essential for its effective adaptation to 
      Hebrew medical exam preparation.
FAU - Ozeri, David J
AU  - Ozeri DJ
AD  - Division of Rheumatology, Sheba Medical Center, Tel Hashomer, Israel.
FAU - Cohen, Adiel
AU  - Cohen A
AD  - Department of Obstetrics and Gynecology, Hadassah Medical Center, Faculty of 
      Medicine, Hebrew University of Jerusalem, Jerusalem, Israel.
FAU - Bacharach, Noa
AU  - Bacharach N
AD  - Department of Pediatrics, Leumit Health Services, Tel Aviv, Israel.
FAU - Ukashi, Offir
AU  - Ukashi O
AD  - Gastroenterology Institute, Sheba Medical Center, Tel Hashomer, Israel.
FAU - Oppenheim, Amit
AU  - Oppenheim A
AD  - Department of Medicine A, Sheba Medical Center, Tel Hashomer, Israel.
LA  - eng
PT  - Journal Article
PL  - Israel
TA  - Isr Med Assoc J
JT  - The Israel Medical Association journal : IMAJ
JID - 100930740
SB  - IM
MH  - Humans
MH  - *Internship and Residency
MH  - Israel
MH  - Biometry
MH  - Internal Medicine
MH  - Language
EDAT- 2024/02/29 12:42
MHDA- 2024/03/01 06:44
CRDT- 2024/02/29 08:45
PHST- 2024/03/01 06:44 [medline]
PHST- 2024/02/29 12:42 [pubmed]
PHST- 2024/02/29 08:45 [entrez]
PST - ppublish
SO  - Isr Med Assoc J. 2024 Feb;26(2):86-88.

PMID- 37464178
OWN - NLM
STAT- MEDLINE
DCOM- 20240315
LR  - 20240315
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 52
IP  - 4
DP  - 2024 Apr
TI  - Innovating Healthcare: The Role of ChatGPT in Streamlining Hospital Workflow in 
      the Future.
PG  - 750-753
LID - 10.1007/s10439-023-03323-w [doi]
AB  - ChatGPT is revolutionizing hospital workflows by enhancing the precision and 
      efficiency of tasks that were formerly the exclusive domain of healthcare 
      professionals. Additionally, ChatGPT can aid in administrative duties, including 
      appointment scheduling and billing, which enables healthcare professionals to 
      allocate more time towards patient care. By shouldering some of these 
      responsibilities, ChatGPT has the potential to advance the quality of patient 
      care, streamline departmental efficiency, and lower healthcare costs. 
      Nevertheless, it is crucial to strike a balance between the advantages of ChatGPT 
      and the necessity of human interaction in healthcare to guarantee optimal patient 
      care. While ChatGPT may assume some of the duties of physicians in particular 
      medical domains, it cannot replace human doctors. Tackling the challenges and 
      constraints associated with the integration of ChatGPT into the healthcare system 
      is critical for its successful implementation.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Zheng, Yue
AU  - Zheng Y
AUID- ORCID: 0000-0003-3865-7051
AD  - Cancer Center, West China Hospital, Sichuan University, Chengdu, 610041, Sichuan, 
      China.
FAU - Wang, Laduona
AU  - Wang L
AD  - Cancer Center, West China Hospital, Sichuan University, Chengdu, 610041, Sichuan, 
      China.
FAU - Feng, Baijie
AU  - Feng B
AD  - West China School of Medicine, Sichuan University, Chengdu, 610041, China.
FAU - Zhao, Ailin
AU  - Zhao A
AD  - Department of Hematology, West China Hospital, Sichuan University, Chengdu, 
      610041, Sichuan, China. irenez20@outlook.com.
FAU - Wu, Yijun
AU  - Wu Y
AD  - Cancer Center, West China Hospital, Sichuan University, Chengdu, 610041, Sichuan, 
      China. wuyj01029@wchscu.com.
LA  - eng
GR  - 2023NSFSC1885/Natural Science Foundation of Sichuan Province/
GR  - 2022SCUH0025/"from zero to one" Innovation Research Project of Sichuan 
      University/
GR  - 2022-YF05-01443-SN/Chengdu Science and Technology Program/
GR  - 23ZDYF2836/Key Research and Development Program of Sichuan Province/
GR  - 2021M692310/China Postdoctoral Science Foundation/
GR  - 82204490/National Natural Science Foundation of China/
PT  - Letter
DEP - 20230718
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - Humans
MH  - Workflow
MH  - *Hospitals
MH  - *Health Personnel
MH  - Delivery of Health Care
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Healthcare
OT  - Hospital Workflow
EDAT- 2023/07/19 01:06
MHDA- 2024/03/15 06:44
CRDT- 2023/07/18 23:32
PHST- 2023/07/11 00:00 [received]
PHST- 2023/07/13 00:00 [accepted]
PHST- 2024/03/15 06:44 [medline]
PHST- 2023/07/19 01:06 [pubmed]
PHST- 2023/07/18 23:32 [entrez]
AID - 10.1007/s10439-023-03323-w [pii]
AID - 10.1007/s10439-023-03323-w [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2024 Apr;52(4):750-753. doi: 10.1007/s10439-023-03323-w. Epub 
      2023 Jul 18.

PMID- 38252483
OWN - NLM
STAT- MEDLINE
DCOM- 20240123
LR  - 20240227
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 26
DP  - 2024 Jan 22
TI  - Uncovering Language Disparity of ChatGPT on Retinal Vascular Disease 
      Classification: Cross-Sectional Study.
PG  - e51926
LID - 10.2196/51926 [doi]
LID - e51926
AB  - BACKGROUND: Benefiting from rich knowledge and the exceptional ability to 
      understand text, large language models like ChatGPT have shown great potential in 
      English clinical environments. However, the performance of ChatGPT in non-English 
      clinical settings, as well as its reasoning, have not been explored in depth. 
      OBJECTIVE: This study aimed to evaluate ChatGPT's diagnostic performance and 
      inference abilities for retinal vascular diseases in a non-English clinical 
      environment. METHODS: In this cross-sectional study, we collected 1226 fundus 
      fluorescein angiography reports and corresponding diagnoses written in Chinese 
      and tested ChatGPT with 4 prompting strategies (direct diagnosis or diagnosis 
      with a step-by-step reasoning process and in Chinese or English). RESULTS: 
      Compared with ChatGPT using Chinese prompts for direct diagnosis that achieved an 
      F(1)-score of 70.47%, ChatGPT using English prompts for direct diagnosis achieved 
      the best diagnostic performance (80.05%), which was inferior to ophthalmologists 
      (89.35%) but close to ophthalmologist interns (82.69%). As for its inference 
      abilities, although ChatGPT can derive a reasoning process with a low error rate 
      (0.4 per report) for both Chinese and English prompts, ophthalmologists 
      identified that the latter brought more reasoning steps with less incompleteness 
      (44.31%), misinformation (1.96%), and hallucinations (0.59%) (all P&lt;.001). Also, 
      analysis of the robustness of ChatGPT with different language prompts indicated 
      significant differences in the recall (P=.03) and F(1)-score (P=.04) between 
      Chinese and English prompts. In short, when prompted in English, ChatGPT 
      exhibited enhanced diagnostic and inference capabilities for retinal vascular 
      disease classification based on Chinese fundus fluorescein angiography reports. 
      CONCLUSIONS: ChatGPT can serve as a helpful medical assistant to provide 
      diagnosis in non-English clinical environments, but there are still performance 
      gaps, language disparities, and errors compared to professionals, which 
      demonstrate the potential limitations and the need to continually explore more 
      robust large language models in ophthalmology practice.
CI  - ©Xiaocong Liu, Jiageng Wu, An Shao, Wenyue Shen, Panpan Ye, Yao Wang, Juan Ye, 
      Kai Jin, Jie Yang. Originally published in the Journal of Medical Internet 
      Research (https://www.jmir.org), 22.01.2024.
FAU - Liu, Xiaocong
AU  - Liu X
AUID- ORCID: 0000-0001-5323-2954
AD  - Eye Center, The Second Affiliated Hospital, Zhejiang University, Zhejiang, China.
AD  - School of Public Health, Zhejiang University School of Medicine, Zhejiang, China.
FAU - Wu, Jiageng
AU  - Wu J
AUID- ORCID: 0000-0003-0984-0818
AD  - School of Public Health, Zhejiang University School of Medicine, Zhejiang, China.
FAU - Shao, An
AU  - Shao A
AUID- ORCID: 0000-0002-1795-4877
AD  - Eye Center, The Second Affiliated Hospital, Zhejiang University, Zhejiang, China.
FAU - Shen, Wenyue
AU  - Shen W
AUID- ORCID: 0000-0002-1352-9419
AD  - Eye Center, The Second Affiliated Hospital, Zhejiang University, Zhejiang, China.
FAU - Ye, Panpan
AU  - Ye P
AUID- ORCID: 0000-0001-8165-023X
AD  - Eye Center, The Second Affiliated Hospital, Zhejiang University, Zhejiang, China.
FAU - Wang, Yao
AU  - Wang Y
AUID- ORCID: 0000-0002-7258-6093
AD  - Eye Center, The Second Affiliated Hospital, Zhejiang University, Zhejiang, China.
FAU - Ye, Juan
AU  - Ye J
AUID- ORCID: 0000-0002-1948-2500
AD  - Eye Center, The Second Affiliated Hospital, Zhejiang University, Zhejiang, China.
FAU - Jin, Kai
AU  - Jin K
AUID- ORCID: 0000-0003-4369-2417
AD  - Eye Center, The Second Affiliated Hospital, Zhejiang University, Zhejiang, China.
FAU - Yang, Jie
AU  - Yang J
AUID- ORCID: 0000-0001-5696-363X
AD  - School of Public Health, Zhejiang University School of Medicine, Zhejiang, China.
LA  - eng
PT  - Journal Article
DEP - 20240122
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - Cross-Sectional Studies
MH  - *Language
MH  - *Vascular Diseases/classification/diagnosis/diagnostic imaging
MH  - *Retinal Diseases/classification/diagnosis/diagnostic imaging
MH  - *Artificial Intelligence
MH  - *Fluorescein Angiography
MH  - *Diagnostic Errors
PMC - PMC10845019
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - clinical decision support
OT  - large language models
OT  - retinal vascular disease
COIS- Conflicts of Interest: None declared.
EDAT- 2024/01/22 12:42
MHDA- 2024/01/23 06:43
PMCR- 2024/01/22
CRDT- 2024/01/22 11:54
PHST- 2023/08/17 00:00 [received]
PHST- 2023/11/30 00:00 [accepted]
PHST- 2023/10/07 00:00 [revised]
PHST- 2024/01/23 06:43 [medline]
PHST- 2024/01/22 12:42 [pubmed]
PHST- 2024/01/22 11:54 [entrez]
PHST- 2024/01/22 00:00 [pmc-release]
AID - v26i1e51926 [pii]
AID - 10.2196/51926 [doi]
PST - epublish
SO  - J Med Internet Res. 2024 Jan 22;26:e51926. doi: 10.2196/51926.

PMID- 38416195
OWN - NLM
STAT- Publisher
LR  - 20240228
IS  - 1434-4726 (Electronic)
IS  - 0937-4477 (Linking)
DP  - 2024 Feb 28
TI  - ChatGPT vs. web search for patient questions: what does ChatGPT do better?
LID - 10.1007/s00405-024-08524-0 [doi]
AB  - PURPOSE: Chat generative pretrained transformer (ChatGPT) has the potential to 
      significantly impact how patients acquire medical information online. Here, we 
      characterize the readability and appropriateness of ChatGPT responses to a range 
      of patient questions compared to results from traditional web searches. METHODS: 
      Patient questions related to the published Clinical Practice Guidelines by the 
      American Academy of Otolaryngology-Head and Neck Surgery were sourced from 
      existing online posts. Questions were categorized using a modified Rothwell 
      classification system into (1) fact, (2) policy, and (3) diagnosis and 
      recommendations. These were queried using ChatGPT and traditional web search. All 
      results were evaluated on readability (Flesch Reading Ease and Flesch-Kinkaid 
      Grade Level) and understandability (Patient Education Materials Assessment Tool). 
      Accuracy was assessed by two blinded clinical evaluators using a three-point 
      ordinal scale. RESULTS: 54 questions were organized into fact (37.0%), policy 
      (37.0%), and diagnosis (25.8%). The average readability for ChatGPT responses was 
      lower than traditional web search (FRE: 42.3 ± 13.1 vs. 55.6 ± 10.5, p &lt; 0.001), 
      while the PEMAT understandability was equivalent (93.8% vs. 93.5%, p = 0.17). 
      ChatGPT scored higher than web search for questions the 'Diagnosis' category 
      (p &lt; 0.01); there was no difference in questions categorized as 'Fact' (p = 0.15) 
      or 'Policy' (p = 0.22). Additional prompting improved ChatGPT response 
      readability (FRE 55.6 ± 13.6, p &lt; 0.01). CONCLUSIONS: ChatGPT outperforms web 
      search in answering patient questions related to symptom-based diagnoses and is 
      equivalent in providing medical facts and established policy. Appropriate 
      prompting can further improve readability while maintaining accuracy. Further 
      patient education is needed to relay the benefits and limitations of this 
      technology as a source of medial information.
CI  - © 2024. The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, 
      part of Springer Nature.
FAU - Shen, Sarek A
AU  - Shen SA
AUID- ORCID: 0000-0001-6627-6139
AD  - Department of Otolaryngology-Head and Neck Surgery, Johns Hopkins School of 
      Medicine, 601 North Caroline Street, Baltimore, MD, 21287, USA. 
      sarek.shen@gmail.com.
FAU - Perez-Heydrich, Carlos A
AU  - Perez-Heydrich CA
AD  - Johns Hopkins School of Medicine, Baltimore, MD, USA.
FAU - Xie, Deborah X
AU  - Xie DX
AD  - Department of Otolaryngology-Head and Neck Surgery, Johns Hopkins School of 
      Medicine, 601 North Caroline Street, Baltimore, MD, 21287, USA.
FAU - Nellis, Jason C
AU  - Nellis JC
AD  - Department of Otolaryngology-Head and Neck Surgery, Johns Hopkins School of 
      Medicine, 601 North Caroline Street, Baltimore, MD, 21287, USA.
LA  - eng
GR  - 5T32DC000027-33/DC/NIDCD NIH HHS/United States
PT  - Journal Article
DEP - 20240228
PL  - Germany
TA  - Eur Arch Otorhinolaryngol
JT  - European archives of oto-rhino-laryngology : official journal of the European 
      Federation of Oto-Rhino-Laryngological Societies (EUFOS) : affiliated with the 
      German Society for Oto-Rhino-Laryngology - Head and Neck Surgery
JID - 9002937
SB  - IM
OTO - NOTNLM
OT  - Accessibility
OT  - Accuracy
OT  - ChatGPT
OT  - Large language model
OT  - Patient education
OT  - Patient questions
OT  - Readability
EDAT- 2024/02/28 12:43
MHDA- 2024/02/28 12:43
CRDT- 2024/02/28 11:06
PHST- 2023/12/18 00:00 [received]
PHST- 2024/01/31 00:00 [accepted]
PHST- 2024/02/28 12:43 [medline]
PHST- 2024/02/28 12:43 [pubmed]
PHST- 2024/02/28 11:06 [entrez]
AID - 10.1007/s00405-024-08524-0 [pii]
AID - 10.1007/s00405-024-08524-0 [doi]
PST - aheadofprint
SO  - Eur Arch Otorhinolaryngol. 2024 Feb 28. doi: 10.1007/s00405-024-08524-0.

PMID- 37490183
OWN - NLM
STAT- MEDLINE
DCOM- 20240315
LR  - 20240315
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 52
IP  - 4
DP  - 2024 Apr
TI  - How Does ChatGPT Perform on the Italian Residency Admission National Exam 
      Compared to 15,869 Medical Graduates?
PG  - 745-749
LID - 10.1007/s10439-023-03318-7 [doi]
AB  - PURPOSE: The study aims to assess ChatGPT performance on the Residency Admission 
      National Exam to evaluate ChatGPT's level of medical knowledge compared to 
      graduate medical doctors in Italy. METHODS: ChatGPT3 was used in June 2023 to 
      undertake the 2022 Italian Residency Admission National Exam-a 140 multiple 
      choice questions computer-based exam taken by all Italian medical graduates 
      yearly, used to assess basic science and applied medical knowledge. The exam was 
      scored using the same criteria defined by the national educational governing 
      body. The performance of ChatGPT was compared to the performance of the 15,869 
      medical graduates who took the exam in July 2022. Lastly, the integrity and 
      quality of ChatGPT's responses were evaluated. RESULTS: ChatGPT answered 
      correctly 122 out of 140 questions. The score ranked in the top 98.8(th) 
      percentile among 15,869 medical graduates. Among the 18 incorrect answers, 10 
      were evaluating direct questions on basic science medical knowledge, while 8 were 
      evaluating candidates' applied clinical knowledge and reasoning under the form of 
      case presentation. Errors were logical (2 incorrect answers) and informational in 
      nature (16 incorrect answers). Explanations to the correct answers were all 
      evaluated as "appropriate." Comparison to national statistics related to the 
      minimal score needed to match into each specialty, demonstrated that the 
      performance of ChatGPT would have granted the candidate a match into any 
      specialty. CONCLUSION: ChatGPT proved to be proficient in basic science medical 
      knowledge and applied clinical knowledge. Future research should assess the 
      impact and reliability of ChatGPT in clinical practice.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Alessandri Bonetti, Mario
AU  - Alessandri Bonetti M
AUID- ORCID: 0000-0002-5506-8323
AD  - Residency Program in Plastic Surgery, University of Milan, Via Festa del Perdono 
      7, 20122, Milan, Italy.
FAU - Giorgino, Riccardo
AU  - Giorgino R
AD  - Residency Program in Orthopedics and Traumatology, University of Milan, Via Festa 
      del Perdono 7, 20122, Milan, Italy.
FAU - Gallo Afflitto, Gabriele
AU  - Gallo Afflitto G
AD  - Residency Program in Ophthalmology, Università di Roma "Tor Vergata", Via 
      Cracovia 50, 00133, Rome, Italy.
FAU - De Lorenzi, Francesca
AU  - De Lorenzi F
AD  - Department of Plastic Surgery, European Institute of Oncology, Via Giuseppe 
      Ripamonti 345, 20122, Milan, Italy.
FAU - Egro, Francesco M
AU  - Egro FM
AUID- ORCID: 0000-0003-1536-7713
AD  - Department of Plastic Surgery, University of Pittsburgh Medical Center, 3550 
      Terrace Street 6B Scaife Hall, Pittsburgh, PA, 15261, USA. 
      francescoegro@gmail.com.
LA  - eng
PT  - Letter
DEP - 20230725
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - Humans
MH  - *Internship and Residency
MH  - Reproducibility of Results
MH  - Italy
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Education
OT  - Medical degree
OT  - Medical knowledge
OT  - Residency
EDAT- 2023/07/25 13:08
MHDA- 2024/03/15 06:43
CRDT- 2023/07/25 11:08
PHST- 2023/07/02 00:00 [received]
PHST- 2023/07/11 00:00 [accepted]
PHST- 2024/03/15 06:43 [medline]
PHST- 2023/07/25 13:08 [pubmed]
PHST- 2023/07/25 11:08 [entrez]
AID - 10.1007/s10439-023-03318-7 [pii]
AID - 10.1007/s10439-023-03318-7 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2024 Apr;52(4):745-749. doi: 10.1007/s10439-023-03318-7. Epub 
      2023 Jul 25.

PMID- 38249789
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240123
IS  - 2624-8212 (Electronic)
IS  - 2624-8212 (Linking)
VI  - 6
DP  - 2023
TI  - The scholarly footprint of ChatGPT: a bibliometric analysis of the early outbreak 
      phase.
PG  - 1270749
LID - 10.3389/frai.2023.1270749 [doi]
LID - 1270749
AB  - This paper presents a comprehensive analysis of the scholarly footprint of 
      ChatGPT, an AI language model, using bibliometric and scientometric methods. The 
      study zooms in on the early outbreak phase from when ChatGPT was launched in 
      November 2022 to early June 2023. It aims to understand the evolution of research 
      output, citation patterns, collaborative networks, application domains, and 
      future research directions related to ChatGPT. By retrieving data from the Scopus 
      database, 533 relevant articles were identified for analysis. The findings reveal 
      the prominent publication venues, influential authors, and countries contributing 
      to ChatGPT research. Collaborative networks among researchers and institutions 
      are visualized, highlighting patterns of co-authorship. The application domains 
      of ChatGPT, such as customer support and content generation, are examined. 
      Moreover, the study identifies emerging keywords and potential research areas for 
      future exploration. The methodology employed includes data extraction, 
      bibliometric analysis using various indicators, and visualization techniques such 
      as Sankey diagrams. The analysis provides valuable insights into ChatGPT's early 
      footprint in academia and offers researchers guidance for further advancements. 
      This study stimulates discussions, collaborations, and innovations to enhance 
      ChatGPT's capabilities and impact across domains.
CI  - Copyright © 2024 Farhat, Silva, Hassani, Madsen, Sohail, Himeur, Alam and Zafar.
FAU - Farhat, Faiza
AU  - Farhat F
AD  - Department of Zoology, Aligarh Muslim University, Aligarh, India.
FAU - Silva, Emmanuel Sirimal
AU  - Silva ES
AD  - Department of Economics and Law, Glasgow School for Business and Society, Glasgow 
      Caledonian University, Glasgow, United Kingdom.
FAU - Hassani, Hossein
AU  - Hassani H
AD  - The Research Institute of Energy Management and Planning (RIEMP), University of 
      Tehran, Tehran, Iran.
FAU - Madsen, Dag Øivind
AU  - Madsen DØ
AD  - USN School of Business, University of South-Eastern Norway, Hønefoss, Norway.
FAU - Sohail, Shahab Saquib
AU  - Sohail SS
AD  - Department of Computer Science and Engineering, School of Engineering Sciences 
      and Technology, Jamia Hamdard, New Delhi, India.
FAU - Himeur, Yassine
AU  - Himeur Y
AD  - College of Engineering and Information Technology, University of Dubai, Dubai, 
      United Arab Emirates.
FAU - Alam, M Afshar
AU  - Alam MA
AD  - Department of Computer Science and Engineering, School of Engineering Sciences 
      and Technology, Jamia Hamdard, New Delhi, India.
FAU - Zafar, Aasim
AU  - Zafar A
AD  - Department of Computer Science, Aligarh Muslim University, Aligarh, India.
LA  - eng
PT  - Systematic Review
DEP - 20240105
PL  - Switzerland
TA  - Front Artif Intell
JT  - Frontiers in artificial intelligence
JID - 101770551
PMC - PMC10797012
OTO - NOTNLM
OT  - ChatGPT
OT  - application domains
OT  - bibliometric analysis
OT  - citation analysis
OT  - collaborative networks
OT  - future directions
OT  - research trends
OT  - scientometric methods
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2024/01/22 06:42
MHDA- 2024/01/22 06:43
PMCR- 2024/01/05
CRDT- 2024/01/22 05:05
PHST- 2023/08/01 00:00 [received]
PHST- 2023/12/08 00:00 [accepted]
PHST- 2024/01/22 06:43 [medline]
PHST- 2024/01/22 06:42 [pubmed]
PHST- 2024/01/22 05:05 [entrez]
PHST- 2024/01/05 00:00 [pmc-release]
AID - 10.3389/frai.2023.1270749 [doi]
PST - epublish
SO  - Front Artif Intell. 2024 Jan 5;6:1270749. doi: 10.3389/frai.2023.1270749. 
      eCollection 2023.

PMID- 37577545
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231020
DP  - 2023 Aug 1
TI  - From Answers to Insights: Unveiling the Strengths and Limitations of ChatGPT and 
      Biomedical Knowledge Graphs.
LID - rs.3.rs-3185632 [pii]
LID - 10.21203/rs.3.rs-3185632/v1 [doi]
AB  - PURPOSE: Large Language Models (LLMs) have shown exceptional performance in 
      various natural language processing tasks, benefiting from their language 
      generation capabilities and ability to acquire knowledge from unstructured text. 
      However, in the biomedical domain, LLMs face limitations that lead to inaccurate 
      and inconsistent answers. Knowledge Graphs (KGs) have emerged as valuable 
      resources for organizing structured information. Biomedical Knowledge Graphs 
      (BKGs) have gained significant attention for managing diverse and large-scale 
      biomedical knowledge. The objective of this study is to assess and compare the 
      capabilities of ChatGPT and existing BKGs in question-answering, biomedical 
      knowledge discovery, and reasoning tasks within the biomedical domain. METHODS: 
      We conducted a series of experiments to assess the performance of ChatGPT and the 
      BKGs in various aspects of querying existing biomedical knowledge, knowledge 
      discovery, and knowledge reasoning. Firstly, we tasked ChatGPT with answering 
      questions sourced from the "Alternative Medicine" sub-category of Yahoo! Answers 
      and recorded the responses. Additionally, we queried BKG to retrieve the relevant 
      knowledge records corresponding to the questions and assessed them manually. In 
      another experiment, we formulated a prediction scenario to assess ChatGPT's 
      ability to suggest potential drug/dietary supplement repurposing candidates. 
      Simultaneously, we utilized BKG to perform link prediction for the same task. The 
      outcomes of ChatGPT and BKG were compared and analyzed. Furthermore, we evaluated 
      ChatGPT and BKG's capabilities in establishing associations between pairs of 
      proposed entities. This evaluation aimed to assess their reasoning abilities and 
      the extent to which they can infer connections within the knowledge domain. 
      RESULTS: The results indicate that ChatGPT with GPT-4.0 outperforms both GPT-3.5 
      and BKGs in providing existing information. However, BKGs demonstrate higher 
      reliability in terms of information accuracy. ChatGPT exhibits limitations in 
      performing novel discoveries and reasoning, particularly in establishing 
      structured links between entities compared to BKGs. CONCLUSIONS: To address the 
      limitations observed, future research should focus on integrating LLMs and BKGs 
      to leverage the strengths of both approaches. Such integration would optimize 
      task performance and mitigate potential risks, leading to advancements in 
      knowledge within the biomedical field and contributing to the overall well-being 
      of individuals.
FAU - Hou, Yu
AU  - Hou Y
AD  - University of Minnesota.
FAU - Yeung, Jeremy
AU  - Yeung J
AD  - University of Minnesota.
FAU - Xu, Hua
AU  - Xu H
AD  - Yale University.
FAU - Su, Chang
AU  - Su C
AD  - Temple University.
FAU - Wang, Fei
AU  - Wang F
AD  - Weill Cornell Medicine.
FAU - Zhang, Rui
AU  - Zhang R
AD  - University of Minnesota.
LA  - eng
GR  - R01 AG078154/AG/NIA NIH HHS/United States
PT  - Preprint
DEP - 20230801
PL  - United States
TA  - Res Sq
JT  - Research square
JID - 101768035
PMC - PMC10418534
OTO - NOTNLM
OT  - Biomedical Knowledge Graph (BKG)
OT  - ChatGPT
OT  - Large Language Models (LLMs)
COIS- Declarations Competing interests The authors declare that they have no competing 
      interests.
EDAT- 2023/08/14 06:41
MHDA- 2023/08/14 06:42
PMCR- 2023/08/11
CRDT- 2023/08/14 05:01
PHST- 2023/08/14 06:41 [pubmed]
PHST- 2023/08/14 06:42 [medline]
PHST- 2023/08/14 05:01 [entrez]
PHST- 2023/08/11 00:00 [pmc-release]
AID - rs.3.rs-3185632 [pii]
AID - 10.21203/rs.3.rs-3185632/v1 [doi]
PST - epublish
SO  - Res Sq [Preprint]. 2023 Aug 1:rs.3.rs-3185632. doi: 10.21203/rs.3.rs-3185632/v1.

PMID- 37776392
OWN - NLM
STAT- MEDLINE
DCOM- 20240214
LR  - 20240323
IS  - 1432-1068 (Electronic)
IS  - 1633-8065 (Print)
IS  - 1633-8065 (Linking)
VI  - 34
IP  - 2
DP  - 2024 Feb
TI  - Evaluating ChatGPT responses in the context of a 53-year-old male with a femoral 
      neck fracture: a qualitative analysis.
PG  - 927-955
LID - 10.1007/s00590-023-03742-4 [doi]
AB  - PURPOSE: The integration of artificial intelligence (AI) tools, such as ChatGPT, 
      in clinical medicine and medical education has gained significant attention due 
      to their potential to support decision-making and improve patient care. However, 
      there is a need to evaluate the benefits and limitations of these tools in 
      specific clinical scenarios. METHODS: This study used a case study approach 
      within the field of orthopaedic surgery. A clinical case report featuring a 
      53-year-old male with a femoral neck fracture was used as the basis for 
      evaluation. ChatGPT, a large language model, was asked to respond to clinical 
      questions related to the case. The responses generated by ChatGPT were evaluated 
      qualitatively, considering their relevance, justification, and alignment with the 
      responses of real clinicians. Alternative dialogue protocols were also employed 
      to assess the impact of additional prompts and contextual information on ChatGPT 
      responses. RESULTS: ChatGPT generally provided clinically appropriate responses 
      to the questions posed in the clinical case report. However, the level of 
      justification and explanation varied across the generated responses. 
      Occasionally, clinically inappropriate responses and inconsistencies were 
      observed in the generated responses across different dialogue protocols and on 
      separate days. CONCLUSIONS: The findings of this study highlight both the 
      potential and limitations of using ChatGPT in clinical practice. While ChatGPT 
      demonstrated the ability to provide relevant clinical information, the lack of 
      consistent justification and occasional clinically inappropriate responses raise 
      concerns about its reliability. These results underscore the importance of 
      careful consideration and validation when using AI tools in healthcare. Further 
      research and clinician training are necessary to effectively integrate AI tools 
      like ChatGPT, ensuring their safe and reliable use in clinical decision-making.
CI  - © 2023. The Author(s).
FAU - Zhou, Yushy
AU  - Zhou Y
AUID- ORCID: 0000-0002-2653-2107
AD  - Department of Surgery, The University of Melbourne, St. Vincent's Hospital 
      Melbourne, 29 Regent Street, Clinical Sciences Block Level 2, Melbourne, VIC, 
      3010, Australia. yushy.zhou@student.unimelb.edu.au.
AD  - Department of Orthopaedic Surgery, St. Vincent's Hospital, Melbourne, Australia. 
      yushy.zhou@student.unimelb.edu.au.
FAU - Moon, Charles
AU  - Moon C
AD  - Department of Orthopaedic Surgery, Cedars-Sinai Medical Centre, Los Angeles, CA, 
      USA.
FAU - Szatkowski, Jan
AU  - Szatkowski J
AD  - Department of Orthopaedic Surgery, Indiana University Health Methodist Hospital, 
      Indianapolis, IN, USA.
FAU - Moore, Derek
AU  - Moore D
AD  - Santa Barbara Orthopedic Associates, Santa Barbara, CA, USA.
FAU - Stevens, Jarrad
AU  - Stevens J
AD  - Department of Orthopaedic Surgery, St. Vincent's Hospital, Melbourne, Australia.
LA  - eng
PT  - Case Reports
PT  - Journal Article
DEP - 20230930
PL  - France
TA  - Eur J Orthop Surg Traumatol
JT  - European journal of orthopaedic surgery &amp; traumatology : orthopedie traumatologie
JID - 9518037
SB  - IM
MH  - Male
MH  - Humans
MH  - Middle Aged
MH  - Artificial Intelligence
MH  - Reproducibility of Results
MH  - *Femoral Neck Fractures/surgery
MH  - Clinical Decision-Making
MH  - *Orthopedic Procedures
PMC - PMC10858115
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Chatgpt
OT  - Clinical
OT  - Decision-making
OT  - Large language model
OT  - Orthopaedic surgery
COIS- DM is the Chief Executive Officer and Founder of OrthoBullets. No other conflicts 
      of interest.
EDAT- 2023/10/01 04:43
MHDA- 2024/02/10 10:47
PMCR- 2023/09/30
CRDT- 2023/09/30 11:07
PHST- 2023/08/14 00:00 [received]
PHST- 2023/09/18 00:00 [accepted]
PHST- 2024/02/10 10:47 [medline]
PHST- 2023/10/01 04:43 [pubmed]
PHST- 2023/09/30 11:07 [entrez]
PHST- 2023/09/30 00:00 [pmc-release]
AID - 10.1007/s00590-023-03742-4 [pii]
AID - 3742 [pii]
AID - 10.1007/s00590-023-03742-4 [doi]
PST - ppublish
SO  - Eur J Orthop Surg Traumatol. 2024 Feb;34(2):927-955. doi: 
      10.1007/s00590-023-03742-4. Epub 2023 Sep 30.

PMID- 37750052
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230928
IS  - 1179-1365 (Print)
IS  - 1179-1365 (Electronic)
IS  - 1179-1365 (Linking)
VI  - 15
DP  - 2023
TI  - Evaluating the Sensitivity, Specificity, and Accuracy of ChatGPT-3.5, ChatGPT-4, 
      Bing AI, and Bard Against Conventional Drug-Drug Interactions Clinical Tools.
PG  - 137-147
LID - 10.2147/DHPS.S425858 [doi]
AB  - BACKGROUND: AI platforms are equipped with advanced ‎algorithms that have the 
      potential to offer a wide range of ‎applications in healthcare services. However, 
      information about the accuracy of AI chatbots against ‎conventional drug-drug 
      interaction tools is limited‎. This study aimed to assess the sensitivity, 
      specificity, and accuracy of ChatGPT-3.5, ChatGPT-4, Bing AI, and Bard in 
      predicting drug-drug interactions. METHODS: AI-based chatbots (ie, ChatGPT-3.5, 
      ChatGPT-4, Microsoft Bing AI, and Google Bard) were compared for their abilities 
      to detect clinically relevant DDIs for 255 drug pairs. Descriptive statistics, 
      such as specificity, sensitivity, accuracy, negative predictive value (NPV), and 
      positive predictive value (PPV), were calculated for each tool. RESULTS: When a 
      subscription tool was used as a reference, the specificity ranged from a low of 
      0.372 (ChatGPT-3.5) to a high of 0.769 (Microsoft Bing AI). Also, Microsoft Bing 
      AI had the highest performance with an accuracy score of 0.788, with ChatGPT-3.5 
      having the lowest accuracy rate of 0.469. There was an overall improvement in 
      performance for all the programs when the reference tool switched to a free DDI 
      source, but still, ChatGPT-3.5 had the lowest specificity (0.392) and accuracy 
      (0.525), and Microsoft Bing AI demonstrated the highest specificity (0.892) and 
      accuracy (0.890). When assessing the consistency of accuracy across two different 
      drug classes, ChatGPT-3.5 and ChatGPT-4 showed the highest ‎variability in 
      accuracy. In addition, ChatGPT-3.5, ChatGPT-4, and Bard exhibited the highest 
      ‎fluctuations in specificity when analyzing two medications belonging to the same 
      drug class. CONCLUSION: Bing AI had the highest accuracy and specificity, 
      outperforming Google's Bard, ChatGPT-3.5, and ChatGPT-4. The findings highlight 
      the significant potential these AI tools hold in transforming patient care. While 
      the current AI platforms evaluated are not without limitations, their ability to 
      quickly analyze potentially significant interactions with good sensitivity 
      suggests a promising step towards improved patient safety.
CI  - © 2023 Al-Ashwal et al.
FAU - Al-Ashwal, Fahmi Y
AU  - Al-Ashwal FY
AUID- ORCID: 0000-0003-2076-0771
AD  - Department of Clinical Pharmacy and Pharmacy Practice, Faculty of Pharmacy, 
      University of Science and Technology, Sana'a, Yemen.
AD  - College of Pharmacy, Al-Ayen University, Thi-Qar, Iraq.
FAU - Zawiah, Mohammed
AU  - Zawiah M
AD  - Department of Pharmacy Practice, Faculty of Clinical Pharmacy, Hodeidah 
      University, Al Hodeidah, Yemen.
FAU - Gharaibeh, Lobna
AU  - Gharaibeh L
AD  - Pharmacological and Diagnostic Research Center, Faculty of Pharmacy, Al-Ahliyya 
      Amman University, Amman, Jordan.
FAU - Abu-Farha, Rana
AU  - Abu-Farha R
AUID- ORCID: 0000-0001-8298-4071
AD  - Clinical Pharmacy and Therapeutics Department, Faculty of Pharmacy, Applied 
      Science Private University, Amman, Jordan.
FAU - Bitar, Ahmad Naoras
AU  - Bitar AN
AUID- ORCID: 0000-0003-0125-2683
AD  - Department of Clinical Pharmacy, Faculty of Pharmacy and Biomedical Sciences, 
      Malaysian Allied Health Sciences Academy, Jenjarom, Selangor, 42610, Malaysia.
LA  - eng
PT  - Journal Article
DEP - 20230920
PL  - New Zealand
TA  - Drug Healthc Patient Saf
JT  - Drug, healthcare and patient safety
JID - 101544775
PMC - PMC10518176
OTO - NOTNLM
OT  - Bard‎
OT  - Bing AI
OT  - ChatGPT
OT  - accuracy
OT  - drug-drug interaction
OT  - patient safety
OT  - sensitivity
OT  - specificity
COIS- The authors report no conflicts of interest in this work.‎
EDAT- 2023/09/26 06:44
MHDA- 2023/09/26 06:45
PMCR- 2023/09/20
CRDT- 2023/09/26 03:34
PHST- 2023/07/11 00:00 [received]
PHST- 2023/09/09 00:00 [accepted]
PHST- 2023/09/26 06:45 [medline]
PHST- 2023/09/26 06:44 [pubmed]
PHST- 2023/09/26 03:34 [entrez]
PHST- 2023/09/20 00:00 [pmc-release]
AID - 425858 [pii]
AID - 10.2147/DHPS.S425858 [doi]
PST - epublish
SO  - Drug Healthc Patient Saf. 2023 Sep 20;15:137-147. doi: 10.2147/DHPS.S425858. 
      eCollection 2023.

PMID- 37323348
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230619
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 5
DP  - 2023 May
TI  - Genital and Extragenital Lichen Sclerosus et Atrophicus: A Case Series Written 
      Using ChatGPT.
PG  - e38987
LID - 10.7759/cureus.38987 [doi]
LID - e38987
AB  - Background Lichen sclerosus et atrophicus (LSEA) is a chronic inflammatory 
      dermatosis of genital and extragenital sites with a prevalence ranging from 9% in 
      prepubertal patients to 50% in postmenopausal patients. Chat generative 
      pre-trained transformer (ChatGPT) is an artificial intelligence tool designed to 
      assist humans based on supervised and reinforcement techniques. In this study, we 
      aimed to evaluate the characteristics of patients with LSEA using ChatGPT. 
      Methods In this retrospective study, we included all patients who presented to 
      the outpatient dermatology department during 2017-2022 at a tertiary care 
      teaching hospital in South India. Information regarding demographic data, 
      characteristics of LSEA, comorbidities, and associated autoimmune disorders was 
      gathered using a medical chart review. Following data analysis and drafting of 
      the manuscript, the utility of ChatGPT-3 and ChatGPT-4 in finalizing the draft 
      was assessed. Results Of 20 patients diagnosed with LSEA, 16 (80%) and four (20%) 
      patients were females and males, respectively. Of them, 50% of female patients 
      had attained menopause. While 65% of patients had genital LSEA, 30% of patients 
      had extragenital LSEA only, and 5% of patients had both genital and extragenital 
      LSEA. Furthermore, four (20%) patients were prepubertal children. Of four male 
      patients, two (50%) were younger than 18 years of age, and one patient was 
      diagnosed with balanitis xerotica obliterans. The commonest associated features 
      in LSEA included joint involvement (30%), hypertension (25%), and anemia (15%). 
      Rare concomitant disorders included&nbsp;psoriasis, asthma, and basal cell carcinoma 
      over the nose. Conclusions LSEA may be confused with other various dermatoses, 
      such as morphea, vitiligo, and lichen planus. A high index of suspicion is 
      required, especially in children, to diagnose it early and intervene to prevent 
      further complications. Its relationship with autoimmune disorders and 
      comorbidities warrants further large-scale studies. ChatGPT was unreliable in the 
      literature search due to the provision of non-existent citations. ChatGPT-4 was 
      better than ChatGPT-3 since it provided few true publications. ChatGPT was used 
      in this study to summarize the articles identified by the authors during the 
      literature search and to correct grammatical errors in the final draft of the 
      manuscript.
CI  - Copyright © 2023, P et al.
FAU - P, Pratibha J
AU  - P PJ
AD  - Department of Dermatology, St. John's Medical College, Bangalore, IND.
FAU - Prasad, Shruthi S
AU  - Prasad SS
AD  - Department of Dermatology, St. John's Medical College, Bangalore, IND.
FAU - Manohar, Naveen
AU  - Manohar N
AD  - Department of Dermatology, Belagavi Institute of Medical Sciences, Belagavi, IND.
LA  - eng
PT  - Journal Article
DEP - 20230513
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10261872
OTO - NOTNLM
OT  - artificial intelligence
OT  - autoimmune
OT  - chatgpt
OT  - depigmentation
OT  - extragenital
OT  - genital
OT  - lichen sclerosus et atrophicus
OT  - lsea
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/06/16 06:42
MHDA- 2023/06/16 06:43
PMCR- 2023/05/13
CRDT- 2023/06/16 03:57
PHST- 2023/05/13 00:00 [accepted]
PHST- 2023/06/16 06:43 [medline]
PHST- 2023/06/16 06:42 [pubmed]
PHST- 2023/06/16 03:57 [entrez]
PHST- 2023/05/13 00:00 [pmc-release]
AID - 10.7759/cureus.38987 [doi]
PST - epublish
SO  - Cureus. 2023 May 13;15(5):e38987. doi: 10.7759/cureus.38987. eCollection 2023 
      May.

PMID- 37033498
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230411
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 3
DP  - 2023 Mar
TI  - Extraventricular Neurocytoma of the Posterior Fossa: A Case Report Written by 
      ChatGPT.
PG  - e35850
LID - 10.7759/cureus.35850 [doi]
LID - e35850
AB  - ChatGPT (Chat Generative Pre-trained Transformer) is the latest artificial 
      intelligence (AI) tool that has taken the internet by storm. A large language 
      model-based AI tool, ChatGPT is used to generate natural prose-like answers 
      learning from a large database of text. A lot is being written and spoken about 
      the future of academic writing using this tool.We attempt to generate a short 
      case report of a brain tumour labelled extraventriuclar neurocytoma (EVN) which 
      is a rare tumour of the central nervous system. When posed with a set of 
      questions on this uncommon topic, ChatGPT did well with relevant but not very 
      specific answers. Validation of the information&nbsp;is an issue like with most 
      machine learning solutions. This case report is an attempt to summarise EVN and 
      its management. Q: Summarise extraventricular neurocytoma. ChatGPT: EVN is a rare 
      and benign tumor that typically occurs in the brain. It often causes no symptoms, 
      but as it grows, it can cause headaches, seizures, and changes in vision or 
      balance. Surgery is usually curative, but there is a lack of studies to know the 
      best treatment options. The prognosis is generally good with high rates of 
      long-term survival and low rates of recurrence. Text italicised in the article is 
      generated by ChatGPT.
CI  - Copyright © 2023, Hegde et al.
FAU - Hegde, Ajay
AU  - Hegde A
AD  - Neurosurgery, Kasturba Medical College, Manipal, IND.
FAU - Srinivasan, Siddharth
AU  - Srinivasan S
AD  - Neurosurgery, Kasturba Medical College, Manipal, IND.
FAU - Menon, Girish
AU  - Menon G
AD  - Neurosurgery, Kasturba Medical College, Manipal, IND.
LA  - eng
PT  - Case Reports
DEP - 20230306
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10076908
OTO - NOTNLM
OT  - artificial intelligence (ai)
OT  - brain tumour
OT  - chatgpt
OT  - extraventricular neurocytoma
OT  - neuro oncology
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/04/11 06:00
MHDA- 2023/04/11 06:01
PMCR- 2023/03/06
CRDT- 2023/04/10 03:54
PHST- 2023/03/05 00:00 [accepted]
PHST- 2023/04/11 06:01 [medline]
PHST- 2023/04/10 03:54 [entrez]
PHST- 2023/04/11 06:00 [pubmed]
PHST- 2023/03/06 00:00 [pmc-release]
AID - 10.7759/cureus.35850 [doi]
PST - epublish
SO  - Cureus. 2023 Mar 6;15(3):e35850. doi: 10.7759/cureus.35850. eCollection 2023 Mar.

PMID- 37954179
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231114
IS  - 1664-1078 (Print)
IS  - 1664-1078 (Electronic)
IS  - 1664-1078 (Linking)
VI  - 14
DP  - 2023
TI  - To use or not to use? Understanding doctoral students' acceptance of ChatGPT in 
      writing through technology acceptance model.
PG  - 1259531
LID - 10.3389/fpsyg.2023.1259531 [doi]
LID - 1259531
AB  - While artificial intelligence-based chatbots have demonstrated great potential 
      for writing, little is known about whether and how doctoral students accept the 
      use of ChatGPT in writing. Framed with Technology Acceptance Model, this study 
      investigated doctoral students' acceptance toward ChatGPT in writing and the 
      factors that influence it. The questionnaire survey revealed a high intention to 
      use ChatGPT in writing among doctoral students in China. The findings further 
      indicated that attitude was a significant predictor of behavioural intention to 
      use ChatGPT in writing and mediated the impacts of perceived usefulness and 
      perceived ease of use on it. Perceived ease of ChatGPT use was in turn influenced 
      by students' past ChatGPT use experience. This study provides powerful evidence 
      for the applicability of Technology Acceptance Model in the acceptance of ChatGPT 
      in writing. The results have significant implications for leveraging ChatGPT for 
      writing in higher education.
CI  - Copyright © 2023 Zou and Huang.
FAU - Zou, Min
AU  - Zou M
AD  - School of Foreign Languages, Beijing Institute of Technology, Beijing, China.
FAU - Huang, Liang
AU  - Huang L
AD  - Department of Public Administration, Southeast University, Nanjing, China.
LA  - eng
PT  - Journal Article
DEP - 20231026
PL  - Switzerland
TA  - Front Psychol
JT  - Frontiers in psychology
JID - 101550902
PMC - PMC10637381
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence-based chatbot
OT  - doctoral students
OT  - technology acceptance model
OT  - writing
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/11/13 06:43
MHDA- 2023/11/13 06:44
PMCR- 2023/10/26
CRDT- 2023/11/13 04:26
PHST- 2023/07/16 00:00 [received]
PHST- 2023/10/16 00:00 [accepted]
PHST- 2023/11/13 06:44 [medline]
PHST- 2023/11/13 06:43 [pubmed]
PHST- 2023/11/13 04:26 [entrez]
PHST- 2023/10/26 00:00 [pmc-release]
AID - 10.3389/fpsyg.2023.1259531 [doi]
PST - epublish
SO  - Front Psychol. 2023 Oct 26;14:1259531. doi: 10.3389/fpsyg.2023.1259531. 
      eCollection 2023.

PMID- 38213186
OWN - NLM
STAT- Publisher
LR  - 20240112
IS  - 1528-1159 (Electronic)
IS  - 0362-2436 (Linking)
DP  - 2024 Jan 12
TI  - Performance of ChatGPT on NASS Clinical Guidelines for the Diagnosis and 
      Treatment of Low Back Pain: A Comparison Study.
LID - 10.1097/BRS.0000000000004915 [doi]
AB  - STUDY DESIGN: Comparative analysis. OBJECTIVE: To evaluate ChatGPT's ability to 
      predict appropriate clinical recommendations based on the most recent clinical 
      guidelines for the diagnosis and treatment of low back pain. BACKGROUND: Low back 
      pain is a very common and often debilitating condition that affects many people 
      globally. Chat Generative Pre-trained Transformer (ChatGPT) is an artificial 
      intelligence model that may be able to generate recommendations for low back 
      pain. METHODS: Using the North American Spine Society Evidence-Based Clinical 
      Guidelines as the gold standard, 82 clinical questions relating to low back pain 
      were entered into ChatGPT (GPT-3.5) independently. For each question, we recorded 
      ChatGPT's answer, then used a point-answer system- the point being the guideline 
      recommendation and the answer being ChatGPT's response- and asked ChatGPT if the 
      point was mentioned in the answer to assess for accuracy. This response accuracy 
      was repeated with one caveat- a prior prompt is given in ChatGPT to answer as an 
      experienced orthopedic surgeon- for each question by guideline category. A 
      two-sample proportion z-test was used to assess any differences between the pre- 
      and post-prompt scenarios with alpha=0.05. RESULTS: ChatGPT's response was 
      accurate 65% (72% post-prompt, P=0.41) for guidelines with clinical 
      recommendations, 46% (58% post-prompt, P=0.11) for guidelines with insufficient 
      or conflicting data, and 49% (16% post-prompt, P=0.003*) for guidelines with no 
      adequate study to address the clinical question. For guidelines with insufficient 
      or conflicting data, 44% (25% post-prompt, P=0.01*) of ChatGPT responses wrongly 
      suggested that sufficient evidence existed. CONCLUSION: ChatGPT was able to 
      produce a sufficient clinical guideline recommendation for low back pain, with 
      overall improvements if initially prompted. However, it tended to wrongly suggest 
      evidence and often failed to mention, especially post-prompt, when there is not 
      enough evidence to adequately give an accurate recommendation.
CI  - Copyright © 2024 Wolters Kluwer Health, Inc. All rights reserved.
FAU - Shrestha, Nancy
AU  - Shrestha N
AD  - Chicago Medical School at Rosalind Franklin University, North Chicago, IL.
FAU - Shen, Zekun
AU  - Shen Z
AD  - Independent Scholar, New York, NY.
FAU - Zaidat, Bashar
AU  - Zaidat B
AD  - Icahn School of Medicine at Mount Sinai, New York, NY.
FAU - Duey, Akiro H
AU  - Duey AH
AD  - Icahn School of Medicine at Mount Sinai, New York, NY.
FAU - Tang, Justin E
AU  - Tang JE
AD  - Icahn School of Medicine at Mount Sinai, New York, NY.
FAU - Ahmed, Wasil
AU  - Ahmed W
AD  - Icahn School of Medicine at Mount Sinai, New York, NY.
FAU - Hoang, Timothy
AU  - Hoang T
AD  - Icahn School of Medicine at Mount Sinai, New York, NY.
FAU - Restrepo Mejia, Mateo
AU  - Restrepo Mejia M
AD  - Icahn School of Medicine at Mount Sinai, New York, NY.
FAU - Rajjoub, Rami
AU  - Rajjoub R
AD  - Icahn School of Medicine at Mount Sinai, New York, NY.
FAU - Markowitz, Jonathan S
AU  - Markowitz JS
AD  - Department of Orthopedics, Mount Sinai Health System, New York, NY.
FAU - Kim, Jun S
AU  - Kim JS
AD  - Department of Orthopedics, Mount Sinai Health System, New York, NY.
FAU - Cho, Samuel K
AU  - Cho SK
AD  - Department of Orthopedics, Mount Sinai Health System, New York, NY.
LA  - eng
PT  - Journal Article
DEP - 20240112
PL  - United States
TA  - Spine (Phila Pa 1976)
JT  - Spine
JID - 7610646
SB  - IM
COIS- Disclosures:Samuel K. Cho, MD, FAAOS. AAOS: Board or committee member. American 
      Orthopaedic Association: Board or committee member. AOSpine North America: Board 
      or committee member. Cerapedics: Fellowship support. Cervical Spine Research 
      Society: Board or committee member. Globus Medical: IP royalties, fellowship 
      support. North American Spine Society: Board or committee member. Scoliosis 
      Research Society: Board or committee member. Stryker: Paid consultant. Jun S. 
      Kim, MD. Stryker: Paid consultant. ATEC: Paid consultant. The following 
      individuals have no conflicts of interest or sources of support that require 
      acknowledgement: Nancy Shrestha, Zekun Shen, Akiro H. Duey, Bashar Zaidat, Justin 
      E. Tang, Wasil Ahmed, Timothy Hoang, Mateo Restrepo Mejia, Rami Rajjoub, Jonathan 
      S. Markowitz Study-Specific Conflicts of Interest: None
EDAT- 2024/01/12 06:42
MHDA- 2024/01/12 06:42
CRDT- 2024/01/12 02:53
PHST- 2023/09/19 00:00 [received]
PHST- 2023/12/14 00:00 [accepted]
PHST- 2024/01/12 06:42 [medline]
PHST- 2024/01/12 06:42 [pubmed]
PHST- 2024/01/12 02:53 [entrez]
AID - 00007632-990000000-00555 [pii]
AID - 10.1097/BRS.0000000000004915 [doi]
PST - aheadofprint
SO  - Spine (Phila Pa 1976). 2024 Jan 12. doi: 10.1097/BRS.0000000000004915.

PMID- 38479923
OWN - NLM
STAT- MEDLINE
DCOM- 20240315
LR  - 20240315
IS  - 2405-4577 (Electronic)
IS  - 2405-4577 (Linking)
VI  - 60
DP  - 2024 Apr
TI  - Decoding dietary myths: The role of ChatGPT in modern nutrition.
PG  - 285-288
LID - S2405-4577(24)00047-0 [pii]
LID - 10.1016/j.clnesp.2024.02.022 [doi]
AB  - In today's world, where nutrition forms the cornerstone of human health, the 
      potential harms of misinformation are concerning. Nutritional myths, whether 
      originating from age-old superstitions, misinterpreted scientific findings, or 
      commercial interests, can lead astray. In the digital age, the proliferation of 
      such misleading information is alarmingly accelerated, thanks to the dominance of 
      social media and search engines. Modern artificial intelligence tools, 
      exemplified by ChatGPT, promise a potential revolution in dispelling these 
      nutrition-related misconceptions. ChatGPT, by offering users immediate and 
      scientifically-backed information, aids in illuminating nutritional myths and 
      misconceptions. However, such AI models come with inherent limitations and 
      potential ethical concerns. Therefore, while tools like ChatGPT are undoubtedly 
      powerful, they are not a panacea. In conclusion, AI stands as a pivotal tool in 
      the dissemination of nutritional knowledge and debunking myths, but a careful and 
      critical approach must be adopted in its usage.
CI  - Copyright © 2024 European Society for Clinical Nutrition and Metabolism. 
      Published by Elsevier Ltd. All rights reserved.
FAU - Arslan, Sedat
AU  - Arslan S
AD  - Nutrition and Dietetics, Faculty of Health Science, Bandirma Onyedi Eylul 
      University, Balıkesir, Turkey. Electronic address: sarslan@bandirma.edu.tr.
LA  - eng
PT  - Journal Article
DEP - 20240223
PL  - England
TA  - Clin Nutr ESPEN
JT  - Clinical nutrition ESPEN
JID - 101654592
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Diet
MH  - Nutritional Status
MH  - Knowledge
OTO - NOTNLM
OT  - AI in healthcare
OT  - ChatGPT
OT  - Digital nutrition tools
OT  - Nutritional myths
COIS- Declaration of competing interest Authors have no conflict of interest to 
      disclose.
EDAT- 2024/03/14 00:43
MHDA- 2024/03/15 06:44
CRDT- 2024/03/13 21:57
PHST- 2023/09/11 00:00 [received]
PHST- 2024/02/06 00:00 [revised]
PHST- 2024/02/20 00:00 [accepted]
PHST- 2024/03/15 06:44 [medline]
PHST- 2024/03/14 00:43 [pubmed]
PHST- 2024/03/13 21:57 [entrez]
AID - S2405-4577(24)00047-0 [pii]
AID - 10.1016/j.clnesp.2024.02.022 [doi]
PST - ppublish
SO  - Clin Nutr ESPEN. 2024 Apr;60:285-288. doi: 10.1016/j.clnesp.2024.02.022. Epub 
      2024 Feb 23.

PMID- 38419805
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240301
IS  - 2673-253X (Electronic)
IS  - 2673-253X (Linking)
VI  - 6
DP  - 2024
TI  - Automating untruths: ChatGPT, self-managed medication abortion, and the threat of 
      misinformation in a post-Roe world.
PG  - 1287186
LID - 10.3389/fdgth.2024.1287186 [doi]
LID - 1287186
AB  - BACKGROUND: ChatGPT is a generative artificial intelligence chatbot that uses 
      natural language processing to understand and execute prompts in a human-like 
      manner. While the chatbot has become popular as a source of information among the 
      public, experts have expressed concerns about the number of false and misleading 
      statements made by ChatGPT. Many people search online for information about 
      self-managed medication abortion, which has become even more common following the 
      overturning of Roe v. Wade. It is likely that ChatGPT is also being used as a 
      source of this information; however, little is known about its accuracy. 
      OBJECTIVE: To assess the accuracy of ChatGPT responses to common questions 
      regarding self-managed abortion safety and the process of using abortion pills. 
      METHODS: We prompted ChatGPT with 65 questions about self-managed medication 
      abortion, which produced approximately 11,000 words of text. We qualitatively 
      coded all data in MAXQDA and performed thematic analysis. RESULTS: ChatGPT 
      responses correctly described clinician-managed medication abortion as both safe 
      and effective. In contrast, self-managed medication abortion was inaccurately 
      described as dangerous and associated with an increase in the risk of 
      complications, which was attributed to the lack of clinician supervision. 
      CONCLUSION: ChatGPT repeatedly provided responses that overstated the risk of 
      complications associated with self-managed medication abortion in ways that 
      directly contradict the expansive body of evidence demonstrating that 
      self-managed medication abortion is both safe and effective. The chatbot's 
      tendency to perpetuate health misinformation and associated stigma regarding 
      self-managed medication abortions poses a threat to public health and 
      reproductive autonomy.
CI  - © 2024 McMahon and McMahon.
FAU - McMahon, Hayley V
AU  - McMahon HV
AD  - Department of Behavioral, Social, and Health Education Sciences, Emory University 
      Rollins School of Public Health, Atlanta, GA, United States.
AD  - The Center for Reproductive Health Research in the Southeast, Emory University 
      Rollins School of Public Health, Atlanta, GA, United States.
FAU - McMahon, Bryan D
AU  - McMahon BD
AD  - Independent Researcher, Atlanta, GA, United States.
LA  - eng
PT  - Journal Article
DEP - 20240214
PL  - Switzerland
TA  - Front Digit Health
JT  - Frontiers in digital health
JID - 101771889
PMC - PMC10900507
OTO - NOTNLM
OT  - ChatGPT
OT  - generative artificial intelligence
OT  - health communication
OT  - health misinformation
OT  - reproductive health
OT  - self-managed abortion
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2024/02/29 06:43
MHDA- 2024/02/29 06:44
PMCR- 2024/02/14
CRDT- 2024/02/29 03:54
PHST- 2023/09/01 00:00 [received]
PHST- 2024/01/26 00:00 [accepted]
PHST- 2024/02/29 06:44 [medline]
PHST- 2024/02/29 06:43 [pubmed]
PHST- 2024/02/29 03:54 [entrez]
PHST- 2024/02/14 00:00 [pmc-release]
AID - 10.3389/fdgth.2024.1287186 [doi]
PST - epublish
SO  - Front Digit Health. 2024 Feb 14;6:1287186. doi: 10.3389/fdgth.2024.1287186. 
      eCollection 2024.

PMID- 37928033
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231107
IS  - 2405-8440 (Print)
IS  - 2405-8440 (Electronic)
IS  - 2405-8440 (Linking)
VI  - 9
IP  - 11
DP  - 2023 Nov
TI  - "Chatting with ChatGPT": Analyzing the factors influencing users' intention to 
      Use the Open AI's ChatGPT using the UTAUT model.
PG  - e20962
LID - 10.1016/j.heliyon.2023.e20962 [doi]
LID - e20962
AB  - Open AI's ChatGPT has emerged as a popular AI language model that can engage in 
      natural language conversations with users. Based on a qualitative research 
      approach using semistructured interviews with 32 ChatGPT users from India, this 
      study examined the factors influencing users' acceptance and use of ChatGPT using 
      the unified theory of acceptance and usage of technology (UTAUT) model. The study 
      results demonstrated that the four factors of UTAUT, along with two extended 
      constructs, i.e. perceived interactivity and privacy concerns, can explain users' 
      interaction and engagement with ChatGPT. The study also found that age and 
      experience can moderate the impact of various factors on the use of ChatGPT. The 
      theoretical and practical implications of the study were also discussed.
CI  - © 2023 The Author(s).
FAU - Menon, Devadas
AU  - Menon D
AD  - Development and Educational Communication Unit, Ahmedabad- 380056, India.
FAU - Shilpa, K
AU  - Shilpa K
AD  - Manipal Academy of Higher Education, Manipal, India.
LA  - eng
PT  - Journal Article
DEP - 20231018
PL  - England
TA  - Heliyon
JT  - Heliyon
JID - 101672560
PMC - PMC10623159
OTO - NOTNLM
OT  - Acceptance and use
OT  - ChatGPT
OT  - Chatbots
OT  - OpenAI
OT  - UTAUT
COIS- The authors declare that they have no known competing financial interests or 
      personal relationships that could have appeared to influence the work reported in 
      this paper.
EDAT- 2023/11/06 06:42
MHDA- 2023/11/06 06:43
PMCR- 2023/10/18
CRDT- 2023/11/06 04:27
PHST- 2023/04/18 00:00 [received]
PHST- 2023/10/11 00:00 [revised]
PHST- 2023/10/12 00:00 [accepted]
PHST- 2023/11/06 06:43 [medline]
PHST- 2023/11/06 06:42 [pubmed]
PHST- 2023/11/06 04:27 [entrez]
PHST- 2023/10/18 00:00 [pmc-release]
AID - S2405-8440(23)08170-7 [pii]
AID - e20962 [pii]
AID - 10.1016/j.heliyon.2023.e20962 [doi]
PST - epublish
SO  - Heliyon. 2023 Oct 18;9(11):e20962. doi: 10.1016/j.heliyon.2023.e20962. 
      eCollection 2023 Nov.

PMID- 38567408
OWN - NLM
STAT- Publisher
LR  - 20240403
IS  - 0260-1060 (Print)
IS  - 0260-1060 (Linking)
DP  - 2024 Apr 3
TI  - Examining the role of ChatGPT in promoting health behaviors and lifestyle changes 
      among cancer patients.
PG  - 2601060241244563
LID - 10.1177/02601060241244563 [doi]
AB  - Purpose: This study aims to investigate the role of ChatGPT in promoting health 
      behavioral changes among cancer patients. Methods: A quasi-experiment design with 
      qualitative approach was adopted in this study, as the ChatGPT technology is 
      novel, and many people are unaware of it. The participants included outpatients 
      at a public hospital. An experiment was carried out, where the participants used 
      ChatGPT for seeking cancer related information for two weeks, which is then 
      followed by focus group (FG) discussions. A total of 72 outpatients participated 
      in ten focus groups. Results: Three main themes with 14 sub-themes were 
      identified reflecting the role of ChatGPT in promoting health behavior changes. 
      Its prominent role was observed in developing health literacy, promoting 
      self-management of conditions through emotional, informational, motivational 
      support. Three challenges including privacy, lack of personalization, and 
      reliability issues were identified. Conclusion: Although ChatGPT has a huge 
      potential in promoting health behavior changes among cancer patients, its ability 
      is minimized by several factors such as regulatory, reliability, and privacy 
      issues. There is a need for further evidence to generalize the results across the 
      regions.
FAU - Alanezi, Fahad
AU  - Alanezi F
AUID- ORCID: 0000-0002-5458-7818
AD  - College of Business Administration, Department Management Information Systems, 
      Imam Abdulrahman Bin Faisal University, Dammam, Saudi Arabia. RINGGOLD: 48023
LA  - eng
PT  - Journal Article
DEP - 20240403
PL  - England
TA  - Nutr Health
JT  - Nutrition and health
JID - 8306569
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - awareness
OT  - behavior
OT  - cancer
OT  - challenges
OT  - lifestyle
COIS- Declaration of conflicting interestsThe author declared no potential conflicts of 
      interest with respect to the research, authorship, and/or publication of this 
      article.
EDAT- 2024/04/03 06:44
MHDA- 2024/04/03 06:44
CRDT- 2024/04/03 04:02
PHST- 2024/04/03 06:44 [medline]
PHST- 2024/04/03 06:44 [pubmed]
PHST- 2024/04/03 04:02 [entrez]
AID - 10.1177/02601060241244563 [doi]
PST - aheadofprint
SO  - Nutr Health. 2024 Apr 3:2601060241244563. doi: 10.1177/02601060241244563.

PMID- 38330745
OWN - NLM
STAT- Publisher
LR  - 20240208
IS  - 1878-0334 (Electronic)
IS  - 1871-4021 (Linking)
VI  - 18
IP  - 2
DP  - 2024 Feb 3
TI  - Exploring the potential of ChatGPT in the peer review process: An observational 
      study.
PG  - 102946
LID - S1871-4021(24)00007-9 [pii]
LID - 10.1016/j.dsx.2024.102946 [doi]
AB  - BACKGROUND: Peer review is the established method for evaluating the quality and 
      validity of research manuscripts in scholarly publishing. However, scientific 
      peer review faces challenges as the volume of submitted research has steadily 
      increased in recent years. Time constraints and peer review quality assurance can 
      place burdens on reviewers, potentially discouraging their participation. Some 
      artificial intelligence (AI) tools might assist in relieving these pressures. 
      This study explores the efficiency and effectiveness of one of the artificial 
      intelligence (AI) chatbots, ChatGPT (Generative Pre-trained Transformer), in the 
      peer review process. METHODS: Twenty-one peer-reviewed research articles were 
      anonymised to ensure unbiased evaluation. Each article was reviewed by two humans 
      and by versions 3.5 and 4.0 of ChatGPT. The AI was instructed to provide three 
      positive and three negative comments on the articles and recommend whether they 
      should be accepted or rejected. The human and AI results were compared using a 
      5-point Likert scale to determine the level of agreement. The correlation between 
      ChatGPT responses and the acceptance or rejection of the papers was also 
      examined. RESULTS: Subjective review similarity between human reviewers and 
      ChatGPT showed a mean score of 3.6/5 for ChatGPT 3.5 and 3.76/5 for ChatGPT 4.0. 
      The correlation between human and AI review scores was statistically significant 
      for ChatGPT 3.5, but not for ChatGPT 4.0. CONCLUSION: ChatGPT can complement 
      human scientific peer review, enhancing efficiency and promptness in the 
      editorial process. However, a fully automated AI review process is currently not 
      advisable, and ChatGPT's role should be regarded as highly constrained for the 
      present and near future.
CI  - Copyright © 2024 Research Trust of DiabetesIndia (DiabetesIndia) and National 
      Diabetes Obesity and Cholesterol Foundation (N-DOC). Published by Elsevier Ltd. 
      All rights reserved.
FAU - Saad, Ahmed
AU  - Saad A
AD  - Department of Orthopedics, Royal Orthopaedic Hospital, Birmingham, B31 2AP, UK. 
      Electronic address: Ahmed.saad3@nhs.net.
FAU - Jenko, Nathan
AU  - Jenko N
AD  - Department of Musculoskeletal Radiology, Royal Orthopaedic Hospital, Birmingham, 
      B31 2AP, UK. Electronic address: nathan.jenko@nhs.net.
FAU - Ariyaratne, Sisith
AU  - Ariyaratne S
AD  - Department of Musculoskeletal Radiology, Royal Orthopaedic Hospital, Birmingham, 
      B31 2AP, UK. Electronic address: sisithariyaratne@gmail.com.
FAU - Birch, Nick
AU  - Birch N
AD  - East Midlands Spine, Bragborough Hall Health &amp; Wellbeing Centre, Welton Road, 
      Braunston, Daventry, Northants, NN117JG, UK. Electronic address: 
      nickbirch@doctors.org.uk.
FAU - Iyengar, Karthikeyan P
AU  - Iyengar KP
AD  - Department of Orthopedics, Mersey and West Lancashire Teaching Hospitals NHS 
      Trust, Southport, PR8 6PN, UK. Electronic address: kartikp31@hotmail.com.
FAU - Davies, Arthur Mark
AU  - Davies AM
AD  - Department of Musculoskeletal Radiology, Royal Orthopaedic Hospital, Birmingham, 
      B31 2AP, UK. Electronic address: mark.davies8@nhs.net.
FAU - Vaishya, Raju
AU  - Vaishya R
AD  - Department of Orthopedics, Indraprastha Apollo Hospital, Mathura Rd, New Delhi, 
      110076, India. Electronic address: raju.vaishya@gmail.com.
FAU - Botchu, Rajesh
AU  - Botchu R
AD  - Department of Musculoskeletal Radiology, Royal Orthopaedic Hospital, Birmingham, 
      B31 2AP, UK. Electronic address: drbrajesh@yahoo.com.
LA  - eng
PT  - Journal Article
DEP - 20240203
PL  - Netherlands
TA  - Diabetes Metab Syndr
JT  - Diabetes &amp; metabolic syndrome
JID - 101462250
SB  - IM
OTO - NOTNLM
OT  - Algorithms
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Computers
OT  - Manuscript writing
OT  - Peer review
OT  - Scientific writing
COIS- Declaration of competing interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2024/02/09 00:42
MHDA- 2024/02/09 00:42
CRDT- 2024/02/08 18:10
PHST- 2023/10/21 00:00 [received]
PHST- 2024/01/09 00:00 [revised]
PHST- 2024/01/10 00:00 [accepted]
PHST- 2024/02/09 00:42 [medline]
PHST- 2024/02/09 00:42 [pubmed]
PHST- 2024/02/08 18:10 [entrez]
AID - S1871-4021(24)00007-9 [pii]
AID - 10.1016/j.dsx.2024.102946 [doi]
PST - aheadofprint
SO  - Diabetes Metab Syndr. 2024 Feb 3;18(2):102946. doi: 10.1016/j.dsx.2024.102946.

PMID- 37933835
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240106
IS  - 2980-1478 (Electronic)
IS  - 2980-1478 (Linking)
VI  - 49
IP  - 6
DP  - 2023 Nov
TI  - Assessing the Performance of Chat Generative Pretrained Transformer (ChatGPT) in 
      Answering Andrology-Related Questions.
PG  - 365-369
LID - 10.5152/tud.2023.23171 [doi]
AB  - OBJECTIVE: The internet and social media have become primary sources of health 
      information, with men frequently turning to these platforms before seeking 
      professional help. Chat generative pretrained transformer (ChatGPT), an 
      artificial intelligence model developed by OpenAI, has gained popularity as a 
      natural language processing program. The present study evaluated the accuracy and 
      reproducibility of ChatGPT's responses to andrology-related questions. METHODS: 
      The study analyzed frequently asked andrology questions from health forums, 
      hospital websites, and social media platforms like YouTube and Instagram. 
      Questions were categorized into topics like male hypogonadism, erectile 
      dysfunction, etc. The European Association of Urology (EAU) guideline 
      recommendations were also included. These questions were input into ChatGPT, and 
      responses were evaluated by 3 experienced urologists who scored them on a scale 
      of 1 to 4. RESULTS: Out of 136 evaluated questions, 108 met the criteria. Of 
      these, 87.9% received correct and adequate answers, 9.3% were correct but 
      insufficient, and 3 responses contained both correct and incorrect information. 
      No question was answered completely wrong. The highest correct answer rates were 
      for disorders of ejaculation, penile curvature, and male hypogonadism. The EAU 
      guideline-based questions achieved a correctness rate of 86.3%. The 
      reproducibility of the answers was over 90%. CONCLUSION: The study found that 
      ChatGPT provided accurate and reliable answers to over 80% of andrology-related 
      questions. While limitations exist, such as potential outdated data and inability 
      to understand emotional aspects, ChatGPT's potential in the health-care sector is 
      promising. Collaborating with health-care professionals during artificial 
      intelligence model development could enhance its reliability.
FAU - Caglar, Ufuk
AU  - Caglar U
AD  - Department of Urology, Haseki Training and Research Hospital, Istanbul, Turkey.
FAU - Yildiz, Oguzhan
AU  - Yildiz O
AD  - Department of Urology, Haseki Training and Research Hospital, Istanbul, Turkey.
FAU - Ozervarli, M Fırat
AU  - Ozervarli MF
AD  - Department of Urology, Istanbul University, Istanbul School of Medicine, 
      Istanbul, Turkey.
FAU - Aydin, Resat
AU  - Aydin R
AD  - Department of Urology, Istanbul University, Istanbul School of Medicine, 
      Istanbul, Turkey.
FAU - Sarilar, Omer
AU  - Sarilar O
AD  - Department of Urology, Haseki Training and Research Hospital, Istanbul, Turkey.
FAU - Ozgor, Faruk
AU  - Ozgor F
AD  - Department of Urology, Haseki Training and Research Hospital, Istanbul, Turkey.
FAU - Ortac, Mazhar
AU  - Ortac M
AD  - Department of Urology, Istanbul University, Istanbul School of Medicine, 
      Istanbul, Turkey.
LA  - eng
PT  - Journal Article
PL  - Turkey
TA  - Urol Res Pract
JT  - Urology research &amp; practice
JID - 9918608789006676
PMC - PMC10765186
EDAT- 2023/11/07 12:42
MHDA- 2023/11/07 12:43
PMCR- 2023/11/01
CRDT- 2023/11/07 07:53
PHST- 2023/11/07 12:43 [medline]
PHST- 2023/11/07 12:42 [pubmed]
PHST- 2023/11/07 07:53 [entrez]
PHST- 2023/11/01 00:00 [pmc-release]
AID - urp-49-6-365 [pii]
AID - 10.5152/tud.2023.23171 [doi]
PST - ppublish
SO  - Urol Res Pract. 2023 Nov;49(6):365-369. doi: 10.5152/tud.2023.23171.

PMID- 37905713
OWN - NLM
STAT- MEDLINE
DCOM- 20240320
LR  - 20240320
IS  - 1445-2197 (Electronic)
IS  - 1445-1433 (Linking)
VI  - 94
IP  - 3
DP  - 2024 Mar
TI  - Conversational artificial intelligence (chatGPT™) in the management of complex 
      colorectal cancer patients: early experience.
PG  - 356-361
LID - 10.1111/ans.18749 [doi]
AB  - INTRODUCTION: In 2022 chatGPT™ (OpenAI, San Francisco) was introduced to the 
      public. The complex reasoning and the natural language processing (NLP) ability 
      of the AI platform has generated much excitement about the potential 
      applications. This study conducted a preliminary analysis of the chatGPT™'s 
      ability to formulate a management plan in accordance with oncological principles 
      for patients with colorectal cancer. METHODOLOGY: Colorectal cancer cases 
      discussed in the multidisciplinary tumor (MDT) board at a single tertiary 
      institution between September 2022 and January 2023 were prospectively collected. 
      The treatment recommendations made by the chatGPT™ for Stage IV, recurrent, 
      synchronous colorectal cancer were analysed for adherence to oncological 
      principles. The recommendations by chatGPT™ were compared with the decision plans 
      made by the MDT. RESULTS: In all cases, the chatGPT™ was able to adhere to 
      oncological principles. The recommendations in all 30 cases factored in the 
      patient's overall health and functional status. The oncological management 
      recommendation concordance rate between chatGPT™ and the MDT was 86.7%. 
      CONCLUSIONS: This study shows a high concordance rate of the chatGPT™'s 
      recommendations with that given by the MDT in the management of complex 
      colorectal patients. This will need to be verified in a larger prospective study.
CI  - © 2023 Royal Australasian College of Surgeons.
FAU - Choo, Jeong Min
AU  - Choo JM
AD  - Korea University Anam Hospital, Division of Colon and Rectal Surgery, Department 
      of Surgery, Korea University College of Medicine, Seoul, South Korea.
FAU - Ryu, Hyo Seon
AU  - Ryu HS
AD  - Korea University Anam Hospital, Division of Colon and Rectal Surgery, Department 
      of Surgery, Korea University College of Medicine, Seoul, South Korea.
FAU - Kim, Ji Seon
AU  - Kim JS
AD  - Korea University Anam Hospital, Division of Colon and Rectal Surgery, Department 
      of Surgery, Korea University College of Medicine, Seoul, South Korea.
FAU - Cheong, Ju Yong
AU  - Cheong JY
AUID- ORCID: 0000-0002-1600-7632
AD  - Korea University Anam Hospital, Division of Colon and Rectal Surgery, Department 
      of Surgery, Korea University College of Medicine, Seoul, South Korea.
FAU - Baek, Se-Jin
AU  - Baek SJ
AUID- ORCID: 0000-0002-3185-8777
AD  - Korea University Anam Hospital, Division of Colon and Rectal Surgery, Department 
      of Surgery, Korea University College of Medicine, Seoul, South Korea.
FAU - Kwak, Jung Myun
AU  - Kwak JM
AD  - Korea University Anam Hospital, Division of Colon and Rectal Surgery, Department 
      of Surgery, Korea University College of Medicine, Seoul, South Korea.
FAU - Kim, Jin
AU  - Kim J
AUID- ORCID: 0000-0001-6479-9673
AD  - Korea University Anam Hospital, Division of Colon and Rectal Surgery, Department 
      of Surgery, Korea University College of Medicine, Seoul, South Korea.
LA  - eng
PT  - Journal Article
DEP - 20231031
PL  - Australia
TA  - ANZ J Surg
JT  - ANZ journal of surgery
JID - 101086634
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Prospective Studies
MH  - *Colorectal Neoplasms/therapy
MH  - Patient Care Team
OTO - NOTNLM
OT  - artificial intelligence
OT  - chatGPT™
OT  - colorectal cancer
OT  - multidisciplinary tumour board
EDAT- 2023/10/31 12:42
MHDA- 2024/03/20 06:45
CRDT- 2023/10/31 07:33
PHST- 2023/10/05 00:00 [revised]
PHST- 2023/03/31 00:00 [received]
PHST- 2023/10/13 00:00 [accepted]
PHST- 2024/03/20 06:45 [medline]
PHST- 2023/10/31 12:42 [pubmed]
PHST- 2023/10/31 07:33 [entrez]
AID - 10.1111/ans.18749 [doi]
PST - ppublish
SO  - ANZ J Surg. 2024 Mar;94(3):356-361. doi: 10.1111/ans.18749. Epub 2023 Oct 31.

PMID- 37456381
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230718
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 6
DP  - 2023 Jun
TI  - Snakebite Advice and Counseling From Artificial Intelligence: An Acute Venomous 
      Snakebite Consultation With ChatGPT.
PG  - e40351
LID - 10.7759/cureus.40351 [doi]
LID - e40351
AB  - BACKGROUND: Snakebites, particularly from venomous species, present a significant 
      global public health challenge. Access to accurate and timely information 
      regarding snakebite prevention, recognition, and management is crucial for 
      minimizing morbidity and mortality. Artificial intelligence (AI) language models, 
      such as&nbsp;ChatGPT (Chat Generative Pre-trained Transformer), have the potential to 
      revolutionize the dissemination of medical information and improve patient 
      education and satisfaction. METHODS: This study aimed to explore the utility of 
      ChatGPT, an advanced language model, in simulating acute venomous snakebite 
      consultations. Nine hypothetical questions based on comprehensive snakebite 
      management guidelines were posed to ChatGPT, and the responses were evaluated by 
      clinical toxicologists and emergency medicine physicians. RESULTS: ChatGPT 
      provided accurate and informative responses related to the immediate management 
      of snakebites, the urgency of seeking medical attention, symptoms, and health 
      issues following venomous snakebites, the role of antivenom, misconceptions about 
      snakebites, recovery, pain management, and prevention strategies. The model 
      highlighted the importance of seeking professional medical care and adhering to 
      healthcare practitioners' advice. However, some limitations were identified, 
      including outdated knowledge, lack of personalization, and inability to consider 
      regional variations and individual characteristics. CONCLUSION: ChatGPT 
      demonstrated proficiency in generating intelligible and well-informed responses 
      related to venomous snakebites. It offers accessible and real-time advice, making 
      it a valuable resource for preliminary information, education, and triage support 
      in remote or underserved areas. While acknowledging its limitations, such as the 
      need for up-to-date information and personalized advice, ChatGPT can serve as a 
      supplementary source of information to complement professional medical 
      consultation and enhance patient education. Future research should focus on 
      addressing the identified limitations and establishing region-specific guidelines 
      for snakebite management.
CI  - Copyright © 2023, Altamimi et al.
FAU - Altamimi, Ibraheem
AU  - Altamimi I
AD  - College of Medicine, King Saud University, Riyadh, SAU.
FAU - Altamimi, Abdullah
AU  - Altamimi A
AD  - Pediatric Emergency and Toxicology Department, King Fahd Medical City, Riyadh, 
      SAU.
FAU - Alhumimidi, Abdullah S
AU  - Alhumimidi AS
AD  - College of Medicine, King Saud University, Riyadh, SAU.
FAU - Altamimi, Abdulaziz
AU  - Altamimi A
AD  - College of Medicine, King Saud Bin Abdulaziz University for Health Sciences, 
      Riyadh, SAU.
FAU - Temsah, Mohamad-Hani
AU  - Temsah MH
AD  - Pediatric Intensive Care Unit, Pediatric Department, King Saud University Medical 
      City, Riyadh, SAU.
LA  - eng
PT  - Journal Article
DEP - 20230613
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10339276
OTO - NOTNLM
OT  - acute venomous snakebite
OT  - ai and machine learning
OT  - ai chatbot
OT  - artificial intelligence and education
OT  - artificial intelligence in healthcare
OT  - chatgpt
OT  - emergency medicine
OT  - medical artificial intelligence
OT  - snake-bite
OT  - toxicology and envenomation
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/07/17 06:42
MHDA- 2023/07/17 06:43
PMCR- 2023/06/13
CRDT- 2023/07/17 04:23
PHST- 2023/06/13 00:00 [accepted]
PHST- 2023/07/17 06:43 [medline]
PHST- 2023/07/17 06:42 [pubmed]
PHST- 2023/07/17 04:23 [entrez]
PHST- 2023/06/13 00:00 [pmc-release]
AID - 10.7759/cureus.40351 [doi]
PST - epublish
SO  - Cureus. 2023 Jun 13;15(6):e40351. doi: 10.7759/cureus.40351. eCollection 2023 
      Jun.

PMID- 38243605
OWN - NLM
STAT- Publisher
LR  - 20240123
IS  - 1754-9485 (Electronic)
IS  - 1754-9477 (Linking)
DP  - 2024 Jan 19
TI  - Current applications and future potential of ChatGPT in radiology: A systematic 
      review.
LID - 10.1111/1754-9485.13621 [doi]
AB  - This study aimed to comprehensively evaluate the current utilization and future 
      potential of ChatGPT, an AI-based chat model, in the field of radiology. The 
      primary focus is on its role in enhancing decision-making processes, optimizing 
      workflow efficiency, and fostering interdisciplinary collaboration and teaching 
      within healthcare. A systematic search was conducted in PubMed, EMBASE and Web of 
      Science databases. Key aspects, such as its impact on complex decision-making, 
      workflow enhancement and collaboration, were assessed. Limitations and challenges 
      associated with ChatGPT implementation were also examined. Overall, six studies 
      met the inclusion criteria and were included in our analysis. All studies were 
      prospective in nature. A total of 551 chatGPT (version 3.0 to 4.0) assessment 
      events were included in our analysis. Considering the generation of academic 
      papers, ChatGPT was found to output data inaccuracies 80% of the time. When 
      ChatGPT was asked questions regarding common interventional radiology procedures, 
      it contained entirely incorrect information 45% of the time. ChatGPT was seen to 
      better answer US board-style questions when lower order thinking was required 
      (P = 0.002). Improvements were seen between chatGPT 3.5 and 4.0 in regard to 
      imaging questions with accuracy rates of 61 versus 85%(P = 0.009). ChatGPT was 
      observed to have an average translational ability score of 4.27/5 on the Likert 
      scale regarding CT and MRI findings. ChatGPT demonstrates substantial potential 
      to augment decision-making and optimizing workflow. While ChatGPT's promise is 
      evident, thorough evaluation and validation are imperative before widespread 
      adoption in the field of radiology.
CI  - © 2024 The Authors. Journal of Medical Imaging and Radiation Oncology published 
      by John Wiley &amp; Sons Australia, Ltd on behalf of Royal Australian and New Zealand 
      College of Radiologists.
FAU - Temperley, Hugo C
AU  - Temperley HC
AUID- ORCID: 0000-0001-9151-3431
AD  - Department of Radiology, St. James's Hospital, Dublin, Ireland.
AD  - Department of Surgery, St. James's Hospital, Dublin, Ireland.
FAU - O'Sullivan, Niall J
AU  - O'Sullivan NJ
AD  - Department of Radiology, St. James's Hospital, Dublin, Ireland.
FAU - Mac Curtain, Benjamin M
AU  - Mac Curtain BM
AD  - Department of Urology, St Vincent's University Hospital, Dublin, Ireland.
FAU - Corr, Alison
AU  - Corr A
AD  - Department of Radiology, St. James's Hospital, Dublin, Ireland.
FAU - Meaney, James F
AU  - Meaney JF
AD  - Department of Radiology, St. James's Hospital, Dublin, Ireland.
FAU - Kelly, Michael E
AU  - Kelly ME
AUID- ORCID: 0000-0002-0757-6411
AD  - Department of Surgery, St. James's Hospital, Dublin, Ireland.
FAU - Brennan, Ian
AU  - Brennan I
AD  - Department of Radiology, St. James's Hospital, Dublin, Ireland.
LA  - eng
PT  - Journal Article
DEP - 20240119
PL  - Australia
TA  - J Med Imaging Radiat Oncol
JT  - Journal of medical imaging and radiation oncology
JID - 101469340
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - large language mode
OT  - machine learning
OT  - radiology
EDAT- 2024/01/20 10:42
MHDA- 2024/01/20 10:42
CRDT- 2024/01/20 02:00
PHST- 2023/09/22 00:00 [received]
PHST- 2023/12/29 00:00 [accepted]
PHST- 2024/01/20 10:42 [pubmed]
PHST- 2024/01/20 10:42 [medline]
PHST- 2024/01/20 02:00 [entrez]
AID - 10.1111/1754-9485.13621 [doi]
PST - aheadofprint
SO  - J Med Imaging Radiat Oncol. 2024 Jan 19. doi: 10.1111/1754-9485.13621.

PMID- 37129780
OWN - NLM
STAT- MEDLINE
DCOM- 20230710
LR  - 20231211
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 51
IP  - 8
DP  - 2023 Aug
TI  - Understanding the Perceptions of Healthcare Researchers Regarding ChatGPT: A 
      Study Based on Bidirectional Encoder Representation from Transformers (BERT) 
      Sentiment Analysis and Topic Modeling.
PG  - 1654-1656
LID - 10.1007/s10439-023-03222-0 [doi]
AB  - In this study, we have used deep learning techniques to understand the perception 
      of researchers in the healthcare sector about the recently introduced chat 
      generative pre-trained transformer (ChatGPT). Ever since the launch of ChatGPT, 
      there have been various debates over the usage of ChatGPT for research purposes. 
      In this article, using the pre-trained BERT (Bidirectional Encoder 
      Representations from Transformers) model, we performed sentiment analysis and 
      topic modeling to analyze the social media posts of healthcare researchers to 
      understand their emotions towards ChatGPT.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Praveen, S V
AU  - Praveen SV
AUID- ORCID: 0000-0002-1450-8839
AD  - Department of Analytics, Xavier Institute of Management and Entrepreneurship, 
      Bangalore, India. praveenscissci@gmail.com.
FAU - Vajrobol, Vajratiya
AU  - Vajrobol V
AD  - Institute of Informatics and Communication, University of Delhi-South Campus, New 
      Delhi, India.
LA  - eng
PT  - Letter
DEP - 20230502
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - Humans
MH  - *Sentiment Analysis
MH  - *Electric Power Supplies
OTO - NOTNLM
OT  - ChatGPT
OT  - Deep learning
OT  - Health care research
OT  - Natural language processing
OT  - Perception
EDAT- 2023/05/02 12:43
MHDA- 2023/07/10 06:42
CRDT- 2023/05/02 11:11
PHST- 2023/04/24 00:00 [received]
PHST- 2023/04/25 00:00 [accepted]
PHST- 2023/07/10 06:42 [medline]
PHST- 2023/05/02 12:43 [pubmed]
PHST- 2023/05/02 11:11 [entrez]
AID - 10.1007/s10439-023-03222-0 [pii]
AID - 10.1007/s10439-023-03222-0 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2023 Aug;51(8):1654-1656. doi: 10.1007/s10439-023-03222-0. Epub 
      2023 May 2.

PMID- 37553205
OWN - NLM
STAT- Publisher
LR  - 20230808
IS  - 1750-3639 (Electronic)
IS  - 1015-6305 (Linking)
DP  - 2023 Aug 8
TI  - Evaluating the performance of large language models: ChatGPT and Google Bard in 
      generating differential diagnoses in clinicopathological conferences of 
      neurodegenerative disorders.
PG  - e13207
LID - 10.1111/bpa.13207 [doi]
AB  - This study explores the utility of the large language models (LLMs), specifically 
      ChatGPT and Google Bard, in predicting neuropathologic diagnoses from clinical 
      summaries. A total of 25 cases of neurodegenerative disorders presented at Mayo 
      Clinic brain bank Clinico-Pathological Conferences were analyzed. The LLMs 
      provided multiple pathologic diagnoses and their rationales, which were compared 
      with the final clinical diagnoses made by physicians. ChatGPT-3.5, ChatGPT-4, and 
      Google Bard correctly made primary diagnoses in 32%, 52%, and 40% of cases, 
      respectively, while correct diagnoses were included in 76%, 84%, and 76% of 
      cases, respectively. These findings highlight the potential of artificial 
      intelligence tools like ChatGPT in neuropathology, suggesting they may facilitate 
      more comprehensive discussions in clinicopathological conferences.
CI  - © 2023 The Authors. Brain Pathology published by John Wiley &amp; Sons Ltd on behalf 
      of International Society of Neuropathology.
FAU - Koga, Shunsuke
AU  - Koga S
AUID- ORCID: 0000-0001-8868-9700
AD  - Department of Neuroscience, Mayo Clinic, Jacksonville, Florida, USA.
FAU - Martin, Nicholas B
AU  - Martin NB
AD  - Department of Neuroscience, Mayo Clinic, Jacksonville, Florida, USA.
FAU - Dickson, Dennis W
AU  - Dickson DW
AD  - Department of Neuroscience, Mayo Clinic, Jacksonville, Florida, USA.
LA  - eng
PT  - Letter
DEP - 20230808
PL  - Switzerland
TA  - Brain Pathol
JT  - Brain pathology (Zurich, Switzerland)
JID - 9216781
SB  - IM
OTO - NOTNLM
OT  - CPC
OT  - ChatGPT
OT  - Google Bard
OT  - artificial intelligence
OT  - clinicopathological conference
OT  - large language model
OT  - neuropathology
OT  - pathology
EDAT- 2023/08/09 01:05
MHDA- 2023/08/09 01:05
CRDT- 2023/08/08 21:13
PHST- 2023/06/22 00:00 [received]
PHST- 2023/07/31 00:00 [accepted]
PHST- 2023/08/09 01:05 [medline]
PHST- 2023/08/09 01:05 [pubmed]
PHST- 2023/08/08 21:13 [entrez]
AID - 10.1111/bpa.13207 [doi]
PST - aheadofprint
SO  - Brain Pathol. 2023 Aug 8:e13207. doi: 10.1111/bpa.13207.

PMID- 38214967
OWN - NLM
STAT- MEDLINE
DCOM- 20240115
LR  - 20240129
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 10
DP  - 2024 Jan 12
TI  - The Use of ChatGPT for Education Modules on Integrated Pharmacotherapy of 
      Infectious Disease: Educators' Perspectives.
PG  - e47339
LID - 10.2196/47339 [doi]
LID - e47339
AB  - BACKGROUND: Artificial Intelligence (AI) plays an important role in many fields, 
      including medical education, practice, and research. Many medical educators 
      started using ChatGPT at the end of 2022 for many purposes. OBJECTIVE: The aim of 
      this study was to explore the potential uses, benefits, and risks of using 
      ChatGPT in education modules on integrated pharmacotherapy of infectious disease. 
      METHODS: A content analysis was conducted to investigate the applications of 
      ChatGPT in education modules on integrated pharmacotherapy of infectious disease. 
      Questions pertaining to curriculum development, syllabus design, lecture note 
      preparation, and examination construction were posed during data collection. 
      Three experienced professors rated the appropriateness and precision of the 
      answers provided by ChatGPT. The consensus rating was considered. The professors 
      also discussed the prospective applications, benefits, and risks of ChatGPT in 
      this educational setting. RESULTS: ChatGPT demonstrated the ability to contribute 
      to various aspects of curriculum design, with ratings ranging from 50% to 92% for 
      appropriateness and accuracy. However, there were limitations and risks 
      associated with its use, including incomplete syllabi, the absence of essential 
      learning objectives, and the inability to design valid questionnaires and 
      qualitative studies. It was suggested that educators use ChatGPT as a resource 
      rather than relying primarily on its output. There are recommendations for 
      effectively incorporating ChatGPT into the curriculum of the education modules on 
      integrated pharmacotherapy of infectious disease. CONCLUSIONS: Medical and health 
      sciences educators can use ChatGPT as a guide in many aspects related to the 
      development of the curriculum of the education modules on integrated 
      pharmacotherapy of infectious disease, syllabus design, lecture notes 
      preparation, and examination preparation with caution.
CI  - ©Yaser Mohammed Al-Worafi, Khang Wen Goh, Andi Hermansyah, Ching Siang Tan, Long 
      Chiau Ming. Originally published in JMIR Medical Education 
      (https://mededu.jmir.org), 12.01.2024.
FAU - Al-Worafi, Yaser Mohammed
AU  - Al-Worafi YM
AUID- ORCID: 0000-0002-5752-2913
AD  - College of Medical Sciences, Azal University for Human Development, Sana'a, 
      Yemen.
AD  - College of Pharmacy, University of Science and Technology of Fujairah, Fujairah, 
      United Arab Emirates.
FAU - Goh, Khang Wen
AU  - Goh KW
AUID- ORCID: 0000-0001-6686-7019
AD  - Faculty of Data Science and Information Technology, INTI International 
      University, Nilai, Malaysia.
FAU - Hermansyah, Andi
AU  - Hermansyah A
AUID- ORCID: 0000-0002-9716-3126
AD  - Department of Pharmacy Practice, Faculty of Pharmacy, Universitas Airlangga, 
      Surabaya, Indonesia.
FAU - Tan, Ching Siang
AU  - Tan CS
AUID- ORCID: 0000-0002-5069-3314
AD  - School of Pharmacy, KPJ Healthcare University, Nilai, Malaysia.
FAU - Ming, Long Chiau
AU  - Ming LC
AUID- ORCID: 0000-0002-6971-1383
AD  - School of Medical and Life Sciences, Sunway University, Selangor, Malaysia.
LA  - eng
PT  - Journal Article
DEP - 20240112
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
SB  - IM
MH  - Humans
MH  - Artificial Intelligence
MH  - Educational Status
MH  - Curriculum
MH  - *Educational Personnel
MH  - *Communicable Diseases/drug therapy
PMC - PMC10818233
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - feasibility
OT  - innovation and infrastructure
OT  - innovation and technology
OT  - partnerships for the goals
OT  - quality education
OT  - social justice
OT  - sustainable communities
OT  - sustainable education
COIS- Conflicts of Interest: None declared.
EDAT- 2024/01/12 12:41
MHDA- 2024/01/15 12:43
PMCR- 2024/01/12
CRDT- 2024/01/12 11:54
PHST- 2023/03/16 00:00 [received]
PHST- 2023/07/25 00:00 [accepted]
PHST- 2023/06/21 00:00 [revised]
PHST- 2024/01/15 12:43 [medline]
PHST- 2024/01/12 12:41 [pubmed]
PHST- 2024/01/12 11:54 [entrez]
PHST- 2024/01/12 00:00 [pmc-release]
AID - v10i1e47339 [pii]
AID - 10.2196/47339 [doi]
PST - epublish
SO  - JMIR Med Educ. 2024 Jan 12;10:e47339. doi: 10.2196/47339.

PMID- 38489735
OWN - NLM
STAT- MEDLINE
DCOM- 20240318
LR  - 20240318
IS  - 1536-5964 (Electronic)
IS  - 0025-7974 (Print)
IS  - 0025-7974 (Linking)
VI  - 103
IP  - 11
DP  - 2024 Mar 15
TI  - Evaluation of ChatGPT in providing appropriate fracture prevention 
      recommendations and medical science question responses: A quantitative research.
PG  - e37458
LID - 10.1097/MD.0000000000037458 [doi]
LID - e37458
AB  - Currently, there are limited studies assessing ChatGPT ability to provide 
      appropriate responses to medical questions. Our study aims to evaluate ChatGPT 
      adequacy in responding to questions regarding osteoporotic fracture prevention 
      and medical science. We created a list of 25 questions based on the guidelines 
      and our clinical experience. Additionally, we included 11 medical science 
      questions from the journal Science. Three patients, 3 non-medical professionals, 
      3 specialist doctor and 3 scientists were involved to evaluate the accuracy and 
      appropriateness of responses by ChatGPT3.5 on October 2, 2023. To simulate a 
      consultation, an inquirer (either a patient or non-medical professional) would 
      send their questions to a consultant (specialist doctor or scientist) via a 
      website. The consultant would forward the questions to ChatGPT for answers, which 
      would then be evaluated for accuracy and appropriateness by the consultant before 
      being sent back to the inquirer via the website for further review. The primary 
      outcome is the appropriate, inappropriate, and unreliable rate of ChatGPT 
      responses as evaluated separately by the inquirer and consultant groups. Compared 
      to orthopedic clinicians, the patients' rating on the appropriateness of ChatGPT 
      responses to the questions about osteoporotic fracture prevention was slightly 
      higher, although the difference was not statistically significant (88% vs 80%, 
      P = .70). For medical science questions, non-medical professionals and medical 
      scientists rated similarly. In addition, the experts' ratings on the 
      appropriateness of ChatGPT responses to osteoporotic fracture prevention and to 
      medical science questions were comparable. On the other hand, the patients 
      perceived that the appropriateness of ChatGPT responses to osteoporotic fracture 
      prevention questions was slightly higher than that to medical science questions 
      (88% vs 72·7%, P = .34). ChatGPT is capable of providing comparable and 
      appropriate responses to medical science questions, as well as to fracture 
      prevention related issues. Both the inquirers seeking advice and the consultants 
      providing advice recognize ChatGPT expertise in these areas.
CI  - Copyright © 2024 the Author(s). Published by Wolters Kluwer Health, Inc.
FAU - Meng, Jiahao
AU  - Meng J
AD  - Department of Orthopaedics, Xiangya Hospital, Central South University, #87 
      Xiangya Road, Changsha, Hunan, China.
FAU - Zhang, Ziyi
AU  - Zhang Z
AD  - Department of Neurology, The Second Xiangya Hospital, Central South University, 
      Changsha, Hunan, China.
FAU - Tang, Hang
AU  - Tang H
AD  - Department of Orthopaedics, Xiangya Hospital, Central South University, #87 
      Xiangya Road, Changsha, Hunan, China.
FAU - Xiao, Yifan
AU  - Xiao Y
AD  - Department of Orthopaedics, Xiangya Hospital, Central South University, #87 
      Xiangya Road, Changsha, Hunan, China.
FAU - Liu, Pan
AU  - Liu P
AD  - Department of Orthopaedics, Xiangya Hospital, Central South University, #87 
      Xiangya Road, Changsha, Hunan, China.
FAU - Gao, Shuguang
AU  - Gao S
AD  - Department of Orthopaedics, Xiangya Hospital, Central South University, #87 
      Xiangya Road, Changsha, Hunan, China.
AD  - National Clinical Research Center of Geriatric Disorders, Xiangya Hospital, 
      Central South University, Changsha, Hunan, China.
FAU - He, Miao
AU  - He M
AUID- ORCID: 0000-0001-6299-722
AD  - Department of Neurology, The Second Xiangya Hospital, Central South University, 
      Changsha, Hunan, China.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Medicine (Baltimore)
JT  - Medicine
JID - 2985248R
SB  - IM
MH  - Humans
MH  - *Osteoporotic Fractures
MH  - *Medicine
MH  - *Orthopedics
MH  - *Physicians
MH  - Referral and Consultation
PMC - PMC10939678
COIS- The authors have no conflicts of interest to disclose.
EDAT- 2024/03/15 18:42
MHDA- 2024/03/18 06:42
PMCR- 2024/03/15
CRDT- 2024/03/15 16:43
PHST- 2024/03/18 06:42 [medline]
PHST- 2024/03/15 18:42 [pubmed]
PHST- 2024/03/15 16:43 [entrez]
PHST- 2024/03/15 00:00 [pmc-release]
AID - 00005792-202403150-00063 [pii]
AID - 10.1097/MD.0000000000037458 [doi]
PST - ppublish
SO  - Medicine (Baltimore). 2024 Mar 15;103(11):e37458. doi: 
      10.1097/MD.0000000000037458.

PMID- 38411833
OWN - NLM
STAT- MEDLINE
DCOM- 20240228
LR  - 20240301
IS  - 1573-689X (Electronic)
IS  - 0148-5598 (Print)
IS  - 0148-5598 (Linking)
VI  - 48
IP  - 1
DP  - 2024 Feb 27
TI  - Knowledge, Perceptions and Attitude of Researchers Towards Using ChatGPT in 
      Research.
PG  - 26
LID - 10.1007/s10916-024-02044-4 [doi]
LID - 26
AB  - INTRODUCTION: ChatGPT, a recently released chatbot from OpenAI, has found 
      applications in various aspects of life, including academic research. This study 
      investigated the knowledge, perceptions, and attitudes of researchers towards 
      using ChatGPT and other chatbots in academic research. METHODS: A pre-designed, 
      self-administered survey using Google Forms was employed to conduct the study. 
      The questionnaire assessed participants' knowledge of ChatGPT and other chatbots, 
      their awareness of current chatbot and artificial intelligence (AI) applications, 
      and their attitudes towards ChatGPT and its potential research uses. RESULTS: Two 
      hundred researchers participated in the survey. A majority were female (57.5%), 
      and over two-thirds belonged to the medical field (68%). While 67% had heard of 
      ChatGPT, only 11.5% had employed it in their research, primarily for rephrasing 
      paragraphs and finding references. Interestingly, over one-third supported the 
      notion of listing ChatGPT as an author in scientific publications. Concerns 
      emerged regarding AI's potential to automate researcher tasks, particularly in 
      language editing, statistics, and data analysis. Additionally, roughly half 
      expressed ethical concerns about using AI applications in scientific research. 
      CONCLUSION: The increasing use of chatbots in academic research necessitates 
      thoughtful regulation that balances potential benefits with inherent limitations 
      and potential risks. Chatbots should not be considered authors of scientific 
      publications but rather assistants to researchers during manuscript preparation 
      and review. Researchers should be equipped with proper training to utilize 
      chatbots and other AI tools effectively and ethically.
CI  - © 2024. The Author(s).
FAU - Abdelhafiz, Ahmed Samir
AU  - Abdelhafiz AS
AD  - Department of Clinical pathology, National Cancer Institute, Cairo University, 
      Kasr Al-Aini Street, from Elkhalig Square, Cairo, 11796, Egypt. 
      ahmed.samir@nci.cu.edu.eg.
FAU - Ali, Asmaa
AU  - Ali A
AD  - Department of Pulmonary Medicine, Abbassia Chest Hospital, Ministry of Health and 
      Population, Cairo, Egypt.
FAU - Maaly, Ayman Mohamed
AU  - Maaly AM
AD  - Department of Anaesthesia and Surgical Intensive Care, Faculty of Medicine, 
      Alexandria University, Alexandria, Egypt.
FAU - Ziady, Hany Hassan
AU  - Ziady HH
AD  - Department of Community Medicine, Faculty of Medicine, Alexandria University, 
      Alexandria, Egypt.
FAU - Sultan, Eman Anwar
AU  - Sultan EA
AD  - Department of Community Medicine, Faculty of Medicine, Alexandria University, 
      Alexandria, Egypt.
FAU - Mahgoub, Mohamed Anwar
AU  - Mahgoub MA
AD  - Department of Microbiology, High Institute of Public Health, Alexandria 
      University, Alexandria, Egypt.
LA  - eng
PT  - Journal Article
DEP - 20240227
PL  - United States
TA  - J Med Syst
JT  - Journal of medical systems
JID - 7806056
SB  - IM
MH  - Humans
MH  - Female
MH  - Male
MH  - *Artificial Intelligence
MH  - *Data Analysis
MH  - Knowledge
MH  - Language
MH  - Software
PMC - PMC10899415
OTO - NOTNLM
OT  - Academic Research
OT  - Artificial Intelligence
OT  - ChatGPT
OT  - Chatbots
OT  - ELSI
COIS- The authors declare no competing interests.
EDAT- 2024/02/27 12:47
MHDA- 2024/02/28 06:45
PMCR- 2024/02/27
CRDT- 2024/02/27 11:12
PHST- 2023/10/12 00:00 [received]
PHST- 2024/02/10 00:00 [accepted]
PHST- 2024/02/28 06:45 [medline]
PHST- 2024/02/27 12:47 [pubmed]
PHST- 2024/02/27 11:12 [entrez]
PHST- 2024/02/27 00:00 [pmc-release]
AID - 10.1007/s10916-024-02044-4 [pii]
AID - 2044 [pii]
AID - 10.1007/s10916-024-02044-4 [doi]
PST - epublish
SO  - J Med Syst. 2024 Feb 27;48(1):26. doi: 10.1007/s10916-024-02044-4.

PMID- 38184368
OWN - NLM
STAT- MEDLINE
DCOM- 20240214
LR  - 20240214
IS  - 1759-8486 (Electronic)
IS  - 1759-8478 (Linking)
VI  - 16
IP  - 3
DP  - 2024 Feb 12
TI  - Assessing the clinical reasoning of ChatGPT for mechanical thrombectomy in 
      patients with stroke.
PG  - 253-260
LID - 10.1136/jnis-2023-021163 [doi]
AB  - BACKGROUND: Artificial intelligence (AI) has become a promising tool in medicine. 
      ChatGPT, a large language model AI Chatbot, shows promise in supporting clinical 
      practice. We assess the potential of ChatGPT as a clinical reasoning tool for 
      mechanical thrombectomy in patients with stroke. METHODS: An internal validation 
      of the abilities of ChatGPT was first performed using artificially created 
      patient scenarios before assessment of real patient scenarios from the medical 
      center's stroke database. All patients with large vessel occlusions who underwent 
      mechanical thrombectomy at Tulane Medical Center between January 1, 2022 and 
      December 31, 2022 were included in the study. The performance of ChatGPT in 
      evaluating which patients should undergo mechanical thrombectomy was compared 
      with the decisions made by board-certified stroke neurologists and 
      neurointerventionalists. The interpretation skills, clinical reasoning, and 
      accuracy of ChatGPT were analyzed. RESULTS: 102 patients with large vessel 
      occlusions underwent mechanical thrombectomy. ChatGPT agreed with the physician's 
      decision whether or not to pursue thrombectomy in 54.3% of the cases. ChatGPT had 
      mistakes in 8.8% of the cases, consisting of mathematics, logic, and 
      misinterpretation errors. In the internal validation phase, ChatGPT was able to 
      provide nuanced clinical reasoning and was able to perform multi-step thinking, 
      although with an increased rate of making mistakes. CONCLUSION: ChatGPT shows 
      promise in clinical reasoning, including the ability to factor a patient's 
      underlying comorbidities when considering mechanical thrombectomy. However, 
      ChatGPT is prone to errors as well and should not be relied on as a sole 
      decision-making tool in its present form, but it has potential to assist 
      clinicians with more efficient work flow.
CI  - © Author(s) (or their employer(s)) 2024. No commercial re-use. See rights and 
      permissions. Published by BMJ.
FAU - Chen, Tse Chiang
AU  - Chen TC
AD  - Tulane University School of Medicine, New Orleans, Louisiana, USA.
FAU - Couldwell, Mitchell W
AU  - Couldwell MW
AD  - Tulane University School of Medicine, New Orleans, Louisiana, USA.
FAU - Singer, Jorie
AU  - Singer J
AD  - Tulane University School of Medicine, New Orleans, Louisiana, USA.
FAU - Singer, Alyssa
AU  - Singer A
AD  - Tulane University School of Medicine, New Orleans, Louisiana, USA.
FAU - Koduri, Laila
AU  - Koduri L
AD  - Tulane University School of Medicine, New Orleans, Louisiana, USA.
FAU - Kaminski, Emily
AU  - Kaminski E
AD  - Tulane University School of Medicine, New Orleans, Louisiana, USA.
FAU - Nguyen, Khoa
AU  - Nguyen K
AD  - Tulane University School of Medicine, New Orleans, Louisiana, USA.
FAU - Multala, Evan
AU  - Multala E
AD  - Tulane University School of Medicine, New Orleans, Louisiana, USA.
FAU - Dumont, Aaron S
AU  - Dumont AS
AD  - Department of Neurological Surgery, Tulane University School of Medicine, New 
      Orleans, Louisiana, USA.
FAU - Wang, Arthur
AU  - Wang A
AUID- ORCID: 0009-0007-4396-2516
AD  - Department of Neurological Surgery, Tulane University School of Medicine, New 
      Orleans, Louisiana, USA awang15@tulane.edu.
LA  - eng
PT  - Journal Article
DEP - 20240212
PL  - England
TA  - J Neurointerv Surg
JT  - Journal of neurointerventional surgery
JID - 101517079
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Stroke/diagnostic imaging/surgery
MH  - Clinical Reasoning
MH  - Databases, Factual
MH  - Thrombectomy
OTO - NOTNLM
OT  - Stroke
OT  - Thrombectomy
COIS- Competing interests: None declared.
EDAT- 2024/01/07 06:44
MHDA- 2024/02/14 12:50
CRDT- 2024/01/06 21:03
PHST- 2023/10/30 00:00 [received]
PHST- 2023/12/15 00:00 [accepted]
PHST- 2024/02/14 12:50 [medline]
PHST- 2024/01/07 06:44 [pubmed]
PHST- 2024/01/06 21:03 [entrez]
AID - jnis-2023-021163 [pii]
AID - 10.1136/jnis-2023-021163 [doi]
PST - epublish
SO  - J Neurointerv Surg. 2024 Feb 12;16(3):253-260. doi: 10.1136/jnis-2023-021163.

PMID- 38517757
OWN - NLM
STAT- MEDLINE
DCOM- 20240325
LR  - 20240325
IS  - 1528-1132 (Electronic)
IS  - 0009-921X (Print)
IS  - 0009-921X (Linking)
VI  - 482
IP  - 4
DP  - 2024 Apr 1
TI  - How Does ChatGPT Use Source Information Compared With Google? A Text Network 
      Analysis of Online Health Information.
PG  - 578-588
LID - 10.1097/CORR.0000000000002995 [doi]
AB  - BACKGROUND: The lay public is increasingly using ChatGPT (a large language model) 
      as a source of medical information. Traditional search engines such as Google 
      provide several distinct responses to each search query and indicate the source 
      for each response, but ChatGPT provides responses in paragraph form in prose 
      without providing the sources used, which makes it difficult or impossible to 
      ascertain whether those sources are reliable. One practical method to infer the 
      sources used by ChatGPT is text network analysis. By understanding how ChatGPT 
      uses source information in relation to traditional search engines, physicians and 
      physician organizations can better counsel patients on the use of this new tool. 
      QUESTIONS/PURPOSES: (1) In terms of key content words, how similar are ChatGPT 
      and Google Search responses for queries related to topics in orthopaedic surgery? 
      (2) Does the source distribution (academic, governmental, commercial, or form of 
      a scientific manuscript) differ for Google Search responses based on the topic's 
      level of medical consensus, and how is this reflected in the text similarity 
      between ChatGPT and Google Search responses? (3) Do these results vary between 
      different versions of ChatGPT? METHODS: We evaluated three search queries 
      relating to orthopaedic conditions: "What is the cause of carpal tunnel 
      syndrome?," "What is the cause of tennis elbow?," and "Platelet-rich plasma for 
      thumb arthritis?" These were selected because of their relatively high, medium, 
      and low consensus in the medical evidence, respectively. Each question was posed 
      to ChatGPT version 3.5 and version 4.0 20 times for a total of 120 responses. 
      Text network analysis using term frequency-inverse document frequency (TF-IDF) 
      was used to compare text similarity between responses from ChatGPT and Google 
      Search. In the field of information retrieval, TF-IDF is a weighted statistical 
      measure of the importance of a key word to a document in a collection of 
      documents. Higher TF-IDF scores indicate greater similarity between two sources. 
      TF-IDF scores are most often used to compare and rank the text similarity of 
      documents. Using this type of text network analysis, text similarity between 
      ChatGPT and Google Search can be determined by calculating and summing the TF-IDF 
      for all keywords in a ChatGPT response and comparing it with each Google search 
      result to assess their text similarity to each other. In this way, text 
      similarity can be used to infer relative content similarity. To answer our first 
      question, we characterized the text similarity between ChatGPT and Google Search 
      responses by finding the TF-IDF scores of the ChatGPT response and each of the 20 
      Google Search results for each question. Using these scores, we could compare the 
      similarity of each ChatGPT response to the Google Search results. To provide a 
      reference point for interpreting TF-IDF values, we generated randomized text 
      samples with the same term distribution as the Google Search results. By 
      comparing ChatGPT TF-IDF to the random text sample, we could assess whether 
      TF-IDF values were statistically significant from TF-IDF values obtained by 
      random chance, and it allowed us to test whether text similarity was an 
      appropriate quantitative statistical measure of relative content similarity. To 
      answer our second question, we classified the Google Search results to better 
      understand sourcing. Google Search provides 20 or more distinct sources of 
      information, but ChatGPT gives only a single prose paragraph in response to each 
      query. So, to answer this question, we used TF-IDF to ascertain whether the 
      ChatGPT response was principally driven by one of four source categories: 
      academic, government, commercial, or material that took the form of a scientific 
      manuscript but was not peer-reviewed or indexed on a government site (such as 
      PubMed). We then compared the TF-IDF similarity between ChatGPT responses and the 
      source category. To answer our third research question, we repeated both analyses 
      and compared the results when using ChatGPT 3.5 versus ChatGPT 4.0. RESULTS: The 
      ChatGPT response was dominated by the top Google Search result. For example, for 
      carpal tunnel syndrome, the top result was an academic website with a mean TF-IDF 
      of 7.2. A similar result was observed for the other search topics. To provide a 
      reference point for interpreting TF-IDF values, a randomly generated sample of 
      text compared with Google Search would have a mean TF-IDF of 2.7 ± 1.9, 
      controlling for text length and keyword distribution. The observed TF-IDF 
      distribution was higher for ChatGPT responses than for random text samples, 
      supporting the claim that keyword text similarity is a measure of relative 
      content similarity. When comparing source distribution, the ChatGPT response was 
      most similar to the most common source category from Google Search. For the 
      subject where there was strong consensus (carpal tunnel syndrome), the ChatGPT 
      response was most similar to high-quality academic sources rather than 
      lower-quality commercial sources (TF-IDF 8.6 versus 2.2). For topics with low 
      consensus, the ChatGPT response paralleled lower-quality commercial websites 
      compared with higher-quality academic websites (TF-IDF 14.6 versus 0.2). ChatGPT 
      4.0 had higher text similarity to Google Search results than ChatGPT 3.5 (mean 
      increase in TF-IDF similarity of 0.80 to 0.91; p &lt; 0.001). The ChatGPT 4.0 
      response was still dominated by the top Google Search result and reflected the 
      most common search category for all search topics. CONCLUSION: ChatGPT responses 
      are similar to individual Google Search results for queries related to 
      orthopaedic surgery, but the distribution of source information can vary 
      substantially based on the relative level of consensus on a topic. For example, 
      for carpal tunnel syndrome, where there is widely accepted medical consensus, 
      ChatGPT responses had higher similarity to academic sources and therefore used 
      those sources more. When fewer academic or government sources are available, 
      especially in our search related to platelet-rich plasma, ChatGPT appears to have 
      relied more heavily on a small number of nonacademic sources. These findings 
      persisted even as ChatGPT was updated from version 3.5 to version 4.0. CLINICAL 
      RELEVANCE: Physicians should be aware that ChatGPT and Google likely use the same 
      sources for a specific question. The main difference is that ChatGPT can draw 
      upon multiple sources to create one aggregate response, while Google maintains 
      its distinctness by providing multiple results. For topics with a low consensus 
      and therefore a low number of quality sources, there is a much higher chance that 
      ChatGPT will use less-reliable sources, in which case physicians should take the 
      time to educate patients on the topic or provide resources that give more 
      reliable information. Physician organizations should make it clear when the 
      evidence is limited so that ChatGPT can reflect the lack of quality information 
      or evidence.
CI  - Copyright © 2024 by the Association of Bone and Joint Surgeons.
FAU - Shen, Oscar Y
AU  - Shen OY
AUID- ORCID: 0000-0003-3854-1470
AD  - Department of Orthopaedic Surgery, Hand and Upper Extremity Service, 
      Massachusetts General Hospital, Harvard Medical School, Boston, MA, USA.
AD  - Faculty of Medicine, The Chinese University of Hong Kong, Hong Kong.
FAU - Pratap, Jayanth S
AU  - Pratap JS
AD  - Department of Orthopaedic Surgery, Hand and Upper Extremity Service, 
      Massachusetts General Hospital, Harvard Medical School, Boston, MA, USA.
AD  - Harvard University, Cambridge, MA, USA.
FAU - Li, Xiang
AU  - Li X
AUID- ORCID: 0000-0002-9851-6376
AD  - Department of Radiology, Massachusetts General Hospital, Harvard Medical School, 
      Boston, MA, USA.
FAU - Chen, Neal C
AU  - Chen NC
AD  - Department of Orthopaedic Surgery, Hand and Upper Extremity Service, 
      Massachusetts General Hospital, Harvard Medical School, Boston, MA, USA.
FAU - Bhashyam, Abhiram R
AU  - Bhashyam AR
AD  - Department of Orthopaedic Surgery, Hand and Upper Extremity Service, 
      Massachusetts General Hospital, Harvard Medical School, Boston, MA, USA.
LA  - eng
PT  - Journal Article
DEP - 20240301
PL  - United States
TA  - Clin Orthop Relat Res
JT  - Clinical orthopaedics and related research
JID - 0075674
SB  - IM
CIN - doi: 10.1097/CORR.0000000000003006
MH  - Humans
MH  - *Search Engine
MH  - *Carpal Tunnel Syndrome
MH  - Information Storage and Retrieval
PMC - PMC10936961
COIS- Each author certifies that there are no funding or commercial associations 
      (consultancies, stock ownership, equity interest, patent/licensing arrangements, 
      etc.) that might pose a conflict of interest in connection with the submitted 
      article related to the author or any immediate family members. All ICMJE Conflict 
      of Interest Forms for authors and Clinical Orthopaedics and Related Research® 
      editors and board members are on file with the publication and can be viewed on 
      request.
EDAT- 2024/03/22 18:44
MHDA- 2024/03/25 06:43
PMCR- 2025/04/01
CRDT- 2024/03/22 12:53
PHST- 2023/09/03 00:00 [received]
PHST- 2024/01/08 00:00 [accepted]
PHST- 2025/04/01 00:00 [pmc-release]
PHST- 2024/03/25 06:43 [medline]
PHST- 2024/03/22 18:44 [pubmed]
PHST- 2024/03/22 12:53 [entrez]
AID - 00003086-202404000-00003 [pii]
AID - CORR-D-23-01040 [pii]
AID - 10.1097/CORR.0000000000002995 [doi]
PST - ppublish
SO  - Clin Orthop Relat Res. 2024 Apr 1;482(4):578-588. doi: 
      10.1097/CORR.0000000000002995. Epub 2024 Mar 1.

PMID- 37438164
OWN - NLM
STAT- Publisher
LR  - 20230712
IS  - 1097-6841 (Electronic)
IS  - 0022-3913 (Linking)
DP  - 2023 Jul 10
TI  - How much can we rely on artificial intelligence chatbots such as the ChatGPT 
      software program to assist with scientific writing?
LID - S0022-3913(23)00371-2 [pii]
LID - 10.1016/j.prosdent.2023.05.023 [doi]
AB  - STATEMENT OF&nbsp;PROBLEM: Use of the ChatGPT software program by authors raises many 
      questions, primarily regarding egregious issues such as plagiarism. Nevertheless, 
      little is known about the extent to which artificial intelligence (AI) models can 
      produce high-quality research publications and advance and shape the direction of 
      a research topic. PURPOSE: The purpose of this study was to determine how well 
      the ChatGPT software program, a writing tool powered by AI, could respond to 
      questions about scientific or research writing and generate accurate references 
      with academic examples. MATERIAL AND METHODS: Questions were made for the ChatGPT 
      software program to locate an abstract containing a particular keyword in the 
      Journal of Prosthetic Dentistry (JPD). Then, whether the resulting articles 
      existed or were published was determined. Questions were made for the algorithm 5 
      times to locate 5 JPD articles containing 2 specific keywords, bringing the total 
      number of articles to 25. The process was repeated twice, each time with a 
      different set of keywords, and the ChatGPT software program provided a total of 
      75 articles. The search was conducted at various times between April 1 and 4, 
      2023. Finally, 2 authors independently searched the JPD website and Google 
      Scholar to determine whether the articles provided by the ChatGPT software 
      program existed. RESULTS: When the author tested the ChatGPT software program's 
      ability to locate articles in the JPD and Google Scholar using a set of keywords, 
      the results did not match the papers that the ChatGPT software program had 
      generated with the help of the AI tool. Consequently, all 75 articles provided by 
      the ChatGPT software program were not accurately located in the JPD or Google 
      Scholar databases and had to be added manually to ensure the accuracy of the 
      relevant references. CONCLUSIONS: Researchers and academic scholars must be 
      cautious when using the ChatGPT software program because AI-generated content 
      cannot provide or analyze the same information as an author or researcher. In 
      addition, the results indicated that writing credit or references to such content 
      or references in prestigious academic journals is not yet appropriate. At this 
      time, scientific writing is only valid when performed manually by researchers.
CI  - Copyright © 2023 Editorial Council for The Journal of Prosthetic Dentistry. 
      Published by Elsevier Inc. All rights reserved.
FAU - Dashti, Mahmood
AU  - Dashti M
AD  - Researcher,&nbsp;School of Dentistry, Shahid Beheshti University of Medical Sciences, 
      Tehran, Iran. Electronic address: Dashti.mahmood72@gmail.com.
FAU - Londono, Jimmy
AU  - Londono J
AD  - Professor and Director of the&nbsp;Prosthodontics Residency Program and the Ronald 
      Goldstein Center for Esthetics and Implant Dentistry, The Dental College of 
      Georgia at Augusta University, Augusta, Ga.
FAU - Ghasemi, Shohreh
AU  - Ghasemi S
AD  - Adjunct Assistant Professor,&nbsp;Department of Oral and Maxillofacial Surgery, The 
      Dental College of Georgia at Augusta University, Augusta, Ga.
FAU - Moghaddasi, Negar
AU  - Moghaddasi N
AD  - Researcher,&nbsp;College of Dental Medicine, Western University of Health Sciences, 
      Pomona, Calif.
LA  - eng
PT  - Journal Article
DEP - 20230710
PL  - United States
TA  - J Prosthet Dent
JT  - The Journal of prosthetic dentistry
JID - 0376364
SB  - IM
EDAT- 2023/07/13 01:06
MHDA- 2023/07/13 01:06
CRDT- 2023/07/12 21:58
PHST- 2023/04/17 00:00 [received]
PHST- 2023/05/22 00:00 [revised]
PHST- 2023/05/24 00:00 [accepted]
PHST- 2023/07/13 01:06 [medline]
PHST- 2023/07/13 01:06 [pubmed]
PHST- 2023/07/12 21:58 [entrez]
AID - S0022-3913(23)00371-2 [pii]
AID - 10.1016/j.prosdent.2023.05.023 [doi]
PST - aheadofprint
SO  - J Prosthet Dent. 2023 Jul 10:S0022-3913(23)00371-2. doi: 
      10.1016/j.prosdent.2023.05.023.
</pre>
      
    </div>
  </main>


  
  


  


</body></html>