<!DOCTYPE html>
<!-- saved from url=(0068)https://pubmed.ncbi.nlm.nih.gov/?term=chatGPT&format=pubmed&size=200 -->
<html lang="en"><head itemscope="" itemtype="http://schema.org/WebPage" prefix="og: http://ogp.me/ns#"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <!-- Mobile properties -->
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov/">
  <link rel="preconnect" href="https://www.ncbi.nlm.nih.gov/">
  <link rel="preconnect" href="https://www.google-analytics.com/">

  
  
    <link rel="stylesheet" href="./page1_PubMed_files/output.5ecf62baa0fa.css" type="text/css">
  

  <link rel="stylesheet" href="./page1_PubMed_files/output.452c70ce66f7.css" type="text/css">

  
    
  

  
    <link rel="stylesheet" href="./page1_PubMed_files/output.97c300a159d1.css" type="text/css">
  

  


    <title>chatGPT - Search Results - PubMed</title>

  
  
  <!-- Favicons -->
  <link rel="shortcut icon" type="image/ico" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.ico">
  <link rel="icon" type="image/png" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.png">

  <!-- 192x192, as recommended for Android
  http://updates.html5rocks.com/2014/11/Support-for-theme-color-in-Chrome-39-for-Android
  -->
  <link rel="icon" type="image/png" sizes="192x192" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-192.png">

  <!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
  <link rel="apple-touch-icon-precomposed" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-57.png">
  <!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
  <link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-72.png">
  <!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
  <link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-114.png">
  <!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-144.png">


  <!-- For Pinger + Google Optimize integration (NS-820) -->
  <meta name="ncbi_sg_optimize_id" content="">

  <!-- Mobile browser address bar color -->
  <meta name="theme-color" content="#20558a">

  <!-- Preserve the Referrer when going from HTTPS to HTTP -->
  <meta name="referrer" content="origin-when-cross-origin">

  <meta name="ncbi_pinger_gtm_track" content="true">
<!-- Logging params: Pinger defaults -->

  
    <meta name="ncbi_app" content="pubmed">
  

  
    <meta name="ncbi_db" content="pubmed">
  

  
    <meta name="ncbi_phid" content="658B00010FEE1FF500003D712CE06DA0.1.m_7">
  

  
    <meta name="ncbi_pinger_stat_url" content="https://www.ncbi.nlm.nih.gov/stat">
  

  
    <meta name="log_category" content="literature">
  

  
    <meta name="ncbi_cost_center" content="pubmed">
  



  <!-- Logging params: Pinger custom -->
  
    <meta name="log_op" content="search">
  
    <meta name="log_query" content="chatGPT">
  
    <meta name="ncbi_pdid" content="searchresult">
  
    <meta name="ncbi_pageno" content="1">
  
    <meta name="log_resultcount" content="2844">
  
    <meta name="log_userterm" content="chatGPT">
  
    <meta name="log_processedquery" content="&quot;chatGPT&quot;[All Fields]">
  
    <meta name="log_filtersactive" content="False">
  
    <meta name="log_filters" content="">
  
    <meta name="ncbi_log_query" content="chatGPT">
  
    <meta name="log_proximity_search_active" content="False">
  
    <meta name="log_format" content="pubmed">
  
    <meta name="log_sortorder" content="relevance">
  
    <meta name="log_pagesize" content="200">
  
    <meta name="log_displayeduids" content="37215063,36811129,37266053,36867743,37379067,37168166,36863937,36916887,36798292,37168339,36943815,36627845,36858933,37085182,37780993,37705820,37802491,37038381,37779749,36990890,37433672,37328321,37211242,38038796,37991290,37926396,37819738,38060759,37812965,38262126,37546142,38026475,37265899,37789636,37307503,37691594,37225599,37425514,37309153,36920578,37387114,37183840,37581690,37440696,38320337,36989584,37720035,38149123,37349064,38281582,37755165,37501022,37334036,37433676,37814667,38358925,37200013,37166289,37680954,37731429,38200693,37162695,38182139,38462064,37271011,37933339,37093625,37549050,37526801,37485160,37024502,38230387,37034742,38138908,37781591,38107211,37962176,37303897,37031289,38405625,37133418,37516680,37544801,37463210,37549788,37059827,37399030,37581444,37023599,37477707,37824352,37264670,37719492,37812468,37149512,37265864,37160568,37928447,38051578,37201835,37128784,37750843,37799027,38492008,37031907,37707442,37892297,37744723,37602076,37885522,38028668,37197105,37061593,38476626,37761751,38153785,38078232,38049299,38041797,38160089,37891532,37948112,37711151,38420977,38340639,37717252,38116306,37648882,37545428,37284995,38549640,38293321,37130197,38451243,38076902,37484787,38217726,38421439,38391243,37671415,38050503,38090410,37244883,37335851,37804030,38148495,37621112,38298626,37590034,37914380,37490317,37812998,37789443,37991498,37460216,37668790,37499880,37465809,37103928,37936648,38118283,37203581,37576290,38022092,38112347,37873042,37040060,37510487,38035435,37455540,37853081,37476297,38112255,38073539,38206389,38487300,37332002,37255525,37529853,37494894,38440148,38090452,38304767,37387301,37976385,38155661,38419827,37986988,38108232,37004317,37220429,38527167,37754479,37901715,38156230,37809128,38081765,37951982,37553552,38440617">
  
    <meta name="ncbi_search_id" content="R3Cs2GC7H0x0KE8U7UASSA:deef7cbfe7e81e7152f8e0e261e5ab1a">
  
    <meta name="ncbi_adj_nav_search_id" content="p-BbjDiyecfR_V1iSYMBHA:fbd847f89c96214ac23b7c62d7cb721a">
  



  <!-- Social meta tags for unfurling urls -->
  
<meta name="description" content="chatGPT - Search Results - PubMed"><meta name="robots" content="noindex,follow,noarchive"><meta property="og:title" content="chatGPT - Search Results - PubMed"><meta property="og:url" content="https://pubmed.ncbi.nlm.nih.gov/?term=chatGPT&amp;format=pubmed&amp;size=200"><meta property="og:description" content="chatGPT - Search Results - PubMed"><meta property="og:image" content="https://cdn.ncbi.nlm.nih.gov/pubmed/persistent/pubmed-meta-image-v2.jpg"><meta property="og:image:secure_url" content="https://cdn.ncbi.nlm.nih.gov/pubmed/persistent/pubmed-meta-image-v2.jpg"><meta property="og:type" content="website"><meta property="og:site_name" content="PubMed"><meta name="twitter:domain" content="pubmed.ncbi.nlm.nih.gov"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="chatGPT - Search Results - PubMed"><meta name="twitter:url" content="https://pubmed.ncbi.nlm.nih.gov/?term=chatGPT&amp;format=pubmed&amp;size=200"><meta name="twitter:description" content="chatGPT - Search Results - PubMed"><meta name="twitter:image" content="https://cdn.ncbi.nlm.nih.gov/pubmed/persistent/pubmed-meta-image-v2.jpg">


  <!-- OpenSearch XML -->
  <link rel="search" type="application/opensearchdescription+xml" href="https://cdn.ncbi.nlm.nih.gov/pubmed/persistent/opensearch.xml" title="PubMed search">

  <!-- Disables severely broken elements when no JS -->
  <noscript>
    <link rel="stylesheet" type="text/css" href="https://cdn.ncbi.nlm.nih.gov/pubmed/09ad9aad-98d9-47ec-b2ea-fb4dba3d550d/core/no-script.css">
  </noscript>

  
    <link rel="canonical" href="https://pubmed.ncbi.nlm.nih.gov/?term=chatGPT&amp;format=pubmed&amp;size=200">
  


</head>
<body>

  
  <main class="search-page" id="search-page">
    <div class="search-results" id="search-results">
      
        <pre class="search-results-chunk">PMID- 37215063
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230523
IS  - 2624-8212 (Electronic)
IS  - 2624-8212 (Linking)
VI  - 6
DP  - 2023
TI  - ChatGPT in medicine: an overview of its applications, advantages, limitations, 
      future prospects, and ethical considerations.
PG  - 1169595
LID - 10.3389/frai.2023.1169595 [doi]
LID - 1169595
AB  - This paper presents an analysis of the advantages, limitations, ethical 
      considerations, future prospects, and practical applications of ChatGPT and 
      artificial intelligence (AI) in the healthcare and medical domains. ChatGPT is an 
      advanced language model that uses deep learning techniques to produce human-like 
      responses to natural language inputs. It is part of the family of generative 
      pre-training transformer (GPT) models developed by OpenAI and is currently one of 
      the largest publicly available language models. ChatGPT is capable of capturing 
      the nuances and intricacies of human language, allowing it to generate 
      appropriate and contextually relevant responses across a broad spectrum of 
      prompts. The potential applications of ChatGPT in the medical field range from 
      identifying potential research topics to assisting professionals in clinical and 
      laboratory diagnosis. Additionally, it can be used to help medical students, 
      doctors, nurses, and all members of the healthcare fraternity to know about 
      updates and new developments in their respective fields. The development of 
      virtual assistants to aid patients in managing their health is another important 
      application of ChatGPT in medicine. Despite its potential applications, the use 
      of ChatGPT and other AI tools in medical writing also poses ethical and legal 
      concerns. These include possible infringement of copyright laws, medico-legal 
      complications, and the need for transparency in AI-generated content. In 
      conclusion, ChatGPT has several potential applications in the medical and 
      healthcare fields. However, these applications come with several limitations and 
      ethical considerations which are presented in detail along with future prospects 
      in medicine and healthcare.
CI  - Copyright © 2023 Dave, Athaluri and Singh.
FAU - Dave, Tirth
AU  - Dave T
AD  - Internal Medicine, Bukovinian State Medical University, Chernivtsi, Ukraine.
FAU - Athaluri, Sai Anirudh
AU  - Athaluri SA
AD  - Rangaraya Medical College, Kakinada, Andhra Pradesh, India.
FAU - Singh, Satyam
AU  - Singh S
AD  - GSVM Medical College, Kanpur, Uttar Pradesh, India.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230504
PL  - Switzerland
TA  - Front Artif Intell
JT  - Frontiers in artificial intelligence
JID - 101770551
PMC - PMC10192861
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - artificial intelligence
OT  - generative pre-training transformer
OT  - healthcare
OT  - medicine
OT  - natural language processing
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/05/22 19:11
MHDA- 2023/05/22 19:12
PMCR- 2023/05/04
CRDT- 2023/05/22 12:19
PHST- 2023/02/19 00:00 [received]
PHST- 2023/04/14 00:00 [accepted]
PHST- 2023/05/22 19:12 [medline]
PHST- 2023/05/22 19:11 [pubmed]
PHST- 2023/05/22 12:19 [entrez]
PHST- 2023/05/04 00:00 [pmc-release]
AID - 10.3389/frai.2023.1169595 [doi]
PST - epublish
SO  - Front Artif Intell. 2023 May 4;6:1169595. doi: 10.3389/frai.2023.1169595. 
      eCollection 2023.

PMID- 36811129
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230224
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 2
DP  - 2023 Feb
TI  - Artificial Hallucinations in ChatGPT: Implications in Scientific Writing.
PG  - e35179
LID - 10.7759/cureus.35179 [doi]
LID - e35179
AB  - While still in its infancy, ChatGPT (Generative Pretrained Transformer), 
      introduced in November 2022, is bound to hugely impact many industries, including 
      healthcare, medical education, biomedical research, and scientific writing. 
      Implications of ChatGPT, that new chatbot introduced by OpenAI on academic 
      writing, is largely unknown. In response to the Journal of Medical Science 
      (Cureus) Turing Test - call for case reports written with the assistance of 
      ChatGPT, we present two cases one of homocystinuria-associated osteoporosis, and 
      the other is on late-onset Pompe disease (LOPD), a rare metabolic disorder. We 
      tested ChatGPT to write about the pathogenesis of these conditions. We documented 
      the positive, negative, and rather troubling aspects of our newly introduced 
      chatbot's performance.
CI  - Copyright © 2023, Alkaissi et al.
FAU - Alkaissi, Hussam
AU  - Alkaissi H
AD  - Internal Medicine, Kings County Hospital Center, Brooklyn, USA.
AD  - Internal Medicine, Veterans Affairs Medical Center, Brooklyn, USA.
AD  - Internal Medicine, State University of New York Downstate Medical Center, 
      Brooklyn, USA.
FAU - McFarlane, Samy I
AU  - McFarlane SI
AD  - Internal Medicine, State University of New York Downstate Medical Center, 
      Brooklyn, USA.
LA  - eng
PT  - Editorial
DEP - 20230219
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC9939079
OTO - NOTNLM
OT  - artificial intelligence and education
OT  - artificial intelligence and writing
OT  - artificial intelligence in medicine
OT  - chatbot
OT  - chatgpt
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/02/23 06:00
MHDA- 2023/02/23 06:01
PMCR- 2023/02/19
CRDT- 2023/02/22 15:15
PHST- 2023/02/19 00:00 [accepted]
PHST- 2023/02/22 15:15 [entrez]
PHST- 2023/02/23 06:00 [pubmed]
PHST- 2023/02/23 06:01 [medline]
PHST- 2023/02/19 00:00 [pmc-release]
AID - 10.7759/cureus.35179 [doi]
PST - epublish
SO  - Cureus. 2023 Feb 19;15(2):e35179. doi: 10.7759/cureus.35179. eCollection 2023 
      Feb.

PMID- 37266053
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230604
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 4
DP  - 2023 Apr
TI  - ChatGPT in Dentistry: A Comprehensive Review.
PG  - e38317
LID - 10.7759/cureus.38317 [doi]
LID - e38317
AB  - Chat generative pre-trained transformer (ChatGPT) is an artificial intelligence 
      chatbot that uses natural language processing that can respond to human input in 
      a conversational manner. ChatGPT has numerous applications in the health care 
      system including dentistry; it is used in diagnoses and for assessing disease 
      risk and scheduling appointments. It also has a role in scientific research. In 
      the dental field, it has provided many benefits such as detecting dental and 
      maxillofacial abnormalities on panoramic radiographs and identifying different 
      dental restorations. Therefore, it helps in decreasing the workload. But even 
      with these benefits, one should take into consideration the risks and limitations 
      of this chatbot. Few articles mentioned the use of ChatGPT in dentistry. This 
      comprehensive review represents data collected from 66 relevant articles using 
      PubMed and Google Scholar as databases. This review aims to discuss all relevant 
      published articles on the use of ChatGPT in dentistry.
CI  - Copyright © 2023, Alhaidry et al.
FAU - Alhaidry, Hind M
AU  - Alhaidry HM
AD  - Advanced General Dentistry, Prince Sultan Military Medical City, Riyadh, SAU.
FAU - Fatani, Bader
AU  - Fatani B
AD  - Dentistry, College of Dentistry, King Saud University, Riyadh, SAU.
FAU - Alrayes, Jenan O
AU  - Alrayes JO
AD  - Dentistry, College of Dentistry, King Saud University, Riyadh, SAU.
FAU - Almana, Aljowhara M
AU  - Almana AM
AD  - Dentistry, College of Dentistry, King Saud University, Riyadh, SAU.
FAU - Alfhaed, Nawaf K
AU  - Alfhaed NK
AD  - Dentistry, College of Dentistry, King Saud University, Riyadh, SAU.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230430
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10230850
OTO - NOTNLM
OT  - artificial intelligence
OT  - chatgpt
OT  - dental
OT  - dentistry
OT  - healthcare
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/06/02 13:16
MHDA- 2023/06/02 13:17
PMCR- 2023/04/30
CRDT- 2023/06/02 10:54
PHST- 2023/04/29 00:00 [accepted]
PHST- 2023/06/02 13:17 [medline]
PHST- 2023/06/02 13:16 [pubmed]
PHST- 2023/06/02 10:54 [entrez]
PHST- 2023/04/30 00:00 [pmc-release]
AID - 10.7759/cureus.38317 [doi]
PST - epublish
SO  - Cureus. 2023 Apr 30;15(4):e38317. doi: 10.7759/cureus.38317. eCollection 2023 
      Apr.

PMID- 36867743
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230325
IS  - 2369-3762 (Print)
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Mar 8
TI  - ChatGPT in Clinical Toxicology.
PG  - e46876
LID - 10.2196/46876 [doi]
LID - e46876
AB  - ChatGPT has recently been shown to pass the United States Medical Licensing 
      Examination (USMLE). We tested ChatGPT (Feb 13, 2023 release) using a typical 
      clinical toxicology case of acute organophosphate poisoning. ChatGPT fared well 
      in answering all of our queries regarding it.
CI  - ©Mary Sabry Abdel-Messih, Maged N Kamel Boulos. Originally published in JMIR 
      Medical Education (https://mededu.jmir.org), 08.03.2023.
FAU - Sabry Abdel-Messih, Mary
AU  - Sabry Abdel-Messih M
AUID- ORCID: 0009-0001-3404-0516
AD  - Clinical Toxicology Centre, Forensic Medicine and Clinical Toxicology Department, 
      Faculty of Medicine, Ain Shams University, Cairo, Egypt.
FAU - Kamel Boulos, Maged N
AU  - Kamel Boulos MN
AUID- ORCID: 0000-0003-2400-6303
AD  - School of Medicine, University of Lisbon, Lisbon, Portugal.
LA  - eng
PT  - Journal Article
DEP - 20230308
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
CON - JMIR Med Educ. 9:e45312.
CIN - JMIR Med Educ. 9:e46885.
PMC - PMC10034604
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - artificial intelligence
OT  - clinical toxicology
OT  - medical education
OT  - organophosphates
COIS- Conflicts of Interest: None declared.
EDAT- 2023/03/04 06:00
MHDA- 2023/03/04 06:01
PMCR- 2023/03/08
CRDT- 2023/03/03 15:02
PHST- 2023/02/28 00:00 [received]
PHST- 2023/03/03 00:00 [accepted]
PHST- 2023/03/04 06:00 [pubmed]
PHST- 2023/03/04 06:01 [medline]
PHST- 2023/03/03 15:02 [entrez]
PHST- 2023/03/08 00:00 [pmc-release]
AID - v9i1e46876 [pii]
AID - 10.2196/46876 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Mar 8;9:e46876. doi: 10.2196/46876.

PMID- 37379067
OWN - NLM
STAT- MEDLINE
DCOM- 20230630
LR  - 20231106
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 25
DP  - 2023 Jun 28
TI  - Utility of ChatGPT in Clinical Practice.
PG  - e48568
LID - 10.2196/48568 [doi]
LID - e48568
AB  - ChatGPT is receiving increasing attention and has a variety of application 
      scenarios in clinical practice. In clinical decision support, ChatGPT has been 
      used to generate accurate differential diagnosis lists, support clinical 
      decision-making, optimize clinical decision support, and provide insights for 
      cancer screening decisions. In addition, ChatGPT has been used for intelligent 
      question-answering to provide reliable information about diseases and medical 
      queries. In terms of medical documentation, ChatGPT has proven effective in 
      generating patient clinical letters, radiology reports, medical notes, and 
      discharge summaries, improving efficiency and accuracy for health care providers. 
      Future research directions include real-time monitoring and predictive analytics, 
      precision medicine and personalized treatment, the role of ChatGPT in 
      telemedicine and remote health care, and integration with existing health care 
      systems. Overall, ChatGPT is a valuable tool that complements the expertise of 
      health care providers and improves clinical decision-making and patient care. 
      However, ChatGPT is a double-edged sword. We need to carefully consider and study 
      the benefits and potential dangers of ChatGPT. In this viewpoint, we discuss 
      recent advances in ChatGPT research in clinical practice and suggest possible 
      risks and challenges of using ChatGPT in clinical practice. It will help guide 
      and support future artificial intelligence research similar to ChatGPT in health.
CI  - ©Jialin Liu, Changyu Wang, Siru Liu. Originally published in the Journal of 
      Medical Internet Research (https://www.jmir.org), 28.06.2023.
FAU - Liu, Jialin
AU  - Liu J
AUID- ORCID: 0000-0002-1369-4625
AD  - Information Center, West China Hospital, Sichuan University, Chengdu, China.
AD  - Department of Medical Informatics, West China Medical School, Chengdu, China.
AD  - Department of Otolaryngology-Head and Neck Surgery, West China Hospital, Sichuan 
      University, Chengdu, China.
FAU - Wang, Changyu
AU  - Wang C
AUID- ORCID: 0000-0003-4548-331X
AD  - Information Center, West China Hospital, Sichuan University, Chengdu, China.
AD  - West China College of Stomatology, Sichuan University, Chengdu, China.
FAU - Liu, Siru
AU  - Liu S
AUID- ORCID: 0000-0002-5003-5354
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, TN, United States.
LA  - eng
PT  - Journal Article
DEP - 20230628
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Organizations
MH  - Clinical Decision-Making
MH  - Diagnosis, Differential
MH  - Documentation
PMC - PMC10365580
OTO - NOTNLM
OT  - ChatGPT
OT  - NLP
OT  - artificial intelligence
OT  - barriers
OT  - best practices
OT  - challenges
OT  - clinical practice
OT  - communication
OT  - doctor-patient
OT  - guidance
OT  - guidelines
OT  - large language model
OT  - large language models
OT  - natural language processing
OT  - patient-physician
OT  - recommendations
OT  - risks
COIS- Conflicts of Interest: None declared.
EDAT- 2023/06/28 13:08
MHDA- 2023/06/30 06:42
PMCR- 2023/06/28
CRDT- 2023/06/28 11:53
PHST- 2023/04/28 00:00 [received]
PHST- 2023/06/15 00:00 [accepted]
PHST- 2023/05/29 00:00 [revised]
PHST- 2023/06/30 06:42 [medline]
PHST- 2023/06/28 13:08 [pubmed]
PHST- 2023/06/28 11:53 [entrez]
PHST- 2023/06/28 00:00 [pmc-release]
AID - v25i1e48568 [pii]
AID - 10.2196/48568 [doi]
PST - epublish
SO  - J Med Internet Res. 2023 Jun 28;25:e48568. doi: 10.2196/48568.

PMID- 37168166
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230514
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 4
DP  - 2023 Apr
TI  - ChatGPT for Future Medical and Dental Research.
PG  - e37285
LID - 10.7759/cureus.37285 [doi]
LID - e37285
AB  - ChatGPT is an artificial intelligence&nbsp;(AI) chatbot developed by OpenAI and it 
      first became available to the public in November 2022. ChatGPT can assist in 
      finding academic papers on the web and summarizing them. This chatbot has the 
      potential to be applied in scientific writing, it has the ability to generate 
      automated drafts, summarize articles, and translate content from several 
      languages. This in turn can make academic writing faster and less challenging. 
      However, due to ethical considerations, its use in scientific writing should be 
      regulated and carefully monitored. Few papers have discussed the use of ChatGPT 
      in scientific research writing. This review aims to discuss all the relevant 
      published papers that discuss&nbsp;the use of ChatGPT in medical and dental research.
CI  - Copyright © 2023, Fatani et al.
FAU - Fatani, Bader
AU  - Fatani B
AD  - Dentistry, College of Dentistry, King Saud University, Riyadh, SAU.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230408
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10165936
OTO - NOTNLM
OT  - artificial intelligence
OT  - chatgpt
OT  - dentistry
OT  - medicine
OT  - research
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/05/12 01:07
MHDA- 2023/05/12 01:08
PMCR- 2023/04/08
CRDT- 2023/05/11 19:16
PHST- 2023/04/08 00:00 [accepted]
PHST- 2023/05/12 01:08 [medline]
PHST- 2023/05/12 01:07 [pubmed]
PHST- 2023/05/11 19:16 [entrez]
PHST- 2023/04/08 00:00 [pmc-release]
AID - 10.7759/cureus.37285 [doi]
PST - epublish
SO  - Cureus. 2023 Apr 8;15(4):e37285. doi: 10.7759/cureus.37285. eCollection 2023 Apr.

PMID- 36863937
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230323
IS  - 2369-3762 (Print)
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Mar 6
TI  - The Role of ChatGPT, Generative Language Models, and Artificial Intelligence in 
      Medical Education: A Conversation With ChatGPT and a Call for Papers.
PG  - e46885
LID - 10.2196/46885 [doi]
LID - e46885
AB  - ChatGPT is a generative language model tool launched by OpenAI on November 30, 
      2022, enabling the public to converse with a machine on a broad range of topics. 
      In January 2023, ChatGPT reached over 100 million users, making it the 
      fastest-growing consumer application to date. This interview with ChatGPT is part 
      2 of a larger interview with ChatGPT. It provides a snapshot of the current 
      capabilities of ChatGPT and illustrates the vast potential for medical education, 
      research, and practice but also hints at current problems and limitations. In 
      this conversation with Gunther Eysenbach, the founder and publisher of JMIR 
      Publications, ChatGPT generated some ideas on how to use chatbots in medical 
      education. It also illustrated its capabilities to generate a virtual patient 
      simulation and quizzes for medical students; critiqued a simulated doctor-patient 
      communication and attempts to summarize a research article (which turned out to 
      be fabricated); commented on methods to detect machine-generated text to ensure 
      academic integrity; generated a curriculum for health professionals to learn 
      about artificial intelligence (AI); and helped to draft a call for papers for a 
      new theme issue to be launched in JMIR Medical Education on ChatGPT. The 
      conversation also highlighted the importance of proper "prompting." Although the 
      language generator does make occasional mistakes, it admits these when 
      challenged. The well-known disturbing tendency of large language models to 
      hallucinate became evident when ChatGPT fabricated references. The interview 
      provides a glimpse into the capabilities and limitations of ChatGPT and the 
      future of AI-supported medical education. Due to the impact of this new 
      technology on medical education, JMIR Medical Education is launching a call for 
      papers for a new e-collection and theme issue. The initial draft of the call for 
      papers was entirely machine generated by ChatGPT, but will be edited by the human 
      guest editors of the theme issue.
CI  - ©Gunther Eysenbach. Originally published in JMIR Medical Education 
      (https://mededu.jmir.org), 06.03.2023.
FAU - Eysenbach, Gunther
AU  - Eysenbach G
AUID- ORCID: 0000-0001-6479-5330
AD  - JMIR Publications, Toronto, ON, Canada.
LA  - eng
PT  - Editorial
DEP - 20230306
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
PMC - PMC10028514
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - artificial intelligence
OT  - future of education
OT  - generative language model
OT  - interview
OT  - medical education
COIS- Conflicts of Interest: The author is publisher and editor at JMIR Publications, 
      receives a salary and owns equity.
EDAT- 2023/03/03 06:00
MHDA- 2023/03/03 06:01
PMCR- 2023/03/06
CRDT- 2023/03/02 22:04
PHST- 2023/02/28 00:00 [received]
PHST- 2023/03/02 00:00 [accepted]
PHST- 2023/03/03 06:00 [pubmed]
PHST- 2023/03/03 06:01 [medline]
PHST- 2023/03/02 22:04 [entrez]
PHST- 2023/03/06 00:00 [pmc-release]
AID - v9i1e46885 [pii]
AID - 10.2196/46885 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Mar 6;9:e46885. doi: 10.2196/46885.

PMID- 36916887
OWN - NLM
STAT- Publisher
LR  - 20230928
IS  - 1935-9780 (Electronic)
IS  - 1935-9772 (Linking)
DP  - 2023 Mar 14
TI  - The rise of ChatGPT: Exploring its potential in medical education.
LID - 10.1002/ase.2270 [doi]
AB  - The integration of artificial intelligence (AI) into medical education has the 
      potential to revolutionize the way students learn about biomedical sciences. 
      Large language models, such as ChatGPT, can serve as virtual teaching assistants, 
      providing students with detailed and relevant information and perhaps eventually 
      interactive simulations. ChatGPT has the potential to increase student engagement 
      and enhance student learning, though research is needed to confirm this. The 
      challenges and limitations of ChatGPT must also be considered, including ethical 
      issues and potentially harmful effects. It is crucial for medical educators to 
      keep pace with technology's rapidly changing landscape and consider the 
      implications for curriculum design, assessment strategies, and teaching methods. 
      Continued research and evaluation are necessary to ensure the optimal integration 
      of AI-based learning tools into medical education.
CI  - © 2023 American Association for Anatomy.
FAU - Lee, Hyunsu
AU  - Lee H
AUID- ORCID: 0000-0003-3631-3028
AD  - Department of Medical Informatics, School of Medicine, Keimyung University, #223, 
      1095, Dalgubeoldae-ro, Dalseo-gu, Daegu, Republic of Korea.
LA  - eng
PT  - Journal Article
DEP - 20230314
PL  - United States
TA  - Anat Sci Educ
JT  - Anatomical sciences education
JID - 101392205
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - medical education
OT  - natural language processing
OT  - virtual teaching assistant
EDAT- 2023/03/15 06:00
MHDA- 2023/03/15 06:00
CRDT- 2023/03/14 09:53
PHST- 2023/03/08 00:00 [revised]
PHST- 2023/02/07 00:00 [received]
PHST- 2023/03/09 00:00 [accepted]
PHST- 2023/03/15 06:00 [pubmed]
PHST- 2023/03/15 06:00 [medline]
PHST- 2023/03/14 09:53 [entrez]
AID - 10.1002/ase.2270 [doi]
PST - aheadofprint
SO  - Anat Sci Educ. 2023 Mar 14. doi: 10.1002/ase.2270.

PMID- 36798292
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230907
DP  - 2023 Feb 7
TI  - Evaluating ChatGPT as an Adjunct for Radiologic Decision-Making.
LID - 2023.02.02.23285399 [pii]
LID - 10.1101/2023.02.02.23285399 [doi]
AB  - BACKGROUND: ChatGPT, a popular new large language model (LLM) built by OpenAI, 
      has shown impressive performance in a number of specialized applications. Despite 
      the rising popularity and performance of AI, studies evaluating the use of LLMs 
      for clinical decision support are lacking. PURPOSE: To evaluate ChatGPT's 
      capacity for clinical decision support in radiology via the identification of 
      appropriate imaging services for two important clinical presentations: breast 
      cancer screening and breast pain. MATERIALS AND METHODS: We compared ChatGPT's 
      responses to the American College of Radiology (ACR) Appropriateness Criteria for 
      breast pain and breast cancer screening. Our prompt formats included an 
      open-ended (OE) format, where ChatGPT was asked to provide the single most 
      appropriate imaging procedure, and a select all that apply (SATA) format, where 
      ChatGPT was given a list of imaging modalities to assess. Scoring criteria 
      evaluated whether proposed imaging modalities were in accordance with ACR 
      guidelines. RESULTS: ChatGPT achieved an average OE score of 1.83 (out of 2) and 
      a SATA average percentage correct of 88.9% for breast cancer screening prompts, 
      and an average OE score of 1.125 (out of 2) and a SATA average percentage correct 
      of 58.3% for breast pain prompts. CONCLUSION: Our results demonstrate the 
      feasibility of using ChatGPT for radiologic decision making, with the potential 
      to improve clinical workflow and responsible use of radiology services.
FAU - Rao, Arya
AU  - Rao A
AUID- ORCID: 0000-0003-3007-4812
FAU - Kim, John
AU  - Kim J
FAU - Kamineni, Meghana
AU  - Kamineni M
FAU - Pang, Michael
AU  - Pang M
FAU - Lie, Winston
AU  - Lie W
FAU - Succi, Marc D
AU  - Succi MD
LA  - eng
PT  - Preprint
DEP - 20230207
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
UIN - J Am Coll Radiol. 2023 Jun 21;:. PMID: 37356806
PMC - PMC9934725
EDAT- 2023/02/18 06:00
MHDA- 2023/02/18 06:01
PMCR- 2023/02/16
CRDT- 2023/02/17 02:06
PHST- 2023/02/17 02:06 [entrez]
PHST- 2023/02/18 06:00 [pubmed]
PHST- 2023/02/18 06:01 [medline]
PHST- 2023/02/16 00:00 [pmc-release]
AID - 2023.02.02.23285399 [pii]
AID - 10.1101/2023.02.02.23285399 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2023 Feb 7:2023.02.02.23285399. doi: 
      10.1101/2023.02.02.23285399.

PMID- 37168339
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230514
IS  - 2156-6976 (Print)
IS  - 2156-6976 (Electronic)
IS  - 2156-6976 (Linking)
VI  - 13
IP  - 4
DP  - 2023
TI  - The role of ChatGPT in scientific communication: writing better scientific review 
      articles.
PG  - 1148-1154
AB  - Artificial intelligence tools represent an exciting opportunity for scientists to 
      streamline their research and write impactful articles. Using artificial 
      intelligence tools like ChatGPT can greatly improve writing review articles for 
      scientists, by enhancing efficiency and quality. ChatGPT speeds up writing, 
      develops outlines, adds details, and helps improve writing style. However, 
      ChatGPT's limitations must be kept in mind, and generated text must be reviewed 
      and edited to avoid plagiarism and fabrication. Despite these limitations, 
      ChatGPT is a powerful tool that allows scientists to focus on analyzing and 
      interpreting literature reviews. Embracing these tools can help scientists 
      produce meaningful research in a more efficient and effective manner, however 
      caution must be taken and unchecked use of ChatGPT in writing should be avoided.
CI  - AJCR Copyright © 2023.
FAU - Huang, Jingshan
AU  - Huang J
AD  - School of Computing and College of Medicine, University of South Alabama Mobile, 
      AL, USA.
FAU - Tan, Ming
AU  - Tan M
AD  - Institute of Biochemistry and Molecular Biology, Institute of Biomedical 
      Sciences, and Research Center for Cancer Biology, China Medical University 
      Taichung, Taiwan.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230415
PL  - United States
TA  - Am J Cancer Res
JT  - American journal of cancer research
JID - 101549944
PMC - PMC10164801
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - review article
OT  - scientific writing
COIS- None.
EDAT- 2023/05/12 01:07
MHDA- 2023/05/12 01:08
PMCR- 2023/04/15
CRDT- 2023/05/11 19:19
PHST- 2023/03/13 00:00 [received]
PHST- 2023/03/23 00:00 [accepted]
PHST- 2023/05/12 01:08 [medline]
PHST- 2023/05/12 01:07 [pubmed]
PHST- 2023/05/11 19:19 [entrez]
PHST- 2023/04/15 00:00 [pmc-release]
PST - epublish
SO  - Am J Cancer Res. 2023 Apr 15;13(4):1148-1154. eCollection 2023.

PMID- 36943815
OWN - NLM
STAT- MEDLINE
DCOM- 20230717
LR  - 20231116
IS  - 1527-330X (Electronic)
IS  - 1090-820X (Linking)
VI  - 43
IP  - 8
DP  - 2023 Jul 15
TI  - Expanding Cosmetic Plastic Surgery Research With ChatGPT.
PG  - 930-937
LID - 10.1093/asj/sjad069 [doi]
AB  - BACKGROUND: In the past 3 months, OpenAI, a San Francisco-based artificial 
      intelligence (AI) research laboratory, has released ChatGPT, a conversation large 
      language model. ChatGPT has the ability to answer user questions, admit to 
      mistakes, and learn from users that are accessing the program. OBJECTIVES: Due to 
      the importance of producing evidence-based research in plastic surgery, the 
      authors of this study wanted to determine how accurate ChatGPT could be in 
      creating novel systematic review ideas that encompass the diverse practice of 
      cosmetic surgery. METHODS: ChatGPT was given commands to produce 20 novel 
      systematic review ideas for 12 different topics within cosmetic surgery. For each 
      topic, the system was told to give 10 general and 10 specific ideas that were 
      related to the concept. To determine the accuracy of ChatGPT, a literature review 
      was conducted with PubMed, CINAHL, EMBASE, and Cochrane. RESULTS: A total of 240 
      "novel" systematic review ideas were constructed by ChatGPT. We determined that 
      the system had an overall accuracy of 55%. When topics were stratified by general 
      and specific ideas, we found that ChatGPT was 35% accurate for general ideas and 
      75% accurate for specific ideas. CONCLUSIONS: ChatGPT is an excellent tool that 
      should be utilized by plastic surgeons. ChatGPT is versatile and has uses beyond 
      research, including patient consultation, patient support, and marketing. As 
      advancements in AI continue to be made, it is important for plastic surgeons to 
      consider the utilization of AI in their clinical practice.
CI  - © The Author(s) 2023. Published by Oxford University Press on behalf of The 
      Aesthetic Society. All rights reserved. For permissions, please e-mail: 
      journals.permissions@oup.com.
FAU - Gupta, Rohun
AU  - Gupta R
FAU - Park, John B
AU  - Park JB
FAU - Bisht, Chirag
AU  - Bisht C
FAU - Herzog, Isabel
AU  - Herzog I
AUID- ORCID: 0000-0001-7491-5746
FAU - Weisberger, Joseph
AU  - Weisberger J
FAU - Chao, John
AU  - Chao J
FAU - Chaiyasate, Kongkrit
AU  - Chaiyasate K
FAU - Lee, Edward S
AU  - Lee ES
LA  - eng
PT  - Journal Article
PT  - Review
PL  - England
TA  - Aesthet Surg J
JT  - Aesthetic surgery journal
JID - 9707469
SB  - IM
CIN - Aesthet Surg J. 2023 Aug 17;43(9):NP726-NP727. PMID: 37227006
MH  - Humans
MH  - *Surgery, Plastic
MH  - Artificial Intelligence
MH  - *Plastic Surgery Procedures
MH  - Communication
MH  - Hospitalization
EDAT- 2023/03/22 06:00
MHDA- 2023/07/17 06:42
CRDT- 2023/03/21 13:24
PHST- 2023/07/17 06:42 [medline]
PHST- 2023/03/22 06:00 [pubmed]
PHST- 2023/03/21 13:24 [entrez]
AID - 7082916 [pii]
AID - 10.1093/asj/sjad069 [doi]
PST - ppublish
SO  - Aesthet Surg J. 2023 Jul 15;43(8):930-937. doi: 10.1093/asj/sjad069.

PMID- 36627845
OWN - NLM
STAT- MEDLINE
DCOM- 20230113
LR  - 20230217
IS  - 1975-5937 (Electronic)
IS  - 1975-5937 (Linking)
VI  - 20
DP  - 2023
TI  - Are ChatGPT’s knowledge and interpretation ability comparable to those of medical 
      students in Korea for taking a parasitology examination?: a descriptive study.
PG  - 1
LID - 10.3352/jeehp.2023.20.1 [doi]
LID - 1
AB  - This study aimed to compare the knowledge and interpretation ability of ChatGPT, 
      a language model of artificial general intelligence, with those of medical 
      students in Korea by administering a parasitology examination to both ChatGPT and 
      medical students. The examination consisted of 79 items and was administered to 
      ChatGPT on January 1, 2023. The examination results were analyzed in terms of 
      ChatGPT’s overall performance score, its correct answer rate by the items’ 
      knowledge level, and the acceptability of its explanations of the items. 
      ChatGPT’s performance was lower than that of the medical students, and ChatGPT’s 
      correct answer rate was not related to the items’ knowledge level. However, there 
      was a relationship between acceptable explanations and correct answers. In 
      conclusion, ChatGPT’s knowledge and interpretation ability for this parasitology 
      examination were not yet comparable to those of medical students in Korea.
FAU - Huh, Sun
AU  - Huh S
AD  - Department of Parasitology and Institute of Medical Education, College of 
      Medicine, Hallym University, Chuncheon, Korea.
LA  - eng
PT  - Journal Article
DEP - 20230111
PL  - Korea (South)
TA  - J Educ Eval Health Prof
JT  - Journal of educational evaluation for health professions
JID - 101490061
SB  - IM
MH  - Humans
MH  - Educational Measurement/methods
MH  - Knowledge
MH  - Republic of Korea
MH  - *Students, Medical
MH  - Artificial Intelligence
PMC - PMC9905868
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Educational measurement
OT  - Knowledge
OT  - Medical students
OT  - Republic of Korea
COIS- Conflict of interest Sun Huh has been the editor of the Journal of Educational 
      Evaluation for Health Professions since 2005. He was not involved in the review 
      process. Otherwise, no potential conflict of interest relevant to this article 
      was reported.
EDAT- 2023/01/12 06:00
MHDA- 2023/01/13 06:00
PMCR- 2023/01/11
CRDT- 2023/01/11 01:41
PHST- 2023/01/03 00:00 [received]
PHST- 2023/01/11 00:00 [accepted]
PHST- 2023/01/11 01:41 [entrez]
PHST- 2023/01/12 06:00 [pubmed]
PHST- 2023/01/13 06:00 [medline]
PHST- 2023/01/11 00:00 [pmc-release]
AID - jeehp.2023.20.1 [pii]
AID - jeehp-20-01 [pii]
AID - 10.3352/jeehp.2023.20.1 [doi]
PST - ppublish
SO  - J Educ Eval Health Prof. 2023;20:1. doi: 10.3352/jeehp.2023.20.1. Epub 2023 Jan 
      11.

PMID- 36858933
OWN - NLM
STAT- MEDLINE
DCOM- 20230529
LR  - 20230720
IS  - 2211-5684 (Electronic)
IS  - 2211-5684 (Linking)
VI  - 104
IP  - 6
DP  - 2023 Jun
TI  - Revolutionizing radiology with GPT-based models: Current applications, future 
      possibilities and limitations of ChatGPT.
PG  - 269-274
LID - S2211-5684(23)00027-X [pii]
LID - 10.1016/j.diii.2023.02.003 [doi]
AB  - Artificial intelligence has demonstrated utility and is increasingly being used 
      in the field of radiology. The use of generative pre-trained transformer 
      (GPT)-based models has the potential to revolutionize the field of radiology, 
      offering new possibilities for improving accuracy, efficiency, and patient 
      outcome. Current applications of GPT-based models in radiology include report 
      generation, educational support, clinical decision support, patient 
      communication, and data analysis. As these models continue to advance and 
      improve, it is likely that more innovative uses for GPT-based models in the field 
      of radiology at large will be developed, further enhancing the role of technology 
      in the diagnostic process. ChatGPT is a variant of GPT that is specifically 
      fine-tuned for conversational language understanding and generation. This article 
      reports some answers provided by ChatGPT to various questions that radiologists 
      may have regarding ChatGPT and identifies the potential benefits ChatGPT may 
      offer in their daily practice but also current limitations. Similar to other 
      applications of artificial intelligence in the field of imaging, further formal 
      validation of ChatGPT is required.
CI  - Copyright © 2023 Société française de radiologie. Published by Elsevier Masson 
      SAS. All rights reserved.
FAU - Lecler, Augustin
AU  - Lecler A
AD  - Department of Neuroradiology, Foundation Adolphe de Rothschild Hospital, 75019 
      Paris, France; Université Paris Cité, 75006 Paris, France. Electronic address: 
      alecler@for.paris.
FAU - Duron, Loïc
AU  - Duron L
AD  - Department of Neuroradiology, Foundation Adolphe de Rothschild Hospital, 75019 
      Paris, France.
FAU - Soyer, Philippe
AU  - Soyer P
AD  - Université Paris Cité, 75006 Paris, France; Department of Radiology, Hopital 
      Cochin, AP-HP, 75014 Paris, France.
LA  - eng
PT  - Journal Article
DEP - 20230228
PL  - France
TA  - Diagn Interv Imaging
JT  - Diagnostic and interventional imaging
JID - 101568499
SB  - IM
CIN - Diagn Interv Imaging. 2023 Jun;104(6):263-264. PMID: 36925365
MH  - Humans
MH  - *Artificial Intelligence
MH  - Radiography
MH  - *Radiology
MH  - Radiologists
MH  - Communication
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Generative pre-trained transformer (GPT)
OT  - Radiology
COIS- Disclosure of interest Philippe Soyer is the Editor-in-Chief of Diagnostic &amp; 
      Interventional Imaging. The other authors have no conflicts of interest to 
      declare.
EDAT- 2023/03/02 06:00
MHDA- 2023/05/29 06:42
CRDT- 2023/03/01 22:04
PHST- 2023/02/08 00:00 [received]
PHST- 2023/02/10 00:00 [accepted]
PHST- 2023/05/29 06:42 [medline]
PHST- 2023/03/02 06:00 [pubmed]
PHST- 2023/03/01 22:04 [entrez]
AID - S2211-5684(23)00027-X [pii]
AID - 10.1016/j.diii.2023.02.003 [doi]
PST - ppublish
SO  - Diagn Interv Imaging. 2023 Jun;104(6):269-274. doi: 10.1016/j.diii.2023.02.003. 
      Epub 2023 Feb 28.

PMID- 37085182
OWN - NLM
STAT- MEDLINE
DCOM- 20230529
LR  - 20230804
IS  - 1473-4893 (Electronic)
IS  - 1470-2118 (Linking)
VI  - 23
IP  - 3
DP  - 2023 May
TI  - Early applications of ChatGPT in medical practice, education and research.
PG  - 278-279
LID - 10.7861/clinmed.2023-0078 [doi]
AB  - ChatGPT, which can automatically generate written responses to queries using 
      internet sources, soon went viral after its release at the end of 2022. The 
      performance of ChatGPT on medical exams shows results near the passing threshold, 
      making it comparable to third-year medical students. It can also write academic 
      abstracts or reviews at an acceptable level. However, it is not clear how ChatGPT 
      deals with harmful content, misinformation or plagiarism; therefore, authors 
      using ChatGPT professionally for academic writing should be cautious. ChatGPT 
      also has the potential to facilitate the interaction between healthcare providers 
      and patients in various ways. However, sophisticated tasks such as understanding 
      the human anatomy are still a limitation of ChatGPT. ChatGPT can simplify 
      radiological reports, but the possibility of incorrect statements and missing 
      medical information remain. Although ChatGPT has the potential to change medical 
      practice, education and research, further improvements of this application are 
      needed for regular use in medicine.
CI  - © Royal College of Physicians 2023. All rights reserved.
FAU - Sedaghat, Sam
AU  - Sedaghat S
AD  - University Hospital of Heidelberg, Heidelberg, Germany samsedaghat1@gmail.com.
LA  - eng
PT  - Journal Article
DEP - 20230421
PL  - England
TA  - Clin Med (Lond)
JT  - Clinical medicine (London, England)
JID - 101092853
SB  - IM
CIN - Clin Med (Lond). 2023 Jul;23(4):429-430. PMID: 37524422
MH  - Humans
MH  - Educational Status
MH  - Health Personnel
MH  - Internet
MH  - *Medicine
MH  - *Students, Medical
OTO - NOTNLM
OT  - ChatGPT
OT  - academic writing
OT  - artificial intelligence
OT  - healthcare
OT  - medical education
EDAT- 2023/04/22 10:42
MHDA- 2023/05/29 06:42
CRDT- 2023/04/21 20:52
PHST- 2023/05/29 06:42 [medline]
PHST- 2023/04/22 10:42 [pubmed]
PHST- 2023/04/21 20:52 [entrez]
AID - clinmed.2023-0078 [pii]
AID - 10.7861/clinmed.2023-0078 [doi]
PST - ppublish
SO  - Clin Med (Lond). 2023 May;23(3):278-279. doi: 10.7861/clinmed.2023-0078. Epub 
      2023 Apr 21.

PMID- 37780993
OWN - NLM
STAT- MEDLINE
DCOM- 20231031
LR  - 20231031
IS  - 1551-4056 (Electronic)
IS  - 0044-0086 (Print)
IS  - 0044-0086 (Linking)
VI  - 96
IP  - 3
DP  - 2023 Sep
TI  - ChatGPT and the Future of Journal Reviews: A Feasibility Study.
PG  - 415-420
LID - 10.59249/SKDH9286 [doi]
AB  - The increasing volume of research submissions to academic journals poses a 
      significant challenge for traditional peer-review processes. To address this 
      issue, this study explores the potential of employing ChatGPT, an advanced large 
      language model (LLM), developed by OpenAI, as an artificial intelligence (AI) 
      reviewer for academic journals. By leveraging the vast knowledge and natural 
      language processing capabilities of ChatGPT, we hypothesize it may be possible to 
      enhance the efficiency, consistency, and quality of the peer-review process. This 
      research investigated key aspects of integrating ChatGPT into the journal review 
      workflow. We compared the critical analysis of ChatGPT, acting as an AI reviewer, 
      to human reviews for a single published article. Our methodological framework 
      involved subjecting ChatGPT to an intricate examination, wherein its evaluative 
      acumen was juxtaposed against human-authored reviews of a singular published 
      article. As this is a feasibility study, one article was reviewed, which was a 
      case report on scurvy. The entire article was used as an input into ChatGPT and 
      commanded it to "Please perform a review of the following article and give points 
      for revision." Since this was a case report with a limited word count the entire 
      article could fit in one chat box. The output by ChatGPT was then compared with 
      the comments by human reviewers. Key performance metrics, including precision and 
      overall agreement, were judiciously and subjectively measured to portray the 
      efficacy of ChatGPT as an AI reviewer in comparison to its human counterparts. 
      The outcomes of this rigorous analysis unveiled compelling evidence regarding 
      ChatGPT's performance as an AI reviewer. We demonstrated that ChatGPT's critical 
      analyses aligned with those of human reviewers, as evidenced by the inter-rater 
      agreement. Notably, ChatGPT exhibited commendable capability in identifying 
      methodological flaws, articulating insightful feedback on theoretical frameworks, 
      and gauging the overall contribution of the articles to their respective fields. 
      While the integration of ChatGPT showcased immense promise, certain challenges 
      and caveats surfaced. For example, ambiguities might present with complex 
      research articles, leading to nuanced discrepancies between AI and human reviews. 
      Also figures and images cannot be reviewed by ChatGPT. Lengthy articles need to 
      be reviewed in parts by ChatGPT as the entire article will not fit in one 
      chat/response. The benefits consist of reduction in time needed by journals to 
      review the articles submitted to them, as well as an AI assistant to give a 
      different perspective about the research papers other than the human reviewers. 
      In conclusion, this research contributes a groundbreaking foundation for 
      incorporating ChatGPT into the pantheon of journal reviewers. The delineated 
      guidelines distill key insights into operationalizing ChatGPT as a proficient 
      reviewer within academic journal frameworks, paving the way for a more efficient 
      and insightful review process.
CI  - Copyright ©2023, Yale Journal of Biology and Medicine.
FAU - Biswas, Som
AU  - Biswas S
AD  - Le Bonheur Children's Hospital, The University of Tennessee Health Science 
      Center, Memphis, TN, USA.
FAU - Dobaria, Dushyant
AU  - Dobaria D
AD  - Le Bonheur Children's Hospital, The University of Tennessee Health Science 
      Center, Memphis, TN, USA.
FAU - Cohen, Harris L
AU  - Cohen HL
AD  - Le Bonheur Children's Hospital, The University of Tennessee Health Science 
      Center, Memphis, TN, USA.
LA  - eng
PT  - Case Reports
PT  - Journal Article
PT  - Review
DEP - 20230929
PL  - United States
TA  - Yale J Biol Med
JT  - The Yale journal of biology and medicine
JID - 0417414
SB  - IM
MH  - Humans
MH  - Feasibility Studies
MH  - *Artificial Intelligence
PMC - PMC10524821
OTO - NOTNLM
OT  - chatGPT
OT  - journal review
OT  - review
EDAT- 2023/10/02 06:42
MHDA- 2023/10/31 06:42
PMCR- 2023/09/29
CRDT- 2023/10/02 04:37
PHST- 2023/10/31 06:42 [medline]
PHST- 2023/10/02 06:42 [pubmed]
PHST- 2023/10/02 04:37 [entrez]
PHST- 2023/09/29 00:00 [pmc-release]
AID - yjbm963415 [pii]
AID - 10.59249/SKDH9286 [doi]
PST - epublish
SO  - Yale J Biol Med. 2023 Sep 29;96(3):415-420. doi: 10.59249/SKDH9286. eCollection 
      2023 Sep.

PMID- 37705820
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230916
IS  - 0970-0358 (Print)
IS  - 1998-376X (Electronic)
IS  - 0970-0358 (Linking)
VI  - 56
IP  - 4
DP  - 2023 Aug
TI  - ChatGPT in Plastic and Reconstructive Surgery.
PG  - 320-325
LID - 10.1055/s-0043-1771514 [doi]
AB  - Background  Chat Generative Pre-Trained Transformer (ChatGPT) is a versatile 
      large language model-based generative artificial intelligence. It is proficient 
      in a variety of tasks from drafting emails to coding to composing music to 
      passing medical licensing exams. While the potential role of ChatGPT in plastic 
      surgery is promising, evidence-based research is needed to guide its 
      implementation in practice. Methods  This review aims to summarize the literature 
      surrounding ChatGPT's use in plastic surgery. Results  A literature search 
      revealed several applications for ChatGPT in the field of plastic surgery, 
      including the ability to create academic literature and to aid the production of 
      research. However, the ethical implications of using such chatbots in scientific 
      writing requires careful consideration. ChatGPT can also generate high-quality 
      patient discharge summaries and operation notes within seconds, freeing up busy 
      junior doctors to complete other tasks. However, currently clinical information 
      must still be manually inputted, and clinicians must consider data privacy 
      implications. Its use in aiding patient communication and education and training 
      is also widely documented in the literature. However, questions have been raised 
      over the accuracy of answers generated given that current versions of ChatGPT 
      cannot access the most up-to-date sources. Conclusions  While one must be aware 
      of its shortcomings, ChatGPT is a useful tool for plastic surgeons to improve 
      productivity for a range of tasks from manuscript preparation to healthcare 
      communication generation to drafting teaching sessions to studying and learning. 
      As access improves and technology becomes more refined, surely more uses for 
      ChatGPT in plastic surgery will become apparent.
CI  - Association of Plastic Surgeons of India. This is an open access article 
      published by Thieme under the terms of the Creative Commons 
      Attribution-NonDerivative-NonCommercial License, permitting copying and 
      reproduction so long as the original work is given appropriate credit. Contents 
      may not be used for commercial purposes, or adapted, remixed, transformed or 
      built upon. ( https://creativecommons.org/licenses/by-nc-nd/4.0/ ).
FAU - Sharma, Sanjeev Chaand
AU  - Sharma SC
AUID- ORCID: 0000-0002-8355-7765
AD  - Department of Plastic Surgery, Leicester Royal Infirmary, Infirmary Square, 
      Leicester, United Kingdom.
FAU - Ramchandani, Jai Parkash
AU  - Ramchandani JP
AD  - Faculty of Life Sciences &amp; Medicine, King's College London, Guy's Campus, Great 
      Maze Pond, London, United Kingdom.
FAU - Thakker, Arjuna
AU  - Thakker A
AD  - Academic Team of Musculoskeletal Surgery, Leicester General Hospital, University 
      Hospitals of Leicester NHS Trust, United Kingdom.
FAU - Lahiri, Anindya
AU  - Lahiri A
AUID- ORCID: 0000-0003-1739-4731
AD  - Department of Plastic Surgery, Sandwell General Hospital, West Bromwich, United 
      Kingdom.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230802
PL  - Germany
TA  - Indian J Plast Surg
JT  - Indian journal of plastic surgery : official publication of the Association of 
      Plastic Surgeons of India
JID - 8405356
PMC - PMC10497341
OTO - NOTNLM
OT  - ChatGPT
OT  - Chatbot
OT  - artificial intelligence
OT  - large language models
COIS- Conflict of Interest None declared.
EDAT- 2023/09/14 06:42
MHDA- 2023/09/14 06:43
PMCR- 2023/08/01
CRDT- 2023/09/14 04:07
PHST- 2023/09/14 06:43 [medline]
PHST- 2023/09/14 06:42 [pubmed]
PHST- 2023/09/14 04:07 [entrez]
PHST- 2023/08/01 00:00 [pmc-release]
AID - IJPS-23-6-2243 [pii]
AID - 10.1055/s-0043-1771514 [doi]
PST - epublish
SO  - Indian J Plast Surg. 2023 Aug 2;56(4):320-325. doi: 10.1055/s-0043-1771514. 
      eCollection 2023 Aug.

PMID- 37802491
OWN - NLM
STAT- MEDLINE
DCOM- 20231216
LR  - 20231216
IS  - 2042-1834 (Electronic)
IS  - 0025-8172 (Linking)
VI  - 91
IP  - 4
DP  - 2023 Dec
TI  - ChatGPT in medical research: challenging time ahead.
PG  - 223-225
LID - 10.1177/00258172231184548 [doi]
AB  - Since its launch, ChatGPT, an artificial intelligence-powered language model 
      tool, has generated significant attention in research writing. The use of ChatGPT 
      in medical research can be a double-edged sword. ChatGPT can expedite the 
      research writing process by assisting with hypothesis formulation, literature 
      review, data analysis and manuscript writing. On the other hand, using ChatGPT 
      raises concerns regarding the originality and authenticity of content, the 
      precision and potential bias of the tool's output, and the potential legal issues 
      associated with privacy, confidentiality and plagiarism. The article also calls 
      for adherence to stringent citation guidelines and the development of regulations 
      promoting the responsible application of AI. Despite the revolutionary 
      capabilities of ChatGPT, the article highlights its inability to replicate human 
      thought and the difficulties in maintaining the integrity and reliability of 
      ChatGPT-enabled research, particularly in complex fields such as medicine and 
      law. AI tools can be used as supplementary aids rather than primary sources of 
      analysis in medical research writing.
FAU - Bhargava, Daideepya C
AU  - Bhargava DC
AD  - Department of Forensic Medicine and Toxicology, All India Institute of Medical 
      Sciences, India.
FAU - Jadav, Devendra
AU  - Jadav D
AUID- ORCID: 0000-0001-7975-2130
AD  - Department of Forensic Medicine and Toxicology, All India Institute of Medical 
      Sciences, India.
FAU - Meshram, Vikas P
AU  - Meshram VP
AD  - Department of Forensic Medicine and Toxicology, All India Institute of Medical 
      Sciences, India.
FAU - Kanchan, Tanuj
AU  - Kanchan T
AD  - Department of Forensic Medicine and Toxicology, All India Institute of Medical 
      Sciences, India.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20231006
PL  - England
TA  - Med Leg J
JT  - The Medico-legal journal
JID - 0412004
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Reproducibility of Results
MH  - *Biomedical Research
MH  - Privacy
MH  - Upper Extremity
OTO - NOTNLM
OT  - ChatGPT
OT  - Medical research
OT  - accuracy
OT  - artificial intelligence
OT  - ethical considerations
OT  - research misconduct
COIS- Declaration of conflicting interestsThe author(s) declared no potential conflicts 
      of interest with respect to the research, authorship, and/or publication of this 
      article.
EDAT- 2023/10/07 00:41
MHDA- 2023/12/17 09:44
CRDT- 2023/10/06 19:42
PHST- 2023/12/17 09:44 [medline]
PHST- 2023/10/07 00:41 [pubmed]
PHST- 2023/10/06 19:42 [entrez]
AID - 10.1177/00258172231184548 [doi]
PST - ppublish
SO  - Med Leg J. 2023 Dec;91(4):223-225. doi: 10.1177/00258172231184548. Epub 2023 Oct 
      6.

PMID- 37038381
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230412
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 4
DP  - 2023 Apr
TI  - Overview of Early ChatGPT's Presence in Medical Literature: Insights From a 
      Hybrid Literature Review by ChatGPT and Human Experts.
PG  - e37281
LID - 10.7759/cureus.37281 [doi]
LID - e37281
AB  - ChatGPT, an artificial intelligence chatbot, has rapidly gained prominence in 
      various domains, including medical education and healthcare literature. This 
      hybrid narrative review, conducted collaboratively by human authors and ChatGPT, 
      aims to summarize and synthesize the current knowledge of ChatGPT in the indexed 
      medical literature during its initial four months. A search strategy was employed 
      in PubMed and EuropePMC databases, yielding 65 and 110 papers, respectively. 
      These papers focused on ChatGPT's impact on medical education, scientific 
      research, medical writing, ethical considerations, diagnostic decision-making, 
      automation potential, and criticisms. The findings indicate a growing body of 
      literature on ChatGPT's applications and implications in healthcare, highlighting 
      the need for further research to assess its effectiveness and ethical concerns.
CI  - Copyright © 2023, Temsah et al.
FAU - Temsah, Omar
AU  - Temsah O
AD  - Collage of Medicine, Alfaisal University, Riyadh, SAU.
FAU - Khan, Samina A
AU  - Khan SA
AD  - Computer Sciences, Universiti Sains Malaysia, Penang, MYS.
FAU - Chaiah, Yazan
AU  - Chaiah Y
AD  - College of Medicine, Alfaisal University, Riyadh, SAU.
FAU - Senjab, Abdulrahman
AU  - Senjab A
AD  - College of Medicine, Alfaisal University, Riyadh, SAU.
FAU - Alhasan, Khalid
AU  - Alhasan K
AD  - Pediatric Nephrology, King Saud University, Riyadh, SAU.
FAU - Jamal, Amr
AU  - Jamal A
AD  - Family and Community Medicine, King Saud University, Riyadh, SAU.
FAU - Aljamaan, Fadi
AU  - Aljamaan F
AD  - Critical Care, King Saud University, Riyadh, SAU.
FAU - Malki, Khalid H
AU  - Malki KH
AD  - Otolaryngology, King Saud University, Riyadh, SAU.
FAU - Halwani, Rabih
AU  - Halwani R
AD  - Clinical Sciences, University of Sharjah, Sharjah, ARE.
FAU - Al-Tawfiq, Jaffar A
AU  - Al-Tawfiq JA
AD  - Specialty Internal Medicine and Quality, Johns Hopkins Aramco Healthcare, 
      Dhahran, SAU.
FAU - Temsah, Mohamad-Hani
AU  - Temsah MH
AD  - Pediatric Intensive Care, King Saud University, Riyadh, SAU.
FAU - Al-Eyadhy, Ayman
AU  - Al-Eyadhy A
AD  - Pediatric Intensive Care, King Saud University, Riyadh, SAU.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230408
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10082551
OTO - NOTNLM
OT  - artificial intelligence in medicine
OT  - chatgpt
OT  - diagnostic decision-making
OT  - ethical considerations
OT  - generative language model
OT  - hybrid method
OT  - machine learning (ml)
OT  - medical education
OT  - medical practice
OT  - medical writing
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/04/12 06:00
MHDA- 2023/04/12 06:01
PMCR- 2023/04/08
CRDT- 2023/04/11 01:43
PHST- 2023/04/07 00:00 [accepted]
PHST- 2023/04/12 06:01 [medline]
PHST- 2023/04/11 01:43 [entrez]
PHST- 2023/04/12 06:00 [pubmed]
PHST- 2023/04/08 00:00 [pmc-release]
AID - 10.7759/cureus.37281 [doi]
PST - epublish
SO  - Cureus. 2023 Apr 8;15(4):e37281. doi: 10.7759/cureus.37281. eCollection 2023 Apr.

PMID- 37779749
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231030
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 8
DP  - 2023 Aug
TI  - ChatGPT in Medical Education and Research: A Boon or a Bane?
PG  - e44316
LID - 10.7759/cureus.44316 [doi]
LID - e44316
AB  - Science fiction literature and films no longer focus on artificial intelligence. 
      In contrast to all other aspects of life, medical education and clinical patient 
      care have been progressing slowly. Recently, a lot of text from the internet was 
      used to construct and train chatbots, especially ChatGPT. The language model 
      ChatGPT, created by OpenAI, has emerged as a useful resource for medical research 
      and education. It has proven to be a useful tool for researchers, students, and 
      medical professionals because of its capacity to produce human-like answers to 
      challenging medical queries. However, using ChatGPT also has significant 
      drawbacks. The possibility of erroneous or biased information being spread, which 
      could have negative effects on patient care, is one of the key worries. Moreover, 
      the overreliance on technology in medical education could also lead to a decline 
      in critical thinking and clinical decision-making skills. Overall, ChatGPT has 
      the potential to be a boon to medical education and research, but its use must be 
      accompanied by caution and critical evaluation.
CI  - Copyright © 2023, Jeyaraman et al.
FAU - Jeyaraman, Madhan
AU  - Jeyaraman M
AD  - Orthopaedics, South Texas Orthopaedic Research Institute (STORI), Laredo, USA.
AD  - Orthopaedics, ACS Medical College and Hospital, Dr MGR Educational and Research 
      Institute, Chennai, IND.
FAU - K, Shanmuga Priya
AU  - K SP
AD  - Pulmonology, Faculty of Medicine, Sri Lalithambigai Medical College and Hospital, 
      Dr MGR Educational and Research Institute, Chennai, IND.
FAU - Jeyaraman, Naveen
AU  - Jeyaraman N
AD  - Orthopaedics, ACS Medical College and Hospital, Dr MGR Educational and Research 
      Institute, Chennai, IND.
FAU - Nallakumarasamy, Arulkumar
AU  - Nallakumarasamy A
AD  - Orthopaedics, ACS Medical College and Hospital, Dr MGR Educational and Research 
      Institute, Chennai, IND.
FAU - Yadav, Sankalp
AU  - Yadav S
AD  - Medicine, Shri Madan Lal Khurana Chest Clinic, New Delhi, IND.
FAU - Bondili, Suresh K
AU  - Bondili SK
AD  - Medical Oncology, Kauvery Hospital, Chennai, IND.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230829
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10536401
OTO - NOTNLM
OT  - ai &amp; robotics in healthcare
OT  - artificial intelligence
OT  - chatgpt
OT  - medical education
OT  - open ai
OT  - research
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/10/02 06:42
MHDA- 2023/10/02 06:43
PMCR- 2023/08/29
CRDT- 2023/10/02 04:17
PHST- 2023/08/29 00:00 [accepted]
PHST- 2023/10/02 06:43 [medline]
PHST- 2023/10/02 06:42 [pubmed]
PHST- 2023/10/02 04:17 [entrez]
PHST- 2023/08/29 00:00 [pmc-release]
AID - 10.7759/cureus.44316 [doi]
PST - epublish
SO  - Cureus. 2023 Aug 29;15(8):e44316. doi: 10.7759/cureus.44316. eCollection 2023 
      Aug.

PMID- 36990890
OWN - NLM
STAT- MEDLINE
DCOM- 20230421
LR  - 20230422
IS  - 1873-5487 (Electronic)
IS  - 0188-4409 (Linking)
VI  - 54
IP  - 3
DP  - 2023 Apr
TI  - ChatGPT and Publication Ethics.
PG  - 272-274
LID - S0188-4409(23)00038-3 [pii]
LID - 10.1016/j.arcmed.2023.03.004 [doi]
AB  - Academic publishing is crucial for scientific communication, is governed by 
      accepted ethical norms, and underpins the collective literature on basic science, 
      and technological and medical principles and advances. In November 2022, the 
      public and professional global communities, including the scientific community, 
      witnessed the release of ChatGPT by OpenAI in San Francisco, California, USA. 
      Excluding its public appeal and entertaining aspects but considering its diverse 
      potential applications, some ethical concerns must be considered before 
      establishing guidelines on using and including ChatGPT or similar platforms in 
      scientific publishing. Some academic publishers and preprints have accepted 
      manuscripts with ChatGPT listed as a "co-author". Though excluding such platforms 
      from scientific publishing may not be practicable with time, establishing ethical 
      principles is essential before ChatGPT could become a "co-author" in any 
      scientific, published manuscript.
CI  - Copyright © 2023 Instituto Mexicano del Seguro Social (IMSS). Published by 
      Elsevier Inc. All rights reserved.
FAU - Rahimi, Farid
AU  - Rahimi F
AD  - Research School of Biology, The Australian National University, Ngunnawal and 
      Ngambri Country, Canberra, ACT, Australia.
FAU - Talebi Bezmin Abadi, Amin
AU  - Talebi Bezmin Abadi A
AD  - Department of Bacteriology, Faculty of Medical Sciences, Tarbiat Modares 
      University, Tehran, Iran. Electronic address: amin.talebi@modares.ac.ir.
LA  - eng
PT  - Letter
DEP - 20230327
PL  - United States
TA  - Arch Med Res
JT  - Archives of medical research
JID - 9312706
SB  - IM
MH  - *Publishing
MH  - *Moral Obligations
EDAT- 2023/03/30 06:00
MHDA- 2023/04/21 06:41
CRDT- 2023/03/29 22:06
PHST- 2023/02/22 00:00 [received]
PHST- 2023/03/07 00:00 [accepted]
PHST- 2023/04/21 06:41 [medline]
PHST- 2023/03/30 06:00 [pubmed]
PHST- 2023/03/29 22:06 [entrez]
AID - S0188-4409(23)00038-3 [pii]
AID - 10.1016/j.arcmed.2023.03.004 [doi]
PST - ppublish
SO  - Arch Med Res. 2023 Apr;54(3):272-274. doi: 10.1016/j.arcmed.2023.03.004. Epub 
      2023 Mar 27.

PMID- 37433672
OWN - NLM
STAT- MEDLINE
DCOM- 20230907
LR  - 20230907
IS  - 1535-5675 (Electronic)
IS  - 0091-4916 (Linking)
VI  - 51
IP  - 3
DP  - 2023 Sep
TI  - A Conversation with ChatGPT.
PG  - 255-260
LID - 10.2967/jnmt.123.265864 [doi]
AB  - ChatGPT chatbot powered by GPT 3.5 was released in late November 2022 but has 
      been rapidly assimilated into educational and clinical environments. Method: 
      Insight into ChatGPT capabilities was undertaken in an interview-style approach 
      with the chatbot itself. Results: ChatGPT powered by GPT 3.5 exudes confidence in 
      its capabilities in supporting and enhancing student learning in nuclear medicine 
      and in supporting clinical practice. ChatGPT is also self-aware of limitations 
      and flaws in capabilities and the risks these pose to academic integrity. 
      Conclusion: Further objective evaluation of ChatGPT capabilities in authentic 
      learning and clinical scenarios is required.
CI  - © 2023 by the Society of Nuclear Medicine and Molecular Imaging.
FAU - Currie, Geoffrey
AU  - Currie G
AD  - Charles Sturt University, Wagga Wagga, New South Wales, Australia 
      gcurrie@csu.edu.au.
LA  - eng
PT  - Journal Article
DEP - 20230711
PL  - United States
TA  - J Nucl Med Technol
JT  - Journal of nuclear medicine technology
JID - 0430303
SB  - IM
MH  - Humans
MH  - *Learning
MH  - *Nuclear Medicine
MH  - Software
MH  - Students
OTO - NOTNLM
OT  - academic integrity
OT  - artificial intelligence
OT  - generative AI
OT  - higher education
OT  - language model
OT  - tertiary education
EDAT- 2023/07/12 01:07
MHDA- 2023/09/07 06:42
CRDT- 2023/07/11 21:38
PHST- 2023/04/12 00:00 [received]
PHST- 2023/05/13 00:00 [revised]
PHST- 2023/09/07 06:42 [medline]
PHST- 2023/07/12 01:07 [pubmed]
PHST- 2023/07/11 21:38 [entrez]
AID - jnmt.123.265864 [pii]
AID - 10.2967/jnmt.123.265864 [doi]
PST - ppublish
SO  - J Nucl Med Technol. 2023 Sep;51(3):255-260. doi: 10.2967/jnmt.123.265864. Epub 
      2023 Jul 11.

PMID- 37328321
OWN - NLM
STAT- MEDLINE
DCOM- 20231002
LR  - 20231002
IS  - 1873-4898 (Electronic)
IS  - 1477-5131 (Linking)
VI  - 19
IP  - 5
DP  - 2023 Oct
TI  - ChatGPT and large language model (LLM) chatbots: The current state of 
      acceptability and a proposal for guidelines on utilization in academic medicine.
PG  - 598-604
LID - S1477-5131(23)00224-3 [pii]
LID - 10.1016/j.jpurol.2023.05.018 [doi]
AB  - INTRODUCTION: There is currently no clear consensus on the standards for using 
      large language models such as ChatGPT in academic medicine. Hence, we performed a 
      scoping review of available literature to understand the current state of LLM use 
      in medicine and to provide a guideline for future utilization in academia. 
      MATERIALS AND METHODS: A scoping review of the literature was performed through a 
      Medline search on February 16, 2023 using a combination of keywords including 
      artificial intelligence, machine learning, natural language processing, 
      generative pre-trained transformer, ChatGPT, and large language model. There were 
      no restrictions to language or date of publication. Records not pertaining to 
      LLMs were excluded. Records pertaining to LLM ChatBots and ChatGPT were 
      identified and evaluated separately. Among the records pertaining to LLM ChatBots 
      and ChatGPT, those that suggest recommendations for ChatGPT use in academia were 
      utilized to create guideline statements for ChatGPT and LLM use in academic 
      medicine. RESULTS: A total of 87 records were identified. 30 records were not 
      pertaining to large language models and were excluded. 54 records underwent a 
      full-text review for evaluation. There were 33 records related to LLM ChatBots or 
      ChatGPT. DISCUSSION: From assessing these texts, five guideline statements for 
      LLM use was developed: (1) ChatGPT/LLM cannot be cited as an author in scientific 
      manuscripts; (2) If use of ChatGPT/LLM are considered for use in academic work, 
      author(s) should have at least a basic understanding of what ChatGPT/LLM is; (3) 
      Do not use ChatGPT/LLM to produce entirety of text in manuscripts; humans must be 
      held accountable for use of ChatGPT/LLM and contents created by ChatGPT/LLM 
      should be meticulously verified by humans; (4) ChatGPT/LLMs may be used for 
      editing and refining of text; (5) Any use of ChatGPT/LLM should be transparent 
      and should be clearly outlined in scientific manuscripts and acknowledged. 
      CONCLUSION: Future authors should remain mindful of the potential impact their 
      academic work may have on healthcare and continue to uphold the highest ethical 
      standards and integrity when utilizing ChatGPT/LLM.
CI  - Copyright © 2023 Journal of Pediatric Urology Company. Published by Elsevier Ltd. 
      All rights reserved.
FAU - Kim, Jin K
AU  - Kim JK
AD  - Division of Urology, Department of Surgery, The Hospital for Sick Children, 
      Toronto, Canada; Division of Urology, Department of Surgery, University of 
      Toronto, Toronto, Canada. Electronic address: jjk.kim@mail.utoronto.ca.
FAU - Chua, Michael
AU  - Chua M
AD  - Division of Urology, Department of Surgery, The Hospital for Sick Children, 
      Toronto, Canada; Division of Urology, Department of Surgery, University of 
      Toronto, Toronto, Canada; Institute of Urology, St. Luke's Medical Center, Quezon 
      City, Philippines.
FAU - Rickard, Mandy
AU  - Rickard M
AD  - Division of Urology, Department of Surgery, The Hospital for Sick Children, 
      Toronto, Canada.
FAU - Lorenzo, Armando
AU  - Lorenzo A
AD  - Division of Urology, Department of Surgery, The Hospital for Sick Children, 
      Toronto, Canada; Division of Urology, Department of Surgery, University of 
      Toronto, Toronto, Canada.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230602
PL  - England
TA  - J Pediatr Urol
JT  - Journal of pediatric urology
JID - 101233150
SB  - IM
CIN - J Pediatr Urol. 2023 Oct;19(5):605-606. PMID: 37495493
MH  - Humans
MH  - *Artificial Intelligence
MH  - Consensus
MH  - *Medicine
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Generative pre-trained transformer
OT  - Large language model
COIS- Conflicts of interest The authors do not have any conflict of interest to 
      disclose.
EDAT- 2023/06/17 05:11
MHDA- 2023/10/02 06:42
CRDT- 2023/06/16 21:54
PHST- 2023/03/01 00:00 [received]
PHST- 2023/05/14 00:00 [revised]
PHST- 2023/05/27 00:00 [accepted]
PHST- 2023/10/02 06:42 [medline]
PHST- 2023/06/17 05:11 [pubmed]
PHST- 2023/06/16 21:54 [entrez]
AID - S1477-5131(23)00224-3 [pii]
AID - 10.1016/j.jpurol.2023.05.018 [doi]
PST - ppublish
SO  - J Pediatr Urol. 2023 Oct;19(5):598-604. doi: 10.1016/j.jpurol.2023.05.018. Epub 
      2023 Jun 2.

PMID- 37211242
OWN - NLM
STAT- MEDLINE
DCOM- 20230728
LR  - 20230728
IS  - 1873-0183 (Electronic)
IS  - 1568-9972 (Linking)
VI  - 22
IP  - 8
DP  - 2023 Aug
TI  - ChatGPT and autoimmunity - A new weapon in the battlefield of knowledge.
PG  - 103360
LID - S1568-9972(23)00094-0 [pii]
LID - 10.1016/j.autrev.2023.103360 [doi]
AB  - The field of medical research has been always full of innovation and huge leaps 
      revolutionizing the scientific world. In the recent years, we have witnessed this 
      firsthand by the evolution of Artificial Intelligence (AI), with ChatGPT being 
      the most recent example. ChatGPT is a language chat bot which generates 
      human-like texts based on data from the internet. If viewed from a medical point 
      view, ChatGPT has shown capabilities of composing medical texts similar to those 
      depicted by experienced authors, to solve clinical cases, to provide medical 
      solutions, among other fascinating performances. Nevertheless, the value of the 
      results, limitations, and clinical implications still need to be carefully 
      evaluated. In our current paper on the role of ChatGPT in clinical medicine, 
      particularly in the field of autoimmunity, we aimed to illustrate the implication 
      of this technology alongside the latest utilization and limitations. In addition, 
      we included an expert opinion on the cyber-related aspects of the bot potentially 
      contributing to the risks attributed to its use, alongside proposed defense 
      mechanisms. All of that, while taking into consideration the rapidity of the 
      continuous improvement AI experiences on a daily basis.
CI  - Copyright © 2023. Published by Elsevier B.V.
FAU - Darkhabani, Mohammad
AU  - Darkhabani M
AD  - International School of Medicine, Istanbul Medipol University, Istanbul, Turkey.
FAU - Alrifaai, Mohamad Aosama
AU  - Alrifaai MA
AD  - International School of Medicine, Istanbul Medipol University, Istanbul, Turkey.
FAU - Elsalti, Abdulrahman
AU  - Elsalti A
AD  - International School of Medicine, Istanbul Medipol University, Istanbul, Turkey.
FAU - Dvir, Yoad M
AU  - Dvir YM
FAU - Mahroum, Naim
AU  - Mahroum N
AD  - International School of Medicine, Istanbul Medipol University, Istanbul, Turkey. 
      Electronic address: naim.mahroum@gmail.com.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230519
PL  - Netherlands
TA  - Autoimmun Rev
JT  - Autoimmunity reviews
JID - 101128967
SB  - IM
MH  - Humans
MH  - *Autoimmunity
MH  - Artificial Intelligence
MH  - *Biomedical Research
MH  - Internet
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Autoimmunity
OT  - Chat bots
OT  - ChatGPT
COIS- Declaration of Competing Interest The authors decalre no conflict of interests.
EDAT- 2023/05/22 00:41
MHDA- 2023/07/28 06:43
CRDT- 2023/05/21 19:25
PHST- 2023/05/03 00:00 [received]
PHST- 2023/05/18 00:00 [accepted]
PHST- 2023/07/28 06:43 [medline]
PHST- 2023/05/22 00:41 [pubmed]
PHST- 2023/05/21 19:25 [entrez]
AID - S1568-9972(23)00094-0 [pii]
AID - 10.1016/j.autrev.2023.103360 [doi]
PST - ppublish
SO  - Autoimmun Rev. 2023 Aug;22(8):103360. doi: 10.1016/j.autrev.2023.103360. Epub 
      2023 May 19.

PMID- 38038796
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231205
IS  - 2197-1153 (Print)
IS  - 2197-1153 (Electronic)
IS  - 2197-1153 (Linking)
VI  - 10
IP  - 1
DP  - 2023 Dec 1
TI  - ChatGPT and large language models in orthopedics: from education and surgery to 
      research.
PG  - 128
LID - 10.1186/s40634-023-00700-1 [doi]
LID - 128
AB  - ChatGPT has quickly popularized since its release in November 2022. Currently, 
      large language models (LLMs) and ChatGPT have been applied in various domains of 
      medical science, including in cardiology, nephrology, orthopedics, ophthalmology, 
      gastroenterology, and radiology. Researchers are exploring the potential of LLMs 
      and ChatGPT for clinicians and surgeons in every domain. This study discusses how 
      ChatGPT can help orthopedic clinicians and surgeons perform various medical 
      tasks. LLMs and ChatGPT can help the patient community by providing suggestions 
      and diagnostic guidelines. In this study, the use of LLMs and ChatGPT to enhance 
      and expand the field of orthopedics, including orthopedic education, surgery, and 
      research, is explored. Present LLMs have several shortcomings, which are 
      discussed herein. However, next-generation and future domain-specific LLMs are 
      expected to be more potent and transform patients' quality of life.
CI  - © 2023. The Author(s).
FAU - Chatterjee, Srijan
AU  - Chatterjee S
AUID- ORCID: 0000-0002-8282-8324
AD  - Institute for Skeletal Aging &amp; Orthopaedic Surgery, Hallym University-Chuncheon 
      Sacred Heart Hospital, Chuncheon-Si, 24252, Gangwon-Do, Republic of Korea.
FAU - Bhattacharya, Manojit
AU  - Bhattacharya M
AUID- ORCID: 0000-0001-9669-1835
AD  - Department of Zoology, Fakir Mohan University, Vyasa Vihar, Balasore, 756020, 
      Odisha, India.
FAU - Pal, Soumen
AU  - Pal S
AUID- ORCID: 0000-0001-9508-2712
AD  - School of Mechanical Engineering, Vellore Institute of Technology, Vellore, Tamil 
      Nadu, India.
FAU - Lee, Sang-Soo
AU  - Lee SS
AUID- ORCID: 0000-0001-5074-7581
AD  - Institute for Skeletal Aging &amp; Orthopaedic Surgery, Hallym University-Chuncheon 
      Sacred Heart Hospital, Chuncheon-Si, 24252, Gangwon-Do, Republic of Korea. 
      123sslee@gmail.com.
FAU - Chakraborty, Chiranjib
AU  - Chakraborty C
AUID- ORCID: 0000-0002-3958-239X
AD  - Department of Biotechnology, School of Life Science and Biotechnology, Adamas 
      University, Kolkata, West Bengal, 700126, India. drchiranjib@yahoo.com.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20231201
PL  - United States
TA  - J Exp Orthop
JT  - Journal of experimental orthopaedics
JID - 101653750
PMC - PMC10692045
OTO - NOTNLM
OT  - ChatGPT
OT  - Concern
OT  - Large language models
OT  - Orthopedics
COIS- The authors declare that they have no competing interests.
EDAT- 2023/12/01 12:44
MHDA- 2023/12/01 12:45
PMCR- 2023/12/01
CRDT- 2023/12/01 11:07
PHST- 2023/08/23 00:00 [received]
PHST- 2023/11/16 00:00 [accepted]
PHST- 2023/12/01 12:45 [medline]
PHST- 2023/12/01 12:44 [pubmed]
PHST- 2023/12/01 11:07 [entrez]
PHST- 2023/12/01 00:00 [pmc-release]
AID - 10.1186/s40634-023-00700-1 [pii]
AID - 700 [pii]
AID - 10.1186/s40634-023-00700-1 [doi]
PST - epublish
SO  - J Exp Orthop. 2023 Dec 1;10(1):128. doi: 10.1186/s40634-023-00700-1.

PMID- 37991290
OWN - NLM
STAT- MEDLINE
DCOM- 20231123
LR  - 20240117
IS  - 1998-3689 (Electronic)
IS  - 0301-4738 (Print)
IS  - 0301-4738 (Linking)
VI  - 71
IP  - 12
DP  - 2023 Dec 1
TI  - ChatGPT in academic writing: Maximizing its benefits and minimizing the risks.
PG  - 3600-3606
LID - 10.4103/IJO.IJO_718_23 [doi]
AB  - This review article explores the use of ChatGPT in academic writing and provides 
      insights on how to utilize it judiciously. With the increasing popularity of 
      AI-powered language models, ChatGPT has emerged as a potential tool for assisting 
      writers in the research and writing process. We have provided a list of potential 
      uses of ChatGPT by a novice researcher for getting help during research proposal 
      preparation and manuscript writing. However, there are concerns regarding its 
      reliability and potential risks associated with its use. The review highlights 
      the importance of maintaining human judgment in the writing process and using 
      ChatGPT as a complementary tool rather than a replacement for human effort. The 
      article concludes with recommendations for researchers and writers to ensure 
      responsible and effective use of ChatGPT in academic writing.
CI  - Copyright © 2023 Copyright: © 2023 Indian Journal of Ophthalmology.
FAU - Mondal, Himel
AU  - Mondal H
AD  - Department of Physiology, All India Institute of Medical Sciences, Deoghar, 
      Jharkhand, India.
FAU - Mondal, Shaikat
AU  - Mondal S
AD  - Department of Physiology, Raiganj Government Medical College and Hospital, West 
      Bengal, India.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20231120
PL  - India
TA  - Indian J Ophthalmol
JT  - Indian journal of ophthalmology
JID - 0405376
SB  - IM
MH  - Humans
MH  - Reproducibility of Results
MH  - *Language
PMC - PMC10788737
COIS- There are no conflicts of interest.
EDAT- 2023/11/22 12:43
MHDA- 2023/11/23 06:42
PMCR- 2023/12/01
CRDT- 2023/11/22 08:33
PHST- 2023/03/14 00:00 [received]
PHST- 2023/08/21 00:00 [accepted]
PHST- 2023/11/23 06:42 [medline]
PHST- 2023/11/22 12:43 [pubmed]
PHST- 2023/11/22 08:33 [entrez]
PHST- 2023/12/01 00:00 [pmc-release]
AID - 02223307-202371120-00006 [pii]
AID - IJO-71-3600 [pii]
AID - 10.4103/IJO.IJO_718_23 [doi]
PST - ppublish
SO  - Indian J Ophthalmol. 2023 Dec 1;71(12):3600-3606. doi: 10.4103/IJO.IJO_718_23. 
      Epub 2023 Nov 20.

PMID- 37926396
OWN - NLM
STAT- MEDLINE
DCOM- 20231216
LR  - 20231216
IS  - 1872-9649 (Electronic)
IS  - 1568-1637 (Linking)
VI  - 92
DP  - 2023 Dec
TI  - ChatGPT's dance with neuropsychological data: A case study in Alzheimer's 
      disease.
PG  - 102117
LID - S1568-1637(23)00276-3 [pii]
LID - 10.1016/j.arr.2023.102117 [doi]
AB  - Artificial intelligence continues to revolutionize the medical and scientific 
      field, especially with the release of ChatGPT. We assessed whether it provides an 
      accurate interpretation of neuropsychological screening. We provided ChatGPT with 
      the neuropsychological data of a patient with mild Alzheimer's Disease and 
      invited it and two neuropsychologists to interpret the data. While ChatGPT 
      provided an accurate interpretation of scores on each of the neuropsychological 
      tests, it did not use standardized scores and did not specify the cognitive 
      domain that may be most impaired. In contrast, the neuropsychologists used 
      standardized scores to determine that the patient was mainly suffering from 
      memory decline. While ChatGPT may succeed in the general interpretation of 
      neuropsychological testing, at least in patients with Alzheimer's Disease, it 
      still cannot create a pattern of scores across different tests to better specify 
      the nature of cognitive impairment.
CI  - Copyright © 2023 Elsevier B.V. All rights reserved.
FAU - El Haj, Mohamad
AU  - El Haj M
AD  - Institut Universitaire de France, Paris, France; CHU Nantes, Clinical Gerontology 
      Department, Bd Jacques Monod, F44093 Nantes, France. Electronic address: 
      mohamad.elhaj@univ-nantes.fr.
FAU - Boutoleau-Bretonnière, Claire
AU  - Boutoleau-Bretonnière C
AD  - CHU Nantes, Inserm CIC04, Nantes, France.
FAU - Chapelet, Guillaume
AU  - Chapelet G
AD  - CHU Nantes, Clinical Gerontology Department, Bd Jacques Monod, F44093 Nantes, 
      France; Université de Nantes, Inserm, TENS, The Enteric Nervous System in Gut and 
      Brain Diseases, IMAD, Nantes, France.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20231104
PL  - England
TA  - Ageing Res Rev
JT  - Ageing research reviews
JID - 101128963
SB  - IM
MH  - Humans
MH  - *Alzheimer Disease/diagnosis
MH  - Artificial Intelligence
MH  - *Cognitive Dysfunction/diagnosis/etiology
MH  - Neuropsychological Tests
OTO - NOTNLM
OT  - Alzheimer’s disease
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Neuropsychological testing
OT  - Neuropsychology
COIS- Declaration of Competing Interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2023/11/06 00:41
MHDA- 2023/12/17 13:19
CRDT- 2023/11/05 19:17
PHST- 2023/10/09 00:00 [received]
PHST- 2023/10/31 00:00 [revised]
PHST- 2023/11/01 00:00 [accepted]
PHST- 2023/12/17 13:19 [medline]
PHST- 2023/11/06 00:41 [pubmed]
PHST- 2023/11/05 19:17 [entrez]
AID - S1568-1637(23)00276-3 [pii]
AID - 10.1016/j.arr.2023.102117 [doi]
PST - ppublish
SO  - Ageing Res Rev. 2023 Dec;92:102117. doi: 10.1016/j.arr.2023.102117. Epub 2023 Nov 
      4.

PMID- 37819738
OWN - NLM
STAT- MEDLINE
DCOM- 20231225
LR  - 20231225
IS  - 1469-0756 (Electronic)
IS  - 0032-5473 (Linking)
VI  - 100
IP  - 1179
DP  - 2023 Dec 21
TI  - ChatGPT in research and health professions education: challenges, opportunities, 
      and future directions.
PG  - 50-55
LID - 10.1093/postmj/qgad090 [doi]
AB  - ChatGPT was launched by OpenAI in November 2022 and within 2 months it became 
      popular across a wide range of industrial, social, and intellectual contexts 
      including healthcare education. This article reviews the impact of ChatGPT on 
      research and health professions education by identifying the challenges and 
      opportunities in these fields. Additionally, it aims to provide future directions 
      to mitigate the challenges and maximize the benefits of this technology in health 
      professions education. ChatGPT has the potential to revolutionize the field of 
      research and health professions education. However, there is a need to address 
      ethical concerns and limitations such as lack of real-time data, data 
      inaccuracies, biases, plagiarism, and copyright infringement before its 
      implementation. Future research can highlight the ways to mitigate these 
      challenges; establish guidelines and policies; and explore how effectively 
      ChatGPT and other AI tools can be used in the field of research and healthcare 
      professions education.
CI  - © The Author(s) 2023. Published by Oxford University Press on behalf of 
      Fellowship of Postgraduate Medicine. All rights reserved. For permissions, please 
      e-mail: journals.permissions@oup.com.
FAU - Sahu, Pradeep Kumar
AU  - Sahu PK
AD  - Centre For Medical Sciences Education, Faculty of Medical Sciences, The 
      University of the West Indies, St Augustine, Trinidad and Tobago.
FAU - Benjamin, Lisa A
AU  - Benjamin LA
AD  - Department of Basic Veterinary Sciences, School of Veterinary Medicine, Faculty 
      of Medical Sciences, The University of the West Indies, St Augustine, Trinidad 
      and Tobago.
FAU - Singh Aswal, Gunjan
AU  - Singh Aswal G
AD  - Department of Restorative Dentistry, School of Dentistry, Faculty of Medical 
      Sciences, The University of the West Indies, St Augustine Trinidad and Tobago.
FAU - Williams-Persad, Arlene
AU  - Williams-Persad A
AD  - Department of Paraclinical Sciences, Faculty of Medical Sciences, The University 
      of the West Indies St. Augustine, Trinidad and Tobago West Indies.
LA  - eng
PT  - Journal Article
PT  - Review
PL  - England
TA  - Postgrad Med J
JT  - Postgraduate medical journal
JID - 0234135
SB  - IM
MH  - Humans
MH  - Educational Status
MH  - *Technology
MH  - *Health Occupations
OTO - NOTNLM
OT  - ChatGPT
OT  - academic research
OT  - artificial intelligence
OT  - health professions education
OT  - teaching and learning
EDAT- 2023/10/11 14:44
MHDA- 2023/12/25 06:42
CRDT- 2023/10/11 12:32
PHST- 2023/09/01 00:00 [received]
PHST- 2023/09/15 00:00 [accepted]
PHST- 2023/12/25 06:42 [medline]
PHST- 2023/10/11 14:44 [pubmed]
PHST- 2023/10/11 12:32 [entrez]
AID - 7304050 [pii]
AID - 10.1093/postmj/qgad090 [doi]
PST - ppublish
SO  - Postgrad Med J. 2023 Dec 21;100(1179):50-55. doi: 10.1093/postmj/qgad090.

PMID- 38060759
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231207
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 11
DP  - 2023 Nov
TI  - Be or Not to Be With ChatGPT?
PG  - e48366
LID - 10.7759/cureus.48366 [doi]
LID - e48366
AB  - In the ever-evolving realm of scientific research, this letter underscores the 
      vital role of ChatGPT as an invaluable ally in manuscript creation, focusing on 
      its remarkable grammar and spelling error correction capabilities. Furthermore, 
      it highlights ChatGPT's efficacy in expediting the manuscript preparation process 
      by streamlining the collection and highlighting critical scientific information. 
      By elucidating the aim of this letter and the multifaceted benefits of ChatGPT, 
      we aspire to illuminate the path toward a future where scientific writing 
      achieves unparalleled efficiency and precision.
CI  - Copyright © 2023, Aliyeva et al.
FAU - Aliyeva, Aynur
AU  - Aliyeva A
AD  - Department of Otolaryngology - Head and Neck Surgery, Cincinnati Children's 
      Hospital Medical Center, Cincinnati, USA.
FAU - Sari, Elif
AU  - Sari E
AD  - Department of Otorhinolaryngology - Head and Neck Surgery, Istanbul Aydın 
      University VM Medical Park Florya Hospital, Istanbul, TUR.
LA  - eng
PT  - Editorial
DEP - 20231106
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10699328
OTO - NOTNLM
OT  - artificial intelligence
OT  - chatgpt
OT  - future in medicine
OT  - research
OT  - scientific manuscript
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/12/07 18:42
MHDA- 2023/12/07 18:43
PMCR- 2023/11/06
CRDT- 2023/12/07 14:46
PHST- 2023/11/06 00:00 [accepted]
PHST- 2023/12/07 18:43 [medline]
PHST- 2023/12/07 18:42 [pubmed]
PHST- 2023/12/07 14:46 [entrez]
PHST- 2023/11/06 00:00 [pmc-release]
AID - 10.7759/cureus.48366 [doi]
PST - epublish
SO  - Cureus. 2023 Nov 6;15(11):e48366. doi: 10.7759/cureus.48366. eCollection 2023 
      Nov.

PMID- 37812965
OWN - NLM
STAT- MEDLINE
DCOM- 20231023
LR  - 20231023
IS  - 1873-4499 (Electronic)
IS  - 0899-7071 (Linking)
VI  - 103
DP  - 2023 Nov
TI  - Improving radiology workflow using ChatGPT and artificial intelligence.
PG  - 109993
LID - S0899-7071(23)00213-9 [pii]
LID - 10.1016/j.clinimag.2023.109993 [doi]
AB  - Artificial Intelligence is a branch of computer science that aims to create 
      intelligent machines capable of performing tasks that typically require human 
      intelligence. One of the branches of artificial intelligence is natural language 
      processing, which is dedicated to studying the interaction between computers and 
      human language. ChatGPT is a sophisticated natural language processing tool that 
      can understand and respond to complex questions and commands in natural language. 
      Radiology is a vital aspect of modern medicine that involves the use of imaging 
      technologies to diagnose and treat medical conditions artificial intelligence, 
      including ChatGPT, can be integrated into radiology workflows to improve 
      efficiency, accuracy, and patient care. ChatGPT can streamline various radiology 
      workflow steps, including patient registration, scheduling, patient check-in, 
      image acquisition, interpretation, and reporting. While ChatGPT has the potential 
      to transform radiology workflows, there are limitations to the technology that 
      must be addressed, such as the potential for bias in artificial intelligence 
      algorithms and ethical concerns. As technology continues to advance, ChatGPT is 
      likely to become an increasingly important tool in the field of radiology, and in 
      healthcare more broadly.
CI  - Copyright © 2023 Elsevier Inc. All rights reserved.
FAU - Mese, Ismail
AU  - Mese I
AD  - Department of Radiology, Health Sciences University, Erenkoy Mental Health and 
      Neurology Training and Research Hospital, 19 Mayıs, Sinan Ercan Cd. No: 23, 
      Kadıköy/Istanbul 34736, Turkey. Electronic address: ismail_mese@yahoo.com.
FAU - Taslicay, Ceylan Altintas
AU  - Taslicay CA
AD  - Department of Radiology, MD Anderson Cancer Center, 1515 Holcombe Blvd, Houston, 
      TX 77030, USA.
FAU - Sivrioglu, Ali Kemal
AU  - Sivrioglu AK
AD  - Department of Radiology, Liv Hospital Vadistanbul, Ayazağa Mahallesi, Kemerburgaz 
      Caddesi, Vadistanbul Park Etabı, 7F Blok, 34396 Sarıyer/İstanbul, Turkey.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20231006
PL  - United States
TA  - Clin Imaging
JT  - Clinical imaging
JID - 8911831
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Workflow
MH  - Radiography
MH  - *Radiology
MH  - Algorithms
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Diagnostic techniques
OT  - Natural language processing
OT  - Radiology
COIS- Declaration of competing interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2023/10/10 00:42
MHDA- 2023/10/23 01:18
CRDT- 2023/10/09 18:36
PHST- 2023/06/16 00:00 [received]
PHST- 2023/08/19 00:00 [revised]
PHST- 2023/09/28 00:00 [accepted]
PHST- 2023/10/23 01:18 [medline]
PHST- 2023/10/10 00:42 [pubmed]
PHST- 2023/10/09 18:36 [entrez]
AID - S0899-7071(23)00213-9 [pii]
AID - 10.1016/j.clinimag.2023.109993 [doi]
PST - ppublish
SO  - Clin Imaging. 2023 Nov;103:109993. doi: 10.1016/j.clinimag.2023.109993. Epub 2023 
      Oct 6.

PMID- 38262126
OWN - NLM
STAT- MEDLINE
DCOM- 20240214
LR  - 20240214
IS  - 1872-7565 (Electronic)
IS  - 0169-2607 (Linking)
VI  - 245
DP  - 2024 Mar
TI  - ChatGPT in healthcare: A taxonomy and systematic review.
PG  - 108013
LID - S0169-2607(24)00008-7 [pii]
LID - 10.1016/j.cmpb.2024.108013 [doi]
AB  - The recent release of ChatGPT, a chat bot research project/product of natural 
      language processing (NLP) by OpenAI, stirs up a sensation among both the general 
      public and medical professionals, amassing a phenomenally large user base in a 
      short time. This is a typical example of the 'productization' of cutting-edge 
      technologies, which allows the general public without a technical background to 
      gain firsthand experience in artificial intelligence (AI), similar to the AI hype 
      created by AlphaGo (DeepMind Technologies, UK) and self-driving cars (Google, 
      Tesla, etc.). However, it is crucial, especially for healthcare researchers, to 
      remain prudent amidst the hype. This work provides a systematic review of 
      existing publications on the use of ChatGPT in healthcare, elucidating the 
      'status quo' of ChatGPT in medical applications, for general readers, healthcare 
      professionals as well as NLP scientists. The large biomedical literature database 
      PubMed is used to retrieve published works on this topic using the keyword 
      'ChatGPT'. An inclusion criterion and a taxonomy are further proposed to filter 
      the search results and categorize the selected publications, respectively. It is 
      found through the review that the current release of ChatGPT has achieved only 
      moderate or 'passing' performance in a variety of tests, and is unreliable for 
      actual clinical deployment, since it is not intended for clinical applications by 
      design. We conclude that specialized NLP models trained on (bio)medical datasets 
      still represent the right direction to pursue for critical clinical applications.
CI  - Copyright © 2024 The Author(s). Published by Elsevier B.V. All rights reserved.
FAU - Li, Jianning
AU  - Li J
AD  - Institute for Artificial Intelligence in Medicine, University Hospital Essen 
      (AöR), Girardetstraße 2, 45131 Essen, Germany.
FAU - Dada, Amin
AU  - Dada A
AD  - Institute for Artificial Intelligence in Medicine, University Hospital Essen 
      (AöR), Girardetstraße 2, 45131 Essen, Germany.
FAU - Puladi, Behrus
AU  - Puladi B
AD  - Institute of Medical Informatics, University Hospital RWTH Aachen, Pauwelsstraße 
      30, 52074 Aachen, Germany; Department of Oral and Maxillofacial Surgery, 
      University Hospital RWTH Aachen, Pauwelsstraße 30, 52074 Aachen, Germany.
FAU - Kleesiek, Jens
AU  - Kleesiek J
AD  - Institute for Artificial Intelligence in Medicine, University Hospital Essen 
      (AöR), Girardetstraße 2, 45131 Essen, Germany; TU Dortmund University, Department 
      of Physics, Otto-Hahn-Straße 4, 44227 Dortmund, Germany.
FAU - Egger, Jan
AU  - Egger J
AD  - Institute for Artificial Intelligence in Medicine, University Hospital Essen 
      (AöR), Girardetstraße 2, 45131 Essen, Germany; Center for Virtual and Extended 
      Reality in Medicine (ZvRM), University Hospital Essen, University Medicine Essen, 
      Hufelandstraße 55, 45147 Essen, Germany. Electronic address: 
      jan.egger@uk-essen.de.
LA  - eng
PT  - Journal Article
PT  - Review
PT  - Systematic Review
DEP - 20240115
PL  - Ireland
TA  - Comput Methods Programs Biomed
JT  - Computer methods and programs in biomedicine
JID - 8506513
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Databases, Factual
MH  - Natural Language Processing
MH  - *Physicians
MH  - PubMed
OTO - NOTNLM
OT  - BERT
OT  - Bard
OT  - ChatGPT
OT  - Healthcare
OT  - LLM
OT  - LLaMA
OT  - NLP
OT  - OpenAI
OT  - Taxonomy
OT  - Transformer
COIS- Declaration of Competing Interest The authors declare no conflict of interests.
EDAT- 2024/01/24 00:42
MHDA- 2024/02/14 12:44
CRDT- 2024/01/23 18:02
PHST- 2023/06/07 00:00 [received]
PHST- 2023/12/29 00:00 [revised]
PHST- 2024/01/08 00:00 [accepted]
PHST- 2024/02/14 12:44 [medline]
PHST- 2024/01/24 00:42 [pubmed]
PHST- 2024/01/23 18:02 [entrez]
AID - S0169-2607(24)00008-7 [pii]
AID - 10.1016/j.cmpb.2024.108013 [doi]
PST - ppublish
SO  - Comput Methods Programs Biomed. 2024 Mar;245:108013. doi: 
      10.1016/j.cmpb.2024.108013. Epub 2024 Jan 15.

PMID- 37546142
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230808
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 7
DP  - 2023 Jul
TI  - ChatGPT in Radiology: The Advantages and Limitations of Artificial Intelligence 
      for Medical Imaging Diagnosis.
PG  - e41435
LID - 10.7759/cureus.41435 [doi]
LID - e41435
AB  - This review article provides an overview of using artificial intelligence (AI) in 
      radiology. It discusses the advantages and limitations of ChatGPT, a large 
      language model, for medical imaging diagnosis. ChatGPT has shown great promise in 
      improving the accuracy and efficiency of radiological diagnoses by reducing 
      interpretation variability and errors and improving workflow efficiency. However, 
      there are also limitations, including the need for high-quality training data, 
      ethical considerations, and further research and development to improve its 
      performance and usability. Despite these challenges, ChatGPT has the potential to 
      significantly impact radiology and medical imaging diagnosis. The review article 
      highlights the need for continued research and development, coupled with ethical 
      and regulatory considerations, to ensure that ChatGPT is used to its full 
      potential in improving radiological diagnoses and patient care.
CI  - Copyright © 2023, Srivastav et al.
FAU - Srivastav, Samriddhi
AU  - Srivastav S
AD  - Medicine, Jawaharlal Nehru Medical College, Datta Meghe Institute of Higher 
      Education &amp; Research, Wardha, IND.
FAU - Chandrakar, Rashi
AU  - Chandrakar R
AD  - Medicine, Jawaharlal Nehru Medical College, Datta Meghe Institute of Higher 
      Education &amp; Research, Wardha, IND.
FAU - Gupta, Shalvi
AU  - Gupta S
AD  - Surgery, Jawaharlal Nehru Medical College, Datta Meghe Institute of Higher 
      Education &amp; Research, Wardha, IND.
FAU - Babhulkar, Vaishnavi
AU  - Babhulkar V
AD  - Medicine, Jawaharlal Nehru Medical College, Datta Meghe Institute of Higher 
      Education &amp; Research, Wardha, IND.
FAU - Agrawal, Sristy
AU  - Agrawal S
AD  - Medicine, Jawaharlal Nehru Medical College, Datta Meghe Institute of Higher 
      Education &amp; Research, Wardha, IND.
FAU - Jaiswal, Arpita
AU  - Jaiswal A
AD  - Obstetrics and Gynaecology, Jawaharlal Nehru Medical College, Datta Meghe 
      Institute of Higher Education &amp; Research, Wardha, IND.
FAU - Prasad, Roshan
AU  - Prasad R
AD  - Medicine and Surgery, Jawaharlal Nehru Medical College, Datta Meghe Institute of 
      Higher Education &amp; Research, Wardha, IND.
FAU - Wanjari, Mayur B
AU  - Wanjari MB
AD  - Research and Development, Jawaharlal Nehru Medical College, Datta Meghe Institute 
      of Higher Education &amp; Research, Wardha, IND.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230706
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10404120
OTO - NOTNLM
OT  - advantages
OT  - artificial intelligence
OT  - chatgpt
OT  - limitations
OT  - medical imaging diagnosis
OT  - radiology
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/08/07 06:41
MHDA- 2023/08/07 06:42
PMCR- 2023/07/06
CRDT- 2023/08/07 04:32
PHST- 2023/05/02 00:00 [received]
PHST- 2023/07/06 00:00 [accepted]
PHST- 2023/08/07 06:42 [medline]
PHST- 2023/08/07 06:41 [pubmed]
PHST- 2023/08/07 04:32 [entrez]
PHST- 2023/07/06 00:00 [pmc-release]
AID - 10.7759/cureus.41435 [doi]
PST - epublish
SO  - Cureus. 2023 Jul 6;15(7):e41435. doi: 10.7759/cureus.41435. eCollection 2023 Jul.

PMID- 38026475
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231201
IS  - 2296-875X (Print)
IS  - 2296-875X (Electronic)
IS  - 2296-875X (Linking)
VI  - 10
DP  - 2023
TI  - ChatGPT in orthopedics: a narrative review exploring the potential of artificial 
      intelligence in orthopedic practice.
PG  - 1284015
LID - 10.3389/fsurg.2023.1284015 [doi]
LID - 1284015
AB  - The field of orthopedics faces complex challenges requiring quick and intricate 
      decisions, with patient education and compliance playing crucial roles in 
      treatment outcomes. Technological advancements in artificial intelligence (AI) 
      can potentially enhance orthopedic care. ChatGPT, a natural language processing 
      technology developed by OpenAI, has shown promise in various sectors, including 
      healthcare. ChatGPT can facilitate patient information exchange in orthopedics, 
      provide clinical decision support, and improve patient communication and 
      education. It can assist in differential diagnosis, suggest appropriate imaging 
      modalities, and optimize treatment plans based on evidence-based guidelines. 
      However, ChatGPT has limitations, such as insufficient expertise in specialized 
      domains and a lack of contextual understanding. The application of ChatGPT in 
      orthopedics is still evolving, with studies exploring its potential in clinical 
      decision-making, patient education, workflow optimization, and scientific 
      literature. The results indicate both the benefits and limitations of ChatGPT, 
      emphasizing the need for caution, ethical considerations, and human oversight. 
      Addressing training data quality, biases, data privacy, and accountability 
      challenges is crucial for responsible implementation. While ChatGPT has the 
      potential to transform orthopedic healthcare, further research and development 
      are necessary to ensure its reliability, accuracy, and ethical use in patient 
      care.
CI  - © 2023 Giorgino, Alessandri-Bonetti, Luca, Migliorini, Rossi, Peretti and 
      Mangiavini.
FAU - Giorgino, Riccardo
AU  - Giorgino R
AD  - IRCCS Istituto Ortopedico Galeazzi, Milan, Italy.
AD  - Residency Program in Orthopedics and Traumatology, University of Milan, Milan, 
      Italy.
FAU - Alessandri-Bonetti, Mario
AU  - Alessandri-Bonetti M
AD  - Department of Plastic Surgery, University of Pittsburgh Medical Center, 
      Pittsburgh, PA, United States.
FAU - Luca, Andrea
AU  - Luca A
AD  - IRCCS Istituto Ortopedico Galeazzi, Milan, Italy.
FAU - Migliorini, Filippo
AU  - Migliorini F
AD  - Department of Orthopaedic, Trauma, and Reconstructive Surgery, RWTH University 
      Medical Centre, Aachen, Germany.
AD  - Department of Orthopedics and Trauma Surgery, Academic Hospital of Bolzano 
      (SABES-ASDAA), Teaching Hospital of the Paracelsus Medical University, Bolzano, 
      Italy.
FAU - Rossi, Nicolò
AU  - Rossi N
AD  - IRCCS Istituto Ortopedico Galeazzi, Milan, Italy.
AD  - Residency Program in Orthopedics and Traumatology, University of Milan, Milan, 
      Italy.
FAU - Peretti, Giuseppe M
AU  - Peretti GM
AD  - IRCCS Istituto Ortopedico Galeazzi, Milan, Italy.
AD  - Dipartimento di Scienze Biomediche per la Salute, Università degli Studi di 
      Milano, Milan, Italy.
FAU - Mangiavini, Laura
AU  - Mangiavini L
AD  - IRCCS Istituto Ortopedico Galeazzi, Milan, Italy.
AD  - Dipartimento di Scienze Biomediche per la Salute, Università degli Studi di 
      Milano, Milan, Italy.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20231101
PL  - Switzerland
TA  - Front Surg
JT  - Frontiers in surgery
JID - 101645127
PMC - PMC10654618
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - artificial intelligence
OT  - clinical decision-making
OT  - orthopedics
OT  - patient education
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/11/29 18:42
MHDA- 2023/11/29 18:43
PMCR- 2023/11/01
CRDT- 2023/11/29 16:54
PHST- 2023/08/27 00:00 [received]
PHST- 2023/10/16 00:00 [accepted]
PHST- 2023/11/29 18:43 [medline]
PHST- 2023/11/29 18:42 [pubmed]
PHST- 2023/11/29 16:54 [entrez]
PHST- 2023/11/01 00:00 [pmc-release]
AID - 10.3389/fsurg.2023.1284015 [doi]
PST - epublish
SO  - Front Surg. 2023 Nov 1;10:1284015. doi: 10.3389/fsurg.2023.1284015. eCollection 
      2023.

PMID- 37265899
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230604
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 5
DP  - 2023 May
TI  - A Critical Review of ChatGPT as a Potential Substitute for Diabetes Educators.
PG  - e38380
LID - 10.7759/cureus.38380 [doi]
LID - e38380
AB  - This review article explores the potential of ChatGPT as a substitute for 
      diabetes educators. Diabetes is a prevalent chronic disease that requires ongoing 
      education and support for patients to effectively manage their condition. 
      However, there is a shortage of diabetes educators, and traditional education 
      methods have limitations in addressing patients' individual needs. ChatGPT is an 
      artificial intelligence technology that offers a personalized and interactive 
      approach to education and support. In this review, we provide an overview of 
      ChatGPT technology, discuss the challenges facing diabetes educators, review 
      evidence supporting the use of ChatGPT in diabetes education, and examine ethical 
      considerations related to its use. We also provide recommendations for further 
      research and development of ChatGPT in diabetes education and integration into 
      clinical practice. ChatGPT has the potential to improve access to education and 
      support for patients with diabetes, but further research is needed to better 
      understand its effectiveness and limitations. It is important to ensure that 
      ChatGPT is developed and integrated in an ethical and equitable manner to 
      maximize its potential benefits and minimize potential risks.
CI  - Copyright © 2023, Sharma et al.
FAU - Sharma, Samriddhi
AU  - Sharma S
AD  - Medicine and Surgery, Jawaharlal Nehru Medical College, Datta Meghe Institute of 
      Higher Education and Research, Wardha, IND.
FAU - Pajai, Sandhya
AU  - Pajai S
AD  - Obstetrics and Gynaecology, Jawaharlal Nehru Medical College, Datta Meghe 
      Institute of Higher Education and Research, Wardha, IND.
FAU - Prasad, Roshan
AU  - Prasad R
AD  - Medicine and Surgery, Jawaharlal Nehru Medical College, Datta Meghe Institute of 
      Higher Education and Research, Wardha, IND.
FAU - Wanjari, Mayur B
AU  - Wanjari MB
AD  - Research and Development, Jawaharlal Nehru Medical College, Datta Meghe Institute 
      of Higher Education and Research, Wardha, IND.
FAU - Munjewar, Pratiksha K
AU  - Munjewar PK
AD  - Medical Surgical Nursing, Srimati Radhikabai Meghe Memorial College of Nursing, 
      Datta Meghe Institute of Higher Education and Research, Wardha, IND.
FAU - Sharma, Ranjana
AU  - Sharma R
AD  - Medical Surgical Nursing, Srimati Radhikabai Meghe Memorial College of Nursing, 
      Datta Meghe Institute of Higher Education and Research, Wardha, IND.
FAU - Pathade, Aniket
AU  - Pathade A
AD  - Research and Development, Jawaharlal Nehru Medical College, Datta Meghe Institute 
      of Higher Education and Research, Wardha, IND.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230501
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10231273
OTO - NOTNLM
OT  - artificial intelligence
OT  - chatgpt
OT  - diabetes education
OT  - emotional support
OT  - ethical considerations
OT  - health technology
OT  - healthcare communication
OT  - medical advice
OT  - patient education
OT  - patient engagement
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/06/02 13:16
MHDA- 2023/06/02 13:17
PMCR- 2023/05/01
CRDT- 2023/06/02 10:51
PHST- 2023/04/14 00:00 [received]
PHST- 2023/05/01 00:00 [accepted]
PHST- 2023/06/02 13:17 [medline]
PHST- 2023/06/02 13:16 [pubmed]
PHST- 2023/06/02 10:51 [entrez]
PHST- 2023/05/01 00:00 [pmc-release]
AID - 10.7759/cureus.38380 [doi]
PST - epublish
SO  - Cureus. 2023 May 1;15(5):e38380. doi: 10.7759/cureus.38380. eCollection 2023 May.

PMID- 37789636
OWN - NLM
STAT- MEDLINE
DCOM- 20231101
LR  - 20240109
IS  - 1466-187X (Electronic)
IS  - 0142-159X (Linking)
VI  - 45
IP  - 11
DP  - 2023 Nov
TI  - ChatGPT for assessment writing.
PG  - 1224-1227
LID - 10.1080/0142159X.2023.2249239 [doi]
AB  - What is the educational challenge?Medical schools invest significant resources 
      into the creation of multiple-choice items for assessments. This process is 
      costly and requires faculty training. Recently ChatGPT has been used in various 
      areas to improve content creation efficiency, and it has otherwise been used to 
      answer USMLE-style assessment items.What are the proposed solutions?We proposed 
      the use of ChatGPT to create initial drafts of multiple-choice items.What are the 
      potential benefits to a wider global audience?The use of ChatGPT to generate 
      assessment items can decrease resources required, allowing for the creation of 
      more items, and freeing-up faculty time to perform higher level assessment 
      activities. ChatGPT is also able to consistently produce items using a standard 
      format while adhering to item writing guidelines, which can be very challenging 
      for faculty teams.What are the next steps?We plan to pilot ChatGPT drafted 
      questions and compare item statistics for those written by ChatGPT with those 
      written by our content experts. We also plan to further identify the types of 
      questions that ChatGPT is most appropriate for, and incorporate media into 
      assessment items (e.g. images, videos).
FAU - Zuckerman, Matthew
AU  - Zuckerman M
AUID- ORCID: 0000-0001-9576-4203
AD  - University of Colorado Anschutz Medical Campus School of Medicine, Aurora, CO, 
      USA.
FAU - Flood, Ryan
AU  - Flood R
AD  - University of Colorado Anschutz Medical Campus School of Medicine, Aurora, CO, 
      USA.
FAU - Tan, Rachael J B
AU  - Tan RJB
AUID- ORCID: 0009-0001-4841-2042
AD  - University of Colorado Anschutz Medical Campus School of Medicine, Aurora, CO, 
      USA.
FAU - Kelp, Nicole
AU  - Kelp N
AUID- ORCID: 0000-0001-8462-5689
AD  - University of Colorado Anschutz Medical Campus School of Medicine, Aurora, CO, 
      USA.
AD  - Department of Microbiology, Immunology, and Pathology, Colorado State University, 
      Fort Collins, CO, USA.
FAU - Ecker, David J
AU  - Ecker DJ
AUID- ORCID: 0000-0002-1530-0079
AD  - University of Colorado Anschutz Medical Campus School of Medicine, Aurora, CO, 
      USA.
FAU - Menke, Jonathan
AU  - Menke J
AD  - University of Colorado Anschutz Medical Campus School of Medicine, Aurora, CO, 
      USA.
FAU - Lockspeiser, Tai
AU  - Lockspeiser T
AUID- ORCID: 0000-0002-1633-4860
AD  - Department of Pediatrics, Children's Hospital Colorado, Aurora, CO, USA.
LA  - eng
PT  - Journal Article
DEP - 20231016
PL  - England
TA  - Med Teach
JT  - Medical teacher
JID - 7909593
SB  - IM
MH  - Humans
MH  - Educational Status
MH  - *Faculty
MH  - *Schools, Medical
MH  - Videotape Recording
MH  - Writing
OTO - NOTNLM
OT  - AI
OT  - Assessment
OT  - ChatGPT
OT  - artificial intelligence
OT  - medical education
EDAT- 2023/10/04 06:43
MHDA- 2023/11/01 12:44
CRDT- 2023/10/04 02:05
PHST- 2023/11/01 12:44 [medline]
PHST- 2023/10/04 06:43 [pubmed]
PHST- 2023/10/04 02:05 [entrez]
AID - 10.1080/0142159X.2023.2249239 [doi]
PST - ppublish
SO  - Med Teach. 2023 Nov;45(11):1224-1227. doi: 10.1080/0142159X.2023.2249239. Epub 
      2023 Oct 16.

PMID- 37307503
OWN - NLM
STAT- MEDLINE
DCOM- 20230929
LR  - 20230929
IS  - 1087-2981 (Electronic)
IS  - 1087-2981 (Linking)
VI  - 28
IP  - 1
DP  - 2023 Dec
TI  - ChatGPT in medical school: how successful is AI in progress testing?
PG  - 2220920
LID - 10.1080/10872981.2023.2220920 [doi]
LID - 2220920
AB  - BACKGROUND: As generative artificial intelligence (AI), ChatGPT provides easy 
      access to a wide range of information, including factual knowledge in the field 
      of medicine. Given that knowledge acquisition is a basic determinant of 
      physicians' performance, teaching and testing different levels of medical 
      knowledge is a central task of medical schools. To measure the factual knowledge 
      level of the ChatGPT responses, we compared the performance of ChatGPT with that 
      of medical students in a progress test. METHODS: A total of 400 multiple-choice 
      questions (MCQs) from the progress test in German-speaking countries were entered 
      into ChatGPT's user interface to obtain the percentage of correctly answered 
      questions. We calculated the correlations of the correctness of ChatGPT responses 
      with behavior in terms of response time, word count, and difficulty of a progress 
      test question. RESULTS: Of the 395 responses evaluated, 65.5% of the progress 
      test questions answered by ChatGPT were correct. On average, ChatGPT required 
      22.8 s (SD 17.5) for a complete response, containing 36.2 (SD 28.1) words. There 
      was no correlation between the time used and word count with the accuracy of the 
      ChatGPT response (correlation coefficient for time rho = -0.08, 95% CI [-0.18, 
      0.02], t(393) = -1.55, p = 0.121; for word count rho = -0.03, 95% CI [-0.13, 
      0.07], t(393) = -0.54, p = 0.592). There was a significant correlation between 
      the difficulty index of the MCQs and the accuracy of the ChatGPT response 
      (correlation coefficient for difficulty: rho = 0.16, 95% CI [0.06, 0.25], 
      t(393) = 3.19, p = 0.002). CONCLUSION: ChatGPT was able to correctly answer 
      two-thirds of all MCQs at the German state licensing exam level in Progress Test 
      Medicine and outperformed almost all medical students in years 1-3. The ChatGPT 
      answers can be compared with the performance of medical students in the second 
      half of their studies.
FAU - Friederichs, Hendrik
AU  - Friederichs H
AUID- ORCID: 0000-0001-9671-5235
AD  - Medical School OWL, Bielefeld University, Bielefeld, Germany.
FAU - Friederichs, Wolf Jonas
AU  - Friederichs WJ
AUID- ORCID: 0000-0003-1733-7788
AD  - Faculty of Mechanical Engineering, RWTH Aachen University, Aachen, Germany.
FAU - März, Maren
AU  - März M
AUID- ORCID: 0000-0002-2661-5076
AD  - Charité- Universitätsmedizin Berlin, Kooperationspartner der Freien Universität 
      Berlin, Humboldt-Universität Zu Berlin, Progress Test Medizin, Charitéplatz 1, 
      Berlin, Germany.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Med Educ Online
JT  - Medical education online
JID - 9806550
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Schools, Medical
MH  - *Students, Medical
MH  - *Educational Measurement
MH  - *Education, Medical
MH  - Machine Learning
PMC - PMC10262795
OTO - NOTNLM
OT  - Medical education
OT  - artificial intelligence
OT  - learning
OT  - machine learning
OT  - progress test
COIS- No potential conflict of interest was reported by the authors.
EDAT- 2023/06/12 19:12
MHDA- 2023/06/14 06:42
PMCR- 2023/06/12
CRDT- 2023/06/12 15:43
PHST- 2023/06/14 06:42 [medline]
PHST- 2023/06/12 19:12 [pubmed]
PHST- 2023/06/12 15:43 [entrez]
PHST- 2023/06/12 00:00 [pmc-release]
AID - 2220920 [pii]
AID - 10.1080/10872981.2023.2220920 [doi]
PST - ppublish
SO  - Med Educ Online. 2023 Dec;28(1):2220920. doi: 10.1080/10872981.2023.2220920.

PMID- 37691594
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230913
IS  - 2383-7977 (Electronic)
IS  - 1975-5171 (Print)
IS  - 1975-5171 (Linking)
VI  - 18
IP  - 3
DP  - 2023 Jul
TI  - Utilizing ChatGPT in clinical research related to anesthesiology: a comprehensive 
      review of opportunities and limitations.
PG  - 244-251
LID - 10.17085/apm.23056 [doi]
AB  - Chat generative pre-trained transformer (ChatGPT) is a chatbot developed by 
      OpenAI that answers questions in a human-like manner. ChatGPT is a GPT language 
      model that understands and responds to natural language created using a 
      transformer, which is a new artificial neural network algorithm first introduced 
      by Google in 2017. ChatGPT can be used to identify research topics and proofread 
      English writing and R scripts to improve work efficiency and optimize time. 
      Attempts to actively utilize generative artificial intelligence (AI) are expected 
      to continue in clinical settings. However, ChatGPT still has many limitations for 
      widespread use in clinical research, owing to AI hallucination symptoms and its 
      training data constraints. Researchers recommend avoiding scientific writing 
      using ChatGPT in many traditional journals because of the current lack of 
      originality guidelines and plagiarism of content generated by ChatGPT. Further 
      regulations and discussions on these topics are expected in the future.
FAU - Lee, Sang-Wook
AU  - Lee SW
AD  - Department of Anesthesiology and Pain Medicine, Asan Medical Center, University 
      of Ulsan College of Medicine, Seoul, Korea.
FAU - Choi, Woo-Jong
AU  - Choi WJ
AD  - Department of Anesthesiology and Pain Medicine, Asan Medical Center, University 
      of Ulsan College of Medicine, Seoul, Korea.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230726
PL  - Korea (South)
TA  - Anesth Pain Med (Seoul)
JT  - Anesthesia and pain medicine
JID - 101517708
PMC - PMC10410543
OTO - NOTNLM
OT  - Anesthesiology
OT  - Artificial intelligence
OT  - Hallucinations
OT  - Plagiarism
OT  - Transformer
COIS- CONFLICTS OF INTEREST No potential conflict of interest relevant to this article 
      was reported.
EDAT- 2023/09/11 06:42
MHDA- 2023/09/11 06:43
PMCR- 2023/07/31
CRDT- 2023/09/11 04:07
PHST- 2023/05/02 00:00 [received]
PHST- 2023/07/17 00:00 [accepted]
PHST- 2023/09/11 06:43 [medline]
PHST- 2023/09/11 06:42 [pubmed]
PHST- 2023/09/11 04:07 [entrez]
PHST- 2023/07/31 00:00 [pmc-release]
AID - apm.23056 [pii]
AID - apm-23056 [pii]
AID - 10.17085/apm.23056 [doi]
PST - ppublish
SO  - Anesth Pain Med (Seoul). 2023 Jul;18(3):244-251. doi: 10.17085/apm.23056. Epub 
      2023 Jul 26.

PMID- 37225599
OWN - NLM
STAT- MEDLINE
DCOM- 20230811
LR  - 20230811
IS  - 1558-4623 (Electronic)
IS  - 0001-2998 (Linking)
VI  - 53
IP  - 5
DP  - 2023 Sep
TI  - Academic integrity and artificial intelligence: is ChatGPT hype, hero or heresy?
PG  - 719-730
LID - S0001-2998(23)00036-3 [pii]
LID - 10.1053/j.semnuclmed.2023.04.008 [doi]
AB  - Academic integrity in both higher education and scientific writing has been 
      challenged by developments in artificial intelligence. The limitations associated 
      with algorithms have been largely overcome by the recently released ChatGPT; a 
      chatbot powered by GPT-3.5 capable of producing accurate and human-like responses 
      to questions in real-time. Despite the potential benefits, ChatGPT confronts 
      significant limitations to its usefulness in nuclear medicine and radiology. Most 
      notably, ChatGPT is prone to errors and fabrication of information which poses a 
      risk to professionalism, ethics and integrity. These limitations simultaneously 
      undermine the value of ChatGPT to the user by not producing outcomes at the 
      expected standard. Nonetheless, there are a number of exciting applications of 
      ChatGPT in nuclear medicine across education, clinical and research sectors. 
      Assimilation of ChatGPT into practice requires redefining of norms, and 
      re-engineering of information expectations.
CI  - Copyright © 2023 Elsevier Inc. All rights reserved.
FAU - Currie, Geoffrey M
AU  - Currie GM
AD  - Charles Sturt University, Wagga Wagga, NSW, Australia; Baylor College of 
      Medicine, Houston, TX. Electronic address: gcurrie@csu.edu.au.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230522
PL  - United States
TA  - Semin Nucl Med
JT  - Seminars in nuclear medicine
JID - 1264464
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Nuclear Medicine
COIS- Declaration of Competing Interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2023/05/25 01:07
MHDA- 2023/08/11 06:42
CRDT- 2023/05/24 21:59
PHST- 2023/04/20 00:00 [received]
PHST- 2023/04/30 00:00 [accepted]
PHST- 2023/08/11 06:42 [medline]
PHST- 2023/05/25 01:07 [pubmed]
PHST- 2023/05/24 21:59 [entrez]
AID - S0001-2998(23)00036-3 [pii]
AID - 10.1053/j.semnuclmed.2023.04.008 [doi]
PST - ppublish
SO  - Semin Nucl Med. 2023 Sep;53(5):719-730. doi: 10.1053/j.semnuclmed.2023.04.008. 
      Epub 2023 May 22.

PMID- 37425514
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230718
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 6
DP  - 2023 Jun
TI  - ChatGPT From the Perspective of an Academic Oral and Maxillofacial Radiologist.
PG  - e40053
LID - 10.7759/cureus.40053 [doi]
LID - e40053
AB  - Chat Generative Pre-Trained Transformer (ChatGPT) is an open artificial 
      intelligence&nbsp;(AI)-powered chatbot with various clinical and academic dentistry 
      applications, including oral and maxillofacial radiology (OMFR). The applications 
      can be extended to generating documents such as oral radiology reports if 
      appropriate prompts are given. There are various challenges associated with this 
      task. Like other fields, ChatGPT can be incorporated to generate content and 
      answer oral radiology-related multiple-choice questions. However, its performance 
      is limited to answering image-based questions. ChatGPT can help in scientific 
      writing but can not be designated as an author due to the lack of validity of the 
      content. This editorial outlines the potential applications and limitations of 
      the current version of&nbsp;ChatGPT in OMFR academic settings.
CI  - Copyright © 2023, Khurana et al.
FAU - Khurana, Sonam
AU  - Khurana S
AD  - Oral Pathology, Radiology, and Medicine, New York University (NYU) College of 
      Dentistry, New York, USA.
FAU - Vaddi, Anusha
AU  - Vaddi A
AD  - Oral and Maxillofacial Radiology, Virginia Commonwealth University School of 
      Dentistry, Richmond, USA.
LA  - eng
PT  - Editorial
DEP - 20230606
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10325627
OTO - NOTNLM
OT  - chatgpt
OT  - dental education
OT  - maxillofacial radiology
OT  - radiology report
OT  - scientific papers
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/07/10 06:42
MHDA- 2023/07/10 06:43
PMCR- 2023/06/06
CRDT- 2023/07/10 04:57
PHST- 2023/06/05 00:00 [accepted]
PHST- 2023/07/10 06:43 [medline]
PHST- 2023/07/10 06:42 [pubmed]
PHST- 2023/07/10 04:57 [entrez]
PHST- 2023/06/06 00:00 [pmc-release]
AID - 10.7759/cureus.40053 [doi]
PST - epublish
SO  - Cureus. 2023 Jun 6;15(6):e40053. doi: 10.7759/cureus.40053. eCollection 2023 Jun.

PMID- 37309153
OWN - NLM
STAT- MEDLINE
DCOM- 20230614
LR  - 20230811
IS  - 1552-7409 (Electronic)
IS  - 0894-3184 (Linking)
VI  - 36
IP  - 3
DP  - 2023 Jul
TI  - ChatGPT and Forms of Deception.
PG  - 232-233
LID - 10.1177/08943184231169753 [doi]
AB  - The artificial intelligence (AI) chatbot ChatGPT movement has upset and permeated 
      all aspects of the healthcare arena, including the discipline of nursing. The use 
      of ChatGPT is ethically controversial. This article begins a discussion regarding 
      the impacts of ChatGPT and the possibilities of deception with its usage in 
      scientific and disciplinary publications and academic products.
FAU - Milton, Constance L
AU  - Milton CL
AUID- ORCID: 0000-0002-5848-6651
AD  - Professor Emeritus, School of Nursing, Azusa Pacific University, Azusa, CA, USA.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Nurs Sci Q
JT  - Nursing science quarterly
JID - 8805022
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Emotions
MH  - Deception
OTO - NOTNLM
OT  - ChatGPT
OT  - Chatbot
OT  - deception
OT  - ethics
OT  - nurse ethics
EDAT- 2023/06/13 06:42
MHDA- 2023/06/14 06:42
CRDT- 2023/06/13 03:39
PHST- 2023/06/14 06:42 [medline]
PHST- 2023/06/13 06:42 [pubmed]
PHST- 2023/06/13 03:39 [entrez]
AID - 10.1177/08943184231169753 [doi]
PST - ppublish
SO  - Nurs Sci Q. 2023 Jul;36(3):232-233. doi: 10.1177/08943184231169753.

PMID- 36920578
OWN - NLM
STAT- MEDLINE
DCOM- 20230425
LR  - 20230928
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 51
IP  - 5
DP  - 2023 May
TI  - Role of Chat GPT in Public Health.
PG  - 868-869
LID - 10.1007/s10439-023-03172-7 [doi]
AB  - ChatGPT, a language model developed by OpenAI, has the potential to play a role 
      in public health. With its ability to generate human-like text based on large 
      amounts of data, ChatGPT has the potential to support individuals and communities 
      in making informed decisions about their health (Panch et al. Lancet Digit Health 
      1:e13-e14, 2019; Baclic et al. Canada Commun Dis Rep 46.6:161, 2020). However, as 
      with any technology, there are limitations and challenges to consider when using 
      ChatGPT in public health. In this overview, we will examine the potential uses of 
      ChatGPT in public health, as well as the advantages and disadvantages of its use.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Biswas, Som S
AU  - Biswas SS
AUID- ORCID: 0000-0002-4038-5844
AD  - Le Bonheur Children's Hospital, The University of Tennessee Health Science 
      Center, Memphis, USA. ssbinmemphis@gmail.com.
LA  - eng
PT  - Letter
DEP - 20230315
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
CIN - Ann Biomed Eng. 2023 Oct;51(10):2120-2122. PMID: 37217804
MH  - Humans
MH  - *Public Health
MH  - Canada
MH  - *Technology
OTO - NOTNLM
OT  - AI
OT  - Public health
OT  - chatGPT
EDAT- 2023/03/16 06:00
MHDA- 2023/04/25 06:42
CRDT- 2023/03/15 12:17
PHST- 2023/02/20 00:00 [received]
PHST- 2023/02/21 00:00 [accepted]
PHST- 2023/04/25 06:42 [medline]
PHST- 2023/03/16 06:00 [pubmed]
PHST- 2023/03/15 12:17 [entrez]
AID - 10.1007/s10439-023-03172-7 [pii]
AID - 10.1007/s10439-023-03172-7 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2023 May;51(5):868-869. doi: 10.1007/s10439-023-03172-7. Epub 
      2023 Mar 15.

PMID- 37387114
OWN - NLM
STAT- MEDLINE
DCOM- 20230703
LR  - 20230703
IS  - 1879-8365 (Electronic)
IS  - 0926-9630 (Linking)
VI  - 305
DP  - 2023 Jun 29
TI  - The Pros and Cons of Using ChatGPT in Medical Education: A Scoping Review.
PG  - 644-647
LID - 10.3233/SHTI230580 [doi]
AB  - This scoping review explores the advantages and disadvantages of using ChatGPT in 
      medical education. We searched PubMed, Google Scholar, Medline, Scopus, and 
      Science Direct to identify relevant studies. Two reviewers independently 
      conducted study selection and data extraction, followed by a narrative synthesis. 
      Out of 197 references, 25 studies met the eligibility criteria. The primary 
      applications of ChatGPT in medical education include automated scoring, teaching 
      assistance, personalized learning, research assistance, quick access to 
      information, generating case scenarios and exam questions, content creation for 
      learning facilitation, and language translation. We also discuss the challenges 
      and limitations of using ChatGPT in medical education, such as its inability to 
      reason beyond existing knowledge, generation of incorrect information, bias, 
      potential undermining of students' critical thinking skills, and ethical 
      concerns. These concerns include using ChatGPT for exam and assignment cheating 
      by students and researchers, as well as issues related to patients' privacy.
FAU - Mohammad, Bushra
AU  - Mohammad B
AD  - College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar.
FAU - Supti, Turjana
AU  - Supti T
AD  - College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar.
FAU - Alzubaidi, Mahmood
AU  - Alzubaidi M
AD  - College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar.
FAU - Shah, Hurmat
AU  - Shah H
AD  - College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar.
FAU - Alam, Tanvir
AU  - Alam T
AD  - College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar.
FAU - Shah, Zubair
AU  - Shah Z
AD  - College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar.
FAU - Househ, Mowafa
AU  - Househ M
AD  - College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar.
LA  - eng
PT  - Journal Article
PT  - Review
PL  - Netherlands
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
MH  - Humans
MH  - *Education, Medical
MH  - Eligibility Determination
MH  - Knowledge
MH  - Learning
MH  - MEDLINE
OTO - NOTNLM
OT  - ChatGPT
OT  - Chatbot
OT  - Medical Education
OT  - Open AI
EDAT- 2023/06/30 06:42
MHDA- 2023/07/03 06:41
CRDT- 2023/06/30 04:24
PHST- 2023/07/03 06:41 [medline]
PHST- 2023/06/30 06:42 [pubmed]
PHST- 2023/06/30 04:24 [entrez]
AID - SHTI230580 [pii]
AID - 10.3233/SHTI230580 [doi]
PST - ppublish
SO  - Stud Health Technol Inform. 2023 Jun 29;305:644-647. doi: 10.3233/SHTI230580.

PMID- 37183840
OWN - NLM
STAT- MEDLINE
DCOM- 20230724
LR  - 20230822
IS  - 1748-880X (Electronic)
IS  - 0007-1285 (Print)
IS  - 0007-1285 (Linking)
VI  - 96
IP  - 1148
DP  - 2023 Aug
TI  - ChatGPT from radiologists' perspective.
PG  - 20230203
LID - 10.1259/bjr.20230203 [doi]
LID - 20230203
AB  - ChatGPT is a newly developed technology created by the OpenAI company. It is an 
      artificial-intelligence-based large language model (LLM) and able to generate 
      human-like text. The potential roles of ChatGPT in clinical decision support and 
      academic writing have led to intense criticism of this technology in the 
      scientific community. Therefore, radiologists also need to be familiar with LLMs 
      such as ChatGPT.
FAU - Şendur, Halit Nahit
AU  - Şendur HN
AUID- ORCID: 0000-0003-1690-2538
AD  - Department of Radiology, Gazi University, Faculty of Medicine, Mevlana Bulvarı, 
      Yenimahalle, Ankara, Turkey.
FAU - Şendur, Aylin Billur
AU  - Şendur AB
AD  - Private Radiology Clinic, Kızılırmak Mah. 1443. Cad. No:25 1071 Plaza, Çankaya, 
      Ankara, Turkey.
FAU - Cerit, Mahi Nur
AU  - Cerit MN
AD  - Department of Radiology, Gazi University, Faculty of Medicine, Mevlana Bulvarı, 
      Yenimahalle, Ankara, Turkey.
LA  - eng
PT  - Journal Article
DEP - 20230515
PL  - England
TA  - Br J Radiol
JT  - The British journal of radiology
JID - 0373125
SB  - IM
CIN - Br J Radiol. 2023 Sep;96(1149):20230442. PMID: 37399112
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Radiologists
PMC - PMC10392643
EDAT- 2023/05/15 13:06
MHDA- 2023/07/24 06:42
PMCR- 2024/08/01
CRDT- 2023/05/15 06:13
PHST- 2024/08/01 00:00 [pmc-release]
PHST- 2023/07/24 06:42 [medline]
PHST- 2023/05/15 13:06 [pubmed]
PHST- 2023/05/15 06:13 [entrez]
AID - 10.1259/bjr.20230203 [doi]
PST - ppublish
SO  - Br J Radiol. 2023 Aug;96(1148):20230203. doi: 10.1259/bjr.20230203. Epub 2023 May 
      15.

PMID- 37581690
OWN - NLM
STAT- MEDLINE
DCOM- 20230905
LR  - 20231229
IS  - 1573-689X (Electronic)
IS  - 0148-5598 (Linking)
VI  - 47
IP  - 1
DP  - 2023 Aug 15
TI  - ChatGPT Performs on the Chinese National Medical Licensing Examination.
PG  - 86
LID - 10.1007/s10916-023-01961-0 [doi]
AB  - ChatGPT, a language model developed by OpenAI, uses a 175 billion parameter 
      Transformer architecture for natural language processing tasks. This study aimed 
      to compare the knowledge and interpretation ability of ChatGPT with those of 
      medical students in China by administering the Chinese National Medical Licensing 
      Examination (NMLE) to both ChatGPT and medical students.&nbsp;We evaluated the 
      performance of ChatGPT in three years' worth of the NMLE, which consists of four 
      units. At the same time, the exam results were compared to those of medical 
      students who had studied for five years at medical colleges.&nbsp;ChatGPT's 
      performance was lower than that of the medical students, and ChatGPT's correct 
      answer rate was related to the year in which the exam questions were 
      released.&nbsp;ChatGPT's knowledge and interpretation ability for the NMLE were not 
      yet comparable to those of medical students in China. It is probable that these 
      abilities will improve through deep learning.
CI  - © 2023. The Author(s), under exclusive licence to Springer Science+Business 
      Media, LLC, part of Springer Nature.
FAU - Wang, Xinyi
AU  - Wang X
AD  - Department of Medical Education, Ruijin Hospital Affifiliated to Shanghai Jiao 
      Tong University School of Medicine, 197 Ruijin Rd. II, Shanghai, 200025, China.
FAU - Gong, Zhenye
AU  - Gong Z
AD  - Department of Medical Education, Ruijin Hospital Affifiliated to Shanghai Jiao 
      Tong University School of Medicine, 197 Ruijin Rd. II, Shanghai, 200025, China.
FAU - Wang, Guoxin
AU  - Wang G
AD  - Department of Medical Education, Ruijin Hospital Affifiliated to Shanghai Jiao 
      Tong University School of Medicine, 197 Ruijin Rd. II, Shanghai, 200025, China.
FAU - Jia, Jingdan
AU  - Jia J
AD  - Department of Medical Education, Ruijin Hospital Affifiliated to Shanghai Jiao 
      Tong University School of Medicine, 197 Ruijin Rd. II, Shanghai, 200025, China.
FAU - Xu, Ying
AU  - Xu Y
AD  - Department of Medical Education, Ruijin Hospital Affifiliated to Shanghai Jiao 
      Tong University School of Medicine, 197 Ruijin Rd. II, Shanghai, 200025, China.
FAU - Zhao, Jialu
AU  - Zhao J
AD  - Department of Medical Education, Ruijin Hospital Affifiliated to Shanghai Jiao 
      Tong University School of Medicine, 197 Ruijin Rd. II, Shanghai, 200025, China.
FAU - Fan, Qingye
AU  - Fan Q
AD  - Department of Medical Education, Ruijin Hospital Affifiliated to Shanghai Jiao 
      Tong University School of Medicine, 197 Ruijin Rd. II, Shanghai, 200025, China.
FAU - Wu, Shaun
AU  - Wu S
AD  - WORK Medical Technology Group LTD, Hangzhou, China.
FAU - Hu, Weiguo
AU  - Hu W
AD  - Department of Medical Education, Ruijin Hospital Affifiliated to Shanghai Jiao 
      Tong University School of Medicine, 197 Ruijin Rd. II, Shanghai, 200025, China.
FAU - Li, Xiaoyang
AU  - Li X
AUID- ORCID: 0000-0003-4309-8709
AD  - Department of Medical Education, Ruijin Hospital Affifiliated to Shanghai Jiao 
      Tong University School of Medicine, 197 Ruijin Rd. II, Shanghai, 200025, China. 
      woodslee429@126.com.
LA  - eng
PT  - Comparative Study
PT  - Journal Article
DEP - 20230815
PL  - United States
TA  - J Med Syst
JT  - Journal of medical systems
JID - 7806056
SB  - IM
MH  - Humans
MH  - Asian People
MH  - China
MH  - Knowledge
MH  - Language
MH  - *Artificial Intelligence
MH  - *Medicine/standards
MH  - *Licensure/standards
MH  - *Students, Medical/statistics &amp; numerical data
MH  - *Educational Measurement/standards
OTO - NOTNLM
OT  - ChatGPT
OT  - Chinese National Medical Licensing Examination
OT  - Medical student
EDAT- 2023/08/15 12:42
MHDA- 2023/08/16 06:43
CRDT- 2023/08/15 11:05
PHST- 2023/02/14 00:00 [received]
PHST- 2023/06/22 00:00 [accepted]
PHST- 2023/08/16 06:43 [medline]
PHST- 2023/08/15 12:42 [pubmed]
PHST- 2023/08/15 11:05 [entrez]
AID - 10.1007/s10916-023-01961-0 [pii]
AID - 10.1007/s10916-023-01961-0 [doi]
PST - epublish
SO  - J Med Syst. 2023 Aug 15;47(1):86. doi: 10.1007/s10916-023-01961-0.

PMID- 37440696
OWN - NLM
STAT- Publisher
LR  - 20231020
IS  - 1536-0075 (Electronic)
IS  - 1526-5161 (Linking)
VI  - 23
IP  - 10
DP  - 2023 Oct
TI  - What Should ChatGPT Mean for Bioethics?
PG  - 8-16
LID - 10.1080/15265161.2023.2233357 [doi]
AB  - In the last several months, several major disciplines have started their initial 
      reckoning with what ChatGPT and other Large Language Models (LLMs) mean for them 
      - law, medicine, business among other professions. With a heavy dose of humility, 
      given how fast the technology is moving and how uncertain its social implications 
      are, this article attempts to give some early tentative thoughts on what ChatGPT 
      might mean for bioethics. I will first argue that many bioethics issues raised by 
      ChatGPT are similar to those raised by current medical AI - built into devices, 
      decision support tools, data analytics, etc. These include issues of data 
      ownership, consent for data use, data representativeness and bias, and privacy. I 
      describe how these familiar issues appear somewhat differently in the ChatGPT 
      context, but much of the existing bioethical thinking on these issues provides a 
      strong starting point. There are, however, a few "new-ish" issues I highlight - 
      by new-ish I mean issues that while perhaps not truly new seem much more 
      important for it than other forms of medical AI. These include issues about 
      informed consent and the right to know we are dealing with an AI, the problem of 
      medical deepfakes, the risk of oligopoly and inequitable access related to 
      foundational models, environmental effects, and on the positive side 
      opportunities for the democratization of knowledge and empowering patients. I 
      also discuss how races towards dominance (between large companies and between the 
      U.S. and geopolitical rivals like China) risk sidelining ethics.
FAU - Cohen, I Glenn
AU  - Cohen IG
AD  - Petrie-Flom Center for Health Law Policy, Biotechnology &amp; Bioethics, Harvard Law 
      School.
LA  - eng
PT  - Journal Article
DEP - 20230713
PL  - United States
TA  - Am J Bioeth
JT  - The American journal of bioethics : AJOB
JID - 100898738
SB  - IM
CIN - Am J Bioeth. 2023 Oct;23(10):60-63. PMID: 37812095
CIN - Am J Bioeth. 2023 Oct;23(10):63-65. PMID: 37812097
CIN - Am J Bioeth. 2023 Oct;23(10):65-68. PMID: 37812098
CIN - Am J Bioeth. 2023 Oct;23(10):80-82. PMID: 37812099
CIN - Am J Bioeth. 2023 Oct;23(10):74-77. PMID: 37812102
CIN - Am J Bioeth. 2023 Oct;23(10):102-104. PMID: 37812104
CIN - Am J Bioeth. 2023 Oct;23(10):113-115. PMID: 37812105
CIN - Am J Bioeth. 2023 Oct;23(10):99-102. PMID: 37812106
CIN - Am J Bioeth. 2023 Oct;23(10):110-113. PMID: 37812107
CIN - Am J Bioeth. 2023 Oct;23(10):86-88. PMID: 37812108
CIN - Am J Bioeth. 2023 Oct;23(10):52-54. PMID: 37812110
CIN - Am J Bioeth. 2023 Oct;23(10):107-110. PMID: 37812112
CIN - Am J Bioeth. 2023 Oct;23(10):55-57. PMID: 37812113
CIN - Am J Bioeth. 2023 Oct;23(10):42-44. PMID: 37812114
CIN - Am J Bioeth. 2023 Oct;23(10):83-85. PMID: 37812116
CIN - Am J Bioeth. 2023 Oct;23(10):58-60. PMID: 37812118
CIN - Am J Bioeth. 2023 Oct;23(10):77-80. PMID: 37812122
CIN - Am J Bioeth. 2023 Oct;23(10):71-73. PMID: 37812123
CIN - Am J Bioeth. 2023 Oct;23(10):1-5. PMID: 37831940
OTO - NOTNLM
OT  - ChatGPT
OT  - bias
OT  - environment
OT  - informed consent
OT  - large language model (LLM)
OT  - oligopoly
OT  - privacy
EDAT- 2023/07/13 19:15
MHDA- 2023/07/13 19:15
CRDT- 2023/07/13 14:43
PHST- 2023/07/13 19:15 [pubmed]
PHST- 2023/07/13 19:15 [medline]
PHST- 2023/07/13 14:43 [entrez]
AID - 10.1080/15265161.2023.2233357 [doi]
PST - ppublish
SO  - Am J Bioeth. 2023 Oct;23(10):8-16. doi: 10.1080/15265161.2023.2233357. Epub 2023 
      Jul 13.

PMID- 38320337
OWN - NLM
STAT- MEDLINE
DCOM- 20240318
LR  - 20240318
IS  - 1873-4499 (Electronic)
IS  - 0899-7071 (Linking)
VI  - 108
DP  - 2024 Apr
TI  - Understanding ChatGPT for evidence-based utilization in interventional radiology.
PG  - 110098
LID - S0899-7071(24)00028-7 [pii]
LID - 10.1016/j.clinimag.2024.110098 [doi]
AB  - Advancement in artificial intelligence (AI) has the potential to improve the 
      efficiency and accuracy of medical care. New techniques used in machine learning 
      have enhanced the functionality of software to perform advanced tasks with 
      human-like capabilities. ChatGPT is the most utilized large language model and 
      provides a diverse range of communication tasks. Interventional Radiology (IR) 
      may benefit from the implementation of ChatGPT for specific tasks. This review 
      summarizes the design principles of ChatGPT relevant to healthcare and highlights 
      activities with the greatest potential for ChatGPT utilization in the practice of 
      IR. These tasks involve patient-directed and physician-directed communications to 
      convey medical information efficiently and act as a medical decision support 
      tool. ChatGPT exemplifies the evolving landscape of new AI tools for advancing 
      patient care and how physicians and patients may benefit with strategic 
      execution.
CI  - Copyright © 2024. Published by Elsevier Inc.
FAU - Campbell, Warren A 4th
AU  - Campbell WA 4th
AD  - Division of Vascular and Interventional Radiology, Department of Radiology, 
      University of Virginia, Charlottesville, VA, United States of America. Electronic 
      address: wac3ua@uvahealth.org.
FAU - Chick, Jeffrey F B
AU  - Chick JFB
AD  - Division of Vascular and Interventional Radiology, Department of Radiology, 
      University of Washington, Seattle, WA, United States of America.
FAU - Shin, David
AU  - Shin D
AD  - Division of Vascular and Interventional Radiology, Department of Radiology, 
      University of Washington, Seattle, WA, United States of America.
FAU - Makary, Mina S
AU  - Makary MS
AD  - Division of Vascular and Interventional Radiology, Department of Radiology, The 
      Ohio State University Wexner Medical Center, Columbus, OH, United States of 
      America.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20240201
PL  - United States
TA  - Clin Imaging
JT  - Clinical imaging
JID - 8911831
SB  - IM
MH  - Humans
MH  - *Radiology, Interventional
MH  - *Artificial Intelligence
MH  - Communication
MH  - Language
MH  - Machine Learning
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - IR
COIS- Declaration of competing interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2024/02/06 18:42
MHDA- 2024/03/18 06:44
CRDT- 2024/02/06 18:00
PHST- 2023/11/02 00:00 [received]
PHST- 2024/01/24 00:00 [revised]
PHST- 2024/01/28 00:00 [accepted]
PHST- 2024/03/18 06:44 [medline]
PHST- 2024/02/06 18:42 [pubmed]
PHST- 2024/02/06 18:00 [entrez]
AID - S0899-7071(24)00028-7 [pii]
AID - 10.1016/j.clinimag.2024.110098 [doi]
PST - ppublish
SO  - Clin Imaging. 2024 Apr;108:110098. doi: 10.1016/j.clinimag.2024.110098. Epub 2024 
      Feb 1.

PMID- 36989584
OWN - NLM
STAT- MEDLINE
DCOM- 20230508
LR  - 20231122
IS  - 1878-0334 (Electronic)
IS  - 1871-4021 (Linking)
VI  - 17
IP  - 4
DP  - 2023 Apr
TI  - ChatGPT: Is this version good for healthcare and research?
PG  - 102744
LID - S1871-4021(23)00040-1 [pii]
LID - 10.1016/j.dsx.2023.102744 [doi]
AB  - BACKGROUND AND AIMS: There have been advancements in artificial intelligence (AI) 
      and deep learning in the past decade. Recently, OpenAI Inc. has launched a new 
      chatbot, called ChatGPT that interacts in a conversational way and its dialogue 
      format makes is user friendly and fast. In this paper we aimed to explore the 
      current position and the accuracy of currently available version of ChatGPT in 
      relation to healthcare and medical research. METHODS: We searched the PubMed, 
      Scopus, and Google databases from 15(th) to 25(th) February 2023, using the 
      keywords: 'ChatGPT' AND 'medical research, healthcare, and scientific writing'. 
      We found 29 results in PubMed and 9 results in Scopus database., in English 
      language. In addition, we (RV, AM) interacted with ChatGPT multiple times to 
      review accuracy of responses of various medical questions. RESULTS: Using 
      literature search and interactions with ChatGPT with medical questions, we infer 
      that this version generates answers rapidly but narrates data from existing 
      internet literature in a general manner. However, as emphasised by the company in 
      the landing page of ChatGPT, we found errors in responses to medical questions, 
      Further, narrated data were limited up to September 2021. Positive features 
      include admission of its limitations in medical field, and as it has been 
      designed, learning from previous answers. CONCLUSION: Current version of ChatGPT 
      may be useful in a limited manner as a narrative AI chatbot for medical 
      personnel, however, researchers are advised to fact check all statements 
      provided, keeping in mind its limitations.
CI  - Copyright © 2023 Research Trust of DiabetesIndia (DiabetesIndia) and National 
      Diabetes Obesity and Cholesterol Foundation (N-DOC). Published by Elsevier Ltd. 
      All rights reserved.
FAU - Vaishya, Raju
AU  - Vaishya R
AD  - Department of Orthopaedics, Indraprastha Apollo Hospitals, Sarita Vihar, 110076, 
      New Delhi, India. Electronic address: raju.vaishya@gmail.com.
FAU - Misra, Anoop
AU  - Misra A
AD  - Department of Endocrinology, Fortis C Doc Hospital, Nehru Place, New Delhi, 
      India.
FAU - Vaish, Abhishek
AU  - Vaish A
AD  - Department of Orthopaedics, Indraprastha Apollo Hospitals, Sarita Vihar, 110076, 
      New Delhi, India.
LA  - eng
PT  - Journal Article
DEP - 20230315
PL  - Netherlands
TA  - Diabetes Metab Syndr
JT  - Diabetes &amp; metabolic syndrome
JID - 101462250
SB  - IM
CIN - Diabetes Metab Syndr. 2023 May;17(5):102779. PMID: 37178512
MH  - Humans
MH  - *Artificial Intelligence
MH  - Health Facilities
MH  - *Biomedical Research
MH  - Databases, Factual
MH  - Delivery of Health Care
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Healthcare
OT  - Research
COIS- Declaration of competing interest None.
EDAT- 2023/03/30 06:00
MHDA- 2023/05/08 06:42
CRDT- 2023/03/29 18:02
PHST- 2023/03/01 00:00 [received]
PHST- 2023/03/07 00:00 [revised]
PHST- 2023/03/10 00:00 [accepted]
PHST- 2023/05/08 06:42 [medline]
PHST- 2023/03/30 06:00 [pubmed]
PHST- 2023/03/29 18:02 [entrez]
AID - S1871-4021(23)00040-1 [pii]
AID - 10.1016/j.dsx.2023.102744 [doi]
PST - ppublish
SO  - Diabetes Metab Syndr. 2023 Apr;17(4):102744. doi: 10.1016/j.dsx.2023.102744. Epub 
      2023 Mar 15.

PMID- 37720035
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240401
DP  - 2023 Aug 28
TI  - Performance of ChatGPT in Diagnosis of Corneal Eye Diseases.
LID - 2023.08.25.23294635 [pii]
LID - 10.1101/2023.08.25.23294635 [doi]
AB  - INTRODUCTION: Assessing the capabilities of ChatGPT-4.0 and ChatGPT-3.5 for 
      diagnosing corneal eye diseases based on case reports and compare with human 
      experts. METHODS: We randomly selected 20 cases of corneal diseases including 
      corneal infections, dystrophies, degenerations, and injuries from a publicly 
      accessible online database from the University of Iowa. We then input the text of 
      each case description into ChatGPT-4.0 and ChatGPT3.5 and asked for a provisional 
      diagnosis. We finally evaluated the responses based on the correct diagnoses then 
      compared with the diagnoses of three cornea specialists (Human experts) and 
      evaluated interobserver agreements. RESULTS: The provisional diagnosis accuracy 
      based on ChatGPT-4.0 was 85% (17 correct out of 20 cases) while the accuracy of 
      ChatGPT-3.5 was 60% (12 correct cases out of 20). The accuracy of three cornea 
      specialists were 100% (20 cases), 90% (18 cases), and 90% (18 cases), 
      respectively. The interobserver agreement between ChatGPT-4.0 and ChatGPT-3.5 was 
      65% (13 cases) while the interobserver agreement between ChatGPT-4.0 and three 
      cornea specialists were 85% (17 cases), 80% (16 cases), and 75% (15 cases), 
      respectively. However, the interobserver agreement between ChatGPT-3.5 and each 
      of three cornea specialists was 60% (12 cases). CONCLUSIONS: The accuracy of 
      ChatGPT-4.0 in diagnosing patients with various corneal conditions was markedly 
      improved than ChatGPT-3.5 and promising for potential clinical integration.
FAU - Delsoz, Mohammad
AU  - Delsoz M
AD  - Hamilton Eye Institute, Department of Ophthalmology, University of Tennessee 
      Health Science Center, Memphis, TN, USA.
FAU - Madadi, Yeganeh
AU  - Madadi Y
AD  - Hamilton Eye Institute, Department of Ophthalmology, University of Tennessee 
      Health Science Center, Memphis, TN, USA.
FAU - Munir, Wuqaas M
AU  - Munir WM
AD  - Department of Ophthalmology and Visual Sciences, University of Maryland School of 
      Medicine, Baltimore, MD, USA.
FAU - Tamm, Brendan
AU  - Tamm B
AD  - Department of Ophthalmology and Visual Sciences, University of Maryland School of 
      Medicine, Baltimore, MD, USA.
FAU - Mehravaran, Shiva
AU  - Mehravaran S
AD  - School of Computer, Mathematical, and Natural Sciences, Morgan State University, 
      Baltimore, MD, USA.
FAU - Soleimani, Mohammad
AU  - Soleimani M
AD  - Department of Ophthalmology and Visual Sciences, University of Illinois at 
      Chicago, Chicago, Illinois, USA.
AD  - Eye Research Center, Farabi Eye Hospital, Tehran University of Medical Sciences, 
      Tehran, Iran.
FAU - Djalilian, Ali
AU  - Djalilian A
AD  - Department of Ophthalmology and Visual Sciences, University of Illinois at 
      Chicago, Chicago, Illinois, USA.
FAU - Yousefi, Siamak
AU  - Yousefi S
AD  - Hamilton Eye Institute, Department of Ophthalmology, University of Tennessee 
      Health Science Center, Memphis, TN, USA.
AD  - Department of Genetics, Genomics, and Informatics, University of Tennessee Health 
      Science Center, Memphis, TN, USA.
LA  - eng
GR  - R01 EY033005/EY/NEI NIH HHS/United States
GR  - R21 EY031725/EY/NEI NIH HHS/United States
PT  - Preprint
DEP - 20230828
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
UIN - Cornea. 2024 Feb 23;:. PMID: 38391243
PMC - PMC10500623
OTO - NOTNLM
OT  - Artificial Intelligence (AI)
OT  - ChatGPT
OT  - Corneal eye diseases
OT  - Generative Pre-trained Transformer (GPT)
OT  - Large Language Models (LLM)
OT  - Provisional Diagnosis
COIS- Conflict of Interest Mohammad Delsoz: None. Yeganeh Madadi: None Wuqaas M Munir: 
      None Brendan Tamm: None Shiva Mehravaran: None Mohammad Soleimani: None Ali 
      Djalilian: None Siamak Yousefi: Remidio, M&amp;S Technologies, Visrtucal Fields, 
      InsihgtAEye, Enolink
EDAT- 2023/09/18 06:42
MHDA- 2023/09/18 06:43
PMCR- 2023/09/14
CRDT- 2023/09/18 04:33
PHST- 2023/09/18 06:43 [medline]
PHST- 2023/09/18 06:42 [pubmed]
PHST- 2023/09/18 04:33 [entrez]
PHST- 2023/09/14 00:00 [pmc-release]
AID - 2023.08.25.23294635 [pii]
AID - 10.1101/2023.08.25.23294635 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2023 Aug 28:2023.08.25.23294635. doi: 
      10.1101/2023.08.25.23294635.

PMID- 38149123
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231228
IS  - 1756-283X (Print)
IS  - 1756-2848 (Electronic)
IS  - 1756-283X (Linking)
VI  - 16
DP  - 2023
TI  - Evaluating the role of ChatGPT in gastroenterology: a comprehensive systematic 
      review of applications, benefits, and limitations.
PG  - 17562848231218618
LID - 10.1177/17562848231218618 [doi]
LID - 17562848231218618
AB  - BACKGROUND: The integration of artificial intelligence (AI) into healthcare has 
      opened new avenues for enhancing patient care and clinical research. In 
      gastroenterology, the potential of AI tools, specifically large language models 
      like ChatGPT, is being explored to understand their utility and effectiveness. 
      OBJECTIVES: The primary goal of this systematic review is to assess the various 
      applications, ascertain the benefits, and identify the limitations of utilizing 
      ChatGPT within the realm of gastroenterology. DESIGN: Through a systematic 
      approach, this review aggregates findings from multiple studies to evaluate the 
      impact of ChatGPT on the field. DATA SOURCES AND METHODS: The review was based on 
      a detailed literature search of the PubMed database, targeting research that 
      delves into the use of ChatGPT for gastroenterological purposes. It incorporated 
      six selected studies, which were meticulously evaluated for quality using the 
      Joanna Briggs Institute critical appraisal instruments. The data were then 
      synthesized narratively to encapsulate the roles, advantages, and drawbacks of 
      ChatGPT in gastroenterology. RESULTS: The investigation unearthed various roles 
      of ChatGPT, including its use in patient education, diagnostic self-assessment, 
      disease management, and the formulation of research queries. Notable benefits 
      were its capability to provide pertinent recommendations, enhance communication 
      between patients and physicians, and prompt valuable research inquiries. 
      Nonetheless, it encountered obstacles in decoding intricate medical questions, 
      yielded inconsistent responses at times, and exhibited limitations in generating 
      novel content. The review also considered ethical implications. CONCLUSION: 
      ChatGPT has demonstrated significant potential in the field of gastroenterology, 
      especially in facilitating patient-physician interactions and managing diseases. 
      Despite these advancements, the review underscores the necessity for ongoing 
      refinement, customization, and ethical regulation of AI tools. These findings 
      serve to enrich the dialog concerning AI's role in healthcare, with a specific 
      focus on ChatGPT's application in gastroenterology.
CI  - © The Author(s), 2023.
FAU - Klang, Eyal
AU  - Klang E
AD  - Division of Data-Driven and Digital Medicine (D3M), Icahn School of Medicine at 
      Mount Sinai, New York, NY, USA.
AD  - The Charles Bronfman Institute of Personalized Medicine, Icahn School of Medicine 
      at Mount Sinai, New York, NY, USA.
AD  - ARC Innovation Center, Sheba Medical Center at Tel Hashomer Affiliated with Tel 
      Aviv Medical School, Tel Aviv University, Tel Aviv, Israel.
FAU - Sourosh, Ali
AU  - Sourosh A
AD  - Division of Data-Driven and Digital Medicine (D3M), Icahn School of Medicine at 
      Mount Sinai, New York, NY, USA.
AD  - The Charles Bronfman Institute of Personalized Medicine, Icahn School of Medicine 
      at Mount Sinai, New York, NY, USA.
FAU - Nadkarni, Girish N
AU  - Nadkarni GN
AD  - Division of Data-Driven and Digital Medicine (D3M), Icahn School of Medicine at 
      Mount Sinai, New York, NY, USA.
AD  - The Charles Bronfman Institute of Personalized Medicine, Icahn School of Medicine 
      at Mount Sinai, New York, NY, USA.
FAU - Sharif, Kassem
AU  - Sharif K
AD  - Department of Gastroenterology, Sheba Medical Center at Tel Hashomer Affiliated 
      with Tel Aviv Medical School, Tel Aviv University, Tel Aviv, Israel.
FAU - Lahat, Adi
AU  - Lahat A
AUID- ORCID: 0000-0003-1513-7280
AD  - Department of Gastroenterology, Sheba Medical Center at Tel Hashomer, Ramat Gan, 
      52621 Affiliated with Tel Aviv Medical School, Tel Aviv University, Tel Aviv, 
      Israel.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20231225
PL  - England
TA  - Therap Adv Gastroenterol
JT  - Therapeutic advances in gastroenterology
JID - 101478893
PMC - PMC10750546
OAB - Checking how ChatGPT works in gastroenterology: a detailed look at its uses, 
      advantages, and challenges Goal We looked at how ChatGPT, a computer program, is 
      used in the study Gastroenterology. We wanted to understand what’s good about it, 
      what’s challenging, and how it can help doctors and patients. How We Did It We 
      searched for articles about ChatGPT in Gastroenterology on PubMed. We found six 
      suitable articles and checked their quality using the Joanna Briggs Institute 
      (JBI) critical appraisal tools. Then, we put all the information together to get 
      a clear picture. What We Found Doctors and researchers use ChatGPT in many ways. 
      Some use it to teach patients about their health, while others use it to help 
      patients check their symptoms or manage their conditions. It can even help come 
      up with research questions. The good things about ChatGPT are that it gives 
      helpful advice, makes talking between doctors and patients easier, and helps come 
      up with research topics. But, sometimes it doesn’t understand hard medical 
      questions, gives different answers for the same question, or lacks new ideas. 
      There are also concerns about using it the right way. What This Means ChatGPT can 
      be a helpful tool in Gastroenterology, especially when talking with patients and 
      managing their health. But, there are challenges that need to be fixed. Our 
      review helps people understand how ChatGPT can be used in health care, especially 
      in the field of Gastroenterology.
OABL- eng
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - gastroenterology
OT  - large language models
OT  - review
COIS- The authors declare that there is no conflict of interest.
EDAT- 2023/12/27 06:42
MHDA- 2023/12/27 06:43
PMCR- 2023/12/25
CRDT- 2023/12/27 03:49
PHST- 2023/10/03 00:00 [received]
PHST- 2023/11/16 00:00 [accepted]
PHST- 2023/12/27 06:43 [medline]
PHST- 2023/12/27 06:42 [pubmed]
PHST- 2023/12/27 03:49 [entrez]
PHST- 2023/12/25 00:00 [pmc-release]
AID - 10.1177_17562848231218618 [pii]
AID - 10.1177/17562848231218618 [doi]
PST - epublish
SO  - Therap Adv Gastroenterol. 2023 Dec 25;16:17562848231218618. doi: 
      10.1177/17562848231218618. eCollection 2023.

PMID- 37349064
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20230626
LR  - 20230626
IS  - 1873-1570 (Electronic)
IS  - 0300-9572 (Linking)
VI  - 188
DP  - 2023 Jul
TI  - ChatGPT can pass the AHA exams: Open-ended questions outperform multiple-choice 
      format.
PG  - 109783
LID - S0300-9572(23)00096-5 [pii]
LID - 10.1016/j.resuscitation.2023.109783 [doi]
AB  - The study by Fijačko et al. tested ChatGPT's ability to pass the BLS and ACLS 
      exams of AHA, but found that ChatGPT failed both exams. A limitation of their 
      study was using ChatGPT to generate only one response, which may have introduced 
      bias. When generating three responses per question, ChatGPT can pass BLS exam 
      with an overall accuracy of 84%. When incorrectly answered questions were 
      rewritten as open-ended questions, ChatGPT's accuracy rate increased to 96% and 
      92.1% for the BLS and ACLS exams, respectively, allowing ChatGPT to pass both 
      exams with outstanding results.
CI  - Copyright © 2023 Elsevier B.V. All rights reserved.
FAU - Zhu, Lingxuan
AU  - Zhu L
AD  - Department of Urology, Renji Hospital, Shanghai Jiao Tong University School of 
      Medicine, 160 Pujian Road, Shanghai 200127, China; The First Clinical Medical 
      School, Southern Medical University, 1023 Shatai South Road, Guangzhou, 510515 
      Guangdong, China.
FAU - Mou, Weiming
AU  - Mou W
AD  - The First Clinical Medical School, Southern Medical University, 1023 Shatai South 
      Road, Guangzhou, 510515 Guangdong, China.
FAU - Yang, Tao
AU  - Yang T
AD  - The First Clinical Medical School, Southern Medical University, 1023 Shatai South 
      Road, Guangzhou, 510515 Guangdong, China.
FAU - Chen, Rui
AU  - Chen R
AD  - Department of Urology, Renji Hospital, Shanghai Jiao Tong University School of 
      Medicine, 160 Pujian Road, Shanghai 200127, China. Electronic address: 
      drchenrui@foxmail.com.
LA  - eng
PT  - Letter
PL  - Ireland
TA  - Resuscitation
JT  - Resuscitation
JID - 0332173
SB  - IM
EDAT- 2023/06/23 01:10
MHDA- 2023/06/23 01:11
CRDT- 2023/06/22 21:01
PHST- 2023/03/15 00:00 [received]
PHST- 2023/03/17 00:00 [accepted]
PHST- 2023/06/23 01:11 [medline]
PHST- 2023/06/23 01:10 [pubmed]
PHST- 2023/06/22 21:01 [entrez]
AID - S0300-9572(23)00096-5 [pii]
AID - 10.1016/j.resuscitation.2023.109783 [doi]
PST - ppublish
SO  - Resuscitation. 2023 Jul;188:109783. doi: 10.1016/j.resuscitation.2023.109783.

PMID- 38281582
OWN - NLM
STAT- MEDLINE
DCOM- 20240320
LR  - 20240320
IS  - 2589-9333 (Electronic)
IS  - 2589-9333 (Linking)
VI  - 6
IP  - 3
DP  - 2024 Mar
TI  - ChatGPT in maternal-fetal medicine practice: a primer for clinicians.
PG  - 101302
LID - S2589-9333(24)00028-4 [pii]
LID - 10.1016/j.ajogmf.2024.101302 [doi]
AB  - ChatGPT (Generative Pre-trained Transformer), a language model that was developed 
      by OpenAI and launched in November 2022, generates human-like responses to 
      prompts using deep-learning technology. The integration of large language 
      processing models into healthcare has the potential to improve the accessibility 
      of medical information for both patients and health professionals alike. In this 
      commentary, we demonstrated the ability of ChatGPT to produce patient information 
      sheets. Four board-certified, maternal-fetal medicine attending physicians rated 
      the accuracy and humanness of the information according to 2 predefined scales of 
      accuracy and completeness. The median score for accuracy of information was rated 
      4.8 on a 6-point scale and the median score for completeness of information was 
      2.2 on a 3-point scale for the 5 patient information leaflets generated by 
      ChatGPT. Concerns raised included the omission of clinically important 
      information for patient counseling in some patient information leaflets and the 
      inability to verify the source of information because ChatGPT does not provide 
      references. ChatGPT is a powerful tool that has the potential to enhance patient 
      care, but such a tool requires extensive validation and is perhaps best 
      considered as an adjunct to clinical practice rather than as a tool to be used 
      freely by the public for healthcare information.
CI  - Copyright © 2024 Elsevier Inc. All rights reserved.
FAU - Horgan, Rebecca
AU  - Horgan R
AD  - Division of Maternal-Fetal Medicine, Department of Obstetrics and Gynecology, 
      Eastern Virginia Medical School, Norfolk, VA.. Electronic address: 
      horganr@evms.edu.
FAU - Martins, Juliana G
AU  - Martins JG
AD  - Division of Maternal-Fetal Medicine, Department of Obstetrics and Gynecology, 
      Eastern Virginia Medical School, Norfolk, VA.
FAU - Saade, George
AU  - Saade G
AD  - Division of Maternal-Fetal Medicine, Department of Obstetrics and Gynecology, 
      Eastern Virginia Medical School, Norfolk, VA.
FAU - Abuhamad, Alfred
AU  - Abuhamad A
AD  - Division of Maternal-Fetal Medicine, Department of Obstetrics and Gynecology, 
      Eastern Virginia Medical School, Norfolk, VA.
FAU - Kawakita, Tetsuya
AU  - Kawakita T
AD  - Division of Maternal-Fetal Medicine, Department of Obstetrics and Gynecology, 
      Eastern Virginia Medical School, Norfolk, VA.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20240126
PL  - United States
TA  - Am J Obstet Gynecol MFM
JT  - American journal of obstetrics &amp; gynecology MFM
JID - 101746609
SB  - IM
MH  - Humans
MH  - *Perinatology
MH  - *Health Personnel
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - maternal-fetal medicine obstetrics
OT  - patient counseling
EDAT- 2024/01/29 00:42
MHDA- 2024/03/20 06:44
CRDT- 2024/01/28 19:12
PHST- 2023/10/04 00:00 [received]
PHST- 2024/01/02 00:00 [revised]
PHST- 2024/01/21 00:00 [accepted]
PHST- 2024/03/20 06:44 [medline]
PHST- 2024/01/29 00:42 [pubmed]
PHST- 2024/01/28 19:12 [entrez]
AID - S2589-9333(24)00028-4 [pii]
AID - 10.1016/j.ajogmf.2024.101302 [doi]
PST - ppublish
SO  - Am J Obstet Gynecol MFM. 2024 Mar;6(3):101302. doi: 10.1016/j.ajogmf.2024.101302. 
      Epub 2024 Jan 26.

PMID- 37755165
OWN - NLM
STAT- MEDLINE
DCOM- 20230928
LR  - 20231003
IS  - 2076-3271 (Electronic)
IS  - 2076-3271 (Linking)
VI  - 11
IP  - 3
DP  - 2023 Sep 17
TI  - A Bibliometric Analysis of the Rise of ChatGPT in Medical Research.
LID - 10.3390/medsci11030061 [doi]
LID - 61
AB  - The rapid emergence of publicly accessible artificial intelligence platforms such 
      as large language models (LLMs) has led to an equally rapid increase in articles 
      exploring their potential benefits and risks. We performed a bibliometric 
      analysis of ChatGPT literature in medicine and science to better understand 
      publication trends and knowledge gaps. Following title, abstract, and keyword 
      searches of PubMed, Embase, Scopus, and Web of Science databases for ChatGPT 
      articles published in the medical field, articles were screened for inclusion and 
      exclusion criteria. Data were extracted from included articles, with citation 
      counts obtained from PubMed and journal metrics obtained from Clarivate Journal 
      Citation Reports. After screening, 267 articles were included in the study, most 
      of which were editorials or correspondence with an average of 7.5 +/- 18.4 
      citations per publication. Published articles on ChatGPT were authored largely in 
      the United States, India, and China. The topics discussed included use and 
      accuracy of ChatGPT in research, medical education, and patient counseling. Among 
      non-surgical specialties, radiology published the most ChatGPT-related articles, 
      while plastic surgery published the most articles among surgical specialties. The 
      average citation number among the top 20 most-cited articles was 60.1 +/- 35.3. 
      Among journals with the most ChatGPT-related publications, there were on average 
      10 +/- 3.7 publications. Our results suggest that managing the inevitable ethical 
      and safety issues that arise with the implementation of LLMs will require further 
      research exploring the capabilities and accuracy of ChatGPT, to generate policies 
      guiding the adoption of artificial intelligence in medicine and science.
FAU - Barrington, Nikki M
AU  - Barrington NM
AD  - Chicago Medical School, Rosalind Franklin University, North Chicago, IL 60064, 
      USA.
FAU - Gupta, Nithin
AU  - Gupta N
AUID- ORCID: 0000-0002-6696-8984
AD  - School of Osteopathic Medicine, Campbell University, Lillington, NC 27546, USA.
FAU - Musmar, Basel
AU  - Musmar B
AD  - Faculty of Medicine and Health Sciences, An-Najah National University, Nablus 
      P.O. Box 7, West Bank, Palestine.
FAU - Doyle, David
AU  - Doyle D
AD  - Central Michigan College of Medicine, Mount Pleasant, MI 48858, USA.
FAU - Panico, Nicholas
AU  - Panico N
AD  - Lake Erie College of Osteopathic Medicine, Erie, PA 16509, USA.
FAU - Godbole, Nikhil
AU  - Godbole N
AUID- ORCID: 0009-0009-9417-2236
AD  - School of Medicine, Tulane University, New Orleans, LA 70112, USA.
FAU - Reardon, Taylor
AU  - Reardon T
AD  - Department of Neurology, Henry Ford Hospital, Detroit, MI 48202, USA.
FAU - D'Amico, Randy S
AU  - D'Amico RS
AD  - Department of Neurosurgery, Lenox Hill Hospital, New York, NY 10075, USA.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230917
PL  - Switzerland
TA  - Med Sci (Basel)
JT  - Medical sciences (Basel, Switzerland)
JID - 101629322
SB  - IM
MH  - Humans
MH  - Artificial Intelligence
MH  - Bibliometrics
MH  - *Biomedical Research
MH  - Benchmarking
MH  - *Radiology
PMC - PMC10535733
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - large language models
OT  - medicine
OT  - research
COIS- The authors declare no conflict of interest.
EDAT- 2023/09/27 12:42
MHDA- 2023/09/28 06:42
PMCR- 2023/09/17
CRDT- 2023/09/27 09:53
PHST- 2023/08/14 00:00 [received]
PHST- 2023/09/04 00:00 [revised]
PHST- 2023/09/11 00:00 [accepted]
PHST- 2023/09/28 06:42 [medline]
PHST- 2023/09/27 12:42 [pubmed]
PHST- 2023/09/27 09:53 [entrez]
PHST- 2023/09/17 00:00 [pmc-release]
AID - medsci11030061 [pii]
AID - medsci-11-00061 [pii]
AID - 10.3390/medsci11030061 [doi]
PST - epublish
SO  - Med Sci (Basel). 2023 Sep 17;11(3):61. doi: 10.3390/medsci11030061.

PMID- 37501022
OWN - NLM
STAT- Publisher
LR  - 20231021
IS  - 1432-1335 (Electronic)
IS  - 0171-5216 (Linking)
VI  - 149
IP  - 15
DP  - 2023 Nov
TI  - ChatGPT and oncological applications: comment.
PG  - 14463
LID - 10.1007/s00432-023-04891-z [doi]
AB  - This letter to editor discusses on the publication on large language models for 
      oncological applications. Pros and Cons for ChatGPT are discussed.
CI  - © 2023. The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, 
      part of Springer Nature.
FAU - Kleebayoon, Amnuay
AU  - Kleebayoon A
AD  - , Samraong, Cambodia. amnuaykleebai@gmail.com.
FAU - Wiwanitkit, Viroj
AU  - Wiwanitkit V
AD  - Chandigarh University, Punjab, India.
AD  - Joesph Ayobabalola University, Ikeji-Arakeji, Nigeria.
LA  - eng
PT  - Letter
DEP - 20230727
PL  - Germany
TA  - J Cancer Res Clin Oncol
JT  - Journal of cancer research and clinical oncology
JID - 7902060
SB  - IM
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - Oncology
EDAT- 2023/07/28 01:08
MHDA- 2023/07/28 01:08
CRDT- 2023/07/27 23:36
PHST- 2023/05/12 00:00 [received]
PHST- 2023/05/20 00:00 [accepted]
PHST- 2023/07/28 01:08 [pubmed]
PHST- 2023/07/28 01:08 [medline]
PHST- 2023/07/27 23:36 [entrez]
AID - 10.1007/s00432-023-04891-z [pii]
AID - 10.1007/s00432-023-04891-z [doi]
PST - ppublish
SO  - J Cancer Res Clin Oncol. 2023 Nov;149(15):14463. doi: 10.1007/s00432-023-04891-z. 
      Epub 2023 Jul 27.

PMID- 37334036
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230620
IS  - 2666-9145 (Electronic)
IS  - 2666-9145 (Linking)
VI  - 3
IP  - 4
DP  - 2023 Dec
TI  - Evaluating the Performance of ChatGPT in Ophthalmology: An Analysis of Its 
      Successes and Shortcomings.
PG  - 100324
LID - 10.1016/j.xops.2023.100324 [doi]
LID - 100324
AB  - PURPOSE: Foundation models are a novel type of artificial intelligence 
      algorithms, in which models are pretrained at scale on unannotated data and 
      fine-tuned for a myriad of downstream tasks, such as generating text. This study 
      assessed the accuracy of ChatGPT, a large language model (LLM), in the 
      ophthalmology question-answering space. DESIGN: Evaluation of diagnostic test or 
      technology. PARTICIPANTS: ChatGPT is a publicly available LLM. METHODS: We tested 
      2 versions of ChatGPT (January 9 "legacy" and ChatGPT Plus) on 2 popular multiple 
      choice question banks commonly used to prepare for the high-stakes Ophthalmic 
      Knowledge Assessment Program (OKAP) examination. We generated two 260-question 
      simulated exams from the Basic and Clinical Science Course (BCSC) Self-Assessment 
      Program and the OphthoQuestions online question bank. We carried out logistic 
      regression to determine the effect of the examination section, cognitive level, 
      and difficulty index on answer accuracy. We also performed a post hoc analysis 
      using Tukey's test to decide if there were meaningful differences between the 
      tested subspecialties. MAIN OUTCOME MEASURES: We reported the accuracy of ChatGPT 
      for each examination section in percentage correct by comparing ChatGPT's outputs 
      with the answer key provided by the question banks. We presented logistic 
      regression results with a likelihood ratio (LR) chi-square. We considered 
      differences between examination sections statistically significant at a P value 
      of &lt; 0.05. RESULTS: The legacy model achieved 55.8% accuracy on the BCSC set and 
      42.7% on the OphthoQuestions set. With ChatGPT Plus, accuracy increased to 59.4% 
      ± 0.6% and 49.2% ± 1.0%, respectively. Accuracy improved with easier questions 
      when controlling for the examination section and cognitive level. Logistic 
      regression analysis of the legacy model showed that the examination section (LR, 
      27.57; P&nbsp;= 0.006) followed by question difficulty (LR, 24.05; P &lt; 0.001) were 
      most predictive of ChatGPT's answer accuracy. Although the legacy model performed 
      best in general medicine and worst in neuro-ophthalmology (P &lt; 0.001) and ocular 
      pathology (P&nbsp;= 0.029), similar post hoc findings were not seen with ChatGPT Plus, 
      suggesting more consistent results across examination sections. CONCLUSION: 
      ChatGPT has encouraging performance on a simulated OKAP examination. Specializing 
      LLMs through domain-specific pretraining may be necessary to improve their 
      performance in ophthalmic subspecialties. FINANCIAL DISCLOSURES: Proprietary or 
      commercial disclosure may be found after the references.
CI  - © 2023 by the American Academy of Ophthalmology.
FAU - Antaki, Fares
AU  - Antaki F
AD  - Department of Ophthalmology, Université de Montréal, Montréal, Quebec, Canada.
AD  - Centre Universitaire d'Ophtalmologie (CUO), Hôpital Maisonneuve-Rosemont, CIUSSS 
      de l'Est-de-l'Île-de-Montréal, Montréal, Quebec, Canada.
AD  - Department of Ophthalmology, Centre Hospitalier de l'Université de Montréal 
      (CHUM), Montréal, Quebec, Canada.
AD  - The CHUM School of Artificial Intelligence in Healthcare (SAIH), Centre 
      Hospitalier de l'Université de Montréal (CHUM), Montréal, Quebec, Canada.
FAU - Touma, Samir
AU  - Touma S
AD  - Department of Ophthalmology, Université de Montréal, Montréal, Quebec, Canada.
AD  - Centre Universitaire d'Ophtalmologie (CUO), Hôpital Maisonneuve-Rosemont, CIUSSS 
      de l'Est-de-l'Île-de-Montréal, Montréal, Quebec, Canada.
AD  - Department of Ophthalmology, Centre Hospitalier de l'Université de Montréal 
      (CHUM), Montréal, Quebec, Canada.
FAU - Milad, Daniel
AU  - Milad D
AD  - Department of Ophthalmology, Université de Montréal, Montréal, Quebec, Canada.
AD  - Centre Universitaire d'Ophtalmologie (CUO), Hôpital Maisonneuve-Rosemont, CIUSSS 
      de l'Est-de-l'Île-de-Montréal, Montréal, Quebec, Canada.
AD  - Department of Ophthalmology, Centre Hospitalier de l'Université de Montréal 
      (CHUM), Montréal, Quebec, Canada.
FAU - El-Khoury, Jonathan
AU  - El-Khoury J
AD  - Department of Ophthalmology, Université de Montréal, Montréal, Quebec, Canada.
AD  - Centre Universitaire d'Ophtalmologie (CUO), Hôpital Maisonneuve-Rosemont, CIUSSS 
      de l'Est-de-l'Île-de-Montréal, Montréal, Quebec, Canada.
AD  - Department of Ophthalmology, Centre Hospitalier de l'Université de Montréal 
      (CHUM), Montréal, Quebec, Canada.
FAU - Duval, Renaud
AU  - Duval R
AD  - Department of Ophthalmology, Université de Montréal, Montréal, Quebec, Canada.
AD  - Centre Universitaire d'Ophtalmologie (CUO), Hôpital Maisonneuve-Rosemont, CIUSSS 
      de l'Est-de-l'Île-de-Montréal, Montréal, Quebec, Canada.
LA  - eng
PT  - Journal Article
DEP - 20230505
PL  - Netherlands
TA  - Ophthalmol Sci
JT  - Ophthalmology science
JID - 9918230896206676
PMC - PMC10272508
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Generative Pretrained Transformer
OT  - Medical education
OT  - Ophthalmology
EDAT- 2023/06/19 06:42
MHDA- 2023/06/19 06:43
PMCR- 2023/05/05
CRDT- 2023/06/19 03:00
PHST- 2023/02/03 00:00 [received]
PHST- 2023/04/21 00:00 [revised]
PHST- 2023/04/25 00:00 [accepted]
PHST- 2023/06/19 06:43 [medline]
PHST- 2023/06/19 06:42 [pubmed]
PHST- 2023/06/19 03:00 [entrez]
PHST- 2023/05/05 00:00 [pmc-release]
AID - S2666-9145(23)00056-8 [pii]
AID - 100324 [pii]
AID - 10.1016/j.xops.2023.100324 [doi]
PST - epublish
SO  - Ophthalmol Sci. 2023 May 5;3(4):100324. doi: 10.1016/j.xops.2023.100324. 
      eCollection 2023 Dec.

PMID- 37433676
OWN - NLM
STAT- MEDLINE
DCOM- 20230907
LR  - 20230907
IS  - 1535-5675 (Electronic)
IS  - 0091-4916 (Linking)
VI  - 51
IP  - 3
DP  - 2023 Sep
TI  - ChatGPT in Nuclear Medicine Education.
PG  - 247-254
LID - 10.2967/jnmt.123.265844 [doi]
AB  - Academic integrity has been challenged by artificial intelligence algorithms in 
      teaching institutions, including those providing nuclear medicine training. The 
      GPT 3.5-powered ChatGPT chatbot released in late November 2022 has emerged as an 
      immediate threat to academic and scientific writing. Methods: Both examinations 
      and written assignments for nuclear medicine courses were tested using ChatGPT. 
      Included was a mix of core theory subjects offered in the second and third years 
      of the nuclear medicine science course. Long-answer-style questions (8 subjects) 
      and calculation-style questions (2 subjects) were included for examinations. 
      ChatGPT was also used to produce responses to authentic writing tasks (6 
      subjects). ChatGPT responses were evaluated by Turnitin plagiarism-detection 
      software for similarity and artificial intelligence scores, scored against 
      standardized rubrics, and compared with the mean performance of student cohorts. 
      Results: ChatGPT powered by GPT 3.5 performed poorly in the 2 calculation 
      examinations (overall, 31.7% compared with 67.3% for students), with particularly 
      poor performance in complex-style questions. ChatGPT failed each of 6 written 
      tasks (overall, 38.9% compared with 67.2% for students), with worsening 
      performance corresponding to increasing writing and research expectations in the 
      third year. In the 8 examinations, ChatGPT performed better than students for 
      general or early subjects but poorly for advanced and specific subjects (overall, 
      51% compared with 57.4% for students). Conclusion: Although ChatGPT poses a risk 
      to academic integrity, its usefulness as a cheating tool can be constrained by 
      higher-order taxonomies. Unfortunately, the constraints to higher-order learning 
      and skill development also undermine potential applications of ChatGPT for 
      enhancing learning. There are several potential applications of ChatGPT for 
      teaching nuclear medicine students.
CI  - © 2023 by the Society of Nuclear Medicine and Molecular Imaging.
FAU - Currie, Geoffrey
AU  - Currie G
AD  - Charles Sturt University, Wagga Wagga, New South Wales, Australia; and 
      gcurrie@csu.edu.au.
FAU - Barry, Kym
AU  - Barry K
AD  - Charles Sturt University, Port Macquarie, New South Wales, Australia.
LA  - eng
PT  - Journal Article
DEP - 20230711
PL  - United States
TA  - J Nucl Med Technol
JT  - Journal of nuclear medicine technology
JID - 0430303
SB  - IM
MH  - Humans
MH  - *Nuclear Medicine
MH  - Artificial Intelligence
MH  - Radionuclide Imaging
MH  - Students
MH  - Learning
OTO - NOTNLM
OT  - academic integrity
OT  - artificial intelligence
OT  - generative AI
OT  - higher education
OT  - language model
OT  - tertiary education
EDAT- 2023/07/12 01:07
MHDA- 2023/09/07 06:42
CRDT- 2023/07/11 21:38
PHST- 2023/04/12 00:00 [received]
PHST- 2023/05/13 00:00 [revised]
PHST- 2023/09/07 06:42 [medline]
PHST- 2023/07/12 01:07 [pubmed]
PHST- 2023/07/11 21:38 [entrez]
AID - jnmt.123.265844 [pii]
AID - 10.2967/jnmt.123.265844 [doi]
PST - ppublish
SO  - J Nucl Med Technol. 2023 Sep;51(3):247-254. doi: 10.2967/jnmt.123.265844. Epub 
      2023 Jul 11.

PMID- 37814667
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231031
IS  - 1985-207X (Print)
IS  - 1985-2274 (Electronic)
IS  - 1985-2274 (Linking)
VI  - 18
DP  - 2023
TI  - Use of ChatGPT in medical research and scientific writing.
PG  - 58
LID - 10.51866/cm0006 [doi]
AB  - ChatGPT, an artificial intelligence (AI) language model based on the GPT-3.5 
      architecture, is revolutionising scientific writing and medical research. 
      Researchers employ ChatGPT for diverse tasks, including automated literature 
      reviews, structured-outline generation and drafting/editing assistance. The tool 
      adapts language for varied audiences, aids in citation management, supports 
      collaborative writing and peer review and facilitates table/figure creation. 
      While it enhances efficiency, concerns arise regarding ethics, bias, accuracy and 
      originality. Transparent data sourcing and validation are crucial, as ChatGPT 
      complements human efforts but does not replace critical thinking. Accordingly, 
      researchers must uphold integrity, ensuring that AI-assisted content aligns with 
      research principles. Acknowledgement of AI use in manuscripts, as recommended by 
      the International Committee of Medical Journal Editors, ensures accountability. 
      ChatGPT's transformative potential lies in harmonising its capabilities with 
      researchers' expertise, fostering a symbiotic relationship that advances 
      scientific progress and ethical standards.
CI  - © Academy of Family Physicians of Malaysia.
FAU - Lee, Ping Yein
AU  - Lee PY
AD  - MBBS, DrFamMed, UM eHealth Unit, Faculty of Medicine, Universiti Malaya, Kuala 
      Lumpur, Malaysia. Email: pylee02@gmail.com.
FAU - Salim, Hani
AU  - Salim H
AD  - MBBChBAO, MFamMed, PhD, Department of Family Medicine, Universiti Putra Malaysia, 
      Seri Kembangan, Selangor, Malaysia.
FAU - Abdullah, Adina
AU  - Abdullah A
AD  - MBBS, MFamMed, PhD, Department of Primary Care Medicine, Faculty of Medicine, 
      Universiti, Malaya, Kuala Lumpur, Malaysia.
FAU - Teo, Chin Hai
AU  - Teo CH
AD  - BMedImag, PhD, Department of Primary Care Medicine, Faculty of Medicine, 
      Universiti, Malaya, Kuala Lumpur, Malaysia.
AD  - UM eHealth Unit, Faculty of Medicine, Universiti Malaya, Kuala Lumpur, Malaysia.
LA  - eng
PT  - Editorial
DEP - 20230925
PL  - Malaysia
TA  - Malays Fam Physician
JT  - Malaysian family physician : the official journal of the Academy of Family 
      Physicians of Malaysia
JID - 101466855
PMC - PMC10560470
OTO - NOTNLM
OT  - Artificial intelligence (AI)
OT  - ChatGPT
OT  - Medical research
OT  - Scientific writing
COIS- All authors declare no conflicts of interest.
EDAT- 2023/10/10 06:41
MHDA- 2023/10/10 06:42
PMCR- 2023/09/25
CRDT- 2023/10/10 03:38
PHST- 2023/10/10 06:42 [medline]
PHST- 2023/10/10 06:41 [pubmed]
PHST- 2023/10/10 03:38 [entrez]
PHST- 2023/09/25 00:00 [pmc-release]
AID - 10.51866/cm0006 [doi]
PST - epublish
SO  - Malays Fam Physician. 2023 Sep 25;18:58. doi: 10.51866/cm0006. eCollection 2023.

PMID- 38358925
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20240219
LR  - 20240318
IS  - 0743-6661 (Print)
IS  - 0743-6661 (Linking)
VI  - 50
IP  - 2
DP  - 2023 Jul 1
TI  - ChatGPT: How Closely Should We Be Watching?
PG  - 143-146
LID - 10.17849/insm-50-2-143-146.1 [doi]
AB  - ChatGPT is about to make major inroads into clinical medicine. This article 
      discusses the pros and cons of its use.
CI  - Copyright © 2024 Journal of Insurance Medicine.
FAU - Meagher, Timothy
AU  - Meagher T
AD  - Address of Correspondent: Munich Re, 1000 Rue de la Gauchetière Ouest, 20e étage, 
      Montréal Québec, H3B 4W5; 514-392-5069; tmeagher@munichre.ca.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - J Insur Med
JT  - Journal of insurance medicine (New York, N.Y.)
JID - 8401468
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - clinical medicine
OT  - foundation models
OT  - risk selection
OT  - technology
EDAT- 2024/02/15 18:42
MHDA- 2024/02/19 06:43
CRDT- 2024/02/15 13:02
PHST- 2024/02/19 06:43 [medline]
PHST- 2024/02/15 18:42 [pubmed]
PHST- 2024/02/15 13:02 [entrez]
AID - 499013 [pii]
AID - 10.17849/insm-50-2-143-146.1 [doi]
PST - ppublish
SO  - J Insur Med. 2023 Jul 1;50(2):143-146. doi: 10.17849/insm-50-2-143-146.1.

PMID- 37200013
OWN - NLM
STAT- MEDLINE
DCOM- 20230522
LR  - 20230525
IS  - 2689-0186 (Electronic)
IS  - 2689-0186 (Linking)
VI  - 4
IP  - 5
DP  - 2023 May 5
TI  - ChatGPT and Physicians' Malpractice Risk.
PG  - e231938
LID - 10.1001/jamahealthforum.2023.1938 [doi]
FAU - Mello, Michelle M
AU  - Mello MM
AD  - Stanford Law School, Stanford, California.
AD  - Department of Health Policy, Stanford University School of Medicine, Stanford, 
      California.
FAU - Guha, Neel
AU  - Guha N
AD  - Stanford Law School, Stanford, California.
AD  - Department of Computer Science, Stanford University, Stanford, California.
LA  - eng
PT  - Journal Article
DEP - 20230505
PL  - United States
TA  - JAMA Health Forum
JT  - JAMA health forum
JID - 101769500
SB  - IM
MH  - Humans
MH  - *Malpractice
MH  - *Physicians
OAB - This JAMA Forum discusses the possibilities, limitations, and risks of physician 
      use of large language models (such as ChatGPT) along with the improvements 
      required to improve the accuracy of the technology.
OABL- eng
EDAT- 2023/05/18 13:09
MHDA- 2023/05/22 06:41
CRDT- 2023/05/18 11:33
PHST- 2023/05/22 06:41 [medline]
PHST- 2023/05/18 13:09 [pubmed]
PHST- 2023/05/18 11:33 [entrez]
AID - 2805334 [pii]
AID - 10.1001/jamahealthforum.2023.1938 [doi]
PST - epublish
SO  - JAMA Health Forum. 2023 May 5;4(5):e231938. doi: 
      10.1001/jamahealthforum.2023.1938.

PMID- 37166289
OWN - NLM
STAT- MEDLINE
DCOM- 20230515
LR  - 20230830
IS  - 1537-2677 (Electronic)
IS  - 0740-9303 (Print)
IS  - 0740-9303 (Linking)
VI  - 39
IP  - 3
DP  - 2023 May-Jun 01
TI  - ChatGPT and Lacrimal Drainage Disorders: Performance and Scope of Improvement.
PG  - 221-225
LID - 10.1097/IOP.0000000000002418 [doi]
AB  - PURPOSE: This study aimed to report the performance of the large language model 
      ChatGPT (OpenAI, San Francisco, CA, U.S.A.) in the context of lacrimal drainage 
      disorders. METHODS: A set of prompts was constructed through questions and 
      statements spanning common and uncommon aspects of lacrimal drainage disorders. 
      Care was taken to avoid constructing prompts that had significant or new 
      knowledge beyond the year 2020. Each of the prompts was presented thrice to 
      ChatGPT. The questions covered common disorders such as primary acquired 
      nasolacrimal duct obstruction and congenital nasolacrimal duct obstruction and 
      their cause and management. The prompts also tested ChatGPT on certain specifics, 
      such as the history of dacryocystorhinostomy (DCR) surgery, lacrimal pump 
      anatomy, and human canalicular surfactants. ChatGPT was also quizzed on 
      controversial topics such as silicone intubation and the use of mitomycin C in 
      DCR surgery. The responses of ChatGPT were carefully analyzed for evidence-based 
      content, specificity of the response, presence of generic text, disclaimers, 
      factual inaccuracies, and its abilities to admit mistakes and challenge incorrect 
      premises. Three lacrimal surgeons graded the responses into three categories: 
      correct, partially correct, and factually incorrect. RESULTS: A total of 21 
      prompts were presented to the ChatGPT. The responses were detailed and were based 
      according to the prompt structure. In response to most questions, ChatGPT 
      provided a generic disclaimer that it could not give medical advice or 
      professional opinion but then provided an answer to the question in detail. 
      Specific prompts such as "how can I perform an external DCR?" were responded by a 
      sequential listing of all the surgical steps. However, several factual 
      inaccuracies were noted across many ChatGPT replies. Several responses on 
      controversial topics such as silicone intubation and mitomycin C were generic and 
      not precisely evidence-based. ChatGPT's response to specific questions such as 
      canalicular surfactants and idiopathic canalicular inflammatory disease was poor. 
      The presentation of variable prompts on a single topic led to responses with 
      either repetition or recycling of the phrases. Citations were uniformly missing 
      across all responses. Agreement among the three observers was high (95%) in 
      grading the responses. The responses of ChatGPT were graded as correct for only 
      40% of the prompts, partially correct in 35%, and outright factually incorrect in 
      25%. Hence, some degree of factual inaccuracy was present in 60% of the 
      responses, if we consider the partially correct responses. The exciting aspect 
      was that ChatGPT was able to admit mistakes and correct them when presented with 
      counterarguments. It was also capable of challenging incorrect prompts and 
      premises. CONCLUSION: The performance of ChatGPT in the context of lacrimal 
      drainage disorders, at best, can be termed average. However, the potential of 
      this AI chatbot to influence medicine is enormous. There is a need for it to be 
      specifically trained and retrained for individual medical subspecialties.
CI  - Copyright © 2023 The Author(s). Published by Wolters Kluwer Health, Inc. on 
      behalf of the American Society of Ophthalmic Plastic and Reconstructive Surgery, 
      Inc.
FAU - Ali, Mohammad Javed
AU  - Ali MJ
AD  - Govindram Seksaria Institute of Dacryology, L.V. Prasad Eye Institute, Hyderabad, 
      India.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20230510
PL  - United States
TA  - Ophthalmic Plast Reconstr Surg
JT  - Ophthalmic plastic and reconstructive surgery
JID - 8508431
RN  - 50SG953SK6 (Mitomycin)
RN  - 0 (Silicones)
SB  - IM
CIN - Ophthalmic Plast Reconstr Surg. 2023 May-Jun 01;39(3):203-205. PMID: 37166288
MH  - Humans
MH  - *Dacryocystorhinostomy/methods
MH  - *Lacrimal Duct Obstruction/diagnosis/therapy
MH  - *Nasolacrimal Duct/surgery
MH  - Mitomycin
MH  - Intubation
MH  - Silicones
PMC - PMC10171282
COIS- The author has no financial or conflicts of interest to disclose.
EDAT- 2023/05/11 13:18
MHDA- 2023/05/15 06:42
PMCR- 2023/05/10
CRDT- 2023/05/11 09:53
PHST- 2023/05/15 06:42 [medline]
PHST- 2023/05/11 13:18 [pubmed]
PHST- 2023/05/11 09:53 [entrez]
PHST- 2023/05/10 00:00 [pmc-release]
AID - 00002341-202305000-00004 [pii]
AID - 10.1097/IOP.0000000000002418 [doi]
PST - ppublish
SO  - Ophthalmic Plast Reconstr Surg. 2023 May-Jun 01;39(3):221-225. doi: 
      10.1097/IOP.0000000000002418. Epub 2023 May 10.

PMID- 37680954
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230909
IS  - 2624-909X (Electronic)
IS  - 2624-909X (Linking)
VI  - 6
DP  - 2023
TI  - Universal skepticism of ChatGPT: a review of early literature on chat generative 
      pre-trained transformer.
PG  - 1224976
LID - 10.3389/fdata.2023.1224976 [doi]
LID - 1224976
AB  - ChatGPT, a new language model developed by OpenAI, has garnered significant 
      attention in various fields since its release. This literature review provides an 
      overview of early ChatGPT literature across multiple disciplines, exploring its 
      applications, limitations, and ethical considerations. The review encompasses 
      Scopus-indexed publications from November 2022 to April 2023 and includes 156 
      articles related to ChatGPT. The findings reveal a predominance of negative 
      sentiment across disciplines, though subject-specific attitudes must be 
      considered. The review highlights the implications of ChatGPT in many fields 
      including healthcare, raising concerns about employment opportunities and ethical 
      considerations. While ChatGPT holds promise for improved communication, further 
      research is needed to address its capabilities and limitations. This literature 
      review provides insights into early research on ChatGPT, informing future 
      investigations and practical applications of chatbot technology, as well as 
      development and usage of generative AI.
CI  - Copyright © 2023 Watters and Lemanski.
FAU - Watters, Casey
AU  - Watters C
AD  - Faculty of Law, Bond University, Gold Coast, QLD, Australia.
FAU - Lemanski, Michal K
AU  - Lemanski MK
AD  - Institute for Human Resource Management, WU Vienna, Vienna, Austria.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230823
PL  - Switzerland
TA  - Front Big Data
JT  - Frontiers in big data
JID - 101770603
PMC - PMC10482048
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - GPT
OT  - artificial intelligence
OT  - disruptive technology
OT  - large language model (LLM)
OT  - transformer
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/09/08 06:43
MHDA- 2023/09/08 06:44
PMCR- 2023/08/23
CRDT- 2023/09/08 04:09
PHST- 2023/05/18 00:00 [received]
PHST- 2023/07/10 00:00 [accepted]
PHST- 2023/09/08 06:44 [medline]
PHST- 2023/09/08 06:43 [pubmed]
PHST- 2023/09/08 04:09 [entrez]
PHST- 2023/08/23 00:00 [pmc-release]
AID - 10.3389/fdata.2023.1224976 [doi]
PST - epublish
SO  - Front Big Data. 2023 Aug 23;6:1224976. doi: 10.3389/fdata.2023.1224976. 
      eCollection 2023.

PMID- 37731429
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230922
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 8
DP  - 2023 Aug
TI  - ChatGPT: A Supplemental Tool for Efficiency and Improved Communication in Rural 
      Dermatology.
PG  - e43812
LID - 10.7759/cureus.43812 [doi]
LID - e43812
AB  - In November 2022, OpenAI released version 3.5 of ChatGPT, the first publicly 
      available artificial intelligence (AI) language model designed to engage in 
      natural, human-like dialogue with users. While this groundbreaking technology has 
      been extensively studied in various domains, its potential applications in rural 
      dermatology remain unexplored in the existing literature. Our research 
      investigates the many benefits that ChatGPT could offer in rural dermatology, 
      particularly concerning administrative tasks and communication with communities 
      with lower healthcare literacy. However, we also acknowledge that utilizing 
      ChatGPT without proper caution and discernment may lead to potential drawbacks. 
      This paper examines the opportunities and challenges associated with integrating 
      ChatGPT into rural dermatology practices, ultimately fostering a well-informed 
      and responsible approach to its implementation.
CI  - Copyright © 2023, Baker et al.
FAU - Baker, Mindy N
AU  - Baker MN
AD  - Dermatology, University of Kentucky College of Medicine, Lexington, USA.
FAU - Burruss, Clayton P
AU  - Burruss CP
AD  - Dermatology, University of Kentucky College of Medicine, Lexington, USA.
FAU - Wilson, Chase L
AU  - Wilson CL
AD  - Dermatology, Elkhorn Dermatology, Georgetown, USA.
LA  - eng
PT  - Editorial
DEP - 20230820
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10508964
OTO - NOTNLM
OT  - artificial intelligence
OT  - language models
OT  - machine learning
OT  - quality of care
OT  - rural dermatology
OT  - rural healthcare access
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/09/21 06:42
MHDA- 2023/09/21 06:43
PMCR- 2023/08/20
CRDT- 2023/09/21 03:54
PHST- 2023/08/20 00:00 [accepted]
PHST- 2023/09/21 06:43 [medline]
PHST- 2023/09/21 06:42 [pubmed]
PHST- 2023/09/21 03:54 [entrez]
PHST- 2023/08/20 00:00 [pmc-release]
AID - 10.7759/cureus.43812 [doi]
PST - epublish
SO  - Cureus. 2023 Aug 20;15(8):e43812. doi: 10.7759/cureus.43812. eCollection 2023 
      Aug.

PMID- 38200693
OWN - NLM
STAT- MEDLINE
DCOM- 20240301
LR  - 20240301
IS  - 1471-1842 (Electronic)
IS  - 1471-1834 (Linking)
VI  - 41
IP  - 1
DP  - 2024 Mar
TI  - ChatGPT in medical libraries, possibilities and future directions: An integrative 
      review.
PG  - 4-15
LID - 10.1111/hir.12518 [doi]
AB  - BACKGROUND: The emergence of the artificial intelligence chatbot ChatGPT in 
      November 2022 has garnered substantial attention across diverse disciplines. 
      Despite widespread adoption in various sectors, the exploration of its 
      application in libraries, especially within the medical domain, remains limited. 
      AIMS/OBJECTIVES: Many areas of interest remain unexplored like ChatGPT in medical 
      libraries and this review aims to synthesise what is currently known about it to 
      identify gaps and stimulate further research. METHODS: Employing Cooper's 
      integrative review method, this study involves a comprehensive analysis of 
      existing literature on ChatGPT and its potential implementations within library 
      contexts. RESULTS: A systematic literature search across various databases 
      yielded 166 papers, with 30 excluded for irrelevance. After abstract reviews and 
      methodological assessments, 136 articles were selected. Critical Appraisal Skills 
      Programme qualitative checklist further narrowed down to 29 papers, forming the 
      basis for the present study. The literature analysis reveals diverse applications 
      of ChatGPT in medical libraries, including aiding users in finding relevant 
      medical information, answering queries, providing recommendations and 
      facilitating access to resources. Potential challenges and ethical considerations 
      associated with ChatGPT in this context are also highlighted. CONCLUSION: 
      Positioned as a review, our study elucidates the applications of ChatGPT in 
      medical libraries and discusses relevant considerations. The integration of 
      ChatGPT into medical library services holds promise for enhancing information 
      retrieval and user experience, benefiting library users and the broader medical 
      community.
CI  - © 2024 Health Libraries Group.
FAU - Lund, Brady D
AU  - Lund BD
AUID- ORCID: 0000-0002-4819-8162
AD  - Department of Information Science, University of North Texas, Denton, Texas, USA.
FAU - Khan, Daud
AU  - Khan D
AUID- ORCID: 0000-0003-1204-2235
AD  - Maulana Azad Library, Aligarh Muslim University, Aligarh, India.
FAU - Yuvaraj, Mayank
AU  - Yuvaraj M
AUID- ORCID: 0000-0002-4754-9151
AD  - Rajarshi Janak Central Library, Central University of South Bihar, Gaya, India.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20240110
PL  - England
TA  - Health Info Libr J
JT  - Health information and libraries journal
JID - 100970070
MH  - Humans
MH  - Artificial Intelligence
MH  - Databases, Factual
MH  - Information Storage and Retrieval
MH  - *Libraries, Medical
MH  - *Library Services
OTO - NOTNLM
OT  - artificial intelligence (AI)
OT  - libraries
OT  - literature
OT  - medical
OT  - review
EDAT- 2024/01/11 07:43
MHDA- 2024/03/01 06:43
CRDT- 2024/01/11 00:33
PHST- 2023/12/12 00:00 [revised]
PHST- 2023/07/04 00:00 [received]
PHST- 2023/12/19 00:00 [accepted]
PHST- 2024/03/01 06:43 [medline]
PHST- 2024/01/11 07:43 [pubmed]
PHST- 2024/01/11 00:33 [entrez]
AID - 10.1111/hir.12518 [doi]
PST - ppublish
SO  - Health Info Libr J. 2024 Mar;41(1):4-15. doi: 10.1111/hir.12518. Epub 2024 Jan 
      10.

PMID- 37162695
OWN - NLM
STAT- MEDLINE
DCOM- 20231010
LR  - 20231010
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 51
IP  - 9
DP  - 2023 Sep
TI  - ChatGPT in Colorectal Surgery: A Promising Tool or a Passing Fad?
PG  - 1892-1897
LID - 10.1007/s10439-023-03232-y [doi]
AB  - Colorectal surgery is a specialized branch of surgery that involves the diagnosis 
      and treatment of conditions affecting the colon, rectum, and anus. In the recent 
      years, the use of artificial intelligence (AI) has gained considerable interest 
      in various medical specialties, including surgery. Chatbot Generative Pre-Trained 
      Transformer (ChatGPT), an AI-based chatbot developed by OpenAI, has shown great 
      potential in improving the quality of healthcare delivery by providing accurate 
      and timely information to both patients and healthcare professionals. In this 
      paper, we investigate the potential application of ChatGPT in colorectal surgery. 
      We also discuss the potential advantages and challenges associated with the 
      implementation of ChatGPT in the surgical setting. Furthermore, we address the 
      socio-ethical implications of utilizing ChatGPT in healthcare. This includes 
      concerns over patient privacy, liability, and the potential impact on the 
      doctor-patient relationship. Our findings suggest that ChatGPT has the potential 
      to revolutionize the field of colorectal surgery by providing personalized and 
      precise medical information, reducing errors and complications, and improving 
      patient outcomes.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Li, Wenbo
AU  - Li W
AD  - Department of Nursing, Jinzhou Medical University, Jinzhou, China.
FAU - Zhang, Yinxu
AU  - Zhang Y
AD  - Department of Colorectal Surgery, The First Affiliated Hospital, Jinzhou Medical 
      University, Jinzhou, 121001, China.
FAU - Chen, Fengmin
AU  - Chen F
AUID- ORCID: 0009-0003-6118-1554
AD  - Department of Colorectal Surgery, The First Affiliated Hospital, Jinzhou Medical 
      University, Jinzhou, 121001, China. 314307031@qq.com.
LA  - eng
PT  - Letter
DEP - 20230510
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - Humans
MH  - *Colorectal Surgery/education/trends
MH  - *Artificial Intelligence
MH  - Physician-Patient Relations
MH  - Software
MH  - Clinical Decision-Making
MH  - Postoperative Care
MH  - Privacy
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Chatbot
OT  - Colorectal surgery
EDAT- 2023/05/10 12:42
MHDA- 2023/08/09 06:43
CRDT- 2023/05/10 11:14
PHST- 2023/05/02 00:00 [received]
PHST- 2023/05/03 00:00 [accepted]
PHST- 2023/08/09 06:43 [medline]
PHST- 2023/05/10 12:42 [pubmed]
PHST- 2023/05/10 11:14 [entrez]
AID - 10.1007/s10439-023-03232-y [pii]
AID - 10.1007/s10439-023-03232-y [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2023 Sep;51(9):1892-1897. doi: 10.1007/s10439-023-03232-y. Epub 
      2023 May 10.

PMID- 38182139
OWN - NLM
STAT- MEDLINE
DCOM- 20240108
LR  - 20240108
IS  - 1550-8080 (Electronic)
IS  - 0091-7370 (Linking)
VI  - 53
IP  - 6
DP  - 2023 Nov
TI  - ChatGPT-Exploring Its Role in Clinical Chemistry.
PG  - 835-839
AB  - OBJECTIVE: To evaluate the utility of artificial intelligence-powered language 
      models (ChatGPT 3.5 and GPT-4) compared to trainees and clinical chemists in 
      responding to common laboratory questions in the broad area of Clinical 
      Chemistry. METHODS: 35 questions from real-life case scenarios, clinical 
      consultations, and clinical chemistry testing questions were used to evaluate 
      ChatGPT 3.5, and GPT-4 alongside clinical chemistry trainees (residents/fellows) 
      and clinical chemistry faculty. The responses were scored based on category and 
      based on years of experience. RESULTS: The Senior Chemistry Faculty demonstrated 
      superior accuracy with 100% of correct responses compared to 90.5%, 82.9%, and 
      71.4% of correct responses from the junior chemistry faculty, fellows, and 
      residents respectively. They all outperformed both ChatGPT 3.5 and GPT-4 which 
      generated 60% and 71.4% correct responses respectively. Of the sub-categories 
      examined, ChatGPT 3.5 achieved 100% accuracy in endocrinology while GPT-4 did not 
      achieve 100% accuracy in any subcategory. GPT-4 was overall better than ChatGPT 
      3.5 by generating similar correct responses as residents (71.4%) but performed 
      poorly to human participants when both partially correct and incorrect indices 
      were considered. CONCLUSION: Despite all the advances in AI-powered language 
      models, ChatGPT 3.5 and GPT-4 cannot replace a trained pathologist in answering 
      clinical chemistry questions. Caution should be observed by people, especially 
      those not trained in clinical chemistry, to interpret test results using 
      chatbots.
CI  - © 2023 by the Association of Clinical Scientists, Inc.
FAU - Ibrahim, Ridwan B
AU  - Ibrahim RB
AD  - Department of Pathology and Immunology, Baylor College of Medicine, Houston, TX, 
      USA.
AD  - Department of Pathology, Texas Children's Hospital, Houston, TX, USA.
FAU - Chokkalla, Anil K
AU  - Chokkalla AK
AD  - Department of Pathology and Immunology, Baylor College of Medicine, Houston, TX, 
      USA.
AD  - Department of Pathology, Texas Children's Hospital, Houston, TX, USA.
FAU - Levett, Kaitlyn
AU  - Levett K
AD  - Department of Pathology and Immunology, Baylor College of Medicine, Houston, TX, 
      USA.
FAU - Gustafson, David
AU  - Gustafson D
AD  - Department of Pathology and Immunology, Baylor College of Medicine, Houston, TX, 
      USA.
FAU - Olayinka, Lily
AU  - Olayinka L
AD  - Alberta Precision Laboratories, Edmonton, Canada.
FAU - Kumar, Sneha
AU  - Kumar S
AD  - Department of Pathology and Immunology, Baylor College of Medicine, Houston, TX, 
      USA.
FAU - Devaraj, Sridevi
AU  - Devaraj S
AD  - Department of Pathology and Immunology, Baylor College of Medicine, Houston, TX, 
      USA sxdevara@texaschildrens.org.
AD  - Department of Pathology, Texas Children's Hospital, Houston, TX, USA.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Ann Clin Lab Sci
JT  - Annals of clinical and laboratory science
JID - 0410247
SB  - IM
MH  - Humans
MH  - *Chemistry, Clinical
MH  - *Artificial Intelligence
MH  - Laboratories
MH  - Pathologists
EDAT- 2024/01/06 10:42
MHDA- 2024/01/08 06:43
CRDT- 2024/01/05 20:32
PHST- 2024/01/08 06:43 [medline]
PHST- 2024/01/06 10:42 [pubmed]
PHST- 2024/01/05 20:32 [entrez]
AID - 53/6/835 [pii]
PST - ppublish
SO  - Ann Clin Lab Sci. 2023 Nov;53(6):835-839.

PMID- 38462064
OWN - NLM
STAT- MEDLINE
DCOM- 20240319
LR  - 20240319
IS  - 1532-0480 (Electronic)
IS  - 1532-0464 (Linking)
VI  - 151
DP  - 2024 Mar
TI  - Evaluation of ChatGPT-generated medical responses: A systematic review and 
      meta-analysis.
PG  - 104620
LID - S1532-0464(24)00038-8 [pii]
LID - 10.1016/j.jbi.2024.104620 [doi]
AB  - OBJECTIVE: Large language models (LLMs) such as ChatGPT are increasingly explored 
      in medical domains. However, the absence of standard guidelines for performance 
      evaluation has led to methodological inconsistencies. This study aims to 
      summarize the available evidence on evaluating ChatGPT's performance in answering 
      medical questions and provide direction for future research. METHODS: An 
      extensive literature search was conducted on June 15, 2023, across ten medical 
      databases. The keyword used was "ChatGPT," without restrictions on publication 
      type, language, or date. Studies evaluating ChatGPT's performance in answering 
      medical questions were included. Exclusions comprised review articles, comments, 
      patents, non-medical evaluations of ChatGPT, and preprint studies. Data was 
      extracted on general study characteristics, question sources, conversation 
      processes, assessment metrics, and performance of ChatGPT. An evaluation 
      framework for LLM in medical inquiries was proposed by integrating insights from 
      selected literature. This study is registered with PROSPERO, CRD42023456327. 
      RESULTS: A total of 3520 articles were identified, of which 60 were reviewed and 
      summarized in this paper and 17 were included in the meta-analysis. ChatGPT 
      displayed an overall integrated accuracy of 56&nbsp;% (95&nbsp;% CI: 51&nbsp;%-60&nbsp;%, 
      I(2)&nbsp;=&nbsp;87&nbsp;%) in addressing medical queries. However, the studies varied in 
      question resource, question-asking process, and evaluation metrics. As per our 
      proposed evaluation framework, many studies failed to report methodological 
      details, such as the date of inquiry, version of ChatGPT, and inter-rater 
      consistency. CONCLUSION: This review reveals ChatGPT's potential in addressing 
      medical inquiries, but the heterogeneity of the study design and insufficient 
      reporting might affect the results' reliability. Our proposed evaluation 
      framework provides insights for the future study design and transparent reporting 
      of LLM in responding to medical questions.
CI  - Copyright © 2024 Elsevier Inc. All rights reserved.
FAU - Wei, Qiuhong
AU  - Wei Q
AD  - Big Data Center for Children's Medical Care, Children's Hospital of Chongqing 
      Medical University, Chongqing, China; Children Nutrition Research Center, 
      Children's Hospital of Chongqing Medical University, Chongqing, China; National 
      Clinical Research Center for Child Health and Disorders, Ministry of Education 
      Key Laboratory of Child Development and Disorders, China International Science 
      and Technology Cooperation Base of Child Development and Critical Disorders, 
      Chongqing Key Laboratory of Child Neurodevelopment and Cognitive Disorders, 
      Chongqing, China.
FAU - Yao, Zhengxiong
AU  - Yao Z
AD  - Department of Neurology, Children's Hospital of Chongqing Medical University, 
      Chongqing, China.
FAU - Cui, Ying
AU  - Cui Y
AD  - Department of Biomedical Data Science, Stanford University School of Medicine, 
      Stanford, CA, USA.
FAU - Wei, Bo
AU  - Wei B
AD  - Department of Global Statistics and Data Science, BeiGene USA Inc., San Mateo, 
      CA, USA.
FAU - Jin, Zhezhen
AU  - Jin Z
AD  - Department of Biostatistics, Mailman School of Public Health, Columbia 
      University, New York, NY, USA.
FAU - Xu, Ximing
AU  - Xu X
AD  - Big Data Center for Children's Medical Care, Children's Hospital of Chongqing 
      Medical University, Chongqing, China.
LA  - eng
PT  - Journal Article
PT  - Meta-Analysis
PT  - Review
PT  - Systematic Review
DEP - 20240308
PL  - United States
TA  - J Biomed Inform
JT  - Journal of biomedical informatics
JID - 100970413
SB  - IM
MH  - Reproducibility of Results
MH  - *Benchmarking
MH  - *Biomedical Research
MH  - Communication
MH  - Databases, Factual
OTO - NOTNLM
OT  - ChatGPT
OT  - Evaluation
OT  - Large language model
OT  - Medicine
COIS- Declaration of competing interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2024/03/11 00:42
MHDA- 2024/03/19 06:43
CRDT- 2024/03/10 20:16
PHST- 2023/11/23 00:00 [received]
PHST- 2024/02/27 00:00 [revised]
PHST- 2024/02/29 00:00 [accepted]
PHST- 2024/03/19 06:43 [medline]
PHST- 2024/03/11 00:42 [pubmed]
PHST- 2024/03/10 20:16 [entrez]
AID - S1532-0464(24)00038-8 [pii]
AID - 10.1016/j.jbi.2024.104620 [doi]
PST - ppublish
SO  - J Biomed Inform. 2024 Mar;151:104620. doi: 10.1016/j.jbi.2024.104620. Epub 2024 
      Mar 8.

PMID- 37271011
OWN - NLM
STAT- MEDLINE
DCOM- 20230628
LR  - 20230816
IS  - 1532-2831 (Electronic)
IS  - 1078-8174 (Linking)
VI  - 29
IP  - 4
DP  - 2023 Jul
TI  - ChatGPT in medical imaging higher education.
PG  - 792-799
LID - S1078-8174(23)00117-7 [pii]
LID - 10.1016/j.radi.2023.05.011 [doi]
AB  - INTRODUCTION: Academic integrity among radiographers and nuclear medicine 
      technologists/scientists in both higher education and scientific writing has been 
      challenged by advances in artificial intelligence (AI). The recent release of 
      ChatGPT, a chatbot powered by GPT-3.5 capable of producing accurate and 
      human-like responses to questions in real-time, has redefined the boundaries of 
      academic and scientific writing. These boundaries require objective evaluation. 
      METHOD: ChatGPT was tested against six subjects across the first three years of 
      the medical radiation science undergraduate course for both exams (n&nbsp;=&nbsp;6) and 
      written assignment tasks (n&nbsp;=&nbsp;3). ChatGPT submissions were marked against 
      standardised rubrics and results compared to student cohorts. Submissions were 
      also evaluated by Turnitin for similarity and AI scores. RESULTS: ChatGPT powered 
      by GPT-3.5 performed below the average student performance in all written tasks 
      with an increasing disparity as subjects advanced. ChatGPT performed better than 
      the average student in foundation or general subject examinations where shallow 
      responses meet learning outcomes. For discipline specific subjects, ChatGPT 
      lacked the depth, breadth, and currency of insight to provide pass level answers. 
      CONCLUSION: ChatGPT simultaneously poses a risk to academic integrity in writing 
      and assessment while affording a tool for enhanced learning environments. These 
      risks and benefits are likely to be restricted to learning outcomes of lower 
      taxonomies. Both risks and benefits are likely to be constrained by higher order 
      taxonomies. IMPLICATIONS FOR PRACTICE: ChatGPT powered by GPT3.5 has limited 
      capacity to support student cheating, introduces errors and fabricated 
      information, and is readily identified by software as AI generated. Lack of depth 
      of insight and appropriateness for professional communication also limits 
      capacity as a learning enhancement tool.
CI  - Copyright © 2023 The College of Radiographers. Published by Elsevier Ltd. All 
      rights reserved.
FAU - Currie, G
AU  - Currie G
AD  - Charles Sturt University, Wagga Wagga, NSW, Australia. Electronic address: 
      gcurrie@csu.edu.au.
FAU - Singh, C
AU  - Singh C
AD  - Charles Sturt University, Wagga Wagga, NSW, Australia.
FAU - Nelson, T
AU  - Nelson T
AD  - Charles Sturt University, Port Macquarie, NSW, Australia.
FAU - Nabasenja, C
AU  - Nabasenja C
AD  - Charles Sturt University, Port Macquarie, NSW, Australia.
FAU - Al-Hayek, Y
AU  - Al-Hayek Y
AD  - Charles Sturt University, Wagga Wagga, NSW, Australia.
FAU - Spuur, K
AU  - Spuur K
AD  - Charles Sturt University, Wagga Wagga, NSW, Australia.
LA  - eng
PT  - Journal Article
DEP - 20230602
PL  - Netherlands
TA  - Radiography (Lond)
JT  - Radiography (London, England : 1995)
JID - 9604102
SB  - IM
CIN - Radiography (Lond). 2023 Aug;29(5):867. PMID: 37413958
CIN - Radiography (Lond). 2023 Aug;29(5):868-869. PMID: 37419046
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Diagnostic Imaging
MH  - Radiography
MH  - Learning
MH  - Software
OTO - NOTNLM
OT  - Academic integrity
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Generative algorithms
OT  - Higher education
OT  - Language model
COIS- Conflict of interest statement None.
EDAT- 2023/06/05 00:41
MHDA- 2023/06/28 06:42
CRDT- 2023/06/04 18:06
PHST- 2023/04/13 00:00 [received]
PHST- 2023/05/17 00:00 [revised]
PHST- 2023/05/17 00:00 [accepted]
PHST- 2023/06/28 06:42 [medline]
PHST- 2023/06/05 00:41 [pubmed]
PHST- 2023/06/04 18:06 [entrez]
AID - S1078-8174(23)00117-7 [pii]
AID - 10.1016/j.radi.2023.05.011 [doi]
PST - ppublish
SO  - Radiography (Lond). 2023 Jul;29(4):792-799. doi: 10.1016/j.radi.2023.05.011. Epub 
      2023 Jun 2.

PMID- 37933339
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231108
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 10
DP  - 2023 Oct
TI  - A Conversation With ChatGPT About the Usage of Lithium in Pregnancy for Bipolar 
      Disorder.
PG  - e46548
LID - 10.7759/cureus.46548 [doi]
LID - e46548
AB  - This conversation with ChatGPT explores the use of lithium in pregnancy for 
      bipolar disorder, a topic of significant importance in psychiatry. Bipolar 
      disorder is characterized by extreme mood swings, and its prevalence varies 
      globally. ChatGPT provides valuable information on bipolar disorder, its 
      prevalence, age of onset, and gender differences. It also discusses the use of 
      lithium during pregnancy, emphasizing the need for individualized decisions, 
      close monitoring, and potential risks and benefits. However, it is essential to 
      note that ChatGPT's responses lack specific references, raising concerns about 
      the reliability of the information provided. Further research is needed to 
      quantify the correctness and dependability of ChatGPT-generated answers in the 
      healthcare context.
CI  - Copyright © 2023, Randhawa et al.
FAU - Randhawa, Jaismeen
AU  - Randhawa J
AD  - Psychiatry, Sri Guru Ram Das Institute of Medical Sciences and Research, 
      Amritsar, IND.
FAU - Khan, Aadil
AU  - Khan A
AD  - Trauma Surgery, OSF Saint Francis Medical Center, University of Illinois Chicago, 
      Peoria, USA.
AD  - Cardiology, University of Illinois Chicago, Illinois, USA.
AD  - Internal Medicine, Lala Lajpat Rai Hospital, Kanpur, IND.
LA  - eng
PT  - Editorial
DEP - 20231005
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10625495
OTO - NOTNLM
OT  - artificial intelligence (ai)
OT  - bipolar disorder
OT  - chat generative pre-trained transformer (chatgpt)
OT  - lithium
OT  - pregnancy
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/11/07 06:45
MHDA- 2023/11/07 06:46
PMCR- 2023/10/05
CRDT- 2023/11/07 03:49
PHST- 2023/10/05 00:00 [accepted]
PHST- 2023/11/07 06:46 [medline]
PHST- 2023/11/07 06:45 [pubmed]
PHST- 2023/11/07 03:49 [entrez]
PHST- 2023/10/05 00:00 [pmc-release]
AID - 10.7759/cureus.46548 [doi]
PST - epublish
SO  - Cureus. 2023 Oct 5;15(10):e46548. doi: 10.7759/cureus.46548. eCollection 2023 
      Oct.

PMID- 37093625
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230511
IS  - 2373-6658 (Electronic)
IS  - 2373-6658 (Linking)
VI  - 7
DP  - 2023 Apr 24
TI  - Impact of ChatGPT on Interdisciplinary Nursing Education and Research.
PG  - e48136
LID - 10.2196/48136 [doi]
LID - e48136
AB  - ChatGPT, a trending artificial intelligence tool developed by OpenAI, was 
      launched in November 2022. The impact of ChatGPT on the nursing and 
      interdisciplinary research ecosystem is profound.
CI  - ©Hongyu Miao, Hyochol Ahn. Originally published in the Asian/Pacific Island 
      Nursing Journal (https://apinj.jmir.org), 24.04.2023.
FAU - Miao, Hongyu
AU  - Miao H
AUID- ORCID: 0000-0002-4131-3164
AD  - Florida State University, Tallahassee, FL, United States.
FAU - Ahn, Hyochol
AU  - Ahn H
AUID- ORCID: 0000-0002-9998-4876
AD  - Florida State University, Tallahassee, FL, United States.
LA  - eng
PT  - Editorial
DEP - 20230424
PL  - Canada
TA  - Asian Pac Isl Nurs J
JT  - Asian/Pacific Island nursing journal
JID - 101699697
PMC - PMC10167576
OTO - NOTNLM
OT  - ChatGPT
OT  - OpenAI
OT  - artificial intelligence
OT  - nursing education
OT  - nursing research
COIS- Conflicts of Interest: None declared.
EDAT- 2023/04/24 12:42
MHDA- 2023/04/24 12:43
PMCR- 2023/04/24
CRDT- 2023/04/24 11:52
PHST- 2023/04/12 00:00 [received]
PHST- 2023/04/14 00:00 [accepted]
PHST- 2023/04/24 12:43 [medline]
PHST- 2023/04/24 12:42 [pubmed]
PHST- 2023/04/24 11:52 [entrez]
PHST- 2023/04/24 00:00 [pmc-release]
AID - v7i1e48136 [pii]
AID - 10.2196/48136 [doi]
PST - epublish
SO  - Asian Pac Isl Nurs J. 2023 Apr 24;7:e48136. doi: 10.2196/48136.

PMID- 37549050
OWN - NLM
STAT- MEDLINE
DCOM- 20230809
LR  - 20230809
IS  - 1943-281X (Electronic)
IS  - 0033-2747 (Linking)
VI  - 86
IP  - 3
DP  - 2023 Fall
TI  - ChatGPT: "To Be or Not to Be" in Bikini Bottom.
PG  - 249-254
LID - 10.1080/00332747.2023.2238617 [doi]
AB  - Objective: In this report, we tested ChatGPT's ability to think abstractly and to 
      integrate information about two seemingly disparate topics by requesting a 
      well-articulated, intellectually stimulating essay in response to a complex and 
      somewhat paradoxical task. Method: We asked ChatGPT to write a satirical essay 
      comparing SpongeBob Squarepants to Shakespeare's Hamlet and examined its ability 
      to create a cohesive essay using abstract thinking. Findings: ChatGPT's 
      comparison of Hamlet and SpongeBob was successful, comprehensive, and convincing, 
      demonstrating the ability to make judgments and to use appropriate metaphors and 
      idioms. Conclusions: Our findings suggest that ChatGPT can respond to complex 
      tasks using abstract thinking.
FAU - Weingrad, Aaron B
AU  - Weingrad AB
FAU - Cozza, Stephen J
AU  - Cozza SJ
AUID- ORCID: 0000-0001-9597-2758
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Psychiatry
JT  - Psychiatry
JID - 0376470
SB  - IM
MH  - Humans
MH  - *Cognition
MH  - *Writing
MH  - *Artificial Intelligence
EDAT- 2023/08/07 19:10
MHDA- 2023/08/09 06:43
CRDT- 2023/08/07 12:52
PHST- 2023/08/09 06:43 [medline]
PHST- 2023/08/07 19:10 [pubmed]
PHST- 2023/08/07 12:52 [entrez]
AID - 10.1080/00332747.2023.2238617 [doi]
PST - ppublish
SO  - Psychiatry. 2023 Fall;86(3):249-254. doi: 10.1080/00332747.2023.2238617.

PMID- 37526801
OWN - NLM
STAT- Publisher
LR  - 20230801
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
DP  - 2023 Aug 1
TI  - Role of ChatGPT-4 for Medical Researchers.
LID - 10.1007/s10439-023-03336-5 [doi]
AB  - The robustness of artificial intelligence (AI) in medical research has gotten a 
      lot of attention in the current era. In particular, ChatGPT-4 is emerging as a 
      notable AI language model. Basically, ChatGPT-4 is a state-of-the-art language 
      model that mimics human responses to natural language inputs using AI-based deep 
      learning methods and was created by OpenAI. ChatGPT-4 allows medical researchers 
      to instantly share and receive up-to-date information on best practices and 
      guidelines. Moreover, practitioners can explore this technology in various fields 
      such as recognizing patterns, predicting outcomes, and providing important 
      insights by entering patient data, medical reports, and other text-based 
      information. No doubt, ChatGPT-4 is in the trending era but still need to know 
      more about this tool. Therefore, this letter highlights the contributions, 
      benefits, and challenges of the ChatGPT-4 tool in the medical field that may help 
      medical professionals or researchers in their future work.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Datt, Mohit
AU  - Datt M
AUID- ORCID: 0000-0001-8586-426X
AD  - Department of Industrial and Production Engineering, Dr. B. R. Ambedkar National 
      Institute of Technology, Jalandhar, India. mohitdatt1991@gmail.com.
FAU - Sharma, Himanshu
AU  - Sharma H
AD  - Department of Civil Engineering, Dr. B. R. Ambedkar National Institute of 
      Technology, Jalandhar, India.
FAU - Aggarwal, Nikita
AU  - Aggarwal N
AD  - Department of Electronics and Communication Engineering, Dr. B. R. Ambedkar 
      National Institute of Technology, Jalandhar, India.
FAU - Sharma, Shivani
AU  - Sharma S
AD  - Department of Electronics and Communication Engineering, Dr. B. R. Ambedkar 
      National Institute of Technology, Jalandhar, India.
LA  - eng
PT  - Letter
DEP - 20230801
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
OTO - NOTNLM
OT  - ChatGPT-4
OT  - Medical researchers
OT  - NLP
OT  - Open artificial intelligence
EDAT- 2023/08/01 13:09
MHDA- 2023/08/01 13:09
CRDT- 2023/08/01 11:10
PHST- 2023/07/25 00:00 [received]
PHST- 2023/07/27 00:00 [accepted]
PHST- 2023/08/01 13:09 [medline]
PHST- 2023/08/01 13:09 [pubmed]
PHST- 2023/08/01 11:10 [entrez]
AID - 10.1007/s10439-023-03336-5 [pii]
AID - 10.1007/s10439-023-03336-5 [doi]
PST - aheadofprint
SO  - Ann Biomed Eng. 2023 Aug 1. doi: 10.1007/s10439-023-03336-5.

PMID- 37485160
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230725
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 6
DP  - 2023 Jun
TI  - Eyes on AI: ChatGPT's Transformative Potential Impact on Ophthalmology.
PG  - e40765
LID - 10.7759/cureus.40765 [doi]
LID - e40765
AB  - ChatGPT, a large language model by OpenAI, has been adopted in various domains 
      since its release in November 2022, but its application in ophthalmology remains 
      less explored. This editorial assesses ChatGPT's potential applications and 
      limitations in ophthalmology across clinical, educational, and research settings. 
      In clinical settings, ChatGPT can serve as an assistant, offering diagnostic and 
      therapeutic suggestions based on patient data and assisting in patient triage. 
      However, its tendencies to generate inaccurate results and its inability to keep 
      up with recent medical guidelines render it unsuitable for standalone clinical 
      decision-making.&nbsp;Data security and compliance with the Health Insurance 
      Portability and Accountability Act (HIPAA) also pose concerns, given ChatGPT's 
      potential to inadvertently expose sensitive patient information. In education, 
      ChatGPT can generate practice questions, provide explanations, and create patient 
      education materials. However, its performance in answering domain-specific 
      questions is suboptimal. In research, ChatGPT can facilitate literature reviews, 
      data analysis, manuscript development, and peer review, but issues of accuracy, 
      bias, and ethics need careful consideration. Ultimately, ensuring accuracy, 
      ethical integrity, and data privacy is essential when integrating ChatGPT into 
      ophthalmology.
CI  - Copyright © 2023, Dossantos et al.
FAU - Dossantos, Jason
AU  - Dossantos J
AD  - Ophthalmology, George Washington University School of Medicine and Health 
      Sciences, Washington, USA.
FAU - An, Jella
AU  - An J
AD  - Ophthalmology, Johns Hopkins University School of Medicine Wilmer Eye Institute, 
      Baltimore, USA.
FAU - Javan, Ramin
AU  - Javan R
AD  - Radiology, George Washington University School of Medicine and Health Sciences, 
      Washington, USA.
LA  - eng
PT  - Editorial
DEP - 20230621
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10362525
OTO - NOTNLM
OT  - artificial intelligence
OT  - artificial intelligence in medicine
OT  - chatgpt
OT  - large language models
OT  - ophthalmology
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/07/24 06:42
MHDA- 2023/07/24 06:43
PMCR- 2023/06/21
CRDT- 2023/07/24 04:54
PHST- 2023/06/21 00:00 [accepted]
PHST- 2023/07/24 06:43 [medline]
PHST- 2023/07/24 06:42 [pubmed]
PHST- 2023/07/24 04:54 [entrez]
PHST- 2023/06/21 00:00 [pmc-release]
AID - 10.7759/cureus.40765 [doi]
PST - epublish
SO  - Cureus. 2023 Jun 21;15(6):e40765. doi: 10.7759/cureus.40765. eCollection 2023 
      Jun.

PMID- 37024502
OWN - NLM
STAT- MEDLINE
DCOM- 20230410
LR  - 20230417
IS  - 2045-2322 (Electronic)
IS  - 2045-2322 (Linking)
VI  - 13
IP  - 1
DP  - 2023 Apr 6
TI  - ChatGPT's inconsistent moral advice influences users' judgment.
PG  - 4569
LID - 10.1038/s41598-023-31341-0 [doi]
LID - 4569
AB  - ChatGPT is not only fun to chat with, but it also searches information, answers 
      questions, and gives advice. With consistent moral advice, it can improve the 
      moral judgment and decisions of users. Unfortunately, ChatGPT's advice is not 
      consistent. Nonetheless, it does influence users' moral judgment, we find in an 
      experiment, even if they know they are advised by a chatting bot, and they 
      underestimate how much they are influenced. Thus, ChatGPT corrupts rather than 
      improves its users' moral judgment. While these findings call for better design 
      of ChatGPT and similar bots, we also propose training to improve users' digital 
      literacy as a remedy. Transparency, however, is not sufficient to enable the 
      responsible use of AI.
CI  - © 2023. The Author(s).
FAU - Krügel, Sebastian
AU  - Krügel S
AD  - Faculty of Computer Science, Technische Hochschule Ingolstadt, Esplanade 10, 
      85049, Ingolstadt, Germany. sebastian.kruegel@thi.de.
FAU - Ostermaier, Andreas
AU  - Ostermaier A
AD  - Department of Business and Management, University of Southern Denmark, Campusvej 
      55, 5230, Odense, Denmark.
FAU - Uhl, Matthias
AU  - Uhl M
AD  - Faculty of Computer Science, Technische Hochschule Ingolstadt, Esplanade 10, 
      85049, Ingolstadt, Germany.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20230406
PL  - England
TA  - Sci Rep
JT  - Scientific reports
JID - 101563288
RN  - EC 2.3.1.6 (Choline O-Acetyltransferase)
SB  - IM
MH  - *Judgment
MH  - *Morals
MH  - Software
MH  - Literacy
MH  - Choline O-Acetyltransferase
PMC - PMC10079665
COIS- The authors declare no competing interests.
EDAT- 2023/04/07 06:00
MHDA- 2023/04/10 06:42
PMCR- 2023/04/06
CRDT- 2023/04/06 23:16
PHST- 2023/01/20 00:00 [received]
PHST- 2023/03/10 00:00 [accepted]
PHST- 2023/04/10 06:42 [medline]
PHST- 2023/04/06 23:16 [entrez]
PHST- 2023/04/07 06:00 [pubmed]
PHST- 2023/04/06 00:00 [pmc-release]
AID - 10.1038/s41598-023-31341-0 [pii]
AID - 31341 [pii]
AID - 10.1038/s41598-023-31341-0 [doi]
PST - epublish
SO  - Sci Rep. 2023 Apr 6;13(1):4569. doi: 10.1038/s41598-023-31341-0.

PMID- 38230387
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240118
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 16
IP  - 1
DP  - 2024 Jan
TI  - Utilizing ChatGPT in Telepharmacy.
PG  - e52365
LID - 10.7759/cureus.52365 [doi]
LID - e52365
AB  - BACKGROUND: ChatGPT is an artificial intelligence-powered chatbot that has 
      demonstrated capabilities in numerous fields, including medical and healthcare 
      sciences. This study evaluates the potential for ChatGPT application in 
      telepharmacy, the delivering of pharmaceutical care via means of 
      telecommunications, through assessing its interactions, adherence to 
      instructions, and ability to role-play as a pharmacist while handling a series of 
      life-like scenario questions. METHODS: Two versions (ChatGPT 3.5 and 4.0, OpenAI) 
      were assessed using two independent trials each. ChatGPT was instructed to act as 
      a pharmacist and answer patient inquiries, followed by a set of 20 assessment 
      questions. Then, ChatGPT was instructed to stop its act, provide feedback and 
      list its sources for drug information. The responses to the assessment questions 
      were evaluated in terms of accuracy, precision and clarity using a 4-point 
      Likert-like scale. RESULTS: ChatGPT demonstrated the ability to follow detailed 
      instructions, role-play as a pharmacist, and appropriately handle all questions. 
      ChatGPT was able to understand case details, recognize generic and brand drug 
      names, identify drug side effects, interactions, prescription requirements and 
      precautions, and provide proper point-by-point instructions regarding 
      administration, dosing, storage and disposal. The overall means of pooled scores 
      were 3.425 (0.712) and 3.7 (0.61) for ChatGPT 3.5 and 4.0, respectively. The rank 
      distribution of scores was not significantly different (P&gt;0.05). None of the 
      answers could be considered directly harmful or labeled as entirely or mostly 
      incorrect, and most point deductions were due to other factors such as 
      indecisiveness, adding immaterial information, missing certain considerations, or 
      partial unclarity. The answers were similar in length across trials and 
      appropriately concise. ChatGPT 4.0 showed superior performance, higher 
      consistency, better character adherence and the ability to report various 
      reliable information sources. However, it only allowed an input of 40 questions 
      every three hours and provided inaccurate feedback regarding the number of 
      assessed patients, compared to 3.5 which allowed unlimited input but was unable 
      to provide feedback. CONCLUSIONS: Integrating ChatGPT in telepharmacy holds 
      promising potential; however, a number of drawbacks are to be overcome in order 
      to function effectively.
CI  - Copyright © 2024, Bazzari et al.
FAU - Bazzari, Firas H
AU  - Bazzari FH
AD  - Pharmacy, Jerash University, Jerash, JOR.
FAU - Bazzari, Amjad H
AU  - Bazzari AH
AD  - Basic Scientific Sciences, Applied Science Private University, Amman, JOR.
LA  - eng
PT  - Journal Article
DEP - 20240116
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10790595
OTO - NOTNLM
OT  - artificial intelligence
OT  - chatgpt
OT  - digital health
OT  - pharmacology
OT  - pharmacy practice
OT  - remote pharmacy
OT  - technology
COIS- The authors have declared that no competing interests exist.
EDAT- 2024/01/17 06:43
MHDA- 2024/01/17 06:44
PMCR- 2024/01/16
CRDT- 2024/01/17 03:55
PHST- 2024/01/15 00:00 [accepted]
PHST- 2024/01/17 06:44 [medline]
PHST- 2024/01/17 06:43 [pubmed]
PHST- 2024/01/17 03:55 [entrez]
PHST- 2024/01/16 00:00 [pmc-release]
AID - 10.7759/cureus.52365 [doi]
PST - epublish
SO  - Cureus. 2024 Jan 16;16(1):e52365. doi: 10.7759/cureus.52365. eCollection 2024 
      Jan.

PMID- 37034742
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230905
DP  - 2023 Mar 29
TI  - Performance of ChatGPT on free-response, clinical reasoning exams.
LID - 2023.03.24.23287731 [pii]
LID - 10.1101/2023.03.24.23287731 [doi]
AB  - IMPORTANCE: Studies show that ChatGPT, a general purpose large language model 
      chatbot, could pass the multiple-choice US Medical Licensing Exams, but the 
      model's performance on open-ended clinical reasoning is unknown. OBJECTIVE: To 
      determine if ChatGPT is capable of consistently meeting the passing threshold on 
      free-response, case-based clinical reasoning assessments. DESIGN: Fourteen 
      multi-part cases were selected from clinical reasoning exams administered to 
      pre-clerkship medical students between 2019 and 2022. For each case, the 
      questions were run through ChatGPT twice and responses were recorded. Two 
      clinician educators independently graded each run according to a standardized 
      grading rubric. To further assess the degree of variation in ChatGPT's 
      performance, we repeated the analysis on a single high-complexity case 20 times. 
      SETTING: A single US medical school. PARTICIPANTS: ChatGPT. MAIN OUTCOMES AND 
      MEASURES: Passing rate of ChatGPT's scored responses and the range in model 
      performance across multiple run throughs of a single case. RESULTS: 12 out of the 
      28 ChatGPT exam responses achieved a passing score (43%) with a mean score of 69% 
      (95% CI: 65% to 73%) compared to the established passing threshold of 70%. When 
      given the same case 20 separate times, ChatGPT's performance on that case varied 
      with scores ranging from 56% to 81%. CONCLUSIONS AND RELEVANCE: ChatGPT's ability 
      to achieve a passing performance in nearly half of the cases analyzed 
      demonstrates the need to revise clinical reasoning assessments and incorporate 
      artificial intelligence (AI)-related topics into medical curricula and practice.
FAU - Strong, Eric
AU  - Strong E
FAU - DiGiammarino, Alicia
AU  - DiGiammarino A
FAU - Weng, Yingjie
AU  - Weng Y
FAU - Basaviah, Preetha
AU  - Basaviah P
FAU - Hosamani, Poonam
AU  - Hosamani P
FAU - Kumar, Andre
AU  - Kumar A
FAU - Nevins, Andrew
AU  - Nevins A
FAU - Kugler, John
AU  - Kugler J
FAU - Hom, Jason
AU  - Hom J
FAU - Chen, Jonathan H
AU  - Chen JH
LA  - eng
PT  - Preprint
DEP - 20230329
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
UIN - JAMA Intern Med. 2023 Jul 17;:. PMID: 37459090
PMC - PMC10081420
EDAT- 2023/04/11 06:00
MHDA- 2023/04/11 06:01
PMCR- 2023/04/07
CRDT- 2023/04/10 04:12
PHST- 2023/04/11 06:01 [medline]
PHST- 2023/04/10 04:12 [entrez]
PHST- 2023/04/11 06:00 [pubmed]
PHST- 2023/04/07 00:00 [pmc-release]
AID - 2023.03.24.23287731 [pii]
AID - 10.1101/2023.03.24.23287731 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2023 Mar 29:2023.03.24.23287731. doi: 
      10.1101/2023.03.24.23287731.

PMID- 38138908
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231225
IS  - 2075-4426 (Print)
IS  - 2075-4426 (Electronic)
IS  - 2075-4426 (Linking)
VI  - 13
IP  - 12
DP  - 2023 Dec 4
TI  - Innovating Personalized Nephrology Care: Exploring the Potential Utilization of 
      ChatGPT.
LID - 10.3390/jpm13121681 [doi]
LID - 1681
AB  - The rapid advancement of artificial intelligence (AI) technologies, particularly 
      machine learning, has brought substantial progress to the field of nephrology, 
      enabling significant improvements in the management of kidney diseases. ChatGPT, 
      a revolutionary language model developed by OpenAI, is a versatile AI model 
      designed to engage in meaningful and informative conversations. Its applications 
      in healthcare have been notable, with demonstrated proficiency in various medical 
      knowledge assessments. However, ChatGPT's performance varies across different 
      medical subfields, posing challenges in nephrology-related queries. At present, 
      comprehensive reviews regarding ChatGPT's potential applications in nephrology 
      remain lacking despite the surge of interest in its role in various domains. This 
      article seeks to fill this gap by presenting an overview of the integration of 
      ChatGPT in nephrology. It discusses the potential benefits of ChatGPT in 
      nephrology, encompassing dataset management, diagnostics, treatment planning, and 
      patient communication and education, as well as medical research and education. 
      It also explores ethical and legal concerns regarding the utilization of AI in 
      medical practice. The continuous development of AI models like ChatGPT holds 
      promise for the healthcare realm but also underscores the necessity of thorough 
      evaluation and validation before implementing AI in real-world medical scenarios. 
      This review serves as a valuable resource for nephrologists and healthcare 
      professionals interested in fully utilizing the potential of AI in innovating 
      personalized nephrology care.
FAU - Miao, Jing
AU  - Miao J
AUID- ORCID: 0000-0003-0642-9740
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
FAU - Thongprayoon, Charat
AU  - Thongprayoon C
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
FAU - Suppadungsuk, Supawadee
AU  - Suppadungsuk S
AUID- ORCID: 0000-0003-1597-2411
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
AD  - Chakri Naruebodindra Medical Institute, Faculty of Medicine Ramathibodi Hospital, 
      Mahidol University, Samut Prakan 10540, Thailand.
FAU - Garcia Valencia, Oscar A
AU  - Garcia Valencia OA
AUID- ORCID: 0000-0003-0186-9448
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
FAU - Qureshi, Fawad
AU  - Qureshi F
AUID- ORCID: 0000-0003-3387-4882
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
FAU - Cheungpasitporn, Wisit
AU  - Cheungpasitporn W
AUID- ORCID: 0000-0001-9954-9711
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20231204
PL  - Switzerland
TA  - J Pers Med
JT  - Journal of personalized medicine
JID - 101602269
PMC - PMC10744377
OTO - NOTNLM
OT  - ChatGPT
OT  - application
OT  - artificial intelligence
OT  - chatbot
OT  - kidney disease
OT  - nephrology
COIS- The authors declare no conflict of interest.
EDAT- 2023/12/23 12:44
MHDA- 2023/12/23 12:45
PMCR- 2023/12/04
CRDT- 2023/12/23 01:19
PHST- 2023/11/01 00:00 [received]
PHST- 2023/12/02 00:00 [revised]
PHST- 2023/12/02 00:00 [accepted]
PHST- 2023/12/23 12:45 [medline]
PHST- 2023/12/23 12:44 [pubmed]
PHST- 2023/12/23 01:19 [entrez]
PHST- 2023/12/04 00:00 [pmc-release]
AID - jpm13121681 [pii]
AID - jpm-13-01681 [pii]
AID - 10.3390/jpm13121681 [doi]
PST - epublish
SO  - J Pers Med. 2023 Dec 4;13(12):1681. doi: 10.3390/jpm13121681.

PMID- 37781591
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240210
DP  - 2023 Sep 14
TI  - ChatGPT Assisting Diagnosis of Neuro-ophthalmology Diseases Based on Case 
      Reports.
LID - 2023.09.13.23295508 [pii]
LID - 10.1101/2023.09.13.23295508 [doi]
AB  - PURPOSE: To evaluate the efficiency of large language models (LLMs) including 
      ChatGPT to assist in diagnosing neuro-ophthalmic diseases based on case reports. 
      DESIGN: Prospective study. SUBJECTS OR PARTICIPANTS: We selected 22 different 
      case reports of neuro-ophthalmic diseases from a publicly available online 
      database. These cases included a wide range of chronic and acute diseases that 
      are commonly seen by neuro-ophthalmic sub-specialists. METHODS: We inserted the 
      text from each case as a new prompt into both ChatGPT v3.5 and ChatGPT Plus v4.0 
      and asked for the most probable diagnosis. We then presented the exact 
      information to two neuro-ophthalmologists and recorded their diagnoses followed 
      by comparison to responses from both versions of ChatGPT. MAIN OUTCOME MEASURES: 
      Diagnostic accuracy in terms of number of correctly diagnosed cases among 
      diagnoses. RESULTS: ChatGPT v3.5, ChatGPT Plus v4.0, and the two 
      neuro-ophthalmologists were correct in 13 (59%), 18 (82%), 19 (86%), and 19 (86%) 
      out of 22 cases, respectively. The agreement between the various diagnostic 
      sources were as follows: ChatGPT v3.5 and ChatGPT Plus v4.0, 13 (59%); ChatGPT 
      v3.5 and the first neuro-ophthalmologist, 12 (55%); ChatGPT v3.5 and the second 
      neuro-ophthalmologist, 12 (55%); ChatGPT Plus v4.0 and the first 
      neuro-ophthalmologist, 17 (77%); ChatGPT Plus v4.0 and the second 
      neuro-ophthalmologist, 16 (73%); and first and second neuro-ophthalmologists 17 
      (17%). CONCLUSIONS: The accuracy of ChatGPT v3.5 and ChatGPT Plus v4.0 in 
      diagnosing patients with neuro-ophthalmic diseases was 59% and 82%, respectively. 
      With further development, ChatGPT Plus v4.0 may have potential to be used in 
      clinical care settings to assist clinicians in providing quick, accurate 
      diagnoses of patients in neuro-ophthalmology. The applicability of using LLMs 
      like ChatGPT in clinical settings that lack access to subspeciality trained 
      neuro-ophthalmologists deserves further research.
FAU - Madadi, Yeganeh
AU  - Madadi Y
AD  - Department of Ophthalmology, University of Tennessee Health Science Center, 
      Memphis, TN, USA.
FAU - Delsoz, Mohammad
AU  - Delsoz M
AD  - Department of Ophthalmology, University of Tennessee Health Science Center, 
      Memphis, TN, USA.
FAU - Lao, Priscilla A
AU  - Lao PA
AD  - Department of Ophthalmology, University of Tennessee Health Science Center, 
      Memphis, TN, USA.
FAU - Fong, Joseph W
AU  - Fong JW
AD  - Department of Ophthalmology, University of Tennessee Health Science Center, 
      Memphis, TN, USA.
FAU - Hollingsworth, T J
AU  - Hollingsworth TJ
AD  - Department of Ophthalmology, University of Tennessee Health Science Center, 
      Memphis, TN, USA.
FAU - Kahook, Malik Y
AU  - Kahook MY
AD  - Department of Ophthalmology, University of Colorado School of Medicine, Aurora, 
      CO, USA.
FAU - Yousefi, Siamak
AU  - Yousefi S
AD  - Department of Ophthalmology, University of Tennessee Health Science Center, 
      Memphis, TN, USA.
AD  - Department of Genetics, Genomics, and Informatics, University of Tennessee Health 
      Science Center, Memphis, TN, USA.
LA  - eng
GR  - R01 EY033005/EY/NEI NIH HHS/United States
GR  - R21 EY031725/EY/NEI NIH HHS/United States
PT  - Preprint
DEP - 20230914
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
PMC - PMC10540811
OTO - NOTNLM
OT  - Artificial Intelligence (AI)
OT  - ChatGPT
OT  - Diagnosis
OT  - Large Language Models (LLM)
OT  - Neuro-Ophthalmology
COIS- Conflicts of interest/Competing interests: Authors declare no relevant conflict 
      of interest(s) to disclose.
EDAT- 2023/10/02 06:42
MHDA- 2023/10/02 06:43
PMCR- 2023/09/29
CRDT- 2023/10/02 04:48
PHST- 2023/10/02 06:42 [pubmed]
PHST- 2023/10/02 06:43 [medline]
PHST- 2023/10/02 04:48 [entrez]
PHST- 2023/09/29 00:00 [pmc-release]
AID - 2023.09.13.23295508 [pii]
AID - 10.1101/2023.09.13.23295508 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2023 Sep 14:2023.09.13.23295508. doi: 
      10.1101/2023.09.13.23295508.

PMID- 38107211
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231219
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 12
DP  - 2023 Dec
TI  - ChatGPT Performance in Diagnostic Clinical Microbiology Laboratory-Oriented Case 
      Scenarios.
PG  - e50629
LID - 10.7759/cureus.50629 [doi]
LID - e50629
AB  - BACKGROUND: Artificial intelligence (AI)-based tools can reshape healthcare 
      practice. This includes ChatGPT which is considered among the most popular 
      AI-based conversational models. Nevertheless, the performance of different 
      versions of ChatGPT needs further evaluation in different settings to assess its 
      reliability and credibility in various healthcare-related tasks. Therefore, the 
      current study aimed to assess the performance of the freely available ChatGPT-3.5 
      and the paid version ChatGPT-4 in 10 different diagnostic clinical microbiology 
      case scenarios. METHODS: The current study followed the METRICS (Model, 
      Evaluation, Timing/Transparency, Range/Randomization, Individual factors, Count, 
      Specificity of the prompts/language) checklist for standardization of the design 
      and reporting of AI-based studies in healthcare. The models tested on December 3, 
      2023 included ChatGPT-3.5 and ChatGPT-4 and the evaluation of the 
      ChatGPT-generated content was based on the CLEAR tool (Completeness, Lack of 
      false information, Evidence support, Appropriateness, and Relevance) assessed on 
      a 5-point Likert scale with a range of the CLEAR scores of 1-5. ChatGPT output 
      was evaluated by two raters independently and the inter-rater agreement was based 
      on the Cohen's κ statistic. Ten diagnostic clinical microbiology laboratory case 
      scenarios were created in the English language by three microbiologists at 
      diverse levels of expertise following an internal discussion of common cases 
      observed in Jordan. The range of topics included bacteriology, mycology, 
      parasitology, and virology cases. Specific prompts were tailored based on the 
      CLEAR tool and a new session was selected following prompting each case scenario. 
      RESULTS: The Cohen's κ values for the five CLEAR items were 0.351-0.737 for 
      ChatGPT-3.5 and 0.294-0.701 for ChatGPT-4 indicating fair to good agreement and 
      suitability for analysis. Based on the average CLEAR scores, ChatGPT-4 
      outperformed ChatGPT-3.5 (mean: 2.64±1.06 vs. 3.21±1.05,&nbsp;P=.012, t-test). The 
      performance of each model varied based on the CLEAR items, with the lowest 
      performance for the "Relevance" item (2.15±0.71 for ChatGPT-3.5 and 2.65±1.16 for 
      ChatGPT-4). A statistically significant difference upon assessing the performance 
      per each CLEAR item was only seen in ChatGPT-4 with the best performance in 
      "Completeness", "Lack of false information", and "Evidence support" (P=0.043). 
      The lowest level of performance for both models was observed with antimicrobial 
      susceptibility testing (AST) queries while the highest level of performance was 
      seen in bacterial and mycologic identification. CONCLUSIONS: Assessment of 
      ChatGPT performance across different diagnostic clinical microbiology case 
      scenarios showed that ChatGPT-4 outperformed ChatGPT-3.5. The performance of 
      ChatGPT demonstrated noticeable variability depending on the specific topic 
      evaluated. A primary shortcoming of both ChatGPT models was the tendency to 
      generate irrelevant content lacking the needed focus. Although the overall 
      ChatGPT performance in these diagnostic microbiology case scenarios might be 
      described as "above average" at best, there remains a significant potential for 
      improvement, considering the identified limitations and unsatisfactory results in 
      a few cases.
CI  - Copyright © 2023, Sallam et al.
FAU - Sallam, Malik
AU  - Sallam M
AD  - Department of Pathology, Microbiology and Forensic Medicine, The University of 
      Jordan, School of Medicine, Amman, JOR.
AD  - Department of Clinical Laboratories and Forensic Medicine, Jordan University 
      Hospital, Amman, JOR.
FAU - Al-Salahat, Khaled
AU  - Al-Salahat K
AD  - Department of Pathology, Microbiology and Forensic Medicine, The University of 
      Jordan, School of Medicine, Amman, JOR.
FAU - Al-Ajlouni, Eyad
AU  - Al-Ajlouni E
AD  - Department of Pathology, Microbiology and Forensic Medicine, The University of 
      Jordan, School of Medicine, Amman, JOR.
LA  - eng
PT  - Journal Article
DEP - 20231216
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10725273
OTO - NOTNLM
OT  - ai chatbot gpt-4
OT  - applications of ai
OT  - clinical laboratory
OT  - healthcare practice
OT  - medical and diagnostic microbiology
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/12/18 06:42
MHDA- 2023/12/18 06:43
PMCR- 2023/12/16
CRDT- 2023/12/18 04:54
PHST- 2023/12/16 00:00 [accepted]
PHST- 2023/12/18 06:43 [medline]
PHST- 2023/12/18 06:42 [pubmed]
PHST- 2023/12/18 04:54 [entrez]
PHST- 2023/12/16 00:00 [pmc-release]
AID - 10.7759/cureus.50629 [doi]
PST - epublish
SO  - Cureus. 2023 Dec 16;15(12):e50629. doi: 10.7759/cureus.50629. eCollection 2023 
      Dec.

PMID- 37962176
OWN - NLM
STAT- MEDLINE
DCOM- 20240208
LR  - 20240208
IS  - 1473-6586 (Electronic)
IS  - 0963-0643 (Linking)
VI  - 34
IP  - 2
DP  - 2024 Mar 1
TI  - ChatGPT in urology practice: revolutionizing efficiency and patient care with 
      generative artificial intelligence.
PG  - 98-104
LID - 10.1097/MOU.0000000000001151 [doi]
AB  - PURPOSE OF REVIEW: ChatGPT has emerged as a potentially useful tool for 
      healthcare. Its role in urology is in its infancy and has much potential for 
      research, clinical practice and for patient assistance. With this narrative 
      review, we want to draw a picture of what is known about ChatGPT's integration in 
      urology, alongside future promises and challenges. RECENT FINDINGS: The use of 
      ChatGPT can ease the administrative work, helping urologists with note-taking and 
      clinical documentation such as discharge summaries and clinical notes. It can 
      improve patient engagement through increasing awareness and facilitating 
      communication, as it has especially been investigated for uro-oncological 
      diseases. Its ability to understand human emotions makes ChatGPT an empathic and 
      thoughtful interactive tool or source for urological patients and their 
      relatives. Currently, its role in clinical diagnosis and treatment decisions is 
      uncertain, as concerns have been raised about misinterpretation, hallucination 
      and out-of-date information. Moreover, a mandatory regulatory process for ChatGPT 
      in urology is yet to be established. SUMMARY: ChatGPT has the potential to 
      contribute to precision medicine and tailored practice by its quick, structured 
      responses. However, this will depend on how well information can be obtained by 
      seeking appropriate responses and asking the pertinent questions. The key lies in 
      being able to validate the responses, regulating the information shared and 
      avoiding misuse of the same to protect the data and patient privacy. Its 
      successful integration into mainstream urology needs educational bodies to 
      provide guidelines or best practice recommendations for the same.
CI  - Copyright © 2023 Wolters Kluwer Health, Inc. All rights reserved.
FAU - Nedbal, Carlotta
AU  - Nedbal C
AD  - Department of Urology, University Hospitals Southampton, NHS Trust, Southampton, 
      UK.
AD  - Urology Unit, Azienda Ospedaliero-Universitaria delle Marche, Polytechnic 
      University of Marche, Ancona, Italy.
FAU - Naik, Nitesh
AU  - Naik N
AD  - Department of Mechanical and Industrial Engineering, Manipal Institute of 
      Technology, Manipal Academy of Higher Education, Manipal, Karnataka, India.
FAU - Castellani, Daniele
AU  - Castellani D
AD  - Urology Unit, Azienda Ospedaliero-Universitaria delle Marche, Polytechnic 
      University of Marche, Ancona, Italy.
FAU - Gauhar, Vineet
AU  - Gauhar V
AD  - Department of Urology, Ng Teng Fong General Hospital, NUHS, Singapore.
FAU - Geraghty, Robert
AU  - Geraghty R
AD  - Department of Urology, Freeman Hospital, Newcastle-upon-Tyne, UK.
FAU - Somani, Bhaskar Kumar
AU  - Somani BK
AD  - Department of Urology, University Hospitals Southampton, NHS Trust, Southampton, 
      UK.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20231114
PL  - United States
TA  - Curr Opin Urol
JT  - Current opinion in urology
JID - 9200621
SB  - IM
MH  - Humans
MH  - *Urology
MH  - Artificial Intelligence
MH  - Patient Care
MH  - Urologists
MH  - Patient Participation
EDAT- 2023/11/14 12:42
MHDA- 2024/02/08 06:42
CRDT- 2023/11/14 07:53
PHST- 2024/02/08 06:42 [medline]
PHST- 2023/11/14 12:42 [pubmed]
PHST- 2023/11/14 07:53 [entrez]
AID - 00042307-990000000-00131 [pii]
AID - 10.1097/MOU.0000000000001151 [doi]
PST - ppublish
SO  - Curr Opin Urol. 2024 Mar 1;34(2):98-104. doi: 10.1097/MOU.0000000000001151. Epub 
      2023 Nov 14.

PMID- 37303897
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230613
IS  - 1664-1078 (Print)
IS  - 1664-1078 (Electronic)
IS  - 1664-1078 (Linking)
VI  - 14
DP  - 2023
TI  - ChatGPT outperforms humans in emotional awareness evaluations.
PG  - 1199058
LID - 10.3389/fpsyg.2023.1199058 [doi]
LID - 1199058
AB  - The artificial intelligence chatbot, ChatGPT, has gained widespread attention for 
      its ability to perform natural language processing tasks and has the 
      fastest-growing user base in history. Although ChatGPT has successfully generated 
      theoretical information in multiple fields, its ability to identify and describe 
      emotions is still unknown. Emotional awareness (EA), the ability to conceptualize 
      one's own and others' emotions, is considered a transdiagnostic mechanism for 
      psychopathology. This study utilized the Levels of Emotional Awareness Scale 
      (LEAS) as an objective, performance-based test to analyze ChatGPT's responses to 
      twenty scenarios and compared its EA performance with that of the general 
      population norms, as reported by a previous study. A second examination was 
      performed one month later to measure EA improvement over time. Finally, two 
      independent licensed psychologists evaluated the fit-to-context of ChatGPT's EA 
      responses. In the first examination, ChatGPT demonstrated significantly higher 
      performance than the general population on all the LEAS scales (Z score = 2.84). 
      In the second examination, ChatGPT's performance significantly improved, almost 
      reaching the maximum possible LEAS score (Z score = 4.26). Its accuracy levels 
      were also extremely high (9.7/10). The study demonstrated that ChatGPT can 
      generate appropriate EA responses, and that its performance may improve 
      significantly over time. The study has theoretical and clinical implications, as 
      ChatGPT can be used as part of cognitive training for clinical populations with 
      EA impairments. In addition, ChatGPT's EA-like abilities may facilitate 
      psychiatric diagnosis and assessment and be used to enhance emotional language. 
      Further research is warranted to better understand the potential benefits and 
      risks of ChatGPT and refine it to promote mental health.
CI  - Copyright © 2023 Elyoseph, Hadar-Shoval, Asraf and Lvovsky.
FAU - Elyoseph, Zohar
AU  - Elyoseph Z
AD  - Department of Psychology and Educational Counseling, The Center for 
      Psychobiological Research, Max Stern Yezreel Valley College, Emek Yezreel, 
      Israel.
AD  - Department of Brain Sciences, Faculty of Medicine, Imperial College London, 
      London, England.
FAU - Hadar-Shoval, Dorit
AU  - Hadar-Shoval D
AD  - Department of Psychology and Educational Counseling, The Center for 
      Psychobiological Research, Max Stern Yezreel Valley College, Emek Yezreel, 
      Israel.
FAU - Asraf, Kfir
AU  - Asraf K
AD  - Psychology Department, Center for Psychobiological Research, Max Stern Yezreel 
      Valley College, Emek Yezreel, Israel.
FAU - Lvovsky, Maya
AU  - Lvovsky M
AD  - Psychology Department, Center for Psychobiological Research, Max Stern Yezreel 
      Valley College, Emek Yezreel, Israel.
LA  - eng
PT  - Journal Article
DEP - 20230526
PL  - Switzerland
TA  - Front Psychol
JT  - Frontiers in psychology
JID - 101550902
PMC - PMC10254409
OTO - NOTNLM
OT  - ChatGPT
OT  - LEAS
OT  - artificial intelligence
OT  - emotional awareness
OT  - emotional intelligence
OT  - psychological assessment
OT  - psychotherapy
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/06/12 06:42
MHDA- 2023/06/12 06:43
PMCR- 2023/05/26
CRDT- 2023/06/12 03:59
PHST- 2023/04/02 00:00 [received]
PHST- 2023/05/11 00:00 [accepted]
PHST- 2023/06/12 06:43 [medline]
PHST- 2023/06/12 06:42 [pubmed]
PHST- 2023/06/12 03:59 [entrez]
PHST- 2023/05/26 00:00 [pmc-release]
AID - 10.3389/fpsyg.2023.1199058 [doi]
PST - epublish
SO  - Front Psychol. 2023 May 26;14:1199058. doi: 10.3389/fpsyg.2023.1199058. 
      eCollection 2023.

PMID- 37031289
OWN - NLM
STAT- MEDLINE
DCOM- 20230425
LR  - 20231213
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Print)
IS  - 0090-6964 (Linking)
VI  - 51
IP  - 5
DP  - 2023 May
TI  - Talk with ChatGPT About the Outbreak of Mpox in 2022: Reflections and Suggestions 
      from AI Dimensions.
PG  - 870-874
LID - 10.1007/s10439-023-03196-z [doi]
AB  - In the era of big data, generative artificial intelligence (AI) models are 
      currently in a boom. The Chatbot Generative Pre-trained Transformer (ChatGPT), a 
      large language model (LLM) developed by OpenAI (San Francisco, CA), is a type of 
      AI software that could generate text based on the input it receives. In this 
      study, in order to explore how ChatGPT could give reflections and suggestions 
      about the sudden outbreak of Mpox in 2022 from the AI dimensions, our group 
      talked with ChatGPT with several questions about Mpox. We hope this talk could 
      enrich our knowledge on Mpox from the new AI dimensions and also explore the 
      possibility of human and AI fight shoulder to shoulder for prevention and 
      containment of the potential epidemics or pandemics in future.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Cheng, Kunming
AU  - Cheng K
AD  - Department of Intensive Care Unit, The Second Affiliated Hospital of Zhengzhou 
      University, Zhengzhou, Henan, China.
FAU - He, Yongbin
AU  - He Y
AD  - School of Sport Medicine and Rehabilitation, Beijing Sport University, Beijing, 
      China.
FAU - Li, Cheng
AU  - Li C
AD  - Department of Orthopaedic Surgery, Beijing Jishuitan Hospital, Fourth Clinical 
      College of Peking University, Beijing, China.
FAU - Xie, Ruijie
AU  - Xie R
AD  - Department of Hand and Microsurgery, Hengyang Medical School, The Affiliated 
      Nanhua Hospital, University of South China Hengyang, Hengyang, China.
FAU - Lu, Yanqiu
AU  - Lu Y
AD  - Department of Intensive Care Unit, The Second Affiliated Hospital of Zhengzhou 
      University, Zhengzhou, Henan, China.
FAU - Gu, Shuqin
AU  - Gu S
AD  - Duke Human Vaccine Institute, Duke University Medical Center, Durham, NC, USA. 
      shuqin.gu@duke.edu.
FAU - Wu, Haiyang
AU  - Wu H
AD  - Department of Graduate School, Tianjin Medical University, Tianjin, China. 
      wuhaiyang2021@tmu.edu.cn.
AD  - Duke Molecular Physiology Institute, Duke University School of Medicine, Durham, 
      NC, USA. wuhaiyang2021@tmu.edu.cn.
LA  - eng
PT  - Letter
DEP - 20230408
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Mpox (monkeypox)
MH  - Software
MH  - Disease Outbreaks
MH  - Electric Power Supplies
PMC - PMC10085783
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Chatbots
OT  - Infectious disease
OT  - Mpox
OT  - Public health
COIS- The authors declare no conflict of interest.
EDAT- 2023/04/09 06:00
MHDA- 2023/04/25 06:42
PMCR- 2023/04/11
CRDT- 2023/04/08 23:20
PHST- 2023/03/21 00:00 [received]
PHST- 2023/03/23 00:00 [accepted]
PHST- 2023/04/25 06:42 [medline]
PHST- 2023/04/09 06:00 [pubmed]
PHST- 2023/04/08 23:20 [entrez]
PHST- 2023/04/11 00:00 [pmc-release]
AID - 10.1007/s10439-023-03196-z [pii]
AID - 3196 [pii]
AID - 10.1007/s10439-023-03196-z [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2023 May;51(5):870-874. doi: 10.1007/s10439-023-03196-z. Epub 
      2023 Apr 8.

PMID- 38405625
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240227
IS  - 2471-1411 (Electronic)
IS  - 2096-1790 (Print)
IS  - 2471-1411 (Linking)
VI  - 8
IP  - 4
DP  - 2023 Dec
TI  - ChatGPT in forensic sciences: a new Pandora's box with advantages and challenges 
      to pay attention.
PG  - 275-279
LID - 10.1093/fsr/owad039 [doi]
AB  - ChatGPT is a variant of the generative pre-trained transformer (GPT) language 
      model that uses large amounts of text-based training data and a transformer 
      architecture to generate human-like text adjusted to the received prompts. 
      ChatGPT presents several advantages in forensic sciences, namely, constituting a 
      virtual assistant to aid lawyers, judges, and victims in managing and 
      interpreting forensic expert data. But what would happen if ChatGPT began to be 
      used to produce forensic expertise reports? Despite its potential applications, 
      the use of ChatGPT and other Large Language Models and artificial intelligence 
      tools in forensic writing also poses ethical and legal concerns, which are 
      discussed in this perspective together with some expected future perspectives.
CI  - © The Author(s) 2023. Published by OUP on behalf of the Academy of Forensic 
      Science.
FAU - Dinis-Oliveira, Ricardo J
AU  - Dinis-Oliveira RJ
AUID- ORCID: 0000-0001-7430-6297
AD  - 1H-TOXRUN-One Health Toxicology Research Unit, University Institute of Health 
      Sciences (IUCS-CESPU), CESPU, CRL, Gandra, Portugal.
AD  - Department of Public Health and Forensic Sciences and Medical Education, Faculty 
      of Medicine, University of Porto, Porto, Portugal.
AD  - UCIBIO/REQUIMTE, Laboratory of Toxicology, Faculty of Pharmacy, University of 
      Porto, R. Jorge Viterbo Ferreira, n° 33-A, Lisboa, Portugal.
AD  - FOREN-Forensic Science Experts, Dr. Mário Moutinho Avenue, n.° 33-A, Lisbon, 
      Portugal.
FAU - Azevedo, Rui M S
AU  - Azevedo RMS
AD  - 1H-TOXRUN-One Health Toxicology Research Unit, University Institute of Health 
      Sciences (IUCS-CESPU), CESPU, CRL, Gandra, Portugal.
LA  - eng
PT  - Editorial
DEP - 20231110
PL  - England
TA  - Forensic Sci Res
JT  - Forensic sciences research
JID - 101724928
PMC - PMC10894065
OTO - NOTNLM
OT  - ChatGPT
OT  - advantages and limitations
OT  - artificial intelligence
OT  - forensic sciences
OT  - medicine
EDAT- 2024/02/26 06:42
MHDA- 2024/02/26 06:43
PMCR- 2023/11/10
CRDT- 2024/02/26 04:47
PHST- 2023/09/18 00:00 [received]
PHST- 2023/10/19 00:00 [accepted]
PHST- 2024/02/26 06:43 [medline]
PHST- 2024/02/26 06:42 [pubmed]
PHST- 2024/02/26 04:47 [entrez]
PHST- 2023/11/10 00:00 [pmc-release]
AID - owad039 [pii]
AID - 10.1093/fsr/owad039 [doi]
PST - epublish
SO  - Forensic Sci Res. 2023 Nov 10;8(4):275-279. doi: 10.1093/fsr/owad039. eCollection 
      2023 Dec.

PMID- 37133418
OWN - NLM
STAT- MEDLINE
DCOM- 20230626
LR  - 20230626
IS  - 1744-5205 (Electronic)
IS  - 0882-0538 (Linking)
VI  - 38
IP  - 5
DP  - 2023 Jul
TI  - ChatGPT and Ophthalmology: Exploring Its Potential with Discharge Summaries and 
      Operative Notes.
PG  - 503-507
LID - 10.1080/08820538.2023.2209166 [doi]
AB  - PURPOSE: This study aimed to report the abilities of the large language model 
      ChatGPT(R) (OpenAI, San Francisco, USA) in constructing ophthalmic discharge 
      summaries and operative notes. METHODS: A set of prompts was constructed through 
      statements incorporating common ophthalmic surgeries across the subspecialties of 
      the cornea, retina, glaucoma, paediatric ophthalmology, neuro-ophthalmology, and 
      ophthalmic plastics surgery. The responses of ChatGPT were assessed by three 
      surgeons carefully and analyzed them for evidence-based content, specificity of 
      the response, presence of generic text, disclaimers, factual inaccuracies, and 
      its abilities to admit mistakes and challenge incorrect premises. RESULTS: A 
      total of 24 prompts were presented to the ChatGPT. Twelve prompts assessed its 
      ability to construct discharge summaries, and an equal number explored the 
      potential for preparing operative notes. The response was found to be tailored 
      based on the quality of inputs given and was provided in a matter of seconds. The 
      ophthalmic discharge summaries had a valid but significant generic text. ChatGPT 
      could incorporate specific medications, follow-up instructions, consultation 
      time, and location within the discharge summaries when prompted appropriately. 
      While the operative notes were detailed, they required significant tuning. 
      ChatGPT routinely admits its mistakes and corrects itself immediately when 
      confronted with factual inaccuracies. The mistakes are avoided in subsequent 
      reports when given similar prompts. CONCLUSION: The performance of ChatGPT in the 
      context of ophthalmic discharge summaries and operative notes was encouraging. 
      These are constructed rapidly in a matter of seconds. Focused training of ChatGPT 
      on these issues with inclusion of a human verification step has an enormous 
      potential to impact healthcare positively.
FAU - Singh, Swati
AU  - Singh S
AD  - Ophthalmic Plastic Surgery Service, L.V. Prasad Eye Institute, Hyderabad, India.
FAU - Djalilian, Ali
AU  - Djalilian A
AD  - Department of Ophthalmology, University of Illinois, Chicago, Illinois, USA.
FAU - Ali, Mohammad Javed
AU  - Ali MJ
AD  - Govindram Seksaria Institute of Dacryology, L.V. Prasad Eye Institute, Hyderabad, 
      India.
LA  - eng
PT  - Journal Article
DEP - 20230503
PL  - England
TA  - Semin Ophthalmol
JT  - Seminars in ophthalmology
JID - 8610759
SB  - IM
MH  - Child
MH  - Humans
MH  - *Ophthalmology
MH  - Patient Discharge
MH  - Cornea
MH  - *Glaucoma
MH  - Referral and Consultation
OTO - NOTNLM
OT  - Chatbot
OT  - LLM
OT  - chatGPT
OT  - cornea
OT  - glaucoma
OT  - lacrimal
OT  - large language models
OT  - ophthalmology
OT  - retina
OT  - strabismus
EDAT- 2023/05/03 12:42
MHDA- 2023/06/26 06:41
CRDT- 2023/05/03 10:23
PHST- 2023/06/26 06:41 [medline]
PHST- 2023/05/03 12:42 [pubmed]
PHST- 2023/05/03 10:23 [entrez]
AID - 10.1080/08820538.2023.2209166 [doi]
PST - ppublish
SO  - Semin Ophthalmol. 2023 Jul;38(5):503-507. doi: 10.1080/08820538.2023.2209166. 
      Epub 2023 May 3.

PMID- 37516680
OWN - NLM
STAT- Publisher
LR  - 20230729
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
DP  - 2023 Jul 29
TI  - ChatGPT and Clinical Decision Support: Scope, Application, and Limitations.
LID - 10.1007/s10439-023-03329-4 [doi]
AB  - This study examines ChatGPT's role in clinical decision support, by analyzing its 
      scope, application, and limitations. By analyzing patient data and providing 
      evidence-based recommendations, ChatGPT, an AI language model, can help 
      healthcare professionals make well-informed decisions. This study examines 
      ChatGPT's use in clinical decision support, including diagnosis and treatment 
      planning. However, it acknowledges limitations like biases, lack of contextual 
      understanding, and human oversight and also proposes a framework for the future 
      clinical decision support system. Understanding these factors will allow 
      healthcare professionals to utilize ChatGPT effectively and make accurate 
      clinical decisions. Further research is needed to understand the implications of 
      using ChatGPT in healthcare settings and to develop safeguards for responsible 
      use.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Ferdush, Jannatul
AU  - Ferdush J
AD  - Department of Computer Science and Engineering, Jashore University of Science and 
      Technology, Jashore, 7408, Bangladesh. jannatulferdush@just.edu.bd.
FAU - Begum, Mahbuba
AU  - Begum M
AD  - Department of Computer Science and Engineering, Mawlana Bhasani Science and 
      Technology, Tangail, 1902, Bangladesh.
FAU - Hossain, Sakib Tanvir
AU  - Hossain ST
AD  - Department of Mechanical Engineering, Khulna University of Engineering and 
      Technology, Khulna, 9203, Bangladesh.
LA  - eng
PT  - Letter
DEP - 20230729
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
OTO - NOTNLM
OT  - Biasness
OT  - CDS
OT  - ChatGPT
OT  - Ethics
EDAT- 2023/07/30 01:06
MHDA- 2023/07/30 01:06
CRDT- 2023/07/29 23:04
PHST- 2023/07/15 00:00 [received]
PHST- 2023/07/18 00:00 [accepted]
PHST- 2023/07/30 01:06 [medline]
PHST- 2023/07/30 01:06 [pubmed]
PHST- 2023/07/29 23:04 [entrez]
AID - 10.1007/s10439-023-03329-4 [pii]
AID - 10.1007/s10439-023-03329-4 [doi]
PST - aheadofprint
SO  - Ann Biomed Eng. 2023 Jul 29. doi: 10.1007/s10439-023-03329-4.

PMID- 37544801
OWN - NLM
STAT- MEDLINE
DCOM- 20231108
LR  - 20231108
IS  - 1531-5037 (Electronic)
IS  - 0022-3468 (Linking)
VI  - 58
IP  - 12
DP  - 2023 Dec
TI  - Revolutionizing Healthcare with ChatGPT: An Early Exploration of an AI Language 
      Model's Impact on Medicine at Large and its Role in Pediatric Surgery.
PG  - 2410-2415
LID - S0022-3468(23)00416-5 [pii]
LID - 10.1016/j.jpedsurg.2023.07.008 [doi]
AB  - BACKGROUND: ChatGPT, a natural language processing model, has shown great promise 
      in revolutionizing the field of medicine. This paper presents a comprehensive 
      evaluation of the transformative potential of OpenAI's ChatGPT on healthcare and 
      scientific research, with an exploration on its prospective capacity to impact 
      the field of pediatric surgery. METHODS: Through an extensive review of the 
      literature, we illuminate ChatGPT's applications in clinical healthcare and 
      medical research while presenting the ethical considerations surrounding its use. 
      RESULTS: Our review reveals the exciting work done so far evaluating the numerous 
      potential uses of ChatGPT in clinical medicine and medical research, but it also 
      shows that significant research and advancements in natural language processing 
      models are still needed. CONCLUSION: ChatGPT has immense promise in transforming 
      how we provide healthcare and how we conduct research. Currently, further robust 
      research on the safety, effectiveness, and ethical considerations of ChatGPT is 
      greatly needed. LEVEL OF STUDY: V.
CI  - Copyright © 2023 Elsevier Inc. All rights reserved.
FAU - Xiao, David
AU  - Xiao D
AD  - Department of Pediatric Surgery, Vanderbilt Children's Medical Center, Nashville, 
      TN, USA. Electronic address: David.Xiao@vumc.org.
FAU - Meyers, Patrick
AU  - Meyers P
AD  - Department of Pediatric Surgery, Vanderbilt Children's Medical Center, Nashville, 
      TN, USA.
FAU - Upperman, Jeffrey S
AU  - Upperman JS
AD  - Department of Pediatric Surgery, Vanderbilt Children's Medical Center, Nashville, 
      TN, USA.
FAU - Robinson, Jamie R
AU  - Robinson JR
AD  - Department of Pediatric Surgery, Vanderbilt Children's Medical Center, Nashville, 
      TN, USA; Department of Biomedical Informatics, Vanderbilt University Medical 
      Center, Nashville, TN, USA.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230720
PL  - United States
TA  - J Pediatr Surg
JT  - Journal of pediatric surgery
JID - 0052631
SB  - IM
MH  - Child
MH  - Humans
MH  - Prospective Studies
MH  - *Medicine
MH  - *Specialties, Surgical
MH  - *Biomedical Research
MH  - Health Facilities
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Large language model
EDAT- 2023/08/07 00:42
MHDA- 2023/11/08 06:44
CRDT- 2023/08/06 21:54
PHST- 2023/06/05 00:00 [received]
PHST- 2023/07/10 00:00 [revised]
PHST- 2023/07/14 00:00 [accepted]
PHST- 2023/11/08 06:44 [medline]
PHST- 2023/08/07 00:42 [pubmed]
PHST- 2023/08/06 21:54 [entrez]
AID - S0022-3468(23)00416-5 [pii]
AID - 10.1016/j.jpedsurg.2023.07.008 [doi]
PST - ppublish
SO  - J Pediatr Surg. 2023 Dec;58(12):2410-2415. doi: 10.1016/j.jpedsurg.2023.07.008. 
      Epub 2023 Jul 20.

PMID- 37463210
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230729
IS  - 1091-6490 (Electronic)
IS  - 0027-8424 (Print)
IS  - 0027-8424 (Linking)
VI  - 120
IP  - 30
DP  - 2023 Jul 25
TI  - ChatGPT outperforms crowd workers for text-annotation tasks.
PG  - e2305016120
LID - 10.1073/pnas.2305016120 [doi]
LID - e2305016120
AB  - Many NLP applications require manual text annotations for a variety of tasks, 
      notably to train classifiers or evaluate the performance of unsupervised models. 
      Depending on the size and degree of complexity, the tasks may be conducted by 
      crowd workers on platforms such as MTurk as well as trained annotators, such as 
      research assistants. Using four samples of tweets and news articles (n = 6,183), 
      we show that ChatGPT outperforms crowd workers for several annotation tasks, 
      including relevance, stance, topics, and frame detection. Across the four 
      datasets, the zero-shot accuracy of ChatGPT exceeds that of crowd workers by 
      about 25 percentage points on average, while ChatGPT's intercoder agreement 
      exceeds that of both crowd workers and trained annotators for all tasks. 
      Moreover, the per-annotation cost of ChatGPT is less than $0.003-about thirty 
      times cheaper than MTurk. These results demonstrate the potential of large 
      language models to drastically increase the efficiency of text classification.
FAU - Gilardi, Fabrizio
AU  - Gilardi F
AUID- ORCID: 0000-0002-0635-3048
AD  - Department of Political Science, University of Zurich, Zurich 8050, Switzerland.
FAU - Alizadeh, Meysam
AU  - Alizadeh M
AUID- ORCID: 0000-0001-6696-6471
AD  - Department of Political Science, University of Zurich, Zurich 8050, Switzerland.
FAU - Kubli, Maël
AU  - Kubli M
AUID- ORCID: 0000-0002-5592-9648
AD  - Department of Political Science, University of Zurich, Zurich 8050, Switzerland.
LA  - eng
GR  - 883121/EC | European Research Council (ERC)/
PT  - Journal Article
DEP - 20230718
PL  - United States
TA  - Proc Natl Acad Sci U S A
JT  - Proceedings of the National Academy of Sciences of the United States of America
JID - 7505876
SB  - IM
PMC - PMC10372638
OTO - NOTNLM
OT  - ChatGPT
OT  - human annotations
OT  - large language models
OT  - text as data
OT  - text classification
COIS- The authors declare no competing interest.
EDAT- 2023/07/18 18:42
MHDA- 2023/07/18 18:43
PMCR- 2023/07/18
CRDT- 2023/07/18 13:43
PHST- 2023/07/18 18:43 [medline]
PHST- 2023/07/18 18:42 [pubmed]
PHST- 2023/07/18 13:43 [entrez]
PHST- 2023/07/18 00:00 [pmc-release]
AID - 202305016 [pii]
AID - 10.1073/pnas.2305016120 [doi]
PST - ppublish
SO  - Proc Natl Acad Sci U S A. 2023 Jul 25;120(30):e2305016120. doi: 
      10.1073/pnas.2305016120. Epub 2023 Jul 18.

PMID- 37549788
OWN - NLM
STAT- MEDLINE
DCOM- 20230904
LR  - 20230925
IS  - 1538-2990 (Electronic)
IS  - 0002-9629 (Linking)
VI  - 366
IP  - 4
DP  - 2023 Oct
TI  - Can ChatGPT pass the thoracic surgery exam?
PG  - 291-295
LID - S0002-9629(23)01292-2 [pii]
LID - 10.1016/j.amjms.2023.08.001 [doi]
AB  - BACKGROUND: The capacity of ChatGPT in academic environments and medical exams is 
      being discovered more and more every day. In this study, we tested the success of 
      ChatGPT on Turkish-language thoracic surgery exam questions. METHODS: ChatGPT was 
      provided with a total of 105 questions divided into seven distinct groups, each 
      of which contained 15 questions. Along with the success of the students, the 
      success of ChatGPT-3.5 and ChatGPT-4 architectures in answering the questions 
      correctly was analyzed. RESULTS: The overall mean score of students was 
      12.50&nbsp;±&nbsp;1.20, corresponding to 83.33%. Moreover, ChatGPT-3.5 managed to surpass 
      students' score of 12.5 with an average of 13.57&nbsp;±&nbsp;0.49 questions correctly on 
      average, while ChatGPT-4 answered 14&nbsp;±&nbsp;0.76 questions correctly (83.3%, 90.48%, 
      and 93.33%, respectively). CONCLUSIONS: When the results of this study and other 
      similar studies in the literature are evaluated together, ChatGPT, which was 
      developed for general purpose, can also produce successful results in a specific 
      field of medicine. AI-powered applications are becoming more and more useful and 
      valuable in providing academic knowledge.
CI  - Copyright © 2023 Southern Society for Clinical Investigation. Published by 
      Elsevier Inc. All rights reserved.
FAU - Gencer, Adem
AU  - Gencer A
AD  - Department of Thoracic Surgery, Afyonkarahisar Health Sciences University, 
      Faculty of Medicine, Zafer Sağlık Külliyesi, Dörtyol Mah. 2078 Sok. No:3 A Blok, 
      Afyonkarahisar, Turkey. Electronic address: dr.ademgencer@gmail.com.
FAU - Aydin, Suphi
AU  - Aydin S
AD  - Department of Thoracic Surgery, Afyonkarahisar Health Sciences University, 
      Faculty of Medicine, Zafer Sağlık Külliyesi, Dörtyol Mah. 2078 Sok. No:3 A Blok, 
      Afyonkarahisar, Turkey.
LA  - eng
PT  - Journal Article
DEP - 20230806
PL  - United States
TA  - Am J Med Sci
JT  - The American journal of the medical sciences
JID - 0370506
SB  - IM
MH  - Humans
MH  - *Thoracic Surgery
MH  - *Medicine
OTO - NOTNLM
OT  - Artificial intelligence (AI)
OT  - ChatGPT
OT  - Large language models
OT  - Medical education
OT  - Thoracic surgery
COIS- Declaration of Competing Interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2023/08/08 00:42
MHDA- 2023/09/04 06:43
CRDT- 2023/08/07 19:13
PHST- 2023/06/07 00:00 [received]
PHST- 2023/06/12 00:00 [revised]
PHST- 2023/08/02 00:00 [accepted]
PHST- 2023/09/04 06:43 [medline]
PHST- 2023/08/08 00:42 [pubmed]
PHST- 2023/08/07 19:13 [entrez]
AID - S0002-9629(23)01292-2 [pii]
AID - 10.1016/j.amjms.2023.08.001 [doi]
PST - ppublish
SO  - Am J Med Sci. 2023 Oct;366(4):291-295. doi: 10.1016/j.amjms.2023.08.001. Epub 
      2023 Aug 6.

PMID- 37059827
OWN - NLM
STAT- MEDLINE
DCOM- 20230717
LR  - 20230811
IS  - 1432-2161 (Electronic)
IS  - 0364-2348 (Linking)
VI  - 52
IP  - 9
DP  - 2023 Sep
TI  - A comparison of ChatGPT-generated articles with human-written articles.
PG  - 1755-1758
LID - 10.1007/s00256-023-04340-5 [doi]
AB  - OBJECTIVE: ChatGPT (Generative Pre-trained Transformer) is an artificial 
      intelligence language tool developed by OpenAI that utilises machine learning 
      algorithms to generate text that closely mimics human language. It has recently 
      taken the internet by storm. There have been several concerns regarding the 
      accuracy of documents it generates. This study compares the accuracy and quality 
      of several ChatGPT-generated academic articles with those written by human 
      authors. MATERIAL AND METHODS: We performed a study to assess the accuracy of 
      ChatGPT-generated radiology articles by comparing them with the published or 
      written, and under review articles. These were independently analysed by two 
      fellowship-trained musculoskeletal radiologists and graded from 1 to 5 (1 being 
      bad and inaccurate to 5 being excellent and accurate). RESULTS: In total, 4 of 
      the 5 articles written by ChatGPT were significantly inaccurate with fictitious 
      references. One of the papers was well written, with a good introduction and 
      discussion; however, all references were fictitious. CONCLUSION: ChatGPT is able 
      to generate coherent research articles, which on initial review may closely 
      resemble authentic articles published by academic researchers. However, all of 
      the articles we assessed were factually inaccurate and had fictitious references. 
      It is worth noting, however, that the articles generated may appear authentic to 
      an untrained reader.
CI  - © 2023. The Author(s), under exclusive licence to International Skeletal Society 
      (ISS).
FAU - Ariyaratne, Sisith
AU  - Ariyaratne S
AD  - Department of Musculoskeletal Radiology, The Royal Orthopedic Hospital, Bristol 
      Road South, Northfield, Birmingham, UK.
FAU - Iyengar, Karthikeyan P
AU  - Iyengar KP
AD  - Department of Orthopedics, Southport and Ormskirk Hospital, Southport, UK.
FAU - Nischal, Neha
AU  - Nischal N
AD  - Department of Radiology, Holy Family Hospital, New Delhi, India.
FAU - Chitti Babu, Naparla
AU  - Chitti Babu N
AD  - Department of Radiology, Srinivas Institute of Medical Sciences &amp; Research 
      Centre, Mukka, Mangalore, India.
FAU - Botchu, Rajesh
AU  - Botchu R
AD  - Department of Musculoskeletal Radiology, The Royal Orthopedic Hospital, Bristol 
      Road South, Northfield, Birmingham, UK. drbrajesh@yahoo.com.
LA  - eng
PT  - Journal Article
DEP - 20230414
PL  - Germany
TA  - Skeletal Radiol
JT  - Skeletal radiology
JID - 7701953
SB  - IM
CIN - Skeletal Radiol. 2023 Dec;52(12):2487-2488. PMID: 37458781
CIN - Skeletal Radiol. 2023 Dec;52(12):2493. PMID: 37566150
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Algorithms
MH  - Fellowships and Scholarships
MH  - Internet
MH  - Machine Learning
OTO - NOTNLM
OT  - Accuracy
OT  - Articles
OT  - ChatGPT
OT  - Research
EDAT- 2023/04/15 06:00
MHDA- 2023/07/17 06:42
CRDT- 2023/04/14 23:18
PHST- 2023/03/01 00:00 [received]
PHST- 2023/04/09 00:00 [accepted]
PHST- 2023/04/06 00:00 [revised]
PHST- 2023/07/17 06:42 [medline]
PHST- 2023/04/15 06:00 [pubmed]
PHST- 2023/04/14 23:18 [entrez]
AID - 10.1007/s00256-023-04340-5 [pii]
AID - 10.1007/s00256-023-04340-5 [doi]
PST - ppublish
SO  - Skeletal Radiol. 2023 Sep;52(9):1755-1758. doi: 10.1007/s00256-023-04340-5. Epub 
      2023 Apr 14.

PMID- 37399030
OWN - NLM
STAT- MEDLINE
DCOM- 20231113
LR  - 20231124
IS  - 1537-6591 (Electronic)
IS  - 1058-4838 (Print)
IS  - 1058-4838 (Linking)
VI  - 77
IP  - 9
DP  - 2023 Nov 11
TI  - ChatGPT, GPT-4, and Other Large Language Models: The Next Revolution for Clinical 
      Microbiology?
PG  - 1322-1328
LID - 10.1093/cid/ciad407 [doi]
AB  - ChatGPT, GPT-4, and Bard are highly advanced natural language process-based 
      computer programs (chatbots) that simulate and process human conversation in 
      written or spoken form. Recently released by the company OpenAI, ChatGPT was 
      trained on billions of unknown text elements (tokens) and rapidly gained wide 
      attention for its ability to respond to questions in an articulate manner across 
      a wide range of knowledge domains. These potentially disruptive large language 
      model (LLM) technologies have a broad range of conceivable applications in 
      medicine and medical microbiology. In this opinion article, I describe how 
      chatbot technologies work and discuss the strengths and weaknesses of ChatGPT, 
      GPT-4, and other LLMs for applications in the routine diagnostic laboratory, 
      focusing on various use cases for the pre- to post-analytical process.
CI  - © The Author(s) 2023. Published by Oxford University Press on behalf of 
      Infectious Diseases Society of America.
FAU - Egli, Adrian
AU  - Egli A
AUID- ORCID: 0000-0002-3564-8603
AD  - Institute of Medical Microbiology, University of Zurich, Zurich, Switzerland.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Clin Infect Dis
JT  - Clinical infectious diseases : an official publication of the Infectious Diseases 
      Society of America
JID - 9203213
SB  - IM
MH  - Humans
MH  - *Language
MH  - *Communication
MH  - Laboratories
MH  - Software
PMC - PMC10640689
OTO - NOTNLM
OT  - artificial intelligence
OT  - chatGPT
OT  - chatbot
OT  - digitalization
OT  - large language model
COIS- Potential conflicts of interest. A. E. reports grants or contracts from the 
      Bangerter Rhyner Foundation and the Swiss National Science Foundation; consulting 
      fees from Pfizer and Illumina; and participation on a data and safety monitoring 
      board or advisory board for Sefunda. The author has submitted the ICMJE Form for 
      Disclosure of Potential Conflicts of Interest. Conflicts that the editors 
      consider relevant to the content of the manuscript have been disclosed.
EDAT- 2023/07/03 13:06
MHDA- 2023/11/13 06:42
PMCR- 2023/07/03
CRDT- 2023/07/03 11:56
PHST- 2023/03/08 00:00 [received]
PHST- 2023/11/13 06:42 [medline]
PHST- 2023/07/03 13:06 [pubmed]
PHST- 2023/07/03 11:56 [entrez]
PHST- 2023/07/03 00:00 [pmc-release]
AID - 7217675 [pii]
AID - ciad407 [pii]
AID - 10.1093/cid/ciad407 [doi]
PST - ppublish
SO  - Clin Infect Dis. 2023 Nov 11;77(9):1322-1328. doi: 10.1093/cid/ciad407.

PMID- 37581444
OWN - NLM
STAT- MEDLINE
DCOM- 20240214
LR  - 20240222
IS  - 1524-4040 (Electronic)
IS  - 0148-396X (Linking)
VI  - 93
IP  - 6
DP  - 2023 Dec 1
TI  - Performance of ChatGPT and GPT-4 on Neurosurgery Written Board Examinations.
PG  - 1353-1365
LID - 10.1227/neu.0000000000002632 [doi]
AB  - BACKGROUND AND OBJECTIVES: Interest surrounding generative large language models 
      (LLMs) has rapidly grown. Although ChatGPT (GPT-3.5), a general LLM, has shown 
      near-passing performance on medical student board examinations, the performance 
      of ChatGPT or its successor GPT-4 on specialized examinations and the factors 
      affecting accuracy remain unclear. This study aims to assess the performance of 
      ChatGPT and GPT-4 on a 500-question mock neurosurgical written board examination. 
      METHODS: The Self-Assessment Neurosurgery Examinations (SANS) American Board of 
      Neurological Surgery Self-Assessment Examination 1 was used to evaluate ChatGPT 
      and GPT-4. Questions were in single best answer, multiple-choice format. χ 2 , 
      Fisher exact, and univariable logistic regression tests were used to assess 
      performance differences in relation to question characteristics. RESULTS: ChatGPT 
      (GPT-3.5) and GPT-4 achieved scores of 73.4% (95% CI: 69.3%-77.2%) and 83.4% (95% 
      CI: 79.8%-86.5%), respectively, relative to the user average of 72.8% (95% CI: 
      68.6%-76.6%). Both LLMs exceeded last year's passing threshold of 69%. Although 
      scores between ChatGPT and question bank users were equivalent ( P = .963), GPT-4 
      outperformed both (both P &lt; .001). GPT-4 answered every question answered 
      correctly by ChatGPT and 37.6% (50/133) of remaining incorrect questions 
      correctly. Among 12 question categories, GPT-4 significantly outperformed users 
      in each but performed comparably with ChatGPT in 3 (functional, other general, 
      and spine) and outperformed both users and ChatGPT for tumor questions. Increased 
      word count (odds ratio = 0.89 of answering a question correctly per +10 words) 
      and higher-order problem-solving (odds ratio = 0.40, P = .009) were associated 
      with lower accuracy for ChatGPT, but not for GPT-4 (both P &gt; .005). Multimodal 
      input was not available at the time of this study; hence, on questions with image 
      content, ChatGPT and GPT-4 answered 49.5% and 56.8% of questions correctly based 
      on contextual context clues alone. CONCLUSION: LLMs achieved passing scores on a 
      mock 500-question neurosurgical written board examination, with GPT-4 
      significantly outperforming ChatGPT.
CI  - Copyright © Congress of Neurological Surgeons 2023. All rights reserved.
FAU - Ali, Rohaid
AU  - Ali R
AD  - Department of Neurosurgery, The Warren Alpert Medical School of Brown University, 
      Providence , Rhode Island , USA.
FAU - Tang, Oliver Y
AU  - Tang OY
AUID- ORCID: 0000-0002-8604-2708
AD  - Department of Neurosurgery, The Warren Alpert Medical School of Brown University, 
      Providence , Rhode Island , USA.
FAU - Connolly, Ian D
AU  - Connolly ID
AD  - Department of Neurosurgery, Massachusetts General Hospital, Boston , 
      Massachusetts , USA.
FAU - Zadnik Sullivan, Patricia L
AU  - Zadnik Sullivan PL
AD  - Department of Neurosurgery, The Warren Alpert Medical School of Brown University, 
      Providence , Rhode Island , USA.
FAU - Shin, John H
AU  - Shin JH
AD  - Department of Neuroscience, Norman Prince Neurosciences Institute, Rhode Island 
      Hospital, Providence , Rhode Island , USA.
FAU - Fridley, Jared S
AU  - Fridley JS
AD  - Department of Neurosurgery, The Warren Alpert Medical School of Brown University, 
      Providence , Rhode Island , USA.
FAU - Asaad, Wael F
AU  - Asaad WF
AD  - Department of Neurosurgery, The Warren Alpert Medical School of Brown University, 
      Providence , Rhode Island , USA.
AD  - Department of Neuroscience, Norman Prince Neurosciences Institute, Rhode Island 
      Hospital, Providence , Rhode Island , USA.
AD  - Department of Neuroscience, Brown University, Providence , Rhode Island , USA.
AD  - Department of Neuroscience, Carney Institute for Brain Science, Brown University, 
      Providence , Rhode Island , USA.
FAU - Cielo, Deus
AU  - Cielo D
AD  - Department of Neurosurgery, The Warren Alpert Medical School of Brown University, 
      Providence , Rhode Island , USA.
FAU - Oyelese, Adetokunbo A
AU  - Oyelese AA
AD  - Department of Neurosurgery, The Warren Alpert Medical School of Brown University, 
      Providence , Rhode Island , USA.
FAU - Doberstein, Curtis E
AU  - Doberstein CE
AD  - Department of Neurosurgery, The Warren Alpert Medical School of Brown University, 
      Providence , Rhode Island , USA.
FAU - Gokaslan, Ziya L
AU  - Gokaslan ZL
AD  - Department of Neurosurgery, The Warren Alpert Medical School of Brown University, 
      Providence , Rhode Island , USA.
FAU - Telfeian, Albert E
AU  - Telfeian AE
AD  - Department of Neurosurgery, The Warren Alpert Medical School of Brown University, 
      Providence , Rhode Island , USA.
LA  - eng
PT  - Journal Article
DEP - 20230815
PL  - United States
TA  - Neurosurgery
JT  - Neurosurgery
JID - 7802914
SB  - IM
MH  - Humans
MH  - *Neurosurgery
MH  - Neurosurgical Procedures
MH  - Odds Ratio
MH  - Self-Assessment
MH  - Spine
EDAT- 2023/08/15 12:42
MHDA- 2024/02/13 00:42
CRDT- 2023/08/15 09:03
PHST- 2023/03/22 00:00 [received]
PHST- 2023/05/19 00:00 [accepted]
PHST- 2024/02/13 00:42 [medline]
PHST- 2023/08/15 12:42 [pubmed]
PHST- 2023/08/15 09:03 [entrez]
AID - 00006123-202312000-00018 [pii]
AID - 10.1227/neu.0000000000002632 [doi]
PST - ppublish
SO  - Neurosurgery. 2023 Dec 1;93(6):1353-1365. doi: 10.1227/neu.0000000000002632. Epub 
      2023 Aug 15.

PMID- 37023599
OWN - NLM
STAT- MEDLINE
DCOM- 20230502
LR  - 20231130
IS  - 1878-0539 (Electronic)
IS  - 1748-6815 (Linking)
VI  - 80
DP  - 2023 May
TI  - Utilization of ChatGPT for Plastic Surgery Research: Friend or Foe?
PG  - 145-147
LID - S1748-6815(23)00136-5 [pii]
LID - 10.1016/j.bjps.2023.03.004 [doi]
AB  - On November 20, 2022, ChatGPT was made available to the general public free of 
      charge. As a large language model (LLM), the software was able to process 
      inquiries by users and generate text based on compiled datasets in a humanist 
      manner. Due to the importance of research in the Plastic Surgery community, we 
      set out to determine if ChatGPT could be utilized to produce novel systematic 
      review ideas relevant to Plastic Surgery. Out of 80 systematic review ideas 
      generated by ChatGPT, we found that the software was highly accurate in creating 
      novel systematic review ideas. Beyond aiding in Plastic Surgery research, ChatGPT 
      has the potential to be used for virtual consultations, pre-operative planning, 
      patient education, and post-operative care for patients. ChatGPT may be a simple 
      solution for the complex problems encountered in Plastic Surgery.
CI  - Copyright © 2023 British Association of Plastic, Reconstructive and Aesthetic 
      Surgeons. Published by Elsevier Ltd. All rights reserved.
FAU - Gupta, Rohun
AU  - Gupta R
AD  - Oakland University William Beaumont School of Medicine, Rochester, MI, USA. 
      Electronic address: rgupta@oakland.edu.
FAU - Herzog, Isabel
AU  - Herzog I
AD  - Department of Plastic Surgery, Rutgers New Jersey School of Medicine, Newark, NJ, 
      USA.
FAU - Weisberger, Joseph
AU  - Weisberger J
AD  - Department of Plastic Surgery, Rutgers New Jersey School of Medicine, Newark, NJ, 
      USA.
FAU - Chao, John
AU  - Chao J
AD  - Department of Plastic Surgery, Rutgers New Jersey School of Medicine, Newark, NJ, 
      USA.
FAU - Chaiyasate, Kongkrit
AU  - Chaiyasate K
AD  - Oakland University William Beaumont School of Medicine, Rochester, MI, USA.
FAU - Lee, Edward S
AU  - Lee ES
AD  - Department of Plastic Surgery, Rutgers New Jersey School of Medicine, Newark, NJ, 
      USA.
LA  - eng
PT  - Journal Article
PT  - Systematic Review
DEP - 20230321
PL  - Netherlands
TA  - J Plast Reconstr Aesthet Surg
JT  - Journal of plastic, reconstructive &amp; aesthetic surgery : JPRAS
JID - 101264239
SB  - IM
CIN - J Plast Reconstr Aesthet Surg. 2023 Jul;82:275. PMID: 37209600
CIN - Aesthet Surg J. 2023 Aug 17;43(9):NP726-NP727. PMID: 37227006
MH  - Humans
MH  - Language
MH  - *Plastic Surgery Procedures
MH  - Postoperative Care
MH  - Referral and Consultation
MH  - *Surgery, Plastic
OTO - NOTNLM
OT  - AI
OT  - Artificial intelligence
OT  - Education
OT  - Systematic reviews
EDAT- 2023/04/07 06:00
MHDA- 2023/05/02 06:42
CRDT- 2023/04/06 18:06
PHST- 2023/02/22 00:00 [received]
PHST- 2023/02/24 00:00 [revised]
PHST- 2023/03/15 00:00 [accepted]
PHST- 2023/05/02 06:42 [medline]
PHST- 2023/04/07 06:00 [pubmed]
PHST- 2023/04/06 18:06 [entrez]
AID - S1748-6815(23)00136-5 [pii]
AID - 10.1016/j.bjps.2023.03.004 [doi]
PST - ppublish
SO  - J Plast Reconstr Aesthet Surg. 2023 May;80:145-147. doi: 
      10.1016/j.bjps.2023.03.004. Epub 2023 Mar 21.

PMID- 37477707
OWN - NLM
STAT- Publisher
LR  - 20230721
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
DP  - 2023 Jul 21
TI  - ChatGPT as a Complementary Mental Health Resource: A Boon or a Bane.
LID - 10.1007/s10439-023-03326-7 [doi]
AB  - The launch of Open AI's chatbot, ChatGPT, has generated a lot of attention and 
      discussion among professionals in several fields. Many concerns and challenges 
      have been brought up by researchers from various fields, particularly in relation 
      to the harm that using these tools for medical diagnosis and treatment 
      recommendations can cause. In addition, it has been debated if ChatGPT is 
      dependable, efficient, and helpful for clinicians and medical professionals. 
      Therefore, in this study, we assess ChatGPT's effectiveness in providing mental 
      health support, particularly for issues related to anxiety and depression, based 
      on the chatbot's responses and cross-questioning. The findings indicate that 
      there are significant inconsistencies and that ChatGPT's reliability is low in 
      this specific domain. As a result, care must be used when using ChatGPT as a 
      complementary mental health resource.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Farhat, Faiza
AU  - Farhat F
AUID- ORCID: 0000-0002-1310-1586
AD  - Section of Parasitology, Department of Zoology, Aligarh Muslim University, 
      Aligarh, UP, 202002, India. faizahaque16@gmail.com.
LA  - eng
PT  - Letter
DEP - 20230721
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
OTO - NOTNLM
OT  - Anxiety
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Depression
OT  - Large language model
OT  - Mental health
EDAT- 2023/07/21 13:15
MHDA- 2023/07/21 13:15
CRDT- 2023/07/21 11:06
PHST- 2023/07/14 00:00 [received]
PHST- 2023/07/17 00:00 [accepted]
PHST- 2023/07/21 13:15 [medline]
PHST- 2023/07/21 13:15 [pubmed]
PHST- 2023/07/21 11:06 [entrez]
AID - 10.1007/s10439-023-03326-7 [pii]
AID - 10.1007/s10439-023-03326-7 [doi]
PST - aheadofprint
SO  - Ann Biomed Eng. 2023 Jul 21. doi: 10.1007/s10439-023-03326-7.

PMID- 37824352
OWN - NLM
STAT- MEDLINE
DCOM- 20231101
LR  - 20231115
IS  - 1972-2680 (Electronic)
IS  - 1972-2680 (Linking)
VI  - 17
IP  - 9
DP  - 2023 Sep 30
TI  - ChatGPT: ethical concerns and challenges in academics and research.
PG  - 1292-1299
LID - 10.3855/jidc.18738 [doi]
AB  - INTRODUCTION: The emergence of artificial intelligence (AI) has presented several 
      opportunities to ease human work. AI applications are available for almost every 
      domain of life. A new technology, Chat Generative Pre-Trained Transformer 
      (ChatGPT), was introduced by OpenAI in November 2022, and has become a topic of 
      discussion across the world. ChatGPT-3 has brought many opportunities, as well as 
      ethical and privacy considerations. ChatGPT is a large language model (LLM) which 
      has been trained on the events that happened until 2021. The use of AI and its 
      assisted technologies in scientific writing is against research and publication 
      ethics. Therefore, policies and guidelines need to be developed over the use of 
      such tools in scientific writing. The main objective of the present study was to 
      highlight the use of AI and AI assisted technologies such as the ChatGPT and 
      other chatbots in the scientific writing and in the research domain resulting in 
      bias, spread of inaccurate information and plagiarism. METHODOLOGY: Experiments 
      were designed to test the accuracy of ChatGPT when used in research and academic 
      writing. RESULTS: The information provided by ChatGPT was inaccurate and may have 
      far-reaching implications in the field of medical science and engineering. 
      Critical thinking should be encouraged among researchers to raise awareness about 
      the associated privacy and ethical risks. CONCLUSIONS: Regulations for ethical 
      and privacy concerns related to the use of ChatGPT in academics and research need 
      to be developed.
CI  - Copyright (c) 2023 Ankita Guleria, Kewal Krishan, Vishal Sharma, Tanuj Kanchan.
FAU - Guleria, Ankita
AU  - Guleria A
AD  - Department of Anthropology, Panjab University, Sector-14, Chandigarh, India.
FAU - Krishan, Kewal
AU  - Krishan K
AD  - Department of Anthropology, Panjab University, Sector-14, Chandigarh, India.
FAU - Sharma, Vishal
AU  - Sharma V
AD  - Institute of Forensic Science and Criminology, Panjab University, Sector-14, 
      Chandigarh, India.
FAU - Kanchan, Tanuj
AU  - Kanchan T
AD  - Department of Forensic Medicine and Toxicology, All India Institute of Medical 
      Sciences, Jodhpur, India.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20230930
PL  - Italy
TA  - J Infect Dev Ctries
JT  - Journal of infection in developing countries
JID - 101305410
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Organizations
OTO - NOTNLM
OT  - ChatGPT
OT  - Open AI
OT  - artificial intelligence
OT  - chatbot
OT  - privacy concerns
OT  - publication ethics
COIS- No Conflict of Interest is declared
EDAT- 2023/10/12 18:42
MHDA- 2023/11/01 12:44
CRDT- 2023/10/12 12:43
PHST- 2023/06/14 00:00 [received]
PHST- 2023/07/12 00:00 [accepted]
PHST- 2023/11/01 12:44 [medline]
PHST- 2023/10/12 18:42 [pubmed]
PHST- 2023/10/12 12:43 [entrez]
AID - 10.3855/jidc.18738 [doi]
PST - epublish
SO  - J Infect Dev Ctries. 2023 Sep 30;17(9):1292-1299. doi: 10.3855/jidc.18738.

PMID- 37264670
OWN - NLM
STAT- Publisher
LR  - 20230602
IS  - 1365-2230 (Electronic)
IS  - 0307-6938 (Linking)
DP  - 2023 Jun 2
TI  - Performance of ChatGPT on dermatology Specialty Certificate Examination multiple 
      choice questions.
LID - llad197 [pii]
LID - 10.1093/ced/llad197 [doi]
AB  - ChatGPT is a large language model trained on increasingly large datasets by 
      OpenAI to perform language-based tasks. It is capable of answering 
      multiple-choice questions, such as those posed by the dermatology SCE 
      examination. We asked two iterations of ChatGPT: ChatGPT-3.5 and ChatGPT-4 84 
      multiple-choice sample questions from the sample dermatology SCE question bank. 
      ChatGPT-3.5 achieved an overall score of 63.1%, and ChatGPT-4 scored 90.5% (a 
      significant improvement in performance (p&lt;0.001)). The typical pass mark for the 
      dermatology SCE is 70-72%. ChatGPT-4 is therefore capable of answering clinical 
      questions and achieving a passing grade in these sample questions. There are many 
      possible educational and clinical implications for increasingly advanced 
      artificial intelligence (AI) and its use in medicine, including in the diagnosis 
      of dermatological conditions. Such advances should be embraced provided that 
      patient safety is a core tenet, and the limitations of AI in the nuances of 
      complex clinical cases are recognised.
CI  - © The Author(s) 2023. Published by Oxford University Press on behalf of British 
      Association of Dermatologists. All rights reserved. For permissions, please 
      e-mail: journals.permissions@oup.com.
FAU - Passby, Lauren
AU  - Passby L
AD  - Department of Dermatology, Solihull Hospital, University Hospitals Birmingham NHS 
      Foundation Trust, UK.
FAU - Jenko, Nathan
AU  - Jenko N
AD  - Department of Radiology, The Royal Orthopaedic Hospital NHS Foundation Trust, UK.
FAU - Wernham, Aaron
AU  - Wernham A
AUID- ORCID: 0000-0001-5920-6888
AD  - Department of Dermatology, Leicester Royal Infirmary, Leicester, UK.
AD  - Department of Dermatology, Manor Hospital, Walsall Healthcare NHS Trust, Walsall, 
      UK.
LA  - eng
PT  - Journal Article
DEP - 20230602
PL  - England
TA  - Clin Exp Dermatol
JT  - Clinical and experimental dermatology
JID - 7606847
SB  - IM
EDAT- 2023/06/02 06:42
MHDA- 2023/06/02 06:42
CRDT- 2023/06/02 03:44
PHST- 2023/05/25 00:00 [received]
PHST- 2023/05/26 00:00 [accepted]
PHST- 2023/06/02 06:42 [medline]
PHST- 2023/06/02 06:42 [pubmed]
PHST- 2023/06/02 03:44 [entrez]
AID - 7188526 [pii]
AID - 10.1093/ced/llad197 [doi]
PST - aheadofprint
SO  - Clin Exp Dermatol. 2023 Jun 2:llad197. doi: 10.1093/ced/llad197.

PMID- 37719492
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230919
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 8
DP  - 2023 Aug
TI  - The Expanding Role of ChatGPT (Chat-Generative Pre-Trained Transformer) in 
      Neurosurgery: A Systematic Review of Literature and Conceptual Framework.
PG  - e43502
LID - 10.7759/cureus.43502 [doi]
LID - e43502
AB  - The objective of this study is to explore the use of ChatGPT&nbsp;(Chat-Generative 
      Pre-Trained Transformer) in neurosurgery and its potential impact on the field. 
      The authors aim to discuss, through a systematic review of current literature, 
      how this rising new artificial intelligence (AI) technology may prove to be a 
      useful tool in the future, weighing its potential benefits and limitations.&nbsp;The 
      authors conducted a comprehensive and systematic literature review of the use of 
      ChatGPT and its applications in healthcare and different neurosurgery topics. 
      Through a systematic review of the literature, with a search strategy using the 
      databases such as PubMed, Google Scholar, and Embase, we analyzed the advantages 
      and limitations of using ChatGPT in neurosurgery and evaluated its potential 
      impact.&nbsp;ChatGPT has demonstrated promising results in various applications, such 
      as natural language processing, language translation, and text summarization. In 
      neurosurgery, ChatGPT can assist in different areas such as surgical planning, 
      image recognition, medical diagnosis, patient care, and scientific production. A 
      total of 128 articles were retrieved from databases, where the final 22 articles 
      were included for thorough analysis. The studies reviewed demonstrate the 
      potential of AI and deep learning (DL), through language models such as ChatGPT, 
      to improve the accuracy and efficiency of neurosurgical procedures, as well as 
      diagnosis, treatment, and patient outcomes across various medical specialties, 
      including neurosurgery. There are, however, limitations to its use, including the 
      need for large datasets and the potential for errors in the output, which most 
      authors concur will need human verification for the final application.&nbsp;Our search 
      demonstrated the potential that ChatGPT holds for the present and future, in 
      accordance with the studies'&nbsp;authors' findings herein analyzed and expert 
      opinions. Further research and development are required to fully understand its 
      capabilities and limitations. AI technology can serve as a useful tool to augment 
      human intelligence; however, it is essential to use it in a responsible and 
      ethical manner.
CI  - Copyright © 2023, Roman et al.
FAU - Roman, Alex
AU  - Roman A
AD  - Neurological Surgery, Cleveland Clinic Abu Dhabi, Abu Dhabi, ARE.
FAU - Al-Sharif, Lubna
AU  - Al-Sharif L
AD  - Physiology, Pharmacology and Toxicology, An-Najah National University, Nablus, 
      PSE.
FAU - Al Gharyani, Mohamed
AU  - Al Gharyani M
AD  - Neurosurgery, University of Benghazi, Benghazi, LBY.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230815
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10500385
OTO - NOTNLM
OT  - ai &amp; robotics in healthcare
OT  - artificial intelligence
OT  - chatgpt
OT  - deep learning
OT  - neurosurgery
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/09/18 06:42
MHDA- 2023/09/18 06:43
PMCR- 2023/08/15
CRDT- 2023/09/18 04:22
PHST- 2023/08/15 00:00 [accepted]
PHST- 2023/09/18 06:43 [medline]
PHST- 2023/09/18 06:42 [pubmed]
PHST- 2023/09/18 04:22 [entrez]
PHST- 2023/08/15 00:00 [pmc-release]
AID - 10.7759/cureus.43502 [doi]
PST - epublish
SO  - Cureus. 2023 Aug 15;15(8):e43502. doi: 10.7759/cureus.43502. eCollection 2023 
      Aug.

PMID- 37812468
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231026
IS  - 2291-9694 (Print)
IS  - 2291-9694 (Electronic)
VI  - 11
DP  - 2023 Oct 9
TI  - ChatGPT-Generated Differential Diagnosis Lists for Complex Case-Derived Clinical 
      Vignettes: Diagnostic Accuracy Evaluation.
PG  - e48808
LID - 10.2196/48808 [doi]
LID - e48808
AB  - BACKGROUND: The diagnostic accuracy of differential diagnoses generated by 
      artificial intelligence chatbots, including ChatGPT models, for complex clinical 
      vignettes derived from general internal medicine (GIM) department case reports is 
      unknown. OBJECTIVE: This study aims to evaluate the accuracy of the differential 
      diagnosis lists generated by both third-generation ChatGPT (ChatGPT-3.5) and 
      fourth-generation ChatGPT (ChatGPT-4) by using case vignettes from case reports 
      published by the Department of GIM of Dokkyo Medical University Hospital, Japan. 
      METHODS: We searched PubMed for case reports. Upon identification, physicians 
      selected diagnostic cases, determined the final diagnosis, and displayed them 
      into clinical vignettes. Physicians typed the determined text with the clinical 
      vignettes in the ChatGPT-3.5 and ChatGPT-4 prompts to generate the top 10 
      differential diagnoses. The ChatGPT models were not specially trained or further 
      reinforced for this task. Three GIM physicians from other medical institutions 
      created differential diagnosis lists by reading the same clinical vignettes. We 
      measured the rate of correct diagnosis within the top 10 differential diagnosis 
      lists, top 5 differential diagnosis lists, and the top diagnosis. RESULTS: In 
      total, 52 case reports were analyzed. The rates of correct diagnosis by ChatGPT-4 
      within the top 10 differential diagnosis lists, top 5 differential diagnosis 
      lists, and top diagnosis were 83% (43/52), 81% (42/52), and 60% (31/52), 
      respectively. The rates of correct diagnosis by ChatGPT-3.5 within the top 10 
      differential diagnosis lists, top 5 differential diagnosis lists, and top 
      diagnosis were 73% (38/52), 65% (34/52), and 42% (22/52), respectively. The rates 
      of correct diagnosis by ChatGPT-4 were comparable to those by physicians within 
      the top 10 (43/52, 83% vs 39/52, 75%, respectively; P=.47) and within the top 5 
      (42/52, 81% vs 35/52, 67%, respectively; P=.18) differential diagnosis lists and 
      top diagnosis (31/52, 60% vs 26/52, 50%, respectively; P=.43) although the 
      difference was not significant. The ChatGPT models' diagnostic accuracy did not 
      significantly vary based on open access status or the publication date (before 
      2011 vs 2022). CONCLUSIONS: This study demonstrates the potential diagnostic 
      accuracy of differential diagnosis lists generated using ChatGPT-3.5 and 
      ChatGPT-4 for complex clinical vignettes from case reports published by the GIM 
      department. The rate of correct diagnoses within the top 10 and top 5 
      differential diagnosis lists generated by ChatGPT-4 exceeds 80%. Although derived 
      from a limited data set of case reports from a single department, our findings 
      highlight the potential utility of ChatGPT-4 as a supplementary tool for 
      physicians, particularly for those affiliated with the GIM department. Further 
      investigations should explore the diagnostic accuracy of ChatGPT by using 
      distinct case materials beyond its training data. Such efforts will provide a 
      comprehensive insight into the role of artificial intelligence in enhancing 
      clinical decision-making.
CI  - ©Takanobu Hirosawa, Ren Kawamura, Yukinori Harada, Kazuya Mizuta, Kazuki 
      Tokumasu, Yuki Kaji, Tomoharu Suzuki, Taro Shimizu. Originally published in JMIR 
      Medical Informatics (https://medinform.jmir.org), 09.10.2023.
FAU - Hirosawa, Takanobu
AU  - Hirosawa T
AUID- ORCID: 0000-0002-3573-8203
AD  - Department of Diagnostic and Generalist Medicine, Dokkyo Medical University, 
      Tochigi, Japan.
FAU - Kawamura, Ren
AU  - Kawamura R
AUID- ORCID: 0000-0002-5632-3218
AD  - Department of Diagnostic and Generalist Medicine, Dokkyo Medical University, 
      Tochigi, Japan.
FAU - Harada, Yukinori
AU  - Harada Y
AUID- ORCID: 0000-0001-6042-7397
AD  - Department of Diagnostic and Generalist Medicine, Dokkyo Medical University, 
      Tochigi, Japan.
FAU - Mizuta, Kazuya
AU  - Mizuta K
AUID- ORCID: 0009-0000-8822-7127
AD  - Department of Diagnostic and Generalist Medicine, Dokkyo Medical University, 
      Tochigi, Japan.
FAU - Tokumasu, Kazuki
AU  - Tokumasu K
AUID- ORCID: 0000-0001-9513-6864
AD  - Department of General Medicine, Okayama University Graduate School of Medicine, 
      Dentistry and Pharmaceutical Sciences, Okayama, Japan.
FAU - Kaji, Yuki
AU  - Kaji Y
AUID- ORCID: 0000-0002-0267-9876
AD  - Department of General Medicine, International University of Health and Welfare 
      Narita Hospital, Chiba, Japan.
FAU - Suzuki, Tomoharu
AU  - Suzuki T
AUID- ORCID: 0000-0002-5557-0516
AD  - Department of Hospital Medicine, Urasoe General Hospital, Okinawa, Japan.
FAU - Shimizu, Taro
AU  - Shimizu T
AUID- ORCID: 0000-0002-3788-487X
AD  - Department of Diagnostic and Generalist Medicine, Dokkyo Medical University, 
      Tochigi, Japan.
LA  - eng
PT  - Journal Article
DEP - 20231009
PL  - Canada
TA  - JMIR Med Inform
JT  - JMIR medical informatics
JID - 101645109
PMC - PMC10594139
OTO - NOTNLM
OT  - AI chatbot
OT  - ChatGPT
OT  - accuracy
OT  - artificial intelligence
OT  - case study
OT  - clinical decision support
OT  - decision support
OT  - diagnosis
OT  - diagnostic
OT  - diagnostic excellence
OT  - language model
OT  - large language models
OT  - natural language processing
OT  - vignette
COIS- Conflicts of Interest: None declared.
EDAT- 2023/10/09 12:43
MHDA- 2023/10/09 12:44
PMCR- 2023/10/09
CRDT- 2023/10/09 11:53
PHST- 2023/05/09 00:00 [received]
PHST- 2023/09/13 00:00 [accepted]
PHST- 2023/07/20 00:00 [revised]
PHST- 2023/10/09 12:44 [medline]
PHST- 2023/10/09 12:43 [pubmed]
PHST- 2023/10/09 11:53 [entrez]
PHST- 2023/10/09 00:00 [pmc-release]
AID - v11i1e48808 [pii]
AID - 10.2196/48808 [doi]
PST - epublish
SO  - JMIR Med Inform. 2023 Oct 9;11:e48808. doi: 10.2196/48808.

PMID- 37149512
OWN - NLM
STAT- MEDLINE
DCOM- 20230809
LR  - 20231213
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 51
IP  - 9
DP  - 2023 Sep
TI  - ChatGPT Applications and Challenges in Controlling Monkey Pox in Pakistan.
PG  - 1889-1891
LID - 10.1007/s10439-023-03231-z [doi]
AB  - Generative Pre-trained Transformer-based Chatbot (ChatGPT) is an emerging OpenAI 
      application with its greater role in revolutionizing the world. ChatGPT can 
      generate a massive amount of data by using the simple textual input. ChatGPT has 
      its role in supporting the communities to make deciding role in healthcare 
      sector. This paper aims to provide information about monkey pox (mpox) infection 
      in Pakistan. Moreover, this paper analyzes the text-based information given by 
      ChatGPT and narrates potential advantages and disadvantages about mpox infection. 
      Spread of infection, symptoms and diagnose of mpox, control and management, and 
      government responsibilities are major identified advantages. Findings of this 
      paper also show some potential issues of ChatGPT AI application, which are as 
      lack of latest data about mpox in Pakistan, reliability and performance issues, 
      cost and resources for appropriate development and implementation of Open AI 
      application in healthcare. Future works can be carried out to address these 
      limitations in ChatGPT AI application.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Hasnain, Muhammad
AU  - Hasnain M
AD  - Lahore Leads University, Lahore, Pakistan. drhasnain.it@leads.edu.pk.
AD  - Department of Computer Science, Lahore Leads University, Lahore, Pakistan. 
      drhasnain.it@leads.edu.pk.
LA  - eng
PT  - Letter
DEP - 20230506
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - Humans
MH  - Pakistan
MH  - *Mpox (monkeypox)
MH  - Reproducibility of Results
MH  - Electric Power Supplies
MH  - Software
OTO - NOTNLM
OT  - Accurate prediction
OT  - Cost
OT  - Monkey pox transmission
OT  - Vaccine
EDAT- 2023/05/07 00:42
MHDA- 2023/08/09 06:43
CRDT- 2023/05/06 23:03
PHST- 2023/05/01 00:00 [received]
PHST- 2023/05/02 00:00 [accepted]
PHST- 2023/08/09 06:43 [medline]
PHST- 2023/05/07 00:42 [pubmed]
PHST- 2023/05/06 23:03 [entrez]
AID - 10.1007/s10439-023-03231-z [pii]
AID - 10.1007/s10439-023-03231-z [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2023 Sep;51(9):1889-1891. doi: 10.1007/s10439-023-03231-z. Epub 
      2023 May 6.

PMID- 37265864
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230804
IS  - 2634-3916 (Electronic)
IS  - 2634-3916 (Linking)
VI  - 4
IP  - 3
DP  - 2023 May
TI  - ChatGPT takes on the European Exam in Core Cardiology: an artificial intelligence 
      success story?
PG  - 279-281
LID - 10.1093/ehjdh/ztad029 [doi]
AB  - Chat Generative Pre-trained Transformer (ChatGPT) is currently a trending topic 
      worldwide triggering extensive debate about its predictive power, its potential 
      uses, and its wider implications. Recent publications have demonstrated that 
      ChatGPT can correctly answer questions from undergraduate exams such as the 
      United States Medical Licensing Examination. We challenged it to answer questions 
      from a more demanding, post-graduate exam-the European Exam in Core Cardiology 
      (EECC), the final exam for the completion of specialty training in Cardiology in 
      many countries. Our results demonstrate that ChatGPT succeeds in the EECC.
CI  - © The Author(s) 2023. Published by Oxford University Press on behalf of the 
      European Society of Cardiology.
FAU - Skalidis, Ioannis
AU  - Skalidis I
AUID- ORCID: 0000-0002-4374-0389
AD  - Cardiology Department, University Hospital of Lausanne, Rue du Bugnon 46, 1011 
      Lausanne, Switzerland.
FAU - Cagnina, Aurelien
AU  - Cagnina A
AD  - Cardiology Department, University Hospital of Lausanne, Rue du Bugnon 46, 1011 
      Lausanne, Switzerland.
FAU - Luangphiphat, Wongsakorn
AU  - Luangphiphat W
AD  - Cardiology Department, University Hospital of Lausanne, Rue du Bugnon 46, 1011 
      Lausanne, Switzerland.
FAU - Mahendiran, Thabo
AU  - Mahendiran T
AD  - Cardiology Department, University Hospital of Lausanne, Rue du Bugnon 46, 1011 
      Lausanne, Switzerland.
AD  - Institute of Mathematics and School of Computer and Communication Sciences, EPFL, 
      EPFL FSB SMA, Station 8,1015 Lausanne, Switzerland.
FAU - Muller, Olivier
AU  - Muller O
AUID- ORCID: 0000-0003-2441-5799
AD  - Cardiology Department, University Hospital of Lausanne, Rue du Bugnon 46, 1011 
      Lausanne, Switzerland.
FAU - Abbe, Emmanuel
AU  - Abbe E
AD  - Institute of Mathematics and School of Computer and Communication Sciences, EPFL, 
      EPFL FSB SMA, Station 8,1015 Lausanne, Switzerland.
FAU - Fournier, Stephane
AU  - Fournier S
AUID- ORCID: 0000-0002-9422-9521
AD  - Cardiology Department, University Hospital of Lausanne, Rue du Bugnon 46, 1011 
      Lausanne, Switzerland.
LA  - eng
PT  - Journal Article
DEP - 20230424
PL  - England
TA  - Eur Heart J Digit Health
JT  - European heart journal. Digital health
JID - 101778323
EIN - Eur Heart J Digit Health. 2023 May 17;4(4):357. PMID: 37538140
PMC - PMC10232281
OTO - NOTNLM
OT  - Artificial Intelligence
OT  - ChatGPT
OT  - Large language models
OT  - Machine learning
OT  - Medical education
COIS- Conflict of interest: None declared.
EDAT- 2023/06/02 13:16
MHDA- 2023/06/02 13:17
PMCR- 2023/04/24
CRDT- 2023/06/02 10:51
PHST- 2023/02/18 00:00 [received]
PHST- 2023/04/12 00:00 [revised]
PHST- 2023/04/21 00:00 [accepted]
PHST- 2023/06/02 13:17 [medline]
PHST- 2023/06/02 13:16 [pubmed]
PHST- 2023/06/02 10:51 [entrez]
PHST- 2023/04/24 00:00 [pmc-release]
AID - ztad029 [pii]
AID - 10.1093/ehjdh/ztad029 [doi]
PST - epublish
SO  - Eur Heart J Digit Health. 2023 Apr 24;4(3):279-281. doi: 10.1093/ehjdh/ztad029. 
      eCollection 2023 May.

PMID- 37160568
OWN - NLM
STAT- MEDLINE
DCOM- 20230511
LR  - 20230511
IS  - 1573-689X (Electronic)
IS  - 0148-5598 (Linking)
VI  - 47
IP  - 1
DP  - 2023 May 9
TI  - Revolutionizing Medical Education: Can ChatGPT Boost Subjective Learning and 
      Expression?
PG  - 61
LID - 10.1007/s10916-023-01957-w [doi]
AB  - ChatGPT is an AI tool that can be used to enhance medical education by helping 
      students develop subjective learning and expression skills. These skills are 
      critical in clinical practice, but the current medical education system is 
      heavily focused on objective assessments, such as Multiple Choice Questions 
      (MCQs). Students from non-English speaking backgrounds can particularly struggle 
      with expressing themselves in English, which is the primary language of 
      instruction in many medical schools worldwide. ChatGPT can provide additional 
      language support for these students to help them develop their language skills 
      and communicate effectively. ChatGPT can be used in small group assessments to 
      serve as a benchmark for students to strive for in their medical education. By 
      comparing their answers to ChatGPT's responses, students can identify gaps in 
      their knowledge and work to fill them. ChatGPT can also provide students with 
      feedback on their writing style and language usage, helping them to improve their 
      subjective expression of medical knowledge. Furthermore, ChatGPT can be used to 
      simulate patient encounters for medical students. By interacting with ChatGPT, 
      students can practice taking medical histories and documenting symptoms 
      accurately. In continuing medical education (CME) programs, physicians can also 
      benefit from ChatGPT's capabilities. By using ChatGPT to search for the latest 
      research articles, clinical trials, and treatment guidelines, physicians can stay 
      informed and provide the best care possible to their patients. Overall, ChatGPT 
      has the potential to be a valuable tool in medical education by helping students 
      and physicians develop the essential skills required for clinical practice, such 
      as communication, problem-solving, and critical thinking.
CI  - © 2023. The Author(s), under exclusive licence to Springer Science+Business 
      Media, LLC, part of Springer Nature.
FAU - Seetharaman, Rajmohan
AU  - Seetharaman R
AUID- ORCID: 0000-0002-4605-2805
AD  - Department of Pharmacology and Therapeutics, Seth G.S. Medical College &amp; KEM 
      Hospital, Parel, Mumbai, 400012, India. rajmohan.seetharaman@gmail.com.
LA  - eng
PT  - Letter
DEP - 20230509
PL  - United States
TA  - J Med Syst
JT  - Journal of medical systems
JID - 7806056
SB  - IM
MH  - Humans
MH  - *Learning
MH  - *Students
MH  - Cognition
MH  - Education, Medical, Continuing
MH  - Benchmarking
EDAT- 2023/05/10 00:41
MHDA- 2023/05/11 06:42
CRDT- 2023/05/09 22:50
PHST- 2023/04/11 00:00 [received]
PHST- 2023/04/20 00:00 [accepted]
PHST- 2023/05/11 06:42 [medline]
PHST- 2023/05/10 00:41 [pubmed]
PHST- 2023/05/09 22:50 [entrez]
AID - 10.1007/s10916-023-01957-w [pii]
AID - 10.1007/s10916-023-01957-w [doi]
PST - epublish
SO  - J Med Syst. 2023 May 9;47(1):61. doi: 10.1007/s10916-023-01957-w.

PMID- 37928447
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231107
IS  - 2624-8212 (Electronic)
IS  - 2624-8212 (Linking)
VI  - 6
DP  - 2023
TI  - Revisiting the political biases of ChatGPT.
PG  - 1232003
LID - 10.3389/frai.2023.1232003 [doi]
LID - 1232003
AB  - Although ChatGPT promises wide-ranging applications, there is a concern that it 
      is politically biased; in particular, that it has a left-libertarian orientation. 
      Nevertheless, following recent trends in attempts to reduce such biases, this 
      study re-evaluated the political biases of ChatGPT using political orientation 
      tests and the application programming interface. The effects of the languages 
      used in the system as well as gender and race settings were evaluated. The 
      results indicate that ChatGPT manifests less political bias than previously 
      assumed; however, they did not entirely dismiss the political bias. The languages 
      used in the system, and the gender and race settings may induce political biases. 
      These findings enhance our understanding of the political biases of ChatGPT and 
      may be useful for bias evaluation and designing the operational strategy of 
      ChatGPT.
CI  - Copyright © 2023 Fujimoto and Takemoto.
FAU - Fujimoto, Sasuke
AU  - Fujimoto S
AD  - Department of Bioscience and Bioinformatics, Kyushu Institute of Technology, 
      Iizuka, Fukuoka, Japan.
FAU - Takemoto, Kazuhiro
AU  - Takemoto K
AD  - Department of Bioscience and Bioinformatics, Kyushu Institute of Technology, 
      Iizuka, Fukuoka, Japan.
LA  - eng
PT  - Journal Article
DEP - 20231020
PL  - Switzerland
TA  - Front Artif Intell
JT  - Frontiers in artificial intelligence
JID - 101770551
PMC - PMC10623051
OTO - NOTNLM
OT  - ChatGPT
OT  - algorithm bias
OT  - large-language model
OT  - natural language processing
OT  - political bias
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/11/06 06:42
MHDA- 2023/11/06 06:43
PMCR- 2023/10/20
CRDT- 2023/11/06 04:33
PHST- 2023/05/31 00:00 [received]
PHST- 2023/10/04 00:00 [accepted]
PHST- 2023/11/06 06:43 [medline]
PHST- 2023/11/06 06:42 [pubmed]
PHST- 2023/11/06 04:33 [entrez]
PHST- 2023/10/20 00:00 [pmc-release]
AID - 10.3389/frai.2023.1232003 [doi]
PST - epublish
SO  - Front Artif Intell. 2023 Oct 20;6:1232003. doi: 10.3389/frai.2023.1232003. 
      eCollection 2023.

PMID- 38051578
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231222
IS  - 2369-3762 (Print)
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Dec 5
TI  - ChatGPT Versus Consultants: Blinded Evaluation on Answering Otorhinolaryngology 
      Case-Based Questions.
PG  - e49183
LID - 10.2196/49183 [doi]
LID - e49183
AB  - BACKGROUND: Large language models (LLMs), such as ChatGPT (Open AI), are 
      increasingly used in medicine and supplement standard search engines as 
      information sources. This leads to more "consultations" of LLMs about personal 
      medical symptoms. OBJECTIVE: This study aims to evaluate ChatGPT's performance in 
      answering clinical case-based questions in otorhinolaryngology (ORL) in 
      comparison to ORL consultants' answers. METHODS: We used 41 case-based questions 
      from established ORL study books and past German state examinations for doctors. 
      The questions were answered by both ORL consultants and ChatGPT 3. ORL 
      consultants rated all responses, except their own, on medical adequacy, 
      conciseness, coherence, and comprehensibility using a 6-point Likert scale. They 
      also identified (in a blinded setting) if the answer was created by an ORL 
      consultant or ChatGPT. Additionally, the character count was compared. Due to the 
      rapidly evolving pace of technology, a comparison between responses generated by 
      ChatGPT 3 and ChatGPT 4 was included to give an insight into the evolving 
      potential of LLMs. RESULTS: Ratings in all categories were significantly higher 
      for ORL consultants (P&lt;.001). Although inferior to the scores of the ORL 
      consultants, ChatGPT's scores were relatively higher in semantic categories 
      (conciseness, coherence, and comprehensibility) compared to medical adequacy. ORL 
      consultants identified ChatGPT as the source correctly in 98.4% (121/123) of 
      cases. ChatGPT's answers had a significantly higher character count compared to 
      ORL consultants (P&lt;.001). Comparison between responses generated by ChatGPT 3 and 
      ChatGPT 4 showed a slight improvement in medical accuracy as well as a better 
      coherence of the answers provided. Contrarily, neither the conciseness (P=.06) 
      nor the comprehensibility (P=.08) improved significantly despite the significant 
      increase in the mean amount of characters by 52.5% (n= (1470-964)/964; P&lt;.001). 
      CONCLUSIONS: While ChatGPT provided longer answers to medical problems, medical 
      adequacy and conciseness were significantly lower compared to ORL consultants' 
      answers. LLMs have potential as augmentative tools for medical care, but their 
      "consultation" for medical problems carries a high risk of misinformation as 
      their high semantic quality may mask contextual deficits.
CI  - ©Christoph Raphael Buhr, Harry Smith, Tilman Huppertz, Katharina Bahr-Hamm, 
      Christoph Matthias, Andrew Blaikie, Tom Kelsey, Sebastian Kuhn, Jonas Eckrich. 
      Originally published in JMIR Medical Education (https://mededu.jmir.org), 
      05.12.2023.
FAU - Buhr, Christoph Raphael
AU  - Buhr CR
AUID- ORCID: 0000-0002-9551-2310
AD  - Department of Otorhinolaryngology, University Medical Center of the Johannes 
      Gutenberg-University Mainz, Mainz, Germany.
AD  - School of Medicine, University of St Andrews, St Andrews, United Kingdom.
FAU - Smith, Harry
AU  - Smith H
AUID- ORCID: 0009-0003-4497-1394
AD  - School of Computer Science, University of St Andrews, St Andrews, United Kingdom.
FAU - Huppertz, Tilman
AU  - Huppertz T
AUID- ORCID: 0000-0003-0654-3551
AD  - Department of Otorhinolaryngology, University Medical Center of the Johannes 
      Gutenberg-University Mainz, Mainz, Germany.
FAU - Bahr-Hamm, Katharina
AU  - Bahr-Hamm K
AUID- ORCID: 0000-0001-7428-127X
AD  - Department of Otorhinolaryngology, University Medical Center of the Johannes 
      Gutenberg-University Mainz, Mainz, Germany.
FAU - Matthias, Christoph
AU  - Matthias C
AUID- ORCID: 0000-0002-7569-2393
AD  - Department of Otorhinolaryngology, University Medical Center of the Johannes 
      Gutenberg-University Mainz, Mainz, Germany.
FAU - Blaikie, Andrew
AU  - Blaikie A
AUID- ORCID: 0000-0001-7913-6872
AD  - School of Medicine, University of St Andrews, St Andrews, United Kingdom.
FAU - Kelsey, Tom
AU  - Kelsey T
AUID- ORCID: 0000-0002-8091-1458
AD  - School of Computer Science, University of St Andrews, St Andrews, United Kingdom.
FAU - Kuhn, Sebastian
AU  - Kuhn S
AUID- ORCID: 0000-0002-8031-2973
AD  - Institute of Digital Medicine, Philipps-University Marburg and University 
      Hospital of Giessen and Marburg, Marburg, Germany.
FAU - Eckrich, Jonas
AU  - Eckrich J
AUID- ORCID: 0000-0001-5498-4031
AD  - Department of Otorhinolaryngology, University Medical Center of the Johannes 
      Gutenberg-University Mainz, Mainz, Germany.
LA  - eng
PT  - Journal Article
DEP - 20231205
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
PMC - PMC10731554
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - LLM
OT  - LLMs
OT  - ORL
OT  - artificial intelligence
OT  - chatbot
OT  - chatbots
OT  - digital health
OT  - global health
OT  - language model
OT  - large language models
OT  - low- and middle-income countries
OT  - otorhinolaryngology
OT  - telehealth
OT  - telemedicine
COIS- Conflicts of Interest: SK is the founder and shareholder of MED.digital.
EDAT- 2023/12/05 17:44
MHDA- 2023/12/05 17:45
PMCR- 2023/12/05
CRDT- 2023/12/05 11:54
PHST- 2023/05/20 00:00 [received]
PHST- 2023/10/20 00:00 [accepted]
PHST- 2023/07/20 00:00 [revised]
PHST- 2023/12/05 17:45 [medline]
PHST- 2023/12/05 17:44 [pubmed]
PHST- 2023/12/05 11:54 [entrez]
PHST- 2023/12/05 00:00 [pmc-release]
AID - v9i1e49183 [pii]
AID - 10.2196/49183 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Dec 5;9:e49183. doi: 10.2196/49183.

PMID- 37201835
OWN - NLM
STAT- MEDLINE
DCOM- 20230614
LR  - 20230614
IS  - 1879-1026 (Electronic)
IS  - 0048-9697 (Linking)
VI  - 888
DP  - 2023 Aug 25
TI  - Use of ChatGPT: What does it mean for biology and environmental science?
PG  - 164154
LID - S0048-9697(23)02775-4 [pii]
LID - 10.1016/j.scitotenv.2023.164154 [doi]
AB  - Artificial intelligence (AI) large language models (LLMs) have emerged as 
      important technologies. Recently, ChatGPT (Generative Pre-trained Transformer) 
      has been released and attracted massive interest from the public, owing to its 
      unique capabilities to simplify many daily tasks of people from diverse 
      backgrounds and social statuses. Here, we discuss how ChatGPT (and similar AI 
      technologies) can impact biology and environmental science, providing examples 
      obtained through interactive sessions with ChatGPT. The benefits that ChatGPT 
      offers are ample and can impact many aspects of biology and environmental 
      science, including education, research, scientific publishing, outreach, and 
      societal translation. Among others, ChatGPT can simplify and expedite highly 
      complex and challenging tasks. As an example to illustrate this, we provide 100 
      important questions for biology and 100 important questions for environmental 
      science. Although ChatGPT offers a plethora of benefits, there are several risks 
      and potential harms associated with its use, which we analyze herein. Awareness 
      of risks and potential harms should be raised. However, understanding and 
      overcoming the current limitations could lead these recent technological advances 
      to push biology and environmental science to their limits.
CI  - Copyright © 2023 Elsevier B.V. All rights reserved.
FAU - Agathokleous, Evgenios
AU  - Agathokleous E
AD  - School of Applied Meteorology, Nanjing University of Information Science &amp; 
      Technology (NUIST), Nanjing 210044, China. Electronic address: 
      evgenios@nuist.edu.cn.
FAU - Saitanis, Costas J
AU  - Saitanis CJ
AD  - Lab of Ecology and Environmental Science, Agricultural University of Athens, Iera 
      Odos 75, Athens 11855, Greece.
FAU - Fang, Chao
AU  - Fang C
AD  - School of Applied Meteorology, Nanjing University of Information Science &amp; 
      Technology (NUIST), Nanjing 210044, China.
FAU - Yu, Zhen
AU  - Yu Z
AD  - School of Applied Meteorology, Nanjing University of Information Science &amp; 
      Technology (NUIST), Nanjing 210044, China. Electronic address: zyu@nuist.edu.cn.
LA  - eng
PT  - Journal Article
DEP - 20230516
PL  - Netherlands
TA  - Sci Total Environ
JT  - The Science of the total environment
JID - 0330500
SB  - IM
MH  - Humans
MH  - *Environmental Science
MH  - Artificial Intelligence
MH  - Educational Status
MH  - Electric Power Supplies
MH  - Biology
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Biology
OT  - ChatGPT
OT  - Environmental science
OT  - Generative Pre-trained Transformer
OT  - Large language model
COIS- Declaration of competing interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2023/05/19 01:04
MHDA- 2023/06/14 06:42
CRDT- 2023/05/18 19:29
PHST- 2023/04/29 00:00 [received]
PHST- 2023/05/09 00:00 [revised]
PHST- 2023/05/10 00:00 [accepted]
PHST- 2023/06/14 06:42 [medline]
PHST- 2023/05/19 01:04 [pubmed]
PHST- 2023/05/18 19:29 [entrez]
AID - S0048-9697(23)02775-4 [pii]
AID - 10.1016/j.scitotenv.2023.164154 [doi]
PST - ppublish
SO  - Sci Total Environ. 2023 Aug 25;888:164154. doi: 10.1016/j.scitotenv.2023.164154. 
      Epub 2023 May 16.

PMID- 37128784
OWN - NLM
STAT- MEDLINE
DCOM- 20240118
LR  - 20240118
IS  - 1527-330X (Electronic)
IS  - 1090-820X (Linking)
VI  - 43
IP  - 12
DP  - 2023 Nov 16
TI  - Performance of ChatGPT on the Plastic Surgery Inservice Training Examination.
PG  - NP1078-NP1082
LID - 10.1093/asj/sjad128 [doi]
AB  - BACKGROUND: Developed originally as a tool for resident self-evaluation, the 
      Plastic Surgery Inservice Training Examination (PSITE) has become a standardized 
      tool adopted by Plastic Surgery residency programs. The introduction of large 
      language models (LLMs), such as ChatGPT (OpenAI, San Francisco, CA), has 
      demonstrated the potential to help propel the field of Plastic Surgery. 
      OBJECTIVES: The authors of this study wanted to assess whether or not ChatGPT 
      could be utilized as a tool in resident education by assessing its accuracy on 
      the PSITE. METHODS: Questions were obtained from the 2022 PSITE, which was 
      present on the American Council of Academic Plastic Surgeons (ACAPS) website. 
      Questions containing images or tables were carefully inspected and flagged before 
      being inputted into ChatGPT. All responses by ChatGPT were qualified utilizing 
      the properties of natural coherence. Responses that were found to be incorrect 
      were divided into the following categories: logical, informational, or explicit 
      fallacy. RESULTS: ChatGPT answered a total of 242 questions with an accuracy of 
      54.96%. The software incorporated logical reasoning in 88.8% of questions, 
      internal information in 95.5% of questions, and external information in 92.1% of 
      questions. When stratified by correct and incorrect responses, we determined that 
      there was a statistically significant difference in ChatGPT's use of external 
      information (P &lt; .05). CONCLUSIONS: ChatGPT is a versatile tool that has the 
      potential to impact resident education by providing general knowledge, clarifying 
      information, providing case-based learning, and promoting evidence-based 
      medicine. With advancements in LLM and artificial intelligence (AI), it is 
      possible that ChatGPT may be an impactful tool for resident education within 
      Plastic Surgery.
CI  - © The Author(s) 2023. Published by Oxford University Press on behalf of The 
      Aesthetic Society. All rights reserved. For permissions, please e-mail: 
      journals.permissions@oup.com.
FAU - Gupta, Rohun
AU  - Gupta R
AUID- ORCID: 0000-0003-1491-2441
FAU - Herzog, Isabel
AU  - Herzog I
AUID- ORCID: 0000-0001-7491-5746
FAU - Park, John B
AU  - Park JB
FAU - Weisberger, Joseph
AU  - Weisberger J
FAU - Firouzbakht, Peter
AU  - Firouzbakht P
FAU - Ocon, Vanessa
AU  - Ocon V
FAU - Chao, John
AU  - Chao J
FAU - Lee, Edward S
AU  - Lee ES
FAU - Mailey, Brian A
AU  - Mailey BA
LA  - eng
PT  - Journal Article
PL  - England
TA  - Aesthet Surg J
JT  - Aesthetic surgery journal
JID - 9707469
SB  - IM
CIN - Aesthet Surg J. 2023 Jun 02;:. PMID: 37265091
EIN - Aesthet Surg J. 2023 Sep 29;:. PMID: 37772448
MH  - Humans
MH  - *Surgery, Plastic
MH  - Artificial Intelligence
MH  - *Plastic Surgery Procedures
MH  - Inservice Training
MH  - Evidence-Based Medicine
EDAT- 2023/05/02 06:42
MHDA- 2024/01/18 06:42
CRDT- 2023/05/02 03:43
PHST- 2024/01/18 06:42 [medline]
PHST- 2023/05/02 06:42 [pubmed]
PHST- 2023/05/02 03:43 [entrez]
AID - 7147614 [pii]
AID - 10.1093/asj/sjad128 [doi]
PST - ppublish
SO  - Aesthet Surg J. 2023 Nov 16;43(12):NP1078-NP1082. doi: 10.1093/asj/sjad128.

PMID- 37750843
OWN - NLM
STAT- MEDLINE
DCOM- 20231225
LR  - 20231225
IS  - 1748-880X (Electronic)
IS  - 0007-1285 (Print)
IS  - 0007-1285 (Linking)
VI  - 96
IP  - 1152
DP  - 2023 Dec
TI  - ChatGPT: a tool for scientific writing or a threat to integrity?
PG  - 20230430
LID - 10.1259/bjr.20230430 [doi]
LID - 20230430
AB  - The use of ChatGPT as a tool for writing and knowledge integration raises 
      concerns about the potential for its use to replace critical thinking and 
      academic writing skills. While ChatGPT can assist in generating text and 
      suggesting appropriate language, it should not replace the human responsibility 
      for creating innovative knowledge through experiential learning. The accuracy and 
      quality of information provided by ChatGPT also require caution, as previous 
      studies have reported inaccuracies in references used by chatbots. ChatGPT 
      acknowledges certain limitations, including the potential for generating 
      erroneous or biased content, and it is essential to exercise caution in 
      interpreting its responses and recognize the indispensable role of human 
      experience in the processes of information retrieval and knowledge creation. 
      Furthermore, the challenge of distinguishing between papers written by humans or 
      AI highlights the need for thorough review processes to prevent the spread of 
      articles that could lead to the loss of confidence in the accuracy and integrity 
      of scientific research. Overall, while the use of ChatGPT can be helpful, it is 
      crucial to raise awareness of the potential issues associated with the use of 
      ChatGPT, as well as to discuss boundaries so that AI can be used without 
      compromising the quality of scientific articles and the integrity of 
      evidence-based knowledge.
FAU - Silva, Thaísa Pinheiro
AU  - Silva TP
AUID- ORCID: 0000-0002-7485-0206
AD  - Department of Oral Diagnosis, Division of Oral Radiology, Piracicaba Dental 
      School, University of Campinas, Piracicaba, Brazil.
FAU - Ocampo, Thaís S C
AU  - Ocampo TSC
AD  - Department of Oral Diagnosis, Division of Oral Radiology, Piracicaba Dental 
      School, University of Campinas, Piracicaba, Brazil.
FAU - Alencar-Palha, Caio
AU  - Alencar-Palha C
AD  - Department of Oral Diagnosis, Division of Oral Radiology, Piracicaba Dental 
      School, University of Campinas, Piracicaba, Brazil.
FAU - Oliveira-Santos, Christiano
AU  - Oliveira-Santos C
AD  - Department of Diagnosis and Oral Health, University of Louisville School of 
      Dentistry, Louisville, United States.
FAU - Takeshita, Wilton Mitsunari
AU  - Takeshita WM
AD  - Department of Diagnosis and Surgery, Paulista State University Júlio de Mesquita 
      Filho, Araçatuba, Brazil.
FAU - Oliveira, Matheus L
AU  - Oliveira ML
AD  - Department of Oral Diagnosis, Division of Oral Radiology, Piracicaba Dental 
      School, University of Campinas, Piracicaba, Brazil.
LA  - eng
PT  - Journal Article
DEP - 20231024
PL  - England
TA  - Br J Radiol
JT  - The British journal of radiology
JID - 0373125
SB  - IM
MH  - Humans
MH  - *Information Storage and Retrieval
MH  - *Knowledge Bases
MH  - Writing
PMC - PMC10646664
EDAT- 2023/09/26 13:43
MHDA- 2023/12/25 06:43
PMCR- 2024/11/01
CRDT- 2023/09/26 10:34
PHST- 2024/11/01 00:00 [pmc-release]
PHST- 2023/12/25 06:43 [medline]
PHST- 2023/09/26 13:43 [pubmed]
PHST- 2023/09/26 10:34 [entrez]
AID - 10.1259/bjr.20230430 [doi]
PST - ppublish
SO  - Br J Radiol. 2023 Dec;96(1152):20230430. doi: 10.1259/bjr.20230430. Epub 2023 Oct 
      24.

PMID- 37799027
OWN - NLM
STAT- Publisher
LR  - 20231006
IS  - 2296-6498 (Print)
IS  - 2296-6498 (Linking)
VI  - 134
IP  - 5
DP  - 2023 Oct 6
TI  - ChatGPT's performance in dentistry and allergy-immunology assessments: a 
      comparative study.
AB  - Large language models (LLMs) such as ChatGPT have potential applications in 
      healthcare, including dentistry. Priming, the practice of providing LLMs with 
      initial, relevant information, is an approach to improve their output quality. 
      This study aimed to evaluate the performance of ChatGPT 3 and ChatGPT 4 on 
      self-assessment questions for dentistry, through the Swiss Federal Licensing 
      Examination in Dental Medicine (SFLEDM), and allergy and clinical immunology, 
      through the European Examination in Allergy and Clinical Immunology (EEAACI). The 
      second objective was to assess the impact of priming on ChatGPT's performance. 
      The SFLEDM and EEAACI multiple-choice questions from the University of Bern's 
      Institute for Medical Education platform were administered to both ChatGPT 
      versions, with and without priming. Performance was analyzed based on correct 
      responses. The statistical analysis included Wilcoxon rank sum tests (α=0.05). 
      The average accuracy rates in the SFLEDM and EEAACI assessments were 63.3% and 
      79.3%, respectively. Both ChatGPT versions performed better on EEAACI than 
      SFLEDM, with ChatGPT 4 outperforming ChatGPT 3 across all tests. ChatGPT 3's 
      performance exhibited a significant improvement with priming for both EEAACI 
      (p=0.017) and SFLEDM (p=0.024) assessments. For ChatGPT 4, the priming effect was 
      significant only in the SFLEDM assessment (p=0.038). The performance disparity 
      between SFLEDM and EEAACI assessments underscores ChatGPT's varying proficiency 
      across different medical domains, likely tied to the nature and amount of 
      training data available in each field. Priming can be a tool for enhancing 
      output, especially in earlier LLMs. Advancements from ChatGPT 3 to 4 highlight 
      the rapid developments in LLM technology. Yet, their use in critical fields such 
      as healthcare must remain cautious owing to LLMs' inherent limitations and risks.
FAU - Fuchs, Alexander
AU  - Fuchs A
AD  - Department of Periodontology, Endodontology, and Cariology, University Center for 
      Dental Medicine Basel UZB, University of Basel, Basel, Switzerland.
FAU - Trachsel, Tina
AU  - Trachsel T
AD  - Division of Allergy, University Children's Hospital Basel, Basel, Switzerland.
FAU - Weiger, Roland
AU  - Weiger R
AD  - Department of Periodontology, Endodontology, and Cariology, University Center for 
      Dental Medicine Basel UZB, University of Basel, Basel, Switzerland.
FAU - Eggmann, Florin
AU  - Eggmann F
AD  - Department of Periodontology, Endodontology, and Cariology, University Center for 
      Dental Medicine Basel UZB, University of Basel, Basel, Switzerland.
LA  - eng
PT  - Journal Article
DEP - 20231006
PL  - Switzerland
TA  - Swiss Dent J
JT  - Swiss dental journal
JID - 101624119
SB  - IM
OTO - NOTNLM
OT  - allergology
OT  - artificial intelligence
OT  - clinical immunology
OT  - dental education
OT  - machine learning
OT  - medical informatics applications
EDAT- 2023/10/06 06:43
MHDA- 2023/10/06 06:43
CRDT- 2023/10/06 03:02
PHST- 2023/10/06 06:43 [medline]
PHST- 2023/10/06 06:43 [pubmed]
PHST- 2023/10/06 03:02 [entrez]
AID - sdj-2024-05-01 [pii]
PST - aheadofprint
SO  - Swiss Dent J. 2023 Oct 6;134(5).

PMID- 38492008
OWN - NLM
STAT- Publisher
LR  - 20240316
IS  - 1434-4726 (Electronic)
IS  - 0937-4477 (Linking)
DP  - 2024 Mar 16
TI  - ChatGPT-4 accuracy for patient education in laryngopharyngeal reflux.
LID - 10.1007/s00405-024-08560-w [doi]
AB  - INTRODUCTION: Chatbot Generative Pre-trained Transformer (ChatGPT) is an 
      artificial intelligence-powered language model chatbot able to help 
      otolaryngologists in practice and research. The ability of ChatGPT in generating 
      patient-centered information related to laryngopharyngeal reflux disease (LPRD) 
      was evaluated. METHODS: Twenty-five questions dedicated to definition, clinical 
      presentation, diagnosis, and treatment of LPRD were developed from the Dubai 
      definition and management of LPRD consensus and recent reviews. Questions about 
      the four aforementioned categories were entered into ChatGPT-4. Four 
      board-certified laryngologists evaluated the accuracy of ChatGPT-4 with a 5-point 
      Likert scale. Interrater reliability was evaluated. RESULTS: The mean scores (SD) 
      of ChatGPT-4 answers for definition, clinical presentation, additional 
      examination, and treatments were 4.13 (0.52), 4.50 (0.72), 3.75 (0.61), and 4.18 
      (0.47), respectively. Experts reported high interrater reliability for sub-scores 
      (ICC = 0.973). The lowest performances of ChatGPT-4 were on answers about the 
      most prevalent LPR signs, the most reliable objective tool for the diagnosis 
      (hypopharyngeal-esophageal multichannel intraluminal impedance-pH monitoring 
      (HEMII-pH)), and the criteria for the diagnosis of LPR using HEMII-pH. 
      CONCLUSION: ChatGPT-4 may provide adequate information on the definition of LPR, 
      differences compared to GERD (gastroesophageal reflux disease), and clinical 
      presentation. Information provided upon extra-laryngeal manifestations and 
      HEMII-pH may need further optimization. Regarding the recent trends identifying 
      increasing patient use of internet sources for self-education, the findings of 
      the present study may help draw attention to ChatGPT-4's accuracy on the topic of 
      LPR.
CI  - © 2024. The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, 
      part of Springer Nature.
FAU - Lechien, Jerome R
AU  - Lechien JR
AUID- ORCID: 0000-0002-0845-0845
AD  - Research Committee, Young Otolaryngologists of the International Federation of 
      Otorhinolaryngological Societies (IFOS), Paris, France. 
      Jerome.Lechien@umons.ac.be.
AD  - Division of Laryngology and Broncho-Esophagology, Department of 
      Otolaryngology-Head Neck Surgery, EpiCURA Hospital, UMONS Research Institute for 
      Health Sciences and Technology, University of Mons (UMons), Mons, Belgium. 
      Jerome.Lechien@umons.ac.be.
AD  - Department of Otorhinolaryngology and Head and Neck Surgery, Foch Hospital, 
      School of Medicine, Phonetics and Phonology Laboratory (UMR 7018 CNRS, Université 
      Sorbonne Nouvelle/Paris 3), Paris, France. Jerome.Lechien@umons.ac.be.
AD  - Polyclinique Elsan de Poitiers, Poitiers, France. Jerome.Lechien@umons.ac.be.
FAU - Carroll, Thomas L
AU  - Carroll TL
AD  - Division of Otolaryngology-Head and Neck Surgery, Brigham and Women's Hospital, 
      Department of Otolaryngology-Head and Neck Surgery, Harvard Medical School, 
      Boston, MA, USA.
FAU - Huston, Molly N
AU  - Huston MN
AD  - Department of Otolaryngology, Washington University School of Medicine in St. 
      Louis, St. Louis, MO, USA.
FAU - Naunheim, Matthew R
AU  - Naunheim MR
AD  - Research Committee, Young Otolaryngologists of the International Federation of 
      Otorhinolaryngological Societies (IFOS), Paris, France.
AD  - Department of Otolaryngology-Head and Neck Surgery, Harvard Medical School, 
      Boston, MA, USA.
AD  - Division of Laryngology, Massachusetts Eye and Ear, Boston, MA, USA.
LA  - eng
PT  - Journal Article
DEP - 20240316
PL  - Germany
TA  - Eur Arch Otorhinolaryngol
JT  - European archives of oto-rhino-laryngology : official journal of the European 
      Federation of Oto-Rhino-Laryngological Societies (EUFOS) : affiliated with the 
      German Society for Oto-Rhino-Laryngology - Head and Neck Surgery
JID - 9002937
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Chatbot
OT  - Head neck surgery
OT  - Laryngopharyngeal
OT  - Otolaryngology
OT  - Reference
OT  - Reflux
EDAT- 2024/03/16 21:47
MHDA- 2024/03/16 21:47
CRDT- 2024/03/16 12:13
PHST- 2024/02/12 00:00 [received]
PHST- 2024/02/13 00:00 [accepted]
PHST- 2024/03/16 21:47 [medline]
PHST- 2024/03/16 21:47 [pubmed]
PHST- 2024/03/16 12:13 [entrez]
AID - 10.1007/s00405-024-08560-w [pii]
AID - 10.1007/s00405-024-08560-w [doi]
PST - aheadofprint
SO  - Eur Arch Otorhinolaryngol. 2024 Mar 16. doi: 10.1007/s00405-024-08560-w.

PMID- 37031907
OWN - NLM
STAT- MEDLINE
DCOM- 20230501
LR  - 20230505
IS  - 1879-0542 (Electronic)
IS  - 0165-2478 (Linking)
VI  - 256-257
DP  - 2023 Apr-May
TI  - Science fact vs science fiction: A ChatGPT immunological review experiment gone 
      awry.
PG  - 42-47
LID - S0165-2478(23)00053-6 [pii]
LID - 10.1016/j.imlet.2023.04.002 [doi]
AB  - Artificial intelligence (AI) has made great progress in recent years. The latest 
      chatbot to make a splash is ChatGPT. To see if this type of AI could also be 
      helpful in creating an immunological review article, I put a planned review on 
      different classes of small RNAs during murine B cell development to the test. 
      Although the general wording sounded very polished and convincing, ChatGPT 
      encountered great difficulties when asked for details and references and made 
      many incorrect statements, leading me to conclude that this kind of AI is not 
      (yet?) suitable for assisting in the writing of scientific articles.
CI  - Copyright © 2023. Published by Elsevier B.V.
FAU - Wittmann, Jürgen
AU  - Wittmann J
AD  - Division of Molecular Immunology, Department of Internal Medicine III, 
      Nikolaus-Fiebiger-Center of Molecular Medicine (NFZ), 
      Friedrich-Alexander-Universität Erlangen-Nürnberg, Glückstraße 6, Erlangen 
      D-91054, Germany. Electronic address: juergen.wittmann@uk-erlangen.de.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230407
PL  - Netherlands
TA  - Immunol Lett
JT  - Immunology letters
JID - 7910006
RN  - 63231-63-0 (RNA)
SB  - IM
MH  - Animals
MH  - Mice
MH  - *Artificial Intelligence
MH  - *Lymphocyte Activation
MH  - RNA
MH  - Software
OTO - NOTNLM
OT  - ChatGPT
OT  - Chatbot
OT  - Human intervention
OT  - Manuscript preparation
OT  - MicroRNAs
OT  - References
EDAT- 2023/04/10 06:00
MHDA- 2023/05/01 06:42
CRDT- 2023/04/09 19:26
PHST- 2023/01/31 00:00 [received]
PHST- 2023/03/23 00:00 [revised]
PHST- 2023/04/03 00:00 [accepted]
PHST- 2023/05/01 06:42 [medline]
PHST- 2023/04/10 06:00 [pubmed]
PHST- 2023/04/09 19:26 [entrez]
AID - S0165-2478(23)00053-6 [pii]
AID - 10.1016/j.imlet.2023.04.002 [doi]
PST - ppublish
SO  - Immunol Lett. 2023 Apr-May;256-257:42-47. doi: 10.1016/j.imlet.2023.04.002. Epub 
      2023 Apr 7.

PMID- 37707442
OWN - NLM
STAT- Publisher
LR  - 20240316
IS  - 1559-8519 (Electronic)
IS  - 0022-4499 (Print)
IS  - 0022-4499 (Linking)
DP  - 2023 Sep 14
TI  - Hey ChatGPT, Let's Talk About Sexual Consent.
PG  - 1-12
LID - 10.1080/00224499.2023.2254772 [doi]
AB  - Access to sexual health education, such as education on sexual consent, is 
      limited in the US. Artificial intelligence (AI), such as ChatGPT, provides a 
      potential opportunity to increase access to sexual consent information and 
      education. However, what ChatGPT knows about sexual consent and if this aligns 
      with the current evidence-based literature on sexual consent is unclear. The goal 
      of this research commentary was to explore what ChatGPT knows about sexual 
      consent with a focus on: 1) the definition of consent, 2) how consent could be 
      communicated, and 3) the impact that substances have on consent. We also examined 
      the reliability of ChatGPT's responses by having three different researchers ask 
      ChatGPT the same set of questions. Across our questions, ChatGPT provided similar 
      and comprehensive responses that discussed key features of consent - that consent 
      is freely given or reversible. ChatGPT provided examples of different verbal and 
      nonverbal cues people can use to communicate and interpret consent and discussed 
      the ways that substances can impact consent communication. Overall, ChatGPT could 
      be a potential resource for educators and young people who seek information about 
      sexual consent; however, we should proceed with caution. ChatGPT is not a 
      replacement for an educator but rather a way to increase access to education.
FAU - Marcantonio, Tiffany L
AU  - Marcantonio TL
AUID- ORCID: 0000-0003-1087-7554
AD  - Department of Health Science, College of Human Environmental Sciences, University 
      of Alabama.
FAU - Nielsen, Karen E
AU  - Nielsen KE
AD  - Population Health Science, School of Public Health, Georgia State University.
FAU - Haikalis, Michelle
AU  - Haikalis M
AUID- ORCID: 0000-0003-1062-5314
AD  - Department of Behavioral and Social Sciences, School of Public Health, Center for 
      Alcohol and Addiction Studies, Brown University.
FAU - Leone, Ruschelle M
AU  - Leone RM
AUID- ORCID: 0000-0002-7179-398X
AD  - Department of Health Policy and Behavioral Sciences, School of Public Health, 
      Georgia State University.
FAU - Woerner, Jacqueline
AU  - Woerner J
AUID- ORCID: 0000-0002-6704-5372
AD  - Department of Sociology, University of Central Florida.
FAU - Neilson, Elizabeth C
AU  - Neilson EC
AUID- ORCID: 0000-0002-4138-8748
AD  - Department of Psychology, Eastern Michigan University.
FAU - Schipani-McLaughlin, Anne Marie
AU  - Schipani-McLaughlin AM
AD  - Department of Health Policy and Behavioral Sciences, School of Public Health, 
      Georgia State University.
LA  - eng
GR  - K01 AA028844/AA/NIAAA NIH HHS/United States
GR  - K08 AA029181/AA/NIAAA NIH HHS/United States
GR  - L30 AA028649/AA/NIAAA NIH HHS/United States
GR  - L30 AA031129/AA/NIAAA NIH HHS/United States
PT  - Journal Article
DEP - 20230914
PL  - United States
TA  - J Sex Res
JT  - Journal of sex research
JID - 0062647
SB  - IM
PMC - PMC10937333
MID - NIHMS1929458
EDAT- 2023/09/14 12:42
MHDA- 2023/09/14 12:42
PMCR- 2025/03/14
CRDT- 2023/09/14 10:22
PHST- 2025/03/14 00:00 [pmc-release]
PHST- 2023/09/14 12:42 [medline]
PHST- 2023/09/14 12:42 [pubmed]
PHST- 2023/09/14 10:22 [entrez]
AID - 10.1080/00224499.2023.2254772 [doi]
PST - aheadofprint
SO  - J Sex Res. 2023 Sep 14:1-12. doi: 10.1080/00224499.2023.2254772.

PMID- 37892297
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231030
IS  - 2227-9067 (Print)
IS  - 2227-9067 (Electronic)
IS  - 2227-9067 (Linking)
VI  - 10
IP  - 10
DP  - 2023 Sep 30
TI  - Can ChatGPT Guide Parents on Tympanostomy Tube Insertion?
LID - 10.3390/children10101634 [doi]
LID - 1634
AB  - BACKGROUND: The emergence of ChatGPT, a state-of-the-art language model developed 
      by OpenAI, has introduced a novel avenue for patients to seek medically related 
      information. This technology holds significant promise in terms of accessibility 
      and convenience. However, the use of ChatGPT as a source of accurate information 
      enhancing patient education and engagement requires careful consideration. The 
      objective of this study was to assess the accuracy and reliability of ChatGPT in 
      providing information on the indications and management of complications 
      post-tympanostomy, the most common pediatric procedure in otolaryngology. 
      METHODS: We prompted ChatGPT-3.5 with questions and compared its generated 
      responses with the recommendations provided by the latest American Academy of 
      Otolaryngology-Head and Neck Surgery Foundation (AAO-HNSF) "Clinical Practice 
      Guideline: Tympanostomy Tubes in Children (Update)". RESULTS: A total of 23 
      responses were generated by ChatGPT against the AAO-HNSF guidelines. Following a 
      thorough review, it was determined that 22/23 (95.7%) responses exhibited a high 
      level of reliability and accuracy, closely aligning with the gold standard. 
      CONCLUSION: Our research study indicates that ChatGPT may be of assistance to 
      parents in search of information regarding tympanostomy tube insertion and its 
      clinical implications.
FAU - Moise, Alexander
AU  - Moise A
AD  - Faculty of Medicine and Health Sciences, McGill University, Montreal, QC H3G 2M1, 
      Canada.
FAU - Centomo-Bozzo, Adam
AU  - Centomo-Bozzo A
AD  - Faculty of Dental Medicine and Oral Health Sciences, McGill University, Montreal, 
      QC H3A 3E8, Canada.
FAU - Orishchak, Ostap
AU  - Orishchak O
AD  - Department of Pediatric Otolaryngology, Montreal Children's Hospital, Montreal, 
      QC H4A 3J1, Canada.
FAU - Alnoury, Mohammed K
AU  - Alnoury MK
AUID- ORCID: 0000-0001-9222-8501
AD  - Department of Otolaryngology, Head and Neck Surgery, King Abdulaziz University, 
      Jeddah 21589, Saudi Arabia.
FAU - Daniel, Sam J
AU  - Daniel SJ
AD  - Department of Pediatric Otolaryngology, Montreal Children's Hospital, Montreal, 
      QC H4A 3J1, Canada.
LA  - eng
PT  - Journal Article
DEP - 20230930
PL  - Switzerland
TA  - Children (Basel)
JT  - Children (Basel, Switzerland)
JID - 101648936
PMC - PMC10605420
OTO - NOTNLM
OT  - ChatGPT
OT  - OpenAI
OT  - artificial intelligence
OT  - myringotomy
OT  - otolaryngology
OT  - tympanostomy tube insertion
COIS- The authors declare no conflict of interest.
EDAT- 2023/10/28 11:45
MHDA- 2023/10/28 11:46
PMCR- 2023/09/30
CRDT- 2023/10/28 01:03
PHST- 2023/08/23 00:00 [received]
PHST- 2023/09/21 00:00 [revised]
PHST- 2023/09/27 00:00 [accepted]
PHST- 2023/10/28 11:46 [medline]
PHST- 2023/10/28 11:45 [pubmed]
PHST- 2023/10/28 01:03 [entrez]
PHST- 2023/09/30 00:00 [pmc-release]
AID - children10101634 [pii]
AID - children-10-01634 [pii]
AID - 10.3390/children10101634 [doi]
PST - epublish
SO  - Children (Basel). 2023 Sep 30;10(10):1634. doi: 10.3390/children10101634.

PMID- 37744723
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230926
IS  - 2296-875X (Print)
IS  - 2296-875X (Electronic)
IS  - 2296-875X (Linking)
VI  - 10
DP  - 2023
TI  - Expanding horizons and navigating challenges for enhanced clinical workflows: 
      ChatGPT in urology.
PG  - 1257191
LID - 10.3389/fsurg.2023.1257191 [doi]
LID - 1257191
AB  - PURPOSE OF REVIEW: ChatGPT has emerged as a potential tool for facilitating 
      doctors' workflows. However, when it comes to applying these findings within a 
      urological context, there have not been many studies. Thus, our objective was 
      rooted in analyzing the pros and cons of ChatGPT use and how it can be exploited 
      and used by urologists. RECENT FINDINGS: ChatGPT can facilitate clinical 
      documentation and note-taking, patient communication and support, medical 
      education, and research. In urology, it was proven that ChatGPT has the potential 
      as a virtual healthcare aide for benign prostatic hyperplasia, an educational and 
      prevention tool on prostate cancer, educational support for urological residents, 
      and as an assistant in writing urological papers and academic work. However, 
      several concerns about its exploitation are presented, such as lack of web 
      crawling, risk of accidental plagiarism, and concerns about patients-data 
      privacy. SUMMARY: The existing limitations mediate the need for further 
      improvement of ChatGPT, such as ensuring the privacy of patient data and 
      expanding the learning dataset to include medical databases, and developing 
      guidance on its appropriate use. Urologists can also help by conducting studies 
      to determine the effectiveness of ChatGPT in urology in clinical scenarios and 
      nosologies other than those previously listed.
CI  - © 2023 Talyshinskii, Naik, Hameed, Zhanbyrbekuly, Khairli, Guliev, Juliebø-Jones, 
      Tzelves and Somani.
FAU - Talyshinskii, Ali
AU  - Talyshinskii A
AD  - Department of Urology, Astana Medical University, Astana, Kazakhstan.
FAU - Naik, Nithesh
AU  - Naik N
AD  - Department of Mechanical and Industrial Engineering, Manipal Institute of 
      Technology, Manipal Academy of Higher Education, Manipal, India.
FAU - Hameed, B M Zeeshan
AU  - Hameed BMZ
AD  - Department of Urology, Father Muller Medical College, Mangalore, India.
FAU - Zhanbyrbekuly, Ulanbek
AU  - Zhanbyrbekuly U
AD  - Department of Urology, Astana Medical University, Astana, Kazakhstan.
FAU - Khairli, Gafur
AU  - Khairli G
AD  - Department of Urology, Astana Medical University, Astana, Kazakhstan.
FAU - Guliev, Bakhman
AU  - Guliev B
AD  - Department of Urology, Mariinsky Hospital, St Petersburg, Russia.
FAU - Juilebø-Jones, Patrick
AU  - Juilebø-Jones P
AD  - Department of Urology, Haukeland University Hospital, Bergen, Norway.
FAU - Tzelves, Lazaros
AU  - Tzelves L
AD  - Department of Urology, National and Kapodistrian University of Athens, 
      Sismanogleion Hospital, Athens, Marousi, Greece.
FAU - Somani, Bhaskar Kumar
AU  - Somani BK
AD  - Department of Urology, University Hospital Southampton NHS Trust, Southampton, 
      United Kingdom.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230907
PL  - Switzerland
TA  - Front Surg
JT  - Frontiers in surgery
JID - 101645127
PMC - PMC10512827
OTO - NOTNLM
OT  - chatGPT
OT  - generative AI
OT  - healthcare
OT  - urology
OT  - workflow
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/09/25 06:42
MHDA- 2023/09/25 06:43
PMCR- 2023/09/07
CRDT- 2023/09/25 04:48
PHST- 2023/07/12 00:00 [received]
PHST- 2023/08/28 00:00 [accepted]
PHST- 2023/09/25 06:43 [medline]
PHST- 2023/09/25 06:42 [pubmed]
PHST- 2023/09/25 04:48 [entrez]
PHST- 2023/09/07 00:00 [pmc-release]
AID - 10.3389/fsurg.2023.1257191 [doi]
PST - epublish
SO  - Front Surg. 2023 Sep 7;10:1257191. doi: 10.3389/fsurg.2023.1257191. eCollection 
      2023.

PMID- 37602076
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230823
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 7
DP  - 2023 Jul
TI  - ChatGPT and Artificial Intelligence in Transplantation Research: Is It Always 
      Correct?
PG  - e42150
LID - 10.7759/cureus.42150 [doi]
LID - e42150
AB  - INTRODUCTION: ChatGPT (OpenAI,&nbsp;San Francisco, California, United States) is a 
      chatbot powered by language-based artificial intelligence (AI). It generates text 
      based on the information provided by users. It is currently being evaluated in 
      medical research, publishing, and healthcare. However, there has been no prior 
      study on the evaluation of its ability to help in kidney transplant research. 
      This feasibility study aimed to evaluate the application and accuracy of ChatGPT 
      in the field of kidney transplantation. METHODS: On two separate dates, February 
      21 and March 2, 2023, ChatGPT 3.5 was questioned regarding the medical treatment 
      of kidney transplants and related scientific facts.&nbsp;The responses provided by the 
      chatbot were compiled, and a panel of two specialists reviewed the correctness of 
      each answer. RESULTS: We demonstrated that ChatGPT possessed substantial general 
      knowledge of kidney transplantation; however, they lacked sufficient information 
      and had inaccurate information that necessitates a deeper understanding of the 
      topic. Moreover, ChatGPT failed to provide references for any of the scientific 
      data it provided regarding kidney transplants, and when requested for references, 
      it provided inaccurate ones. CONCLUSION: The results of this short feasibility 
      study indicate that ChatGPT may have the ability to assist in data collecting 
      when a particular query is posed. However, caution should be exercised and it 
      should not be used in isolation as a supplement to research or decisions 
      regarding healthcare because there are still challenges with data accuracy and 
      missing information.
CI  - Copyright © 2023, Rawashdeh et al.
FAU - Rawashdeh, Badi
AU  - Rawashdeh B
AD  - Transplant Surgery, Medical College of Wisconsin, Milwaukee, USA.
FAU - Kim, Joohyun
AU  - Kim J
AD  - Transplant Surgery, Medical College of Wisconsin, Milwaukee, USA.
FAU - AlRyalat, Saif Aldeen
AU  - AlRyalat SA
AD  - Opthalmology, The University of Jordan, Amman, JOR.
FAU - Prasad, Raj
AU  - Prasad R
AD  - Transplant Surgery, Medical College of Wisconsin, Milwaukee, USA.
FAU - Cooper, Matthew
AU  - Cooper M
AD  - Transplant Surgery, Medical College of Wisconsin, Milwaukee, USA.
LA  - eng
PT  - Journal Article
DEP - 20230719
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10438857
OTO - NOTNLM
OT  - artificial intelligence
OT  - chatgpt
OT  - kidney transplantation
OT  - machine learning
OT  - research
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/08/21 06:42
MHDA- 2023/08/21 06:43
PMCR- 2023/07/19
CRDT- 2023/08/21 05:09
PHST- 2023/07/18 00:00 [accepted]
PHST- 2023/08/21 06:43 [medline]
PHST- 2023/08/21 06:42 [pubmed]
PHST- 2023/08/21 05:09 [entrez]
PHST- 2023/07/19 00:00 [pmc-release]
AID - 10.7759/cureus.42150 [doi]
PST - epublish
SO  - Cureus. 2023 Jul 19;15(7):e42150. doi: 10.7759/cureus.42150. eCollection 2023 
      Jul.

PMID- 37885522
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231028
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 9
DP  - 2023 Sep
TI  - Analyzing the Performance of ChatGPT About Osteoporosis.
PG  - e45890
LID - 10.7759/cureus.45890 [doi]
LID - e45890
AB  - INTRODUCTION: This study evaluates the knowledge of ChatGPT about osteoporosis. 
      METHODS: Osteoporosis-related frequently asked questions (FAQs) created by 
      examining the websites frequently visited by patients, the official websites of 
      hospitals, and social media. Questions based on these scientific data have been 
      prepared in accordance with National Osteoporosis Guideline Group guides. Rater 
      scored all ChatGPT answers between 1 and 4 (1 stated that the information was 
      completely correct, 2 stated that the information was correct but insufficient, 3 
      stated that although some of the information was correct, there was incorrect 
      information in the answer, and 4 stated that the answer consisted of completely 
      incorrect information). The reproducibility of ChatGPT responses on osteoporosis 
      was assessed by asking each question twice. The repeatability of the ChatGPT 
      answer was considered as getting the same score twice. RESULTS: ChatGPT responded 
      to 72 FAQs with an accuracy rate of 80.6%. The highest accuracy in ChatGPT's 
      answers about osteoporosis was in the prevention category, 91.7%, and in the 
      general knowledge category, 85.8%. Only 19 of the 31 (61.3%) questions prepared 
      according to the National Osteoporosis Guideline Group guidelines were answered 
      correctly by ChatGPT, and two answers (6.4%) were categorized as grade 4. The 
      reproducibility rate of ChatGPT answers on 72 FAQs was 86.1% and the 
      reproducibility rate of ChatGPT answers on National Osteoporosis Guideline Group 
      guidelines was 83.9%. CONCLUSION: Present study outcomes for the first time 
      showed that ChatGPT provided adequate answers to more than 80% of FAQs about 
      osteoporosis. However, the accuracy of ChatGPT's answers to inquiries based on 
      National Osteoporosis Guideline Group guidelines was decreased to 61.3%.
CI  - Copyright © 2023, Cinar et al.
FAU - Cinar, Cigdem
AU  - Cinar C
AD  - Department of Interventional Physiatry, Biruni University, Istanbul, TUR.
LA  - eng
PT  - Journal Article
DEP - 20230925
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10599213
OTO - NOTNLM
OT  - artificial intelligence
OT  - chatgpt
OT  - guideline
OT  - information source
OT  - osteoporosis
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/10/27 06:43
MHDA- 2023/10/27 06:44
PMCR- 2023/09/25
CRDT- 2023/10/27 04:19
PHST- 2023/09/24 00:00 [accepted]
PHST- 2023/10/27 06:44 [medline]
PHST- 2023/10/27 06:43 [pubmed]
PHST- 2023/10/27 04:19 [entrez]
PHST- 2023/09/25 00:00 [pmc-release]
AID - 10.7759/cureus.45890 [doi]
PST - epublish
SO  - Cureus. 2023 Sep 25;15(9):e45890. doi: 10.7759/cureus.45890. eCollection 2023 
      Sep.

PMID- 38028668
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231201
IS  - 2624-8212 (Electronic)
IS  - 2624-8212 (Linking)
VI  - 6
DP  - 2023
TI  - Overview of Chatbots with special emphasis on artificial intelligence-enabled 
      ChatGPT in medical science.
PG  - 1237704
LID - 10.3389/frai.2023.1237704 [doi]
LID - 1237704
AB  - The release of ChatGPT has initiated new thinking about AI-based Chatbot and its 
      application and has drawn huge public attention worldwide. Researchers and 
      doctors have started thinking about the promise and application of AI-related 
      large language models in medicine during the past few months. Here, the 
      comprehensive review highlighted the overview of Chatbot and ChatGPT and their 
      current role in medicine. Firstly, the general idea of Chatbots, their evolution, 
      architecture, and medical use are discussed. Secondly, ChatGPT is discussed with 
      special emphasis of its application in medicine, architecture and training 
      methods, medical diagnosis and treatment, research ethical issues, and a 
      comparison of ChatGPT with other NLP models are illustrated. The article also 
      discussed the limitations and prospects of ChatGPT. In the future, these large 
      language models and ChatGPT will have immense promise in healthcare. However, 
      more research is needed in this direction.
CI  - Copyright © 2023 Chakraborty, Pal, Bhattacharya, Dash and Lee.
FAU - Chakraborty, Chiranjib
AU  - Chakraborty C
AD  - Department of Biotechnology, School of Life Science and Biotechnology, Adamas 
      University, Kolkata, West Bengal, India.
FAU - Pal, Soumen
AU  - Pal S
AD  - School of Mechanical Engineering, Vellore Institute of Technology, Vellore, Tamil 
      Nadu, India.
FAU - Bhattacharya, Manojit
AU  - Bhattacharya M
AD  - Department of Zoology, Fakir Mohan University, Balasore, Odisha, India.
FAU - Dash, Snehasish
AU  - Dash S
AD  - School of Mechanical Engineering, Vellore Institute of Technology, Vellore, Tamil 
      Nadu, India.
FAU - Lee, Sang-Soo
AU  - Lee SS
AD  - Institute for Skeletal Aging and Orthopedic Surgery, Hallym University Chuncheon 
      Sacred Heart Hospital, Chuncheon-si, Gangwon-do, Republic of Korea.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20231031
PL  - Switzerland
TA  - Front Artif Intell
JT  - Frontiers in artificial intelligence
JID - 101770551
PMC - PMC10644239
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - Chatbot
OT  - large language models
OT  - medical use
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/11/29 18:43
MHDA- 2023/11/29 18:44
PMCR- 2023/10/31
CRDT- 2023/11/29 17:16
PHST- 2023/06/09 00:00 [received]
PHST- 2023/10/05 00:00 [accepted]
PHST- 2023/11/29 18:44 [medline]
PHST- 2023/11/29 18:43 [pubmed]
PHST- 2023/11/29 17:16 [entrez]
PHST- 2023/10/31 00:00 [pmc-release]
AID - 10.3389/frai.2023.1237704 [doi]
PST - epublish
SO  - Front Artif Intell. 2023 Oct 31;6:1237704. doi: 10.3389/frai.2023.1237704. 
      eCollection 2023.

PMID- 37197105
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230519
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 4
DP  - 2023 Apr
TI  - Evaluation of ChatGPT's Capabilities in Medical Report Generation.
PG  - e37589
LID - 10.7759/cureus.37589 [doi]
LID - e37589
AB  - The growing demand for efficient healthcare delivery has intensified the need for 
      technological innovations that facilitate medical professionals' decision-making 
      processes. In this study, we investigate ChatGPT (OpenAI Incorporated, Mission 
      District, San Francisco, United States), a state-of-the-art language model based 
      on the GPT-4 architecture, as an effective tool for assisting healthcare 
      professionals in writing medical reports based on real patient&nbsp;laboratory 
      results. By leveraging ChatGPT's extraordinary performance across multiple 
      medical domains, including lab result diagnostics and medical literature 
      analysis, we aimed to streamline and enhance the medical report generation 
      process. The generated case report presents a 31-year-old male patient with no 
      significant past medical history who visited a clinic to establish care and seek 
      evaluation for abdominal pain. Following routine laboratory tests, including a 
      complete blood count, comprehensive metabolic panel, and a Helicobacter pylori 
      breath test, ChatGPT provided tailored recommendations addressing identified 
      concerns and abnormalities. These included lifestyle modifications, such as 
      dietary changes, weight management, and avoiding trigger foods or behaviors; 
      alongside medical treatment options, the patient was advised to consult a 
      gastroenterologist for further evaluation and potential advanced treatment 
      options. The organization and structure of this case study are derived from 
      ChatGPT's output, using patient's actual physical information and lab results as 
      input, without any prior knowledge. Ultimately, we will compare the generated 
      report with suggestions from an online doctor consultation system to demonstrate 
      the precision and reliability of ChatGPT's recommendations. Through this 
      comparison, we aim to show that ChatGPT can produce coherent, comprehensive, and 
      clinically relevant medical reports with a relatively high degree of accuracy and 
      consistency.
CI  - Copyright © 2023, Zhou et al.
FAU - Zhou, Zeyu
AU  - Zhou Z
AD  - Computer Science, Georgia Institute of Technology, Atlanta, USA.
LA  - eng
PT  - Case Reports
DEP - 20230414
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10184716
OTO - NOTNLM
OT  - chatgpt
OT  - epigastric
OT  - epigastric pain
OT  - gerd
OT  - medical examination
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/05/18 01:07
MHDA- 2023/05/18 01:08
PMCR- 2023/04/14
CRDT- 2023/05/17 19:55
PHST- 2023/04/14 00:00 [accepted]
PHST- 2023/05/18 01:08 [medline]
PHST- 2023/05/18 01:07 [pubmed]
PHST- 2023/05/17 19:55 [entrez]
PHST- 2023/04/14 00:00 [pmc-release]
AID - 10.7759/cureus.37589 [doi]
PST - epublish
SO  - Cureus. 2023 Apr 14;15(4):e37589. doi: 10.7759/cureus.37589. eCollection 2023 
      Apr.

PMID- 37061593
OWN - NLM
STAT- MEDLINE
DCOM- 20230523
LR  - 20230523
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 51
IP  - 6
DP  - 2023 Jun
TI  - Behind the ChatGPT Hype: Are Its Suggestions Contributing to Addiction?
PG  - 1128-1129
LID - 10.1007/s10439-023-03201-5 [doi]
AB  - ChatGPT has been a frequent topic of discussion lately. All over the Internet, 
      from YouTube to blogs, there have been reports about how ChatGPT is able to plan 
      people's daily activities, even for a whole month. However, what matters is what 
      activities ChatGPT recommends. When ChatGPT was trained on a vast amount of data 
      from the Internet, we wondered if it would suggest activities that can lead to 
      addiction. In our test, not once did ChatGPT recommend an activity related to 
      alcohol, drug use, or any other activity that can lead to addiction with serious 
      health consequences. Suggestions seemed more like self-improvement posts on blogs 
      than discussion forums where people might mention drinking in the evenings. Thus, 
      if a person were to use ChatGPT as a personal lifestyle advisor, it does not 
      appear on the basis of this test that ChatGPT would recommend activities that 
      would be fundamentally detrimental to their health. However, more detailed 
      long-term testing of similar tools is needed before recommendations for use in 
      practice can be made.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Haman, Michael
AU  - Haman M
AUID- ORCID: 0000-0001-5772-2045
AD  - Department of Humanities, Faculty of Economics and Management, Czech University 
      of Life Sciences Prague, Kamýcká 129, 165 00, Prague-Suchdol, Czechia. 
      haman@pef.czu.cz.
FAU - Školník, Milan
AU  - Školník M
AUID- ORCID: 0000-0002-0672-219X
AD  - Department of Humanities, Faculty of Economics and Management, Czech University 
      of Life Sciences Prague, Kamýcká 129, 165 00, Prague-Suchdol, Czechia.
LA  - eng
PT  - Letter
DEP - 20230415
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Addiction Medicine
OTO - NOTNLM
OT  - AI
OT  - Addiction
OT  - ChatGPT
OT  - Language model
OT  - Personal improvement
EDAT- 2023/04/16 06:00
MHDA- 2023/05/12 07:06
CRDT- 2023/04/15 23:18
PHST- 2023/03/31 00:00 [received]
PHST- 2023/04/03 00:00 [accepted]
PHST- 2023/05/12 07:06 [medline]
PHST- 2023/04/16 06:00 [pubmed]
PHST- 2023/04/15 23:18 [entrez]
AID - 10.1007/s10439-023-03201-5 [pii]
AID - 10.1007/s10439-023-03201-5 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2023 Jun;51(6):1128-1129. doi: 10.1007/s10439-023-03201-5. Epub 
      2023 Apr 15.

PMID- 38476626
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240314
IS  - 1178-7074 (Print)
IS  - 1178-7074 (Electronic)
IS  - 1178-7074 (Linking)
VI  - 17
DP  - 2024
TI  - The Potential Applications and Challenges of ChatGPT in the Medical Field.
PG  - 817-826
LID - 10.2147/IJGM.S456659 [doi]
AB  - ChatGPT, an AI-driven conversational large language model (LLM), has garnered 
      significant scholarly attention since its inception, owing to its manifold 
      applications in the realm of medical science. This study primarily examines the 
      merits, limitations, anticipated developments, and practical applications of 
      ChatGPT in clinical practice, healthcare, medical education, and medical 
      research. It underscores the necessity for further research and development to 
      enhance its performance and deployment. Moreover, future research avenues 
      encompass ongoing enhancements and standardization of ChatGPT, mitigating its 
      limitations, and exploring its integration and applicability in translational and 
      personalized medicine. Reflecting the narrative nature of this review, a focused 
      literature search was performed to identify relevant publications on ChatGPT's 
      use in medicine. This process was aimed at gathering a broad spectrum of insights 
      to provide a comprehensive overview of the current state and future prospects of 
      ChatGPT in the medical domain. The objective is to aid healthcare professionals 
      in understanding the groundbreaking advancements associated with the latest 
      artificial intelligence tools, while also acknowledging the opportunities and 
      challenges presented by ChatGPT.
CI  - © 2024 Mu and He.
FAU - Mu, Yonglin
AU  - Mu Y
AUID- ORCID: 0009-0006-7275-3345
AD  - Department of Urology, Children's Hospital of Chongqing Medical University, 
      Chongqing, People's Republic of China.
FAU - He, Dawei
AU  - He D
AUID- ORCID: 0000-0002-1695-5886
AD  - Department of Urology, Children's Hospital of Chongqing Medical University, 
      Chongqing, People's Republic of China.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20240305
PL  - New Zealand
TA  - Int J Gen Med
JT  - International journal of general medicine
JID - 101515487
PMC - PMC10929156
OTO - NOTNLM
OT  - ChatGPT
OT  - challenges
OT  - clinical practice
OT  - healthcare
OT  - medical education
OT  - medical research
COIS- The authors report no conflicts of interest in this work. None of the authors 
      have direct conflicts of interest with OpenAI.
EDAT- 2024/03/13 06:47
MHDA- 2024/03/13 06:48
PMCR- 2024/03/05
CRDT- 2024/03/13 03:55
PHST- 2024/01/10 00:00 [received]
PHST- 2024/02/26 00:00 [accepted]
PHST- 2024/03/13 06:48 [medline]
PHST- 2024/03/13 06:47 [pubmed]
PHST- 2024/03/13 03:55 [entrez]
PHST- 2024/03/05 00:00 [pmc-release]
AID - 456659 [pii]
AID - 10.2147/IJGM.S456659 [doi]
PST - epublish
SO  - Int J Gen Med. 2024 Mar 5;17:817-826. doi: 10.2147/IJGM.S456659. eCollection 
      2024.

PMID- 37761751
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231003
IS  - 2227-9032 (Print)
IS  - 2227-9032 (Electronic)
IS  - 2227-9032 (Linking)
VI  - 11
IP  - 18
DP  - 2023 Sep 15
TI  - ChatGPT's Skills in Statistical Analysis Using the Example of Allergology: Do We 
      Have Reason for Concern?
LID - 10.3390/healthcare11182554 [doi]
LID - 2554
AB  - BACKGROUND: Content generated by artificial intelligence is sometimes not 
      truthful. To date, there have been a number of medical studies related to the 
      validity of ChatGPT's responses; however, there is a lack of studies addressing 
      various aspects of statistical analysis. The aim of this study was to assess the 
      validity of the answers provided by ChatGPT in relation to statistical analysis, 
      as well as to identify recommendations to be implemented in the future in 
      connection with the results obtained. METHODS: The study was divided into four 
      parts and was based on the exemplary medical field of allergology. The first part 
      consisted of asking ChatGPT 30 different questions related to statistical 
      analysis. The next five questions included a request for ChatGPT to perform the 
      relevant statistical analyses, and another five requested ChatGPT to indicate 
      which statistical test should be applied to articles accepted for publication in 
      Allergy. The final part of the survey involved asking ChatGPT the same 
      statistical question three times. RESULTS: Out of the 40 general questions asked 
      that related to broad statistical analysis, ChatGPT did not fully answer half of 
      them. Assumptions necessary for the application of specific statistical tests 
      were not included. ChatGPT also gave completely divergent answers to one question 
      about which test should be used. CONCLUSION: The answers provided by ChatGPT to 
      various statistical questions may give rise to the use of inappropriate 
      statistical tests and, consequently, the subsequent misinterpretation of the 
      research results obtained. Questions asked in this regard need to be framed more 
      precisely.
FAU - Ordak, Michal
AU  - Ordak M
AUID- ORCID: 0000-0001-5652-4397
AD  - Department of Pharmacotherapy and Pharmaceutical Care, Faculty of Pharmacy, 
      Medical University of Warsaw, Banacha 1 Str., 02-097 Warsaw, Poland.
LA  - eng
PT  - Journal Article
DEP - 20230915
PL  - Switzerland
TA  - Healthcare (Basel)
JT  - Healthcare (Basel, Switzerland)
JID - 101666525
PMC - PMC10530997
OTO - NOTNLM
OT  - ChatGPT
OT  - statistical analysis
COIS- The author has no conflict of interest to declare.
EDAT- 2023/09/28 06:42
MHDA- 2023/09/28 06:43
PMCR- 2023/09/15
CRDT- 2023/09/28 01:14
PHST- 2023/08/16 00:00 [received]
PHST- 2023/09/13 00:00 [revised]
PHST- 2023/09/13 00:00 [accepted]
PHST- 2023/09/28 06:43 [medline]
PHST- 2023/09/28 06:42 [pubmed]
PHST- 2023/09/28 01:14 [entrez]
PHST- 2023/09/15 00:00 [pmc-release]
AID - healthcare11182554 [pii]
AID - healthcare-11-02554 [pii]
AID - 10.3390/healthcare11182554 [doi]
PST - epublish
SO  - Healthcare (Basel). 2023 Sep 15;11(18):2554. doi: 10.3390/healthcare11182554.

PMID- 38153785
OWN - NLM
STAT- MEDLINE
DCOM- 20231229
LR  - 20240114
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Dec 28
TI  - Differentiating ChatGPT-Generated and Human-Written Medical Texts: Quantitative 
      Study.
PG  - e48904
LID - 10.2196/48904 [doi]
LID - e48904
AB  - BACKGROUND: Large language models, such as ChatGPT, are capable of generating 
      grammatically perfect and human-like text content, and a large number of 
      ChatGPT-generated texts have appeared on the internet. However, medical texts, 
      such as clinical notes and diagnoses, require rigorous validation, and erroneous 
      medical content generated by ChatGPT could potentially lead to disinformation 
      that poses significant harm to health care and the general public. OBJECTIVE: 
      This study is among the first on responsible artificial intelligence-generated 
      content in medicine. We focus on analyzing the differences between medical texts 
      written by human experts and those generated by ChatGPT and designing machine 
      learning workflows to effectively detect and differentiate medical texts 
      generated by ChatGPT. METHODS: We first constructed a suite of data sets 
      containing medical texts written by human experts and generated by ChatGPT. We 
      analyzed the linguistic features of these 2 types of content and uncovered 
      differences in vocabulary, parts-of-speech, dependency, sentiment, perplexity, 
      and other aspects. Finally, we designed and implemented machine learning methods 
      to detect medical text generated by ChatGPT. The data and code used in this paper 
      are published on GitHub. RESULTS: Medical texts written by humans were more 
      concrete, more diverse, and typically contained more useful information, while 
      medical texts generated by ChatGPT paid more attention to fluency and logic and 
      usually expressed general terminologies rather than effective information 
      specific to the context of the problem. A bidirectional encoder representations 
      from transformers-based model effectively detected medical texts generated by 
      ChatGPT, and the F(1) score exceeded 95%. CONCLUSIONS: Although text generated by 
      ChatGPT is grammatically perfect and human-like, the linguistic characteristics 
      of generated medical texts were different from those written by human experts. 
      Medical text generated by ChatGPT could be effectively detected by the proposed 
      machine learning algorithms. This study provides a pathway toward trustworthy and 
      accountable use of large language models in medicine.
CI  - ©Wenxiong Liao, Zhengliang Liu, Haixing Dai, Shaochen Xu, Zihao Wu, Yiyang Zhang, 
      Xiaoke Huang, Dajiang Zhu, Hongmin Cai, Quanzheng Li, Tianming Liu, Xiang Li. 
      Originally published in JMIR Medical Education (https://mededu.jmir.org), 
      28.12.2023.
FAU - Liao, Wenxiong
AU  - Liao W
AUID- ORCID: 0000-0002-9432-9426
AD  - School of Computer Science and Engineering, South China University of Technology, 
      Guangzhou, China.
FAU - Liu, Zhengliang
AU  - Liu Z
AUID- ORCID: 0000-0001-7061-6714
AD  - School of Computing, University of Georgia, Athens, GA, United States.
FAU - Dai, Haixing
AU  - Dai H
AUID- ORCID: 0000-0003-0409-6129
AD  - School of Computing, University of Georgia, Athens, GA, United States.
FAU - Xu, Shaochen
AU  - Xu S
AUID- ORCID: 0009-0008-0802-9218
AD  - School of Computing, University of Georgia, Athens, GA, United States.
FAU - Wu, Zihao
AU  - Wu Z
AUID- ORCID: 0000-0001-7483-6570
AD  - School of Computing, University of Georgia, Athens, GA, United States.
FAU - Zhang, Yiyang
AU  - Zhang Y
AUID- ORCID: 0000-0001-5625-0971
AD  - School of Computer Science and Engineering, South China University of Technology, 
      Guangzhou, China.
FAU - Huang, Xiaoke
AU  - Huang X
AUID- ORCID: 0000-0002-1795-3065
AD  - School of Computer Science and Engineering, South China University of Technology, 
      Guangzhou, China.
FAU - Zhu, Dajiang
AU  - Zhu D
AUID- ORCID: 0000-0002-6940-3911
AD  - Department of Computer Science and Engineering, University of Texas at Arlington, 
      Arlington, TX, United States.
FAU - Cai, Hongmin
AU  - Cai H
AUID- ORCID: 0000-0002-2747-7234
AD  - School of Computer Science and Engineering, South China University of Technology, 
      Guangzhou, China.
FAU - Li, Quanzheng
AU  - Li Q
AUID- ORCID: 0000-0002-9651-5820
AD  - Department of Radiology, Massachusetts General Hospital, Boston, MA, United 
      States.
FAU - Liu, Tianming
AU  - Liu T
AUID- ORCID: 0000-0002-8132-9048
AD  - School of Computing, University of Georgia, Athens, GA, United States.
FAU - Li, Xiang
AU  - Li X
AUID- ORCID: 0000-0002-9851-6376
AD  - Department of Radiology, Massachusetts General Hospital, Boston, MA, United 
      States.
LA  - eng
PT  - Journal Article
DEP - 20231228
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Algorithms
MH  - Disinformation
MH  - Electric Power Supplies
MH  - Health Facilities
PMC - PMC10784984
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - linguistic analysis
OT  - machine learning
OT  - medical ethics
OT  - medical texts
OT  - text classification
COIS- Conflicts of Interest: None declared.
EDAT- 2023/12/28 12:42
MHDA- 2023/12/29 06:43
PMCR- 2023/12/28
CRDT- 2023/12/28 11:54
PHST- 2023/05/19 00:00 [received]
PHST- 2023/09/10 00:00 [accepted]
PHST- 2023/08/03 00:00 [revised]
PHST- 2023/12/29 06:43 [medline]
PHST- 2023/12/28 12:42 [pubmed]
PHST- 2023/12/28 11:54 [entrez]
PHST- 2023/12/28 00:00 [pmc-release]
AID - v9i1e48904 [pii]
AID - 10.2196/48904 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Dec 28;9:e48904. doi: 10.2196/48904.

PMID- 38078232
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231211
IS  - 1664-1078 (Print)
IS  - 1664-1078 (Electronic)
IS  - 1664-1078 (Linking)
VI  - 14
DP  - 2023
TI  - ChatGPT's advice is perceived as better than that of professional advice 
      columnists.
PG  - 1281255
LID - 10.3389/fpsyg.2023.1281255 [doi]
LID - 1281255
AB  - ChatGPT is a high-performance large language model that has the potential to 
      significantly improve human-computer interactions. It can provide advice on a 
      range of topics, but it is unclear how good this advice is relative to that 
      provided by competent humans, especially in situations where empathy is required. 
      Here, we report the first investigation of whether ChatGPT's responses are 
      perceived as better than those of humans in a task where humans were attempting 
      to be empathetic. Fifty social dilemma questions were randomly selected from 10 
      well-known advice columns. In a pre-registered survey, participants (N = 404) 
      were each shown one question, along with the corresponding response by an advice 
      columnist and by ChatGPT. ChatGPT's advice was perceived as more balanced, 
      complete, empathetic, helpful, and better than the advice provided by 
      professional advice columnists (all values of p &lt; 0.001). Although participants 
      could not determine which response was written by ChatGPT (54%, p = 0.29), most 
      participants preferred that their own social dilemma questions be answered by a 
      human than by a computer (77%, p &lt; 0.001). ChatGPT's responses were longer than 
      those produced by the advice columnists (mean 280.9 words vs. 142.2 words, 
      p &lt; 0.001). In a second pre-registered survey, each ChatGPT answer was 
      constrained to be approximately the same length as that of the advice columnist 
      (mean 143.2 vs. 142.2 words, p = 0.95). This survey (N = 401) replicated the 
      above findings, showing that the benefit of ChatGPT was not solely due to it 
      writing longer answers.
CI  - Copyright © 2023 Howe, Fay, Saletta and Hovy.
FAU - Howe, Piers Douglas Lionel
AU  - Howe PDL
AD  - Complex Human Data Hub, Melbourne School of Psychological Sciences, University of 
      Melbourne, Melbourne, VIC, Australia.
FAU - Fay, Nicolas
AU  - Fay N
AD  - School of Psychological Science, University of Western Australia, Perth, WA, 
      Australia.
FAU - Saletta, Morgan
AU  - Saletta M
AD  - Hunt Laboratory, University of Melbourne, Melbourne, VIC, Australia.
FAU - Hovy, Eduard
AU  - Hovy E
AD  - Melbourne Connect, University of Melbourne, Melbourne, VIC, Australia.
LA  - eng
PT  - Journal Article
DEP - 20231121
PL  - Switzerland
TA  - Front Psychol
JT  - Frontiers in psychology
JID - 101550902
PMC - PMC10702579
OTO - NOTNLM
OT  - ChatGPT
OT  - advice
OT  - advice column
OT  - agony aunt
OT  - empathy
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/12/11 12:43
MHDA- 2023/12/11 12:44
PMCR- 2023/11/21
CRDT- 2023/12/11 06:41
PHST- 2023/08/22 00:00 [received]
PHST- 2023/10/30 00:00 [accepted]
PHST- 2023/12/11 12:44 [medline]
PHST- 2023/12/11 12:43 [pubmed]
PHST- 2023/12/11 06:41 [entrez]
PHST- 2023/11/21 00:00 [pmc-release]
AID - 10.3389/fpsyg.2023.1281255 [doi]
PST - epublish
SO  - Front Psychol. 2023 Nov 21;14:1281255. doi: 10.3389/fpsyg.2023.1281255. 
      eCollection 2023.

PMID- 38049299
OWN - NLM
STAT- MEDLINE
DCOM- 20231206
LR  - 20231217
IS  - 1938-2421 (Electronic)
IS  - 0148-4834 (Linking)
VI  - 62
IP  - 12
DP  - 2023 Dec
TI  - ChatGPT for Automated Writing Evaluation in Scholarly Writing Instruction.
PG  - 721-727
LID - 10.3928/01484834-20231006-02 [doi]
AB  - BACKGROUND: Effective strategies for developing scholarly writing skills in 
      postsecondary nursing students are needed. Generative artificial intelligence 
      (GAI) tools, such as ChatGPT, for automated writing evaluation (AWE) hold promise 
      for mitigating challenges associated with scholarly writing instruction in 
      nursing education. This article explores the suitability of ChatGPT for AWE in 
      writing instruction. METHOD: ChatGPT feedback on 42 nursing student texts from 
      the Michigan Corpus of Upper-Level Student Papers was assessed. Assessment 
      criteria were derived from recent AWE research. RESULTS: ChatGPT demonstrated 
      utility as an AWE tool. Its scoring performance demonstrated stricter grading 
      than human raters, related feedback to macro-level writing features, and 
      supported multiple submissions and learner autonomy. CONCLUSION: Despite concerns 
      surrounding GAI in academia, educators can accelerate the feedback process 
      without increasing their workload, and students can receive individualized 
      feedback by incorporating AWE provided by ChatGPT into the writing process. [J 
      Nurs Educ. 2023;62(12):721-727.].
FAU - Parker, Jessica L
AU  - Parker JL
FAU - Becker, Kimberly
AU  - Becker K
FAU - Carroca, Catherine
AU  - Carroca C
LA  - eng
PT  - Journal Article
DEP - 20231201
PL  - United States
TA  - J Nurs Educ
JT  - The Journal of nursing education
JID - 7705432
SB  - IM
MH  - Humans
MH  - Artificial Intelligence
MH  - *Education, Nursing
MH  - Feedback
MH  - Writing
MH  - *Students, Nursing
EDAT- 2023/12/05 00:41
MHDA- 2023/12/06 06:42
CRDT- 2023/12/04 21:02
PHST- 2023/12/06 06:42 [medline]
PHST- 2023/12/05 00:41 [pubmed]
PHST- 2023/12/04 21:02 [entrez]
AID - 10.3928/01484834-20231006-02 [doi]
PST - ppublish
SO  - J Nurs Educ. 2023 Dec;62(12):721-727. doi: 10.3928/01484834-20231006-02. Epub 
      2023 Dec 1.

PMID- 38041797
OWN - NLM
STAT- In-Process
LR  - 20240403
IS  - 1943-7722 (Electronic)
IS  - 0002-9173 (Linking)
VI  - 161
IP  - 4
DP  - 2024 Apr 3
TI  - Evaluation of ChatGPT pathology knowledge using board-style questions.
PG  - 393-398
LID - 10.1093/ajcp/aqad158 [doi]
AB  - OBJECTIVES: ChatGPT is an artificial intelligence chatbot developed by OpenAI. 
      Its extensive knowledge and unique interactive capabilities enable its use in 
      various innovative ways in the medical field, such as writing clinical notes and 
      simplifying radiology reports. Through this study, we aimed to analyze the 
      pathology knowledge of ChatGPT to advocate its role in transforming pathology 
      education. METHODS: The American Society for Clinical Pathology Resident Question 
      Bank 2022 was used to test ChatGPT, version 4. Practice tests were created in 
      each subcategory and answered based on the input that ChatGPT provided. Questions 
      that required interpretation of images were excluded. We analyzed ChatGPT 
      performance and compared it with average peer performance. RESULTS: The overall 
      performance of ChatGPT was 56.98%, lower than that of the average peer 
      performance of 62.81%. ChatGPT performed better on clinical pathology (60.42%) 
      than on anatomic pathology (54.94%). Furthermore, its performance was better on 
      easy questions (68.47%) than on intermediate (52.88%) and difficult questions 
      (37.21%). CONCLUSIONS: ChatGPT has the potential to be a valuable resource in 
      pathology education if trained on a larger, specialized medical data set. Those 
      relying on it (in its current form) solely for the purpose of pathology training 
      should be cautious.
CI  - © The Author(s) 2023. Published by Oxford University Press on behalf of American 
      Society for Clinical Pathology. All rights reserved. For permissions, please 
      e-mail: journals.permissions@oup.com.
FAU - Geetha, Saroja D
AU  - Geetha SD
AD  - Department of Pathology and Laboratory Medicine, North Shore University Hospital 
      and Long Island Jewish Medical Center, Donald and Barbara Zucker School of 
      Medicine at Hofstra/Northwell Health, Greenvale, NY, US.
FAU - Khan, Anam
AU  - Khan A
AD  - Department of Pathology and Laboratory Medicine, North Shore University Hospital 
      and Long Island Jewish Medical Center, Donald and Barbara Zucker School of 
      Medicine at Hofstra/Northwell Health, Greenvale, NY, US.
FAU - Khan, Atif
AU  - Khan A
AD  - Department of Pathology and Laboratory Medicine, North Shore University Hospital 
      and Long Island Jewish Medical Center, Donald and Barbara Zucker School of 
      Medicine at Hofstra/Northwell Health, Greenvale, NY, US.
FAU - Kannadath, Bijun S
AU  - Kannadath BS
AD  - Department of Internal Medicine, University of Arizona College of Medicine, 
      Phoenix, AZ, US.
FAU - Vitkovski, Taisia
AU  - Vitkovski T
AD  - Department of Pathology and Laboratory Medicine, North Shore University Hospital 
      and Long Island Jewish Medical Center, Donald and Barbara Zucker School of 
      Medicine at Hofstra/Northwell Health, Greenvale, NY, US.
LA  - eng
PT  - Journal Article
PL  - England
TA  - Am J Clin Pathol
JT  - American journal of clinical pathology
JID - 0370470
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - chatbot
OT  - natural language processing
OT  - neural networks
OT  - pathology education
EDAT- 2023/12/02 12:42
MHDA- 2023/12/02 12:42
CRDT- 2023/12/02 11:32
PHST- 2023/06/08 00:00 [received]
PHST- 2023/10/16 00:00 [accepted]
PHST- 2023/12/02 12:42 [pubmed]
PHST- 2023/12/02 12:42 [medline]
PHST- 2023/12/02 11:32 [entrez]
AID - 7457992 [pii]
AID - 10.1093/ajcp/aqad158 [doi]
PST - ppublish
SO  - Am J Clin Pathol. 2024 Apr 3;161(4):393-398. doi: 10.1093/ajcp/aqad158.

PMID- 38160089
OWN - NLM
STAT- Publisher
LR  - 20231230
IS  - 1878-4046 (Electronic)
IS  - 1076-6332 (Linking)
DP  - 2023 Dec 29
TI  - Could ChatGPT Pass the UK Radiology Fellowship Examinations?
LID - S1076-6332(23)00661-X [pii]
LID - 10.1016/j.acra.2023.11.026 [doi]
AB  - RATIONALE AND OBJECTIVES: Chat Generative Pre-trained Transformer (ChatGPT) is an 
      artificial intelligence (AI) tool which utilises machine learning to generate 
      original text resembling human language. AI models have recently demonstrated 
      remarkable ability at analysing and solving problems, including passing 
      professional examinations. We investigate the performance of ChatGPT on some of 
      the UK radiology fellowship equivalent examination questions. METHODS: ChatGPT 
      was asked to answer questions from question banks resembling the Fellowship of 
      the Royal College of Radiologists (FRCR) examination. The entire physics part 1 
      question bank (203 5-part true/false questions) was answered by the GPT-4 model 
      and answers recorded. 240 single best answer questions (SBAs) (representing the 
      true length of the FRCR 2A examination) were answered by both GPT-3.5 and GPT-4 
      models. RESULTS: ChatGPT 4 answered 74.8% of part 1 true/false statements 
      correctly. The spring 2023 passing mark of the part 1 examination was 75.5% and 
      ChatGPT thus narrowly failed. In the 2A examination, ChatGPT 3.5 answered 50.8% 
      SBAs correctly, while GPT-4 answered 74.2% correctly. The winter 2022 2A pass 
      mark was 63.3% and thus GPT-4 clearly passed. CONCLUSION: AI models such as 
      ChatGPT are able to answer the majority of questions in an FRCR style 
      examination. It is reasonable to assume that further developments in AI will be 
      more likely to succeed in comprehending and solving questions related to 
      medicine, specifically clinical radiology. ADVANCES IN KNOWLEDGE: Our findings 
      outline the unprecedented capabilities of AI, adding to the current relatively 
      small body of literature on the subject, which in turn can play a role medical 
      training, evaluation and practice. This can undoubtedly have implications for 
      radiology.
CI  - Copyright © 2023 The Association of University Radiologists. Published by 
      Elsevier Inc. All rights reserved.
FAU - Ariyaratne, Sisith
AU  - Ariyaratne S
AD  - Department of Musculoskeletal Radiology, The Royal Orthopaedic Hospital NHS 
      Foundation Trust, Northfield, Birmingham, UK (S.A., N.J., A.M.D., R.B.). 
      Electronic address: sisithariyaratne@gmail.com.
FAU - Jenko, Nathan
AU  - Jenko N
AD  - Department of Musculoskeletal Radiology, The Royal Orthopaedic Hospital NHS 
      Foundation Trust, Northfield, Birmingham, UK (S.A., N.J., A.M.D., R.B.).
FAU - Mark Davies, A
AU  - Mark Davies A
AD  - Department of Musculoskeletal Radiology, The Royal Orthopaedic Hospital NHS 
      Foundation Trust, Northfield, Birmingham, UK (S.A., N.J., A.M.D., R.B.).
FAU - Iyengar, Karthikeyan P
AU  - Iyengar KP
AD  - Department of Trauma &amp; Orthopaedics, Southport &amp; Ormskirk Hospitals, Mersey and 
      West Lancashire Teaching NHS Trust, Southport, UK (K.P.I.).
FAU - Botchu, Rajesh
AU  - Botchu R
AD  - Department of Musculoskeletal Radiology, The Royal Orthopaedic Hospital NHS 
      Foundation Trust, Northfield, Birmingham, UK (S.A., N.J., A.M.D., R.B.).
LA  - eng
PT  - Journal Article
DEP - 20231229
PL  - United States
TA  - Acad Radiol
JT  - Academic radiology
JID - 9440159
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - FRCR examination
COIS- Declaration of Competing Interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2024/01/02 11:42
MHDA- 2024/01/02 11:42
CRDT- 2023/12/30 21:54
PHST- 2023/08/24 00:00 [received]
PHST- 2023/11/12 00:00 [revised]
PHST- 2023/11/18 00:00 [accepted]
PHST- 2024/01/02 11:42 [medline]
PHST- 2024/01/02 11:42 [pubmed]
PHST- 2023/12/30 21:54 [entrez]
AID - S1076-6332(23)00661-X [pii]
AID - 10.1016/j.acra.2023.11.026 [doi]
PST - aheadofprint
SO  - Acad Radiol. 2023 Dec 29:S1076-6332(23)00661-X. doi: 10.1016/j.acra.2023.11.026.

PMID- 37891532
OWN - NLM
STAT- MEDLINE
DCOM- 20231030
LR  - 20231030
IS  - 1471-2334 (Electronic)
IS  - 1471-2334 (Linking)
VI  - 23
IP  - 1
DP  - 2023 Oct 27
TI  - ChatGPT and mycosis- a new weapon in the knowledge battlefield.
PG  - 731
LID - 10.1186/s12879-023-08724-9 [doi]
LID - 731
AB  - As current trend for physician tools, ChatGPT can sift through massive amounts of 
      information and solve problems through easy-to-understand conversations, 
      ultimately improving efficiency. Mycosis is currently facing great challenges, 
      including high fungal burdens, high mortality, limited choice of antifungal drugs 
      and increasing drug resistance. To address these challenges, We asked ChatGPT for 
      fungal infection scenario-based questions and assessed its appropriateness, 
      consistency, and potential pitfalls. We concluded ChatGPT can provide compelling 
      responses to most prompts, including diagnosis, recommendations for examination, 
      treatment and rational drug use. Moreover, we summarized exciting future 
      applications in mycosis, such as clinical work, scientific research, education 
      and healthcare. However, the largest barriers to implementation are deficits in 
      indiviudal advice, timely literature updates, consistency, accuracy and data 
      safety. To fully embrace the opportunity, we need to address these barriers and 
      manage the risks. We expect that ChatGPT will become a new weapon in in the 
      battlefield of mycosis.
CI  - © 2023. The Author(s).
FAU - Jin, Yi
AU  - Jin Y
AD  - Department of Dermatology, Shanghai Key Laboratory of Medical Mycology, Second 
      Affiliated Hospital of Naval Medical University, Shanghai, 200003, P.R. China.
FAU - Liu, Hua
AU  - Liu H
AD  - Department of Anesthesiology, Shanghai Ninth People's Hospital, Shanghai Jiao 
      Tong University School of Medicine, Shanghai, China.
FAU - Zhao, Bin
AU  - Zhao B
AD  - Department of Anesthesiology and SICU, Xinhua Hospital, School of Medicine, 
      Shanghai Jiao Tong University, Shanghai, 200092, P.R. China. 
      zbgbtj0926@gmail.com.
FAU - Pan, Weihua
AU  - Pan W
AD  - Department of Dermatology, Shanghai Key Laboratory of Medical Mycology, Second 
      Affiliated Hospital of Naval Medical University, Shanghai, 200003, P.R. China. 
      panweihua9@sina.com.
LA  - eng
GR  - grant no. 2021QN38/Naval Medical University/
PT  - Journal Article
DEP - 20231027
PL  - England
TA  - BMC Infect Dis
JT  - BMC infectious diseases
JID - 100968551
RN  - 0 (Antifungal Agents)
SB  - IM
MH  - Humans
MH  - *Mycoses/diagnosis/drug therapy
MH  - Antifungal Agents/therapeutic use
MH  - Communication
MH  - Educational Status
MH  - Health Facilities
PMC - PMC10605453
OTO - NOTNLM
OT  - Applications
OT  - ChatGPT
OT  - Mycosis
COIS- The authors declare no competing interests.
EDAT- 2023/10/28 11:42
MHDA- 2023/10/30 06:47
PMCR- 2023/10/27
CRDT- 2023/10/27 23:47
PHST- 2023/08/27 00:00 [received]
PHST- 2023/10/17 00:00 [accepted]
PHST- 2023/10/30 06:47 [medline]
PHST- 2023/10/28 11:42 [pubmed]
PHST- 2023/10/27 23:47 [entrez]
PHST- 2023/10/27 00:00 [pmc-release]
AID - 10.1186/s12879-023-08724-9 [pii]
AID - 8724 [pii]
AID - 10.1186/s12879-023-08724-9 [doi]
PST - epublish
SO  - BMC Infect Dis. 2023 Oct 27;23(1):731. doi: 10.1186/s12879-023-08724-9.

PMID- 37948112
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231127
IS  - 2369-3762 (Print)
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Nov 10
TI  - ChatGPT Interactive Medical Simulations for Early Clinical Education: Case Study.
PG  - e49877
LID - 10.2196/49877 [doi]
LID - e49877
AB  - BACKGROUND: The transition to clinical clerkships can be difficult for medical 
      students, as it requires the synthesis and application of preclinical information 
      into diagnostic and therapeutic decisions. ChatGPT-a generative language model 
      with many medical applications due to its creativity, memory, and accuracy-can 
      help students in this transition. OBJECTIVE: This paper models ChatGPT 3.5's 
      ability to perform interactive clinical simulations and shows this tool's benefit 
      to medical education. METHODS: Simulation starting prompts were refined using 
      ChatGPT 3.5 in Google Chrome. Starting prompts were selected based on assessment 
      format, stepwise progression of simulation events and questions, free-response 
      question type, responsiveness to user inputs, postscenario feedback, and medical 
      accuracy of the feedback. The chosen scenarios were advanced cardiac life support 
      and medical intensive care (for sepsis and pneumonia). RESULTS: Two starting 
      prompts were chosen. Prompt 1 was developed through 3 test simulations and used 
      successfully in 2 simulations. Prompt 2 was developed through 10 additional test 
      simulations and used successfully in 1 simulation. CONCLUSIONS: ChatGPT is 
      capable of creating simulations for early clinical education. These simulations 
      let students practice novel parts of the clinical curriculum, such as forming 
      independent diagnostic and therapeutic impressions over an entire patient 
      encounter. Furthermore, the simulations can adapt to user inputs in a way that 
      replicates real life more accurately than premade question bank clinical 
      vignettes. Finally, ChatGPT can create potentially unlimited free simulations 
      with specific feedback, which increases access for medical students with lower 
      socioeconomic status and underresourced medical schools. However, no tool is 
      perfect, and ChatGPT is no exception; there are concerns about simulation 
      accuracy and replicability that need to be addressed to further optimize 
      ChatGPT's performance as an educational resource.
CI  - ©Riley Scherr, Faris F Halaseh, Aidin Spina, Saman Andalib, Ronald Rivera. 
      Originally published in JMIR Medical Education (https://mededu.jmir.org), 
      10.11.2023.
FAU - Scherr, Riley
AU  - Scherr R
AUID- ORCID: 0009-0008-4796-4081
AD  - Irvine School of Medicine, University of California, Irvine, CA, United States.
FAU - Halaseh, Faris F
AU  - Halaseh FF
AUID- ORCID: 0000-0003-0569-1915
AD  - Irvine School of Medicine, University of California, Irvine, CA, United States.
FAU - Spina, Aidin
AU  - Spina A
AUID- ORCID: 0000-0003-3994-9646
AD  - Irvine School of Medicine, University of California, Irvine, CA, United States.
FAU - Andalib, Saman
AU  - Andalib S
AUID- ORCID: 0009-0002-3281-8256
AD  - Irvine School of Medicine, University of California, Irvine, CA, United States.
FAU - Rivera, Ronald
AU  - Rivera R
AUID- ORCID: 0000-0002-2221-9877
AD  - Department of Emergency Medicine, Irvine School of Medicine, University of 
      California, Irvine, CA, United States.
LA  - eng
PT  - Journal Article
DEP - 20231110
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
PMC - PMC10674152
OTO - NOTNLM
OT  - AI
OT  - AI in medical education
OT  - ChatGPT
OT  - artificial intelligence
OT  - clinical education
OT  - curriculum
OT  - generative
OT  - medical education
OT  - medical school simulations
OT  - preclinical curriculum
OT  - simulation
OT  - simulations
COIS- Conflicts of Interest: None declared.
EDAT- 2023/11/10 12:44
MHDA- 2023/11/10 12:45
PMCR- 2023/11/10
CRDT- 2023/11/10 11:54
PHST- 2023/06/14 00:00 [received]
PHST- 2023/10/20 00:00 [accepted]
PHST- 2023/08/30 00:00 [revised]
PHST- 2023/11/10 12:45 [medline]
PHST- 2023/11/10 12:44 [pubmed]
PHST- 2023/11/10 11:54 [entrez]
PHST- 2023/11/10 00:00 [pmc-release]
AID - v9i1e49877 [pii]
AID - 10.2196/49877 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Nov 10;9:e49877. doi: 10.2196/49877.

PMID- 37711151
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230917
IS  - 2054-5703 (Print)
IS  - 2054-5703 (Electronic)
IS  - 2054-5703 (Linking)
VI  - 10
IP  - 9
DP  - 2023 Sep
TI  - Using ChatGPT for human-computer interaction research: a primer.
PG  - 231053
LID - 10.1098/rsos.231053 [doi]
LID - 231053
AB  - ChatGPT could serve as a tool for text analysis within the field of 
      Human-Computer Interaction, though its validity requires investigation. This 
      study applied ChatGPT to: (1) textbox questionnaire responses on nine 
      augmented-reality interfaces, (2) interview data from participants who 
      experienced these interfaces in a virtual simulator, and (3) transcribed 
      think-aloud data of participants who viewed a real painting and its replica. 
      Using a hierarchical approach, ChatGPT produced scores or summaries of text 
      batches, which were then aggregated. Results showed that (1) ChatGPT generated 
      sentiment scores of the interfaces that correlated extremely strongly (r &gt; 0.99) 
      with human rating scale outcomes and with a rule-based sentiment analysis method 
      (criterion validity). Additionally, (2) by inputting automatically transcribed 
      interviews to ChatGPT, it provided meaningful meta-summaries of the qualities of 
      the interfaces (face validity). One meta-summary analysed in depth was found to 
      have substantial but imperfect overlap with a content analysis conducted by an 
      independent researcher (criterion validity). Finally, (3) ChatGPT's summary of 
      the think-aloud data highlighted subtle differences between the real painting and 
      the replica (face validity), a distinction corresponding with a keyword analysis 
      (criterion validity). In conclusion, our research indicates that, with 
      appropriate precautions, ChatGPT can be used as a valid tool for analysing text 
      data.
CI  - © 2023 The Authors.
FAU - Tabone, Wilbert
AU  - Tabone W
AUID- ORCID: 0000-0002-5796-9571
AD  - Department of Cognitive Robotics, Faculty of Mechanical, Maritime and Materials 
      Engineering, Delft University of Technology, Delft 2628CD, The Netherlands.
FAU - de Winter, Joost
AU  - de Winter J
AUID- ORCID: 0000-0002-1281-8200
AD  - Department of Cognitive Robotics, Faculty of Mechanical, Maritime and Materials 
      Engineering, Delft University of Technology, Delft 2628CD, The Netherlands.
LA  - eng
PT  - Journal Article
DEP - 20230913
PL  - England
TA  - R Soc Open Sci
JT  - Royal Society open science
JID - 101647528
PMC - PMC10498031
OTO - NOTNLM
OT  - application programming interface (API)
OT  - human-subject research
OT  - prompt engineering
OT  - reproducibility
COIS- We declare we have no competing interests.
EDAT- 2023/09/15 06:43
MHDA- 2023/09/15 06:44
PMCR- 2023/09/13
CRDT- 2023/09/15 03:44
PHST- 2023/07/21 00:00 [received]
PHST- 2023/08/17 00:00 [accepted]
PHST- 2023/09/15 06:44 [medline]
PHST- 2023/09/15 06:43 [pubmed]
PHST- 2023/09/15 03:44 [entrez]
PHST- 2023/09/13 00:00 [pmc-release]
AID - rsos231053 [pii]
AID - 10.1098/rsos.231053 [doi]
PST - epublish
SO  - R Soc Open Sci. 2023 Sep 13;10(9):231053. doi: 10.1098/rsos.231053. eCollection 
      2023 Sep.

PMID- 38420977
OWN - NLM
STAT- MEDLINE
DCOM- 20240301
LR  - 20240301
IS  - 1565-1088 (Print)
VI  - 26
IP  - 2
DP  - 2024 Feb
TI  - Advancing Medical Practice with Artificial Intelligence: ChatGPT in Healthcare.
PG  - 80-85
AB  - BACKGROUND: Advancements in artificial intelligence (AI) and natural language 
      processing (NLP) have led to the development of language models such as ChatGPT. 
      These models have the potential to transform healthcare and medical research. 
      However, understanding their applications and limitations is essential. 
      OBJECTIVES: To present a view of ChatGPT research and to critically assess 
      ChatGPT's role in medical writing and clinical environments. METHODS: We 
      performed a literature review via the PubMed search engine from 20 November 2022, 
      to 23 April 2023. The search terms included ChatGPT, OpenAI, and large language 
      models. We included studies that focused on ChatGPT, explored its use or 
      implications in medicine, and were original research articles. The selected 
      studies were analyzed considering study design, NLP tasks, main findings, and 
      limitations. RESULTS: Our study included 27 articles that examined ChatGPT's 
      performance in various tasks and medical fields. These studies covered knowledge 
      assessment, writing, and analysis tasks. While ChatGPT was found to be useful in 
      tasks such as generating research ideas, aiding clinical reasoning, and 
      streamlining workflows, limitations were also identified. These limitations 
      included inaccuracies, inconsistencies, fictitious information, and limited 
      knowledge, highlighting the need for further improvements. CONCLUSIONS: The 
      review underscores ChatGPT's potential in various medical applications. Yet, it 
      also points to limitations that require careful human oversight and responsible 
      use to improve patient care, education, and decision-making.
FAU - Tessler, Idit
AU  - Tessler I
AD  - Department of Otolaryngology and Head and Neck Surgery, Sheba Medical Center, Tel 
      Hashomer, Israel, ARC Innovation Center, Sheba Medical Center, Tel Hashomer, 
      Israel, Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel.
FAU - Wolfovitz, Amit
AU  - Wolfovitz A
AD  - Department of Otolaryngology and Head and Neck Surgery, Sheba Medical Center, Tel 
      Hashomer, Israel, Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel.
FAU - Livneh, Nir
AU  - Livneh N
AD  - Department of Otolaryngology and Head and Neck Surgery, Sheba Medical Center, Tel 
      Hashomer, Israel, Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel.
FAU - Gecel, Nir A
AU  - Gecel NA
AD  - Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel.
FAU - Sorin, Vera
AU  - Sorin V
AD  - ARC Innovation Center, Sheba Medical Center, Tel Hashomer, Israel, Division of 
      Diagnostic Imaging, Sheba Medical Center, Tel Hashomer, Israel, Faculty of 
      Medicine, Tel Aviv University, Tel Aviv, Israel.
FAU - Barash, Yiftach
AU  - Barash Y
AD  - Division of Diagnostic Imaging, Sheba Medical Center, Tel Hashomer, Israel, 
      Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel.
FAU - Konen, Eli
AU  - Konen E
AD  - Division of Diagnostic Imaging, Sheba Medical Center, Tel Hashomer, Israel, 
      Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel.
FAU - Klang, Eyal
AU  - Klang E
AD  - ARC Innovation Center, Sheba Medical Center, Tel Hashomer, Israel, Division of 
      Diagnostic Imaging, Sheba Medical Center, Tel Hashomer, Israel, Faculty of 
      Medicine, Tel Aviv University, Tel Aviv, Israel, Mount Sinai Clinical 
      Intelligence Center, Icahn School of Medicine at Mount Sinai, New York, NY, USA.
LA  - eng
PT  - Journal Article
PT  - Review
PL  - Israel
TA  - Isr Med Assoc J
JT  - The Israel Medical Association journal : IMAJ
JID - 100930740
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Educational Status
MH  - Language
MH  - *Medicine
MH  - Delivery of Health Care
EDAT- 2024/02/29 12:46
MHDA- 2024/03/01 06:44
CRDT- 2024/02/29 08:45
PHST- 2024/03/01 06:44 [medline]
PHST- 2024/02/29 12:46 [pubmed]
PHST- 2024/02/29 08:45 [entrez]
PST - ppublish
SO  - Isr Med Assoc J. 2024 Feb;26(2):80-85.

PMID- 38340639
OWN - NLM
STAT- MEDLINE
DCOM- 20240227
LR  - 20240227
IS  - 1532-2793 (Electronic)
IS  - 0260-6917 (Linking)
VI  - 135
DP  - 2024 Apr
TI  - A scoping review of ChatGPT's role in healthcare education and research.
PG  - 106121
LID - S0260-6917(24)00031-5 [pii]
LID - 10.1016/j.nedt.2024.106121 [doi]
AB  - OBJECTIVES: To examine and consolidate literature regarding the advantages and 
      disadvantages of utilizing ChatGPT in healthcare education and research. 
      DESIGN/METHODS: We searched seven electronic databases (PubMed/Medline, CINAHL, 
      Embase, PsycINFO, Scopus, ProQuest Dissertations and Theses Global, and Web of 
      Science) from November 2022 until September 2023. This scoping review adhered to 
      Arksey and O'Malley's framework and followed reporting guidelines outlined in the 
      PRISMA-ScR checklist. For analysis, we employed Thomas and Harden's thematic 
      synthesis framework. RESULTS: A total of 100 studies were included. An 
      overarching theme, "Forging the Future: Bridging Theory and Integration of 
      ChatGPT" emerged, accompanied by two main themes (1) Enhancing Healthcare 
      Education, Research, and Writing with ChatGPT, (2) Controversies and Concerns 
      about ChatGPT in Healthcare Education Research and Writing, and seven subthemes. 
      CONCLUSIONS: Our review underscores the importance of acknowledging legitimate 
      concerns related to the potential misuse of ChatGPT such as 'ChatGPT 
      hallucinations', its limited understanding of specialized healthcare knowledge, 
      its impact on teaching methods and assessments, confidentiality and security 
      risks, and the controversial practice of crediting it as a co-author on 
      scientific papers, among other considerations. Furthermore, our review also 
      recognizes the urgency of establishing timely guidelines and regulations, along 
      with the active engagement of relevant stakeholders, to ensure the responsible 
      and safe implementation of ChatGPT's capabilities. We advocate for the use of 
      cross-verification techniques to enhance the precision and reliability of 
      generated content, the adaptation of higher education curricula to incorporate 
      ChatGPT's potential, educators' need to familiarize themselves with the 
      technology to improve their literacy and teaching approaches, and the development 
      of innovative methods to detect ChatGPT usage. Furthermore, data protection 
      measures should be prioritized when employing ChatGPT, and transparent reporting 
      becomes crucial when integrating ChatGPT into academic writing.
CI  - Copyright © 2024 The Author(s). Published by Elsevier Ltd.. All rights reserved.
FAU - Shorey, Shefaly
AU  - Shorey S
AD  - Alice Lee Centre for Nursing Studies, Yong Loo Lin School of Medicine, National 
      University of Singapore, Singapore. Electronic address: nurssh@nus.edu.sg.
FAU - Mattar, Citra
AU  - Mattar C
AD  - Division of Maternal Fetal Medicine, Department of Obstetrics and Gynaecology, 
      National University Health Systems, Singapore; Department of Obstetrics and 
      Gynaecology, Yong Loo Lin School of Medicine, National University of Singapore, 
      Singapore.
FAU - Pereira, Travis Lanz-Brian
AU  - Pereira TL
AD  - Alice Lee Centre for Nursing Studies, Yong Loo Lin School of Medicine, National 
      University of Singapore, Singapore.
FAU - Choolani, Mahesh
AU  - Choolani M
AD  - Division of Maternal Fetal Medicine, Department of Obstetrics and Gynaecology, 
      National University Health Systems, Singapore; Department of Obstetrics and 
      Gynaecology, Yong Loo Lin School of Medicine, National University of Singapore, 
      Singapore.
LA  - eng
PT  - Journal Article
PT  - Review
PT  - Systematic Review
DEP - 20240206
PL  - Scotland
TA  - Nurse Educ Today
JT  - Nurse education today
JID - 8511379
MH  - Humans
MH  - Reproducibility of Results
MH  - Educational Status
MH  - *Curriculum
MH  - *Literacy
MH  - Checklist
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Health occupations
OT  - Health personnel
OT  - Healthcare
OT  - Machine learning
OT  - Natural language processing
COIS- Declaration of competing interest No conflict of interest has been declared by 
      the author(s).
EDAT- 2024/02/11 07:42
MHDA- 2024/02/27 06:45
CRDT- 2024/02/10 18:12
PHST- 2023/10/26 00:00 [received]
PHST- 2024/01/05 00:00 [revised]
PHST- 2024/02/04 00:00 [accepted]
PHST- 2024/02/27 06:45 [medline]
PHST- 2024/02/11 07:42 [pubmed]
PHST- 2024/02/10 18:12 [entrez]
AID - S0260-6917(24)00031-5 [pii]
AID - 10.1016/j.nedt.2024.106121 [doi]
PST - ppublish
SO  - Nurse Educ Today. 2024 Apr;135:106121. doi: 10.1016/j.nedt.2024.106121. Epub 2024 
      Feb 6.

PMID- 37717252
OWN - NLM
STAT- Publisher
LR  - 20230917
IS  - 1097-6817 (Electronic)
IS  - 0194-5998 (Linking)
DP  - 2023 Sep 17
TI  - Is ChatGPT-4 Accurate in Proofread a Manuscript in Otolaryngology-Head and Neck 
      Surgery?
LID - 10.1002/ohn.526 [doi]
AB  - ChatGPT is a new artificial intelligence-powered language model of chatbot able 
      to help otolaryngologists in clinical practice and research. We investigated the 
      ability of ChatGPT-4 in the editing of a manuscript in otolaryngology. Four 
      papers were written by a nonnative English otolaryngologist and edited by a 
      professional editing service. ChatGPT-4 was used to detect and correct errors in 
      manuscripts. From the 171 errors in the manuscripts, ChatGPT-4 detected 86 errors 
      (50.3%) including vocabulary (N = 36), determiner (N = 27), preposition (N = 24), 
      capitalization (N = 20), and number (N = 11). ChatGPT-4 proposed appropriate 
      corrections for 72 (83.7%) errors, while some errors were poorly detected (eg, 
      capitalization [5%] and vocabulary [44.4%] errors. ChatGPT-4 claimed to change 
      something that was already there in 82 cases. ChatGPT demonstrated usefulness in 
      identifying some types of errors but not all. Nonnative English researchers 
      should be aware of the current limits of ChatGPT-4 in the proofreading of 
      manuscripts.
CI  - © 2023 American Academy of Otolaryngology-Head and Neck Surgery Foundation.
FAU - Lechien, Jerome R
AU  - Lechien JR
AD  - Department of Otolaryngology-Head Neck Surgery, Division of Laryngology and 
      Broncho-esophagology, EpiCURA Hospital, UMONS Research Institute for Health 
      Sciences and Technology, University of Mons (UMons), Mons, Belgium.
AD  - Department of Otorhinolaryngology and Head and Neck Surgery, Foch Hospital, 
      School of Medicine, UFR Simone Veil, Université Versailles 
      Saint-Quentin-en-Yvelines (Paris Saclay University), Paris, France.
AD  - Department of Otorhinolaryngology and Head and Neck Surgery, CHU de Bruxelles, 
      CHU Saint-Pierre, School of Medicine, Université Libre de Bruxelles, Brussels, 
      Belgium.
AD  - Polyclinique Elsan de Poitiers, Poitiers, France.
FAU - Gorton, Amy
AU  - Gorton A
AD  - Faculty of Translation and Interpretation (FTI-EII), University of Mons, Mons, 
      Belgium.
FAU - Robertson, Jean
AU  - Robertson J
AD  - Faculty of Translation and Interpretation (FTI-EII), University of Mons, Mons, 
      Belgium.
FAU - Vaira, Luigi A
AU  - Vaira LA
AD  - Maxillofacial Surgery Operative Unit, Department of Medicine, Surgery and 
      Pharmacy, University of Sassari, Sassari, Italy.
AD  - PhD School of Biomedical Sciences, Department of Biomedical Sciences, University 
      of Sassari, Sassari, Italy.
LA  - eng
PT  - Journal Article
DEP - 20230917
PL  - England
TA  - Otolaryngol Head Neck Surg
JT  - Otolaryngology--head and neck surgery : official journal of American Academy of 
      Otolaryngology-Head and Neck Surgery
JID - 8508176
SB  - IM
OTO - NOTNLM
OT  - ChatGPT-4
OT  - GPT-4
OT  - artificial
OT  - correction
OT  - head neck
OT  - intelligence
OT  - otolaryngology
OT  - proofread
OT  - scientific
OT  - surgery
OT  - writing
EDAT- 2023/09/17 18:42
MHDA- 2023/09/17 18:42
CRDT- 2023/09/17 14:51
PHST- 2023/08/01 00:00 [revised]
PHST- 2023/05/04 00:00 [received]
PHST- 2023/08/18 00:00 [accepted]
PHST- 2023/09/17 18:42 [medline]
PHST- 2023/09/17 18:42 [pubmed]
PHST- 2023/09/17 14:51 [entrez]
AID - 10.1002/ohn.526 [doi]
PST - aheadofprint
SO  - Otolaryngol Head Neck Surg. 2023 Sep 17. doi: 10.1002/ohn.526.

PMID- 38116306
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231221
IS  - 1178-2390 (Print)
IS  - 1178-2390 (Electronic)
IS  - 1178-2390 (Linking)
VI  - 16
DP  - 2023
TI  - ChatGPT and Clinical Training: Perception, Concerns, and Practice of Pharm-D 
      Students.
PG  - 4099-4110
LID - 10.2147/JMDH.S439223 [doi]
AB  - BACKGROUND: The emergence of Chat-Generative Pre-trained Transformer (ChatGPT) by 
      OpenAI has revolutionized AI technology, demonstrating significant potential in 
      healthcare and pharmaceutical education, yet its real-world applicability in 
      clinical training warrants further investigation. METHODS: A cross-sectional 
      study was conducted between April and May 2023 to assess PharmD students' 
      perceptions, concerns, and experiences regarding the integration of ChatGPT into 
      clinical pharmacy education. The study utilized a convenient sampling method 
      through online platforms and involved a questionnaire with sections on 
      demographics, perceived benefits, concerns, and experience with ChatGPT. 
      Statistical analysis was performed using SPSS, including descriptive and 
      inferential analyses. RESULTS: The findings of the study involving 211 PharmD 
      students revealed that the majority of participants were male (77.3%), and had 
      prior experience with artificial intelligence (68.2%). Over two-thirds were aware 
      of ChatGPT. Most students (n= 139, 65.9%) perceived potential benefits in using 
      ChatGPT for various clinical tasks, with concerns including over-reliance, 
      accuracy, and ethical considerations. Adoption of ChatGPT in clinical training 
      varied, with some students not using it at all, while others utilized it for 
      tasks like evaluating drug-drug interactions and developing care plans. Previous 
      users tended to have higher perceived benefits and lower concerns, but the 
      differences were not statistically significant. CONCLUSION: Utilizing ChatGPT in 
      clinical training offers opportunities, but students' lack of trust in it for 
      clinical decisions highlights the need for collaborative human-ChatGPT 
      decision-making. It should complement healthcare professionals' expertise and be 
      used strategically to compensate for human limitations. Further research is 
      essential to optimize ChatGPT's effective integration.
CI  - © 2023 Zawiah et al.
FAU - Zawiah, Mohammed
AU  - Zawiah M
AD  - Department of Clinical Pharmacy, College of Pharmacy, Northern Border University, 
      Rafha, 91911, Saudi Arabia.
AD  - Department of Pharmacy Practice, College of Clinical Pharmacy, Hodeidah 
      University, Al Hodeidah, Yemen.
FAU - Al-Ashwal, Fahmi Y
AU  - Al-Ashwal FY
AUID- ORCID: 0000-0003-2076-0771
AD  - Department of Clinical Pharmacy, College of Pharmacy, Al-Ayen University, 
      Thi-Qar, Iraq.
FAU - Gharaibeh, Lobna
AU  - Gharaibeh L
AUID- ORCID: 0000-0002-7490-5465
AD  - Pharmacological and Diagnostic Research Center, Faculty of Pharmacy, Al-Ahliyya 
      Amman University, Amman, Jordan.
FAU - Abu Farha, Rana
AU  - Abu Farha R
AUID- ORCID: 0000-0001-8298-4071
AD  - Clinical Pharmacy and Therapeutics Department, Faculty of Pharmacy, Applied 
      Science Private University, Amman, Jordan.
FAU - Alzoubi, Karem H
AU  - Alzoubi KH
AUID- ORCID: 0000-0002-2808-5099
AD  - Department of Pharmacy Practice and Pharmacotherapeutics, University of Sharjah, 
      Sharjah, 27272, United Arab Emirates.
AD  - Department of Clinical Pharmacy, Faculty of Pharmacy, Jordan University of 
      Science and Technology, Irbid, 22110, Jordan.
FAU - Abu Hammour, Khawla
AU  - Abu Hammour K
AD  - Department of Clinical Pharmacy and Biopharmaceutics, Faculty of Pharmacy, 
      University of Jordan, Amman, Jordan.
FAU - Qasim, Qutaiba A
AU  - Qasim QA
AD  - Department of Clinical Pharmacy, College of Pharmacy, Al-Ayen University, 
      Thi-Qar, Iraq.
FAU - Abrah, Fahd
AU  - Abrah F
AD  - Discipline of Social and Administrative Pharmacy, School of Pharmaceutical 
      Sciences, Universiti Sains Malaysia, Penang, Malaysia.
LA  - eng
PT  - Journal Article
DEP - 20231215
PL  - New Zealand
TA  - J Multidiscip Healthc
JT  - Journal of multidisciplinary healthcare
JID - 101512691
PMC - PMC10729768
OTO - NOTNLM
OT  - ChatGPT
OT  - Pharm-D
OT  - clinical training
OT  - perception
COIS- The authros report no conflicts of interest in this work.
EDAT- 2023/12/20 06:43
MHDA- 2023/12/20 06:44
PMCR- 2023/12/15
CRDT- 2023/12/20 03:58
PHST- 2023/09/09 00:00 [received]
PHST- 2023/12/04 00:00 [accepted]
PHST- 2023/12/20 06:44 [medline]
PHST- 2023/12/20 06:43 [pubmed]
PHST- 2023/12/20 03:58 [entrez]
PHST- 2023/12/15 00:00 [pmc-release]
AID - 439223 [pii]
AID - 10.2147/JMDH.S439223 [doi]
PST - epublish
SO  - J Multidiscip Healthc. 2023 Dec 15;16:4099-4110. doi: 10.2147/JMDH.S439223. 
      eCollection 2023.

PMID- 37648882
OWN - NLM
STAT- MEDLINE
DCOM- 20230926
LR  - 20230926
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 51
IP  - 10
DP  - 2023 Oct
TI  - Can ChatGPT Help in the Awareness of Diabetes?
PG  - 2125-2129
LID - 10.1007/s10439-023-03356-1 [doi]
AB  - Diabetes is a common chronic illness that requires continual patient education 
      and support to be effectively managed. The lack of diabetes educators and the 
      limitations of conventional education approaches make it difficult to meet the 
      specific needs of each patient. The artificial intelligence (AI) tool ChatGPT 
      provides a tailored and interactive approach to support and instruction. ChatGPT 
      has the potential to increase diabetes patients' access to information and 
      assistance, but more research is required to fully comprehend its benefits and 
      drawbacks. To maximize ChatGPT's potential benefits and reduce its possible 
      hazards, care must be taken to ensure that it is developed and integrated in an 
      ethical and equitable manner. In this post, we talk about how crucial ChatGPT is 
      for educating people about diabetes.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Khan, Imran
AU  - Khan I
AUID- ORCID: 0000-0003-0053-8938
AD  - Department of Computer Science and Engineering, Harcourt Butler Technical 
      University, Kanpur, UP, India. imrankhan.ee2531@gmail.com.
FAU - Agarwal, Rashi
AU  - Agarwal R
AD  - Department of Computer Science and Engineering, Harcourt Butler Technical 
      University, Kanpur, UP, India.
LA  - eng
PT  - Letter
DEP - 20230830
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Diabetes Mellitus
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Diabetes
OT  - Machine learning
EDAT- 2023/08/31 00:41
MHDA- 2023/09/26 13:43
CRDT- 2023/08/30 23:31
PHST- 2023/08/17 00:00 [received]
PHST- 2023/08/21 00:00 [accepted]
PHST- 2023/09/26 13:43 [medline]
PHST- 2023/08/31 00:41 [pubmed]
PHST- 2023/08/30 23:31 [entrez]
AID - 10.1007/s10439-023-03356-1 [pii]
AID - 10.1007/s10439-023-03356-1 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2023 Oct;51(10):2125-2129. doi: 10.1007/s10439-023-03356-1. Epub 
      2023 Aug 30.

PMID- 37545428
OWN - NLM
STAT- Publisher
LR  - 20230807
IS  - 1545-1569 (Electronic)
IS  - 1055-6656 (Linking)
DP  - 2023 Aug 7
TI  - Dr. ChatGPT: Utilizing Artificial Intelligence in Surgical Education.
PG  - 10556656231193966
LID - 10.1177/10556656231193966 [doi]
AB  - OBJECTIVE: This study sought to explore the unexamined capabilities of ChatGPT in 
      describing the surgical steps of a specialized operation, the Fisher cleft lip 
      repair. DESIGN: A chat log within ChatGPT was created to generate the procedural 
      steps of a cleft lip repair utilizing the Fisher technique. A board certified 
      craniomaxillofacial (CMF) surgeon then wrote the Fisher repair in his own words 
      blinded to the ChatGPT response. Using both responses, a voluntary survey 
      questionnaire was distributed to residents of plastic and reconstructive surgery 
      (PRS), general surgery (GS), internal medicine (IM), and medical students at our 
      institution in a blinded study. SETTING: Authors collected information from 
      residents (PRS, GS, IM) and medical students at one institution. MAIN OUTCOME 
      MEASURES: Primary outcome measures included understanding, preference, and author 
      identification of the procedural prompts. RESULTS: Results show PRS residents 
      were able to detect more inaccuracies of the ChatGPT response as well as prefer 
      the CMF surgeon's prompt in performing the surgery. Residents with less expertise 
      in the procedure not only failed to detect who wrote what procedure, but 
      preferred the ChatGPT response in explaining the concept and chose it to perform 
      the surgery. CONCLUSIONS: In applications to surgical education, ChatGPT was 
      found to be effective in generating easy to understand procedural steps that can 
      be followed by medical personnel of all specialties. However, it does not have 
      expert capabilities to provide the minute detail of measurements and specific 
      anatomy required to perform medical procedures.
FAU - Lebhar, Michael S
AU  - Lebhar MS
AUID- ORCID: 0000-0001-6560-3329
AD  - Division of Plastic and Reconstructive Surgery, University of Mississippi Medical 
      Center, Jackson, MS, USA.
FAU - Velazquez, Alexander
AU  - Velazquez A
AD  - University of Mississippi School of Medicine, Jackson, MS, USA.
FAU - Goza, Shelby
AU  - Goza S
AD  - University of Mississippi School of Medicine, Jackson, MS, USA.
FAU - Hoppe, Ian C
AU  - Hoppe IC
AUID- ORCID: 0000-0001-8332-2280
AD  - Division of Plastic and Reconstructive Surgery, University of Mississippi Medical 
      Center, Jackson, MS, USA.
LA  - eng
PT  - Journal Article
DEP - 20230807
PL  - United States
TA  - Cleft Palate Craniofac J
JT  - The Cleft palate-craniofacial journal : official publication of the American 
      Cleft Palate-Craniofacial Association
JID - 9102566
SB  - IM
OTO - NOTNLM
OT  - artificial intelligence
OT  - craniofacial surgery
OT  - surgical technique
EDAT- 2023/08/07 06:41
MHDA- 2023/08/07 06:41
CRDT- 2023/08/07 04:04
PHST- 2023/08/07 06:41 [medline]
PHST- 2023/08/07 06:41 [pubmed]
PHST- 2023/08/07 04:04 [entrez]
AID - 10.1177/10556656231193966 [doi]
PST - aheadofprint
SO  - Cleft Palate Craniofac J. 2023 Aug 7:10556656231193966. doi: 
      10.1177/10556656231193966.

PMID- 37284995
OWN - NLM
STAT- Publisher
LR  - 20231024
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 51
IP  - 11
DP  - 2023 Nov
TI  - Passive Contribution of ChatGPT to Scientific Papers.
PG  - 2340-2350
LID - 10.1007/s10439-023-03260-8 [doi]
AB  - Arguably ChatGPT jeopardizes the integrity and validity of the academic 
      publications instead of ethically facilitating them. ChatGPT can apparently 
      fulfill a portion of one of the four authorship criteria set by the International 
      Committee of Medical Journal Editors (ICMJE), i.e., "drafting." However, the 
      authorship criteria by ICMJE must all be collectively met, not singly or 
      partially. Many published manuscripts or preprints have credited ChatGPT by 
      including it in the author byline, and the academic publishing enterprise seems 
      to be unguided on how to handle such manuscripts. Interestingly, PLoS Digital 
      Health removed ChatGPT off a paper which had ChatGPT listed initially in the 
      author byline of the preprint version. Revised publishing policies are, thus, 
      promptly required to guide a consistent stance regarding ChatGPT or similar 
      artificial content generators. Publishing policies must accord among publishers, 
      preprint servers ( https://asapbio.org/preprint-servers ), universities, and 
      research institutions worldwide and across different disciplines. Ideally, 
      considering any declaration of the contribution of ChatGPT to writing any 
      scientific article should be recognized as publishing misconduct immediately and 
      be retracted. Meanwhile, all parties involved in the scientific reporting and 
      publishing must be educated about how ChatGPT fails to meet the essential 
      authorship criteria, so that no author must submit a manuscript with ChatGPT 
      contributing as a "co-author." Meanwhile, using ChatGPT for writing laboratory 
      reports or short summaries of experiments may be acceptable, but not for academic 
      publishing or formal scientific reporting.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Rahimi, Farid
AU  - Rahimi F
AUID- ORCID: 0000-0002-0920-8188
AD  - Research School of Biology, The Australian National University, Ngunnawal and 
      Ngambri Country, Canberra, ACT, Australia. farid.rahimi@anu.edu.au.
FAU - Talebi Bezmin Abadi, Amin
AU  - Talebi Bezmin Abadi A
AD  - Department of Bacteriology, Faculty of Medical Sciences, Tarbiat Modares 
      University, Tehran, Iran.
LA  - eng
PT  - Letter
DEP - 20230607
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Authorship
OT  - ChatGPT
OT  - International Committee of Medical Journal Editors
OT  - Scientific misconduct
EDAT- 2023/06/07 13:10
MHDA- 2023/06/07 13:10
CRDT- 2023/06/07 11:11
PHST- 2023/05/25 00:00 [received]
PHST- 2023/05/26 00:00 [accepted]
PHST- 2023/06/07 13:10 [pubmed]
PHST- 2023/06/07 13:10 [medline]
PHST- 2023/06/07 11:11 [entrez]
AID - 10.1007/s10439-023-03260-8 [pii]
AID - 10.1007/s10439-023-03260-8 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2023 Nov;51(11):2340-2350. doi: 10.1007/s10439-023-03260-8. Epub 
      2023 Jun 7.

PMID- 38549640
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240330
IS  - 2542-4823 (Electronic)
IS  - 2542-4823 (Linking)
VI  - 8
IP  - 1
DP  - 2024
TI  - ChatGPT as a Diagnostic Aid in Alzheimer's Disease: An Exploratory Study.
PG  - 495-500
LID - 10.3233/ADR-230191 [doi]
AB  - BACKGROUND: The potential of ChatGPT in medical diagnosis has been explored in 
      various medical conditions. OBJECTIVE: We assessed whether ChatGPT can contribute 
      to the diagnosis of Alzheimer's disease (AD). METHODS: We provided ChatGPT with 
      four generated cases (mild, moderate, or advanced stage AD dementia, or mild 
      cognitive impairment), including descriptions of their complaints, physical 
      examinations, as well as biomarker, neuroimaging, and neuropsychological data. 
      RESULTS: ChatGPT accurately diagnosed the test cases similarly to two blinded 
      specialists. CONCLUSIONS: While the use of generated cases can be a limitation to 
      our study, our findings demonstrate that ChatGPT can be a useful tool for symptom 
      assessment and the diagnosis of AD. However, while the use of ChatGPT in AD 
      diagnosis is promising, it should be seen as an adjunct to clinical judgment 
      rather than a replacement.
CI  - © 2024 – The authors. Published by IOS Press.
FAU - El Haj, Mohamad
AU  - El Haj M
AD  - Institut Universitaire de France, Paris, France.
AD  - Clinical Gerontology Department, CHU Nantes, Nantes, France.
FAU - Boutoleau-Bretonnière, Claire
AU  - Boutoleau-Bretonnière C
AD  - CHU Nantes, Inserm CIC04, Nantes, France.
FAU - Gallouj, Karim
AU  - Gallouj K
AD  - Unité de Gériatrie, Centre Hospitalier de Tourcoing, Tourcoing, France.
FAU - Wagemann, Nathalie
AU  - Wagemann N
AD  - CHU Nantes, Inserm CIC04, Nantes, France.
FAU - Antoine, Pascal
AU  - Antoine P
AD  - Universite de Lille, CNRS, CHU Lille, UMR 9193 SCALab - Sciences Cognitives et 
      Sciences Affectives, Lille, France.
FAU - Kapogiannis, Dimitrios
AU  - Kapogiannis D
AD  - Laboratory of Clinical Investigation, National Institute on Aging, Baltimore, MD, 
      USA.
FAU - Chapelet, Guillaume
AU  - Chapelet G
AD  - Clinical Gerontology Department, CHU Nantes, Nantes, France.
AD  - Université de Nantes, Inserm, TENS, The Enteric Nervous System in Gut and Brain 
      Diseases, IMAD, Nantes, France.
LA  - eng
PT  - Journal Article
DEP - 20240319
PL  - Netherlands
TA  - J Alzheimers Dis Rep
JT  - Journal of Alzheimer's disease reports
JID - 101705500
PMC - PMC10977430
OTO - NOTNLM
OT  - Alzheimer’s disease
OT  - ChatGPT
OT  - artificial intelligence
OT  - diagnosis
OT  - mild cognitive impairment
COIS- MEH is an Editorial Board Member of this journal but was not involved in the 
      peer-review process of this article nor had access to any information regarding 
      its peer-review.
EDAT- 2024/03/29 06:47
MHDA- 2024/03/29 06:48
PMCR- 2024/03/19
CRDT- 2024/03/29 03:55
PHST- 2023/12/17 00:00 [received]
PHST- 2024/02/09 00:00 [accepted]
PHST- 2024/03/29 06:48 [medline]
PHST- 2024/03/29 06:47 [pubmed]
PHST- 2024/03/29 03:55 [entrez]
PHST- 2024/03/19 00:00 [pmc-release]
AID - ADR230191 [pii]
AID - 10.3233/ADR-230191 [doi]
PST - epublish
SO  - J Alzheimers Dis Rep. 2024 Mar 19;8(1):495-500. doi: 10.3233/ADR-230191. 
      eCollection 2024.

PMID- 38293321
OWN - NLM
STAT- MEDLINE
DCOM- 20240201
LR  - 20240206
IS  - 2219-2840 (Electronic)
IS  - 1007-9327 (Print)
IS  - 1007-9327 (Linking)
VI  - 30
IP  - 1
DP  - 2024 Jan 7
TI  - May ChatGPT be a tool producing medical information for common inflammatory bowel 
      disease patients' questions? An evidence-controlled analysis.
PG  - 17-33
LID - 10.3748/wjg.v30.i1.17 [doi]
AB  - Artificial intelligence is increasingly entering everyday healthcare. Large 
      language model (LLM) systems such as Chat Generative Pre-trained Transformer 
      (ChatGPT) have become potentially accessible to everyone, including patients with 
      inflammatory bowel diseases (IBD). However, significant ethical issues and 
      pitfalls exist in innovative LLM tools. The hype generated by such systems may 
      lead to unweighted patient trust in these systems. Therefore, it is necessary to 
      understand whether LLMs (trendy ones, such as ChatGPT) can produce plausible 
      medical information (MI) for patients. This review examined ChatGPT's potential 
      to provide MI regarding questions commonly addressed by patients with IBD to 
      their gastroenterologists. From the review of the outputs provided by ChatGPT, 
      this tool showed some attractive potential while having significant limitations 
      in updating and detailing information and providing inaccurate information in 
      some cases. Further studies and refinement of the ChatGPT, possibly aligning the 
      outputs with the leading medical evidence provided by reliable databases, are 
      needed.
CI  - ©The Author(s) 2024. Published by Baishideng Publishing Group Inc. All rights 
      reserved.
FAU - Gravina, Antonietta Gerarda
AU  - Gravina AG
AD  - Division of Hepatogastroenterology, Department of Precision Medicine, University 
      of Campania Luigi Vanvitelli, Naples 80138, Italy.
FAU - Pellegrino, Raffaele
AU  - Pellegrino R
AD  - Division of Hepatogastroenterology, Department of Precision Medicine, University 
      of Campania Luigi Vanvitelli, Naples 80138, Italy. 
      raffaele.pellegrino@unicampania.it.
FAU - Cipullo, Marina
AU  - Cipullo M
AD  - Division of Hepatogastroenterology, Department of Precision Medicine, University 
      of Campania Luigi Vanvitelli, Naples 80138, Italy.
FAU - Palladino, Giovanna
AU  - Palladino G
AD  - Division of Hepatogastroenterology, Department of Precision Medicine, University 
      of Campania Luigi Vanvitelli, Naples 80138, Italy.
FAU - Imperio, Giuseppe
AU  - Imperio G
AD  - Division of Hepatogastroenterology, Department of Precision Medicine, University 
      of Campania Luigi Vanvitelli, Naples 80138, Italy.
FAU - Ventura, Andrea
AU  - Ventura A
AD  - Division of Hepatogastroenterology, Department of Precision Medicine, University 
      of Campania Luigi Vanvitelli, Naples 80138, Italy.
FAU - Auletta, Salvatore
AU  - Auletta S
AD  - Division of Hepatogastroenterology, Department of Precision Medicine, University 
      of Campania Luigi Vanvitelli, Naples 80138, Italy.
FAU - Ciamarra, Paola
AU  - Ciamarra P
AD  - Division of Hepatogastroenterology, Department of Precision Medicine, University 
      of Campania Luigi Vanvitelli, Naples 80138, Italy.
FAU - Federico, Alessandro
AU  - Federico A
AD  - Division of Hepatogastroenterology, Department of Precision Medicine, University 
      of Campania Luigi Vanvitelli, Naples 80138, Italy.
LA  - eng
PT  - Journal Article
PT  - Review
PL  - United States
TA  - World J Gastroenterol
JT  - World journal of gastroenterology
JID - 100883448
SB  - IM
MH  - Humans
MH  - Artificial Intelligence
MH  - Databases, Factual
MH  - *Gastroenterologists
MH  - *Inflammatory Bowel Diseases
MH  - Language
PMC - PMC10823903
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Chat Generative Pre-trained Transformer
OT  - Crohn’s disease
OT  - Inflammatory bowel disease
OT  - Large language model
OT  - Ulcerative colitis
COIS- Conflict-of-interest statement: All the authors report no relevant conflicts of 
      interest for this article.
EDAT- 2024/01/31 06:43
MHDA- 2024/02/01 06:42
PMCR- 2024/01/07
CRDT- 2024/01/31 04:24
PHST- 2023/11/04 00:00 [received]
PHST- 2023/12/07 00:00 [revised]
PHST- 2023/12/28 00:00 [accepted]
PHST- 2024/02/01 06:42 [medline]
PHST- 2024/01/31 06:43 [pubmed]
PHST- 2024/01/31 04:24 [entrez]
PHST- 2024/01/07 00:00 [pmc-release]
AID - 10.3748/wjg.v30.i1.17 [doi]
PST - ppublish
SO  - World J Gastroenterol. 2024 Jan 7;30(1):17-33. doi: 10.3748/wjg.v30.i1.17.

PMID- 37130197
OWN - NLM
STAT- MEDLINE
DCOM- 20231102
LR  - 20231102
IS  - 1538-9855 (Electronic)
IS  - 0363-3624 (Linking)
VI  - 48
IP  - 5
DP  - 2023 Sep-Oct 01
TI  - Can ChatGPT Accurately Answer a PICOT Question? Assessing AI Response to a 
      Clinical Question.
PG  - 231-233
LID - 10.1097/NNE.0000000000001436 [doi]
AB  - BACKGROUND: ChatGPT, an artificial intelligence (AI) text generator trained to 
      predict correct words, can provide answers to questions but has shown mixed 
      results in answering medical questions. PURPOSE: To assess the reliability and 
      accuracy of ChatGPT in providing answers to a complex clinical question. METHODS: 
      A Population, Intervention, Comparison, Outcome, and Time (PICOT) formatted 
      question was queried, along with a request for references. Full-text articles 
      were reviewed to verify the accuracy of the evidence summary provided by the 
      chatbot. RESULTS: ChatGPT was unable to provide a certifiable response to a PICOT 
      question. The references cited as evidence included incorrect journal 
      information, and many study details summarized by ChatGPT proved to be patently 
      false, including providing fabricated data. CONCLUSIONS: ChatGPT provides answers 
      that appear legitimate but may be factually incorrect. The system is not 
      transparent in how it gathers data to answer questions and sometimes fabricates 
      information that looks plausible, making it an unreliable tool for clinical 
      questions.
CI  - Copyright © 2023 Wolters Kluwer Health, Inc. All rights reserved.
FAU - Branum, Candise
AU  - Branum C
AUID- ORCID: 0009-0005-2486-0675
AD  - Health Science Librarian and Assistant Professor (Mx Branum), Foley Center 
      Library, and Assistant Professor (Dr Schiavenato), School of Nursing and Human 
      Physiology, Gonzaga University, Spokane, Washington.
FAU - Schiavenato, Martin
AU  - Schiavenato M
LA  - eng
PT  - Journal Article
DEP - 20230428
PL  - United States
TA  - Nurse Educ
JT  - Nurse educator
JID - 7701902
MH  - Humans
MH  - *Artificial Intelligence
MH  - Reproducibility of Results
MH  - Nursing Education Research
MH  - *Software
COIS- The authors declare no conflicts of interest.
EDAT- 2023/05/02 18:41
MHDA- 2023/05/02 18:42
CRDT- 2023/05/02 14:23
PHST- 2023/05/02 18:42 [medline]
PHST- 2023/05/02 18:41 [pubmed]
PHST- 2023/05/02 14:23 [entrez]
AID - 00006223-990000000-00234 [pii]
AID - 10.1097/NNE.0000000000001436 [doi]
PST - ppublish
SO  - Nurse Educ. 2023 Sep-Oct 01;48(5):231-233. doi: 10.1097/NNE.0000000000001436. 
      Epub 2023 Apr 28.

PMID- 38451243
OWN - NLM
STAT- Publisher
LR  - 20240307
IS  - 1940-1574 (Electronic)
IS  - 0003-3197 (Linking)
DP  - 2024 Mar 7
TI  - ChatGPT and Patients With Heart Failure.
PG  - 33197241238403
LID - 10.1177/00033197241238403 [doi]
AB  - ChatGPT (Generative Pre-trained Transformer) is a large-scale language processing 
      model, with possibilities for professional patient support in a patient-friendly 
      way. The aim of the study was to examine the accuracy and reproducibility of 
      ChatGPT in answering questions about knowledge and management of heart failure 
      (HF). First, we recorded 47 most frequently asked questions by patients about HF. 
      The answers of ChatGPT to these questions were independently assessed by two 
      researchers. ChatGPT was able to render the definition of the disease in a very 
      simple and explanatory way. It listed a number of the most important causes of HF 
      and the most important risk factors for its occurrence. It provided correct 
      answers about the most important diagnostic tests and why they are recommended. 
      In addition, it answered health and dietary questions, such as the daily fluid 
      and the alcohol intake. ChatGPT listed the most important classes of drugs in HF 
      and their mechanism of action. It also answered with arguments to questions about 
      patient's sex life, whether they could work, drive, or travel by plane. The 
      performance of ChatGPT was described as very good as it was able to adequately 
      answer all questions posed to it.
FAU - Dimitriadis, Fotis
AU  - Dimitriadis F
AD  - Cardiology Department, General Hospital G. Papanikolaou, Thessaloniki, Greece. 
      RINGGOLD: 37798
FAU - Alkagiet, Stelina
AU  - Alkagiet S
AD  - Cardiology Department, General Hospital G. Papanikolaou, Thessaloniki, Greece. 
      RINGGOLD: 37798
FAU - Tsigkriki, Lamprini
AU  - Tsigkriki L
AD  - Cardiology Department, General Hospital G. Papanikolaou, Thessaloniki, Greece. 
      RINGGOLD: 37798
FAU - Kleitsioti, Panagiota
AU  - Kleitsioti P
AD  - Cardiology Department, General Hospital G. Papanikolaou, Thessaloniki, Greece. 
      RINGGOLD: 37798
FAU - Sidiropoulos, George
AU  - Sidiropoulos G
AD  - Cardiology Department, General Hospital G. Papanikolaou, Thessaloniki, Greece. 
      RINGGOLD: 37798
FAU - Efstratiou, Dimitris
AU  - Efstratiou D
AD  - Cardiology Department, General Hospital G. Papanikolaou, Thessaloniki, Greece. 
      RINGGOLD: 37798
FAU - Askalidi, Taisa
AU  - Askalidi T
AD  - Cardiology Department, General Hospital G. Papanikolaou, Thessaloniki, Greece. 
      RINGGOLD: 37798
FAU - Tsaousidis, Adam
AU  - Tsaousidis A
AD  - Cardiology Department, General Hospital G. Papanikolaou, Thessaloniki, Greece. 
      RINGGOLD: 37798
FAU - Siarkos, Michail
AU  - Siarkos M
AD  - Cardiology Department, General Hospital G. Papanikolaou, Thessaloniki, Greece. 
      RINGGOLD: 37798
FAU - Giannakopoulou, Pinelopi
AU  - Giannakopoulou P
AD  - Cardiology Department, General Hospital G. Papanikolaou, Thessaloniki, Greece. 
      RINGGOLD: 37798
FAU - Mavrogianni, Angeliki-Despoina
AU  - Mavrogianni AD
AD  - Cardiology Department, General Hospital G. Papanikolaou, Thessaloniki, Greece. 
      RINGGOLD: 37798
FAU - Zarifis, John
AU  - Zarifis J
AD  - Cardiology Department, General Hospital G. Papanikolaou, Thessaloniki, Greece. 
      RINGGOLD: 37798
FAU - Koulaouzidis, George
AU  - Koulaouzidis G
AUID- ORCID: 0000-0001-8340-9423
AD  - Department of Biochemical Sciences, Pomeranian Medical University, Szczecin, 
      Poland. RINGGOLD: 37805
LA  - eng
PT  - Journal Article
DEP - 20240307
PL  - United States
TA  - Angiology
JT  - Angiology
JID - 0203706
SB  - IM
OTO - NOTNLM
OT  - Generative Pre-trained Transformer
OT  - artificial intelligence
OT  - heart failure
OT  - patient education
COIS- Declaration of Conflicting InterestsThe author(s) declared no potential conflicts 
      of interest with respect to the research, authorship, and/or publication of this 
      article.
EDAT- 2024/03/07 12:42
MHDA- 2024/03/07 12:42
CRDT- 2024/03/07 10:53
PHST- 2024/03/07 12:42 [medline]
PHST- 2024/03/07 12:42 [pubmed]
PHST- 2024/03/07 10:53 [entrez]
AID - 10.1177/00033197241238403 [doi]
PST - aheadofprint
SO  - Angiology. 2024 Mar 7:33197241238403. doi: 10.1177/00033197241238403.

PMID- 38076902
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231211
DP  - 2023 Oct 29
TI  - Evaluating ChatGPT as an Agent for Providing Genetic Education.
LID - 2023.10.25.564074 [pii]
LID - 10.1101/2023.10.25.564074 [doi]
AB  - Genetic disorders are complex and can greatly impact an individual's health and 
      well-being. In this study, we assess the ability of ChatGPT, a language model 
      developed by OpenAI, to answer questions related to three specific genetic 
      disorders: BRCA1, MLH1, and HFE. ChatGPT has shown it can supply articulate 
      answers to a wide spectrum of questions. However, its ability to answer questions 
      related to genetic disorders has yet to be evaluated. The aim of this study is to 
      perform both quantitative and qualitative assessments of ChatGPT's performance in 
      this area. The ability of ChatGPT to provide accurate and useful information to 
      patients was assessed by genetic experts. Here we show that ChatGPT answered 
      64.7% of the 68 genetic questions asked and was able to respond coherently to 
      complex questions related to the three genes/conditions. Our results reveal that 
      ChatGPT can provide valuable information to individuals seeking information about 
      genetic disorders, however, it still has some limitations and inaccuracies, 
      particularly in understanding human inheritance patterns. The results of this 
      study have implications for both genomics and medicine and can inform future 
      developments in this area. AI platforms, like ChatGPT, have significant potential 
      in the field of genomics. As these technologies become integrated into 
      consumer-facing products, appropriate oversight is required to ensure accurate 
      and safe delivery of medical information. With such oversight and training 
      specifically for genetic information, these platforms could have the potential to 
      augment some clinical interactions.
FAU - Walton, Nephi
AU  - Walton N
AUID- ORCID: 0000-0002-9095-7265
FAU - Gracefo, Sara
AU  - Gracefo S
FAU - Sutherland, Nykole
AU  - Sutherland N
FAU - Kozel, Beth A
AU  - Kozel BA
FAU - Danford, Christopher J
AU  - Danford CJ
FAU - McGrath, Scott P
AU  - McGrath SP
LA  - eng
PT  - Preprint
DEP - 20231029
PL  - United States
TA  - bioRxiv
JT  - bioRxiv : the preprint server for biology
JID - 101680187
PMC - PMC10705538
EDAT- 2023/12/11 12:43
MHDA- 2023/12/11 12:44
PMCR- 2023/12/08
CRDT- 2023/12/11 06:20
PHST- 2023/12/11 12:44 [medline]
PHST- 2023/12/11 12:43 [pubmed]
PHST- 2023/12/11 06:20 [entrez]
PHST- 2023/12/08 00:00 [pmc-release]
AID - 2023.10.25.564074 [pii]
AID - 10.1101/2023.10.25.564074 [doi]
PST - epublish
SO  - bioRxiv [Preprint]. 2023 Oct 29:2023.10.25.564074. doi: 
      10.1101/2023.10.25.564074.

PMID- 37484787
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230725
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 7
DP  - 2023 Jul
TI  - ChatGPT's Ability to Assess Quality and Readability of Online Medical 
      Information: Evidence From a Cross-Sectional Study.
PG  - e42214
LID - 10.7759/cureus.42214 [doi]
LID - e42214
AB  - Introduction Artificial Intelligence (AI) platforms have gained widespread 
      attention for their distinct ability to generate automated responses to various 
      prompts. However, its role in assessing the quality and readability of a provided 
      text remains unclear. Thus, the purpose of this study is to evaluate the 
      proficiency of the conversational generative pre-trained transformer (ChatGPT) in 
      utilizing the DISCERN tool to evaluate the quality of online content regarding 
      shock wave therapy for erectile dysfunction. Methods Websites were generated 
      using a Google search of "shock wave therapy for erectile dysfunction" with 
      location filters disabled. Readability was analyzed using Readable software 
      (Readable.com, Horsham, United Kingdom). Quality was assessed independently by 
      three reviewers using the DISCERN tool. The same plain text files collected were 
      inputted into ChatGPT to determine whether they produced comparable metrics for 
      readability and quality. Results The study results revealed a notable disparity 
      between ChatGPT's readability assessment and that obtained from a reliable tool, 
      Readable.com (p&lt;0.05). This indicates a lack of alignment between ChatGPT's 
      algorithm and that of established tools, such as Readable.com. Similarly, the 
      DISCERN score generated by ChatGPT differed significantly from the scores 
      generated manually by human evaluators (p&lt;0.05), suggesting that ChatGPT may not 
      be capable of accurately identifying poor-quality information sources regarding 
      shock wave therapy as a treatment for erectile dysfunction. Conclusion ChatGPT's 
      evaluation of the quality and readability of online text regarding shockwave 
      therapy for erectile dysfunction differs from that of human raters and trusted 
      tools. Therefore, ChatGPT's current capabilities were not sufficient for reliably 
      assessing the quality and readability of textual content. Further research is 
      needed to elucidate the role of AI in the objective evaluation of online medical 
      content in other fields. Continued development in AI and incorporation of tools 
      such as DISCERN into AI software may enhance the way patients navigate the web in 
      search of high-quality medical content in the future.
CI  - Copyright © 2023, Golan et al.
FAU - Golan, Roei
AU  - Golan R
AD  - Department of Clinical Sciences, Florida State University College of Medicine, 
      Tallahassee, USA.
FAU - Ripps, Sarah J
AU  - Ripps SJ
AD  - Department of Clinical Sciences, Florida State University College of Medicine, 
      Tallahassee, USA.
FAU - Reddy, Raghuram
AU  - Reddy R
AD  - Herbert Wertheim College of Medicine, Florida International University, Miami, 
      USA.
FAU - Loloi, Justin
AU  - Loloi J
AD  - Department of Urology, Montefiore Medical Center, Bronx, USA.
FAU - Bernstein, Ari P
AU  - Bernstein AP
AD  - Department of Urology, New York University Langone Health, New York, USA.
FAU - Connelly, Zachary M
AU  - Connelly ZM
AD  - Department of Surgery, Louisiana State University Health Shreveport, Shreveport, 
      USA.
FAU - Golan, Noa S
AU  - Golan NS
AD  - Department of Psychology, University of Florida, Gainesville, USA.
FAU - Ramasamy, Ranjith
AU  - Ramasamy R
AD  - Department of Urology, Desai Sethi Urology Institute, Miami, USA.
LA  - eng
PT  - Journal Article
DEP - 20230720
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10362474
OTO - NOTNLM
OT  - artificial intelligence in medicine
OT  - chatgpt
OT  - healthcare ai and robotics
OT  - online medical information
OT  - readability
OT  - shock wave therapy
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/07/24 06:42
MHDA- 2023/07/24 06:43
PMCR- 2023/07/20
CRDT- 2023/07/24 04:48
PHST- 2023/05/16 00:00 [received]
PHST- 2023/07/20 00:00 [accepted]
PHST- 2023/07/24 06:43 [medline]
PHST- 2023/07/24 06:42 [pubmed]
PHST- 2023/07/24 04:48 [entrez]
PHST- 2023/07/20 00:00 [pmc-release]
AID - 10.7759/cureus.42214 [doi]
PST - epublish
SO  - Cureus. 2023 Jul 20;15(7):e42214. doi: 10.7759/cureus.42214. eCollection 2023 
      Jul.

PMID- 38217726
OWN - NLM
STAT- MEDLINE
DCOM- 20240318
LR  - 20240402
IS  - 1434-4726 (Electronic)
IS  - 0937-4477 (Print)
IS  - 0937-4477 (Linking)
VI  - 281
IP  - 4
DP  - 2024 Apr
TI  - ChatGPT vs UpToDate: comparative study of usefulness and reliability of Chatbot 
      in common clinical presentations of otorhinolaryngology-head and neck surgery.
PG  - 2145-2151
LID - 10.1007/s00405-023-08423-w [doi]
AB  - PURPOSE: The usage of Chatbots as a kind of Artificial Intelligence in medicine 
      is getting to increase in recent years. UpToDate® is another well-known search 
      tool established on evidence-based knowledge and is used daily by doctors 
      worldwide. In this study, we aimed to investigate the usefulness and reliability 
      of ChatGPT compared to UpToDate in Otorhinolaryngology and Head and Neck Surgery 
      (ORL-HNS). MATERIALS AND METHODS: ChatGPT-3.5 and UpToDate were interrogated for 
      the management of 25 common clinical case scenarios (13 males/12 females) 
      recruited from literature considering the daily observation at the Department of 
      Otorhinolaryngology of Ege University&nbsp;Faculty&nbsp;of Medicine. Scientific references 
      for the management were requested for each clinical case. The accuracy of the 
      references in the ChatGPT answers was assessed on a 0-2 scale and the usefulness 
      of the ChatGPT and UpToDate answers was assessed with 1-3 scores by reviewers. 
      UpToDate and ChatGPT 3.5 responses were compared. RESULTS: ChatGPT did not give 
      references in some questions in contrast to UpToDate. Information on the ChatGPT 
      was limited to 2021. UpToDate supported the paper with subheadings, tables, 
      figures, and algorithms. The mean accuracy score of references in ChatGPT answers 
      was 0.25-weak/unrelated. The median (Q1-Q3) was 1.00 (1.25-2.00) for ChatGPT and 
      2.63 (2.75-3.00) for UpToDate, the difference was statistically significant 
      (p &lt; 0.001). UpToDate was observed more useful and reliable than ChatGPT. 
      CONCLUSIONS: ChatGPT has the potential to support the physicians to find out the 
      information but our results suggest that ChatGPT needs to be improved to increase 
      the usefulness and reliability of medical evidence-based knowledge.
CI  - © 2024. The Author(s).
FAU - Karimov, Ziya
AU  - Karimov Z
AUID- ORCID: 0000-0001-7237-4878
AD  - Medicine Program, Ege University Faculty of Medicine, 35100, Izmir, Türkiye. 
      dr.ziya.karimov@gmail.com.
FAU - Allahverdiyev, Irshad
AU  - Allahverdiyev I
AUID- ORCID: 0009-0000-2503-5419
AD  - Medicine Program, Istanbul University, Istanbul Faculty of Medicine, Istanbul, 
      Türkiye.
FAU - Agayarov, Ozlem Yagiz
AU  - Agayarov OY
AUID- ORCID: 0000-0002-8455-4400
AD  - Department of Otolaryngology-Head and Neck Surgery, Izmir Tepecik Education and 
      Research Hospital, Health Sciences University, Izmir, Türkiye.
FAU - Demir, Dogukan
AU  - Demir D
AUID- ORCID: 0009-0002-9872-990X
AD  - Department of Otolaryngology-Head and Neck Surgery, Izmir Tepecik Education and 
      Research Hospital, Health Sciences University, Izmir, Türkiye.
FAU - Almuradova, Elvina
AU  - Almuradova E
AUID- ORCID: 0000-0002-5551-7731
AD  - Department of Medical Oncology, Ege University Faculty of Medicine, Izmir, 
      Türkiye.
AD  - Department of Oncology, Medicana International Hospital, Izmir, Türkiye.
LA  - eng
PT  - Journal Article
DEP - 20240113
PL  - Germany
TA  - Eur Arch Otorhinolaryngol
JT  - European archives of oto-rhino-laryngology : official journal of the European 
      Federation of Oto-Rhino-Laryngological Societies (EUFOS) : affiliated with the 
      German Society for Oto-Rhino-Laryngology - Head and Neck Surgery
JID - 9002937
SB  - IM
MH  - Female
MH  - Male
MH  - Humans
MH  - *Artificial Intelligence
MH  - Reproducibility of Results
MH  - Software
MH  - *Otolaryngology
MH  - Algorithms
PMC - PMC10942922
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Chatbot
OT  - ENT
OT  - Otorhinolaryngology and head and neck surgery
OT  - UpToDate
COIS- The authors declare no conflict of interest.
EDAT- 2024/01/13 17:44
MHDA- 2024/03/18 06:43
PMCR- 2024/01/13
CRDT- 2024/01/13 11:14
PHST- 2023/09/02 00:00 [received]
PHST- 2023/12/18 00:00 [accepted]
PHST- 2024/03/18 06:43 [medline]
PHST- 2024/01/13 17:44 [pubmed]
PHST- 2024/01/13 11:14 [entrez]
PHST- 2024/01/13 00:00 [pmc-release]
AID - 10.1007/s00405-023-08423-w [pii]
AID - 8423 [pii]
AID - 10.1007/s00405-023-08423-w [doi]
PST - ppublish
SO  - Eur Arch Otorhinolaryngol. 2024 Apr;281(4):2145-2151. doi: 
      10.1007/s00405-023-08423-w. Epub 2024 Jan 13.

PMID- 38421439
OWN - NLM
STAT- Publisher
LR  - 20240229
IS  - 1436-2813 (Electronic)
IS  - 0941-1291 (Linking)
DP  - 2024 Feb 29
TI  - ChatGPT in surgery: a revolutionary innovation?
LID - 10.1007/s00595-024-02800-6 [doi]
AB  - ChatGPT has brought about a new era of digital health, as this model has become 
      prominent and been rapidly developing since its release. ChatGPT may be able to 
      facilitate improvements in surgery as well; however, the influence of ChatGPT on 
      surgery is largely unknown at present. Therefore, the present study reports on 
      the current applications of ChatGPT in the field of surgery, evaluating its 
      workflow, practical implementations, limitations, and future perspectives. A 
      literature search was performed using the PubMed and Embase databases. The 
      initial search was performed from its inception until July 2023. This study 
      revealed that ChatGPT has promising capabilities in areas of surgical research, 
      education, training, and practice. In daily practice, surgeons and surgical 
      residents can be aided in performing logistics and administrative tasks, and 
      patients can be more efficiently informed about the details of their condition. 
      However, priority should be given to establishing proper policies and protocols 
      to ensure the safe and reliable use of this model.
CI  - © 2024. The Author(s).
FAU - Bektaş, Mustafa
AU  - Bektaş M
AD  - Amsterdam UMC Location Vrije Universiteit Amsterdam, Surgery, De Boelelaan 1117, 
      Amsterdam, The Netherlands. M.Bektas@amsterdamumc.nl.
FAU - Pereira, Jaime Ken
AU  - Pereira JK
AD  - Department of Computer Science, Vrije Universiteit Amsterdam, De Boelelaan 1105, 
      Amsterdam, The Netherlands.
FAU - Daams, Freek
AU  - Daams F
AD  - Amsterdam UMC Location Vrije Universiteit Amsterdam, Surgery, De Boelelaan 1117, 
      Amsterdam, The Netherlands.
FAU - van der Peet, Donald L
AU  - van der Peet DL
AD  - Amsterdam UMC Location Vrije Universiteit Amsterdam, Surgery, De Boelelaan 1117, 
      Amsterdam, The Netherlands.
LA  - eng
PT  - Journal Article
DEP - 20240229
PL  - Japan
TA  - Surg Today
JT  - Surgery today
JID - 9204360
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Surgery
EDAT- 2024/02/29 12:46
MHDA- 2024/02/29 12:46
CRDT- 2024/02/29 11:07
PHST- 2023/09/21 00:00 [received]
PHST- 2023/12/13 00:00 [accepted]
PHST- 2024/02/29 12:46 [medline]
PHST- 2024/02/29 12:46 [pubmed]
PHST- 2024/02/29 11:07 [entrez]
AID - 10.1007/s00595-024-02800-6 [pii]
AID - 10.1007/s00595-024-02800-6 [doi]
PST - aheadofprint
SO  - Surg Today. 2024 Feb 29. doi: 10.1007/s00595-024-02800-6.

PMID- 38391243
OWN - NLM
STAT- MEDLINE
DCOM- 20240403
LR  - 20240403
IS  - 1536-4798 (Electronic)
IS  - 0277-3740 (Linking)
VI  - 43
IP  - 5
DP  - 2024 May 1
TI  - Performance of ChatGPT in Diagnosis of Corneal Eye Diseases.
PG  - 664-670
LID - 10.1097/ICO.0000000000003492 [doi]
AB  - PURPOSE: The aim of this study was to assess the capabilities of ChatGPT-4.0 and 
      ChatGPT-3.5 for diagnosing corneal eye diseases based on case reports and compare 
      with human experts. METHODS: We randomly selected 20 cases of corneal diseases 
      including corneal infections, dystrophies, and degenerations from a publicly 
      accessible online database from the University of Iowa. We then input the text of 
      each case description into ChatGPT-4.0 and ChatGPT-3.5 and asked for a 
      provisional diagnosis. We finally evaluated the responses based on the correct 
      diagnoses, compared them with the diagnoses made by 3 corneal specialists (human 
      experts), and evaluated interobserver agreements. RESULTS: The provisional 
      diagnosis accuracy based on ChatGPT-4.0 was 85% (17 correct of 20 cases), whereas 
      the accuracy of ChatGPT-3.5 was 60% (12 correct cases of 20). The accuracy of 3 
      corneal specialists compared with ChatGPT-4.0 and ChatGPT-3.5 was 100% (20 cases, 
      P = 0.23, P = 0.0033), 90% (18 cases, P = 0.99, P = 0.6), and 90% (18 cases, P = 
      0.99, P = 0.6), respectively. The interobserver agreement between ChatGPT-4.0 and 
      ChatGPT-3.5 was 65% (13 cases), whereas the interobserver agreement between 
      ChatGPT-4.0 and 3 corneal specialists was 85% (17 cases), 80% (16 cases), and 75% 
      (15 cases), respectively. However, the interobserver agreement between 
      ChatGPT-3.5 and each of 3 corneal specialists was 60% (12 cases). CONCLUSIONS: 
      The accuracy of ChatGPT-4.0 in diagnosing patients with various corneal 
      conditions was markedly improved than ChatGPT-3.5 and promising for potential 
      clinical integration. A balanced approach that combines artificial 
      intelligence-generated insights with clinical expertise holds a key role for 
      unveiling its full potential in eye care.
CI  - Copyright © 2024 Wolters Kluwer Health, Inc. All rights reserved.
FAU - Delsoz, Mohammad
AU  - Delsoz M
AUID- ORCID: 0000-0001-5638-2034
AD  - Department of Ophthalmology, Hamilton Eye Institute, University of Tennessee 
      Health Science Center, Memphis, TN.
FAU - Madadi, Yeganeh
AU  - Madadi Y
AD  - Department of Ophthalmology, Hamilton Eye Institute, University of Tennessee 
      Health Science Center, Memphis, TN.
FAU - Raja, Hina
AU  - Raja H
AD  - Department of Ophthalmology, Hamilton Eye Institute, University of Tennessee 
      Health Science Center, Memphis, TN.
FAU - Munir, Wuqaas M
AU  - Munir WM
AD  - Department of Ophthalmology and Visual Sciences, University of Maryland School of 
      Medicine, Baltimore, MD.
FAU - Tamm, Brendan
AU  - Tamm B
AD  - Department of Ophthalmology and Visual Sciences, University of Maryland School of 
      Medicine, Baltimore, MD.
FAU - Mehravaran, Shiva
AU  - Mehravaran S
AD  - Department of Biology, School of Computer, Mathematical, and Natural Sciences, 
      Morgan State University, Baltimore, MD.
FAU - Soleimani, Mohammad
AU  - Soleimani M
AD  - Department of Ophthalmology and Visual Sciences, University of Illinois at 
      Chicago, Chicago, IL.
AD  - Eye Research Center, Farabi Eye Hospital, Tehran University of Medical Sciences, 
      Tehran, Iran ; and.
FAU - Djalilian, Ali
AU  - Djalilian A
AD  - Department of Ophthalmology and Visual Sciences, University of Illinois at 
      Chicago, Chicago, IL.
FAU - Yousefi, Siamak
AU  - Yousefi S
AUID- ORCID: 0000-0001-8633-5730
AD  - Department of Ophthalmology, Hamilton Eye Institute, University of Tennessee 
      Health Science Center, Memphis, TN.
AD  - Department of Genetics, Genomics, and Informatics, University of Tennessee Health 
      Science Center, Memphis, TN.
LA  - eng
PT  - Case Reports
PT  - Journal Article
DEP - 20240223
PL  - United States
TA  - Cornea
JT  - Cornea
JID - 8216186
SB  - IM
UOF - medRxiv. 2023 Aug 28;:. PMID: 37720035
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Corneal Diseases/diagnosis
MH  - Cornea
MH  - Databases, Factual
COIS- W. M. Munir is in the advisory board for Sanofi. S. Yousefi received prototype 
      instruments from Remidio, M&amp;S Technologies, and Visrtucal Fields. He gives 
      consultations to the InsihgtAEye and Enolink. The remaining authors have no 
      conflicts of interest to disclose.
EDAT- 2024/02/23 12:42
MHDA- 2024/04/03 06:44
CRDT- 2024/02/23 09:13
PHST- 2023/09/26 00:00 [received]
PHST- 2023/12/28 00:00 [accepted]
PHST- 2024/04/03 06:44 [medline]
PHST- 2024/02/23 12:42 [pubmed]
PHST- 2024/02/23 09:13 [entrez]
AID - 00003226-990000000-00493 [pii]
AID - 10.1097/ICO.0000000000003492 [doi]
PST - ppublish
SO  - Cornea. 2024 May 1;43(5):664-670. doi: 10.1097/ICO.0000000000003492. Epub 2024 
      Feb 23.

PMID- 37671415
OWN - NLM
STAT- MEDLINE
DCOM- 20231120
LR  - 20231120
IS  - 1940-5480 (Electronic)
IS  - 1067-151X (Print)
IS  - 1067-151X (Linking)
VI  - 31
IP  - 23
DP  - 2023 Dec 1
TI  - Comparison of ChatGPT-3.5, ChatGPT-4, and Orthopaedic Resident Performance on 
      Orthopaedic Assessment Examinations.
PG  - 1173-1179
LID - 10.5435/JAAOS-D-23-00396 [doi]
AB  - INTRODUCTION: Artificial intelligence (AI) programs have the ability to answer 
      complex queries including medical profession examination questions. The purpose 
      of this study was to compare the performance of orthopaedic residents (ortho 
      residents) against Chat Generative Pretrained Transformer (ChatGPT)-3.5 and GPT-4 
      on orthopaedic assessment examinations. A secondary objective was to perform a 
      subgroup analysis comparing the performance of each group on questions that 
      included image interpretation versus text-only questions. METHODS: The ResStudy 
      orthopaedic examination question bank was used as the primary source of 
      questions. One hundred eighty questions and answer choices from nine different 
      orthopaedic subspecialties were directly input into ChatGPT-3.5 and then GPT-4. 
      ChatGPT did not have consistently available image interpretation, so no images 
      were directly provided to either AI format. Answers were recorded as correct 
      versus incorrect by the chatbot, and resident performance was recorded based on 
      user data provided by ResStudy. RESULTS: Overall, ChatGPT-3.5, GPT-4, and ortho 
      residents scored 29.4%, 47.2%, and 74.2%, respectively. There was a difference 
      among the three groups in testing success, with ortho residents scoring higher 
      than ChatGPT-3.5 and GPT-4 ( P &lt; 0.001 and P &lt; 0.001). GPT-4 scored higher than 
      ChatGPT-3.5 ( P = 0.002). A subgroup analysis was performed by dividing questions 
      into question stems without images and question stems with images. ChatGPT-3.5 
      was more correct (37.8% vs. 22.4%, respectively, OR = 2.1, P = 0.033) and 
      ChatGPT-4 was also more correct (61.0% vs. 35.7%, OR = 2.8, P &lt; 0.001), when 
      comparing text-only questions versus questions with images. Residents were 72.6% 
      versus 75.5% correct with text-only questions versus questions with images, with 
      no significant difference ( P = 0.302). CONCLUSION: Orthopaedic residents were 
      able to answer more questions accurately than ChatGPT-3.5 and GPT-4 on 
      orthopaedic assessment examinations. GPT-4 is superior to ChatGPT-3.5 for 
      answering orthopaedic resident assessment examination questions. Both ChatGPT-3.5 
      and GPT-4 performed better on text-only questions than questions with images. It 
      is unlikely that GPT-4 or ChatGPT-3.5 would pass the American Board of 
      Orthopaedic Surgery written examination.
CI  - Copyright © 2023 The Author(s). Published by Wolters Kluwer Health, Inc. on 
      behalf of the American Academy of Orthopaedic Surgeons.
FAU - Massey, Patrick A
AU  - Massey PA
AUID- ORCID: 0000-0001-8637-0122
AD  - From the Department of Orthopaedic Surgery, Louisiana State University Health 
      Sciences Center Shreveport, Shreveport, LA.
FAU - Montgomery, Carver
AU  - Montgomery C
FAU - Zhang, Andrew S
AU  - Zhang AS
AUID- ORCID: 0000-0003-1799-8703
LA  - eng
PT  - Journal Article
DEP - 20230904
PL  - United States
TA  - J Am Acad Orthop Surg
JT  - The Journal of the American Academy of Orthopaedic Surgeons
JID - 9417468
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Orthopedics
MH  - Physical Examination
MH  - Software
PMC - PMC10627532
EDAT- 2023/09/06 06:42
MHDA- 2023/11/20 06:54
PMCR- 2023/11/06
CRDT- 2023/09/06 03:59
PHST- 2023/04/26 00:00 [received]
PHST- 2023/07/22 00:00 [accepted]
PHST- 2023/11/20 06:54 [medline]
PHST- 2023/09/06 06:42 [pubmed]
PHST- 2023/09/06 03:59 [entrez]
PHST- 2023/11/06 00:00 [pmc-release]
AID - 00124635-990000000-00782 [pii]
AID - JAAOS-D-23-00396 [pii]
AID - 10.5435/JAAOS-D-23-00396 [doi]
PST - ppublish
SO  - J Am Acad Orthop Surg. 2023 Dec 1;31(23):1173-1179. doi: 
      10.5435/JAAOS-D-23-00396. Epub 2023 Sep 4.

PMID- 38050503
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231206
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 11
DP  - 2023 Nov
TI  - ChatGPT's Potential in Enhancing Physician Efficiency: A Japanese Case Study.
PG  - e48235
LID - 10.7759/cureus.48235 [doi]
LID - e48235
AB  - Artificial intelligence (AI), particularly ChatGPT, developed by OpenAI (San 
      Francisco, CA, USA), is making significant strides in the medical field. In a 
      simulated case study, a 66-year-old Japanese female patient's dialogue with a 
      physician was transcribed and inputted into ChatGPT to assess its efficacy in 
      drafting medical records, formulating differential diagnoses, and establishing 
      treatment plans. The results showed a high similarity between the medical 
      summaries generated by ChatGPT and those of the attending physician. This 
      suggests that ChatGPT has the potential to assist physicians in clinical 
      reasoning and reduce the administrative burden, allowing them to spend more time 
      with patients. However, there are limitations, such as the system's reliance on 
      linguistic data and occasional inaccuracies. Despite its potential, the ethical 
      implications of using patient data and the risk of AI replacing clinicians 
      emphasize the need for continuous evaluation, rigorous oversight, and the 
      establishment of comprehensive guidelines. As AI continues to integrate into 
      healthcare, it is crucial for physicians to ensure that technology complements, 
      rather than replaces, human expertise, with the primary focus remaining on 
      delivering high-quality patient care.
CI  - Copyright © 2023, Kaneda et al.
FAU - Kaneda, Yudai
AU  - Kaneda Y
AD  - Epidemiology and Public Health, School of Medicine, Hokkaido University, 
      Hokkaido, JPN.
FAU - Takita, Morihito
AU  - Takita M
AD  - Internal Medicine, Medical Governance Research Institute, Tokyo, JPN.
FAU - Hamaki, Tamae
AU  - Hamaki T
AD  - Internal Medicine, Accessible Rail Medical Services Tetsuikai, Navitas Clinic 
      Shinjuku, Tokyo, JPN.
FAU - Ozaki, Akihiko
AU  - Ozaki A
AD  - Breast and Thyroid Surgery, Jyoban Hospital of Tokiwa Foundation, Fukushima, JPN.
FAU - Tanimoto, Tetsuya
AU  - Tanimoto T
AD  - Internal Medicine, Accessible Rail Medical Services Tetsuikai, Navitas Clinic 
      Kawasaki, Kanagawa, JPN.
LA  - eng
PT  - Journal Article
DEP - 20231103
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10693924
OTO - NOTNLM
OT  - ai &amp; robotics in healthcare
OT  - chatgpt
OT  - differential diagnoses
OT  - japan
OT  - medical records
COIS- The authors have declared financial relationships, which are detailed in the next 
      section.
EDAT- 2023/12/05 12:42
MHDA- 2023/12/05 12:43
PMCR- 2023/11/03
CRDT- 2023/12/05 03:47
PHST- 2023/11/03 00:00 [accepted]
PHST- 2023/12/05 12:43 [medline]
PHST- 2023/12/05 12:42 [pubmed]
PHST- 2023/12/05 03:47 [entrez]
PHST- 2023/11/03 00:00 [pmc-release]
AID - 10.7759/cureus.48235 [doi]
PST - epublish
SO  - Cureus. 2023 Nov 3;15(11):e48235. doi: 10.7759/cureus.48235. eCollection 2023 
      Nov.

PMID- 38090410
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231213
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 11
DP  - 2023 Nov
TI  - The Impact of Chat Generative Pre-trained Transformer (ChatGPT) on Oncology: 
      Application, Expectations, and Future Prospects.
PG  - e48670
LID - 10.7759/cureus.48670 [doi]
LID - e48670
AB  - The integration of&nbsp;Chat Generative Pre-trained Transformer (ChatGPT) into the 
      field of oncology has recently garnered significant attention, with potential 
      implications for enhancing both research and clinical practice. This paper 
      presents a comprehensive review of the evolving landscape of ChatGPT applications 
      in oncology, emphasizing its contributions to diagnosis, treatment, research, and 
      patient education. We examine its role in assisting medical professionals, 
      researchers, and patients in understanding complex cancer-related data and making 
      informed decisions. Ethical considerations and potential challenges associated 
      with the implementation of ChatGPT in oncology are also discussed. This article 
      highlights the promising role of ChatGPT as a valuable tool in the oncology 
      domain and outlines future directions for research and application.
CI  - Copyright © 2023, Li et al.
FAU - Li, Yanxing
AU  - Li Y
AD  - Department of Clinical Oncology, Xi'an Jiaotong University Health Science Center, 
      Xi'an, CHN.
FAU - Gao, Wentao
AU  - Gao W
AD  - Department of Clinical Oncology, Xi'an Jiaotong University Health Science Center, 
      Xi'an, CHN.
FAU - Luan, Zhenhua
AU  - Luan Z
AD  - Department of Clinical Oncology, Xi'an Jiaotong University Health Science Center, 
      Xi'an, CHN.
FAU - Zhou, Zhi
AU  - Zhou Z
AD  - Department of Clinical Oncology, Xi'an Jiaotong University Health Science Center, 
      Xi'an, CHN.
FAU - Li, Jianjun
AU  - Li J
AD  - Department of Cardiology, Jincheng People's Hospital, Changzhi Medical College, 
      Jincheng, CHN.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20231111
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10714025
OTO - NOTNLM
OT  - artificial intelligence
OT  - cancer
OT  - chatgpt
OT  - diagnosis
OT  - oncology
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/12/13 18:42
MHDA- 2023/12/13 18:43
PMCR- 2023/11/11
CRDT- 2023/12/13 13:08
PHST- 2023/11/11 00:00 [accepted]
PHST- 2023/12/13 18:43 [medline]
PHST- 2023/12/13 18:42 [pubmed]
PHST- 2023/12/13 13:08 [entrez]
PHST- 2023/11/11 00:00 [pmc-release]
AID - 10.7759/cureus.48670 [doi]
PST - epublish
SO  - Cureus. 2023 Nov 11;15(11):e48670. doi: 10.7759/cureus.48670. eCollection 2023 
      Nov.

PMID- 37244883
OWN - NLM
STAT- MEDLINE
DCOM- 20230926
LR  - 20230926
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 51
IP  - 10
DP  - 2023 Oct
TI  - ChatGPT: Detection in Academic Journals is Editors' and Publishers' 
      Responsibilities.
PG  - 2103-2104
LID - 10.1007/s10439-023-03247-5 [doi]
AB  - This letter makes note that the responsibility to detect text written by AI, such 
      as ChatGPT, is the sole responsibility of editors and journals/publishers. This 
      proposed policy is made to ensure proper authorship and to therefore assuage 
      readers of a paper's authorship validity-so as not to have AI-driven guest 
      authorship-so that the integrity of the biomedical literature is not further 
      degraded. Two letters to the editor were recently written in this journal by 
      ChatGPT and edited by the author. The extent to which ChatGPT contributed to 
      those letters' content is unknown.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Teixeira da Silva, Jaime A
AU  - Teixeira da Silva JA
AD  - Independent researcher, Ikenobe 3011-2, Kagawa-ken, 761-0799, Japan.
LA  - eng
PT  - Letter
DEP - 20230527
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - *Editorial Policies
MH  - *Periodicals as Topic
MH  - Authorship
OTO - NOTNLM
OT  - AI
OT  - Human editing
OT  - Large language models
OT  - Productivity
OT  - Publish or perish
EDAT- 2023/05/28 01:07
MHDA- 2023/09/26 13:42
CRDT- 2023/05/27 23:03
PHST- 2023/05/16 00:00 [received]
PHST- 2023/05/17 00:00 [accepted]
PHST- 2023/09/26 13:42 [medline]
PHST- 2023/05/28 01:07 [pubmed]
PHST- 2023/05/27 23:03 [entrez]
AID - 10.1007/s10439-023-03247-5 [pii]
AID - 10.1007/s10439-023-03247-5 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2023 Oct;51(10):2103-2104. doi: 10.1007/s10439-023-03247-5. Epub 
      2023 May 27.

PMID- 37335851
OWN - NLM
STAT- MEDLINE
DCOM- 20230821
LR  - 20240210
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 30
IP  - 9
DP  - 2023 Aug 18
TI  - ChatGPT and the clinical informatics board examination: the end of unproctored 
      maintenance of certification?
PG  - 1558-1560
LID - 10.1093/jamia/ocad104 [doi]
AB  - We aimed to assess ChatGPT's performance on the Clinical Informatics Board 
      Examination and to discuss the implications of large language models (LLMs) for 
      board certification and maintenance. We tested ChatGPT using 260 multiple-choice 
      questions from Mankowitz's Clinical Informatics Board Review book, omitting 6 
      image-dependent questions. ChatGPT answered 190 (74%) of 254 eligible questions 
      correctly. While performance varied across the Clinical Informatics Core Content 
      Areas, differences were not statistically significant. ChatGPT's performance 
      raises concerns about the potential misuse in medical certification and the 
      validity of knowledge assessment exams. Since ChatGPT is able to answer 
      multiple-choice questions accurately, permitting candidates to use artificial 
      intelligence (AI) systems for exams will compromise the credibility and validity 
      of at-home assessments and undermine public trust. The advent of AI and LLMs 
      threatens to upend existing processes of board certification and maintenance and 
      necessitates new approaches to the evaluation of proficiency in medical 
      education.
CI  - © The Author(s) 2023. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association. All rights reserved. For permissions, 
      please email: journals.permissions@oup.com.
FAU - Kumah-Crystal, Yaa
AU  - Kumah-Crystal Y
AD  - Department of Biomedical Informatics, Pediatric Endocrinology, Vanderbilt 
      University Medical Center, Nashville, Tennessee, USA.
FAU - Mankowitz, Scott
AU  - Mankowitz S
AD  - Department of Clinical Informatics, Overlook Medical Center, Summit, New Jersey, 
      USA.
FAU - Embi, Peter
AU  - Embi P
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee, USA.
FAU - Lehmann, Christoph U
AU  - Lehmann CU
AUID- ORCID: 0000-0001-9559-4646
AD  - Clinical Informatics Center, UT Southwestern Medical Center, Dallas, Texas, USA.
LA  - eng
GR  - UL1 TR003163/TR/NCATS NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
MH  - Artificial Intelligence
MH  - Certification
MH  - *Medical Informatics
MH  - *Education, Medical
MH  - Language
PMC - PMC10436139
OTO - NOTNLM
OT  - ChatGPT
OT  - Clinical Informatics Board Examination
OT  - artificial intelligence
OT  - large language models
OT  - medical education
COIS- The authors declare that they have no conflicts of interest.
EDAT- 2023/06/19 19:12
MHDA- 2023/08/21 06:43
PMCR- 2024/06/19
CRDT- 2023/06/19 14:43
PHST- 2023/03/23 00:00 [received]
PHST- 2023/05/31 00:00 [revised]
PHST- 2023/06/08 00:00 [accepted]
PHST- 2024/06/19 00:00 [pmc-release]
PHST- 2023/08/21 06:43 [medline]
PHST- 2023/06/19 19:12 [pubmed]
PHST- 2023/06/19 14:43 [entrez]
AID - 7202064 [pii]
AID - ocad104 [pii]
AID - 10.1093/jamia/ocad104 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2023 Aug 18;30(9):1558-1560. doi: 10.1093/jamia/ocad104.

PMID- 37804030
OWN - NLM
STAT- MEDLINE
DCOM- 20231101
LR  - 20231101
IS  - 1681-7168 (Electronic)
IS  - 1022-386X (Linking)
VI  - 33
IP  - 10
DP  - 2023 Oct
TI  - ChatGPT: Transcending Language Limitations in Scientific Research Using 
      Artificial Intelligence.
PG  - 1198-1200
LID - 10.29271/jcpsp.2023.10.1198 [doi]
AB  - Health and scientific researchers in non-English speaking countries such as 
      Pakistan, are not proficient in English, which limits their ability to 
      communicate their ideas and findings to the international scientific community. 
      ChatGPT is a large language model that can help non-native English speakers to 
      write high-quality scientific papers much faster by assisting them in conveying 
      their ideas in a clear and understandable manner, as well as avoiding common 
      language errors. In fact, ChatGPT has already been used in publication of 
      research papers, literature reviews, and editorials. However, it is imperative to 
      recognise that ChatGPT is still in its early stages, thus, it is important to 
      recognise its limitations. It is suggested that ChatGPT should be employed to 
      complement writing and reviewing tasks but should not be relied on to generate 
      original content or perform essential analysis, as it cannot replace human 
      expertise, contextual knowledge, experience, and intelligence. Researchers should 
      exercise caution and thoroughly scrutinise the generated text for accuracy and 
      plagiarism before incorporating it into their work. Key Words: Artificial 
      intelligence, ChatGPT, Health research, Scientific research.
FAU - Osama, Muhammad
AU  - Osama M
AD  - Foundation University College of Physical Therapy (FUCP), Foundation University, 
      Islamabad, Pakistan.
AD  - Rawal Institute of Health Sciences, Islamabad, Pakistan.
FAU - Afridi, Sabah
AU  - Afridi S
AD  - Hofstra University, New York, United States of America.
FAU - Maaz, Muhammad
AU  - Maaz M
LA  - eng
PT  - Journal Article
PL  - Pakistan
TA  - J Coll Physicians Surg Pak
JT  - Journal of the College of Physicians and Surgeons--Pakistan : JCPSP
JID - 9606447
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Exercise
MH  - Knowledge
MH  - Language
MH  - Pakistan
EDAT- 2023/10/07 11:43
MHDA- 2023/11/01 12:44
CRDT- 2023/10/07 03:51
PHST- 2023/02/01 00:00 [received]
PHST- 2023/08/31 00:00 [accepted]
PHST- 2023/11/01 12:44 [medline]
PHST- 2023/10/07 11:43 [pubmed]
PHST- 2023/10/07 03:51 [entrez]
AID - 040579197 [pii]
AID - 10.29271/jcpsp.2023.10.1198 [doi]
PST - ppublish
SO  - J Coll Physicians Surg Pak. 2023 Oct;33(10):1198-1200. doi: 
      10.29271/jcpsp.2023.10.1198.

PMID- 38148495
OWN - NLM
STAT- MEDLINE
DCOM- 20231228
LR  - 20240214
IS  - 1975-5937 (Electronic)
IS  - 1975-5937 (Linking)
VI  - 20
DP  - 2023
TI  - Application of artificial intelligence chatbots, including ChatGPT, in education, 
      scholarly work, programming, and content generation and its prospects: a 
      narrative review.
PG  - 38
LID - 10.3352/jeehp.2023.20.38 [doi]
AB  - This study aims to explore ChatGPT’s (GPT-3.5 version) functionalities, including 
      reinforcement learning, diverse applications, and limitations. ChatGPT is an 
      artificial intelligence (AI) chatbot powered by OpenAI’s Generative Pre-trained 
      Transformer (GPT) model. The chatbot’s applications span education, programming, 
      content generation, and more, demonstrating its versatility. ChatGPT can improve 
      education by creating assignments and offering personalized feedback, as shown by 
      its notable performance in medical exams and the United States Medical Licensing 
      Exam. However, concerns include plagiarism, reliability, and educational 
      disparities. It aids in various research tasks, from design to writing, and has 
      shown proficiency in summarizing and suggesting titles. Its use in scientific 
      writing and language translation is promising, but professional oversight is 
      needed for accuracy and originality. It assists in programming tasks like writing 
      code, debugging, and guiding installation and updates. It offers diverse 
      applications, from cheering up individuals to generating creative content like 
      essays, news articles, and business plans. Unlike search engines, ChatGPT 
      provides interactive, generative responses and understands context, making it 
      more akin to human conversation, in contrast to conventional search engines’ 
      keyword-based, non-interactive nature. ChatGPT has limitations, such as potential 
      bias, dependence on outdated data, and revenue generation challenges. 
      Nonetheless, ChatGPT is considered to be a transformative AI tool poised to 
      redefine the future of generative technology. In conclusion, advancements in AI, 
      such as ChatGPT, are altering how knowledge is acquired and applied, marking a 
      shift from search engines to creativity engines. This transformation highlights 
      the increasing importance of AI literacy and the ability to effectively utilize 
      AI in various domains of life.
FAU - Kim, Tae Won
AU  - Kim TW
AD  - AI‧Future Strategy Center, National Information Society Agency of Korea, Daegu, 
      Korea.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20231227
PL  - Korea (South)
TA  - J Educ Eval Health Prof
JT  - Journal of educational evaluation for health professions
JID - 101490061
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Reproducibility of Results
MH  - Educational Status
MH  - *Software
MH  - Learning
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Literacy
OT  - Reproducibility of results
OT  - Search engine
OT  - Writing
EDAT- 2023/12/27 00:41
MHDA- 2023/12/28 06:42
CRDT- 2023/12/26 23:40
PHST- 2023/12/26 00:00 [received]
PHST- 2023/12/26 00:00 [accepted]
PHST- 2023/12/28 06:42 [medline]
PHST- 2023/12/27 00:41 [pubmed]
PHST- 2023/12/26 23:40 [entrez]
AID - jeehp.2023.20.38 [pii]
AID - 10.3352/jeehp.2023.20.38 [doi]
PST - ppublish
SO  - J Educ Eval Health Prof. 2023;20:38. doi: 10.3352/jeehp.2023.20.38. Epub 2023 Dec 
      27.

PMID- 37621112
OWN - NLM
STAT- MEDLINE
DCOM- 20231229
LR  - 20240305
IS  - 1365-2125 (Electronic)
IS  - 0306-5251 (Linking)
VI  - 90
IP  - 1
DP  - 2024 Jan
TI  - ChatGPT in pharmacometrics? Potential opportunities and limitations.
PG  - 360-365
LID - 10.1111/bcp.15895 [doi]
AB  - The potential of using ChatGPT in pharmacometrics was explored in this study, 
      with a focus on developing a population pharmacokinetic (PK) model for standard 
      half-life factor VIII. Our results demonstrated that ChatGPT can be utilized to 
      accurately obtain typical PK parameters from literature, generate a population PK 
      model in R and develop an interactive Shiny application to visualize the results. 
      ChatGPT's language generation capabilities enabled the development of R codes 
      with minimal programming knowledge and helped to identify as well fix errors in 
      the code. While ChatGPT presents several advantages, such as its ability to 
      streamline the development process, its use in pharmacometrics also has 
      limitations and challenges, including the accuracy and reliability of 
      AI-generated data, the lack of transparency and reproducibility regarding codes 
      generated by ChatGPT. Overall, our study demonstrates the potential of using 
      ChatGPT in pharmacometrics, but researchers must carefully evaluate its use for 
      their specific needs.
CI  - © 2023 The Authors. British Journal of Clinical Pharmacology published by John 
      Wiley &amp; Sons Ltd on behalf of British Pharmacological Society.
FAU - Cloesmeijer, Michael E
AU  - Cloesmeijer ME
AUID- ORCID: 0000-0002-2810-1570
AD  - Department of Hospital Pharmacy - Clinical Pharmacology, Amsterdam University 
      Medical Centers, Amsterdam, The Netherlands.
FAU - Janssen, Alexander
AU  - Janssen A
AD  - Department of Hospital Pharmacy - Clinical Pharmacology, Amsterdam University 
      Medical Centers, Amsterdam, The Netherlands.
FAU - Koopman, Sjoerd F
AU  - Koopman SF
AUID- ORCID: 0000-0002-4536-2692
AD  - Department of Hospital Pharmacy - Clinical Pharmacology, Amsterdam University 
      Medical Centers, Amsterdam, The Netherlands.
FAU - Cnossen, Marjon H
AU  - Cnossen MH
AD  - Department of Pediatric Hematology and Oncology, Erasmus University Medical 
      Center - Sophia Children's Hospital Rotterdam, Rotterdam, The Netherlands.
FAU - Mathôt, Ron A A
AU  - Mathôt RAA
AD  - Department of Hospital Pharmacy - Clinical Pharmacology, Amsterdam University 
      Medical Centers, Amsterdam, The Netherlands.
CN  - SYMPHONY consortium
LA  - eng
GR  - SYMPHONY/
GR  - NWA.1160.18.038/Netherlands Organization for Scientific Research/
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20230906
PL  - England
TA  - Br J Clin Pharmacol
JT  - British journal of clinical pharmacology
JID - 7503323
SB  - IM
MH  - Humans
MH  - *Reproducibility of Results
MH  - Half-Life
OTO - NOTNLM
OT  - haematology
OT  - modelling and simulation
OT  - pharmacokinetics
OT  - pharmacometrics
EDAT- 2023/08/25 06:42
MHDA- 2023/12/29 06:42
CRDT- 2023/08/25 02:07
PHST- 2023/07/31 00:00 [revised]
PHST- 2023/04/24 00:00 [received]
PHST- 2023/08/17 00:00 [accepted]
PHST- 2023/12/29 06:42 [medline]
PHST- 2023/08/25 06:42 [pubmed]
PHST- 2023/08/25 02:07 [entrez]
AID - 10.1111/bcp.15895 [doi]
PST - ppublish
SO  - Br J Clin Pharmacol. 2024 Jan;90(1):360-365. doi: 10.1111/bcp.15895. Epub 2023 
      Sep 6.

PMID- 38298626
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240202
IS  - 2405-8440 (Print)
IS  - 2405-8440 (Electronic)
IS  - 2405-8440 (Linking)
VI  - 10
IP  - 2
DP  - 2024 Jan 30
TI  - The application and challenges of ChatGPT in educational transformation: New 
      demands for teachers' roles.
PG  - e24289
LID - 10.1016/j.heliyon.2024.e24289 [doi]
LID - e24289
AB  - With the rapid development of information technology, artificial intelligence has 
      demonstrated great potential in promoting educational transformation. In November 
      2022, the release of the artificial intelligence product ChatGPT attracted 
      widespread attention, particularly in the field of education, sparking heated 
      discussions among scholars. As a language processing tool, ChatGPT can not only 
      answer user questions but also complete user-specified tasks and even 
      continuously optimize task performance. However, while possessing powerful 
      features, ChatGPT also has some shortcomings that need improvement, such as the 
      accuracy of answering questions, data pollution issues, ethical and safety 
      concerns, and the risk of knowledge plagiarism. In the process of promoting 
      school education reform, the application of ChatGPT brings both opportunities and 
      challenges. Moreover, ChatGPT's emergence offers teachers an opportunity to 
      reflect on their professional value and sets higher demands for them.
CI  - © 2024 The Author.
FAU - Yu, Hao
AU  - Yu H
AD  - Faculty of Education, Shaanxi Normal University, Xi'an, Shaanxi, China.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20240108
PL  - England
TA  - Heliyon
JT  - Heliyon
JID - 101672560
PMC - PMC10828640
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Educational transformation
OT  - Teacher education
OT  - Teacher literacy
COIS- The authors declare that they have no known competing financial interests or 
      personal relationships that could have appeared to influence the work reported in 
      this paper.
EDAT- 2024/02/01 06:43
MHDA- 2024/02/01 06:44
PMCR- 2024/01/08
CRDT- 2024/02/01 04:12
PHST- 2023/06/14 00:00 [received]
PHST- 2023/11/10 00:00 [revised]
PHST- 2024/01/05 00:00 [accepted]
PHST- 2024/02/01 06:44 [medline]
PHST- 2024/02/01 06:43 [pubmed]
PHST- 2024/02/01 04:12 [entrez]
PHST- 2024/01/08 00:00 [pmc-release]
AID - S2405-8440(24)00320-7 [pii]
AID - e24289 [pii]
AID - 10.1016/j.heliyon.2024.e24289 [doi]
PST - epublish
SO  - Heliyon. 2024 Jan 8;10(2):e24289. doi: 10.1016/j.heliyon.2024.e24289. eCollection 
      2024 Jan 30.

PMID- 37590034
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230904
IS  - 2369-3762 (Print)
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Aug 17
TI  - Using ChatGPT as a Learning Tool in Acupuncture Education: Comparative Study.
PG  - e47427
LID - 10.2196/47427 [doi]
LID - e47427
AB  - BACKGROUND: ChatGPT (Open AI) is a state-of-the-art artificial intelligence model 
      with potential applications in the medical fields of clinical practice, research, 
      and education. OBJECTIVE: This study aimed to evaluate the potential of ChatGPT 
      as an educational tool in college acupuncture programs, focusing on its ability 
      to support students in learning acupuncture point selection, treatment planning, 
      and decision-making. METHODS: We collected case studies published in Acupuncture 
      in Medicine between June 2022 and May 2023. Both ChatGPT-3.5 and ChatGPT-4 were 
      used to generate suggestions for acupuncture points based on case presentations. 
      A Wilcoxon signed-rank test was conducted to compare the number of acupuncture 
      points generated by ChatGPT-3.5 and ChatGPT-4, and the overlapping ratio of 
      acupuncture points was calculated. RESULTS: Among the 21 case studies, 14 studies 
      were included for analysis. ChatGPT-4 generated significantly more acupuncture 
      points (9.0, SD 1.1) compared to ChatGPT-3.5 (5.6, SD 0.6; P&lt;.001). The 
      overlapping ratios of acupuncture points for ChatGPT-3.5 (0.40, SD 0.28) and 
      ChatGPT-4 (0.34, SD 0.27; P=.67) were not significantly different. CONCLUSIONS: 
      ChatGPT may be a useful educational tool for acupuncture students, providing 
      valuable insights into personalized treatment plans. However, it cannot fully 
      replace traditional diagnostic methods, and further studies are needed to ensure 
      its safe and effective implementation in acupuncture education.
CI  - ©Hyeonhoon Lee. Originally published in JMIR Medical Education 
      (https://mededu.jmir.org), 17.08.2023.
FAU - Lee, Hyeonhoon
AU  - Lee H
AUID- ORCID: 0000-0002-9426-823X
AD  - Department of Anesthesiology and Pain Medicine, Seoul National University 
      Hospital, Seoul, Republic of Korea.
AD  - Biomedical Research Institute, Seoul National University Hospital, Seoul, 
      Republic of Korea.
LA  - eng
PT  - Journal Article
DEP - 20230817
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
PMC - PMC10472163
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - acupuncture
OT  - artificial intelligence
OT  - educational tool
OT  - personalized education
OT  - students
COIS- Conflicts of Interest: None declared.
EDAT- 2023/08/17 12:41
MHDA- 2023/08/17 12:42
PMCR- 2023/08/17
CRDT- 2023/08/17 11:53
PHST- 2023/03/20 00:00 [received]
PHST- 2023/07/25 00:00 [accepted]
PHST- 2023/06/10 00:00 [revised]
PHST- 2023/08/17 12:42 [medline]
PHST- 2023/08/17 12:41 [pubmed]
PHST- 2023/08/17 11:53 [entrez]
PHST- 2023/08/17 00:00 [pmc-release]
AID - v9i1e47427 [pii]
AID - 10.2196/47427 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Aug 17;9:e47427. doi: 10.2196/47427.

PMID- 37914380
OWN - NLM
STAT- MEDLINE
DCOM- 20231222
LR  - 20231222
IS  - 2352-0787 (Electronic)
IS  - 2352-0779 (Linking)
VI  - 11
IP  - 1
DP  - 2024 Jan
TI  - Comparison of ChatGPT and Traditional Patient Education Materials for Men's 
      Health.
PG  - 87-94
LID - 10.1097/UPJ.0000000000000490 [doi]
AB  - INTRODUCTION: ChatGPT is an artificial intelligence platform available to 
      patients seeking medical advice. Traditionally, urology patients consulted 
      official provider-created materials, particularly the Urology Care Foundation™ 
      (UCF). Today, men increasingly go online due to the rising costs of health care 
      and the stigma surrounding sexual health. Online health information is largely 
      inaccessible to laypersons as it exceeds the recommended American sixth to eighth 
      grade reading level. We conducted a comparative assessment of patient education 
      materials generated by ChatGPT vs UCF regarding men's health conditions. METHODS: 
      All 6 UCF men's health resources were identified. ChatGPT responses were 
      generated using patient questions obtained from UCF. Adjusted ChatGPT responses 
      were generated by prompting, "Explain it to me like I am in sixth grade." Textual 
      analysis was performed using sentence, word, syllable, and complex word count. 
      Six validated formulae were used for readability analysis. Two physicians 
      independently scored responses for accuracy, comprehensiveness, and 
      understandability. Statistical analysis involved Wilcoxon matched-pairs test. 
      RESULTS: ChatGPT responses were longer and more complex. Both UCF and ChatGPT 
      failed official readability standards, although ChatGPT performed significantly 
      worse across all 6 topics (all P &lt; .001). Conversely, adjusted ChatGPT 
      readability typically surpassed UCF, even meeting the recommended level for 2 
      topics. Qualitatively, UCF and ChatGPT had comparable accuracy, although ChatGPT 
      had better comprehensiveness and worse understandability. CONCLUSIONS: When 
      comparing readability, ChatGPT-generated education is less accessible than 
      provider-written content, although neither meets the recommended level. Our 
      analysis indicates that specific artificial intelligence prompts can simplify 
      educational materials to meet national standards and accommodate individual 
      literacy.
FAU - Shah, Yash B
AU  - Shah YB
AUID- ORCID: 0000-0003-1551-7611
AD  - Department of Urology, Sidney Kimmel Medical College, Thomas Jefferson 
      University, Philadelphia, Pennsylvania.
FAU - Ghosh, Anushka
AU  - Ghosh A
AD  - Department of Urology, Sidney Kimmel Medical College, Thomas Jefferson 
      University, Philadelphia, Pennsylvania.
FAU - Hochberg, Aaron R
AU  - Hochberg AR
AD  - Department of Urology, Sidney Kimmel Medical College, Thomas Jefferson 
      University, Philadelphia, Pennsylvania.
FAU - Rapoport, Eli
AU  - Rapoport E
AD  - Department of Urology, NYU Langone, New York, New York.
FAU - Lallas, Costas D
AU  - Lallas CD
AD  - Department of Urology, Sidney Kimmel Medical College, Thomas Jefferson 
      University, Philadelphia, Pennsylvania.
FAU - Shah, Mihir S
AU  - Shah MS
AD  - Department of Urology, Sidney Kimmel Medical College, Thomas Jefferson 
      University, Philadelphia, Pennsylvania.
FAU - Cohen, Seth D
AU  - Cohen SD
AD  - Department of Urology, NYU Langone, New York, New York.
LA  - eng
PT  - Journal Article
DEP - 20231101
PL  - United States
TA  - Urol Pract
JT  - Urology practice
JID - 101635343
SB  - IM
CIN - Urol Pract. 2024 Jan;11(1):94. PMID: 38051302
CIN - Urol Pract. 2024 Jan;11(1):94-95. PMID: 38051304
MH  - Male
MH  - Humans
MH  - United States
MH  - *Health Literacy
MH  - Artificial Intelligence
MH  - Men's Health
MH  - Patient Education as Topic
MH  - Educational Status
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - health literacy
OT  - men’s health
OT  - patient education
EDAT- 2023/11/02 00:42
MHDA- 2023/12/22 06:43
CRDT- 2023/11/01 21:13
PHST- 2023/12/22 06:43 [medline]
PHST- 2023/11/02 00:42 [pubmed]
PHST- 2023/11/01 21:13 [entrez]
AID - 10.1097/UPJ.0000000000000490 [doi]
PST - ppublish
SO  - Urol Pract. 2024 Jan;11(1):87-94. doi: 10.1097/UPJ.0000000000000490. Epub 2023 
      Nov 1.

PMID- 37490317
OWN - NLM
STAT- MEDLINE
DCOM- 20230731
LR  - 20230811
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 25
DP  - 2023 Jul 25
TI  - ChatGPT vs Google for Queries Related to Dementia and Other Cognitive Decline: 
      Comparison of Results.
PG  - e48966
LID - 10.2196/48966 [doi]
LID - e48966
AB  - BACKGROUND: People living with dementia or other cognitive decline and their 
      caregivers (PLWD) increasingly rely on the web to find information about their 
      condition and available resources and services. The recent advancements in large 
      language models (LLMs), such as ChatGPT, provide a new alternative to the more 
      traditional web search engines, such as Google. OBJECTIVE: This study compared 
      the quality of the results of ChatGPT and Google for a collection of PLWD-related 
      queries. METHODS: A set of 30 informational and 30 service delivery 
      (transactional) PLWD-related queries were selected and submitted to both Google 
      and ChatGPT. Three domain experts assessed the results for their currency of 
      information, reliability of the source, objectivity, relevance to the query, and 
      similarity of their response. The readability of the results was also analyzed. 
      Interrater reliability coefficients were calculated for all outcomes. RESULTS: 
      Google had superior currency and higher reliability. ChatGPT results were 
      evaluated as more objective. ChatGPT had a significantly higher response 
      relevance, while Google often drew upon sources that were referral services for 
      dementia care or service providers themselves. The readability was low for both 
      platforms, especially for ChatGPT (mean grade level 12.17, SD 1.94) compared to 
      Google (mean grade level 9.86, SD 3.47). The similarity between the content of 
      ChatGPT and Google responses was rated as high for 13 (21.7%) responses, medium 
      for 16 (26.7%) responses, and low for 31 (51.6%) responses. CONCLUSIONS: Both 
      Google and ChatGPT have strengths and weaknesses. ChatGPT rarely includes the 
      source of a result. Google more often provides a date for and a known reliable 
      source of the response compared to ChatGPT, whereas ChatGPT supplies more 
      relevant responses to queries. The results of ChatGPT may be out of date and 
      often do not specify a validity time stamp. Google sometimes returns results 
      based on commercial entities. The readability scores for both indicate that 
      responses are often not appropriate for persons with low health literacy skills. 
      In the future, the addition of both the source and the date of health-related 
      information and availability in other languages may increase the value of these 
      platforms for both nonmedical and medical professionals.
CI  - ©Vagelis Hristidis, Nicole Ruggiano, Ellen L Brown, Sai Rithesh Reddy Ganta, 
      Selena Stewart. Originally published in the Journal of Medical Internet Research 
      (https://www.jmir.org), 25.07.2023.
FAU - Hristidis, Vagelis
AU  - Hristidis V
AUID- ORCID: 0000-0001-8679-4988
AD  - Department of Computer Science and Engineering, University of California, 
      Riverside, Riverside, CA, United States.
FAU - Ruggiano, Nicole
AU  - Ruggiano N
AUID- ORCID: 0000-0002-2398-7077
AD  - School of Social Work, University of Alabama, Tuscaloosa, AL, United States.
FAU - Brown, Ellen L
AU  - Brown EL
AUID- ORCID: 0000-0002-2418-3257
AD  - Nicole Wertheim College of Nursing and Health Sciences, Florida International 
      University, Miami, FL, United States.
FAU - Ganta, Sai Rithesh Reddy
AU  - Ganta SRR
AUID- ORCID: 0009-0006-3445-7561
AD  - Department of Computer Science and Engineering, University of California, 
      Riverside, Riverside, CA, United States.
FAU - Stewart, Selena
AU  - Stewart S
AUID- ORCID: 0009-0009-0060-2865
AD  - School of Social Work, University of Alabama, Tuscaloosa, AL, United States.
LA  - eng
PT  - Comparative Study
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20230725
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - *Cognitive Dysfunction
MH  - *Dementia
MH  - Language
MH  - Reproducibility of Results
MH  - Search Engine
MH  - *Artificial Intelligence
MH  - Geriatrics
PMC - PMC10410383
OTO - NOTNLM
OT  - ChatGPT
OT  - Google
OT  - aging
OT  - chatbots
OT  - cognition
OT  - cognitive
OT  - dementia
OT  - geriatric
OT  - geriatrics
OT  - gerontology
OT  - information seeking
OT  - language model
OT  - large language models
OT  - queries
OT  - query
OT  - search
OT  - web search
COIS- Conflicts of Interest: VH is the founder of SmartBot360, which is a health care 
      chatbot company. SmartBot360 was not discussed in this paper.
EDAT- 2023/07/25 13:09
MHDA- 2023/07/26 06:42
PMCR- 2023/07/25
CRDT- 2023/07/25 11:52
PHST- 2023/05/15 00:00 [received]
PHST- 2023/07/10 00:00 [accepted]
PHST- 2023/06/09 00:00 [revised]
PHST- 2023/07/26 06:42 [medline]
PHST- 2023/07/25 13:09 [pubmed]
PHST- 2023/07/25 11:52 [entrez]
PHST- 2023/07/25 00:00 [pmc-release]
AID - v25i1e48966 [pii]
AID - 10.2196/48966 [doi]
PST - epublish
SO  - J Med Internet Res. 2023 Jul 25;25:e48966. doi: 10.2196/48966.

PMID- 37812998
OWN - NLM
STAT- MEDLINE
DCOM- 20231107
LR  - 20231107
IS  - 1876-2026 (Electronic)
IS  - 1876-2018 (Linking)
VI  - 89
DP  - 2023 Nov
TI  - Appraising the performance of ChatGPT in psychiatry using 100 clinical case 
      vignettes.
PG  - 103770
LID - S1876-2018(23)00326-X [pii]
LID - 10.1016/j.ajp.2023.103770 [doi]
AB  - BACKGROUND: ChatGPT has emerged as the most advanced and rapidly developing large 
      language chatbot system. With its immense potential ranging from answering a 
      simple query to cracking highly competitive medical exams, ChatGPT continues to 
      impress the scientists and researchers worldwide giving room for more discussions 
      regarding its utility in various fields. One such field of attention is 
      Psychiatry. With suboptimal diagnosis and treatment, assuring mental health and 
      well-being is a challenge in many countries, particularly developing nations. To 
      this regard, we conducted an evaluation to assess the performance of ChatGPT 3.5 
      in Psychiatry using clinical cases to provide evidence-based information 
      regarding the implication of ChatGPT 3.5 in enhancing mental health and 
      well-being. METHODS: ChatGPT 3.5 was used in this experimental study to initiate 
      the conversations and collect responses to clinical vignettes in Psychiatry. 
      Using 100 clinical case vignettes, the replies were assessed by expert faculties 
      from the Department of Psychiatry. There were 100 different psychiatric illnesses 
      represented in the cases. We recorded and assessed the initial ChatGPT 3.5 
      responses. The evaluation was conducted using the objective of questions that 
      were put forth at the conclusion of the case, and the aim of the questions was 
      divided into 10 categories. The grading was completed by taking the mean value of 
      the scores provided by the evaluators. Graphs and tables were used to represent 
      the grades. RESULTS: The evaluation report suggests that ChatGPT 3.5 fared 
      extremely well in Psychiatry by receiving "Grade A" ratings in 61 out of 100 
      cases, "Grade B" ratings in 31, and "Grade C" ratings in 8. Majority of the 
      queries were concerned with the management strategies, which were followed by 
      diagnosis, differential diagnosis, assessment, investigation, counselling, 
      clinical reasoning, ethical reasoning, prognosis, and request acceptance. ChatGPT 
      3.5 performed extremely well, especially in generating management strategies 
      followed by diagnoses for different psychiatric conditions. There were no 
      responses which were graded "D" indicating that there were no errors in the 
      diagnosis or response for clinical care. Only a few discrepancies and additional 
      details were missed in a few responses that received a "Grade C" CONCLUSION: It 
      is evident from our study that ChatGPT 3.5 has appreciable knowledge and 
      interpretation skills in Psychiatry. Thus, ChatGPT 3.5 undoubtedly has the 
      potential to transform the field of Medicine and we emphasize its utility in 
      Psychiatry through the finding of our study. However, for any AI model to be 
      successful, assuring the reliability, validation of information, proper 
      guidelines and implementation framework are necessary.
CI  - Copyright © 2023 Elsevier B.V. All rights reserved.
FAU - Franco D'Souza, Russell
AU  - Franco D'Souza R
AD  - Professor of Organizational Psychological Medicine, International Institute of 
      Organisational Psychological Medicine, 71 Cleeland Street, Dandenong Victoria, 
      Melbourne, 3175 Australia.
FAU - Amanullah, Shabbir
AU  - Amanullah S
AD  - Division of Geriatric Psychiatry, Queen's University, 752 King Street West, 
      Postal Bag 603 Kingston, ON K7L7X3.
FAU - Mathew, Mary
AU  - Mathew M
AD  - Department of Pathology, Kasturba Medical College, Manipal Academy of Higher 
      Education, Tiger Circle Road, Madhav Nagar, Manipal, Karnataka 576104.
FAU - Surapaneni, Krishna Mohan
AU  - Surapaneni KM
AD  - Department of Biochemistry, Panimalar Medical College Hospital &amp; Research 
      Institute, Varadharajapuram, Poonamallee, Chennai - 600 123, Tamil Nadu, India; 
      Departments of Medical Education, Molecular Virology, Research, Clinical Skills &amp; 
      Simulation, Panimalar Medical College Hospital &amp; Research Institute, 
      Varadharajapuram, Poonamallee, Chennai - 600 123, Tamil Nadu, India. Electronic 
      address: krishnamohan.surapaneni@gmail.com.
LA  - eng
PT  - Journal Article
DEP - 20230920
PL  - Netherlands
TA  - Asian J Psychiatr
JT  - Asian journal of psychiatry
JID - 101517820
SB  - IM
MH  - Humans
MH  - Reproducibility of Results
MH  - *Psychiatry
MH  - Diagnosis, Differential
MH  - *Mental Disorders/diagnosis/drug therapy
MH  - Communication
OTO - NOTNLM
OT  - “Artificial Intelligence”, “ChatGPT”
OT  - “Mental health”
OT  - “Mental well-being”
OT  - “Psychiatry”
COIS- Declaration of Competing Interest All the authors declare that, there is No 
      Conflict of Interest associated with this study.
EDAT- 2023/10/10 00:42
MHDA- 2023/11/07 06:46
CRDT- 2023/10/09 18:38
PHST- 2023/05/20 00:00 [received]
PHST- 2023/09/13 00:00 [revised]
PHST- 2023/09/18 00:00 [accepted]
PHST- 2023/11/07 06:46 [medline]
PHST- 2023/10/10 00:42 [pubmed]
PHST- 2023/10/09 18:38 [entrez]
AID - S1876-2018(23)00326-X [pii]
AID - 10.1016/j.ajp.2023.103770 [doi]
PST - ppublish
SO  - Asian J Psychiatr. 2023 Nov;89:103770. doi: 10.1016/j.ajp.2023.103770. Epub 2023 
      Sep 20.

PMID- 37789443
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231122
IS  - 2052-3211 (Print)
IS  - 2052-3211 (Electronic)
IS  - 2052-3211 (Linking)
VI  - 16
IP  - 1
DP  - 2023 Oct 3
TI  - ChatGPT in pharmacy practice: a cross-sectional exploration of Jordanian 
      pharmacists' perception, practice, and concerns.
PG  - 115
LID - 10.1186/s40545-023-00624-2 [doi]
LID - 115
AB  - OBJECTIVES: The purpose of this study is to find out how much pharmacists know 
      and have used ChatGPT in their practice. We investigated the advantages and 
      disadvantages of utilizing ChatGPT in a pharmacy context, the amount of training 
      necessary to use it proficiently, and the influence on patient care using a 
      survey. METHODS: This cross-sectional study was carried out between May and June 
      2023 to assess the potential and problems that pharmacists observed while 
      integrating chatbots powered by AI (ChatGPT) in pharmacy practice. The 
      correlation between perceived benefits and concerns was evaluated using 
      Spearman's rho correlation due to the data's non-normal distribution.Any 
      pharmacists licensed by the Jordanian&nbsp;Pharmacists Association were included in 
      the study. A convenient&nbsp;sampling technique was used to choose the participants, 
      and the study questionnaire was distributed utilizing an online medium (Facebook 
      and WhatsApp). Anyone who expressed interest in taking part was given a link to 
      the study's instructions so they may read them before giving their electronic 
      consent and accessing the survey. RESULTS: The potential advantages of ChatGPT in 
      the pharmacy practice were widely acknowledged by the participants. The majority 
      of participants (69.9%) concurred that educational material about pharmacy items 
      or therapeutic areas can be provided using ChatGPT, with 66.9% of respondents 
      believing that ChatGPT is a machine learning algorithm. Concerns about the 
      accuracy of AI-generated responses were also prevalent. More than half of the 
      participants (55.7%) raised the possibility that AI systems such as ChatGPT could 
      pick up on and replicate prejudices and discriminatory patterns from the data 
      they were trained on. Analysis shows a statistically significant positive link, 
      albeit a minor one, between the perceived advantages of ChatGPT and its drawbacks 
      (r = 0.255, p &lt; 0.001). However, concerns were strongly correlated with knowledge 
      of ChatGPT. In contrast to those who were either unsure or had not heard of 
      ChatGPT (64.2%), individuals who had heard of it were more likely to have strong 
      concerns (79.8%) (p = 0.002). Finally, the results show a statistically 
      significant association between the frequency of ChatGPT use and positive 
      perceptions of the tool (p &lt; 0.001). CONCLUSIONS: Although ChatGPT has shown 
      promise in health and pharmaceutical practice, its application should be 
      rigorously regulated by evidence-based law. According to the study's findings, 
      pharmacists support the use of ChatGPT in pharmacy practice but have concerns 
      about its use due to ethical reasons, legal problems, privacy concerns, worries 
      about the accuracy of the data generated, data learning, and bias risk.
CI  - © 2023. Dr. Zaheer-Ud-Din Babar and Auckland UniServices Ltd.
FAU - Abu Hammour, Khawla
AU  - Abu Hammour K
AD  - Department of Clinical Pharmacy and Biopharmaceutics, Faculty of Pharmacy, 
      University of Jordan, Amman, Jordan.
FAU - Alhamad, Hamza
AU  - Alhamad H
AD  - Department of Clinical Pharmacy, Faculty of Pharmacy, Zarqa University, Zarqa, 
      Jordan.
FAU - Al-Ashwal, Fahmi Y
AU  - Al-Ashwal FY
AUID- ORCID: 0000-0003-2076-0771
AD  - Department of Clinical Pharmacy, College of Pharmacy, Al-Ayen University, 
      Thi-Qar, Iraq. fahmialashwal89@gmail.com.
AD  - Department of Clinical Pharmacy and Pharmacy Practice, Faculty of Pharmacy, 
      University of Science and Technology, Sana'a, Yemen. fahmialashwal89@gmail.com.
FAU - Halboup, Abdulsalam
AU  - Halboup A
AD  - Department of Clinical Pharmacy and Pharmacy Practice, Faculty of Pharmacy, 
      University of Science and Technology, Sana'a, Yemen.
AD  - Discipline of Clinical Pharmacy, School of Pharmaceutical Sciences, University 
      Sains Malaysia, Gelugor, Pulau Pinang, Malaysia.
FAU - Abu Farha, Rana
AU  - Abu Farha R
AD  - Clinical Pharmacy and Therapeutics Department, Faculty of Pharmacy, Applied 
      Science Private University, P.O. Box 11937, Amman, Jordan.
FAU - Abu Hammour, Adnan
AU  - Abu Hammour A
AD  - Medrise Medical Center, Dubai Healthcare City, Dubai, United Arab Emirates.
LA  - eng
PT  - Journal Article
DEP - 20231003
PL  - England
TA  - J Pharm Policy Pract
JT  - Journal of pharmaceutical policy and practice
JID - 101627192
EIN - J Pharm Policy Pract. 2023 Oct 30;16(1):129. PMID: 37904185
PMC - PMC10548710
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Pharmacy practice
COIS- The Authors declare that there is no conflict of interest.
EDAT- 2023/10/04 00:42
MHDA- 2023/10/04 00:43
PMCR- 2023/10/03
CRDT- 2023/10/03 23:55
PHST- 2023/07/13 00:00 [received]
PHST- 2023/09/22 00:00 [accepted]
PHST- 2023/10/04 00:43 [medline]
PHST- 2023/10/04 00:42 [pubmed]
PHST- 2023/10/03 23:55 [entrez]
PHST- 2023/10/03 00:00 [pmc-release]
AID - 10.1186/s40545-023-00624-2 [pii]
AID - 624 [pii]
AID - 10.1186/s40545-023-00624-2 [doi]
PST - epublish
SO  - J Pharm Policy Pract. 2023 Oct 3;16(1):115. doi: 10.1186/s40545-023-00624-2.

PMID- 37991498
OWN - NLM
STAT- MEDLINE
DCOM- 20240318
LR  - 20240402
IS  - 1434-4726 (Electronic)
IS  - 0937-4477 (Linking)
VI  - 281
IP  - 4
DP  - 2024 Apr
TI  - Accuracy of ChatGPT in head and neck oncological board decisions: preliminary 
      findings.
PG  - 2105-2114
LID - 10.1007/s00405-023-08326-w [doi]
AB  - OBJECTIVES: To evaluate the ChatGPT-4 performance in oncological board decisions. 
      METHODS: Twenty medical records of patients with head and neck cancer were 
      evaluated by ChatGPT-4 for additional examinations, management, and therapeutic 
      approaches. The ChatGPT-4 propositions were assessed with the Artificial 
      Intelligence Performance Instrument. The stability of ChatGPT-4 was evaluated 
      through regenerated answers at 1-day interval. RESULTS: ChatGPT-4 provided 
      adequate explanations for cTNM staging in 19 cases (95%). ChatGPT-4 proposed a 
      significant higher number of additional examinations than practitioners (72 
      versus 103; p = 0.001). ChatGPT-4 indications of endoscopy-biopsy, HPV research, 
      ultrasonography, and PET-CT were consistent with the oncological board decisions. 
      The therapeutic propositions of ChatGPT-4 were accurate in 13 cases (65%). Most 
      additional examination and primary treatment propositions were consistent 
      throughout regenerated response process. CONCLUSIONS: ChatGPT-4 may be an 
      adjunctive theoretical tool in oncological board simple decisions.
CI  - © 2023. The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, 
      part of Springer Nature.
FAU - Lechien, Jerome R
AU  - Lechien JR
AUID- ORCID: 0000-0002-0845-0845
AD  - Research Committee of Young-Otolaryngologists of the International Federations of 
      Oto-Rhino-Laryngological Societies (YO-IFOS), Paris, France. 
      Jerome.Lechien@umons.ac.be.
AD  - Department of Otolaryngology-Head Neck Surgery, Foch Hospital, UFR Simone Veil, 
      University Paris Saclay, Paris, France. Jerome.Lechien@umons.ac.be.
AD  - Phonetics and Phonology Laboratory (UMR 7018 CNRS, Université Sorbonne 
      Nouvelle/Paris 3), Paris, France. Jerome.Lechien@umons.ac.be.
AD  - Department of Otorhinolaryngology and Head and Neck Surgery, CHU Saint-Pierre, 
      Brussels, Belgium. Jerome.Lechien@umons.ac.be.
AD  - Division of Laryngology and Broncho-Esophagology, Department of 
      Otolaryngology-Head and Neck Surgery, EpiCURA Hospital, Baudour, Belgium. 
      Jerome.Lechien@umons.ac.be.
FAU - Chiesa-Estomba, Carlos-Miguel
AU  - Chiesa-Estomba CM
AD  - Research Committee of Young-Otolaryngologists of the International Federations of 
      Oto-Rhino-Laryngological Societies (YO-IFOS), Paris, France.
AD  - Department of Otorhinolaryngology-Head and Neck Surgery, Hospital Universitario 
      Donostia, San Sebastian, Spain.
FAU - Baudouin, Robin
AU  - Baudouin R
AD  - Research Committee of Young-Otolaryngologists of the International Federations of 
      Oto-Rhino-Laryngological Societies (YO-IFOS), Paris, France.
AD  - Department of Otolaryngology-Head Neck Surgery, Foch Hospital, UFR Simone Veil, 
      University Paris Saclay, Paris, France.
AD  - Phonetics and Phonology Laboratory (UMR 7018 CNRS, Université Sorbonne 
      Nouvelle/Paris 3), Paris, France.
FAU - Hans, Stéphane
AU  - Hans S
AD  - Research Committee of Young-Otolaryngologists of the International Federations of 
      Oto-Rhino-Laryngological Societies (YO-IFOS), Paris, France.
AD  - Department of Otolaryngology-Head Neck Surgery, Foch Hospital, UFR Simone Veil, 
      University Paris Saclay, Paris, France.
AD  - Phonetics and Phonology Laboratory (UMR 7018 CNRS, Université Sorbonne 
      Nouvelle/Paris 3), Paris, France.
LA  - eng
PT  - Journal Article
DEP - 20231122
PL  - Germany
TA  - Eur Arch Otorhinolaryngol
JT  - European archives of oto-rhino-laryngology : official journal of the European 
      Federation of Oto-Rhino-Laryngological Societies (EUFOS) : affiliated with the 
      German Society for Oto-Rhino-Laryngology - Head and Neck Surgery
JID - 9002937
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Positron Emission Tomography Computed Tomography
MH  - Head
MH  - Neck
MH  - Biopsy
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Decision
OT  - GPT
OT  - Head neck surgery
OT  - Otolaryngology
OT  - Performance
EDAT- 2023/11/22 12:43
MHDA- 2024/03/18 06:42
CRDT- 2023/11/22 11:03
PHST- 2023/10/05 00:00 [received]
PHST- 2023/10/27 00:00 [accepted]
PHST- 2024/03/18 06:42 [medline]
PHST- 2023/11/22 12:43 [pubmed]
PHST- 2023/11/22 11:03 [entrez]
AID - 10.1007/s00405-023-08326-w [pii]
AID - 10.1007/s00405-023-08326-w [doi]
PST - ppublish
SO  - Eur Arch Otorhinolaryngol. 2024 Apr;281(4):2105-2114. doi: 
      10.1007/s00405-023-08326-w. Epub 2023 Nov 22.

PMID- 37460216
OWN - NLM
STAT- Publisher
LR  - 20240118
IS  - 1468-3318 (Electronic)
IS  - 0964-4563 (Print)
IS  - 0964-4563 (Linking)
DP  - 2023 Jul 17
TI  - Exploring the ChatGPT platform with scenario-specific prompts for vaping 
      cessation.
LID - tc-2023-058009 [pii]
LID - 10.1136/tc-2023-058009 [doi]
AB  - OBJECTIVE: To evaluate and start a discussion on the potential usefulness of 
      applying Artificial Intelligence (AI)-driven natural language processing 
      technology such as the ChatGPT in tobacco control efforts, specifically vaping 
      cessation. METHOD: Ten real-world questions about vaping cessation were selected 
      from a Reddit forum and used as ChatGPT prompts or queries. Content analysis was 
      performed on the ChatGPT responses to identify the thematic aspects of vaping 
      cessation support represented in the responses. Next, the responses were 
      empirically evaluated by five experts in tobacco control on accuracy, quality, 
      clarity, and empathy. RESULT: The following themes related to vaping cessation 
      support were identified: understanding nicotine withdrawal symptoms, 
      self-regulation, peer support, motivational support, and Nicotine Replacement 
      Therapy (NRT). The experts judged the ChatGPT responses to be 'satisfactory' to 
      'excellent' in areas of accuracy, quality, clarity, and empathy. CONCLUSION: If 
      managed by a group of experts, including clinicians, and behavioral and computer 
      scientists, a platform such as the ChatGPT may be leveraged to design tailored 
      interventions for tobacco use cessation, including vaping cessation.
CI  - © Author(s) (or their employer(s)) 2023. No commercial re-use. See rights and 
      permissions. Published by BMJ.
FAU - Amin, Samia
AU  - Amin S
AUID- ORCID: 0000-0001-9526-1606
AD  - Population Sciences in the Pacific Program, University of Hawai'i Cancer Center, 
      Honolulu, Hawaii, USA samin@cc.hawaii.edu.
FAU - Kawamoto, Crissy Terawaki
AU  - Kawamoto CT
AUID- ORCID: 0000-0003-0335-6275
AD  - Population Sciences in the Pacific Program, University of Hawai'i Cancer Center, 
      Honolulu, Hawaii, USA.
FAU - Pokhrel, Pallav
AU  - Pokhrel P
AUID- ORCID: 0000-0002-7906-0799
AD  - Population Sciences in the Pacific Program, University of Hawai'i Cancer Center, 
      Honolulu, Hawaii, USA.
LA  - eng
GR  - R01 CA228905/CA/NCI NIH HHS/United States
PT  - Journal Article
DEP - 20230717
PL  - England
TA  - Tob Control
JT  - Tobacco control
JID - 9209612
SB  - IM
PMC - PMC10792116
MID - NIHMS1925759
OTO - NOTNLM
OT  - Cessation
OT  - ChatGPT
OT  - E-Cigarettes
OT  - Quit
OT  - Vaping
COIS- Competing interests: None declared.
EDAT- 2023/07/18 01:09
MHDA- 2023/07/18 01:09
PMCR- 2025/01/17
CRDT- 2023/07/17 21:13
PHST- 2023/02/16 00:00 [received]
PHST- 2023/06/28 00:00 [accepted]
PHST- 2025/01/17 00:00 [pmc-release]
PHST- 2023/07/18 01:09 [pubmed]
PHST- 2023/07/18 01:09 [medline]
PHST- 2023/07/17 21:13 [entrez]
AID - tc-2023-058009 [pii]
AID - 10.1136/tc-2023-058009 [doi]
PST - aheadofprint
SO  - Tob Control. 2023 Jul 17:tc-2023-058009. doi: 10.1136/tc-2023-058009.

PMID- 37668790
OWN - NLM
STAT- MEDLINE
DCOM- 20231117
LR  - 20240223
IS  - 1432-0711 (Electronic)
IS  - 0932-0067 (Linking)
VI  - 308
IP  - 6
DP  - 2023 Dec
TI  - Performance of ChatGPT in Israeli Hebrew OBGYN national residency examinations.
PG  - 1797-1802
LID - 10.1007/s00404-023-07185-4 [doi]
AB  - PURPOSE: Previous studies of ChatGPT performance in the field of medical 
      examinations have reached contradictory results. Moreover, the performance of 
      ChatGPT in other languages other than English is yet to be explored. We aim to 
      study the performance of ChatGPT in Hebrew OBGYN-'Shlav-Alef' (Phase 1) 
      examination. METHODS: A performance study was conducted using a consecutive 
      sample of text-based multiple choice questions, originated from authentic Hebrew 
      OBGYN-'Shlav-Alef' examinations in 2021-2022. We constructed 150 multiple choice 
      questions from consecutive text-based-only original questions. We compared the 
      performance of ChatGPT performance to the real-life actual performance of OBGYN 
      residents who completed the tests in 2021-2022. We also compared ChatGTP Hebrew 
      performance vs. previously published English medical tests. RESULTS: In 
      2021-2022, 27.8% of OBGYN residents failed the 'Shlav-Alef' examination and the 
      mean score of the residents was 68.4. Overall, 150 authentic questions were 
      evaluated (one examination). ChatGPT correctly answered 58 questions (38.7%) and 
      reached a failed score. The performance of Hebrew ChatGPT was lower when compared 
      to actual performance of residents: 38.7% vs. 68.4%, p &lt; .001. In a comparison to 
      ChatGPT performance in 9,091 English language questions in the field of medicine, 
      the performance of Hebrew ChatGPT was lower (38.7% in Hebrew vs. 60.7% in 
      English, p &lt; .001). CONCLUSIONS: ChatGPT answered correctly on less than 40% of 
      Hebrew OBGYN resident examination questions. Residents cannot rely on ChatGPT for 
      the preparation of this examination. Efforts should be made to improve ChatGPT 
      performance in other languages besides English.
CI  - © 2023. The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, 
      part of Springer Nature.
FAU - Cohen, Adiel
AU  - Cohen A
AUID- ORCID: 0000-0002-6218-1156
AD  - Department of Obstetrics and Gynecology, Hadassah Medical Organization and 
      Faculty of Medicine, Hebrew University of Jerusalem, Ein Kerem, P.O.B. 12000, 
      91120, Jerusalem, Israel. adielic@gmail.com.
FAU - Alter, Roie
AU  - Alter R
AD  - Department of Obstetrics and Gynecology, Hadassah Medical Organization and 
      Faculty of Medicine, Hebrew University of Jerusalem, Ein Kerem, P.O.B. 12000, 
      91120, Jerusalem, Israel.
FAU - Lessans, Naama
AU  - Lessans N
AD  - Department of Obstetrics and Gynecology, Hadassah Medical Organization and 
      Faculty of Medicine, Hebrew University of Jerusalem, Ein Kerem, P.O.B. 12000, 
      91120, Jerusalem, Israel.
FAU - Meyer, Raanan
AU  - Meyer R
AD  - Department of Obstetrics and Gynecology, Chaim Sheba Medical Center, Ramat-Gan, 
      Israel.
AD  - Faculty of Medicine, Tel-Aviv University, Tel-Aviv, Israel.
AD  - Cedar-Sinai Medical Center, Los Angeles, USA.
FAU - Brezinov, Yoav
AU  - Brezinov Y
AD  - Lady Davis Institute for Cancer Research, Jewish General Hospital, McGill 
      University, Montreal, Canada.
FAU - Levin, Gabriel
AU  - Levin G
AD  - Lady Davis Institute for Cancer Research, Jewish General Hospital, McGill 
      University, Montreal, Canada.
AD  - The Department of Gynecoloic Oncology, Hadassah Medical Center, Faculty of 
      Medicine, Hebrew University of Jerusalem, Jerusalem, Israel.
LA  - eng
PT  - Journal Article
DEP - 20230905
PL  - Germany
TA  - Arch Gynecol Obstet
JT  - Archives of gynecology and obstetrics
JID - 8710213
SB  - IM
MH  - Humans
MH  - *Internship and Residency
MH  - Israel
MH  - Language
MH  - Physical Examination
MH  - Artificial Intelligence
OTO - NOTNLM
OT  - ChatGPT
OT  - Hebrew
OT  - OBGYN
OT  - Performance
OT  - Test
EDAT- 2023/09/05 12:42
MHDA- 2023/11/17 15:29
CRDT- 2023/09/05 11:14
PHST- 2023/06/11 00:00 [received]
PHST- 2023/08/02 00:00 [accepted]
PHST- 2023/11/17 15:29 [medline]
PHST- 2023/09/05 12:42 [pubmed]
PHST- 2023/09/05 11:14 [entrez]
AID - 10.1007/s00404-023-07185-4 [pii]
AID - 10.1007/s00404-023-07185-4 [doi]
PST - ppublish
SO  - Arch Gynecol Obstet. 2023 Dec;308(6):1797-1802. doi: 10.1007/s00404-023-07185-4. 
      Epub 2023 Sep 5.

PMID- 37499880
OWN - NLM
STAT- Publisher
LR  - 20231022
IS  - 1878-1632 (Electronic)
IS  - 1529-9430 (Linking)
VI  - 23
IP  - 11
DP  - 2023 Nov
TI  - Thromboembolic prophylaxis in spine surgery: an analysis of ChatGPT 
      recommendations.
PG  - 1684-1691
LID - S1529-9430(23)03285-0 [pii]
LID - 10.1016/j.spinee.2023.07.015 [doi]
AB  - BACKGROUND CONTEXT: Venous thromboembolism is a negative outcome of elective 
      spine surgery. However, the use of thromboembolic chemoprophylaxis in this 
      patient population is controversial due to the possible increased risk of 
      epidural hematoma. ChatGPT is an artificial intelligence model which may be able 
      to generate recommendations for thromboembolic prophylaxis in spine surgery. 
      PURPOSE: To evaluate the accuracy of ChatGPT recommendations for thromboembolic 
      prophylaxis in spine surgery. STUDY DESIGN/SETTING: Comparative analysis. PATIENT 
      SAMPLE: None. OUTCOME MEASURES: Accuracy, over-conclusiveness, supplemental, and 
      incompleteness of ChatGPT responses compared to the North American Spine Society 
      (NASS) clinical guidelines. METHODS: ChatGPT was prompted with questions from the 
      2009 NASS clinical guidelines for antithrombotic therapies and evaluated for 
      concordance with the clinical guidelines. ChatGPT-3.5 responses were obtained on 
      March 5, 2023, and ChatGPT-4.0 responses were obtained on April 7, 2023. A 
      ChatGPT response was classified as accurate if it did not contradict the clinical 
      guideline. Three additional categories were created to further evaluate the 
      ChatGPT responses in comparison to the NASS guidelines: over-conclusiveness, 
      supplementary, and incompleteness. ChatGPT was classified as over-conclusive if 
      it made a recommendation where the NASS guideline did not provide one. ChatGPT 
      was classified as supplementary if it included additional relevant information 
      not specified by the NASS guideline. ChatGPT was classified as incomplete if it 
      failed to provide relevant information included in the NASS guideline. RESULTS: 
      Twelve clinical guidelines were evaluated in total. Compared to the NASS clinical 
      guidelines, ChatGPT-3.5 was accurate in 4 (33%) of its responses while 
      ChatGPT-4.0 was accurate in 11 (92%) responses. ChatGPT-3.5 was over-conclusive 
      in 6 (50%) of its responses while ChatGPT-4.0 was over-conclusive in 1 (8%) 
      response. ChatGPT-3.5 provided supplemental information in 8 (67%) of its 
      responses, and ChatGPT-4.0 provided supplemental information in 11 (92%) 
      responses. Four (33%) responses from ChatGPT-3.5 were incomplete, and 4 (33%) 
      responses from ChatGPT-4.0 were incomplete. CONCLUSIONS: ChatGPT was able to 
      provide recommendations for thromboembolic prophylaxis with reasonable accuracy. 
      ChatGPT-3.5 tended to cite nonexistent sources and was more likely to give 
      specific recommendations while ChatGPT-4.0 was more conservative in its answers. 
      As ChatGPT is continuously updated, further validation is needed before it can be 
      used as a guideline for clinical practice.
CI  - Copyright © 2023 Elsevier Inc. All rights reserved.
FAU - Duey, Akiro H
AU  - Duey AH
AD  - Department of Orthopedics, Icahn School of Medicine, New York, NY.
FAU - Nietsch, Katrina S
AU  - Nietsch KS
AD  - Department of Orthopedics, Icahn School of Medicine, New York, NY.
FAU - Zaidat, Bashar
AU  - Zaidat B
AD  - Department of Orthopedics, Icahn School of Medicine, New York, NY.
FAU - Ren, Renee
AU  - Ren R
AD  - Department of Orthopedics, Icahn School of Medicine, New York, NY.
FAU - Ndjonko, Laura C Mazudie
AU  - Ndjonko LCM
AD  - Department of Orthopedics, Icahn School of Medicine, New York, NY.
FAU - Shrestha, Nancy
AU  - Shrestha N
AD  - Department of Orthopedics, Icahn School of Medicine, New York, NY.
FAU - Rajjoub, Rami
AU  - Rajjoub R
AD  - Department of Orthopedics, Icahn School of Medicine, New York, NY.
FAU - Ahmed, Wasil
AU  - Ahmed W
AD  - Department of Orthopedics, Icahn School of Medicine, New York, NY.
FAU - Hoang, Timothy
AU  - Hoang T
AD  - Department of Orthopedics, Icahn School of Medicine, New York, NY.
FAU - Saturno, Michael P
AU  - Saturno MP
AD  - Department of Orthopedics, Icahn School of Medicine, New York, NY.
FAU - Tang, Justin E
AU  - Tang JE
AD  - Department of Orthopedics, Icahn School of Medicine, New York, NY.
FAU - Gallate, Zachary S
AU  - Gallate ZS
AD  - Department of Orthopedics, Icahn School of Medicine, New York, NY.
FAU - Kim, Jun S
AU  - Kim JS
AD  - Department of Orthopedics, Icahn School of Medicine, New York, NY.
FAU - Cho, Samuel K
AU  - Cho SK
AD  - Department of Orthopedics, Icahn School of Medicine, New York, NY. Electronic 
      address: samuel.cho@mountsinai.org.
LA  - eng
PT  - Journal Article
DEP - 20230725
PL  - United States
TA  - Spine J
JT  - The spine journal : official journal of the North American Spine Society
JID - 101130732
SB  - IM
OTO - NOTNLM
OT  - Antithrombotic therapy
OT  - ChatGPT
OT  - Chemoprophylaxis
OT  - Deep vein thrombosis
OT  - Pulmonary embolism
OT  - Subdural hematoma
OT  - Thromboembolic prophylaxis
OT  - Thromboprophylaxis
OT  - Venous thromboembolism
COIS- Declarations of competing interests One or more of the authors declare financial 
      or professional relationships on ICMJE-TSJ disclosure forms.
EDAT- 2023/07/28 01:08
MHDA- 2023/07/28 01:08
CRDT- 2023/07/27 19:16
PHST- 2023/05/23 00:00 [received]
PHST- 2023/07/10 00:00 [revised]
PHST- 2023/07/18 00:00 [accepted]
PHST- 2023/07/28 01:08 [pubmed]
PHST- 2023/07/28 01:08 [medline]
PHST- 2023/07/27 19:16 [entrez]
AID - S1529-9430(23)03285-0 [pii]
AID - 10.1016/j.spinee.2023.07.015 [doi]
PST - ppublish
SO  - Spine J. 2023 Nov;23(11):1684-1691. doi: 10.1016/j.spinee.2023.07.015. Epub 2023 
      Jul 25.

PMID- 37465809
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230720
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 6
DP  - 2023 Jun
TI  - When Precision Meets Penmanship: ChatGPT and Surgery Documentation.
PG  - e40546
LID - 10.7759/cureus.40546 [doi]
LID - e40546
AB  - ChatGPT (Chatbot Generative Pre-Trained Transformer) is an artificial 
      intelligence with several potential applications in the field of medicine. As a 
      large language model, it is particularly good at generating text. This study 
      investigates the use of ChatGPT in constructing operation notes for laparoscopic 
      appendicectomy, one of the most common surgical procedures in the UK. We prompted 
      ChatGPT-4, the latest generation of ChatGPT, to produce operation notes for 
      laparoscopic appendicectomy, which were then evaluated against 'Getting It Right 
      First Time' (GIRFT) recommendations. GIRFT is an organisation that has 
      collaborated with the National Health Service (NHS) to improve surgical 
      documentation guidelines. Excluding certain items documented elsewhere in patient 
      records, the generated notes were assessed against 30 key points in GIRFT 
      recommendations. This process was repeated three times to obtain an average 
      score. Our results showed that ChatGPT generated operation notes in seconds, with 
      an average coverage of 78.8% (23.66 out of 30 points) of the GIRFT guidelines, 
      surpassing average compliance with similar guidelines from the Royal College of 
      Surgeons (RCS). However, the quality of ChatGPT's output was found to be 
      dependent on the quality of the prompt, highlighting the need for verification of 
      the generated content. Additionally, secure integration with electronic health 
      records is required before ChatGPT can be adopted into the NHS.
CI  - Copyright © 2023, Robinson et al.
FAU - Robinson, Alexander
AU  - Robinson A
AD  - General Surgery, Mid and South Essex NHS (National Health Service) Foundation 
      Trust, Chelmsford, GBR.
FAU - Aggarwal, Shaurya Jr
AU  - Aggarwal S Jr
AD  - General Surgery, Mid and South Essex NHS (National Health Service) Foundation 
      Trust, Chelmsford, GBR.
LA  - eng
PT  - Journal Article
DEP - 20230617
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10350653
OTO - NOTNLM
OT  - appendicectomy
OT  - chatgpt
OT  - laparoscopic surgery
OT  - nhs
OT  - surgical documentation
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/07/19 06:42
MHDA- 2023/07/19 06:43
PMCR- 2023/06/17
CRDT- 2023/07/19 04:07
PHST- 2023/06/16 00:00 [accepted]
PHST- 2023/07/19 06:43 [medline]
PHST- 2023/07/19 06:42 [pubmed]
PHST- 2023/07/19 04:07 [entrez]
PHST- 2023/06/17 00:00 [pmc-release]
AID - 10.7759/cureus.40546 [doi]
PST - epublish
SO  - Cureus. 2023 Jun 17;15(6):e40546. doi: 10.7759/cureus.40546. eCollection 2023 
      Jun.

PMID- 37103928
OWN - NLM
STAT- MEDLINE
DCOM- 20230619
LR  - 20231206
IS  - 2168-6173 (Electronic)
IS  - 2168-6165 (Print)
IS  - 2168-6165 (Linking)
VI  - 141
IP  - 6
DP  - 2023 Jun 1
TI  - Performance of an Artificial Intelligence Chatbot in Ophthalmic Knowledge 
      Assessment.
PG  - 589-597
LID - 10.1001/jamaophthalmol.2023.1144 [doi]
AB  - IMPORTANCE: ChatGPT is an artificial intelligence (AI) chatbot that has 
      significant societal implications. Training curricula using AI are being 
      developed in medicine, and the performance of chatbots in ophthalmology has not 
      been characterized. OBJECTIVE: To assess the performance of ChatGPT in answering 
      practice questions for board certification in ophthalmology. DESIGN, SETTING, AND 
      PARTICIPANTS: This cross-sectional study used a consecutive sample of text-based 
      multiple-choice questions provided by the OphthoQuestions practice question bank 
      for board certification examination preparation. Of 166 available multiple-choice 
      questions, 125 (75%) were text-based. EXPOSURES: ChatGPT answered questions from 
      January 9 to 16, 2023, and on February 17, 2023. MAIN OUTCOMES AND MEASURES: Our 
      primary outcome was the number of board certification examination practice 
      questions that ChatGPT answered correctly. Our secondary outcomes were the 
      proportion of questions for which ChatGPT provided additional explanations, the 
      mean length of questions and responses provided by ChatGPT, the performance of 
      ChatGPT in answering questions without multiple-choice options, and changes in 
      performance over time. RESULTS: In January 2023, ChatGPT correctly answered 58 of 
      125 questions (46%). ChatGPT's performance was the best in the category general 
      medicine (11/14; 79%) and poorest in retina and vitreous (0%). The proportion of 
      questions for which ChatGPT provided additional explanations was similar between 
      questions answered correctly and incorrectly (difference, 5.82%; 95% CI, -11.0% 
      to 22.0%; χ21 = 0.45; P = .51). The mean length of questions was similar between 
      questions answered correctly and incorrectly (difference, 21.4 characters; SE, 
      36.8; 95% CI, -51.4 to 94.3; t = 0.58; df = 123; P = .22). The mean length of 
      responses was similar between questions answered correctly and incorrectly 
      (difference, -80.0 characters; SE, 65.4; 95% CI, -209.5 to 49.5; t = -1.22; 
      df = 123; P = .22). ChatGPT selected the same multiple-choice response as the 
      most common answer provided by ophthalmology trainees on OphthoQuestions 44% of 
      the time. In February 2023, ChatGPT provided a correct response to 73 of 125 
      multiple-choice questions (58%) and 42 of 78 stand-alone questions (54%) without 
      multiple-choice options. CONCLUSIONS AND RELEVANCE: ChatGPT answered 
      approximately half of questions correctly in the OphthoQuestions free trial for 
      ophthalmic board certification preparation. Medical professionals and trainees 
      should appreciate the advances of AI in medicine while acknowledging that ChatGPT 
      as used in this investigation did not answer sufficient multiple-choice questions 
      correctly for it to provide substantial assistance in preparing for board 
      certification at this time.
FAU - Mihalache, Andrew
AU  - Mihalache A
AD  - Schulich School of Medicine and Dentistry, University of Western Ontario, London, 
      Ontario, Canada.
FAU - Popovic, Marko M
AU  - Popovic MM
AD  - Department of Ophthalmology and Vision Sciences, University of Toronto, Toronto, 
      Ontario, Canada.
FAU - Muni, Rajeev H
AU  - Muni RH
AD  - Department of Ophthalmology and Vision Sciences, University of Toronto, Toronto, 
      Ontario, Canada.
AD  - Department of Ophthalmology, St Michael's Hospital/Unity Health Toronto, Toronto, 
      Ontario, Canada.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - JAMA Ophthalmol
JT  - JAMA ophthalmology
JID - 101589539
SB  - IM
CIN - JAMA Ophthalmol. 2023 Jun 1;141(6):514-515. PMID: 37103930
MH  - Humans
MH  - *Artificial Intelligence
MH  - Cross-Sectional Studies
MH  - Retina
MH  - Curriculum
MH  - *Ophthalmology
PMC - PMC10141269
COIS- Conflict of Interest Disclosures: Dr Popovic reported grants (to his institution) 
      from PSI Foundation and Fighting Blindness Canada outside the submitted work. Dr 
      Muni reported serving on the advisory board for Alcon, Bausch and Lomb, Bayer, 
      Novartis, Allergan, and Roche and receiving financial support (to his 
      institution) from Bayer, Novartis, and Roche outside the submitted work. No other 
      disclosures were reported.
EDAT- 2023/04/27 12:41
MHDA- 2023/06/19 13:08
PMCR- 2024/04/27
CRDT- 2023/04/27 11:33
PHST- 2024/04/27 00:00 [pmc-release]
PHST- 2023/06/19 13:08 [medline]
PHST- 2023/04/27 12:41 [pubmed]
PHST- 2023/04/27 11:33 [entrez]
AID - 2804364 [pii]
AID - ebr230002 [pii]
AID - 10.1001/jamaophthalmol.2023.1144 [doi]
PST - ppublish
SO  - JAMA Ophthalmol. 2023 Jun 1;141(6):589-597. doi: 
      10.1001/jamaophthalmol.2023.1144.

PMID- 37936648
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231109
IS  - 2632-6140 (Electronic)
IS  - 2632-6140 (Linking)
VI  - 5
IP  - 2
DP  - 2023
TI  - Assessment of ChatGPT's performance on neurology written board examination 
      questions.
PG  - e000530
LID - 10.1136/bmjno-2023-000530 [doi]
LID - e000530
AB  - BACKGROUND AND OBJECTIVES: ChatGPT has shown promise in healthcare. To assess the 
      utility of this novel tool in healthcare education, we evaluated ChatGPT's 
      performance in answering neurology board exam questions. METHODS: Neurology 
      board-style examination questions were accessed from BoardVitals, a commercial 
      neurology question bank. ChatGPT was provided a full question prompt and multiple 
      answer choices. First attempts and additional attempts up to three tries were 
      given to ChatGPT to select the correct answer. A total of 560 questions (14 
      blocks of 40 questions) were used, although any image-based questions were 
      disregarded due to ChatGPT's inability to process visual input. The artificial 
      intelligence (AI) answers were then compared with human user data provided by the 
      question bank to gauge its performance. RESULTS: Out of 509 eligible questions 
      over 14 question blocks, ChatGPT correctly answered 335 questions (65.8%) on the 
      first attempt/iteration and 383 (75.3%) over three attempts/iterations, scoring 
      at approximately the 26th and 50th percentiles, respectively. The highest 
      performing subjects were pain (100%), epilepsy &amp; seizures (85%) and genetic (82%) 
      while the lowest performing subjects were imaging/diagnostic studies (27%), 
      critical care (41%) and cranial nerves (48%). DISCUSSION: This study found that 
      ChatGPT performed similarly to its human counterparts. The accuracy of the AI 
      increased with multiple attempts and performance fell within the expected range 
      of neurology resident learners. This study demonstrates ChatGPT's potential in 
      processing specialised medical information. Future studies would better define 
      the scope to which AI would be able to integrate into medical decision making.
CI  - © Author(s) (or their employer(s)) 2023. Re-use permitted under CC BY-NC. No 
      commercial re-use. See rights and permissions. Published by BMJ.
FAU - Chen, Tse Chian
AU  - Chen TC
AD  - Neurology, Tulane University School of Medicine, New Orleans, Louisiana, USA.
FAU - Multala, Evan
AU  - Multala E
AD  - Tulane University School of Medicine, New Orleans, Louisiana, USA.
FAU - Kearns, Patrick
AU  - Kearns P
AD  - Tulane University School of Medicine, New Orleans, Louisiana, USA.
FAU - Delashaw, Johnny
AU  - Delashaw J
AD  - Neurosurgery, Tulane University School of Medicine, New Orleans, Louisiana, USA.
FAU - Dumont, Aaron
AU  - Dumont A
AD  - Neurosurgery, Tulane University School of Medicine, New Orleans, Louisiana, USA.
FAU - Maraganore, Demetrius
AU  - Maraganore D
AD  - Neurology, Tulane University School of Medicine, New Orleans, Louisiana, USA.
FAU - Wang, Arthur
AU  - Wang A
AUID- ORCID: 0009-0007-4396-2516
AD  - Neurosurgery, Tulane University School of Medicine, New Orleans, Louisiana, USA.
LA  - eng
PT  - Journal Article
DEP - 20231102
PL  - England
TA  - BMJ Neurol Open
JT  - BMJ neurology open
JID - 101775450
PMC - PMC10626870
OTO - NOTNLM
OT  - CLINICAL NEUROLOGY
COIS- Competing interests: None declared.
EDAT- 2023/11/08 06:42
MHDA- 2023/11/08 06:43
PMCR- 2023/11/02
CRDT- 2023/11/08 03:50
PHST- 2023/09/07 00:00 [received]
PHST- 2023/10/19 00:00 [accepted]
PHST- 2023/11/08 06:43 [medline]
PHST- 2023/11/08 06:42 [pubmed]
PHST- 2023/11/08 03:50 [entrez]
PHST- 2023/11/02 00:00 [pmc-release]
AID - bmjno-2023-000530 [pii]
AID - 10.1136/bmjno-2023-000530 [doi]
PST - epublish
SO  - BMJ Neurol Open. 2023 Nov 2;5(2):e000530. doi: 10.1136/bmjno-2023-000530. 
      eCollection 2023.

PMID- 38118283
OWN - NLM
STAT- MEDLINE
DCOM- 20240206
LR  - 20240206
IS  - 1532-2688 (Electronic)
IS  - 1059-1311 (Linking)
VI  - 114
DP  - 2024 Jan
TI  - ChatGPT's responses to questions related to epilepsy.
PG  - 105
LID - S1059-1311(23)00318-7 [pii]
LID - 10.1016/j.seizure.2023.12.004 [doi]
AB  - This is a correspondence on published article on "ChatGPT's responses to 
      questions related to epilepsy".
CI  - Copyright © 2023 British Epilepsy Association. Published by Elsevier Ltd. All 
      rights reserved.
FAU - Daungsupawong, Hinpetch
AU  - Daungsupawong H
AD  - Phonhong, Lao People's Democratic Republic. Electronic address: 
      hinpetchdaung@gmail.com.
FAU - Wiwanitkit, Viroj
AU  - Wiwanitkit V
AD  - Department of Research Analytics, Saveetha Dental College and Hospitals, Saveetha 
      Institute of Medical and Technical Sciences Saveetha University India.
LA  - eng
PT  - Letter
DEP - 20231205
PL  - England
TA  - Seizure
JT  - Seizure
JID - 9306979
SB  - IM
MH  - Humans
MH  - *Epilepsy
MH  - *Artificial Intelligence
OTO - NOTNLM
OT  - ChatGPT
OT  - Seizure
OT  - Technology
COIS- Declaration of Competing Interest None.
EDAT- 2023/12/21 00:42
MHDA- 2024/01/23 06:43
CRDT- 2023/12/20 18:06
PHST- 2023/11/30 00:00 [received]
PHST- 2023/12/04 00:00 [accepted]
PHST- 2024/01/23 06:43 [medline]
PHST- 2023/12/21 00:42 [pubmed]
PHST- 2023/12/20 18:06 [entrez]
AID - S1059-1311(23)00318-7 [pii]
AID - 10.1016/j.seizure.2023.12.004 [doi]
PST - ppublish
SO  - Seizure. 2024 Jan;114:105. doi: 10.1016/j.seizure.2023.12.004. Epub 2023 Dec 5.

PMID- 37203581
OWN - NLM
STAT- MEDLINE
DCOM- 20230526
LR  - 20230912
IS  - 1879-8365 (Electronic)
IS  - 0926-9630 (Linking)
VI  - 302
DP  - 2023 May 18
TI  - How Good Is ChatGPT for Medication Evidence Synthesis?
PG  - 1062-1066
LID - 10.3233/SHTI230347 [doi]
AB  - With its seeming competence to mimic human responses, ChatGPT, an emerging 
      AI-powered chatbot, has spurred great interest. This study aims to explore the 
      role of ChatGPT in synthesizing medication literature and compare it with a 
      hybrid summarization system. We tested ten medications' effectiveness with 
      reference to their definitions and descriptions extracted from DrugBank. ChatGPT 
      could generate coherent summaries that are not backed by evidence. In contrast, 
      our approach can provide a highly structured and concise synthesis of related 
      evidence, but the resulting summary is not as fluent and convincing as ChatGPT. 
      Therefore, we recommend integrating both techniques to achieve the best 
      performance.
FAU - Liu, Hao
AU  - Liu H
AD  - Dept. of Biomedical Informatics, Columbia University, New York, NY, USA.
FAU - Peng, Yifan
AU  - Peng Y
AD  - Dept. of Population Health Sciences, Weill Cornell Medicine, New York, NY, USA.
FAU - Weng, Chunhua
AU  - Weng C
AD  - Dept. of Biomedical Informatics, Columbia University, New York, NY, USA.
LA  - eng
PT  - Journal Article
PL  - Netherlands
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
MH  - *Software
MH  - *Artificial Intelligence
OTO - NOTNLM
OT  - ChatGPT
OT  - Natural Language Processing
OT  - Summarization
EDAT- 2023/05/19 06:42
MHDA- 2023/05/22 06:41
CRDT- 2023/05/19 05:29
PHST- 2023/05/22 06:41 [medline]
PHST- 2023/05/19 06:42 [pubmed]
PHST- 2023/05/19 05:29 [entrez]
AID - SHTI230347 [pii]
AID - 10.3233/SHTI230347 [doi]
PST - ppublish
SO  - Stud Health Technol Inform. 2023 May 18;302:1062-1066. doi: 10.3233/SHTI230347.

PMID- 37576290
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230815
IS  - 2405-8440 (Print)
IS  - 2405-8440 (Electronic)
IS  - 2405-8440 (Linking)
VI  - 9
IP  - 8
DP  - 2023 Aug
TI  - ChatGPT's influence on customer experience in digital marketing: Investigating 
      the moderating roles.
PG  - e18770
LID - 10.1016/j.heliyon.2023.e18770 [doi]
LID - e18770
AB  - ChatGPT is an artificial intelligence model intended for conversational purposes 
      that has grown in popularity in digital marketing, offering organizations a vital 
      tool for engaging with clients and enhancing their marketing efforts. The main 
      objective of this research is to investigate the impact of ChatGPT on the 
      customer experience in digital marketing. Additionally, the study intends to 
      investigate the moderating impacts of business type and technology familiarity 
      and comfort on the customer experience. Furthermore, the research explores the 
      moderating roles of gender, age, and education level. The data for this study 
      were collected electronically from 394 clients who have interacted with ChatGPT 
      in digital marketing using an open-access questionnaire. The results support the 
      significance of the moderating role of (Familiarity and Comfort with Technology, 
      Business Type, Age, and Education level on the relation between customer 
      experience with ChatGPT and overall satisfaction with digital marketing, while 
      Gender is not supported. This article's findings are intended to contribute to 
      the current literature on the use of conversational AI models in digital 
      marketing and customer experience, providing insights and recommendations for 
      future research.
CI  - © 2023 The Author.
FAU - Abdelkader, Osama Ahmed
AU  - Abdelkader OA
AD  - Marketing Department, College of Business Administration, Imam Abdulrahman Bin 
      Faisal University, Saudi Arabia.
LA  - eng
PT  - Journal Article
DEP - 20230802
PL  - England
TA  - Heliyon
JT  - Heliyon
JID - 101672560
PMC - PMC10415881
OTO - NOTNLM
OT  - ChatGPT
OT  - Chatbots
OT  - Consumer behavior
OT  - Digital marketing
OT  - Marketing
COIS- The authors declare that they have no known competing financial interests or 
      personal relationships that could have appeared to influence the work reported in 
      this paper.
EDAT- 2023/08/14 06:42
MHDA- 2023/08/14 06:43
PMCR- 2023/08/02
CRDT- 2023/08/14 04:40
PHST- 2023/04/30 00:00 [received]
PHST- 2023/07/26 00:00 [revised]
PHST- 2023/07/27 00:00 [accepted]
PHST- 2023/08/14 06:43 [medline]
PHST- 2023/08/14 06:42 [pubmed]
PHST- 2023/08/14 04:40 [entrez]
PHST- 2023/08/02 00:00 [pmc-release]
AID - S2405-8440(23)05978-9 [pii]
AID - e18770 [pii]
AID - 10.1016/j.heliyon.2023.e18770 [doi]
PST - epublish
SO  - Heliyon. 2023 Aug 2;9(8):e18770. doi: 10.1016/j.heliyon.2023.e18770. eCollection 
      2023 Aug.

PMID- 38022092
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231201
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 10
DP  - 2023 Oct
TI  - ChatGPT's Epoch in Rheumatological Diagnostics: A Critical Assessment in the 
      Context of Sjögren's Syndrome.
PG  - e47754
LID - 10.7759/cureus.47754 [doi]
LID - e47754
AB  - INTRODUCTION: The rise of artificial intelligence in medical practice is 
      reshaping clinical care. Large language models (LLMs) like ChatGPT have the 
      potential to assist in rheumatology by personalizing scientific information 
      retrieval, particularly in the context of Sjögren's Syndrome. This study aimed to 
      evaluate the efficacy of ChatGPT in providing insights into Sjögren's Syndrome, 
      differentiating it from other rheumatological conditions. MATERIALS AND METHODS: 
      &nbsp;A database of peer-reviewed articles and clinical guidelines focused on 
      Sjögren's Syndrome was compiled. Clinically relevant questions were presented to 
      ChatGPT, with responses assessed for accuracy, relevance, and comprehensiveness. 
      Techniques such as blinding, random control queries, and temporal analysis 
      ensured unbiased evaluation. ChatGPT's responses were also assessed using the 
      15-questionnaire DISCERN tool. RESULTS: &nbsp;ChatGPT effectively highlighted key 
      immunopathological and histopathological characteristics of Sjögren's Syndrome, 
      though some crucial data and citation inconsistencies were noted. For a given 
      clinical vignette, ChatGPT correctly identified potential etiological 
      considerations with Sjögren's Syndrome being prominent. DISCUSSION: &nbsp;LLMs like 
      ChatGPT offer rapid access to vast amounts of data, beneficial for both patients 
      and providers. While it democratizes information, limitations like potential 
      oversimplification and reference inaccuracies were observed. The balance between 
      LLM insights and clinical judgment, as well as continuous model refinement, is 
      crucial. CONCLUSION: &nbsp;LLMs like ChatGPT offer significant potential in 
      rheumatology, providing swift and broad medical insights. However, a cautious 
      approach is vital, ensuring rigorous training and ethical application for optimal 
      patient care and clinical practice.
CI  - Copyright © 2023, Irfan et al.
FAU - Irfan, Bilal
AU  - Irfan B
AD  - Microbiology and Immunology, University of Michigan, Ann Arbor, USA.
FAU - Yaqoob, Aneela
AU  - Yaqoob A
AD  - Infectious Diseases, Beaumont Hospital, Taylor, USA.
LA  - eng
PT  - Journal Article
DEP - 20231026
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10676288
OTO - NOTNLM
OT  - artificial intelligence (ai)
OT  - chatgpt
OT  - chatgpt-4
OT  - large language models (llms)
OT  - sjögren’s syndrome
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/11/29 18:42
MHDA- 2023/11/29 18:43
PMCR- 2023/10/26
CRDT- 2023/11/29 15:17
PHST- 2023/10/26 00:00 [accepted]
PHST- 2023/11/29 18:43 [medline]
PHST- 2023/11/29 18:42 [pubmed]
PHST- 2023/11/29 15:17 [entrez]
PHST- 2023/10/26 00:00 [pmc-release]
AID - 10.7759/cureus.47754 [doi]
PST - epublish
SO  - Cureus. 2023 Oct 26;15(10):e47754. doi: 10.7759/cureus.47754. eCollection 2023 
      Oct.

PMID- 38112347
OWN - NLM
STAT- MEDLINE
DCOM- 20231221
LR  - 20231221
IS  - 0043-5147 (Print)
IS  - 0043-5147 (Linking)
VI  - 76
IP  - 11
DP  - 2023
TI  - FROM TEXT TO DIAGNOSE: CHATGPT'S EFFICACY IN MEDICAL DECISION-MAKING.
PG  - 2345-2350
LID - 10.36740/WLek202311101 [doi]
AB  - OBJECTIVE: The aim: Evaluate the diagnostic capabilities of the ChatGPT in the 
      field of medical diagnosis. PATIENTS AND METHODS: Materials and methods: We 
      utilized 50 clinical cases, employing Large Language Model ChatGPT-3.5. The 
      experiment had three phases, each with a new chat setup. In the initial phase, 
      ChatGPT received detailed clinical case descriptions, guided by a "Persona 
      Pattern" prompt. In the second phase, cases with diagnostic errors were addressed 
      by providing potential diagnoses for ChatGPT to choose from. The final phase 
      assessed artificial intelligence's ability to mimic a medical practitioner's 
      diagnostic process, with prompts limiting initial information to symptoms and 
      history. RESULTS: Results: In the initial phase, ChatGPT showed a 66.00% 
      diagnostic accuracy, surpassing physicians by nearly 50%. Notably, in 11 cases 
      requiring image inter¬pretation, ChatGPT struggled initially but achieved a 
      correct diagnosis for four without added interpretations. In the second phase, 
      ChatGPT demonstrated a remarkable 70.59% diagnostic accuracy, while physicians 
      averaged 41.47%. Furthermore, the overall accuracy of Large Language Model in 
      first and second phases together was 90.00%. In the third phase emulating real 
      doctor decision-making, ChatGPT achieved a 46.00% success rate. CONCLUSION: 
      Conclusions: Our research underscores ChatGPT's strong potential in clinical 
      medicine as a diagnostic tool, especially in structured scenarios. It emphasizes 
      the need for supplementary data and the complexity of medical diagnosis. This 
      contributes valuable insights to AI-driven clinical diagnostics, with a nod to 
      the importance of prompt engineering techniques in ChatGPT's interaction with 
      doctors.
FAU - Mykhalko, Yaroslav
AU  - Mykhalko Y
AD  - UZHHOROD NATIONAL UNIVERSITY, UZHHOROD, UKRAINE.
FAU - Kish, Pavlo
AU  - Kish P
AD  - UZHHOROD NATIONAL UNIVERSITY, UZHHOROD, UKRAINE.
FAU - Rubtsova, Yelyzaveta
AU  - Rubtsova Y
AD  - UZHHOROD NATIONAL UNIVERSITY, UZHHOROD, UKRAINE.
FAU - Kutsyn, Oleksandr
AU  - Kutsyn O
AD  - UZHHOROD NATIONAL UNIVERSITY, UZHHOROD, UKRAINE.
FAU - Koval, Valentyna
AU  - Koval V
AD  - UZHHOROD NATIONAL UNIVERSITY, UZHHOROD, UKRAINE.
LA  - eng
PT  - Journal Article
PL  - Poland
TA  - Wiad Lek
JT  - Wiadomosci lekarskie (Warsaw, Poland : 1960)
JID - 9705467
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Clinical Decision-Making
MH  - Diagnostic Errors
MH  - Language
MH  - *Physicians
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - clinical decision support
OT  - diagnose
OT  - large language models
EDAT- 2023/12/19 19:54
MHDA- 2023/12/21 06:42
CRDT- 2023/12/19 08:32
PHST- 2023/12/21 06:42 [medline]
PHST- 2023/12/19 19:54 [pubmed]
PHST- 2023/12/19 08:32 [entrez]
AID - 10.36740/WLek202311101 [doi]
PST - ppublish
SO  - Wiad Lek. 2023;76(11):2345-2350. doi: 10.36740/WLek202311101.

PMID- 37873042
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231026
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 10
DP  - 2023 Oct
TI  - Healthcare's New Horizon With ChatGPT's Voice and Vision Capabilities: A Leap 
      Beyond Text.
PG  - e47469
LID - 10.7759/cureus.47469 [doi]
LID - e47469
AB  - The integration of artificial intelligence (AI) in healthcare is responsible for 
      a paradigm shift in medicine. OpenAI's recent augmentation of their Generative 
      Pre-trained Transformer (ChatGPT) large language model (LLM) with voice and image 
      recognition capabilities (OpenAI, Delaware) presents another potential 
      transformative tool for healthcare. Envision a healthcare setting where 
      professionals engage in dynamic interactions with ChatGPT to navigate the 
      complexities of atypical medical scenarios. In this innovative landscape, 
      practitioners could solicit ChatGPT's expertise for concise summarizations and 
      insightful extrapolations from a myriad of web-based resources pertaining to 
      similar medical conditions.&nbsp;Furthermore, imagine patients using ChatGPT to 
      identify abnormalities in medical images or skin lesions.&nbsp;While the prospects are 
      diverse, challenges such as suboptimal audio quality and ensuring data security 
      necessitate cautious integration in medical practice. Drawing insights from 
      previous ChatGPT iterations could provide a prudent roadmap for navigating 
      possible challenges. This editorial explores some possible horizons and potential 
      hurdles of ChatGPT's enhanced functionalities in healthcare, emphasizing the 
      importance of continued refinements and vigilance to maximize the benefits while 
      minimizing risks. Through collaborative efforts between AI developers and 
      healthcare professionals, another fusion of AI and healthcare can evolve into 
      enriched patient care and enhanced medical experience.
CI  - Copyright © 2023, Temsah et al.
FAU - Temsah, Reem
AU  - Temsah R
AD  - College of Pharmacy, Alfaisal University, Riyadh, SAU.
FAU - Altamimi, Ibraheem
AU  - Altamimi I
AD  - College of Medicine, King Saud University, Riyadh, SAU.
FAU - Alhasan, Khalid
AU  - Alhasan K
AD  - Pediatric Nephrology, King Saud University, Riyadh, SAU.
AD  - Solid Organ Transplant Center of Excellence, King Faisal Specialist Hospital and 
      Research Centre, Riyadh, SAU.
FAU - Temsah, Mohamad-Hani
AU  - Temsah MH
AD  - Evidence-Based Health Care &amp; Knowledge Translation Research, King Saud 
      University, Riyadh, SAU.
AD  - College of Medicine, King Saud University, Riyadh, SAU.
FAU - Jamal, Amr
AU  - Jamal A
AD  - Evidence-Based Health Care &amp; Knowledge Translation Research, King Saud 
      University, Riyadh, SAU.
AD  - College of Medicine, King Saud University, Riyadh, SAU.
LA  - eng
PT  - Editorial
DEP - 20231022
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10590619
OTO - NOTNLM
OT  - artificial intelligence chatgpt-4
OT  - dalle-3
OT  - image recognition
OT  - user-centric interface
OT  - voice recognition technology
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/10/24 06:41
MHDA- 2023/10/24 06:42
PMCR- 2023/10/22
CRDT- 2023/10/24 03:49
PHST- 2023/10/22 00:00 [accepted]
PHST- 2023/10/24 06:42 [medline]
PHST- 2023/10/24 06:41 [pubmed]
PHST- 2023/10/24 03:49 [entrez]
PHST- 2023/10/22 00:00 [pmc-release]
AID - 10.7759/cureus.47469 [doi]
PST - epublish
SO  - Cureus. 2023 Oct 22;15(10):e47469. doi: 10.7759/cureus.47469. eCollection 2023 
      Oct.

PMID- 37040060
OWN - NLM
STAT- MEDLINE
DCOM- 20230512
LR  - 20230512
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 51
IP  - 6
DP  - 2023 Jun
TI  - Transforming Maritime Health with ChatGPT-Powered Healthcare Services for 
      Mariners.
PG  - 1123-1125
LID - 10.1007/s10439-023-03195-0 [doi]
AB  - The maritime industry is vital to international trade, however, it also poses 
      inimitable challenges to the health and well-being of mariners. Long voyages at 
      sea might make it grim to receive high-quality healthcare. This is a descriptive 
      study that highlights the use of ChatGPT in providing healthcare amenities to 
      mariners. AI technologies can revolutionize maritime healthcare to tackle this 
      issue. ChatGPT, a state-of-the-art AI system developed by OpenAI can provide 
      valuable support for the health and welfare of seafarers'. By harnessing the 
      extensive expertise and conversational capacities of ChatGPT, maritime industries 
      can provide personalized and prompt healthcare services to their stakeholders. 
      This research work will highlight how ChatGPT-powered healthcare services can 
      boost the health and well-being of seafarers. ChatGPT has the potential to 
      revolutionize the marine sector by enabling virtual consultations with healthcare 
      professionals for the analysis of health data. The assimilation of ChatGPT 
      technology into maritime healthcare has the potential to revolutionize the way 
      seafarers receive care and support. Certainly, some challenges need to be taken 
      into consideration.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Sharma, Manik
AU  - Sharma M
AUID- ORCID: 0000-0002-5942-134X
AD  - DAV University Jalandhar, Jalandhar, Punjab, India. manik_sharma25@yahoo.com.
FAU - Sharma, Samriti
AU  - Sharma S
AD  - Guru Nanak Dev University, Amritsar, Punjab, India.
LA  - eng
PT  - Letter
DEP - 20230411
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - Humans
MH  - *Ships
MH  - Commerce
MH  - *Occupational Health
MH  - Internationality
MH  - Delivery of Health Care
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Health
OT  - Mariner
OT  - Maritime
EDAT- 2023/04/12 06:00
MHDA- 2023/05/12 07:06
CRDT- 2023/04/11 11:27
PHST- 2023/03/21 00:00 [received]
PHST- 2023/03/23 00:00 [accepted]
PHST- 2023/05/12 07:06 [medline]
PHST- 2023/04/12 06:00 [pubmed]
PHST- 2023/04/11 11:27 [entrez]
AID - 10.1007/s10439-023-03195-0 [pii]
AID - 10.1007/s10439-023-03195-0 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2023 Jun;51(6):1123-1125. doi: 10.1007/s10439-023-03195-0. Epub 
      2023 Apr 11.

PMID- 37510487
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231106
IS  - 2227-9032 (Print)
IS  - 2227-9032 (Electronic)
IS  - 2227-9032 (Linking)
VI  - 11
IP  - 14
DP  - 2023 Jul 17
TI  - ChatGPT Knowledge Evaluation in Basic and Clinical Medical Sciences: Multiple 
      Choice Question Examination-Based Performance.
LID - 10.3390/healthcare11142046 [doi]
LID - 2046
AB  - The Chatbot Generative Pre-Trained Transformer (ChatGPT) has garnered great 
      attention from the public, academicians and science communities. It responds with 
      appropriate and articulate answers and explanations across various disciplines. 
      For the use of ChatGPT in education, research and healthcare, different 
      perspectives exist with some level of ambiguity around its acceptability and 
      ideal uses. However, the literature is acutely lacking in establishing a link to 
      assess the intellectual levels of ChatGPT in the medical sciences. Therefore, the 
      present study aimed to investigate the knowledge level of ChatGPT in medical 
      education both in basic and clinical medical sciences, multiple-choice question 
      (MCQs) examination-based performance and its impact on the medical examination 
      system. In this study, initially, a subject-wise question bank was established 
      with a pool of multiple-choice questions (MCQs) from various medical textbooks 
      and university examination pools. The research team members carefully reviewed 
      the MCQ contents and ensured that the MCQs were relevant to the subject's 
      contents. Each question was scenario-based with four sub-stems and had a single 
      correct answer. In this study, 100 MCQs in various disciplines, including basic 
      medical sciences (50 MCQs) and clinical medical sciences (50 MCQs), were randomly 
      selected from the MCQ bank. The MCQs were manually entered one by one, and a 
      fresh ChatGPT session was started for each entry to avoid memory retention bias. 
      The task was given to ChatGPT to assess the response and knowledge level of 
      ChatGPT. The first response obtained was taken as the final response. Based on a 
      pre-determined answer key, scoring was made on a scale of 0 to 1, with zero 
      representing incorrect and one representing the correct answer. The results 
      revealed that out of 100 MCQs in various disciplines of basic and clinical 
      medical sciences, ChatGPT attempted all the MCQs and obtained 37/50 (74%) marks 
      in basic medical sciences and 35/50 (70%) marks in clinical medical sciences, 
      with an overall score of 72/100 (72%) in both basic and clinical medical 
      sciences. It is concluded that ChatGPT obtained a satisfactory score in both 
      basic and clinical medical sciences subjects and demonstrated a degree of 
      understanding and explanation. This study's findings suggest that ChatGPT may be 
      able to assist medical students and faculty in medical education settings since 
      it has potential as an innovation in the framework of medical sciences and 
      education.
FAU - Meo, Sultan Ayoub
AU  - Meo SA
AUID- ORCID: 0000-0001-9820-1852
AD  - Department of Physiology, College of Medicine, King Saud University, Riyadh 
      11461, Saudi Arabia.
FAU - Al-Masri, Abeer A
AU  - Al-Masri AA
AD  - Department of Physiology, College of Medicine, King Saud University, Riyadh 
      11461, Saudi Arabia.
FAU - Alotaibi, Metib
AU  - Alotaibi M
AD  - University Diabetes Unit, Department of Medicine, College of Medicine, King Saud 
      University, Riyadh 11461, Saudi Arabia.
FAU - Meo, Muhammad Zain Sultan
AU  - Meo MZS
AD  - College of Medicine, Alfaisal University, Riyadh 11533, Saudi Arabia.
FAU - Meo, Muhammad Omair Sultan
AU  - Meo MOS
AD  - College of Medicine, Alfaisal University, Riyadh 11533, Saudi Arabia.
LA  - eng
GR  - (IFKSUOR3-4-3)/Deputyship for Research &amp; Innovation, Ministry of Education, Saudi 
      Arabia (IFKSUOR3-4-3./
PT  - Journal Article
DEP - 20230717
PL  - Switzerland
TA  - Healthcare (Basel)
JT  - Healthcare (Basel, Switzerland)
JID - 101666525
PMC - PMC10379728
OTO - NOTNLM
OT  - ChatGPT
OT  - intellect level
OT  - knowledge
OT  - medical education
COIS- The authors declare no conflict of interest.
EDAT- 2023/07/29 11:43
MHDA- 2023/07/29 11:44
PMCR- 2023/07/17
CRDT- 2023/07/29 01:18
PHST- 2023/06/09 00:00 [received]
PHST- 2023/07/12 00:00 [revised]
PHST- 2023/07/14 00:00 [accepted]
PHST- 2023/07/29 11:44 [medline]
PHST- 2023/07/29 11:43 [pubmed]
PHST- 2023/07/29 01:18 [entrez]
PHST- 2023/07/17 00:00 [pmc-release]
AID - healthcare11142046 [pii]
AID - healthcare-11-02046 [pii]
AID - 10.3390/healthcare11142046 [doi]
PST - epublish
SO  - Healthcare (Basel). 2023 Jul 17;11(14):2046. doi: 10.3390/healthcare11142046.

PMID- 38035435
OWN - NLM
STAT- MEDLINE
DCOM- 20240115
LR  - 20240115
IS  - 1532-2831 (Electronic)
IS  - 1078-8174 (Linking)
VI  - 30
IP  - 1
DP  - 2024 Jan
TI  - Harnessing the benefits of ChatGPT for radiography education: A&nbsp;discussion paper.
PG  - 209-216
LID - S1078-8174(23)00225-0 [pii]
LID - 10.1016/j.radi.2023.11.009 [doi]
AB  - OBJECTIVE: Radiography education is pivotal in training skilled radiographers for 
      diagnostic imaging and therapeutic applications. With technological advancements, 
      interest in innovative educational tools to enhance traditional teaching methods 
      is growing. This discussion paper explores the possibility of the integration of 
      ChatGPT, a cutting-edge conversational AI language model, into radiography 
      education. KEY FINDINGS: We report that ChatGPT offers interactive learning 
      opportunities that can facilitate learning. It also provides self-paced learning, 
      revision platforms, and supports educators in scenario creation, assessment 
      development, group collaboration, and professional and research activities. 
      Despite these benefits, it is important to carefully consider issues related to 
      academic integrity and privacy, along with the opportunities and challenges 
      presented by this new technology in radiography education. CONCLUSION: This paper 
      highlights some of the prospects and limitations of the potential applications of 
      ChatGPT in radiography education, underscoring the benefits for both students and 
      educators. However, its implementation must be considered thoughtfully and 
      ethically, taking into account its strengths and limitations. IMPLICATIONS FOR 
      PRACTICE: Integrating ChatGPT in radiography education has the potential to 
      improve radiography education by improving digital literacy and graduate outcomes 
      of students while streamlining the preparation process for educators. However, 
      ethical implementation is vital for optimal outcomes.
CI  - Copyright © 2023 The Author(s). Published by Elsevier Ltd.. All rights reserved.
FAU - Amedu, C
AU  - Amedu C
AD  - Diagnostic Radiography, Department of Midwifery &amp; Radiography School of Health &amp; 
      Psychological Sciences City, University of London, Northampton Square London EC1V 
      0HB, UK.
FAU - Ohene-Botwe, B
AU  - Ohene-Botwe B
AD  - Diagnostic Radiography, Department of Midwifery &amp; Radiography School of Health &amp; 
      Psychological Sciences City, University of London, Northampton Square London EC1V 
      0HB, UK. Electronic address: benard.ohene-botwe@city.ac.uk.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20231129
PL  - Netherlands
TA  - Radiography (Lond)
JT  - Radiography (London, England : 1995)
JID - 9604102
SB  - IM
MH  - Humans
MH  - Educational Status
MH  - Radiography
MH  - *Students
MH  - Learning
MH  - *Simulation Training
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Benefits
OT  - ChatGPT
OT  - Educational tools
OT  - Radiography education
COIS- Conflict of interest statement None.
EDAT- 2023/12/01 00:43
MHDA- 2024/01/15 12:42
CRDT- 2023/11/30 18:01
PHST- 2023/08/21 00:00 [received]
PHST- 2023/10/25 00:00 [revised]
PHST- 2023/11/09 00:00 [accepted]
PHST- 2024/01/15 12:42 [medline]
PHST- 2023/12/01 00:43 [pubmed]
PHST- 2023/11/30 18:01 [entrez]
AID - S1078-8174(23)00225-0 [pii]
AID - 10.1016/j.radi.2023.11.009 [doi]
PST - ppublish
SO  - Radiography (Lond). 2024 Jan;30(1):209-216. doi: 10.1016/j.radi.2023.11.009. Epub 
      2023 Nov 29.

PMID- 37455540
OWN - NLM
STAT- MEDLINE
DCOM- 20231228
LR  - 20231228
IS  - 1741-3850 (Electronic)
IS  - 1741-3842 (Linking)
VI  - 45
IP  - 4
DP  - 2023 Nov 29
TI  - ChatGPT in the higher education environment: perspectives from the theory of high 
      order thinking skills.
PG  - e840-e841
LID - 10.1093/pubmed/fdad120 [doi]
AB  - ChatGPT is a form of technological progress in the 5.0 era. The use of ChatGPT 
      has begun to penetrate all fields of science, including the field of education. 
      Students use ChatGPT to help them complete their assignments in the university 
      environment. Apart from providing many benefits, ChatGPT also has many dangers 
      threatening students. One of the dangers for students who rely too much on 
      ChatGPT is a decrease in higher-order thinking skills.
CI  - © The Author(s) 2023. Published by Oxford University Press on behalf of Faculty 
      of Public Health. All rights reserved. For permissions, please e-mail: 
      journals.permissions@oup.com.
FAU - Putra, Febri W
AU  - Putra FW
AD  - Department of Guidance and Counseling, Faculty of Education, Universitas Negeri 
      Padang, West Sumatera, Indonesia.
FAU - Rangka, Itsar B
AU  - Rangka IB
AUID- ORCID: 0000-0002-6934-2469
AD  - Departement of Guidance and Counseling, Faculty of Education and Social Sciences, 
      Universitas Indraprasta PGRI, Jakarta, Indonesia.
FAU - Aminah, Siti
AU  - Aminah S
AUID- ORCID: 0000-0002-6640-6412
AD  - Department of Education Psychology and Guidance, Faculty of Education and 
      Psychology, Universitas Negeri Yogyakarta, Yogyakarta, Indonesia.
FAU - Aditama, Mint H R
AU  - Aditama MHR
AUID- ORCID: 0000-0003-4593-8935
AD  - Department of Guidance and Counseling, Faculty of Education and Psychology, 
      Universitas Negeri Manado, Tondano, Indonesia.
LA  - eng
PT  - Journal Article
PL  - England
TA  - J Public Health (Oxf)
JT  - Journal of public health (Oxford, England)
JID - 101188638
SB  - IM
MH  - Humans
MH  - Educational Status
MH  - *Students
MH  - *Thinking
MH  - Universities
MH  - *Artificial Intelligence
OTO - NOTNLM
OT  - ChatGPT
OT  - cognitive
OT  - high-order thinking skills
OT  - students
OT  - university
EDAT- 2023/07/17 06:42
MHDA- 2023/12/04 12:42
CRDT- 2023/07/17 02:33
PHST- 2023/06/19 00:00 [received]
PHST- 2023/06/27 00:00 [accepted]
PHST- 2023/12/04 12:42 [medline]
PHST- 2023/07/17 06:42 [pubmed]
PHST- 2023/07/17 02:33 [entrez]
AID - 7224312 [pii]
AID - 10.1093/pubmed/fdad120 [doi]
PST - ppublish
SO  - J Public Health (Oxf). 2023 Nov 29;45(4):e840-e841. doi: 10.1093/pubmed/fdad120.

PMID- 37853081
OWN - NLM
STAT- Publisher
LR  - 20231018
IS  - 1432-5241 (Electronic)
IS  - 0364-216X (Linking)
DP  - 2023 Oct 18
TI  - Can ChatGPT be the Plastic Surgeon's New Digital Assistant? A Bibliometric 
      Analysis and Scoping Review of ChatGPT in Plastic Surgery Literature.
LID - 10.1007/s00266-023-03709-0 [doi]
AB  - BACKGROUND: ChatGPT, an artificial intelligence (AI) chatbot that uses natural 
      language processing (NLP) to interact in a humanlike manner, has made significant 
      contributions to various healthcare fields, including plastic surgery. However, 
      its widespread use has raised ethical and security concerns. This study examines 
      the presence of ChatGPT, an artificial intelligence (AI) chatbot, in the 
      literature of plastic surgery. METHODS: A bibliometric analysis and scoping 
      review of the ChatGPT plastic surgery literature were performed. PubMed was 
      queried using the search term "ChatGPT" to identify all biomedical literature on 
      ChatGPT, with only studies related to plastic, reconstructive, or aesthetic 
      surgery topics being considered eligible for inclusion. RESULTS: The analysis 
      included 30 out of 724 articles retrieved from PubMed, focusing on publications 
      from December 2022 to July 2023. Four key areas of research emerged: applications 
      in research/creation of original work, clinical application, surgical education, 
      and ethics/commentary on previous studies. The versatility of ChatGPT in 
      research, its potential in surgical education, and its role in enhancing patient 
      education were explored. Ethical concerns regarding patient privacy, plagiarism, 
      and the accuracy of information obtained from ChatGPT-generated sources were also 
      highlighted. CONCLUSION: While ethical concerns persist, the study underscores 
      the potential of ChatGPT in plastic surgery research and practice, emphasizing 
      the need for careful utilization and collaboration to optimize its benefits while 
      minimizing risks. LEVEL OF EVIDENCE V: This journal requires that authors assign 
      a level of evidence to each article. For a full description of these 
      Evidence-Based Medicine ratings, please refer to the Table of Contents or the 
      online Instructions to Authors www.springer.com/00266 .
CI  - © 2023. Springer Science+Business Media, LLC, part of Springer Nature and 
      International Society of Aesthetic Plastic Surgery.
FAU - Liu, Hilary Y
AU  - Liu HY
AD  - Department of Plastic Surgery, University of Pittsburgh Medical Center, 1350 
      Locust Street, Pittsburgh, PA, G10315219, USA.
FAU - Alessandri-Bonetti, Mario
AU  - Alessandri-Bonetti M
AD  - Department of Plastic Surgery, University of Pittsburgh Medical Center, 1350 
      Locust Street, Pittsburgh, PA, G10315219, USA.
FAU - Arellano, José Antonio
AU  - Arellano JA
AD  - Department of Plastic Surgery, University of Pittsburgh Medical Center, 1350 
      Locust Street, Pittsburgh, PA, G10315219, USA.
FAU - Egro, Francesco M
AU  - Egro FM
AUID- ORCID: 0000-0003-1536-7713
AD  - Department of Plastic Surgery, University of Pittsburgh Medical Center, 1350 
      Locust Street, Pittsburgh, PA, G10315219, USA. francescoegro@gmail.com.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20231018
PL  - United States
TA  - Aesthetic Plast Surg
JT  - Aesthetic plastic surgery
JID - 7701756
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Clinical practice
OT  - Ethics
OT  - Medical education
OT  - Patient education
OT  - Plastic surgery
OT  - Research
EDAT- 2023/10/19 00:45
MHDA- 2023/10/19 00:45
CRDT- 2023/10/18 23:30
PHST- 2023/08/19 00:00 [received]
PHST- 2023/09/30 00:00 [accepted]
PHST- 2023/10/19 00:45 [medline]
PHST- 2023/10/19 00:45 [pubmed]
PHST- 2023/10/18 23:30 [entrez]
AID - 10.1007/s00266-023-03709-0 [pii]
AID - 10.1007/s00266-023-03709-0 [doi]
PST - aheadofprint
SO  - Aesthetic Plast Surg. 2023 Oct 18. doi: 10.1007/s00266-023-03709-0.

PMID- 37476297
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231020
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 7
DP  - 2023 Jul
TI  - The Potential Usefulness of ChatGPT in Oral and Maxillofacial Radiology.
PG  - e42133
LID - 10.7759/cureus.42133 [doi]
LID - e42133
AB  - Aim This study aimed to evaluate the potential usefulness of Chat Generated 
      Pre-Trained Transformer-3 (ChatGPT-3) in oral and maxillofacial radiology for 
      report writing by identifying radiographic anatomical landmarks&nbsp;and learning 
      about oral and maxillofacial pathologies&nbsp;and their radiographic features. The 
      study also aimed to evaluate the performance of ChatGPT-3 and its usage in oral 
      and maxillofacial radiology training. Materials and methods A questionnaire 
      consisting of 80 questions was queried on the OpenAI app ChatGPT-3. The questions 
      were stratified based on three categories. The categorization was based on random 
      anatomical landmarks, oral and maxillofacial pathologies, and the radiographic 
      features of some of these pathologies. One oral and maxillofacial radiologist 
      evaluated queries that were answered by the ChatGPT-3 model and rated them on a 
      4-point, modified Likert scale. The post-survey analysis for the performance of 
      ChatGPT-3 was based on the Strengths, Weaknesses, Opportunities, and Threats 
      (SWOT) analysis,&nbsp;its application in oral and maxillofacial radiology training, 
      and its recommended use. Results In order of efficiency, Chat GPT-3 gave 
      100%&nbsp;accuracy in describing radiographic landmarks. However, the content of the 
      oral and maxillofacial pathologies was limited to major or characteristic 
      radiographic features. The mean scores for the queries related to the anatomic 
      landmarks, oral and maxillofacial pathologies, and radiographic features of the 
      oral and maxillofacial pathologies were 3.94, 3.85, and 3.96, respectively. 
      However, the median and mode scores were 4 and were similar to all categories. 
      The data for the oral and maxillofacial pathologies when the questions were not 
      specifically included in the format of the introduction of the pathology, causes, 
      symptoms, and treatment. Out of two abbreviations, one was not answered 
      correctly. Conclusion The study showed that ChatGPT-3 is efficient in describing 
      the pathology, characteristic radiographic features, and describing anatomical 
      landmarks. ChatGPT-3 can be used as an adjunct when an oral radiologist needs 
      additional information on any pathology, however, it cannot be the mainstay for 
      reference. ChatGPT-3 is less detail-oriented, and the data has a risk of 
      infodemics and the possibility of medical errors. However, Chat GPT-3 can be an 
      excellent tool in helping the community in increasing the knowledge and awareness 
      of various pathologies and decreasing the anxiety of the patients while dental 
      healthcare professionals formulate an appropriate treatment plan.
CI  - Copyright © 2023, Mago et al.
FAU - Mago, Jyoti
AU  - Mago J
AD  - Oral and Maxillofacial Radiology, University of Nevada, Las Vegas (UNLV), Las 
      Vegas, USA.
FAU - Sharma, Manoj
AU  - Sharma M
AD  - Public Health, University of Nevada, Las Vegas (UNLV), Las Vegas, USA.
LA  - eng
PT  - Journal Article
DEP - 20230719
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10355343
OTO - NOTNLM
OT  - chatgpt
OT  - open-ai
OT  - oral and maxillofacial radiology
OT  - pathology
OT  - radiographic features
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/07/21 06:42
MHDA- 2023/07/21 06:43
PMCR- 2023/07/19
CRDT- 2023/07/21 04:03
PHST- 2023/07/19 00:00 [accepted]
PHST- 2023/07/21 06:43 [medline]
PHST- 2023/07/21 06:42 [pubmed]
PHST- 2023/07/21 04:03 [entrez]
PHST- 2023/07/19 00:00 [pmc-release]
AID - 10.7759/cureus.42133 [doi]
PST - epublish
SO  - Cureus. 2023 Jul 19;15(7):e42133. doi: 10.7759/cureus.42133. eCollection 2023 
      Jul.

PMID- 38112255
OWN - NLM
STAT- In-Process
LR  - 20240403
IS  - 1539-3429 (Electronic)
IS  - 1470-8175 (Linking)
VI  - 52
IP  - 2
DP  - 2024 Mar-Apr
TI  - Evaluating ChatGPT as a self-learning tool in medical biochemistry: A performance 
      assessment in undergraduate medical university examination.
PG  - 237-248
LID - 10.1002/bmb.21808 [doi]
AB  - The emergence of ChatGPT as one of the most advanced chatbots and its ability to 
      generate diverse data has given room for numerous discussions worldwide regarding 
      its utility, particularly in advancing medical education and research. This study 
      seeks to assess the performance of ChatGPT in medical biochemistry to evaluate 
      its potential as an effective self-learning tool for medical students. This 
      evaluation was carried out using the university examination question papers of 
      both parts 1 and 2 of medical biochemistry which comprised theory and multiple 
      choice questions (MCQs) accounting for a total of 100 in each part. The questions 
      were used to interact with ChatGPT, and three raters independently reviewed and 
      scored the answers to prevent bias in scoring. We conducted the inter-item 
      correlation matrix and the interclass correlation between raters 1, 2, and 3. For 
      MCQs, symmetric measures in the form of kappa value (a measure of agreement) were 
      performed between raters 1, 2, and 3. ChatGPT generated relevant and appropriate 
      answers to all questions along with explanations for MCQs. ChatGPT has "passed" 
      the medical biochemistry university examination with an average score of 117 out 
      of 200 (58%) in both papers. In Paper 1, ChatGPT has secured 60 ± 2.29 and 
      57 ± 4.36 in Paper 2. The kappa value for all the cross-analysis of Rater 1, 
      Rater 2, and Rater 3 scores in MCQ was 1.000. The evaluation of ChatGPT as a 
      self-learning tool in medical biochemistry has yielded important insights. While 
      it is encouraging that ChatGPT has demonstrated proficiency in this area, the 
      overall score of 58% indicates that there is work to be done. To unlock its full 
      potential as a self-learning tool, ChatGPT must focus on generating not only 
      accurate but also comprehensive and contextually relevant content.
CI  - © 2023 International Union of Biochemistry and Molecular Biology.
FAU - Surapaneni, Krishna Mohan
AU  - Surapaneni KM
AUID- ORCID: 0000-0002-5204-5708
AD  - Department of Biochemistry, Panimalar Medical College Hospital &amp; Research 
      Institute, Chennai, India.
AD  - Department of Medical Education, Panimalar Medical College Hospital &amp; Research 
      Institute, Chennai, India.
AD  - Department of Clinical Skills &amp; Simulation, Panimalar Medical College Hospital &amp; 
      Research Institute, Chennai, India.
FAU - Rajajagadeesan, Anusha
AU  - Rajajagadeesan A
AD  - Department of Biochemistry, Panimalar Medical College Hospital &amp; Research 
      Institute, Chennai, India.
FAU - Goudhaman, Lakshmi
AU  - Goudhaman L
AD  - Department of Biochemistry, Panimalar Medical College Hospital &amp; Research 
      Institute, Chennai, India.
FAU - Lakshmanan, Shalini
AU  - Lakshmanan S
AD  - Department of Biochemistry, Panimalar Medical College Hospital &amp; Research 
      Institute, Chennai, India.
FAU - Sundaramoorthi, Saranya
AU  - Sundaramoorthi S
AD  - Department of Biochemistry, Panimalar Medical College Hospital &amp; Research 
      Institute, Chennai, India.
FAU - Ravi, Dineshkumar
AU  - Ravi D
AD  - Department of Biochemistry, Panimalar Medical College Hospital &amp; Research 
      Institute, Chennai, India.
FAU - Rajendiran, Kalaiselvi
AU  - Rajendiran K
AD  - Department of Biochemistry, Panimalar Medical College Hospital &amp; Research 
      Institute, Chennai, India.
FAU - Swaminathan, Porchelvan
AU  - Swaminathan P
AD  - Department of Community Medicine, Panimalar Medical College Hospital &amp; Research 
      Institute, Chennai, India.
LA  - eng
PT  - Journal Article
DEP - 20231219
PL  - United States
TA  - Biochem Mol Biol Educ
JT  - Biochemistry and molecular biology education : a bimonthly publication of the 
      International Union of Biochemistry and Molecular Biology
JID - 100970605
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - biochemistry
OT  - medical education
EDAT- 2023/12/19 19:54
MHDA- 2023/12/19 19:54
CRDT- 2023/12/19 07:52
PHST- 2023/10/24 00:00 [revised]
PHST- 2023/03/28 00:00 [received]
PHST- 2023/12/04 00:00 [accepted]
PHST- 2023/12/19 19:54 [pubmed]
PHST- 2023/12/19 19:54 [medline]
PHST- 2023/12/19 07:52 [entrez]
AID - 10.1002/bmb.21808 [doi]
PST - ppublish
SO  - Biochem Mol Biol Educ. 2024 Mar-Apr;52(2):237-248. doi: 10.1002/bmb.21808. Epub 
      2023 Dec 19.

PMID- 38073539
OWN - NLM
STAT- Publisher
LR  - 20231211
IS  - 1532-5040 (Electronic)
IS  - 0959-3985 (Linking)
DP  - 2023 Dec 11
TI  - Clinical reasoning using ChatGPT: Is it beyond credibility for physiotherapists 
      use?
PG  - 1-20
LID - 10.1080/09593985.2023.2291656 [doi]
AB  - BACKGROUND: Artificial Intelligence (AI) tools are gaining popularity in 
      healthcare. OpenAI released ChatGPT on November 30, 2022. ChatGPT is a language 
      model that comprehends and generates human language, providing instant data 
      analysis and recommendations. This is particularly significant in the dynamic 
      field of physiotherapy, where its integration has the potential to enhance 
      healthcare efficiency. OBJECTIVES: This study aims to evaluate whether 
      ChatGPT-3.5 (free version) provides consistent and accurate clinical responses, 
      its ability to imitate human clinical reasoning in simple and complex scenarios, 
      and its capability to produce a differential diagnosis. METHODS: Two studies were 
      conducted using the ChatGPT-3.5. Study 1 evaluated the consistency and accuracy 
      of ChatGPT's responses in clinical assessment using ten user-participants who 
      submitted the phrase "Which are the main steps for a completed physiotherapy 
      assessment?" Study 2 assessed ChatGPT's differential diagnostic ability using 
      published case studies by 2 independent participants. The case reports consisted 
      of one simple and one complex scenario. RESULTS: Study 1 underscored the 
      variability in ChatGPT's responses, which ranged from comprehensive to concise. 
      Notably, essential steps such as re-assessment and subjective examination were 
      omitted in 30% and 40% of the responses, respectively. In Study 2, ChatGPT 
      demonstrated its capability to develop evidence-based clinical reasoning, 
      particularly evident in simple clinical scenarios. Question phrasing 
      significantly impacted the generated answers. CONCLUSIONS: This study highlights 
      the potential benefits of using ChatGPT in healthcare. It also provides a 
      balanced perspective on ChatGPT's strengths and limitations and emphasizes the 
      importance of using AI tools in a responsible and informed manner.
FAU - Bilika, Paraskevi
AU  - Bilika P
AD  - Physiotherapy Department, Faculty of Health Sciences, Clinical Exercise 
      Physiology and Rehabilitation Research Laboratory, University of Thessaly, Lamia, 
      Greece.
FAU - Stefanouli, Vasiliki
AU  - Stefanouli V
AD  - Physiotherapy Department, Faculty of Health Sciences, Health Assessment and 
      Quality of Life Research Laboratory, University of Thessaly, Lamia, Greece.
FAU - Strimpakos, Nikolaos
AU  - Strimpakos N
AD  - Physiotherapy Department, Faculty of Health Sciences, Health Assessment and 
      Quality of Life Research Laboratory, University of Thessaly, Lamia, Greece.
AD  - Division of Musculoskeletal and Dermatological Sciences, University of 
      Manchester, Manchester, UK.
FAU - Kapreli, Eleni V
AU  - Kapreli EV
AD  - Physiotherapy Department, Faculty of Health Sciences, Clinical Exercise 
      Physiology and Rehabilitation Research Laboratory, University of Thessaly, Lamia, 
      Greece.
LA  - eng
PT  - Journal Article
DEP - 20231211
PL  - England
TA  - Physiother Theory Pract
JT  - Physiotherapy theory and practice
JID - 9015520
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - Diagnosis
OT  - artificial intelligence
OT  - clinical reasoning
OT  - physiotherapy assessment
EDAT- 2023/12/11 06:45
MHDA- 2023/12/11 06:45
CRDT- 2023/12/11 05:28
PHST- 2023/12/11 06:45 [medline]
PHST- 2023/12/11 06:45 [pubmed]
PHST- 2023/12/11 05:28 [entrez]
AID - 10.1080/09593985.2023.2291656 [doi]
PST - aheadofprint
SO  - Physiother Theory Pract. 2023 Dec 11:1-20. doi: 10.1080/09593985.2023.2291656.

PMID- 38206389
OWN - NLM
STAT- MEDLINE
DCOM- 20240318
LR  - 20240402
IS  - 1434-4726 (Electronic)
IS  - 0937-4477 (Linking)
VI  - 281
IP  - 4
DP  - 2024 Apr
TI  - Accuracy of ChatGPT-3.5 and -4 in providing scientific references in 
      otolaryngology-head and neck surgery.
PG  - 2159-2165
LID - 10.1007/s00405-023-08441-8 [doi]
AB  - INTRODUCTION: Chatbot generative pre-trained transformer (ChatGPT) is a new 
      artificial intelligence-powered language model of chatbot able to help 
      otolaryngologists in practice and research. We investigated the accuracy of 
      ChatGPT-3.5 and -4 in the referencing of manuscripts published in otolaryngology. 
      METHODS: ChatGPT-3.5 and ChatGPT-4 were interrogated for providing references of 
      the top-30 most cited papers in otolaryngology in the past 40&nbsp;years including 
      clinical guidelines and key studies that changed the practice. The responses were 
      regenerated three times to assess the accuracy and stability of ChatGPT. 
      ChatGPT-3.5 and ChatGPT-4 were compared for accuracy of reference and potential 
      mistakes. RESULTS: The accuracy of ChatGPT-3.5 and ChatGPT-4.0 ranged from 47% to 
      60%, and 73% to 87%, respectively (p &lt; 0.005). ChatGPT-3.5 provided 19 inaccurate 
      references and invented 2 references throughout the regenerated questions. 
      ChatGPT-4.0 provided 13 inaccurate references, while it proposed only one 
      invented reference. The stability of responses throughout regenerated answers was 
      mild (k = 0.238) and moderate (k = 0.408) for ChatGPT-3.5 and 4.0, respectively. 
      CONCLUSIONS: ChatGPT-4.0 reported higher accuracy than the free-access version 
      (3.5). False references were detected in both 3.5 and 4.0 versions. Practitioners 
      need to be careful regarding the use of ChatGPT in the reach of some key 
      reference when writing a report.
CI  - © 2024. The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, 
      part of Springer Nature.
FAU - Lechien, Jerome R
AU  - Lechien JR
AUID- ORCID: 0000-0002-0845-0845
AD  - Division of Laryngology and Broncho-Esophagology, Department of 
      Otolaryngology-Head Neck Surgery, EpiCURA Hospital, UMONS Research Institute for 
      Health Sciences and Technology, University of Mons (UMons), Mons, Belgium. 
      Jerome.Lechien@umons.ac.be.
AD  - Department of Otorhinolaryngology and Head and Neck Surgery, School of Medicine, 
      Phonetics and Phonology Laboratory (UMR 7018, Foch Hospital, CNRS, Université 
      Sorbonne Nouvelle/Paris 3), Paris, France. Jerome.Lechien@umons.ac.be.
AD  - Department of Otorhinolaryngology and Head and Neck Surgery, School of Medicine, 
      CHU de Bruxelles, CHU Saint-Pierre, Université Libre de Bruxelles, Brussels, 
      Belgium. Jerome.Lechien@umons.ac.be.
AD  - Polyclinique Elsan de Poitiers, Poitiers, France. Jerome.Lechien@umons.ac.be.
AD  - Department of Human Anatomy and Experimental Oncology, Faculty of Medicine, UMONS 
      Research Institute for Health Sciences and Technology, Avenue du Champ de Mars, 
      6, 7000, Mons, Belgium. Jerome.Lechien@umons.ac.be.
FAU - Briganti, Giovanni
AU  - Briganti G
AD  - Chair of AI and Digital Medicine, Faculty of Medicine, University of Mons, Mons, 
      Belgium.
FAU - Vaira, Luigi A
AU  - Vaira LA
AD  - Maxillofacial Surgery Operative Unit, Department of Medicine, Surgery and 
      Pharmacy, University of Sassari, Sassari, Italy.
AD  - Biomedical Sciences Department, PhD School of Biomedical Science, University of 
      Sassari, Sassari, Italy.
LA  - eng
PT  - Journal Article
DEP - 20240111
PL  - Germany
TA  - Eur Arch Otorhinolaryngol
JT  - European archives of oto-rhino-laryngology : official journal of the European 
      Federation of Oto-Rhino-Laryngological Societies (EUFOS) : affiliated with the 
      German Society for Oto-Rhino-Laryngology - Head and Neck Surgery
JID - 9002937
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Otolaryngology
MH  - Software
MH  - Otolaryngologists
MH  - Language
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Chatbot
OT  - Head neck surgery
OT  - Otolaryngology
OT  - Reference
EDAT- 2024/01/11 12:42
MHDA- 2024/03/18 06:44
CRDT- 2024/01/11 11:07
PHST- 2023/10/07 00:00 [received]
PHST- 2023/12/26 00:00 [accepted]
PHST- 2024/03/18 06:44 [medline]
PHST- 2024/01/11 12:42 [pubmed]
PHST- 2024/01/11 11:07 [entrez]
AID - 10.1007/s00405-023-08441-8 [pii]
AID - 10.1007/s00405-023-08441-8 [doi]
PST - ppublish
SO  - Eur Arch Otorhinolaryngol. 2024 Apr;281(4):2159-2165. doi: 
      10.1007/s00405-023-08441-8. Epub 2024 Jan 11.

PMID- 38487300
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240316
IS  - 2382-1205 (Print)
IS  - 2382-1205 (Electronic)
IS  - 2382-1205 (Linking)
VI  - 11
DP  - 2024 Jan-Dec
TI  - Can ChatGPT-3.5 Pass a Medical Exam? A Systematic Review of ChatGPT's Performance 
      in Academic Testing.
PG  - 23821205241238641
LID - 10.1177/23821205241238641 [doi]
LID - 23821205241238641
AB  - OBJECTIVE: We, therefore, aim to conduct a systematic review to assess the 
      academic potential of ChatGPT-3.5, along with its strengths and limitations when 
      giving medical exams. METHOD: Following PRISMA guidelines, a systemic search of 
      the literature was performed using electronic databases PUBMED/MEDLINE, Google 
      Scholar, and Cochrane. Articles from their inception till April 4, 2023, were 
      queried. A formal narrative analysis was conducted by systematically arranging 
      similarities and differences between individual findings together. RESULTS: After 
      rigorous screening, 12 articles underwent this review. All the selected papers 
      assessed the academic performance of ChatGPT-3.5. One study compared the 
      performance of ChatGPT-3.5 with the performance of ChatGPT-4 when giving a 
      medical exam. Overall, ChatGPT performed well in 4 tests, averaged in 4 tests, 
      and performed badly in 4 tests. ChatGPT's performance was directly proportional 
      to the level of the questions' difficulty but was unremarkable on whether the 
      questions were binary, descriptive, or MCQ-based. ChatGPT's explanation, 
      reasoning, memory, and accuracy were remarkably good, whereas it failed to 
      understand image-based questions, and lacked insight and critical thinking. 
      CONCLUSION: ChatGPT-3.5 performed satisfactorily in the exams it took as an 
      examinee. However, there is a need for future related studies to fully explore 
      the potential of ChatGPT in medical education.
CI  - © The Author(s) 2024.
FAU - Sumbal, Anusha
AU  - Sumbal A
AUID- ORCID: 0000-0003-0685-9767
AD  - Dow University of Health Sciences, Karachi, Pakistan. RINGGOLD: 66818
FAU - Sumbal, Ramish
AU  - Sumbal R
AD  - Dow University of Health Sciences, Karachi, Pakistan. RINGGOLD: 66818
FAU - Amir, Alina
AU  - Amir A
AD  - Dow University of Health Sciences, Karachi, Pakistan. RINGGOLD: 66818
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20240313
PL  - United States
TA  - J Med Educ Curric Dev
JT  - Journal of medical education and curricular development
JID - 101690298
PMC - PMC10938614
OTO - NOTNLM
OT  - ChatGPT
OT  - academic performance
OT  - artificial intelligence
OT  - digital health
OT  - medical education
OT  - medicine
COIS- The author(s) declared no potential conflicts of interest with respect to the 
      research, authorship, and/or publication of this article.
EDAT- 2024/03/15 06:43
MHDA- 2024/03/15 06:44
PMCR- 2024/03/13
CRDT- 2024/03/15 04:06
PHST- 2023/10/31 00:00 [received]
PHST- 2024/02/25 00:00 [accepted]
PHST- 2024/03/15 06:44 [medline]
PHST- 2024/03/15 06:43 [pubmed]
PHST- 2024/03/15 04:06 [entrez]
PHST- 2024/03/13 00:00 [pmc-release]
AID - 10.1177_23821205241238641 [pii]
AID - 10.1177/23821205241238641 [doi]
PST - epublish
SO  - J Med Educ Curric Dev. 2024 Mar 13;11:23821205241238641. doi: 
      10.1177/23821205241238641. eCollection 2024 Jan-Dec.

PMID- 37332002
OWN - NLM
STAT- MEDLINE
DCOM- 20231124
LR  - 20231124
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 51
IP  - 12
DP  - 2023 Dec
TI  - The Potential of ChatGPT in Assisting Children with Down Syndrome.
PG  - 2638-2640
LID - 10.1007/s10439-023-03281-3 [doi]
AB  - ChatGPT, an advanced language generation model developed by OpenAI, has the 
      potential to revolutionize healthcare delivery and support for individuals with 
      various conditions, including Down syndrome. This article explores the 
      applications of ChatGPT in assisting children with Down syndrome, highlighting 
      the benefits it can bring to their education, social interaction, and overall 
      well-being. While acknowledging the challenges and limitations, we examine how 
      ChatGPT can be utilized as a valuable tool in enhancing the lives of these 
      children, promoting their cognitive development, and supporting their unique 
      needs.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Yang, Jing
AU  - Yang J
AD  - Department of Computer System and Technology, Faculty of Computer Science and 
      Information Technology, Universiti Malaya, 50603, Kuala Lumpur, Malaysia.
FAU - Por, Lip Yee
AU  - Por LY
AD  - Department of Computer System and Technology, Faculty of Computer Science and 
      Information Technology, Universiti Malaya, 50603, Kuala Lumpur, Malaysia. 
      porlip@um.edu.my.
FAU - Leong, Ming Chern
AU  - Leong MC
AD  - Paediatric &amp; Congenital Heart Centre, Institut Jantung Negara, 145, Jalan Tun 
      Razak, 51200, Kuala Lumpur, Malaysia. mcleong@ijn.com.my.
FAU - Ku, Chin Soon
AU  - Ku CS
AUID- ORCID: 0000-0003-0793-3308
AD  - Department of Computer Science, Universiti Tunku Abdul Rahman, 31900, Kampar, 
      Malaysia. kucs@utar.edu.my.
LA  - eng
PT  - Letter
DEP - 20230618
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - Child
MH  - Humans
MH  - *Down Syndrome
MH  - *Artificial Intelligence
OTO - NOTNLM
OT  - ChatGPT
OT  - Down syndrome
OT  - Education
OT  - Learning
OT  - Social interaction
EDAT- 2023/06/19 00:42
MHDA- 2023/11/09 06:41
CRDT- 2023/06/18 23:35
PHST- 2023/06/04 00:00 [received]
PHST- 2023/06/13 00:00 [accepted]
PHST- 2023/11/09 06:41 [medline]
PHST- 2023/06/19 00:42 [pubmed]
PHST- 2023/06/18 23:35 [entrez]
AID - 10.1007/s10439-023-03281-3 [pii]
AID - 10.1007/s10439-023-03281-3 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2023 Dec;51(12):2638-2640. doi: 10.1007/s10439-023-03281-3. Epub 
      2023 Jun 18.

PMID- 37255525
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230918
IS  - 2382-1205 (Print)
IS  - 2382-1205 (Electronic)
IS  - 2382-1205 (Linking)
VI  - 10
DP  - 2023 Jan-Dec
TI  - Practical Applications of ChatGPT in Undergraduate Medical Education.
PG  - 23821205231178449
LID - 10.1177/23821205231178449 [doi]
LID - 23821205231178449
AB  - ChatGPT is a chatbot developed by OpenAI that has garnered significant attention 
      for achieving at or near a passing standard on the United States Medical 
      Licensing Exam (USMLE). Currently, researchers and users are exploring ChatGPT's 
      broad range of potential applications in academia, business, programming, and 
      beyond. We attempt outline how ChatGPT may be applied to support undergraduate 
      medical education during the preclinical and clinical years, and highlight 
      possible concerns regarding its use which necessitates the creation of formal 
      policies and training by medical schools.
CI  - © The Author(s) 2023.
FAU - Tsang, Ricky
AU  - Tsang R
AD  - Department of Medicine, Faculty of Medicine, University of British Columbia, 
      Vancouver, BC, Canada. RINGGOLD: 12358
LA  - eng
PT  - Journal Article
DEP - 20230524
PL  - United States
TA  - J Med Educ Curric Dev
JT  - Journal of medical education and curricular development
JID - 101690298
PMC - PMC10226299
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - Medical education
OT  - UGME
OT  - chatbot
COIS- The author declared no potential conflicts of interest with respect to the 
      research, authorship, and/or publication of this article.
EDAT- 2023/05/31 13:11
MHDA- 2023/05/31 13:12
PMCR- 2023/05/24
CRDT- 2023/05/31 10:23
PHST- 2023/03/24 00:00 [received]
PHST- 2023/05/10 00:00 [accepted]
PHST- 2023/05/31 13:11 [pubmed]
PHST- 2023/05/31 13:12 [medline]
PHST- 2023/05/31 10:23 [entrez]
PHST- 2023/05/24 00:00 [pmc-release]
AID - 10.1177_23821205231178449 [pii]
AID - 10.1177/23821205231178449 [doi]
PST - epublish
SO  - J Med Educ Curric Dev. 2023 May 24;10:23821205231178449. doi: 
      10.1177/23821205231178449. eCollection 2023 Jan-Dec.

PMID- 37529853
OWN - NLM
STAT- Publisher
LR  - 20230802
IS  - 1097-6817 (Electronic)
IS  - 0194-5998 (Linking)
DP  - 2023 Aug 2
TI  - Head-to-Head Comparison of ChatGPT Versus Google Search for Medical Knowledge 
      Acquisition.
LID - 10.1002/ohn.465 [doi]
AB  - OBJECTIVE: Chat Generative Pretrained Transformer (ChatGPT) is the newest 
      iteration of OpenAI's generative artificial intelligence (AI) with the potential 
      to influence many facets of life, including health care. This study sought to 
      assess ChatGPT's capabilities as a source of medical knowledge, using Google 
      Search as a comparison. STUDY DESIGN: Cross-sectional analysis. SETTING: Online 
      using ChatGPT, Google Seach, and Clinical Practice Guidelines (CPG). METHODS: CPG 
      Plain Language Summaries for 6 conditions were obtained. Questions relevant to 
      specific conditions were developed and input into ChatGPT and Google Search. All 
      questions were written from the patient perspective and sought (1) general 
      medical knowledge or (2) medical recommendations, with varying levels of acuity 
      (urgent or emergent vs routine clinical scenarios). Two blinded reviewers scored 
      all passages and compared results from ChatGPT and Google Search, using the 
      Patient Education Material Assessment Tool (PEMAT-P) as the primary outcome. 
      Additional customized questions were developed that assessed the medical content 
      of the passages. RESULTS: The overall average PEMAT-P score for medical advice 
      was 68.2% (standard deviation [SD]: 4.4) for ChatGPT and 89.4% (SD: 5.9) for 
      Google Search (p &lt; .001). There was a statistically significant difference in the 
      PEMAT-P score by source (p &lt; .001) but not by urgency of the clinical situation 
      (p = .613). ChatGPT scored significantly higher than Google Search (87% vs 78%, 
      p = .012) for patient education questions. CONCLUSION: ChatGPT fared better than 
      Google Search when offering general medical knowledge, but it scored worse when 
      providing medical recommendations. Health care providers should strive to 
      understand the potential benefits and ramifications of generative AI to guide 
      patients appropriately.
CI  - © 2023 American Academy of Otolaryngology-Head and Neck Surgery Foundation.
FAU - Ayoub, Noel F
AU  - Ayoub NF
AUID- ORCID: 0000-0003-1867-994X
AD  - Department of Otolaryngology-Head and Neck Surgery, Division of Head &amp; Neck 
      Surgery, Stanford University School of Medicine, Stanford, California, USA.
FAU - Lee, Yu-Jin
AU  - Lee YJ
AD  - Department of Otolaryngology-Head and Neck Surgery, Division of Head &amp; Neck 
      Surgery, Stanford University School of Medicine, Stanford, California, USA.
FAU - Grimm, David
AU  - Grimm D
AD  - Department of Otolaryngology-Head and Neck Surgery, Division of Head &amp; Neck 
      Surgery, Stanford University School of Medicine, Stanford, California, USA.
FAU - Divi, Vasu
AU  - Divi V
AD  - Department of Otolaryngology-Head and Neck Surgery, Division of Head &amp; Neck 
      Surgery, Stanford University School of Medicine, Stanford, California, USA.
LA  - eng
PT  - Journal Article
DEP - 20230802
PL  - England
TA  - Otolaryngol Head Neck Surg
JT  - Otolaryngology--head and neck surgery : official journal of American Academy of 
      Otolaryngology-Head and Neck Surgery
JID - 8508176
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - generative artificial intelligence
OT  - health literacy
OT  - large language models
OT  - online search engines
OT  - patient education
EDAT- 2023/08/02 06:42
MHDA- 2023/08/02 06:42
CRDT- 2023/08/02 04:13
PHST- 2023/07/07 00:00 [revised]
PHST- 2023/03/19 00:00 [received]
PHST- 2023/07/14 00:00 [accepted]
PHST- 2023/08/02 06:42 [medline]
PHST- 2023/08/02 06:42 [pubmed]
PHST- 2023/08/02 04:13 [entrez]
AID - 10.1002/ohn.465 [doi]
PST - aheadofprint
SO  - Otolaryngol Head Neck Surg. 2023 Aug 2. doi: 10.1002/ohn.465.

PMID- 37494894
OWN - NLM
STAT- MEDLINE
DCOM- 20231127
LR  - 20231127
IS  - 1423-002X (Electronic)
IS  - 0378-7346 (Linking)
VI  - 88
IP  - 5
DP  - 2023
TI  - Diagnostic and Management Performance of ChatGPT in Obstetrics and Gynecology.
PG  - 310-313
LID - 10.1159/000533177 [doi]
AB  - OBJECTIVES: The use of artificial intelligence (AI) in clinical patient 
      management and medical education has been advancing over time. ChatGPT was 
      developed and trained recently, using a large quantity of textual data from the 
      internet. Medical science is expected to be transformed by its use. The present 
      study was conducted to evaluate the diagnostic and management performance of the 
      ChatGPT AI model in obstetrics and gynecology. DESIGN: A cross-sectional study 
      was conducted. PARTICIPANTS/MATERIALS, SETTING, METHODS: This study was conducted 
      in Iran in March 2023. Medical histories and examination results of 30 cases were 
      determined in six areas of obstetrics and gynecology. The cases were presented to 
      a gynecologist and ChatGPT for diagnosis and management. Answers from the 
      gynecologist and ChatGPT were compared, and the diagnostic and management 
      performance of ChatGPT were determined. RESULTS: Ninety percent (27 of 30) of the 
      cases in obstetrics and gynecology were correctly handled by ChatGPT. Its 
      responses were eloquent, informed, and free of a significant number of errors or 
      misinformation. Even when the answers provided by ChatGPT were incorrect, the 
      responses contained a logical explanation about the case as well as information 
      provided in the question stem. LIMITATIONS: The data used in this study were 
      taken from the electronic book and may reflect bias in the diagnosis of ChatGPT. 
      CONCLUSIONS: This is the first evaluation of ChatGPT's performance in diagnosis 
      and management in the field of obstetrics and gynecology. It appears that ChatGPT 
      has potential applications in the practice of medicine and is (currently) free 
      and simple to use. However, several ethical considerations and limitations such 
      as bias, validity, copyright infringement, and plagiarism need to be addressed in 
      future studies.
CI  - © 2023 S. Karger AG, Basel.
FAU - Allahqoli, Leila
AU  - Allahqoli L
AD  - Midwifery Department, Ministry of Health and Medical Education, Tehran, Iran, 
      lallahqoli@gmail.com.
FAU - Ghiasvand, Mohammad Matin
AU  - Ghiasvand MM
AD  - Department of Computer Engineering, Amirkabir University of Technology (AUT), 
      Tehran, Iran.
FAU - Mazidimoradi, Afrooz
AU  - Mazidimoradi A
AD  - Student Research Committee, Shiraz University of Medical Sciences, Shiraz, Iran.
FAU - Salehiniya, Hamid
AU  - Salehiniya H
AD  - Social Determinants of Health Research Center, Birjand University of Medical 
      Sciences, Birjand, Iran.
FAU - Alkatout, Ibrahim
AU  - Alkatout I
AD  - Campus Kiel, Kiel School of Gynaecological Endoscopy, University Hospitals 
      Schleswig-Holstein, Kiel, Germany.
LA  - eng
PT  - News
DEP - 20230726
PL  - Switzerland
TA  - Gynecol Obstet Invest
JT  - Gynecologic and obstetric investigation
JID - 7900587
SB  - IM
MH  - Female
MH  - Pregnancy
MH  - Humans
MH  - *Gynecology
MH  - Artificial Intelligence
MH  - Cross-Sectional Studies
MH  - *Obstetrics
MH  - Gynecologists
OTO - NOTNLM
OT  - Artificial intelligence model
OT  - ChatGPT
OT  - Diagnostic performance
OT  - Gynecology
OT  - Management
OT  - Obstetrics
EDAT- 2023/07/27 01:09
MHDA- 2023/11/27 12:41
CRDT- 2023/07/26 18:23
PHST- 2023/05/19 00:00 [received]
PHST- 2023/07/20 00:00 [accepted]
PHST- 2023/11/27 12:41 [medline]
PHST- 2023/07/27 01:09 [pubmed]
PHST- 2023/07/26 18:23 [entrez]
AID - 000533177 [pii]
AID - 10.1159/000533177 [doi]
PST - ppublish
SO  - Gynecol Obstet Invest. 2023;88(5):310-313. doi: 10.1159/000533177. Epub 2023 Jul 
      26.

PMID- 38440148
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240306
IS  - 2312-7996 (Electronic)
IS  - 2312-7996 (Linking)
VI  - 13
DP  - 2023
TI  - Accelerating medical education with ChatGPT: an implementation guide.
PG  - 64
LID - 10.12688/mep.19732.2 [doi]
LID - 64
AB  - Chatbots powered by artificial intelligence have revolutionized many industries 
      and fields of study, including medical education. Medical educators are 
      increasingly asked to perform more administrative, written, and assessment 
      functions with less time and resources. Safe use of chatbots, like ChatGPT, can 
      help medical educators efficiently perform these functions. In this article, we 
      provide medical educators with tips for the implementation of ChatGPT in medical 
      education. Through creativity and careful construction of prompts, medical 
      educators can use these and other implementations of chatbots, like ChatGPT, in 
      their practice.
CI  - Copyright: © 2023 Peacock J et al.
FAU - Peacock, Justin
AU  - Peacock J
AUID- ORCID: 0000-0003-1510-8367
AD  - Department of Radiology and Radiological Sciences, Uniformed Services University, 
      Bethesda, MD, USA.
FAU - Austin, Andrea
AU  - Austin A
AD  - Department of Military and Emergency Medicine, Uniformed Services University, 
      Bethesda, MD, USA.
AD  - UHS Southern California Education Consortium, Temecula, CA, USA.
FAU - Shapiro, Marina
AU  - Shapiro M
AD  - Center for Health Professions Education, Uniformed Services University, Bethesda, 
      MD, USA.
FAU - Battista, Alexis
AU  - Battista A
AD  - Center for Health Professions Education, Uniformed Services University, Bethesda, 
      MD, USA.
FAU - Samuel, Anita
AU  - Samuel A
AUID- ORCID: 0000-0001-9488-9565
AD  - Center for Health Professions Education, Uniformed Services University, Bethesda, 
      MD, USA.
LA  - eng
PT  - Journal Article
DEP - 20231121
PL  - Scotland
TA  - MedEdPublish (2016)
JT  - MedEdPublish (2016)
JID - 9918418288706676
PMC - PMC10910173
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - generative AI
OT  - medical education
COIS- Competing interests: Anita Samuel is a member of the MedEdPublish Advisory Board. 
      This had no influence on the decision to publish or in any part of the peer 
      review process.
EDAT- 2024/03/05 06:45
MHDA- 2024/03/05 06:46
PMCR- 2023/11/21
CRDT- 2024/03/05 03:51
PHST- 2023/11/17 00:00 [accepted]
PHST- 2024/03/05 06:46 [medline]
PHST- 2024/03/05 06:45 [pubmed]
PHST- 2024/03/05 03:51 [entrez]
PHST- 2023/11/21 00:00 [pmc-release]
AID - 10.12688/mep.19732.2 [doi]
PST - epublish
SO  - MedEdPublish (2016). 2023 Nov 21;13:64. doi: 10.12688/mep.19732.2. eCollection 
      2023.

PMID- 38090452
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231213
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 11
DP  - 2023 Nov
TI  - A Strengths, Weaknesses, Opportunities, and Threats (SWOT) Analysis of ChatGPT 
      Integration in Nursing Education: A Narrative Review.
PG  - e48643
LID - 10.7759/cureus.48643 [doi]
LID - e48643
AB  - Amidst evolving healthcare demands, nursing education plays a pivotal role in 
      preparing future nurses for complex challenges. Traditional approaches, however, 
      must be revised to meet modern healthcare needs. The ChatGPT, an AI-based 
      chatbot, has garnered significant attention due to its ability to personalize 
      learning experiences, enhance virtual clinical simulations, and foster 
      collaborative learning in nursing education. This review aims to thoroughly 
      assess the potential impact of integrating ChatGPT into nursing education. The 
      hypothesis is that valuable insights can be provided for stakeholders through a 
      comprehensive SWOT analysis examining the strengths, weaknesses, opportunities, 
      and threats associated with ChatGPT. This will enable informed decisions about 
      its integration, prioritizing improved learning outcomes. A thorough narrative 
      literature review was undertaken to provide a solid foundation for the SWOT 
      analysis. The materials included scholarly articles and reports, which ensure the 
      study's credibility and allow for a holistic and unbiased assessment. The 
      analysis identified accessibility, consistency, adaptability, cost-effectiveness, 
      and staying up-to-date as crucial factors influencing the strengths, weaknesses, 
      opportunities, and threats associated with ChatGPT integration in nursing 
      education. These themes provided a framework to understand the potential risks 
      and benefits of integrating ChatGPT into nursing education. This review 
      highlights the importance of responsible and effective use of ChatGPT in nursing 
      education and the need for collaboration among educators, policymakers, and AI 
      developers. Addressing the identified challenges and leveraging the strengths of 
      ChatGPT can lead to improved learning outcomes and enriched educational 
      experiences for students. The findings emphasize the importance of responsibly 
      integrating ChatGPT in nursing education, balancing technological advancement 
      with careful consideration of associated risks, to achieve optimal outcomes.
CI  - Copyright © 2023, Abujaber et al.
FAU - Abujaber, Ahmad A
AU  - Abujaber AA
AD  - Department of Nursing, Hamad Medical Corporation, Doha, QAT.
FAU - Abd-Alrazaq, Alaa
AU  - Abd-Alrazaq A
AD  - AI Center for Precision Health, Weill Cornell Medicine-Qatar, Doha, QAT.
FAU - Al-Qudimat, Ahmad R
AU  - Al-Qudimat AR
AD  - Department of Public Health, Qatar University, Doha, QAT.
AD  - Surgical Research Section, Department of Surgery, Hamad Medical Corporation, 
      Doha, QAT.
FAU - Nashwan, Abdulqadir J
AU  - Nashwan AJ
AD  - Department of Nursing, Hamad Medical Corporation, Doha, QAT.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20231111
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10711690
OTO - NOTNLM
OT  - chatgpt
OT  - gpt-4
OT  - large language models
OT  - nursing education
OT  - swot analysis
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/12/13 18:42
MHDA- 2023/12/13 18:43
PMCR- 2023/11/11
CRDT- 2023/12/13 13:08
PHST- 2023/11/11 00:00 [accepted]
PHST- 2023/12/13 18:43 [medline]
PHST- 2023/12/13 18:42 [pubmed]
PHST- 2023/12/13 13:08 [entrez]
PHST- 2023/11/11 00:00 [pmc-release]
AID - 10.7759/cureus.48643 [doi]
PST - epublish
SO  - Cureus. 2023 Nov 11;15(11):e48643. doi: 10.7759/cureus.48643. eCollection 2023 
      Nov.

PMID- 38304767
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240203
IS  - 2405-8440 (Print)
IS  - 2405-8440 (Electronic)
IS  - 2405-8440 (Linking)
VI  - 10
IP  - 2
DP  - 2024 Jan 30
TI  - ChatGPT in finance: Applications, challenges, and solutions.
PG  - e24890
LID - 10.1016/j.heliyon.2024.e24890 [doi]
LID - e24890
AB  - The emergence of ChatGPT, a generative artificial intelligence tool, has sparked 
      a revolution in the finance industry, enabling individuals to interact with 
      technology in natural language. However, the use of ChatGPT in finance presents a 
      profound array of ethical considerations that demand careful scrutiny to ensure 
      its responsible and ethical use. After a concise exploration of ChatGPT's 
      applications in finance, this policy article delves into the ethical challenges 
      arising from the use of ChatGPT in finance, including outcomes contaminated with 
      biases, incorporation of fake information in the financial decisions, concerns 
      surrounding privacy and security, lack of transparency and accountability in the 
      decision-making processes and financial services, human job displacement, and the 
      intricate web of legal complexities. Our article asserts that financial 
      institutions employing ChatGPT must proactively devise strategies to confront 
      these burgeoning challenges, mitigating their adverse effects on both individuals 
      and society as a whole. Additionally, we propose relevant policies to tackle 
      these ethical quandaries head-on. In essence, this article illuminates the 
      imperative need for a meticulous ethical framework, facilitating an informed and 
      responsible use of ChatGPT in the realm of finance, safeguarding the welfare of 
      individuals and society. While our work significantly contributes to the research 
      and practice of finance, we also identify future research avenues.
CI  - © 2024 The Authors.
FAU - Khan, Muhammad Salar
AU  - Khan MS
AD  - Schar School of Policy and Government, George Mason University, USA.
FAU - Umer, Hamza
AU  - Umer H
AD  - Hitotsubashi Institute for Advanced Study (HIAS), Institute of Economic Research 
      (IER), Hitotsubashi University, Japan.
LA  - eng
PT  - Journal Article
DEP - 20240117
PL  - England
TA  - Heliyon
JT  - Heliyon
JID - 101672560
PMC - PMC10831748
OTO - NOTNLM
OT  - Applications
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Ethical challenges
OT  - Finance
OT  - Policies
COIS- The authors declare that they have no known competing financial interests or 
      personal relationships that could have appeared to influence the work reported in 
      this paper.
EDAT- 2024/02/02 06:43
MHDA- 2024/02/02 06:44
PMCR- 2024/01/17
CRDT- 2024/02/02 04:13
PHST- 2023/05/15 00:00 [received]
PHST- 2023/12/13 00:00 [revised]
PHST- 2024/01/16 00:00 [accepted]
PHST- 2024/02/02 06:44 [medline]
PHST- 2024/02/02 06:43 [pubmed]
PHST- 2024/02/02 04:13 [entrez]
PHST- 2024/01/17 00:00 [pmc-release]
AID - S2405-8440(24)00921-6 [pii]
AID - e24890 [pii]
AID - 10.1016/j.heliyon.2024.e24890 [doi]
PST - epublish
SO  - Heliyon. 2024 Jan 17;10(2):e24890. doi: 10.1016/j.heliyon.2024.e24890. 
      eCollection 2024 Jan 30.

PMID- 37387301
OWN - NLM
STAT- MEDLINE
DCOM- 20230703
LR  - 20230703
IS  - 1120-9763 (Print)
IS  - 1120-9763 (Linking)
VI  - 47
IP  - 3
DP  - 2023 May-Jun
TI  - [ChatGPT in scientific research: a guide to informed use].
PG  - 203-207
LID - 10.19191/EP23.3.A639.051 [doi]
AB  - Using ChatGPT in scientific research offers revolutionary opportunities thanks to 
      its natural language interaction capabilities and production of coherent and 
      sophisticated text.Artificial intelligence can automate activities such as 
      information synthesis and schematization, improving scientific communication and 
      computer code writing.However, the lack of a complete understanding of context, 
      the risk of spreading misleading information, and the possibility of plagiarism 
      represent some of the biggest limitations in the current use of this 
      technology.The role of human experience remains fundamental for in-depth 
      understanding of context, exercising critical thinking, and ensuring respect for 
      the ethical principles of scientific research.A responsible and aware use of 
      tools such as ChatGPT can offer great benefits to the scientific community, but 
      it is essential to remember that these tools are only a support and cannot 
      replace human judgment and experience.
FAU - Ferrante, Gianluigi
AU  - Ferrante G
AD  - SSD epidemiologia screening, AOU Città della salute e della scienza di Torino, 
      CPO Piemonte, Torino; gianluigi.ferrante@iss.it.
FAU - Lanera, Corrado
AU  - Lanera C
AD  - Unità di biostatistica, epidemiologia e sanità pubblica, Università degli studi 
      di Padova.
LA  - ita
PT  - English Abstract
PT  - Journal Article
TT  - ChatGPT nella ricerca scientifica: guida all’uso consapevole.
PL  - Italy
TA  - Epidemiol Prev
JT  - Epidemiologia e prevenzione
JID - 8902507
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Italy
MH  - *Communication
MH  - Exercise
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGpt
OT  - Ethical implications
OT  - Large language models
OT  - Scientific research
EDAT- 2023/06/30 13:11
MHDA- 2023/07/03 06:41
CRDT- 2023/06/30 06:14
PHST- 2023/07/03 06:41 [medline]
PHST- 2023/06/30 13:11 [pubmed]
PHST- 2023/06/30 06:14 [entrez]
AID - 10.19191/EP23.3.A639.051 [doi]
PST - ppublish
SO  - Epidemiol Prev. 2023 May-Jun;47(3):203-207. doi: 10.19191/EP23.3.A639.051.

PMID- 37976385
OWN - NLM
STAT- MEDLINE
DCOM- 20240122
LR  - 20240131
IS  - 1940-5480 (Electronic)
IS  - 1067-151X (Linking)
VI  - 32
IP  - 3
DP  - 2024 Feb 1
TI  - ChatGPT's Ability to Assist with Clinical Documentation: A Randomized Controlled 
      Trial.
PG  - 123-129
LID - 10.5435/JAAOS-D-23-00474 [doi]
AB  - INTRODUCTION: Clinical documentation is a critical aspect of health care that 
      enables healthcare providers to communicate effectively with each other and 
      maintain accurate patient care records. Artificial intelligence tools, such as 
      chatbots and virtual assistants, have the potential to assist healthcare 
      providers in clinical documentation. ChatGPT is an artificial intelligence 
      conversational model that generates human-like responses to text-based prompts. 
      In this study, we sought to investigate ChatGPT's ability to assist with writing 
      a history of present illness based on standardized patient histories. METHODS: A 
      blinded, randomized controlled study was conducted to compare the use of typing, 
      dictation, and ChatGPT as tools to document history of present illness (HPI) of 
      standardized patient histories. Eleven study participants, consisting of medical 
      students, orthopaedic surgery residents, and attending surgeons, completed three 
      HPIs using a different documentation technique for each one. Participants were 
      randomized into cohorts based on the type of documentation technique. 
      Participants were asked to interview standardized patients and document the 
      patient's history of present illness using their assigned method. RESULTS: 
      ChatGPT was found to be intermediate for speed; dictation was fastest, but 
      produced markedly longer and higher quality patient histories based on Physician 
      Documentation Quality Instrument score compared with dictation and typing. 
      However, ChatGPT included erroneous information in 36% of the documents. Poor 
      agreement existed on the quality of patient histories between reviewers. 
      DISCUSSION: Our study suggests that ChatGPT has the potential to improve clinical 
      documentation by producing more comprehensive and organized HPIs. ChatGPT can 
      generate longer and more detailed documentation compared with typing or dictation 
      documentation methods. However, additional studies are needed to investigate and 
      address concerns regarding privacy, bias, and accuracy of information.
CI  - Copyright © 2023 by the American Academy of Orthopaedic Surgeons.
FAU - Baker, Hayden P
AU  - Baker HP
AUID- ORCID: 0000-0002-9306-7006
AD  - From the Department of Orthopaedic Surgery, University of Chicago, Chicago, IL.
FAU - Dwyer, Emma
AU  - Dwyer E
FAU - Kalidoss, Senthooran
AU  - Kalidoss S
FAU - Hynes, Kelly
AU  - Hynes K
FAU - Wolf, Jennifer
AU  - Wolf J
FAU - Strelzow, Jason A
AU  - Strelzow JA
LA  - eng
PT  - Journal Article
PT  - Randomized Controlled Trial
DEP - 20231117
PL  - United States
TA  - J Am Acad Orthop Surg
JT  - The Journal of the American Academy of Orthopaedic Surgeons
JID - 9417468
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Communication
MH  - Documentation
MH  - Health Facilities
MH  - *Surgeons
EDAT- 2023/11/17 18:42
MHDA- 2024/01/22 06:42
CRDT- 2023/11/17 14:23
PHST- 2023/05/23 00:00 [received]
PHST- 2023/09/29 00:00 [accepted]
PHST- 2024/01/22 06:42 [medline]
PHST- 2023/11/17 18:42 [pubmed]
PHST- 2023/11/17 14:23 [entrez]
AID - 00124635-990000000-00834 [pii]
AID - 10.5435/JAAOS-D-23-00474 [doi]
PST - ppublish
SO  - J Am Acad Orthop Surg. 2024 Feb 1;32(3):123-129. doi: 10.5435/JAAOS-D-23-00474. 
      Epub 2023 Nov 17.

PMID- 38155661
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231230
IS  - 2296-858X (Print)
IS  - 2296-858X (Electronic)
IS  - 2296-858X (Linking)
VI  - 10
DP  - 2023
TI  - ChatGPT's performance in German OB/GYN exams - paving the way for AI-enhanced 
      medical education and clinical practice.
PG  - 1296615
LID - 10.3389/fmed.2023.1296615 [doi]
LID - 1296615
AB  - BACKGROUND: Chat Generative Pre-Trained Transformer (ChatGPT) is an artificial 
      learning and large language model tool developed by OpenAI in 2022. It utilizes 
      deep learning algorithms to process natural language and generate responses, 
      which renders it suitable for conversational interfaces. ChatGPT's potential to 
      transform medical education and clinical practice is currently being explored, 
      but its capabilities and limitations in this domain remain incompletely 
      investigated. The present study aimed to assess ChatGPT's performance in medical 
      knowledge competency for problem assessment in obstetrics and gynecology 
      (OB/GYN). METHODS: Two datasets were established for analysis: questions (1) from 
      OB/GYN course exams at a German university hospital and (2) from the German 
      medical state licensing exams. In order to assess ChatGPT's performance, 
      questions were entered into the chat interface, and responses were documented. A 
      quantitative analysis compared ChatGPT's accuracy with that of medical students 
      for different levels of difficulty and types of questions. Additionally, a 
      qualitative analysis assessed the quality of ChatGPT's responses regarding ease 
      of understanding, conciseness, accuracy, completeness, and relevance. Non-obvious 
      insights generated by ChatGPT were evaluated, and a density index of insights was 
      established in order to quantify the tool's ability to provide students with 
      relevant and concise medical knowledge. RESULTS: ChatGPT demonstrated consistent 
      and comparable performance across both datasets. It provided correct responses at 
      a rate comparable with that of medical students, thereby indicating its ability 
      to handle a diverse spectrum of questions ranging from general knowledge to 
      complex clinical case presentations. The tool's accuracy was partly affected by 
      question difficulty in the medical state exam dataset. Our qualitative assessment 
      revealed that ChatGPT provided mostly accurate, complete, and relevant answers. 
      ChatGPT additionally provided many non-obvious insights, especially in correctly 
      answered questions, which indicates its potential for enhancing autonomous 
      medical learning. CONCLUSION: ChatGPT has promise as a supplementary tool in 
      medical education and clinical practice. Its ability to provide accurate and 
      insightful responses showcases its adaptability to complex clinical scenarios. As 
      AI technologies continue to evolve, ChatGPT and similar tools may contribute to 
      more efficient and personalized learning experiences and assistance for health 
      care providers.
CI  - Copyright © 2023 Riedel, Kaefinger, Stuehrenberg, Ritter, Amann, Graf, Recker, 
      Klein, Kiechle, Riedel and Meyer.
FAU - Riedel, Maximilian
AU  - Riedel M
AD  - Department of Gynecology and Obstetrics, Klinikum Rechts der Isar, Technical 
      University Munich (TU), Munich, Germany.
FAU - Kaefinger, Katharina
AU  - Kaefinger K
AD  - Department of Gynecology and Obstetrics, Klinikum Rechts der Isar, Technical 
      University Munich (TU), Munich, Germany.
FAU - Stuehrenberg, Antonia
AU  - Stuehrenberg A
AD  - Department of Gynecology and Obstetrics, Klinikum Rechts der Isar, Technical 
      University Munich (TU), Munich, Germany.
FAU - Ritter, Viktoria
AU  - Ritter V
AD  - Department of Gynecology and Obstetrics, Klinikum Rechts der Isar, Technical 
      University Munich (TU), Munich, Germany.
FAU - Amann, Niklas
AU  - Amann N
AD  - Department of Gynecology and Obstetrics, Friedrich-Alexander-University 
      Erlangen-Nuremberg (FAU), Erlangen, Germany.
FAU - Graf, Anna
AU  - Graf A
AD  - Department of Gynecology and Obstetrics, Klinikum Rechts der Isar, Technical 
      University Munich (TU), Munich, Germany.
FAU - Recker, Florian
AU  - Recker F
AD  - Department of Gynecology and Obstetrics, Bonn University Hospital, Bonn, Germany.
FAU - Klein, Evelyn
AU  - Klein E
AD  - Department of Gynecology and Obstetrics, Klinikum Rechts der Isar, Technical 
      University Munich (TU), Munich, Germany.
FAU - Kiechle, Marion
AU  - Kiechle M
AD  - Department of Gynecology and Obstetrics, Klinikum Rechts der Isar, Technical 
      University Munich (TU), Munich, Germany.
FAU - Riedel, Fabian
AU  - Riedel F
AD  - Department of Gynecology and Obstetrics, Heidelberg University Hospital, 
      Heidelberg, Germany.
FAU - Meyer, Bastian
AU  - Meyer B
AD  - Department of Gynecology and Obstetrics, Klinikum Rechts der Isar, Technical 
      University Munich (TU), Munich, Germany.
LA  - eng
PT  - Journal Article
DEP - 20231213
PL  - Switzerland
TA  - Front Med (Lausanne)
JT  - Frontiers in medicine
JID - 101648047
PMC - PMC10753765
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - machine learning
OT  - medical education
OT  - obstetrics and gynecology
OT  - students
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2024/01/02 10:02
MHDA- 2024/01/02 10:03
PMCR- 2023/12/13
CRDT- 2023/12/29 03:35
PHST- 2023/09/18 00:00 [received]
PHST- 2023/11/27 00:00 [accepted]
PHST- 2024/01/02 10:03 [medline]
PHST- 2024/01/02 10:02 [pubmed]
PHST- 2023/12/29 03:35 [entrez]
PHST- 2023/12/13 00:00 [pmc-release]
AID - 10.3389/fmed.2023.1296615 [doi]
PST - epublish
SO  - Front Med (Lausanne). 2023 Dec 13;10:1296615. doi: 10.3389/fmed.2023.1296615. 
      eCollection 2023.

PMID- 38419827
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240301
IS  - 2210-5433 (Print)
IS  - 2210-5441 (Electronic)
IS  - 2210-5433 (Linking)
VI  - 37
IP  - 1
DP  - 2024
TI  - Authorship and ChatGPT: a Conservative View.
PG  - 34
LID - 10.1007/s13347-024-00715-1 [doi]
LID - 34
AB  - Is ChatGPT an author?&nbsp;Given its capacity to generate something that reads like 
      human-written text in response to prompts, it might seem natural to ascribe 
      authorship to ChatGPT. However, we argue that ChatGPT is not an author. ChatGPT 
      fails to meet the criteria of authorship because it lacks the ability to perform 
      illocutionary speech acts such as promising or asserting, lacks the fitting 
      mental states like knowledge, belief, or intention, and cannot take 
      responsibility for the texts it produces. Three perspectives are compared: 
      liberalism (which ascribes authorship to ChatGPT), conservatism (which denies 
      ChatGPT's authorship for normative and metaphysical reasons), and moderatism 
      (which treats ChatGPT as if it possesses authorship without committing to the 
      existence of mental states like knowledge, belief, or intention). We conclude 
      that conservatism provides a more nuanced understanding of authorship in AI than 
      liberalism and moderatism, without denying the significant potential, influence, 
      or utility of AI technologies such as ChatGPT.
CI  - © The Author(s) 2024.
FAU - van Woudenberg, René
AU  - van Woudenberg R
AUID- ORCID: 0000-0002-1169-6539
AD  - Department of Philosophy, Vrije Universiteit, Amsterdam, Netherlands. GRID: 
      grid.12380.38. ISNI: 0000 0004 1754 9227
FAU - Ranalli, Chris
AU  - Ranalli C
AUID- ORCID: 0000-0002-5652-4829
AD  - Department of Philosophy, Vrije Universiteit, Amsterdam, Netherlands. GRID: 
      grid.12380.38. ISNI: 0000 0004 1754 9227
FAU - Bracker, Daniel
AU  - Bracker D
AD  - Department of Philosophy, Vrije Universiteit, Amsterdam, Netherlands. GRID: 
      grid.12380.38. ISNI: 0000 0004 1754 9227
LA  - eng
PT  - Journal Article
DEP - 20240226
PL  - Netherlands
TA  - Philos Technol
JT  - Philosophy &amp; technology
JID - 101583724
PMC - PMC10896910
OTO - NOTNLM
OT  - AI
OT  - Agency
OT  - Assertion
OT  - Authorship
OT  - ChatGPT
OT  - Conservativism
OT  - Intention
OT  - Normativity
OT  - Promising
COIS- Competing InterestsThe authors have no relevant financial or non-financial 
      interests to disclose.
EDAT- 2024/02/29 06:43
MHDA- 2024/02/29 06:44
PMCR- 2024/02/26
CRDT- 2024/02/29 03:57
PHST- 2023/08/09 00:00 [received]
PHST- 2024/02/05 00:00 [accepted]
PHST- 2024/02/29 06:44 [medline]
PHST- 2024/02/29 06:43 [pubmed]
PHST- 2024/02/29 03:57 [entrez]
PHST- 2024/02/26 00:00 [pmc-release]
AID - 715 [pii]
AID - 10.1007/s13347-024-00715-1 [doi]
PST - ppublish
SO  - Philos Technol. 2024;37(1):34. doi: 10.1007/s13347-024-00715-1. Epub 2024 Feb 26.

PMID- 37986988
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240311
DP  - 2023 Dec 29
TI  - ChatGPT to enhance learning in dental education at a historically black medical 
      college.
LID - rs.3.rs-3546693 [pii]
LID - 10.21203/rs.3.rs-3546693/v2 [doi]
AB  - The recent rise of powerful large language model (LLM)-based AI tools, 
      exemplified by ChatGPT and Bard, poses a great challenge to contemporary dental 
      education while simultaneously offering a unique resource and approach that 
      potentially complements today's teaching and learning, where existing widely 
      available learning resources have often fallen short. Although both the clinical 
      and educational aspects of dentistry will be shaped profoundly by the LLM tools, 
      the didactic curricula, which primarily rely on lecture-based courses where 
      instructors impart knowledge through presentations and discussions, need to be 
      upgraded urgently. In this paper, we used dental course materials, syllabi, and 
      textbooks adopted currently in the School of Dentistry (SOD) at Meharry Medical 
      College to assess the potential utility and effectiveness of ChatGPT in dental 
      education. We collected the responses of the chatbot to questions as well as 
      students' interactions with it for assessment. Our results showed that ChatGPT 
      can assist in dental essay writing and generate relevant content for dental 
      students, in addition to other benefits. The limitations of ChatGPT were also 
      discussed in the paper.
FAU - Rahad, Khandoker
AU  - Rahad K
AD  - Meharry Medical College.
FAU - Martin, Kianna
AU  - Martin K
AD  - Meharry Medical College.
FAU - Amugo, Ihunna
AU  - Amugo I
AD  - Meharry Medical College.
FAU - Ferguson, Shania
AU  - Ferguson S
AD  - Meharry Medical College.
FAU - Curtis, Angela
AU  - Curtis A
AD  - Meharry Medical College.
FAU - Davis, Anniya
AU  - Davis A
AD  - Meharry Medical College.
FAU - Gangula, Pandu
AU  - Gangula P
AD  - Meharry Medical College.
FAU - Wang, Qingguo
AU  - Wang Q
AUID- ORCID: 0000-0002-5125-3724
AD  - Meharry Medical College.
LA  - eng
GR  - OT2 OD032581/OD/NIH HHS/United States
GR  - U01 DE033241/DE/NIDCR NIH HHS/United States
GR  - U54 MD007586/MD/NIMHD NIH HHS/United States
PT  - Preprint
DEP - 20231229
PL  - United States
TA  - Res Sq
JT  - Research square
JID - 101768035
UIN - Dent Res Oral Health. 2024;7(1):8-14. PMID: 38404561
PMC - PMC10659452
OTO - NOTNLM
OT  - ChatGPT
OT  - Dental Education
OT  - Dentistry
OT  - Large language model
OT  - Student Learning
COIS- Competing interests: There is no conflict of interest in connection with this 
      article.
EDAT- 2023/11/21 06:42
MHDA- 2023/11/21 06:43
PMCR- 2024/01/02
CRDT- 2023/11/21 05:09
PHST- 2023/11/21 06:42 [pubmed]
PHST- 2023/11/21 06:43 [medline]
PHST- 2023/11/21 05:09 [entrez]
PHST- 2024/01/02 00:00 [pmc-release]
AID - rs.3.rs-3546693 [pii]
AID - 10.21203/rs.3.rs-3546693/v2 [doi]
PST - epublish
SO  - Res Sq [Preprint]. 2023 Dec 29:rs.3.rs-3546693. doi: 10.21203/rs.3.rs-3546693/v2.

PMID- 38108232
OWN - NLM
STAT- Publisher
LR  - 20231218
IS  - 1879-3479 (Electronic)
IS  - 0020-7292 (Linking)
DP  - 2023 Dec 18
TI  - Accuracy and reproducibility of ChatGPT's free version answers about 
      endometriosis.
LID - 10.1002/ijgo.15309 [doi]
AB  - OBJECTIVE: To evaluate the accuracy and reproducibility of ChatGPT's free version 
      answers about endometriosis for the first time. METHODS: Detailed internet 
      searches to identify frequently asked questions (FAQs) about endometriosis have 
      been performed. Scientific questions were prepared in accordance with the 
      European Society of Human Reproduction and Embryology (ESHRE) endometriosis 
      guidelines. An experienced gynecologist gave a score of 1-4 for each ChatGPT 
      answer. The repeatability of ChatGPT answers about endometriosis was analyzed by 
      asking each question twice, and the reproducibility of ChatGPT was accepted as 
      scoring the answer to the same question in the same score category. RESULTS: A 
      total of 91.4% (n = 71) of all FAQs were answered completely, accurately, and 
      sufficiently. ChatGPT had the highest accuracy in the symptom and diagnosis 
      category (94.1%, 16/17 questions) and the lowest accuracy in the treatment 
      category (81.3%, 13/16 questions). Furthermore, of the 40 questions based on the 
      ESHRE endometriosis guidelines, 27 (67.5%) were classified as grade 1, seven 
      (17.5%) as grade 2, and six (15.0%) as grade 3. The reproducibility rate of FAQs 
      in the prevention, symptoms, and diagnosis, and complications categories was the 
      highest (100% for all categories). The reproducibility rate was the lowest for 
      questions based on the ESHRE endometriosis guidelines (70.0%). CONCLUSION: 
      ChatGPT accurately and satisfactorily responded to more than 90% of the questions 
      about endometriosis, but to only 67.5% of questions based on the ESHRE 
      endometriosis guidelines.
CI  - © 2023 The Authors. International Journal of Gynecology &amp; Obstetrics published by 
      John Wiley &amp; Sons Ltd on behalf of International Federation of Gynecology and 
      Obstetrics.
FAU - Ozgor, Bahar Yuksel
AU  - Ozgor BY
AUID- ORCID: 0000-0003-3728-3414
AD  - Department of Obstetrics and Gynecology, Biruni University, Istanbul, Turkey.
AD  - Endometriosis Research and Support Organization (Endo Türkiye), Istanbul, Turkey.
FAU - Simavi, Melek Azade
AU  - Simavi MA
AD  - Endometriosis Research and Support Organization (Endo Türkiye), Istanbul, Turkey.
LA  - eng
PT  - Journal Article
DEP - 20231218
PL  - United States
TA  - Int J Gynaecol Obstet
JT  - International journal of gynaecology and obstetrics: the official organ of the 
      International Federation of Gynaecology and Obstetrics
JID - 0210174
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - endometriosis
EDAT- 2023/12/18 06:41
MHDA- 2023/12/18 06:41
CRDT- 2023/12/18 05:33
PHST- 2023/11/27 00:00 [revised]
PHST- 2023/09/11 00:00 [received]
PHST- 2023/12/04 00:00 [accepted]
PHST- 2023/12/18 06:41 [medline]
PHST- 2023/12/18 06:41 [pubmed]
PHST- 2023/12/18 05:33 [entrez]
AID - 10.1002/ijgo.15309 [doi]
PST - aheadofprint
SO  - Int J Gynaecol Obstet. 2023 Dec 18. doi: 10.1002/ijgo.15309.

PMID- 37004317
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20231102
LR  - 20231103
IS  - 1532-818X (Electronic)
IS  - 0196-0709 (Linking)
VI  - 44
IP  - 4
DP  - 2023 Jul-Aug
TI  - Potential role of ChatGPT in clinical otolaryngology explained by ChatGPT.
PG  - 103873
LID - S0196-0709(23)00087-X [pii]
LID - 10.1016/j.amjoto.2023.103873 [doi]
FAU - Park, Isabel
AU  - Park I
AD  - Division of Otolaryngology-Head and Neck Surgery, George Washington University 
      School of Medicine &amp; Health Sciences, Washington, DC, USA. Electronic address: 
      isabelpark@gwmail.gwu.edu.
FAU - Joshi, Arjun S
AU  - Joshi AS
AD  - Division of Otolaryngology-Head and Neck Surgery, George Washington University 
      School of Medicine &amp; Health Sciences, Washington, DC, USA.
FAU - Javan, Ramin
AU  - Javan R
AD  - Department of Radiology, George Washington University Hospital, Washington, DC, 
      USA.
LA  - eng
PT  - Journal Article
DEP - 20230329
PL  - United States
TA  - Am J Otolaryngol
JT  - American journal of otolaryngology
JID - 8000029
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Chatbot
OT  - Clinical otolaryngology
OT  - OpenAI
EDAT- 2023/04/03 06:00
MHDA- 2023/04/03 06:01
CRDT- 2023/04/02 18:04
PHST- 2023/03/03 00:00 [received]
PHST- 2023/03/20 00:00 [revised]
PHST- 2023/03/25 00:00 [accepted]
PHST- 2023/04/03 06:01 [medline]
PHST- 2023/04/03 06:00 [pubmed]
PHST- 2023/04/02 18:04 [entrez]
AID - S0196-0709(23)00087-X [pii]
AID - 10.1016/j.amjoto.2023.103873 [doi]
PST - ppublish
SO  - Am J Otolaryngol. 2023 Jul-Aug;44(4):103873. doi: 10.1016/j.amjoto.2023.103873. 
      Epub 2023 Mar 29.

PMID- 37220429
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230525
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 4
DP  - 2023 Apr
TI  - Capacity of ChatGPT to Identify Guideline-Based Treatments for Advanced Solid 
      Tumors.
PG  - e37938
LID - 10.7759/cureus.37938 [doi]
LID - e37938
AB  - BACKGROUND: &nbsp;ChatGPT, created by OpenAI, is a large language model which has 
      become the fastest growing consumer application in history, recognized for its 
      expansive knowledge of varied subjects. The field of oncology is highly 
      specialized and requires nuanced understanding of medications and conditions. 
      Herein, we sought to better qualify the ability of ChatGPT to name applicable 
      treatments for patients with advanced solid cancers. METHODS: &nbsp;This observational 
      study was conducted utilizing ChatGPT. The capacity of ChatGPT to tabulate 
      appropriate systemic therapies for new diagnoses of advanced solid malignancies 
      was ascertained through standardized prompts. A ratio of those medications listed 
      by ChatGPT to those suggested in the National Comprehensive Cancer Network (NCCN) 
      guidelines was produced and called the valid therapy quotient (VTQ). Additional 
      descriptive analyses of the VTQ and its association with incidence and type of 
      treatment were performed. RESULTS: &nbsp;Some 51 distinct diagnoses were utilized 
      within this experiment. ChatGPT was able to identify 91 distinct medications in 
      response to prompts related to advanced solid tumors. The overall VTQ is 0.77. In 
      all cases, ChatGPT was able to provide at least one example of systemic therapy 
      suggested by the NCCN. There was a weak association between incidence of each 
      malignancy and the VTQ. CONCLUSION: &nbsp;The capacity of ChatGPT to identify 
      medications used to treat advanced solid tumors indicates a level of concordance 
      with the NCCN guidelines. As it stands, the role of ChatGPT to assist oncologists 
      and patients in treatment decision making remains unknown. Nonetheless, in future 
      iterations, it may be anticipated that accuracy and consistency in this domain 
      will improve, and further studies will be needed to better quantify its 
      capabilities.
CI  - Copyright © 2023, Schulte et al.
FAU - Schulte, Brian
AU  - Schulte B
AD  - Medicine, University of California San Francisco, San Francisco, USA.
LA  - eng
PT  - Journal Article
DEP - 20230421
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10200252
OTO - NOTNLM
OT  - cancer
OT  - chatgpt
OT  - chemotherapy
OT  - immunotherapy
OT  - nccn guidelines
OT  - oncology
OT  - targeted therapy
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/05/23 19:09
MHDA- 2023/05/23 19:10
PMCR- 2023/04/21
CRDT- 2023/05/23 17:13
PHST- 2023/04/20 00:00 [accepted]
PHST- 2023/05/23 19:10 [medline]
PHST- 2023/05/23 19:09 [pubmed]
PHST- 2023/05/23 17:13 [entrez]
PHST- 2023/04/21 00:00 [pmc-release]
AID - 10.7759/cureus.37938 [doi]
PST - epublish
SO  - Cureus. 2023 Apr 21;15(4):e37938. doi: 10.7759/cureus.37938. eCollection 2023 
      Apr.

PMID- 38527167
OWN - NLM
STAT- Publisher
LR  - 20240325
IS  - 2771-1897 (Electronic)
IS  - 2771-1897 (Linking)
DP  - 2024 Mar 25
TI  - ChatGPT in Urogynecology Research: Novel or Not?
LID - 10.1097/SPV.0000000000001505 [doi]
AB  - IMPORTANCE: ChatGPT (Chat Generative Pre-trained Transformer) is an artificial 
      intelligence (AI) chatbot that provides human-like responses to text prompts. 
      Little is known regarding ChatGPT's ability to identify original research ideas 
      in urogynecology. OBJECTIVE: Our objective was to evaluate the accuracy of 
      ChatGPT in generating novel systematic review (SR) and research ideas in 
      urogynecology. STUDY DESIGN: In this cross-sectional study, we asked ChatGPT to 
      generate 10 novel SR ideas that have not yet been published for each of the 
      following 5 topics: (1) urogynecology, (2) tension-free vaginal tape slings, (3) 
      pessaries for pelvic organ prolapse, (4) beta-3 agonist use for overactive 
      bladder, and (5) sexual function with genitourinary syndrome of menopause. 
      Research idea novelty was assessed by cross-referencing PubMed and Scopus to 
      determine if any prior publications existed. RESULTS: ChatGPT proposed 50 total 
      SR ideas, including 10 for each prompt. Overall, ChatGPT showed 54% overall 
      accuracy in developing novel SR ideas. Nonnovel SR ideas had a median of 19 
      (interquartile range, 8-35) published SRs on the suggested topic. When stratified 
      by prompt type, 50% of general and 40-70% of specific urogynecology proposed SR 
      ideas were found to be novel. There were no publications of any type identified 
      for 7 of the 50 suggested ideas. CONCLUSIONS: ChatGPT may be helpful for 
      identifying novel research ideas in urogynecology, but its accuracy is limited. 
      It is essential for those using ChatGPT to review existing literature to ensure 
      originality and credibility. As AI transforms health care, we encourage all 
      urogynecologists to familiarize themselves with popular AI platforms.
CI  - Copyright © 2024 American Urogynecologic Society. All rights reserved.
FAU - Choueka, David
AU  - Choueka D
AD  - From the Department of Obstetrics and Gynecology, Donald and Barbara Zucker 
      School of Medicine at Hofstra/Northwell, New York.
FAU - Tabakin, Alexandra L
AU  - Tabakin AL
AD  - Division of Urogynecology and Reconstructive Pelvic Surgery, Donald and Barbara 
      Zucker School of Medicine at Hofstra/Northwell, Great Neck, NY.
FAU - Shalom, Dara F
AU  - Shalom DF
AD  - Division of Urogynecology and Reconstructive Pelvic Surgery, Donald and Barbara 
      Zucker School of Medicine at Hofstra/Northwell, Great Neck, NY.
LA  - eng
PT  - Journal Article
DEP - 20240325
PL  - United States
TA  - Urogynecology (Phila)
JT  - Urogynecology (Philadelphia, Pa.)
JID - 9918452588006676
SB  - IM
COIS- The authors have declared they have no conflicts of interest.
EDAT- 2024/03/25 18:42
MHDA- 2024/03/25 18:42
CRDT- 2024/03/25 14:23
PHST- 2024/03/25 18:42 [medline]
PHST- 2024/03/25 18:42 [pubmed]
PHST- 2024/03/25 14:23 [entrez]
AID - 02273501-990000000-00197 [pii]
AID - 10.1097/SPV.0000000000001505 [doi]
PST - aheadofprint
SO  - Urogynecology (Phila). 2024 Mar 25. doi: 10.1097/SPV.0000000000001505.

PMID- 37754479
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231020
IS  - 2254-9625 (Electronic)
IS  - 2174-8144 (Print)
IS  - 2174-8144 (Linking)
VI  - 13
IP  - 9
DP  - 2023 Sep 21
TI  - Assessing the Usability of ChatGPT for Formal English Language Learning.
PG  - 1937-1960
LID - 10.3390/ejihpe13090140 [doi]
AB  - Recently, the emerging technologies have been constantly shaping the education 
      domain, especially the use of artificial intelligence (AI) for language learning, 
      which has attracted significant attention. Many of the AI tools are being used 
      for learning foreign languages, in both formal and informal ways. There are many 
      studies that have explored the potential of the recent technology "ChatGPT" for 
      education and learning languages, but none of the existing studies have conducted 
      any exploratory study for assessing the usability of ChatGPT. This paper conducts 
      an assessment for usability of ChatGPT for formal English language learning. The 
      study uses a standard questionnaire-based approach to ask participants about 
      their feedback for usefulness and effectiveness of ChatGPT. The participants were 
      asked for their feedback after performing series of tasks related to formal 
      English language learning with ChatGPT. A variety of student participants were 
      selected for this study with diverse English language proficiency levels, 
      education levels, and nationalities. The quantitative analysis of the participant 
      responses shed light on their experience with regards to the usability of ChatGPT 
      for performing different English language learning tasks such as conversation, 
      writing, grammar, and vocabulary. The findings from this study are quite 
      promising and indicate that ChatGPT is an effective tool to be used for formal 
      English language learning. Overall, this study contributes to the fast-growing 
      research domain on using emerging technologies for formal English language 
      learning by conducting in-depth assessment of usability for ChatGPT in formal 
      English language learning.
FAU - Shaikh, Sarang
AU  - Shaikh S
AUID- ORCID: 0000-0003-2099-4797
AD  - Department of Information Security and Communication Technology (IIK), Norwegian 
      University of Science and Technology (NTNU), 2815 Gjøvik, Norway.
FAU - Yayilgan, Sule Yildirim
AU  - Yayilgan SY
AUID- ORCID: 0000-0002-1982-6609
AD  - Department of Information Security and Communication Technology (IIK), Norwegian 
      University of Science and Technology (NTNU), 2815 Gjøvik, Norway.
FAU - Klimova, Blanka
AU  - Klimova B
AUID- ORCID: 0000-0001-8000-9766
AD  - Department of Applied Linguistics, Faculty of Informatics and Management, 
      University of Hradec Kralove, Rokitanskeho 62, 500 03 Hradec Kralove, Czech 
      Republic.
FAU - Pikhart, Marcel
AU  - Pikhart M
AUID- ORCID: 0000-0002-5633-9332
AD  - Department of Applied Linguistics, Faculty of Informatics and Management, 
      University of Hradec Kralove, Rokitanskeho 62, 500 03 Hradec Kralove, Czech 
      Republic.
LA  - eng
PT  - Journal Article
DEP - 20230921
PL  - Switzerland
TA  - Eur J Investig Health Psychol Educ
JT  - European journal of investigation in health, psychology and education
JID - 101751466
PMC - PMC10528190
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - English language
OT  - chatbots
OT  - formal learning
OT  - language learning
OT  - usability testing
COIS- The authors declare no conflict of interest.
EDAT- 2023/09/27 12:42
MHDA- 2023/09/27 12:43
PMCR- 2023/09/21
CRDT- 2023/09/27 08:55
PHST- 2023/07/10 00:00 [received]
PHST- 2023/08/29 00:00 [revised]
PHST- 2023/09/13 00:00 [accepted]
PHST- 2023/09/27 12:43 [medline]
PHST- 2023/09/27 12:42 [pubmed]
PHST- 2023/09/27 08:55 [entrez]
PHST- 2023/09/21 00:00 [pmc-release]
AID - ejihpe13090140 [pii]
AID - ejihpe-13-00140 [pii]
AID - 10.3390/ejihpe13090140 [doi]
PST - epublish
SO  - Eur J Investig Health Psychol Educ. 2023 Sep 21;13(9):1937-1960. doi: 
      10.3390/ejihpe13090140.

PMID- 37901715
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240313
IS  - 2950-1628 (Electronic)
IS  - 2950-1628 (Linking)
VI  - 1
IP  - 2
DP  - 2023 Sep
TI  - A Comprehensive Survey of ChatGPT: Advancements, Applications, Prospects, and 
      Challenges.
LID - 100022 [pii]
LID - 10.1016/j.metrad.2023.100022 [doi]
AB  - Large Language Models (LLMs) especially when combined with Generative Pre-trained 
      Transformers (GPT) represent a groundbreaking in natural language processing. In 
      particular, ChatGPT, a state-of-the-art conversational language model with a 
      user-friendly interface, has garnered substantial attention owing to its 
      remarkable capability for generating human-like responses across a variety of 
      conversational scenarios. This survey offers an overview of ChatGPT, delving into 
      its inception, evolution, and key technology. We summarize the fundamental 
      principles that underpin ChatGPT, encompassing its introduction in conjunction 
      with GPT and LLMs. We also highlight the specific characteristics of GPT models 
      with details of their impressive language understanding and generation 
      capabilities. We then summarize applications of ChatGPT in a few representative 
      domains. In parallel to the many advantages that ChatGPT can provide, we discuss 
      the limitations and challenges along with potential mitigation strategies. 
      Despite various controversial arguments and ethical concerns, ChatGPT has drawn 
      significant attention from research industries and academia in a very short 
      period. The survey concludes with an envision of promising avenues for future 
      research in the field of ChatGPT. It is worth noting that knowing and addressing 
      the challenges faced by ChatGPT will mount the way for more reliable and 
      trustworthy conversational agents in the years to come.
FAU - Nazir, Anam
AU  - Nazir A
AD  - Department of Diagnostic Radiology and Nuclear Medicine, University of Maryland 
      School of Medicine. W 670 Baltimore St, HSF III, Room 1173, Baltimore, MD 21201.
FAU - Wang, Ze
AU  - Wang Z
AD  - Department of Diagnostic Radiology and Nuclear Medicine, University of Maryland 
      School of Medicine. W 670 Baltimore St, HSF III, Room 1173, Baltimore, MD 21201.
LA  - eng
GR  - R01 AG060054/AG/NIA NIH HHS/United States
GR  - R01 AG070227/AG/NIA NIH HHS/United States
GR  - P41 EB029460/EB/NIBIB NIH HHS/United States
GR  - UL1 TR003098/TR/NCATS NIH HHS/United States
GR  - R01 AG081693/AG/NIA NIH HHS/United States
GR  - R01 EB031080/EB/NIBIB NIH HHS/United States
PT  - Journal Article
DEP - 20231007
PL  - Netherlands
TA  - Meta Radiol
JT  - Meta-radiology
JID - 9918697480806676
CIN - Med Ultrason. 2023 Dec 27;25(4):373-374. PMID: 38150677
PMC - PMC10611551
MID - NIHMS1934956
OTO - NOTNLM
OT  - ChatGPT
OT  - Contextual Learning
OT  - Generative Pre-trained Transformers (GPT)
OT  - Human-Computer Interaction
OT  - Large Language Models (LLMs)
OT  - Natural Language Processing (NLP)
OT  - Trustworthy Conversational Agents
EDAT- 2023/10/30 06:46
MHDA- 2023/10/30 06:47
PMCR- 2023/10/27
CRDT- 2023/10/30 04:56
PHST- 2023/10/30 06:47 [medline]
PHST- 2023/10/30 06:46 [pubmed]
PHST- 2023/10/30 04:56 [entrez]
PHST- 2023/10/27 00:00 [pmc-release]
AID - 100022 [pii]
AID - 10.1016/j.metrad.2023.100022 [doi]
PST - ppublish
SO  - Meta Radiol. 2023 Sep;1(2):100022. doi: 10.1016/j.metrad.2023.100022. Epub 2023 
      Oct 7.

PMID- 38156230
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231230
IS  - 2732-494X (Electronic)
IS  - 2732-494X (Linking)
VI  - 3
IP  - 1
DP  - 2023
TI  - All aboard the ChatGPT steamroller: Top 10 ways to make artificial intelligence 
      work for healthcare professionals.
PG  - e243
LID - 10.1017/ash.2023.512 [doi]
LID - e243
AB  - Chat Generative Pre-trained Transformer (ChatGPT), the flagship generative 
      artificial intelligence (AI) chatbot by OpenAI, is transforming many things in 
      medicine, from healthcare and research to medical education. It is anticipated to 
      integrate in many aspects of the medical industry, and we should brace for this 
      inevitability and use it to our advantage. Here are proposed ways you can use 
      ChatGPT in medicine with some specific use cases in antimicrobial stewardship and 
      hospital epidemiology.
CI  - © The Author(s) 2023.
FAU - Non, Lemuel R
AU  - Non LR
AUID- ORCID: 0000-0001-8438-4168
AD  - Division of Infectious Diseases, Department of Medicine, University of Iowa 
      Hospitals and Clinics, Iowa City, IA, USA.
LA  - eng
PT  - Editorial
DEP - 20231218
PL  - England
TA  - Antimicrob Steward Healthc Epidemiol
JT  - Antimicrobial stewardship &amp; healthcare epidemiology : ASHE
JID - 9918266096106676
PMC - PMC10753501
COIS- The author reports no conflicts of interest relevant to this article.
EDAT- 2023/12/29 18:42
MHDA- 2023/12/29 18:43
PMCR- 2023/12/18
CRDT- 2023/12/29 03:50
PHST- 2023/10/20 00:00 [received]
PHST- 2023/11/08 00:00 [revised]
PHST- 2023/11/09 00:00 [accepted]
PHST- 2023/12/29 18:43 [medline]
PHST- 2023/12/29 18:42 [pubmed]
PHST- 2023/12/29 03:50 [entrez]
PHST- 2023/12/18 00:00 [pmc-release]
AID - S2732494X23005120 [pii]
AID - 10.1017/ash.2023.512 [doi]
PST - epublish
SO  - Antimicrob Steward Healthc Epidemiol. 2023 Dec 18;3(1):e243. doi: 
      10.1017/ash.2023.512. eCollection 2023.

PMID- 37809128
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231010
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 9
DP  - 2023 Sep
TI  - Predicting Future Pandemics and Formulating Prevention Strategies: The Role of 
      ChatGPT.
PG  - e44825
LID - 10.7759/cureus.44825 [doi]
LID - e44825
AB  - The emergence of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) in 
      late 2019 and its subsequent worldwide spread has emphasized the urgent need for 
      better approaches for predicting and managing infectious disease outbreaks. One 
      potential instrument in this effort is artificial intelligence (AI), and in 
      specific, language models like ChatGPT (Chat Generative Pre-trained Transformer). 
      In the present study,&nbsp;to explore how ChatGPT could predict future pandemics and 
      give suggestions about the prevention strategy, our research team chatted with 
      ChatGPT with several questions on July 12, 2023. Based on our conversation, we 
      can conclude that AI is not a substitute for human expertise, but an adjunct to 
      support early prediction, prevention, and management of future pandemics.
CI  - Copyright © 2023, Jana et al.
FAU - Jana, Pradip K
AU  - Jana PK
AD  - Regional Virus Research and Diagnostic Laboratory, Indian Council of Medical 
      Research, National Institute of Cholera and Enteric Diseases, Kolkata, IND.
FAU - Majumdar, Agniva
AU  - Majumdar A
AD  - Regional Virus Research and Diagnostic Laboratory, Indian Council of Medical 
      Research, National Institute of Cholera and Enteric Diseases, Kolkata, IND.
FAU - Dutta, Shanta
AU  - Dutta S
AD  - Bacteriology, Indian Council of Medical Research, National Institute of Cholera 
      and Enteric Diseases, Kolkata, IND.
LA  - eng
PT  - Editorial
DEP - 20230907
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10559259
OTO - NOTNLM
OT  - ai &amp; robotics in healthcare
OT  - artificial intelligence
OT  - chatbot
OT  - chatgpt
OT  - machine learning
OT  - outbreak
OT  - pandemic
COIS- Responses from the ChatGPT Language Model are directly copied and pasted in Table 
      1 of our manuscript.
EDAT- 2023/10/09 06:42
MHDA- 2023/10/09 06:43
PMCR- 2023/09/07
CRDT- 2023/10/09 05:52
PHST- 2023/09/07 00:00 [accepted]
PHST- 2023/10/09 06:43 [medline]
PHST- 2023/10/09 06:42 [pubmed]
PHST- 2023/10/09 05:52 [entrez]
PHST- 2023/09/07 00:00 [pmc-release]
AID - 10.7759/cureus.44825 [doi]
PST - epublish
SO  - Cureus. 2023 Sep 7;15(9):e44825. doi: 10.7759/cureus.44825. eCollection 2023 Sep.

PMID- 38081765
OWN - NLM
STAT- MEDLINE
DCOM- 20231216
LR  - 20231221
IS  - 2632-1009 (Electronic)
IS  - 2632-1009 (Linking)
VI  - 30
IP  - 1
DP  - 2023 Dec 11
TI  - ChatGPT in Iranian medical licensing examination: evaluating the diagnostic 
      accuracy and decision-making capabilities of an AI-based model.
LID - 10.1136/bmjhci-2023-100815 [doi]
LID - e100815
AB  - INTRODUCTION: Large language models such as ChatGPT have gained popularity for 
      their ability to generate comprehensive responses to human queries. In the field 
      of medicine, ChatGPT has shown promise in applications ranging from diagnostics 
      to decision-making. However, its performance in medical examinations and its 
      comparison to random guessing have not been extensively studied. METHODS: This 
      study aimed to evaluate the performance of ChatGPT in the preinternship 
      examination, a comprehensive medical assessment for students in Iran. The 
      examination consisted of 200 multiple-choice questions categorised into basic 
      science evaluation, diagnosis and decision-making. GPT-4 was used, and the 
      questions were translated to English. A statistical analysis was conducted to 
      assess the performance of ChatGPT and also compare it with a random test group. 
      RESULTS: The results showed that ChatGPT performed exceptionally well, with 68.5% 
      of the questions answered correctly, significantly surpassing the pass mark of 
      45%. It exhibited superior performance in decision-making and successfully passed 
      all specialties. Comparing ChatGPT to the random test group, ChatGPT's 
      performance was significantly higher, demonstrating its ability to provide more 
      accurate responses and reasoning. CONCLUSION: This study highlights the potential 
      of ChatGPT in medical licensing examinations and its advantage over random 
      guessing. However, it is important to note that ChatGPT still falls short of 
      human physicians in terms of diagnostic accuracy and decision-making 
      capabilities. Caution should be exercised when using ChatGPT, and its results 
      should be verified by human experts to ensure patient safety and avoid potential 
      errors in the medical field.
CI  - © Author(s) (or their employer(s)) 2023. Re-use permitted under CC BY-NC. No 
      commercial re-use. See rights and permissions. Published by BMJ.
FAU - Ebrahimian, Manoochehr
AU  - Ebrahimian M
AUID- ORCID: 0000-0003-1286-3308
AD  - Pediatric Surgery Research Center, Research Institute for Children's Health, 
      Shahid Beheshti University of Medical Sciences, Tehran, Iran 
      manoochehrebrahimian@gmail.com.
FAU - Behnam, Behdad
AU  - Behnam B
AD  - Gastrointestinal and Liver Disease Research Center, Iran University of Medical 
      Sciences, Tehran, Iran.
FAU - Ghayebi, Negin
AU  - Ghayebi N
AD  - School of Medicine, Shahid Beheshti University of Medical Sciences, Tehran, Iran.
FAU - Sobhrakhshankhah, Elham
AU  - Sobhrakhshankhah E
AD  - Gastrointestinal and Liver Disease Research Center, Iran University of Medical 
      Sciences, Tehran, Iran.
LA  - eng
PT  - Journal Article
DEP - 20231211
PL  - England
TA  - BMJ Health Care Inform
JT  - BMJ health &amp; care informatics
JID - 101745500
SB  - IM
MH  - Humans
MH  - Iran
MH  - *Patient Safety
MH  - *Physicians
MH  - Research Design
MH  - Artificial Intelligence
PMC - PMC10729145
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Decision Making, Computer-Assisted
OT  - Neural Networks, Computer
COIS- Competing interests: None declared.
EDAT- 2023/12/12 00:42
MHDA- 2023/12/17 09:42
PMCR- 2023/12/11
CRDT- 2023/12/11 22:23
PHST- 2023/05/30 00:00 [received]
PHST- 2023/11/28 00:00 [accepted]
PHST- 2023/12/17 09:42 [medline]
PHST- 2023/12/12 00:42 [pubmed]
PHST- 2023/12/11 22:23 [entrez]
PHST- 2023/12/11 00:00 [pmc-release]
AID - bmjhci-2023-100815 [pii]
AID - 10.1136/bmjhci-2023-100815 [doi]
PST - epublish
SO  - BMJ Health Care Inform. 2023 Dec 11;30(1):e100815. doi: 
      10.1136/bmjhci-2023-100815.

PMID- 37951982
OWN - NLM
STAT- MEDLINE
DCOM- 20240131
LR  - 20240206
IS  - 1476-5497 (Electronic)
IS  - 0307-0565 (Linking)
VI  - 48
IP  - 2
DP  - 2024 Feb
TI  - Credibility of ChatGPT in the assessment of obesity in type 2 diabetes according 
      to the guidelines.
PG  - 271-275
LID - 10.1038/s41366-023-01410-5 [doi]
AB  - BACKGROUND: The Chat Generative Pre-trained Transformer (ChatGPT) allows 
      students, researchers, and patients in the medical field to access information 
      easily and has gained attention nowadays. We aimed to evaluate the credibility of 
      ChatGPT according to the guidelines for the assessment of obesity in type 2 
      diabetes (T2D), which is one of the major concerns of this century. MATERIALS AND 
      METHOD: In this cross-sectional non-human subject study, experienced 
      endocrinologists posed 20 questions to ChatGPT in subsections, which were 
      assessments and different treatment options for obesity according to the American 
      Diabetes Association and American Association of Clinical Endocrinology 
      guidelines. The responses of ChatGPT were classified into four categories: 
      compatible, compatible but insufficient, partially incompatible and incompatible 
      with the guidelines. RESULTS: ChatGPT demonstrated a systematic approach to 
      answering questions and recommended consulting a healthcare provider to receive 
      personalized advice based on the specific health needs and circumstances of 
      patients. The compatibility of ChatGPT with the guidelines was 100% in the 
      assessment of obesity in type 2 diabetes; however, it was lower in the therapy 
      sections, which included nutritional, medical, and surgical approaches to weight 
      loss. Furthermore, ChatGPT required additional prompts for responses that were 
      evaluated as "compatible but insufficient" to provide all the information in the 
      guidelines. CONCLUSION: The assessment and management of obesity in T2D are 
      highly individualized. Despite ChatGPT's comprehensive and understandable 
      responses, it should not be used as a substitute for healthcare professionals' 
      patient-centered approach.
CI  - © 2023. The Author(s), under exclusive licence to Springer Nature Limited.
FAU - Barlas, Tugba
AU  - Barlas T
AUID- ORCID: 0000-0003-0042-6928
AD  - Department of Endocrinology and Metabolism, Gazi University Faculty of Medicine, 
      Ankara, Turkey. drtugbabarlas@gmail.com.
FAU - Altinova, Alev Eroglu
AU  - Altinova AE
AD  - Department of Endocrinology and Metabolism, Gazi University Faculty of Medicine, 
      Ankara, Turkey.
FAU - Akturk, Mujde
AU  - Akturk M
AD  - Department of Endocrinology and Metabolism, Gazi University Faculty of Medicine, 
      Ankara, Turkey.
FAU - Toruner, Fusun Balos
AU  - Toruner FB
AD  - Department of Endocrinology and Metabolism, Gazi University Faculty of Medicine, 
      Ankara, Turkey.
LA  - eng
PT  - Journal Article
DEP - 20231111
PL  - England
TA  - Int J Obes (Lond)
JT  - International journal of obesity (2005)
JID - 101256108
SB  - IM
CIN - Int J Obes (Lond). 2023 Dec 11;:. PMID: 38081927
MH  - Humans
MH  - *Diabetes Mellitus, Type 2/diagnosis/epidemiology/therapy
MH  - Cross-Sectional Studies
MH  - Obesity/complications/epidemiology
MH  - Health Personnel
MH  - Referral and Consultation
EDAT- 2023/11/12 00:41
MHDA- 2024/01/31 06:42
CRDT- 2023/11/11 23:29
PHST- 2023/06/07 00:00 [received]
PHST- 2023/10/30 00:00 [accepted]
PHST- 2023/10/22 00:00 [revised]
PHST- 2024/01/31 06:42 [medline]
PHST- 2023/11/12 00:41 [pubmed]
PHST- 2023/11/11 23:29 [entrez]
AID - 10.1038/s41366-023-01410-5 [pii]
AID - 10.1038/s41366-023-01410-5 [doi]
PST - ppublish
SO  - Int J Obes (Lond). 2024 Feb;48(2):271-275. doi: 10.1038/s41366-023-01410-5. Epub 
      2023 Nov 11.

PMID- 37553552
OWN - NLM
STAT- MEDLINE
DCOM- 20231027
LR  - 20231027
IS  - 1433-7347 (Electronic)
IS  - 0942-2056 (Print)
IS  - 0942-2056 (Linking)
VI  - 31
IP  - 11
DP  - 2023 Nov
TI  - Exploring the potential of ChatGPT as a supplementary tool for providing 
      orthopaedic information.
PG  - 5190-5198
LID - 10.1007/s00167-023-07529-2 [doi]
AB  - PURPOSE: To investigate the potential use of large language models (LLMs) in 
      orthopaedics by presenting queries pertinent to anterior cruciate ligament (ACL) 
      surgery to generative pre-trained transformer (ChatGPT, specifically using its 
      GPT-4 model of March 14th 2023). Additionally, this study aimed to evaluate the 
      depth of the LLM's knowledge and investigate its adaptability to different user 
      groups. It was hypothesized that the ChatGPT would be able to adapt to different 
      target groups due to its strong language understanding and processing 
      capabilities. METHODS: ChatGPT was presented with 20 questions and response was 
      requested for two distinct target audiences: patients and non-orthopaedic medical 
      doctors. Two board-certified orthopaedic sports medicine surgeons and two expert 
      orthopaedic sports medicine surgeons independently evaluated the responses 
      generated by ChatGPT. Mean correctness, completeness, and adaptability to the 
      target audiences (patients and non-orthopaedic medical doctors) were determined. 
      A three-point response scale facilitated nuanced assessment. RESULTS: ChatGPT 
      exhibited fair accuracy, with average correctness scores of 1.69 and 1.66 (on a 
      scale from 0, incorrect, 1, partially correct, to 2, correct) for patients and 
      medical doctors, respectively. Three of the 20 questions (15.0%) were deemed 
      incorrect by any of the four orthopaedic sports medicine surgeon assessors. 
      Moreover, overall completeness was calculated to be 1.51 and 1.64 for patients 
      and medical doctors, respectively, while overall adaptiveness was determined to 
      be 1.75 and 1.73 for patients and doctors, respectively. CONCLUSION: Overall, 
      ChatGPT was successful in generating correct responses in approximately 65% of 
      the cases related to ACL surgery. The findings of this study imply that LLMs 
      offer potential as a supplementary tool for acquiring orthopaedic knowledge. 
      However, although ChatGPT can provide guidance and effectively adapt to diverse 
      target audiences, it cannot supplant the expertise of orthopaedic sports medicine 
      surgeons in diagnostic and treatment planning endeavours due to its limited 
      understanding of orthopaedic domains and its potential for erroneous responses. 
      LEVEL OF EVIDENCE: V.
CI  - © 2023. The Author(s).
FAU - Kaarre, Janina
AU  - Kaarre J
AUID- ORCID: 0000-0003-2559-8283
AD  - Department of Orthopaedic Surgery, UPMC Freddie Fu Sports Medicine Center, 
      University of Pittsburgh, Pittsburgh, USA. janina.kaarre@gu.se.
AD  - Department of Orthopaedics, Institute of Clinical Sciences, Sahlgrenska Academy, 
      University of Gothenburg, Göteborgsvägen 31, 431 80, Mölndal, Sweden. 
      janina.kaarre@gu.se.
FAU - Feldt, Robert
AU  - Feldt R
AD  - Department of Computer Science and Engineering, Chalmers University of 
      Technology, Gothenburg, Sweden.
FAU - Keeling, Laura E
AU  - Keeling LE
AD  - Department of Orthopaedic Surgery, UPMC Freddie Fu Sports Medicine Center, 
      University of Pittsburgh, Pittsburgh, USA.
FAU - Dadoo, Sahil
AU  - Dadoo S
AD  - Department of Orthopaedic Surgery, UPMC Freddie Fu Sports Medicine Center, 
      University of Pittsburgh, Pittsburgh, USA.
FAU - Zsidai, Bálint
AU  - Zsidai B
AD  - Department of Orthopaedics, Institute of Clinical Sciences, Sahlgrenska Academy, 
      University of Gothenburg, Göteborgsvägen 31, 431 80, Mölndal, Sweden.
FAU - Hughes, Jonathan D
AU  - Hughes JD
AD  - Department of Orthopaedic Surgery, UPMC Freddie Fu Sports Medicine Center, 
      University of Pittsburgh, Pittsburgh, USA.
FAU - Samuelsson, Kristian
AU  - Samuelsson K
AD  - Department of Orthopaedics, Institute of Clinical Sciences, Sahlgrenska Academy, 
      University of Gothenburg, Göteborgsvägen 31, 431 80, Mölndal, Sweden.
AD  - Department of Orthopaedics, Sahlgrenska University Hospital, Mölndal, Sweden.
FAU - Musahl, Volker
AU  - Musahl V
AD  - Department of Orthopaedic Surgery, UPMC Freddie Fu Sports Medicine Center, 
      University of Pittsburgh, Pittsburgh, USA.
LA  - eng
PT  - Journal Article
DEP - 20230808
PL  - Germany
TA  - Knee Surg Sports Traumatol Arthrosc
JT  - Knee surgery, sports traumatology, arthroscopy : official journal of the ESSKA
JID - 9314730
SB  - IM
MH  - Humans
MH  - *Orthopedics
MH  - *Orthopedic Procedures
MH  - *Orthopedic Surgeons
MH  - Anterior Cruciate Ligament
MH  - Language
PMC - PMC10598178
OTO - NOTNLM
OT  - ACL
OT  - Anterior cruciate ligament
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Correctness
OT  - Large language models
COIS- Robert Feldt is CTO and founder of a software consultancy company (Accelerandium 
      AB). Volker Musahl reports educational grants, consulting fees, and speaking fees 
      from Smith &amp; Nephew plc, educational grants from Arthrex and DePuy/Synthes, is a 
      board member of the International Society of Arthroscopy, Knee Surgery and 
      Orthopaedic Sports Medicine (ISAKOS), and deputy editor-in-chief of Knee Surgery, 
      Sports Traumatology, Arthroscopy (KSSTA). Volker Musahl also has a patent, U.S. 
      Patent No. 9,949,684, issued on April 24, 2018, to the University of Pittsburgh. 
      Kristian Samuelsson is a member of the Board of Directors of Getinge AB (publ).
EDAT- 2023/08/09 01:05
MHDA- 2023/10/27 06:42
PMCR- 2023/08/08
CRDT- 2023/08/08 23:30
PHST- 2023/04/19 00:00 [received]
PHST- 2023/07/26 00:00 [accepted]
PHST- 2023/10/27 06:42 [medline]
PHST- 2023/08/09 01:05 [pubmed]
PHST- 2023/08/08 23:30 [entrez]
PHST- 2023/08/08 00:00 [pmc-release]
AID - 10.1007/s00167-023-07529-2 [pii]
AID - 7529 [pii]
AID - 10.1007/s00167-023-07529-2 [doi]
PST - ppublish
SO  - Knee Surg Sports Traumatol Arthrosc. 2023 Nov;31(11):5190-5198. doi: 
      10.1007/s00167-023-07529-2. Epub 2023 Aug 8.

PMID- 38440617
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240306
IS  - 2231-3796 (Print)
IS  - 0973-7707 (Electronic)
IS  - 2231-3796 (Linking)
VI  - 76
IP  - 1
DP  - 2024 Feb
TI  - ChatGPT in Head and Neck Oncology-Opportunities and Challenges.
PG  - 1425-1429
LID - 10.1007/s12070-023-04201-6 [doi]
AB  - Head and neck oncology represents a complex and challenging field, encompassing 
      the diagnosis, treatment and management of various malignancies affecting the 
      intricate anatomical structures of the head and neck region. With advancements in 
      artificial intelligence (AI), chatbot applications have emerged as a promising 
      tool to revolutionize the field of Head and Neck oncology. ChatGPT is a 
      cutting-edge language model developed by OpenAI that can help the oncologist in 
      the clinic in scheduling appointments, establishing a clinical diagnosis, making 
      a treatment plan and follow-up. ChatGPT also plays an essential role in 
      telemedicine consultations, medical documentation, scientific writing and 
      research. ChatGPT carries its inherent drawbacks too. ChatGPT raises significant 
      ethical concerns related to authorship, accountability, transparency, bias, and 
      the potential for misinformation. ChatGPT's training data is limited to September 
      2021; thus, regular updates are required to keep pace with the rapidly evolving 
      medical research and advancements. Therefore, a judicial approach to using 
      ChatGPT is of utmost importance. Head and Neck Oncologists can reap the maximum 
      benefit of this technology in terms of patient care, education and research to 
      improve clinical outcomes.
CI  - © Association of Otolaryngologists of India 2023. Springer Nature or its licensor 
      (e.g. a society or other partner) holds exclusive rights to this article under a 
      publishing agreement with the author(s) or other rightsholder(s); author 
      self-archiving of the accepted manuscript version of this article is solely 
      governed by the terms of such publishing agreement and applicable law.
FAU - Sarma, Gautam
AU  - Sarma G
AUID- ORCID: 0000-0002-2907-210X
AD  - Department of Radiation Oncology, All India Institute of Medical Sciences 
      Guwahati, Changsari, Assam, 781101 India. ROR: https://ror.org/000kxhc93
FAU - Kashyap, Hrishikesh
AU  - Kashyap H
AUID- ORCID: 0009-0004-2591-3022
AD  - Department of Radiation Oncology, All India Institute of Medical Sciences 
      Guwahati, Changsari, Assam, 781101 India. ROR: https://ror.org/000kxhc93
FAU - Medhi, Partha Pratim
AU  - Medhi PP
AUID- ORCID: 0000-0002-3997-4350
AD  - Department of Radiation Oncology, All India Institute of Medical Sciences 
      Guwahati, Changsari, Assam, 781101 India. ROR: https://ror.org/000kxhc93
LA  - eng
PT  - Journal Article
DEP - 20230831
PL  - India
TA  - Indian J Otolaryngol Head Neck Surg
JT  - Indian journal of otolaryngology and head and neck surgery : official publication 
      of the Association of Otolaryngologists of India
JID - 9422551
PMC - PMC10908741
OTO - NOTNLM
OT  - Artificial Intelligence
OT  - ChatGPT
OT  - Head and Neck
OT  - Oncology
EDAT- 2024/03/05 06:46
MHDA- 2024/03/05 06:47
PMCR- 2025/02/01
CRDT- 2024/03/05 03:58
PHST- 2023/07/28 00:00 [received]
PHST- 2023/08/28 00:00 [accepted]
PHST- 2025/02/01 00:00 [pmc-release]
PHST- 2024/03/05 06:47 [medline]
PHST- 2024/03/05 06:46 [pubmed]
PHST- 2024/03/05 03:58 [entrez]
AID - 4201 [pii]
AID - 10.1007/s12070-023-04201-6 [doi]
PST - ppublish
SO  - Indian J Otolaryngol Head Neck Surg. 2024 Feb;76(1):1425-1429. doi: 
      10.1007/s12070-023-04201-6. Epub 2023 Aug 31.
</pre>
      
    </div>
  </main>


  
  


  


</body></html>