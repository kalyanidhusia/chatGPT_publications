<!DOCTYPE html>
<!-- saved from url=(0075)https://pubmed.ncbi.nlm.nih.gov/?term=chatGPT&page=7&format=pubmed&size=200 -->
<html lang="en"><head itemscope="" itemtype="http://schema.org/WebPage" prefix="og: http://ogp.me/ns#"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <!-- Mobile properties -->
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov/">
  <link rel="preconnect" href="https://www.ncbi.nlm.nih.gov/">
  <link rel="preconnect" href="https://www.google-analytics.com/">

  
  
    <link rel="stylesheet" href="./page7_PubMed_files/output.5ecf62baa0fa.css" type="text/css">
  

  <link rel="stylesheet" href="./page7_PubMed_files/output.452c70ce66f7.css" type="text/css">

  
    
  

  
    <link rel="stylesheet" href="./page7_PubMed_files/output.97c300a159d1.css" type="text/css">
  

  


    <title>chatGPT - Search Results - PubMed</title>

  
  
  <!-- Favicons -->
  <link rel="shortcut icon" type="image/ico" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.ico">
  <link rel="icon" type="image/png" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.png">

  <!-- 192x192, as recommended for Android
  http://updates.html5rocks.com/2014/11/Support-for-theme-color-in-Chrome-39-for-Android
  -->
  <link rel="icon" type="image/png" sizes="192x192" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-192.png">

  <!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
  <link rel="apple-touch-icon-precomposed" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-57.png">
  <!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
  <link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-72.png">
  <!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
  <link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-114.png">
  <!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-144.png">


  <!-- For Pinger + Google Optimize integration (NS-820) -->
  <meta name="ncbi_sg_optimize_id" content="">

  <!-- Mobile browser address bar color -->
  <meta name="theme-color" content="#20558a">

  <!-- Preserve the Referrer when going from HTTPS to HTTP -->
  <meta name="referrer" content="origin-when-cross-origin">

  <meta name="ncbi_pinger_gtm_track" content="true">
<!-- Logging params: Pinger defaults -->

  
    <meta name="ncbi_app" content="pubmed">
  

  
    <meta name="ncbi_db" content="pubmed">
  

  
    <meta name="ncbi_phid" content="658B00010FEE1FF50000399090CAC823.1.m_7">
  

  
    <meta name="ncbi_pinger_stat_url" content="https://www.ncbi.nlm.nih.gov/stat">
  

  
    <meta name="log_category" content="literature">
  

  
    <meta name="ncbi_cost_center" content="pubmed">
  



  <!-- Logging params: Pinger custom -->
  
    <meta name="log_op" content="search">
  
    <meta name="log_query" content="chatGPT">
  
    <meta name="ncbi_pdid" content="searchresult">
  
    <meta name="ncbi_pageno" content="7">
  
    <meta name="log_resultcount" content="2844">
  
    <meta name="log_userterm" content="chatGPT">
  
    <meta name="log_processedquery" content="&quot;chatGPT&quot;[All Fields]">
  
    <meta name="log_filtersactive" content="False">
  
    <meta name="log_filters" content="">
  
    <meta name="ncbi_log_query" content="chatGPT">
  
    <meta name="log_proximity_search_active" content="False">
  
    <meta name="log_format" content="pubmed">
  
    <meta name="log_sortorder" content="relevance">
  
    <meta name="log_pagesize" content="200">
  
    <meta name="log_displayeduids" content="38558067,38216806,38285894,37949772,38438614,38244612,37581145,37440293,37832828,38175720,37780059,37679532,37620342,38130535,37106269,37648742,37256297,37009366,38290872,38044041,38172581,36909067,38564173,37852647,38454175,37757748,38521671,38382193,38032714,38441945,38009003,38405784,37621662,37727841,37578830,37562028,36920012,38155290,36912286,36856927,37956228,38057467,37399360,37336169,37673708,37405455,36906947,38164563,36918736,37236498,37034476,38362894,37775381,37703085,37323042,36748354,38147047,37731643,38528008,38510403,36841840,38228809,38150678,38329802,38549897,37943581,37957964,38294325,38244054,37428336,38261307,38277084,38133911,36702491,36747099,36690769,37738926,37567593,37171282,37336139,38194585,37905264,37843579,37506622,37094759,38499312,37848712,37127465,37791148,37056551,38261400,36943139,37684390,37433941,37155982,38445611,37976093,37615142,37505381,37384388,36754723,37704854,37480927,37045954,36481949,37222278,37410934,37038563,36517680,37863153,38470237,38568227,38320079,37663854,38500671,38353440,38296195,37869501,37852648,37845528,37443308,37074116,37660692,38536805,37556434,37595113,37257813,37461512,37668714,38450533,37410672,37598184,36854734,38144532,36760131,37095351,38395327,37285189,38441296,38366218,37817721,37703484,37565001,37220943,38206246,37647848,38537293,38457221,37087108,38391760,38259432,37941716,37284994,37707390,37786788,37268021,37684388,37001998,38418736,38114679,37993616,37197782,37772448,36494443,37542362,38026769,38114830,37830256,37798200,38178785,37065364,38123858,37974032,38026315,38001275,37399112,37133539,37026967,37817033,37804010,37438635,38413129,38330366,38504411,37327133,38082605,37077585,37566133,37210278,38317003,37968529,37812094,37541730,37144055,37869810,38443210,37690015,36865238,37644984,38076260">
  
    <meta name="ncbi_search_id" content="R3Cs2GC7H0x0KE8U7UASSA:deef7cbfe7e81e7152f8e0e261e5ab1a">
  
    <meta name="ncbi_adj_nav_search_id" content="Ox47RiAm6zlmZFrjHH9QLg:fbd847f89c96214ac23b7c62d7cb721a">
  



  <!-- Social meta tags for unfurling urls -->
  
<meta name="description" content="chatGPT - Search Results - PubMed"><meta name="robots" content="noindex,follow,noarchive"><meta property="og:title" content="chatGPT - Search Results - PubMed"><meta property="og:url" content="https://pubmed.ncbi.nlm.nih.gov/?term=chatGPT&amp;page=7&amp;format=pubmed&amp;size=200"><meta property="og:description" content="chatGPT - Search Results - PubMed"><meta property="og:image" content="https://cdn.ncbi.nlm.nih.gov/pubmed/persistent/pubmed-meta-image-v2.jpg"><meta property="og:image:secure_url" content="https://cdn.ncbi.nlm.nih.gov/pubmed/persistent/pubmed-meta-image-v2.jpg"><meta property="og:type" content="website"><meta property="og:site_name" content="PubMed"><meta name="twitter:domain" content="pubmed.ncbi.nlm.nih.gov"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="chatGPT - Search Results - PubMed"><meta name="twitter:url" content="https://pubmed.ncbi.nlm.nih.gov/?term=chatGPT&amp;page=7&amp;format=pubmed&amp;size=200"><meta name="twitter:description" content="chatGPT - Search Results - PubMed"><meta name="twitter:image" content="https://cdn.ncbi.nlm.nih.gov/pubmed/persistent/pubmed-meta-image-v2.jpg">


  <!-- OpenSearch XML -->
  <link rel="search" type="application/opensearchdescription+xml" href="https://cdn.ncbi.nlm.nih.gov/pubmed/persistent/opensearch.xml" title="PubMed search">

  <!-- Disables severely broken elements when no JS -->
  <noscript>
    <link rel="stylesheet" type="text/css" href="https://cdn.ncbi.nlm.nih.gov/pubmed/09ad9aad-98d9-47ec-b2ea-fb4dba3d550d/core/no-script.css">
  </noscript>

  
    <link rel="canonical" href="https://pubmed.ncbi.nlm.nih.gov/?term=chatGPT&amp;page=7&amp;format=pubmed&amp;size=200">
  


</head>
<body>

  
  <main class="search-page" id="search-page">
    <div class="search-results" id="search-results">
      
        <pre class="search-results-chunk">PMID- 38558067
OWN - NLM
STAT- MEDLINE
DCOM- 20240403
LR  - 20240403
IS  - 2795-4552 (Electronic)
IS  - 2795-4552 (Linking)
VI  - 3
IP  - 1
DP  - 2024 Jan-Mar
TI  - ChatGPT's accuracy and patient-oriented answers about fibromyalgia.
PG  - 58-69
FAU - Parente, Hugo
AU  - Parente H
AD  - Rheumatology Department, Unidade Local do Alto Minho, Ponte de Lima, Portugal.
FAU - Soares, Catarina
AU  - Soares C
AD  - Rheumatology Department, Unidade Local do Alto Minho, Ponte de Lima, Portugal.
FAU - Ferreira, Maria Pontes
AU  - Ferreira MP
AD  - Rheumatology Department, Unidade Local do Alto Minho, Ponte de Lima, Portugal.
FAU - Cunha, Anita
AU  - Cunha A
AD  - Rheumatology Department, Unidade Local do Alto Minho, Ponte de Lima, Portugal.
FAU - Guimarães, Francisca
AU  - Guimarães F
AD  - Rheumatology Department, Unidade Local do Alto Minho, Ponte de Lima, Portugal.
FAU - Azevedo, Soraia
AU  - Azevedo S
AD  - Rheumatology Department, Unidade Local do Alto Minho, Ponte de Lima, Portugal.
FAU - Afonso, Carmo
AU  - Afonso C
AD  - Rheumatology Department, Unidade Local do Alto Minho, Ponte de Lima, Portugal.
FAU - Teixeira, Filipa
AU  - Teixeira F
AD  - Rheumatology Department, Unidade Local do Alto Minho, Ponte de Lima, Portugal.
FAU - Tavares-Costa, José
AU  - Tavares-Costa J
AD  - Rheumatology Department, Unidade Local do Alto Minho, Ponte de Lima, Portugal.
LA  - eng
PT  - Journal Article
TT  - ChatGPT’s accuracy and patient-oriented answers about fibromyalgia.
PL  - Portugal
TA  - ARP Rheumatol
JT  - ARP rheumatology
JID - 9918402287906676
SB  - IM
MH  - Humans
MH  - *Fibromyalgia/diagnosis
EDAT- 2024/04/01 18:42
MHDA- 2024/04/03 06:44
CRDT- 2024/04/01 16:19
PHST- 2024/04/03 06:44 [medline]
PHST- 2024/04/01 18:42 [pubmed]
PHST- 2024/04/01 16:19 [entrez]
AID - CE230361 [pii]
PST - ppublish
SO  - ARP Rheumatol. 2024 Jan-Mar;3(1):58-69.

PMID- 38216806
OWN - NLM
STAT- MEDLINE
DCOM- 20240305
LR  - 20240307
IS  - 1544-2241 (Electronic)
IS  - 1544-1873 (Print)
IS  - 1544-1873 (Linking)
VI  - 22
IP  - 1
DP  - 2024 Feb
TI  - The Utility of AI in Writing a Scientific Review Article on the Impacts of 
      COVID-19 on Musculoskeletal Health.
PG  - 146-151
LID - 10.1007/s11914-023-00855-x [doi]
AB  - PURPOSE OF REVIEW: There were two primary purposes to our reviews. First, to 
      provide an update to the scientific community about the impacts of COVID-19 on 
      musculoskeletal health. Second, was to determine the value of using a large 
      language model, ChatGPT 4.0, in the process of writing a scientific review 
      article. To accomplish these objectives, we originally set out to write three 
      review articles on the topic using different methods to produce the initial 
      drafts of the review articles. The first review article was written in the 
      traditional manner by humans, the second was to be written exclusively using 
      ChatGPT (AI-only or AIO), and the third approach was to input the outline and 
      references selected by humans from approach 1 into ChatGPT, using the AI to 
      assist in completing the writing (AI-assisted or AIA). All review articles were 
      extensively fact-checked and edited by all co-authors leading to the final drafts 
      of the manuscripts, which were significantly different from the initial drafts. 
      RECENT FINDINGS: Unfortunately, during this process, it became clear that 
      approach 2 was not feasible for a very recent topic like COVID-19 as at the time, 
      ChatGPT 4.0 had a cutoff date of September 2021 and all articles published after 
      this date had to be provided to ChatGPT, making approaches 2 and 3 virtually 
      identical. Therefore, only two approaches and two review articles were written 
      (human and AI-assisted). Here we found that the human-only approach took less 
      time to complete than the AI-assisted approach. This was largely due to the 
      number of hours required to fact-check and edit the AI-assisted manuscript. Of 
      note, the AI-assisted approach resulted in inaccurate attributions of references 
      (about 20%) and had a higher similarity index suggesting an increased risk of 
      plagiarism. The main aim of this project was to determine whether the use of AI 
      could improve the process of writing a scientific review article. Based on our 
      experience, with the current state of technology, it would not be advised to 
      solely use AI to write a scientific review article, especially on a recent topic.
CI  - © 2024. This is a U.S. Government work and not under copyright protection in the 
      US; foreign copyright protection may apply.
FAU - Awosanya, Olatundun D
AU  - Awosanya OD
AD  - Department of Orthopaedic Surgery, Indiana University School of Medicine, 
      Indianapolis, IN, USA.
FAU - Harris, Alexander
AU  - Harris A
AD  - Department of Orthopaedic Surgery, Indiana University School of Medicine, 
      Indianapolis, IN, USA.
FAU - Creecy, Amy
AU  - Creecy A
AD  - Department of Orthopaedic Surgery, Indiana University School of Medicine, 
      Indianapolis, IN, USA.
FAU - Qiao, Xian
AU  - Qiao X
AD  - Critical Care, and Sleep Specialists, SMG Pulmonary, Norfolk, VA, USA.
AD  - Division of Pulmonary and Critical Care Medicine, Eastern Virginia Medical 
      School, Norfolk, VA, USA.
AD  - Department of Internal Medicine, Eastern Virginia Medical School, Norfolk, VA, 
      USA.
FAU - Toepp, Angela J
AU  - Toepp AJ
AD  - Department of Internal Medicine, Eastern Virginia Medical School, Norfolk, VA, 
      USA.
AD  - Sentara Health, Enterprise Analytics, Norfolk, VA, USA.
FAU - McCune, Thomas
AU  - McCune T
AD  - Department of Internal Medicine, Eastern Virginia Medical School, Norfolk, VA, 
      USA.
AD  - Division of Nephrology, Eastern Virginia Medical School, Norfolk, VA, USA.
FAU - Kacena, Melissa A
AU  - Kacena MA
AD  - Department of Orthopaedic Surgery, Indiana University School of Medicine, 
      Indianapolis, IN, USA. mkacena@iupui.edu.
AD  - Richard L. Roudebush VA Medical Center, Indianapolis, IN, USA. mkacena@iupui.edu.
FAU - Ozanne, Marie V
AU  - Ozanne MV
AD  - Department of Mathematics and Statistics, Mount Holyoke College, South Hadley, 
      MA, USA. mozanne@mtholyoke.edu.
LA  - eng
GR  - R01 AG060621/AG/NIA NIH HHS/United States
GR  - F31AG077931/NH/NIH HHS/United States
GR  - UL1 TR002529/TR/NCATS NIH HHS/United States
GR  - F31 AG077931/AG/NIA NIH HHS/United States
GR  - I01 RX003552/RX/RRD VA/United States
GR  - IK6 RX004809/RX/RRD VA/United States
GR  - AR065971/NH/NIH HHS/United States
GR  - I01 BX003751/BX/BLRD VA/United States
GR  - T32 AR065971/AR/NIAMS NIH HHS/United States
PT  - Journal Article
PT  - Review
DEP - 20240113
PL  - United States
TA  - Curr Osteoporos Rep
JT  - Current osteoporosis reports
JID - 101176492
SB  - IM
MH  - Humans
MH  - *COVID-19
MH  - Writing
MH  - Artificial Intelligence
PMC - PMC10912275
OTO - NOTNLM
OT  - AI
OT  - Bone Loss
OT  - COVID-19
OT  - ChatGPT
OT  - Fracture
OT  - Osteoporosis
OT  - Query
OT  - SARS-CoV-2
OT  - Scientific review article
COIS- Melissa Kacena is the Editor-in-Chief for Current Osteoporosis Reports.
EDAT- 2024/01/13 00:42
MHDA- 2024/03/05 06:46
PMCR- 2024/01/13
CRDT- 2024/01/12 23:29
PHST- 2023/12/21 00:00 [accepted]
PHST- 2024/03/05 06:46 [medline]
PHST- 2024/01/13 00:42 [pubmed]
PHST- 2024/01/12 23:29 [entrez]
PHST- 2024/01/13 00:00 [pmc-release]
AID - 10.1007/s11914-023-00855-x [pii]
AID - 855 [pii]
AID - 10.1007/s11914-023-00855-x [doi]
PST - ppublish
SO  - Curr Osteoporos Rep. 2024 Feb;22(1):146-151. doi: 10.1007/s11914-023-00855-x. 
      Epub 2024 Jan 13.

PMID- 38285894
OWN - NLM
STAT- Publisher
LR  - 20240323
IS  - 1466-187X (Electronic)
IS  - 0142-159X (Linking)
DP  - 2024 Jan 29
TI  - Twelve tips on creating and using custom GPTs to enhance health professions 
      education.
PG  - 1-5
LID - 10.1080/0142159X.2024.2305365 [doi]
AB  - The custom GPT is the latest powerful feature added to ChatGPT. Non-programmers 
      can create and share their own GPTs ("chat bots"), allowing Health Professions 
      Educators to apply the capabilities of ChatGPT to create administrative 
      assistants, online tutors, virtual patients, and more, to support their clinical 
      and non-clinical teaching environments. To achieve this correctly, however, 
      requires some skills, and this 12-Tips paper provides those: we explain how to 
      construct data sources, build relevant GPTs, and apply some basic security.
FAU - Masters, Ken
AU  - Masters K
AUID- ORCID: 0000-0003-3425-5020
AD  - Department of FDE Medical Education and Informatics, Sultan Qaboos University, 
      Muscat, Oman.
FAU - Benjamin, Jennifer
AU  - Benjamin J
AUID- ORCID: 0000-0001-6085-5973
AD  - Texas Childrens Hospital, Baylor College of Medicine, Houston, TX, USA.
FAU - Agrawal, Anoop
AU  - Agrawal A
AUID- ORCID: 0000-0003-1359-0209
AD  - Emergency Medicine, Baylor College of Medicine, Houston, TX, USA.
FAU - MacNeill, Heather
AU  - MacNeill H
AUID- ORCID: 0000-0001-9842-3578
AD  - Department of Medicine, University of Toronto Temerty of Medicine, Toronto, CA, 
      USA.
FAU - Pillow, M Tyson
AU  - Pillow MT
AUID- ORCID: 0000-0001-7584-5452
AD  - Department of Education, Innovation &amp; Technology, Baylor College of Medicine, 
      Houston, TX, USA.
FAU - Mehta, Neil
AU  - Mehta N
AUID- ORCID: 0000-0001-8342-4252
AD  - Department of Internal Medicine and Geriatrics, Cleveland Clinic, Cleveland, OH, 
      USA.
LA  - eng
PT  - Journal Article
DEP - 20240129
PL  - England
TA  - Med Teach
JT  - Medical teacher
JID - 7909593
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - custom GPT
OT  - large language model
OT  - medical education
EDAT- 2024/01/29 19:57
MHDA- 2024/01/29 19:57
CRDT- 2024/01/29 14:24
PHST- 2024/01/29 19:57 [pubmed]
PHST- 2024/01/29 19:57 [medline]
PHST- 2024/01/29 14:24 [entrez]
AID - 10.1080/0142159X.2024.2305365 [doi]
PST - aheadofprint
SO  - Med Teach. 2024 Jan 29:1-5. doi: 10.1080/0142159X.2024.2305365.

PMID- 37949772
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20240214
LR  - 20240214
IS  - 2603-6479 (Electronic)
IS  - 2603-6479 (Linking)
VI  - 39
IP  - 1
DP  - 2024 Jan-Feb
TI  - [Considerations for using ChatGPT in medical practice].
PG  - 55-56
LID - S2603-6479(23)00054-4 [pii]
LID - 10.1016/j.jhqr.2023.09.007 [doi]
FAU - Iglesias-Puzas, A
AU  - Iglesias-Puzas A
AD  - Servicio de Dermatología, Hospital Universitario Clínico San Carlos, Universidad 
      Complutense, Madrid, España. Electronic address: alvaroigpu@gmail.com.
FAU - Conde-Taboada, A
AU  - Conde-Taboada A
AD  - Servicio de Dermatología, Hospital Universitario Clínico San Carlos, Universidad 
      Complutense, Madrid, España.
FAU - López-Bran, E
AU  - López-Bran E
AD  - Servicio de Dermatología, Hospital Universitario Clínico San Carlos, Universidad 
      Complutense, Madrid, España.
LA  - spa
PT  - Letter
TT  - Consideraciones sobre el uso de ChatGPT en la práctica médica.
DEP - 20231108
PL  - Spain
TA  - J Healthc Qual Res
JT  - Journal of healthcare quality research
JID - 101735273
SB  - IM
EDAT- 2023/11/11 11:43
MHDA- 2023/11/11 11:44
CRDT- 2023/11/10 21:58
PHST- 2023/04/18 00:00 [received]
PHST- 2023/05/03 00:00 [revised]
PHST- 2023/09/26 00:00 [accepted]
PHST- 2023/11/11 11:44 [medline]
PHST- 2023/11/11 11:43 [pubmed]
PHST- 2023/11/10 21:58 [entrez]
AID - S2603-6479(23)00054-4 [pii]
AID - 10.1016/j.jhqr.2023.09.007 [doi]
PST - ppublish
SO  - J Healthc Qual Res. 2024 Jan-Feb;39(1):55-56. doi: 10.1016/j.jhqr.2023.09.007. 
      Epub 2023 Nov 8.

PMID- 38438614
OWN - NLM
STAT- Publisher
LR  - 20240304
IS  - 1434-4726 (Electronic)
IS  - 0937-4477 (Linking)
DP  - 2024 Mar 4
TI  - Will ChatGPT soon replace otolaryngologists?
LID - 10.1007/s00405-024-08543-x [doi]
FAU - Mat, Quentin
AU  - Mat Q
AUID- ORCID: 0000-0001-5545-6927
AD  - Department of Otorhinolaryngology, C.H.U. Charleroi, Chaussée de Bruxelles 140, 
      6042, Charleroi, Belgium. quentin.mat@humani.be.
AD  - Faculty of Medicine and Pharmacy, University of Mons (UMons), Mons, Belgium. 
      quentin.mat@humani.be.
FAU - Briganti, Giovanni
AU  - Briganti G
AUID- ORCID: 0000-0002-4038-3363
AD  - Faculty of Medicine and Pharmacy, University of Mons (UMons), Mons, Belgium.
AD  - Department of Clinical Science, Faculty of Medicine, University of Liège, 
      Quartier Hôpital, Avenue Hippocrate 13, 4000, Liege, Belgium.
AD  - Faculty of Medicine, Université Libre de Bruxelles, Route de Lennik 808, 1070, 
      Brussels, Belgium.
FAU - Maniaci, Antonino
AU  - Maniaci A
AUID- ORCID: 0000-0002-1251-0185
AD  - Faculty of Medicine and Surgery, University of Enna "Kore", Enna, Italy.
FAU - Lelubre, Christophe
AU  - Lelubre C
AUID- ORCID: 0000-0002-7319-661X
AD  - Faculty of Medicine and Pharmacy, University of Mons (UMons), Mons, Belgium.
AD  - Department of Internal Medicine, C.H.U. Charleroi, Charleroi, Belgium.
LA  - eng
PT  - Letter
DEP - 20240304
PL  - Germany
TA  - Eur Arch Otorhinolaryngol
JT  - European archives of oto-rhino-laryngology : official journal of the European 
      Federation of Oto-Rhino-Laryngological Societies (EUFOS) : affiliated with the 
      German Society for Oto-Rhino-Laryngology - Head and Neck Surgery
JID - 9002937
SB  - IM
OTO - NOTNLM
OT  - Artificial
OT  - ChatGPT
OT  - GPT
OT  - Large language model
OT  - Medicine
OT  - Otolaryngology
EDAT- 2024/03/05 00:45
MHDA- 2024/03/05 00:45
CRDT- 2024/03/04 23:31
PHST- 2024/01/09 00:00 [received]
PHST- 2024/02/08 00:00 [accepted]
PHST- 2024/03/05 00:45 [medline]
PHST- 2024/03/05 00:45 [pubmed]
PHST- 2024/03/04 23:31 [entrez]
AID - 10.1007/s00405-024-08543-x [pii]
AID - 10.1007/s00405-024-08543-x [doi]
PST - aheadofprint
SO  - Eur Arch Otorhinolaryngol. 2024 Mar 4. doi: 10.1007/s00405-024-08543-x.

PMID- 38244612
OWN - NLM
STAT- Publisher
LR  - 20240210
IS  - 1097-6787 (Electronic)
IS  - 0190-9622 (Linking)
DP  - 2024 Jan 19
TI  - Can ChatGPT vision diagnose melanoma? An exploratory diagnostic accuracy study.
LID - S0190-9622(24)00076-8 [pii]
LID - 10.1016/j.jaad.2023.12.062 [doi]
FAU - Shifai, Naweed
AU  - Shifai N
AD  - Department of Dermatology, Netherlands Cancer Institute, Amsterdam, The 
      Netherlands.
FAU - van Doorn, Remco
AU  - van Doorn R
AD  - Department of Dermatology, Leiden University Medical Center, Leiden, The 
      Netherlands.
FAU - Malvehy, Josep
AU  - Malvehy J
AD  - Melanoma Unit, Dermatology Department, Hospital Clínic de Barcelona, IDIBAPS, 
      Universitat de Barcelona, Barcelona, Spain; Centro de Investigación Biomédica en 
      Red de Enfermedades Raras (CIBERER), Barcelona, Spain.
FAU - Sangers, Tobias E
AU  - Sangers TE
AD  - Department of Dermatology, Leiden University Medical Center, Leiden, The 
      Netherlands. Electronic address: t.e.sangers@lumc.nl.
LA  - eng
PT  - Journal Article
DEP - 20240119
PL  - United States
TA  - J Am Acad Dermatol
JT  - Journal of the American Academy of Dermatology
JID - 7907132
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - GPT-4V
OT  - Large Language Models
OT  - artificial intelligence
OT  - melanoma
OT  - nevi
OT  - skin cancer
COIS- Conflicts of interest T.E.S. reports receiving speaker fees from Janssen-Cilag, 
      UCB, Pfizer, AbbVie, Eli-Lilly, consulting fees from Mylan bv, and works on 
      research projects which were funded by an unrestricted research grant from 
      SkinVision bv, none directly related to this manuscript. J.M. declares that the 
      research at the Melanoma Unit in Hospital Clinic Barcelona is partially financed 
      by the European Commission: grant CE_HE_CANCER21_RIA, CE_H2020-SC1_20_2s04. grant 
      CE_H2020-SC1_19_1s24, grant CE H2020 SC1-BHC-06-2020/965221 — iToBoS; Instituto 
      de Salud Carlos III (ISCIII), grant PI22/01457, grant PI18/00419, grant 
      PI18/00959; Fundació La Marató de TV3, grant 718/C/2019. Part of the work was 
      carried out at the Esther Koplowitz Center, Barcelona. Josep Malvehy is 
      co-founder of Athena Tech, a spinoff of AI in melanoma with the Hospital Clinic 
      of Barcelona. N.S. and R.v.D. have no conflict of interest to declare.
EDAT- 2024/01/21 00:41
MHDA- 2024/01/21 00:41
CRDT- 2024/01/20 19:13
PHST- 2023/11/03 00:00 [received]
PHST- 2023/12/07 00:00 [revised]
PHST- 2023/12/24 00:00 [accepted]
PHST- 2024/01/21 00:41 [pubmed]
PHST- 2024/01/21 00:41 [medline]
PHST- 2024/01/20 19:13 [entrez]
AID - S0190-9622(24)00076-8 [pii]
AID - 10.1016/j.jaad.2023.12.062 [doi]
PST - aheadofprint
SO  - J Am Acad Dermatol. 2024 Jan 19:S0190-9622(24)00076-8. doi: 
      10.1016/j.jaad.2023.12.062.

PMID- 37581145
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230816
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 7
DP  - 2023 Jul
TI  - Pitfalls in the Diagnosis and Management of an Unusual Presentation of Clinically 
      Amyopathic Dermatomyositis: A Case Report Written With the Assistance of ChatGPT.
PG  - e41879
LID - 10.7759/cureus.41879 [doi]
LID - e41879
AB  - Clinically amyopathic dermatomyositis (CADM) is a rare form of dermatomyositis. 
      Patients with this condition present with the typical skin findings of 
      dermatomyositis but lack the characteristic muscle weakness associated with 
      dermatomyositis. This case presentation highlights the unusual clinical 
      manifestation of CADM in a 49-year-old Vietnamese female. The patient initially 
      presented with persistent hyperpigmented plaques on her hands, which did not 
      respond to the standard treatment for atopic dermatitis. The patient later 
      developed respiratory failure and lung fibrosis in Vietnam. This case underscores 
      the challenges in diagnosing and managing CADM, particularly in patients with 
      atypical presentations, and emphasizes the difficulties in managing such cases of 
      CADM in the community setting.
CI  - Copyright © 2023, Jansz et al.
FAU - Jansz, Jacqueline
AU  - Jansz J
AD  - Internal Medicine, University of Illinois at Chicago, Chicago, USA.
FAU - Tran, Huynh W
AU  - Tran HW
AD  - Rheumatology, Wynn Medical Center, Rosemead, USA.
FAU - Sweiss, Nadera J
AU  - Sweiss NJ
AD  - Rheumatology, University of Illinois at Chicago, Chicago, USA.
LA  - eng
PT  - Case Reports
DEP - 20230714
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10423618
OTO - NOTNLM
OT  - amyopathic dermatomyositis
OT  - anti-mda5
OT  - cadm
OT  - chatgpt
OT  - clinically amyopathic dermatomyositis
OT  - dermatomyositis
OT  - ild
OT  - interstitial lung disease
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/08/15 06:42
MHDA- 2023/08/15 06:43
PMCR- 2023/07/14
CRDT- 2023/08/15 03:38
PHST- 2023/07/14 00:00 [accepted]
PHST- 2023/08/15 06:43 [medline]
PHST- 2023/08/15 06:42 [pubmed]
PHST- 2023/08/15 03:38 [entrez]
PHST- 2023/07/14 00:00 [pmc-release]
AID - 10.7759/cureus.41879 [doi]
PST - epublish
SO  - Cureus. 2023 Jul 14;15(7):e41879. doi: 10.7759/cureus.41879. eCollection 2023 
      Jul.

PMID- 37440293
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230730
IS  - 2369-3762 (Print)
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Jul 13
TI  - Variability in Large Language Models' Responses to Medical Licensing and 
      Certification Examinations. Comment on "How Does ChatGPT Perform on the United 
      States Medical Licensing Examination? The Implications of Large Language Models 
      for Medical Education and Knowledge Assessment".
PG  - e48305
LID - 10.2196/48305 [doi]
LID - e48305
FAU - Epstein, Richard H
AU  - Epstein RH
AUID- ORCID: 0000-0001-8466-3845
AD  - Department of Anesthesiology, Perioperative Medicine and Pain Management, 
      University of Miami Miller School of Medicine, Miami, FL, United States.
FAU - Dexter, Franklin
AU  - Dexter F
AUID- ORCID: 0000-0001-5897-2484
AD  - Division of Management Consulting, Department of Anesthesia, University of Iowa, 
      Iowa City, IA, United States.
LA  - eng
PT  - Journal Article
DEP - 20230713
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
CON - JMIR Med Educ. 9:e45312.
CIN - JMIR Med Educ. 9:e50336.
PMC - PMC10375390
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - GPT
OT  - Google Bard
OT  - MedQA
OT  - NLP
OT  - artificial intelligence
OT  - chatbot
OT  - conversational agent
OT  - education technology
OT  - generative pre-trained transformer
OT  - knowledge assessment
OT  - large language models
OT  - machine learning
OT  - medical education
OT  - natural language processing
COIS- Conflicts of Interest: None declared.
EDAT- 2023/07/13 12:31
MHDA- 2023/07/13 12:32
PMCR- 2023/07/13
CRDT- 2023/07/13 11:53
PHST- 2023/04/18 00:00 [received]
PHST- 2023/06/22 00:00 [accepted]
PHST- 2023/06/16 00:00 [revised]
PHST- 2023/07/13 12:32 [medline]
PHST- 2023/07/13 12:31 [pubmed]
PHST- 2023/07/13 11:53 [entrez]
PHST- 2023/07/13 00:00 [pmc-release]
AID - v9i1e48305 [pii]
AID - 10.2196/48305 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Jul 13;9:e48305. doi: 10.2196/48305.

PMID- 37832828
OWN - NLM
STAT- MEDLINE
DCOM- 20240401
LR  - 20240401
IS  - 2468-7855 (Electronic)
IS  - 2468-7855 (Linking)
VI  - 125
IP  - 2
DP  - 2024 Apr
TI  - Virtual surgical planning in orthognathic surgery and ChatGPT-4: how artificial 
      intelligence can optimize patient care.
PG  - 101655
LID - S2468-7855(23)00276-8 [pii]
LID - 10.1016/j.jormas.2023.101655 [doi]
FAU - Santana, Lucas Alves da Mota
AU  - Santana LADM
AD  - School of Dentistry, Federal University of Sergipe (UFS), Aracaju, SE, Brazil; 
      School of Dentistry, Tiradentes University (UNIT), Aracaju, SE, Brazil. 
      Electronic address: lucassantana.pat@gmail.com.
FAU - Floresta, Lara Góis
AU  - Floresta LG
AD  - School of Dentistry, Tiradentes University (UNIT), Aracaju, SE, Brazil.
FAU - Alves, Êmilly Victória Maciel
AU  - Alves ÊVM
AD  - School of Dentistry, Tiradentes University (UNIT), Aracaju, SE, Brazil.
FAU - Barbosa, Breno Ferreira
AU  - Barbosa BF
AD  - School of Dentistry, Federal University of Sergipe (UFS), Aracaju, SE, Brazil.
FAU - Borges, Lysandro Pinto
AU  - Borges LP
AD  - Schoolof Pharmacy, Federal University of Sergipe (UFS), Aracaju, SE, Brazil.
FAU - Barreto, Marina Dos Santos
AU  - Barreto MDS
AD  - Schoolof Pharmacy, Federal University of Sergipe (UFS), Aracaju, SE, Brazil.
FAU - Santos, Ronaldy Santana
AU  - Santos RS
AD  - Schoolof Pharmacy, Federal University of Sergipe (UFS), Aracaju, SE, Brazil.
FAU - Silva, Deise Maria Rego Rodrigues
AU  - Silva DMRR
AD  - Schoolof Pharmacy, Federal University of Sergipe (UFS), Aracaju, SE, Brazil.
FAU - Palanch Repeke, Carlos Eduardo
AU  - Palanch Repeke CE
AD  - School of Dentistry, Federal University of Sergipe (UFS), Lagarto, SE, Brazil.
FAU - Brasileiro, Bernardo Ferreira
AU  - Brasileiro BF
AD  - School of Dentistry, Federal University of Sergipe (UFS), Aracaju, SE, Brazil.
FAU - Trento, Cleverson Luciano
AU  - Trento CL
AD  - School of Dentistry, Federal University of Sergipe (UFS), Aracaju, SE, Brazil.
LA  - eng
PT  - Letter
DEP - 20231011
PL  - France
TA  - J Stomatol Oral Maxillofac Surg
JT  - Journal of stomatology, oral and maxillofacial surgery
JID - 101701089
SB  - IM
MH  - Humans
MH  - *Orthognathic Surgery
MH  - Artificial Intelligence
MH  - *Orthognathic Surgical Procedures
MH  - Patient Care
MH  - Facial Bones
OTO - NOTNLM
OT  - ChatGPT
OT  - Orthognathic surgery
OT  - Virtual surgical planning
COIS- Declaration of Competing Interest The authors declare that they have no known 
      competing financial interestsor personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2023/10/14 10:41
MHDA- 2024/04/01 06:43
CRDT- 2023/10/13 19:27
PHST- 2023/09/28 00:00 [received]
PHST- 2023/10/10 00:00 [accepted]
PHST- 2024/04/01 06:43 [medline]
PHST- 2023/10/14 10:41 [pubmed]
PHST- 2023/10/13 19:27 [entrez]
AID - S2468-7855(23)00276-8 [pii]
AID - 10.1016/j.jormas.2023.101655 [doi]
PST - ppublish
SO  - J Stomatol Oral Maxillofac Surg. 2024 Apr;125(2):101655. doi: 
      10.1016/j.jormas.2023.101655. Epub 2023 Oct 11.

PMID- 38175720
OWN - NLM
STAT- MEDLINE
DCOM- 20240219
LR  - 20240219
IS  - 1536-5166 (Electronic)
IS  - 1070-8022 (Linking)
VI  - 44
IP  - 1
DP  - 2024 Mar 1
TI  - Utility of ChatGPT for Automated Creation of Patient Education Handouts: An 
      Application in Neuro-Ophthalmology.
PG  - 119-124
LID - 10.1097/WNO.0000000000002074 [doi]
AB  - BACKGROUND: Patient education in ophthalmology poses a challenge for physicians 
      because of time and resource limitations. ChatGPT (OpenAI, San Francisco) may 
      assist with automating production of patient handouts on common neuro-ophthalmic 
      diseases. METHODS: We queried ChatGPT-3.5 to generate 51 patient education 
      handouts across 17 conditions. We devised the "Quality of Generated Language 
      Outputs for Patients" (QGLOP) tool to assess handouts on the domains of 
      accuracy/comprehensiveness, bias, currency, and tone, each scored out of 4 for a 
      total of 16. A fellowship-trained neuro-ophthalmologist scored each passage. 
      Handout readability was assessed using the Simple Measure of Gobbledygook (SMOG), 
      which estimates years of education required to understand a text. RESULTS: The 
      QGLOP scores for accuracy, bias, currency, and tone were found to be 2.43, 3, 
      3.43, and 3.02 respectively. The mean QGLOP score was 11.9 [95% CI 8.98, 14.8] 
      out of 16 points, indicating a performance of 74.4% [95% CI 56.1%, 92.5%]. The 
      mean SMOG across responses as 10.9 [95% CI 9.36, 12.4] years of education. 
      CONCLUSIONS: The mean QGLOP score suggests that a fellowship-trained 
      ophthalmologist may have at-least a moderate level of satisfaction with the 
      write-up quality conferred by ChatGPT. This still requires a final review and 
      editing before dissemination. Comparatively, the rarer 5% of responses 
      collectively on either extreme would require very mild or extensive revision. 
      Also, the mean SMOG score exceeded the accepted upper limits of grade 8 reading 
      level for health-related patient handouts. In its current iteration, ChatGPT 
      should be used as an efficiency tool to generate an initial draft for the 
      neuro-ophthalmologist, who may then refine the accuracy and readability for a lay 
      readership.
CI  - Copyright © 2024 by North American Neuro-Ophthalmology Society.
FAU - Tao, Brendan K
AU  - Tao BK
AD  - Faculty of Medicine (BKT), The University of British Columbia, Vancouver, Canada 
      ; Department of Ophthalmology &amp; Vision Science (AH, EAM, JAM), University of 
      Toronto, Toronto, Canada; Temerty Faculty of Medicine (NJH), University of 
      Toronto, Toronto, Canada; Department of Ophthalmology (ARV), Max Rady College of 
      Medicine, University of Manitoba, Winnipeg, Canada; Mount Sinai Hospital (EAM), 
      Toronto, Canada; Division of Neurology (EAM, JAM), Department of Medicine, 
      University of Toronto, Toronto, Canada; Toronto Western Hospital (EAM, JAM), 
      Toronto, Canada; University Health Network (EAM, JAM), Toronto, Canada; 
      Kensington Vision and Research Center (JAM), Toronto, Canada; and St. Michael's 
      Hospital (JAM), Toronto, Canada.
FAU - Handzic, Armin
AU  - Handzic A
FAU - Hua, Nicholas J
AU  - Hua NJ
FAU - Vosoughi, Amir R
AU  - Vosoughi AR
FAU - Margolin, Edward A
AU  - Margolin EA
FAU - Micieli, Jonathan A
AU  - Micieli JA
AUID- ORCID: 0000-0003-4947-9772
LA  - eng
PT  - Journal Article
DEP - 20240104
PL  - United States
TA  - J Neuroophthalmol
JT  - Journal of neuro-ophthalmology : the official journal of the North American 
      Neuro-Ophthalmology Society
JID - 9431308
RN  - 0 (Smog)
SB  - IM
MH  - Humans
MH  - *Ophthalmology
MH  - Smog
MH  - Patient Education as Topic
MH  - Fellowships and Scholarships
MH  - *Neurology
COIS- The authors report no conflicts of interest.
EDAT- 2024/01/04 12:41
MHDA- 2024/02/19 06:42
CRDT- 2024/01/04 12:04
PHST- 2024/02/19 06:42 [medline]
PHST- 2024/01/04 12:41 [pubmed]
PHST- 2024/01/04 12:04 [entrez]
AID - 00041327-990000000-00547 [pii]
AID - 10.1097/WNO.0000000000002074 [doi]
PST - ppublish
SO  - J Neuroophthalmol. 2024 Mar 1;44(1):119-124. doi: 10.1097/WNO.0000000000002074. 
      Epub 2024 Jan 4.

PMID- 37780059
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231004
IS  - 2055-2076 (Print)
IS  - 2055-2076 (Electronic)
IS  - 2055-2076 (Linking)
VI  - 9
DP  - 2023 Jan-Dec
TI  - Changes in patient perceptions regarding ChatGPT-written explanations on 
      lifestyle modifications for preventing urolithiasis recurrence.
PG  - 20552076231203940
LID - 10.1177/20552076231203940 [doi]
LID - 20552076231203940
AB  - PURPOSE: Artificial Intelligence (AI) imitating human-like language, such as 
      ChatGPT, has impacted lives throughout various multidisciplinary fields. However, 
      despite these innovations, it is unclear how well its implementation will assist 
      patients in clinical situations. We evaluated changes in patient perceptions 
      regarding AI before and after reading a ChatGPT-written explanation. MATERIALS 
      AND METHODS: In total, 24 South Korean patients receiving urolithiasis treatment 
      were surveyed through questionnaires. The ChatGPT explanatory note was provided 
      between the first and second questionnaires, detailing lifestyle modifications 
      for preventing urolithiasis recurrence. The study questionnaire was the Korean 
      version of the General Attitudes toward Artificial Intelligence Scale, including 
      positive and negative attitude items. Wilcoxon signed-rank tests were 
      accomplished to compare questionnaire scores before and after receiving the 
      explanatory note. A linear regression analysis with stepwise elimination was used 
      to assess variable (demographic data) accuracy in predicting outcomes. RESULTS: 
      There were significant differences between total negative questionnaire scores 
      pre- and post-surveys of ChatGPT, but not in the positive scores. Among 
      variables, only education level significantly influenced mean score differences 
      in the negative questionnaires. CONCLUSIONS: The negative perception change among 
      urolithiasis patients after receiving the explanatory note provided by the AI 
      chatbot program was observed, evidencing that patients with lower education 
      levels expressed a more negative response. The explanatory note provided by the 
      AI chatbot program could provoke an adverse change in AI perception. Negative 
      human responses must be considered to improve and adapt new technology in health 
      care. Only through changing patient perspectives will upgraded AI technology 
      integrate into medical healthcare.
CI  - © The Author(s) 2023.
FAU - Kim, Seong Hwan
AU  - Kim SH
AD  - Department of Orthopedic Surgery, Chung-Ang University Hospital, Chung-Ang 
      University College of Medicine, Seoul, Republic of Korea. RINGGOLD: 26729. 
      RINGGOLD: 26729
FAU - Tae, Jong Hyun
AU  - Tae JH
AD  - Department of Urology, Chung-Ang University Hospital, Chung-Ang University 
      College of Medicine, Seoul, Republic of Korea. RINGGOLD: 26729. RINGGOLD: 26729
FAU - Chang, In Ho
AU  - Chang IH
AD  - Department of Urology, Chung-Ang University Hospital, Chung-Ang University 
      College of Medicine, Seoul, Republic of Korea. RINGGOLD: 26729. RINGGOLD: 26729
FAU - Kim, Tae-Hyoung
AU  - Kim TH
AD  - Department of Urology, Chung-Ang University Hospital, Chung-Ang University 
      College of Medicine, Seoul, Republic of Korea. RINGGOLD: 26729. RINGGOLD: 26729
FAU - Myung, Soon Chul
AU  - Myung SC
AD  - Department of Urology, Chung-Ang University Hospital, Chung-Ang University 
      College of Medicine, Seoul, Republic of Korea. RINGGOLD: 26729. RINGGOLD: 26729
FAU - Nguyen, Tuan Thanh
AU  - Nguyen TT
AD  - Department of Urology, Cho Ray Hospital, University of Medicine and Pharmacy, Ho 
      Chi Minh City, Vietnam. RINGGOLD: 58601
FAU - Choi, Joongwon
AU  - Choi J
AD  - Department of Urology, Chung-Ang University Gwangmyeong Hospital, Chung-Ang 
      University College of Medicine, Gyeonggi-do, Republic of Korea. RINGGOLD: 26729. 
      RINGGOLD: 26729
FAU - Kim, Jung Hoon
AU  - Kim JH
AD  - Department of Urology, Chung-Ang University Gwangmyeong Hospital, Chung-Ang 
      University College of Medicine, Gyeonggi-do, Republic of Korea. RINGGOLD: 26729. 
      RINGGOLD: 26729
FAU - Kim, Jin Wook
AU  - Kim JW
AD  - Department of Urology, Chung-Ang University Gwangmyeong Hospital, Chung-Ang 
      University College of Medicine, Gyeonggi-do, Republic of Korea. RINGGOLD: 26729. 
      RINGGOLD: 26729
FAU - Lee, Yong Seong
AU  - Lee YS
AD  - Department of Urology, Chung-Ang University Gwangmyeong Hospital, Chung-Ang 
      University College of Medicine, Gyeonggi-do, Republic of Korea. RINGGOLD: 26729. 
      RINGGOLD: 26729
FAU - Choi, Se Young
AU  - Choi SY
AUID- ORCID: 0000-0002-4615-0966
AD  - Department of Urology, Chung-Ang University Hospital, Chung-Ang University 
      College of Medicine, Seoul, Republic of Korea. RINGGOLD: 26729. RINGGOLD: 26729
LA  - eng
PT  - Journal Article
DEP - 20230928
PL  - United States
TA  - Digit Health
JT  - Digital health
JID - 101690863
PMC - PMC10540569
OTO - NOTNLM
OT  - Artificial intelligence
OT  - healthcare
OT  - language model
OT  - patient knowledge
OT  - ureterolithiasis
COIS- The author(s) declared no potential conflicts of interest with respect to the 
      research, authorship, and/or publication of this article.
EDAT- 2023/10/02 06:41
MHDA- 2023/10/02 06:42
PMCR- 2023/09/28
CRDT- 2023/10/02 04:21
PHST- 2023/07/14 00:00 [received]
PHST- 2023/09/09 00:00 [accepted]
PHST- 2023/10/02 06:42 [medline]
PHST- 2023/10/02 06:41 [pubmed]
PHST- 2023/10/02 04:21 [entrez]
PHST- 2023/09/28 00:00 [pmc-release]
AID - 10.1177_20552076231203940 [pii]
AID - 10.1177/20552076231203940 [doi]
PST - epublish
SO  - Digit Health. 2023 Sep 28;9:20552076231203940. doi: 10.1177/20552076231203940. 
      eCollection 2023 Jan-Dec.

PMID- 37679532
OWN - NLM
STAT- MEDLINE
DCOM- 20240101
LR  - 20240101
IS  - 1434-4726 (Electronic)
IS  - 0937-4477 (Linking)
VI  - 280
IP  - 11
DP  - 2023 Nov
TI  - Assessing the accuracy of ChatGPT references in head and neck and ENT 
      disciplines.
PG  - 5129-5133
LID - 10.1007/s00405-023-08205-4 [doi]
AB  - PURPOSE: ChatGPT has gained popularity as a web application since its release in 
      2022. While artificial intelligence (AI) systems' potential in scientific writing 
      is widely discussed, their reliability in reviewing literature and providing 
      accurate references remains unexplored. This study examines the reliability of 
      references generated by ChatGPT language models in the Head and Neck field. 
      METHODS: Twenty clinical questions were generated across different Head and Neck 
      disciplines, to prompt ChatGPT versions 3.5 and 4.0 to produce texts on the 
      assigned topics. The generated references were categorized as "true," 
      "erroneous," or "inexistent" based on congruence with existing records in 
      scientific databases. RESULTS: ChatGPT 4.0 outperformed version 3.5 in terms of 
      reference reliability. However, both versions displayed a tendency to provide 
      erroneous/non-existent references. CONCLUSIONS: It is crucial to address this 
      challenge to maintain the reliability of scientific literature. Journals and 
      institutions should establish strategies and good-practice principles in the 
      evolving landscape of AI-assisted scientific writing.
CI  - © 2023. The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, 
      part of Springer Nature.
FAU - Frosolini, Andrea
AU  - Frosolini A
AUID- ORCID: 0000-0003-1347-4013
AD  - Department of Maxillo-Facial Surgery, Policlinico Le Scotte, University of Siena, 
      Siena, Italy. andreafrosolini@gmail.com.
FAU - Franz, Leonardo
AU  - Franz L
AUID- ORCID: 0000-0002-2306-4088
AD  - Phoniatris and Audiology Unit, Department of Neuroscience DNS, University of 
      Padova, Treviso, Italy.
AD  - Artificial Intelligence in Medicine and Innovation in Clinical Research and 
      Methodology (PhD Program), Department of Clinical and Experimental Sciences, 
      University of Brescia, Brescia, Italy.
FAU - Benedetti, Simone
AU  - Benedetti S
AUID- ORCID: 0000-0002-8997-5335
AD  - Department of Maxillo-Facial Surgery, Policlinico Le Scotte, University of Siena, 
      Siena, Italy.
FAU - Vaira, Luigi Angelo
AU  - Vaira LA
AUID- ORCID: 0000-0002-7789-145X
AD  - Maxillofacial Surgery Operative Unit, Department of Medicine, Surgery and 
      Pharmacy, University of Sassari, Sassari, Italy.
AD  - PhD School of Biomedical Sciences, Department of Biomedical Sciences, University 
      of Sassari, Sassari, Italy.
FAU - de Filippis, Cosimo
AU  - de Filippis C
AUID- ORCID: 0000-0002-2491-7783
AD  - Phoniatris and Audiology Unit, Department of Neuroscience DNS, University of 
      Padova, Treviso, Italy.
FAU - Gennaro, Paolo
AU  - Gennaro P
AUID- ORCID: 0000-0002-1603-3697
AD  - Department of Maxillo-Facial Surgery, Policlinico Le Scotte, University of Siena, 
      Siena, Italy.
FAU - Marioni, Gino
AU  - Marioni G
AUID- ORCID: 0000-0001-8751-0588
AD  - Phoniatris and Audiology Unit, Department of Neuroscience DNS, University of 
      Padova, Treviso, Italy.
FAU - Gabriele, Guido
AU  - Gabriele G
AUID- ORCID: 0000-0002-1028-7493
AD  - Department of Maxillo-Facial Surgery, Policlinico Le Scotte, University of Siena, 
      Siena, Italy.
LA  - eng
PT  - Journal Article
DEP - 20230908
PL  - Germany
TA  - Eur Arch Otorhinolaryngol
JT  - European archives of oto-rhino-laryngology : official journal of the European 
      Federation of Oto-Rhino-Laryngological Societies (EUFOS) : affiliated with the 
      German Society for Oto-Rhino-Laryngology - Head and Neck Surgery
JID - 9002937
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Reproducibility of Results
MH  - *Head
MH  - Neck
MH  - Databases, Factual
OTO - NOTNLM
OT  - AI
OT  - Artificial intelligence
OT  - Chat-GPT
OT  - Head and neck surgery
OT  - Maxillofacial
EDAT- 2023/09/08 00:41
MHDA- 2024/01/02 11:42
CRDT- 2023/09/07 23:36
PHST- 2023/07/21 00:00 [received]
PHST- 2023/08/19 00:00 [accepted]
PHST- 2024/01/02 11:42 [medline]
PHST- 2023/09/08 00:41 [pubmed]
PHST- 2023/09/07 23:36 [entrez]
AID - 10.1007/s00405-023-08205-4 [pii]
AID - 10.1007/s00405-023-08205-4 [doi]
PST - ppublish
SO  - Eur Arch Otorhinolaryngol. 2023 Nov;280(11):5129-5133. doi: 
      10.1007/s00405-023-08205-4. Epub 2023 Sep 8.

PMID- 37620342
OWN - NLM
STAT- MEDLINE
DCOM- 20230828
LR  - 20231121
IS  - 2045-2322 (Electronic)
IS  - 2045-2322 (Linking)
VI  - 13
IP  - 1
DP  - 2023 Aug 24
TI  - Perception, performance, and detectability of conversational artificial 
      intelligence across 32 university courses.
PG  - 12187
LID - 10.1038/s41598-023-38964-3 [doi]
LID - 12187
AB  - The emergence of large language models has led to the development of powerful 
      tools such as ChatGPT that can produce text indistinguishable from 
      human-generated work. With the increasing accessibility of such technology, 
      students across the globe may utilize it to help with their school work-a 
      possibility that has sparked ample discussion on the integrity of student 
      evaluation processes in the age of artificial intelligence (AI). To date, it is 
      unclear how such tools perform compared to students on university-level courses 
      across various disciplines. Further, students' perspectives regarding the use of 
      such tools in school work, and educators' perspectives on treating their use as 
      plagiarism, remain unknown. Here, we compare the performance of the 
      state-of-the-art tool, ChatGPT, against that of students on 32 university-level 
      courses. We also assess the degree to which its use can be detected by two 
      classifiers designed specifically for this purpose. Additionally, we conduct a 
      global survey across five countries, as well as a more in-depth survey at the 
      authors' institution, to discern students' and educators' perceptions of 
      ChatGPT's use in school work. We find that ChatGPT's performance is comparable, 
      if not superior, to that of students in a multitude of courses. Moreover, current 
      AI-text classifiers cannot reliably detect ChatGPT's use in school work, due to 
      both their propensity to classify human-written answers as AI-generated, as well 
      as the relative ease with which AI-generated text can be edited to evade 
      detection. Finally, there seems to be an emerging consensus among students to use 
      the tool, and among educators to treat its use as plagiarism. Our findings offer 
      insights that could guide policy discussions addressing the integration of 
      artificial intelligence into educational frameworks.
CI  - © 2023. The Author(s).
FAU - Ibrahim, Hazem
AU  - Ibrahim H
AD  - Division of Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Liu, Fengyuan
AU  - Liu F
AD  - Division of Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Asim, Rohail
AU  - Asim R
AD  - Division of Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Battu, Balaraju
AU  - Battu B
AD  - Division of Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Benabderrahmane, Sidahmed
AU  - Benabderrahmane S
AD  - Division of Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Alhafni, Bashar
AU  - Alhafni B
AD  - Division of Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Adnan, Wifag
AU  - Adnan W
AD  - Division of Social Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Alhanai, Tuka
AU  - Alhanai T
AD  - Division of Engineering, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - AlShebli, Bedoor
AU  - AlShebli B
AD  - Division of Social Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Baghdadi, Riyadh
AU  - Baghdadi R
AD  - Division of Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Bélanger, Jocelyn J
AU  - Bélanger JJ
AD  - Division of Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Beretta, Elena
AU  - Beretta E
AD  - Division of Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Celik, Kemal
AU  - Celik K
AD  - Division of Engineering, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Chaqfeh, Moumena
AU  - Chaqfeh M
AD  - Division of Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Daqaq, Mohammed F
AU  - Daqaq MF
AD  - Division of Engineering, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Bernoussi, Zaynab El
AU  - Bernoussi ZE
AD  - Division of Social Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Fougnie, Daryl
AU  - Fougnie D
AD  - Division of Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Garcia de Soto, Borja
AU  - Garcia de Soto B
AD  - Division of Engineering, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Gandolfi, Alberto
AU  - Gandolfi A
AD  - Division of Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Gyorgy, Andras
AU  - Gyorgy A
AD  - Division of Engineering, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Habash, Nizar
AU  - Habash N
AD  - Division of Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Harris, J Andrew
AU  - Harris JA
AD  - Division of Social Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Kaufman, Aaron
AU  - Kaufman A
AD  - Division of Social Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Kirousis, Lefteris
AU  - Kirousis L
AD  - Division of Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Kocak, Korhan
AU  - Kocak K
AD  - Division of Social Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Lee, Kangsan
AU  - Lee K
AD  - Division of Social Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Lee, Seungah S
AU  - Lee SS
AD  - Division of Social Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Malik, Samreen
AU  - Malik S
AD  - Division of Social Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Maniatakos, Michail
AU  - Maniatakos M
AD  - Division of Engineering, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Melcher, David
AU  - Melcher D
AD  - Division of Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Mourad, Azzam
AU  - Mourad A
AD  - Division of Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Park, Minsu
AU  - Park M
AD  - Division of Social Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Rasras, Mahmoud
AU  - Rasras M
AD  - Division of Engineering, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Reuben, Alicja
AU  - Reuben A
AD  - Division of Social Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Zantout, Dania
AU  - Zantout D
AD  - Division of Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Gleason, Nancy W
AU  - Gleason NW
AD  - Division of Social Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Makovi, Kinga
AU  - Makovi K
AD  - Division of Social Science, New York University Abu Dhabi, Abu Dhabi, UAE.
FAU - Rahwan, Talal
AU  - Rahwan T
AD  - Division of Science, New York University Abu Dhabi, Abu Dhabi, UAE. 
      talal.rahwan@nyu.edu.
FAU - Zaki, Yasir
AU  - Zaki Y
AD  - Division of Science, New York University Abu Dhabi, Abu Dhabi, UAE. 
      yasir.zaki@nyu.edu.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20230824
PL  - England
TA  - Sci Rep
JT  - Scientific reports
JID - 101563288
SB  - IM
EIN - Sci Rep. 2023 Oct 10;13(1):17101. PMID: 37816805
MH  - Humans
MH  - Universities
MH  - *Artificial Intelligence
MH  - *Communication
MH  - Schools
MH  - Perception
PMC - PMC10449897
COIS- The authors declare no competing interests.
EDAT- 2023/08/25 00:42
MHDA- 2023/08/28 07:16
PMCR- 2023/08/24
CRDT- 2023/08/24 23:19
PHST- 2023/04/14 00:00 [received]
PHST- 2023/07/18 00:00 [accepted]
PHST- 2023/08/28 07:16 [medline]
PHST- 2023/08/25 00:42 [pubmed]
PHST- 2023/08/24 23:19 [entrez]
PHST- 2023/08/24 00:00 [pmc-release]
AID - 10.1038/s41598-023-38964-3 [pii]
AID - 38964 [pii]
AID - 10.1038/s41598-023-38964-3 [doi]
PST - epublish
SO  - Sci Rep. 2023 Aug 24;13(1):12187. doi: 10.1038/s41598-023-38964-3.

PMID- 38130535
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231223
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 11
DP  - 2023 Nov
TI  - A Study on Distinguishing ChatGPT-Generated and Human-Written Orthopaedic 
      Abstracts by Reviewers: Decoding the Discrepancies.
PG  - e49166
LID - 10.7759/cureus.49166 [doi]
LID - e49166
AB  - BACKGROUND: ChatGPT (OpenAI Incorporated, Mission District, San Francisco, United 
      States)&nbsp;is an artificial intelligence (AI)-based language model that generates 
      human-resembling texts. This AI-generated literary work is comprehensible&nbsp;and 
      contextually relevant and it is really difficult to differentiate from 
      human-written content. ChatGPT has risen in popularity lately and is widely 
      utilized in scholarly manuscript drafting. The aim of this study is to identify 
      if 1) human reviewers can differentiate between AI-generated and human-written 
      abstracts and&nbsp;2) AI detectors are currently reliable in detecting AI-generated 
      abstracts. METHODS: Seven blinded reviewers were asked to read 21 abstracts and 
      differentiate which were AI-generated and which were human-written. The first 
      group consisted of three orthopaedic residents with limited research experience 
      (OR). The second group included three orthopaedic professors with extensive 
      research experience (OP). The seventh reviewer was a non-orthopaedic doctor and 
      acted as a control in terms of expertise. All abstracts were scanned by a 
      plagiarism detector program. The performance of detecting AI-generated abstracts 
      of two different AI detectors was also analyzed. A structured interview was 
      conducted at the end of the survey in order to evaluate the decision-making 
      process utilized by each reviewer. RESULTS: The OR group managed to identify 
      correctly 34.9% of the abstracts' authorship and the OP group 31.7%. The 
      non-orthopaedic control identified correctly 76.2%. All AI-generated abstracts 
      were 100% unique (0% plagiarism). The first AI detector managed to identify 
      correctly only 9/21 (42.9%) of the abstracts' authors, whereas the second AI 
      detector identified 14/21 (66.6%). CONCLUSION: Inability to correctly identify 
      AI-generated context poses a significant scientific risk as "false" abstracts can 
      end up in scientific conferences or publications.&nbsp;Neither expertise nor research 
      background was shown to have any meaningful impact on the predictive outcome. 
      Focus on statistical data presentation may help the differentiation process. 
      Further research is warranted in order to highlight which elements could help 
      reveal an AI-generated abstract.
CI  - Copyright © 2023, Makiev et al.
FAU - Makiev, Konstantinos G
AU  - Makiev KG
AD  - Department of Orthopaedics, University General Hospital of Alexandroupolis, 
      Democritus University of Thrace, Alexandroupoli, GRC.
FAU - Asimakidou, Maria
AU  - Asimakidou M
AD  - School of Medicine, University General Hospital of Alexandroupolis, Democritus 
      University of Thrace, Alexandroupoli, GRC.
FAU - Vasios, Ioannis S
AU  - Vasios IS
AD  - Department of Orthopaedics, University General Hospital of Alexandroupolis, 
      Democritus University of Thrace, Alexandroupoli, GRC.
FAU - Keskinis, Anthimos
AU  - Keskinis A
AD  - Department of Orthopaedics, University General Hospital of Alexandroupolis, 
      Democritus University of Thrace, Alexandroupoli, GRC.
FAU - Petkidis, Georgios
AU  - Petkidis G
AD  - Department of Orthopaedics, University General Hospital of Alexandroupolis, 
      Democritus University of Thrace, Alexandroupoli, GRC.
FAU - Tilkeridis, Konstantinos
AU  - Tilkeridis K
AD  - Department of Orthopaedics, University General Hospital of Alexandroupolis, 
      Democritus University of Thrace, Alexandroupoli, GRC.
FAU - Ververidis, Athanasios
AU  - Ververidis A
AD  - Department of Orthopaedics, University General Hospital of Alexandroupolis, 
      Democritus University of Thrace, Alexandroupoli, GRC.
FAU - Iliopoulos, Efthymios
AU  - Iliopoulos E
AD  - Department of Orthopaedics, University General Hospital of Alexandroupolis, 
      Democritus University of Thrace, Alexandroupoli, GRC.
LA  - eng
PT  - Journal Article
DEP - 20231121
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10733892
OTO - NOTNLM
OT  - ai detector
OT  - artificial intelligence
OT  - chatgpt
OT  - identification
OT  - orthopaedic abstracts
OT  - reviewers
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/12/22 06:43
MHDA- 2023/12/22 06:44
PMCR- 2023/11/21
CRDT- 2023/12/22 03:53
PHST- 2023/11/21 00:00 [accepted]
PHST- 2023/12/22 06:44 [medline]
PHST- 2023/12/22 06:43 [pubmed]
PHST- 2023/12/22 03:53 [entrez]
PHST- 2023/11/21 00:00 [pmc-release]
AID - 10.7759/cureus.49166 [doi]
PST - epublish
SO  - Cureus. 2023 Nov 21;15(11):e49166. doi: 10.7759/cureus.49166. eCollection 2023 
      Nov.

PMID- 37106269
OWN - NLM
STAT- MEDLINE
DCOM- 20230605
LR  - 20231119
IS  - 1708-0428 (Electronic)
IS  - 0960-8923 (Print)
IS  - 0960-8923 (Linking)
VI  - 33
IP  - 6
DP  - 2023 Jun
TI  - Assessing the Accuracy of Responses by the Language Model ChatGPT to Questions 
      Regarding Bariatric Surgery.
PG  - 1790-1796
LID - 10.1007/s11695-023-06603-5 [doi]
AB  - PURPOSE: ChatGPT is a large&nbsp;language model trained on a large dataset covering a 
      broad range of topics, including the medical literature. We aim to examine its 
      accuracy and reproducibility in answering patient questions regarding bariatric 
      surgery. MATERIALS AND METHODS: Questions were gathered from nationally regarded 
      professional societies and health institutions as well as Facebook support 
      groups. Board-certified bariatric surgeons graded the accuracy and 
      reproducibility of responses. The grading scale included the following: (1) 
      comprehensive, (2) correct but inadequate, (3) some correct and some incorrect, 
      and (4) completely incorrect. Reproducibility was determined by asking the model 
      each question twice and examining difference in grading category between the two 
      responses. RESULTS: In total, 151 questions related to bariatric surgery were 
      included. The model provided "comprehensive" responses to 131/151 (86.8%) of 
      questions. When examined by category, the model provided "comprehensive" 
      responses to 93.8% of questions related to "efficacy, eligibility and procedure 
      options"; 93.3% related to "preoperative preparation"; 85.3% related to 
      "recovery, risks, and complications"; 88.2% related to "lifestyle changes"; and 
      66.7% related to "other". The model provided reproducible answers to 137 (90.7%) 
      of questions. CONCLUSION: The large&nbsp;language model ChatGPT often provided 
      accurate and reproducible responses to common questions related to bariatric 
      surgery. ChatGPT may serve as a helpful adjunct information resource for patients 
      regarding bariatric surgery in addition to standard of care provided by licensed 
      healthcare professionals. We encourage future studies to examine how to leverage 
      this disruptive technology to improve patient outcomes and quality of life.
CI  - © 2023. The Author(s).
FAU - Samaan, Jamil S
AU  - Samaan JS
AUID- ORCID: 0000-0002-6191-2631
AD  - Karsh Division of Gastroenterology and Hepatology, Cedars-Sinai Medical Center, 
      8700 Beverly Blvd, Los Angeles, CA, 90048, USA. jamil.samaan@gmail.com.
FAU - Yeo, Yee Hui
AU  - Yeo YH
AD  - Karsh Division of Gastroenterology and Hepatology, Cedars-Sinai Medical Center, 
      8700 Beverly Blvd, Los Angeles, CA, 90048, USA.
FAU - Rajeev, Nithya
AU  - Rajeev N
AD  - Division of Upper GI and General Surgery, Department of Surgery, Health Care 
      Consultation Center, Keck School of Medicine of USC, 1510 San Pablo St. #514, Los 
      Angeles, CA, 90033, USA.
FAU - Hawley, Lauren
AU  - Hawley L
AD  - Division of Upper GI and General Surgery, Department of Surgery, Health Care 
      Consultation Center, Keck School of Medicine of USC, 1510 San Pablo St. #514, Los 
      Angeles, CA, 90033, USA.
FAU - Abel, Stuart
AU  - Abel S
AD  - Division of Upper GI and General Surgery, Department of Surgery, Health Care 
      Consultation Center, Keck School of Medicine of USC, 1510 San Pablo St. #514, Los 
      Angeles, CA, 90033, USA.
FAU - Ng, Wee Han
AU  - Ng WH
AD  - Bristol Medical School, University of Bristol, 5 Tyndall Ave, Bristol, BS8 1UD, 
      UK.
FAU - Srinivasan, Nitin
AU  - Srinivasan N
AD  - Division of Upper GI and General Surgery, Department of Surgery, Health Care 
      Consultation Center, Keck School of Medicine of USC, 1510 San Pablo St. #514, Los 
      Angeles, CA, 90033, USA.
FAU - Park, Justin
AU  - Park J
AD  - Division of Upper GI and General Surgery, Department of Surgery, Health Care 
      Consultation Center, Keck School of Medicine of USC, 1510 San Pablo St. #514, Los 
      Angeles, CA, 90033, USA.
FAU - Burch, Miguel
AU  - Burch M
AD  - Department of Surgery, Cedars-Sinai Medical Center, 8700 Beverly Blvd, Los 
      Angeles, CA, 90048, USA.
FAU - Watson, Rabindra
AU  - Watson R
AD  - Karsh Division of Gastroenterology and Hepatology, Cedars-Sinai Medical Center, 
      8700 Beverly Blvd, Los Angeles, CA, 90048, USA.
FAU - Liran, Omer
AU  - Liran O
AD  - Department of Psychiatry and Behavioral Sciences, Cedars-Sinai Medical Center, 
      8700 Beverly Blvd, Los Angeles, CA, 90048, USA.
AD  - Division of Health Services Research, Department of Medicine, Cedars-Sinai 
      Medical Center, 8700 Beverly Blvd, Los Angeles, CA, 90048, USA.
FAU - Samakar, Kamran
AU  - Samakar K
AD  - Division of Upper GI and General Surgery, Department of Surgery, Health Care 
      Consultation Center, Keck School of Medicine of USC, 1510 San Pablo St. #514, Los 
      Angeles, CA, 90033, USA.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20230427
PL  - United States
TA  - Obes Surg
JT  - Obesity surgery
JID - 9106714
SB  - IM
CIN - Obes Surg. 2023 Aug;33(8):2588-2589. PMID: 37301782
CIN - Obes Surg. 2023 Aug;33(8):2590-2591. PMID: 37312008
CIN - Obes Surg. 2023 Aug;33(8):2596. PMID: 37351764
CIN - Obes Surg. 2023 Aug;33(8):2597. PMID: 37353693
MH  - Humans
MH  - Quality of Life
MH  - Reproducibility of Results
MH  - *Obesity, Morbid/surgery
MH  - *Bariatric Surgery
MH  - Language
PMC - PMC10234918
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Bariatric surgery
OT  - ChatGPT
OT  - Health literacy
OT  - Language learning models
OT  - Weight loss
COIS- The authors declare no competing interests.
EDAT- 2023/04/28 00:42
MHDA- 2023/06/05 06:42
PMCR- 2023/04/27
CRDT- 2023/04/27 23:32
PHST- 2023/02/21 00:00 [received]
PHST- 2023/04/17 00:00 [accepted]
PHST- 2023/04/10 00:00 [revised]
PHST- 2023/06/05 06:42 [medline]
PHST- 2023/04/28 00:42 [pubmed]
PHST- 2023/04/27 23:32 [entrez]
PHST- 2023/04/27 00:00 [pmc-release]
AID - 10.1007/s11695-023-06603-5 [pii]
AID - 6603 [pii]
AID - 10.1007/s11695-023-06603-5 [doi]
PST - ppublish
SO  - Obes Surg. 2023 Jun;33(6):1790-1796. doi: 10.1007/s11695-023-06603-5. Epub 2023 
      Apr 27.

PMID- 37648742
OWN - NLM
STAT- MEDLINE
DCOM- 20230901
LR  - 20231119
IS  - 2045-2322 (Electronic)
IS  - 2045-2322 (Linking)
VI  - 13
IP  - 1
DP  - 2023 Aug 30
TI  - Performance of ChatGPT, human radiologists, and context-aware ChatGPT in 
      identifying AO codes from radiology reports.
PG  - 14215
LID - 10.1038/s41598-023-41512-8 [doi]
LID - 14215
AB  - While radiologists can describe a fracture's morphology and complexity with ease, 
      the translation into classification systems such as the Arbeitsgemeinschaft 
      Osteosynthesefragen (AO) Fracture and Dislocation Classification Compendium is 
      more challenging. We tested the performance of generic chatbots and chatbots 
      aware of specific knowledge of the AO classification provided by a vector-index 
      and compared it to human readers. In the 100 radiological reports we created 
      based on random AO codes, chatbots provided AO codes significantly faster than 
      humans (mean 3.2&nbsp;s per case vs. 50&nbsp;s per case, p &lt; .001) though not reaching 
      human performance (max. chatbot performance of 86% correct full AO codes vs. 95% 
      in human readers). In general, chatbots based on GPT 4 outperformed the ones 
      based on GPT 3.5-Turbo. Further, we found that providing specific knowledge 
      substantially enhances the chatbot's performance and consistency as the 
      context-aware chatbot based on GPT 4 provided 71% consistent correct full AO 
      codes for the compared to the 2% consistent correct full AO codes for the generic 
      ChatGPT 4. This provides evidence, that refining and providing specific context 
      to ChatGPT will be the next essential step in harnessing its power.
CI  - © 2023. Springer Nature Limited.
FAU - Russe, Maximilian F
AU  - Russe MF
AD  - Department of Diagnostic and Interventional Radiology, Medical Center - 
      University of Freiburg, Faculty of Medicine, University of Freiburg, Breisacher 
      Str. 64, 79106, Freiburg, Germany. maximilian.russe@uniklinik-freiburg.de.
FAU - Fink, Anna
AU  - Fink A
AD  - Department of Diagnostic and Interventional Radiology, Medical Center - 
      University of Freiburg, Faculty of Medicine, University of Freiburg, Breisacher 
      Str. 64, 79106, Freiburg, Germany.
FAU - Ngo, Helen
AU  - Ngo H
AD  - Department of Diagnostic and Interventional Radiology, Medical Center - 
      University of Freiburg, Faculty of Medicine, University of Freiburg, Breisacher 
      Str. 64, 79106, Freiburg, Germany.
FAU - Tran, Hien
AU  - Tran H
AD  - Department of Diagnostic and Interventional Radiology, Medical Center - 
      University of Freiburg, Faculty of Medicine, University of Freiburg, Breisacher 
      Str. 64, 79106, Freiburg, Germany.
FAU - Bamberg, Fabian
AU  - Bamberg F
AD  - Department of Diagnostic and Interventional Radiology, Medical Center - 
      University of Freiburg, Faculty of Medicine, University of Freiburg, Breisacher 
      Str. 64, 79106, Freiburg, Germany.
FAU - Reisert, Marco
AU  - Reisert M
AD  - Department of Stereotactic and Functional Neurosurgery, Medical Center - 
      University of Freiburg, Faculty of Medicine, University of Freiburg, Freiburg, 
      Germany.
AD  - Medical Physics, Department of Diagnostic and Interventional Radiology, Medical 
      Center - University of Freiburg, Faculty of Medicine, University of Freiburg, 
      Freiburg, Germany.
FAU - Rau, Alexander
AU  - Rau A
AD  - Department of Diagnostic and Interventional Radiology, Medical Center - 
      University of Freiburg, Faculty of Medicine, University of Freiburg, Breisacher 
      Str. 64, 79106, Freiburg, Germany.
AD  - Department of Neuroradiology, Medical Center - University of Freiburg, Faculty of 
      Medicine, University of Freiburg, Freiburg, Germany.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20230830
PL  - England
TA  - Sci Rep
JT  - Scientific reports
JID - 101563288
RN  - 0 (Drugs, Generic)
SB  - IM
MH  - Humans
MH  - Awareness
MH  - Drugs, Generic
MH  - *Fractures, Bone
MH  - Radiologists
MH  - *Radiology
PMC - PMC10468502
COIS- The authors declare no competing interests.
EDAT- 2023/08/31 00:41
MHDA- 2023/09/01 06:42
PMCR- 2023/08/30
CRDT- 2023/08/30 23:20
PHST- 2023/05/15 00:00 [received]
PHST- 2023/08/28 00:00 [accepted]
PHST- 2023/09/01 06:42 [medline]
PHST- 2023/08/31 00:41 [pubmed]
PHST- 2023/08/30 23:20 [entrez]
PHST- 2023/08/30 00:00 [pmc-release]
AID - 10.1038/s41598-023-41512-8 [pii]
AID - 41512 [pii]
AID - 10.1038/s41598-023-41512-8 [doi]
PST - epublish
SO  - Sci Rep. 2023 Aug 30;13(1):14215. doi: 10.1038/s41598-023-41512-8.

PMID- 37256297
OWN - NLM
STAT- MEDLINE
DCOM- 20231023
LR  - 20240205
IS  - 1432-5241 (Electronic)
IS  - 0364-216X (Linking)
VI  - 47
IP  - 5
DP  - 2023 Oct
TI  - The Artificial Intelligence application in Aesthetic Medicine: How ChatGPT can 
      Revolutionize the Aesthetic World.
PG  - 2211-2212
LID - 10.1007/s00266-023-03416-w [doi]
AB  - Aesthetic medicine is witnessing a growing importance of ChatGPT and artificial 
      intelligence (AI) technologies, as highlighted by the pioneering work of Xie et 
      al. in their article, "Aesthetic Surgery Advice and Counseling from Artificial 
      Intelligence: A Rhinoplasty Consultation with ChatGPT." These advancements 
      promise to revolutionize patient consultations, treatment planning, and follow-up 
      care. AI-driven chatbots, such as ChatGPT, can enhance patient consultations by 
      providing accurate and reliable information on aesthetic procedures, their risks, 
      benefits, and potential outcomes, enabling well-informed decisions and improved 
      treatment outcomes. Furthermore, AI can personalize treatment plans by analyzing 
      patient data, leading to increased precision and satisfaction. AI-powered 
      platforms can also streamline patient follow-up and monitoring, improving patient 
      outcomes and resource utilization, while serving as a valuable educational tool 
      for clinicians. Despite these benefits, AI integration in aesthetic medicine 
      raises concerns about data privacy, security, and potential biases in AI 
      algorithms. To address these challenges, the aesthetic medicine community must 
      establish ethical guidelines, adopt stringent security protocols, and ensure 
      diverse and representative datasets for AI training. Additionally, maintaining 
      the personal connection between patients and providers is crucial for preserving 
      the human touch in patient care.Level of Evidence V This journal requires that 
      authors assign a level of evidence to each article. For a full description of 
      these Evidence-Based Medicine ratings, please refer to the Table of Contents or 
      the online Instructions to Authors https://www.springer.com/00266 .
CI  - © 2023. Springer Science+Business Media, LLC, part of Springer Nature and 
      International Society of Aesthetic Plastic Surgery.
FAU - Buzzaccarini, Giovanni
AU  - Buzzaccarini G
AUID- ORCID: 0000-0002-9466-0178
AD  - Department of Obstetrics and Gynaecology, IRCCS San Raffaele Scientific 
      Institute, Vita-Salute San Raffaele University, Via Olgettina 58-60, 20132, 
      Milan, Italy. giovanni.buzzaccarini@gmail.com.
FAU - Degliuomini, Rebecca Susanna
AU  - Degliuomini RS
AD  - Department of Obstetrics and Gynaecology, IRCCS San Raffaele Scientific 
      Institute, Vita-Salute San Raffaele University, Via Olgettina 58-60, 20132, 
      Milan, Italy.
FAU - Borin, Marco
AU  - Borin M
AD  - U.O.C. Otorhinolaryngology, ASST Grande Ospedale Metropolitano Niguarda, Piazza 
      Ospedale Maggiore, 3, 20162, Milan, Italy.
LA  - eng
PT  - Comment
PT  - Letter
DEP - 20230531
PL  - United States
TA  - Aesthetic Plast Surg
JT  - Aesthetic plastic surgery
JID - 7701756
SB  - IM
CON - Aesthetic Plast Surg. 2023 Oct;47(5):1985-1993. PMID: 37095384
CIN - Aesthetic Plast Surg. 2023 Oct;47(5):2213-2214. PMID: 37314465
MH  - Humans
MH  - *Surgery, Plastic/methods
MH  - Artificial Intelligence
MH  - *Rhinoplasty/methods
MH  - Treatment Outcome
MH  - Esthetics
EDAT- 2023/05/31 13:12
MHDA- 2023/10/23 00:42
CRDT- 2023/05/31 11:03
PHST- 2023/05/10 00:00 [received]
PHST- 2023/05/11 00:00 [accepted]
PHST- 2023/10/23 00:42 [medline]
PHST- 2023/05/31 13:12 [pubmed]
PHST- 2023/05/31 11:03 [entrez]
AID - 10.1007/s00266-023-03416-w [pii]
AID - 10.1007/s00266-023-03416-w [doi]
PST - ppublish
SO  - Aesthetic Plast Surg. 2023 Oct;47(5):2211-2212. doi: 10.1007/s00266-023-03416-w. 
      Epub 2023 May 31.

PMID- 37009366
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230404
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 3
DP  - 2023 Mar
TI  - Medical Literature Writing With ChatGPT: A Rare Case of Choriocarcinoma Syndrome 
      With Hemorrhagic Brain Metastases Due to Burned Out Metastatic Mixed Testicular 
      Cancer.
PG  - e36655
LID - 10.7759/cureus.36655 [doi]
LID - e36655
AB  - Testicular tumors are one of the most commonly observed malignancies among men. 
      An aggressive and rare subtype of the disease, testicular choriocarcinoma, has a 
      worse prognosis due to the tendency of early hematogenous spread to multiple 
      organs and advanced symptoms at presentation time. Characteristic features of 
      choriocarcinoma include elevated beta human chorionic gonadotropin (β-hCG) in a 
      young male with testicular mass. However, when the primary testicular tumor 
      overutilizes its blood supply and spontaneously regresses, it is presumed to have 
      been "burnt out" with remnants evident by metastatic retroperitoneal 
      lymphadenopathy, scarred tissue, and calcifications. Treatment of advanced 
      testicular cancer may be complicated by a rare entity known as choriocarcinoma 
      syndrome, distinguished by rapid and fatal hemorrhaging of metastatic tumor 
      sites. Prior described cases of choriocarcinoma syndrome involve pulmonary and 
      gastrointestinal hemorrhages. We present an uncommon case of a 34-year-old male 
      with a "burnt out" metastatic mixed testicular cancer who presented with 
      choriocarcinoma syndrome (CS) treated with chemotherapy but developed deadly 
      hemorrhaging of brain metastases. In addition, with the assistance of ChatGPT, we 
      report our experience with this OpenAI tool and its potential uses in medical 
      literature writing.
CI  - Copyright © 2023, Le et al.
FAU - Le, David P
AU  - Le DP
AD  - Internal Medicine, University of South Alabama, Mobile, USA.
FAU - Hall, Samuel C
AU  - Hall SC
AD  - Internal Medicine, University of South Alabama, Mobile, USA.
LA  - eng
PT  - Case Reports
DEP - 20230324
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10065126
OTO - NOTNLM
OT  - burned-out testicular tumor
OT  - chatgpt
OT  - choriocarcinoma
OT  - choriocarcinoma syndrome
OT  - embryonal cell carcinoma
OT  - germ cell and embryonal neoplasms
OT  - intracerebral hemorrhage
OT  - metastatic testicular cancer
OT  - pulmonary hemorrhage
OT  - testicular cancer
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/04/04 06:00
MHDA- 2023/04/04 06:01
PMCR- 2023/03/24
CRDT- 2023/04/03 04:26
PHST- 2023/03/24 00:00 [accepted]
PHST- 2023/04/04 06:01 [medline]
PHST- 2023/04/03 04:26 [entrez]
PHST- 2023/04/04 06:00 [pubmed]
PHST- 2023/03/24 00:00 [pmc-release]
AID - 10.7759/cureus.36655 [doi]
PST - epublish
SO  - Cureus. 2023 Mar 24;15(3):e36655. doi: 10.7759/cureus.36655. eCollection 2023 
      Mar.

PMID- 38290872
OWN - NLM
STAT- Publisher
LR  - 20240130
IS  - 1578-8989 (Electronic)
IS  - 0025-7753 (Linking)
DP  - 2024 Jan 29
TI  - Massive generation of synthetic medical records with ChatGPT: An example in hip 
      fractures.
LID - S0025-7753(24)00002-2 [pii]
LID - 10.1016/j.medcli.2023.11.027 [doi]
FAU - Calvo-Lorenzo, Isidoro
AU  - Calvo-Lorenzo I
AD  - Servicio de Cirugía Ortopédica y Traumatología, Hospital Universitario Galdakao 
      Usansolo, Galdakao, Vizcaya, España. Electronic address: isidorocalvo@gmail.com.
FAU - Uriarte-Llano, Iker
AU  - Uriarte-Llano I
AD  - Servicio de Cirugía Ortopédica y Traumatología, Hospital Universitario Galdakao 
      Usansolo, Galdakao, Vizcaya, España.
LA  - eng
LA  - spa
PT  - Journal Article
TT  - Generación masiva de historias clínicas sintéticas con ChatGPT: un ejemplo en 
      fractura de cadera.
DEP - 20240129
PL  - Spain
TA  - Med Clin (Barc)
JT  - Medicina clinica
JID - 0376377
SB  - IM
EDAT- 2024/01/31 00:42
MHDA- 2024/01/31 00:42
CRDT- 2024/01/30 21:59
PHST- 2023/09/21 00:00 [received]
PHST- 2023/11/20 00:00 [revised]
PHST- 2023/11/22 00:00 [accepted]
PHST- 2024/01/31 00:42 [medline]
PHST- 2024/01/31 00:42 [pubmed]
PHST- 2024/01/30 21:59 [entrez]
AID - S0025-7753(24)00002-2 [pii]
AID - 10.1016/j.medcli.2023.11.027 [doi]
PST - aheadofprint
SO  - Med Clin (Barc). 2024 Jan 29:S0025-7753(24)00002-2. doi: 
      10.1016/j.medcli.2023.11.027.

PMID- 38044041
OWN - NLM
STAT- Publisher
LR  - 20231203
IS  - 1444-0938 (Electronic)
IS  - 0816-4622 (Linking)
DP  - 2023 Dec 3
TI  - Accuracy of a Large Language Model as a new tool for optometry education.
PG  - 1-4
LID - 10.1080/08164622.2023.2288174 [doi]
AB  - CLINICAL RELEVANCE: The unsupervised introduction of certain Artificial 
      Intelligence tools in optometry education may challenge the proper acquisition of 
      accurate clinical knowledge and skills proficiency. BACKGROUND: Large Language 
      Models like ChatGPT (Generative Pretrained Transformer) are increasingly being 
      used by researchers and students for work and academic assignments. The 
      authoritative and conversationally correct language provided by these tools may 
      mask their inherent limitations when presented with specific scientific and 
      clinical queries. METHODS: Three sets of 10 queries related to contact lenses &amp; 
      anterior eye, low vision and binocular vision &amp; vision therapy were presented to 
      ChatGPT, with instructions to provide five relevant references to support each 
      response. Three experts and 53 undergraduate and post-graduate students graded 
      from 0 to 10 the accuracy of the responses, and the references were evaluated for 
      precision and relevance. Students graded from 0 to 10 the potential usefulness of 
      ChatGPT for their academic coursework. RESULTS: Median scores were 7, 8 and 6 
      (experts) and 8, 9 and 7.5 (students) for the contact lenses &amp; anterior eye, low 
      vision and binocular vision &amp; vision therapy categories, respectively. Responses 
      to more specific queries were awarded lower scores by both experts (ρ = -0.612; 
      P &lt; 0.001) and students (ρ = -0.578; P = 0.001). Of 150 references, 24% were 
      accurate and 19.3% relevant. Students graded the usefulness of ChatGPT with 7.5 
      (2 to 9), 7 (3 to 9) and 8.5 (3 to 10) for contact lenses &amp; anterior eye, low 
      vision and binocular vision &amp; vision therapy, respectively. CONCLUSION: Careful 
      expert appraisal of the responses and, particularly, of the references provided 
      by ChatGPT is required in research and academic settings. As the use of these 
      tools becomes widespread, it is essential to take proactive steps to address 
      their limitations and ensure their responsible use.
FAU - Cardona, Genis
AU  - Cardona G
AUID- ORCID: 0000-0002-4770-8992
AD  - Department of Optics and Optometry, Universitat Politècnica de Catalunya, 
      Terrassa, Spain.
FAU - Argiles, Marc
AU  - Argiles M
AUID- ORCID: 0000-0001-5474-9832
AD  - Department of Optics and Optometry, Universitat Politècnica de Catalunya, 
      Terrassa, Spain.
FAU - Pérez-Mañá, Lluis
AU  - Pérez-Mañá L
AUID- ORCID: 0000-0002-8672-7803
AD  - Department of Optics and Optometry, Universitat Politècnica de Catalunya, 
      Terrassa, Spain.
LA  - eng
PT  - Journal Article
DEP - 20231203
PL  - United States
TA  - Clin Exp Optom
JT  - Clinical &amp; experimental optometry
JID - 8703442
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Large Language Model
OT  - ethics
OT  - optometry education
EDAT- 2023/12/04 00:42
MHDA- 2023/12/04 00:42
CRDT- 2023/12/03 21:22
PHST- 2023/12/04 00:42 [medline]
PHST- 2023/12/04 00:42 [pubmed]
PHST- 2023/12/03 21:22 [entrez]
AID - 10.1080/08164622.2023.2288174 [doi]
PST - aheadofprint
SO  - Clin Exp Optom. 2023 Dec 3:1-4. doi: 10.1080/08164622.2023.2288174.

PMID- 38172581
OWN - NLM
STAT- Publisher
LR  - 20240103
IS  - 1476-5454 (Electronic)
IS  - 0950-222X (Linking)
DP  - 2024 Jan 3
TI  - ChatGPT and Beyond: An overview of the growing field of large language models and 
      their use in ophthalmology.
LID - 10.1038/s41433-023-02915-z [doi]
AB  - ChatGPT, an artificial intelligence (AI) chatbot built on large language models 
      (LLMs), has rapidly gained popularity. The benefits and limitations of this 
      transformative technology have been discussed across various fields, including 
      medicine. The widespread availability of ChatGPT has enabled clinicians to study 
      how these tools could be used for a variety of tasks such as generating 
      differential diagnosis lists, organizing patient notes, and synthesizing 
      literature for scientific research. LLMs have shown promising capabilities in 
      ophthalmology by performing well on the Ophthalmic Knowledge Assessment Program, 
      providing fairly accurate responses to questions about retinal diseases, and in 
      generating differential diagnoses list. There are current limitations to this 
      technology, including the propensity of LLMs to "hallucinate", or confidently 
      generate false information; their potential role in perpetuating biases in 
      medicine; and the challenges in incorporating LLMs into research without allowing 
      "AI-plagiarism" or publication of false information. In this paper, we provide a 
      balanced overview of what LLMs are and introduce some of the LLMs that have been 
      generated in the past few years. We discuss recent literature evaluating the role 
      of these language models in medicine with a focus on ChatGPT. The field of AI is 
      fast-paced, and new applications based on LLMs are being generated rapidly; 
      therefore, it is important for ophthalmologists to be aware of how this 
      technology works and how it may impact patient care. Here, we discuss the 
      benefits, limitations, and future advancements of LLMs in patient care and 
      research.
CI  - © 2023. The Author(s), under exclusive licence to The Royal College of 
      Ophthalmologists.
FAU - Kedia, Nikita
AU  - Kedia N
AD  - Department of Ophthalmology, University of Pittsburgh School of Medicine, 
      Pittsburgh, PA, USA.
FAU - Sanjeev, Suvansh
AU  - Sanjeev S
AD  - Brilliantly AI Research and Consulting, Pittsburgh, PA, USA.
FAU - Ong, Joshua
AU  - Ong J
AUID- ORCID: 0000-0003-4860-827X
AD  - Department of Ophthalmology and Visual Sciences, University of Michigan Kellogg 
      Eye Center, Ann Arbor, MI, USA.
FAU - Chhablani, Jay
AU  - Chhablani J
AUID- ORCID: 0000-0003-1772-3558
AD  - Department of Ophthalmology, University of Pittsburgh School of Medicine, 
      Pittsburgh, PA, USA. jay.chhablani@gmail.com.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20240103
PL  - England
TA  - Eye (Lond)
JT  - Eye (London, England)
JID - 8703986
SB  - IM
EDAT- 2024/01/04 11:43
MHDA- 2024/01/04 11:43
CRDT- 2024/01/03 23:40
PHST- 2023/04/26 00:00 [received]
PHST- 2023/12/20 00:00 [accepted]
PHST- 2023/11/23 00:00 [revised]
PHST- 2024/01/04 11:43 [medline]
PHST- 2024/01/04 11:43 [pubmed]
PHST- 2024/01/03 23:40 [entrez]
AID - 10.1038/s41433-023-02915-z [pii]
AID - 10.1038/s41433-023-02915-z [doi]
PST - aheadofprint
SO  - Eye (Lond). 2024 Jan 3. doi: 10.1038/s41433-023-02915-z.

PMID- 36909067
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230314
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 2
DP  - 2023 Feb
TI  - Acute Pulmonary Edema After Hyperbaric Oxygen Treatment: A Case Report Written 
      With ChatGPT Assistance.
PG  - e34752
LID - 10.7759/cureus.34752 [doi]
LID - e34752
AB  - Acute pulmonary edema is a rare but severe complication of hyperbaric oxygen 
      therapy. While patients with known cardiovascular problems may be able to 
      withstand this therapy, rapid decompensation can still occur. Here, we present a 
      case of a patient with known low ejection fraction and severe mitral 
      regurgitation who developed acute pulmonary edema during the first hyperbaric 
      treatment for a foot ulcer. This case highlights the importance of identifying 
      patients that are high risk, such as those with moderate-to-severe cardiac 
      disease, and pursuing other treatment options to avoid this complication.
CI  - Copyright © 2023, Akhter et al.
FAU - Akhter, Haris M
AU  - Akhter HM
AD  - Hyperbaric Medicine, University of Nebraska Medical Center, Omaha, USA.
FAU - Cooper, Jeffrey S
AU  - Cooper JS
AD  - Hyperbaric Medicine, University of Nebraska Medical Center, Omaha, USA.
LA  - eng
PT  - Case Reports
DEP - 20230207
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC9998302
OTO - NOTNLM
OT  - acute pulmonary edema
OT  - chatgpt
OT  - diabetes
OT  - heart failure with reduced ejection fraction
OT  - hyperbaric oxygen therapy (hbot)
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/03/14 06:00
MHDA- 2023/03/14 06:01
PMCR- 2023/02/07
CRDT- 2023/03/13 03:54
PHST- 2023/02/07 00:00 [accepted]
PHST- 2023/03/13 03:54 [entrez]
PHST- 2023/03/14 06:00 [pubmed]
PHST- 2023/03/14 06:01 [medline]
PHST- 2023/02/07 00:00 [pmc-release]
AID - 10.7759/cureus.34752 [doi]
PST - epublish
SO  - Cureus. 2023 Feb 7;15(2):e34752. doi: 10.7759/cureus.34752. eCollection 2023 Feb.

PMID- 38564173
OWN - NLM
STAT- Publisher
LR  - 20240402
IS  - 1708-0428 (Electronic)
IS  - 0960-8923 (Linking)
DP  - 2024 Apr 2
TI  - ChatGPT as a Source of Information for Bariatric Surgery Patients: a Comparative 
      Analysis of Accuracy and Comprehensiveness Between GPT-4 and GPT-3.5.
LID - 10.1007/s11695-024-07212-6 [doi]
FAU - Samaan, Jamil S
AU  - Samaan JS
AUID- ORCID: 0000-0002-6191-2631
AD  - Karsh Division of Digestive and Liver Diseases, Department of Medicine, 
      Cedars-Sinai Medical Center, 8700 Beverly Blvd, Los Angeles, CA, 90048, USA. 
      jamil.samaan@gmail.com.
FAU - Rajeev, Nithya
AU  - Rajeev N
AD  - Division of Upper GI and General Surgery, Department of Surgery, Keck School of 
      Medicine of USC, Health Care Consultation Center, 1510 San Pablo St #514, Los 
      Angeles, CA, 90033, USA.
FAU - Ng, Wee Han
AU  - Ng WH
AD  - Bristol Medical School, University of Bristol, 5 Tyndall Ave, Bristol, BS8 1UD, 
      UK.
FAU - Srinivasan, Nitin
AU  - Srinivasan N
AD  - Division of Upper GI and General Surgery, Department of Surgery, Keck School of 
      Medicine of USC, Health Care Consultation Center, 1510 San Pablo St #514, Los 
      Angeles, CA, 90033, USA.
FAU - Busam, Jonathan A
AU  - Busam JA
AD  - Karsh Division of Digestive and Liver Diseases, Department of Medicine, 
      Cedars-Sinai Medical Center, 8700 Beverly Blvd, Los Angeles, CA, 90048, USA.
FAU - Yeo, Yee Hui
AU  - Yeo YH
AD  - Karsh Division of Digestive and Liver Diseases, Department of Medicine, 
      Cedars-Sinai Medical Center, 8700 Beverly Blvd, Los Angeles, CA, 90048, USA.
FAU - Samakar, Kamran
AU  - Samakar K
AD  - Division of Upper GI and General Surgery, Department of Surgery, Keck School of 
      Medicine of USC, Health Care Consultation Center, 1510 San Pablo St #514, Los 
      Angeles, CA, 90033, USA.
LA  - eng
PT  - Journal Article
DEP - 20240402
PL  - United States
TA  - Obes Surg
JT  - Obesity surgery
JID - 9106714
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Bariatric surgery
OT  - ChatGPT
OT  - GPT-3.5
OT  - GPT-4
OT  - Surgery
OT  - Weight loss
EDAT- 2024/04/02 12:47
MHDA- 2024/04/02 12:47
CRDT- 2024/04/02 11:24
PHST- 2023/10/03 00:00 [received]
PHST- 2024/03/28 00:00 [accepted]
PHST- 2024/03/22 00:00 [revised]
PHST- 2024/04/02 12:47 [medline]
PHST- 2024/04/02 12:47 [pubmed]
PHST- 2024/04/02 11:24 [entrez]
AID - 10.1007/s11695-024-07212-6 [pii]
AID - 10.1007/s11695-024-07212-6 [doi]
PST - aheadofprint
SO  - Obes Surg. 2024 Apr 2. doi: 10.1007/s11695-024-07212-6.

PMID- 37852647
OWN - NLM
STAT- MEDLINE
DCOM- 20231207
LR  - 20231207
IS  - 1535-5675 (Electronic)
IS  - 0091-4916 (Linking)
VI  - 51
IP  - 4
DP  - 2023 Dec 5
TI  - GPT-4 in Nuclear Medicine Education: Does It Outperform GPT-3.5?
PG  - 314-317
LID - 10.2967/jnmt.123.266485 [doi]
AB  - The emergence of ChatGPT has challenged academic integrity in teaching 
      institutions, including those providing nuclear medicine training. Although 
      previous evaluations of ChatGPT have suggested a limited scope for academic 
      writing, the March 2023 release of generative pretrained transformer (GPT)-4 
      promises enhanced capabilities that require evaluation. Methods: Examinations 
      (final and calculation) and written assignments for nuclear medicine subjects 
      were tested using GPT-3.5 and GPT-4. GPT-3.5 and GPT-4 responses were evaluated 
      by Turnitin software for artificial intelligence scores, marked against 
      standardized rubrics, and compared with the mean performance of student cohorts. 
      Results: ChatGPT powered by GPT-3.5 performed poorly in calculation examinations 
      (31.4%), compared with GPT-4 (59.1%). GPT-3.5 failed each of 3 written tasks 
      (39.9%), whereas GPT-4 passed each task (56.3%). Conclusion: Although GPT-3.5 
      poses a minimal risk to academic integrity, its usefulness as a cheating tool can 
      be significantly enhanced by GPT-4 but remains prone to hallucination and 
      fabrication.
CI  - © 2023 by the Society of Nuclear Medicine and Molecular Imaging.
FAU - Currie, Geoffrey M
AU  - Currie GM
AD  - Charles Sturt University, Wagga Wagga, New South Wales, Australia 
      gcurrie@csu.edu.au.
LA  - eng
PT  - Journal Article
DEP - 20231205
PL  - United States
TA  - J Nucl Med Technol
JT  - Journal of nuclear medicine technology
JID - 0430303
SB  - IM
MH  - Humans
MH  - *Nuclear Medicine
MH  - Artificial Intelligence
MH  - Radionuclide Imaging
MH  - Students
MH  - Software
OTO - NOTNLM
OT  - academic integrity
OT  - artificial intelligence
OT  - generative algorithms
OT  - higher education
OT  - patient education
OT  - scientific writing
EDAT- 2023/10/19 00:44
MHDA- 2023/12/07 12:42
CRDT- 2023/10/18 20:43
PHST- 2023/08/02 00:00 [received]
PHST- 2023/09/12 00:00 [revised]
PHST- 2023/12/07 12:42 [medline]
PHST- 2023/10/19 00:44 [pubmed]
PHST- 2023/10/18 20:43 [entrez]
AID - jnmt.123.266485 [pii]
AID - 10.2967/jnmt.123.266485 [doi]
PST - epublish
SO  - J Nucl Med Technol. 2023 Dec 5;51(4):314-317. doi: 10.2967/jnmt.123.266485.

PMID- 38454175
OWN - NLM
STAT- Publisher
LR  - 20240307
IS  - 2578-5745 (Electronic)
IS  - 2578-5745 (Linking)
DP  - 2024 Mar 7
TI  - A Novel Approach for Mixed-Methods Research Using Large Language Models: A Report 
      Using Patients' Perspectives on Barriers to Arthroplasty.
LID - 10.1002/acr2.11662 [doi]
AB  - OBJECTIVE: Mixed-methods research is valuable in health care to gain insights 
      into patient perceptions. However, analyzing textual data from interviews can be 
      time-consuming and require multiple analysts for investigator triangulation. This 
      study aims to explore a novel approach to investigator triangulation in 
      mixed-methods research by employing a large language model (LLM) for analyzing 
      data from patient interviews. METHODS: This study compared the thematic analysis 
      and survey generation performed by human investigators and ChatGPT-4, which uses 
      GPT-4 as its backbone model, using data from an existing study that explored 
      patient perceptions of barriers to arthroplasty. The human- and 
      ChatGPT-4-generated themes and surveys were compared and evaluated based on their 
      representation of salient themes from a predetermined topic guide. RESULTS: 
      ChatGPT-4 generated analogous dominant themes and a comprehensive corresponding 
      survey as the human investigators but in significantly less time. The survey 
      questions generated by ChatGPT-4 were less precise than those developed by human 
      investigators. The mixed-methods flowchart proposes integrating LLMs and human 
      investigators as a supplementary tool for the preliminary thematic analysis of 
      qualitative data and survey generation. CONCLUSION: By utilizing a combination of 
      LLMs and human investigators through investigator triangulation, researchers may 
      be able to conduct more efficient mixed-methods research to better understand 
      patient perspectives. Ethical and qualitative implications of using LLMs should 
      be considered.
CI  - © 2024 The Authors. ACR Open Rheumatology published by Wiley Periodicals LLC on 
      behalf of American College of Rheumatology.
FAU - Mannstadt, Insa
AU  - Mannstadt I
AD  - Hospital for Special Surgery, New York, NY.
FAU - Goodman, Susan M
AU  - Goodman SM
AUID- ORCID: 0000-0003-1197-7864
AD  - Weill Cornell Medicine and Hospital for Special Surgery, New York, NY.
FAU - Rajan, Mangala
AU  - Rajan M
AD  - Hospital for Special Surgery, New York, NY.
AD  - Department of Medicine, Weill Cornell Medicine, New York, NY.
FAU - Young, Sarah R
AU  - Young SR
AD  - Binghamton University, Binghamton, NY.
FAU - Wang, Fei
AU  - Wang F
AD  - Hospital for Special Surgery, New York, NY.
AD  - Department of Population Health Sciences, Weill Cornell Medical College, Cornell 
      University, New York, NY.
FAU - Navarro-Millán, Iris
AU  - Navarro-Millán I
AUID- ORCID: 0000-0002-9540-6614
AD  - Weill Cornell Medicine and Hospital for Special Surgery, New York, NY.
FAU - Mehta, Bella
AU  - Mehta B
AUID- ORCID: 0000-0003-2535-0974
AD  - Weill Cornell Medicine and Hospital for Special Surgery, New York, NY.
LA  - eng
PT  - Journal Article
DEP - 20240307
PL  - United States
TA  - ACR Open Rheumatol
JT  - ACR open rheumatology
JID - 101740025
EDAT- 2024/03/08 00:43
MHDA- 2024/03/08 00:43
CRDT- 2024/03/07 23:51
PHST- 2024/01/23 00:00 [revised]
PHST- 2023/04/27 00:00 [received]
PHST- 2024/02/09 00:00 [accepted]
PHST- 2024/03/08 00:43 [medline]
PHST- 2024/03/08 00:43 [pubmed]
PHST- 2024/03/07 23:51 [entrez]
AID - 10.1002/acr2.11662 [doi]
PST - aheadofprint
SO  - ACR Open Rheumatol. 2024 Mar 7. doi: 10.1002/acr2.11662.

PMID- 37757748
OWN - NLM
STAT- MEDLINE
DCOM- 20240321
LR  - 20240321
IS  - 1938-2367 (Electronic)
IS  - 0147-7447 (Linking)
VI  - 47
IP  - 2
DP  - 2024 Mar-Apr
TI  - The Rapid Development of Artificial Intelligence: GPT-4's Performance on 
      Orthopedic Surgery Board Questions.
PG  - e85-e89
LID - 10.3928/01477447-20230922-05 [doi]
AB  - Advances in artificial intelligence and machine learning models, like Chat 
      Generative Pre-trained Transformer (ChatGPT), have occurred at a remarkably fast 
      rate. OpenAI released its newest model of ChatGPT, GPT-4, in March 2023. It 
      offers a wide range of medical applications. The model has demonstrated notable 
      proficiency on many medical board examinations. This study sought to assess 
      GPT-4's performance on the Orthopaedic In-Training Examination (OITE) used to 
      prepare residents for the American Board of Orthopaedic Surgery (ABOS) Part I 
      Examination. The data gathered from GPT-4's performance were additionally 
      compared with the data of the previous iteration of ChatGPT, GPT-3.5, which was 
      released 4 months before GPT-4. GPT-4 correctly answered 251 of the 396 attempted 
      questions (63.4%), whereas GPT-3.5 correctly answered 46.3% of 410 attempted 
      questions. GPT-4 was significantly more accurate than GPT-3.5 on orthopedic 
      board-style questions (P&lt;.00001). GPT-4's performance is most comparable to that 
      of an average third-year orthopedic surgery resident, while GPT-3.5 performed 
      below an average orthopedic intern. GPT-4's overall accuracy was just below the 
      approximate threshold that indicates a likely pass on the ABOS Part I 
      Examination. Our results demonstrate significant improvements in OpenAI's newest 
      model, GPT-4. Future studies should assess potential clinical applications as AI 
      models continue to be trained on larger data sets and offer more capabilities. 
      [Orthopedics. 2024;47(2):e85-e89.].
FAU - Hofmann, Hayden L
AU  - Hofmann HL
FAU - Guerra, Gage A
AU  - Guerra GA
FAU - Le, Jonathan L
AU  - Le JL
FAU - Wong, Alexander M
AU  - Wong AM
FAU - Hofmann, Grady H
AU  - Hofmann GH
FAU - Mayfield, Cory K
AU  - Mayfield CK
FAU - Petrigliano, Frank A
AU  - Petrigliano FA
FAU - Liu, Joseph N
AU  - Liu JN
LA  - eng
PT  - Journal Article
DEP - 20230927
PL  - United States
TA  - Orthopedics
JT  - Orthopedics
JID - 7806107
SB  - IM
MH  - Humans
MH  - *Orthopedics/education
MH  - *Internship and Residency
MH  - Artificial Intelligence
MH  - Educational Measurement
MH  - Clinical Competence
MH  - *Orthopedic Procedures
EDAT- 2023/09/28 00:42
MHDA- 2024/03/21 12:44
CRDT- 2023/09/27 18:13
PHST- 2024/03/21 12:44 [medline]
PHST- 2023/09/28 00:42 [pubmed]
PHST- 2023/09/27 18:13 [entrez]
AID - 10.3928/01477447-20230922-05 [doi]
PST - ppublish
SO  - Orthopedics. 2024 Mar-Apr;47(2):e85-e89. doi: 10.3928/01477447-20230922-05. Epub 
      2023 Sep 27.

PMID- 38521671
OWN - NLM
STAT- Publisher
LR  - 20240323
IS  - 1878-3562 (Electronic)
IS  - 1590-8658 (Linking)
DP  - 2024 Mar 22
TI  - Author's reply: AI in medicine, bridging the chasm between potential and 
      capability.
LID - S1590-8658(24)00298-6 [pii]
LID - 10.1016/j.dld.2024.02.017 [doi]
FAU - Zhang, Yiwen
AU  - Zhang Y
AD  - Department of Endocrinology and Metabolic Hepatology, The Affiliated Hospital of 
      Qingdao University, Qingdao, China.
FAU - Xu, Lili
AU  - Xu L
AD  - Department of Endocrinology and Metabolic Hepatology, The Affiliated Hospital of 
      Qingdao University, Qingdao, China.
FAU - Ji, Hongwei
AU  - Ji H
AD  - Tsinghua Medicine, Beijing Tsinghua Changgung Hospital, Tsinghua University, 
      Beijing, China. Electronic address: hongweijicn@gmail.com.
LA  - eng
PT  - Letter
DEP - 20240322
PL  - Netherlands
TA  - Dig Liver Dis
JT  - Digestive and liver disease : official journal of the Italian Society of 
      Gastroenterology and the Italian Association for the Study of the Liver
JID - 100958385
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Large language models
COIS- Conflicts of interest None.
EDAT- 2024/03/24 00:42
MHDA- 2024/03/24 00:42
CRDT- 2024/03/23 23:22
PHST- 2024/02/25 00:00 [received]
PHST- 2024/02/28 00:00 [revised]
PHST- 2024/02/29 00:00 [accepted]
PHST- 2024/03/24 00:42 [medline]
PHST- 2024/03/24 00:42 [pubmed]
PHST- 2024/03/23 23:22 [entrez]
AID - S1590-8658(24)00298-6 [pii]
AID - 10.1016/j.dld.2024.02.017 [doi]
PST - aheadofprint
SO  - Dig Liver Dis. 2024 Mar 22:S1590-8658(24)00298-6. doi: 10.1016/j.dld.2024.02.017.

PMID- 38382193
OWN - NLM
STAT- Publisher
LR  - 20240222
IS  - 1943-569X (Electronic)
IS  - 0003-1488 (Linking)
DP  - 2024 Feb 21
TI  - Two artificial intelligence models underperform on examinations in a veterinary 
      curriculum.
PG  - 1-6
LID - 10.2460/javma.23.12.0666 [doi]
AB  - OBJECTIVE: Advancements in artificial intelligence (AI) and large language models 
      have rapidly generated new possibilities for education and knowledge 
      dissemination in various domains. Currently, our understanding of the knowledge 
      of these models, such as ChatGPT, in the medical and veterinary sciences is in 
      its nascent stage. Educators are faced with an urgent need to better understand 
      these models in order to unleash student potential, promote responsible use, and 
      align AI models with educational goals and learning objectives. The objectives of 
      this study were to evaluate the knowledge level and consistency of responses of 2 
      platforms of ChatGPT, namely GPT-3.5 and GPT-4.0. SAMPLE: A total of 495 
      multiple-choice and true/false questions from 15 courses used in the assessment 
      of third-year veterinary students at a single veterinary institution were 
      included in this study. METHODS: The questions were manually entered 3 times into 
      each platform, and answers were recorded. These answers were then compared 
      against those provided by the faculty members coordinating the courses. RESULTS: 
      GPT-3.5 achieved an overall performance score of 55%, whereas GPT-4.0 had a 
      significantly (P &lt; .05) greater performance score of 77%. Importantly, the 
      performance scores of both platforms were significantly (P &lt; .05) below that of 
      the veterinary students (86%). CLINICAL RELEVANCE: Findings of this study 
      suggested that veterinary educators and veterinary students retrieving 
      information from these AI-based platforms should do so with caution.
FAU - Coleman, Michelle C
AU  - Coleman MC
FAU - Moore, James N
AU  - Moore JN
LA  - eng
PT  - Journal Article
DEP - 20240221
PL  - United States
TA  - J Am Vet Med Assoc
JT  - Journal of the American Veterinary Medical Association
JID - 7503067
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - curriculum
OT  - education
OT  - large language models
EDAT- 2024/02/22 00:42
MHDA- 2024/02/22 00:42
CRDT- 2024/02/21 18:04
PHST- 2023/12/05 00:00 [received]
PHST- 2024/01/08 00:00 [accepted]
PHST- 2024/02/22 00:42 [pubmed]
PHST- 2024/02/22 00:42 [medline]
PHST- 2024/02/21 18:04 [entrez]
AID - 10.2460/javma.23.12.0666 [doi]
PST - aheadofprint
SO  - J Am Vet Med Assoc. 2024 Feb 21:1-6. doi: 10.2460/javma.23.12.0666.

PMID- 38032714
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231217
IS  - 2369-3762 (Print)
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Nov 30
TI  - Can we use ChatGPT for Mental Health and Substance Use Education? Examining Its 
      Quality and Potential Harms.
PG  - e51243
LID - 10.2196/51243 [doi]
LID - e51243
AB  - BACKGROUND: The use of generative artificial intelligence, more specifically 
      large language models (LLMs), is proliferating, and as such, it is vital to 
      consider both the value and potential harms of its use in medical education. 
      Their efficiency in a variety of writing styles makes LLMs, such as ChatGPT, 
      attractive for tailoring educational materials. However, this technology can 
      feature biases and misinformation, which can be particularly harmful in medical 
      education settings, such as mental health and substance use education. This 
      viewpoint investigates if ChatGPT is sufficient for 2 common health education 
      functions in the field of mental health and substance use: (1) answering users' 
      direct queries and (2) aiding in the development of quality consumer educational 
      health materials. OBJECTIVE: This viewpoint includes a case study to provide 
      insight into the accessibility, biases, and quality of ChatGPT's query responses 
      and educational health materials. We aim to provide guidance for the general 
      public and health educators wishing to utilize LLMs. METHODS: We collected real 
      world queries from 2 large-scale mental health and substance use portals and 
      engineered a variety of prompts to use on GPT-4 Pro with the Bing BETA internet 
      browsing plug-in. The outputs were evaluated with tools from the Sydney Health 
      Literacy Lab to determine the accessibility, the adherence to Mindframe 
      communication guidelines to identify biases, and author assessments on quality, 
      including tailoring to audiences, duty of care disclaimers, and evidence-based 
      internet references. RESULTS: GPT-4's outputs had good face validity, but upon 
      detailed analysis were substandard in comparison to expert-developed materials. 
      Without engineered prompting, the reading level, adherence to communication 
      guidelines, and use of evidence-based websites were poor. Therefore, all outputs 
      still required cautious human editing and oversight. CONCLUSIONS: GPT-4 is 
      currently not reliable enough for direct-consumer queries, but educators and 
      researchers can use it for creating educational materials with caution. Materials 
      created with LLMs should disclose the use of generative artificial intelligence 
      and be evaluated on their efficacy with the target audience.
CI  - ©Sophia Spallek, Louise Birrell, Stephanie Kershaw, Emma Krogh Devine, Louise 
      Thornton. Originally published in JMIR Medical Education 
      (https://mededu.jmir.org), 30.11.2023.
FAU - Spallek, Sophia
AU  - Spallek S
AUID- ORCID: 0000-0001-5222-1794
AD  - The Matilda Centre for Research in Mental Health and Substance Use, The 
      University of Sydney, Sydney, Australia.
FAU - Birrell, Louise
AU  - Birrell L
AUID- ORCID: 0000-0002-1335-1382
AD  - The Matilda Centre for Research in Mental Health and Substance Use, The 
      University of Sydney, Sydney, Australia.
FAU - Kershaw, Stephanie
AU  - Kershaw S
AUID- ORCID: 0000-0003-2494-4391
AD  - The Matilda Centre for Research in Mental Health and Substance Use, The 
      University of Sydney, Sydney, Australia.
FAU - Devine, Emma Krogh
AU  - Devine EK
AUID- ORCID: 0000-0001-8110-6445
AD  - The Matilda Centre for Research in Mental Health and Substance Use, The 
      University of Sydney, Sydney, Australia.
FAU - Thornton, Louise
AU  - Thornton L
AUID- ORCID: 0000-0001-7705-833X
AD  - The Matilda Centre for Research in Mental Health and Substance Use, The 
      University of Sydney, Sydney, Australia.
LA  - eng
PT  - Journal Article
DEP - 20231130
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
PMC - PMC10722374
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - educational intervention
OT  - generative artificial intelligence
OT  - health education
OT  - large language models
OT  - medical education
OT  - mental health
OT  - patient education handout
OT  - preventive health services
OT  - substance use
COIS- Conflicts of Interest: None declared.
EDAT- 2023/11/30 12:42
MHDA- 2023/11/30 12:43
PMCR- 2023/11/30
CRDT- 2023/11/30 11:54
PHST- 2023/07/26 00:00 [received]
PHST- 2023/11/08 00:00 [accepted]
PHST- 2023/11/02 00:00 [revised]
PHST- 2023/11/30 12:43 [medline]
PHST- 2023/11/30 12:42 [pubmed]
PHST- 2023/11/30 11:54 [entrez]
PHST- 2023/11/30 00:00 [pmc-release]
AID - v9i1e51243 [pii]
AID - 10.2196/51243 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Nov 30;9:e51243. doi: 10.2196/51243.

PMID- 38441945
OWN - NLM
STAT- MEDLINE
DCOM- 20240306
LR  - 20240322
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 26
DP  - 2024 Mar 5
TI  - What's in a Name? Experimental Evidence of Gender Bias in Recommendation Letters 
      Generated by ChatGPT.
PG  - e51837
LID - 10.2196/51837 [doi]
LID - e51837
AB  - BACKGROUND: Artificial intelligence chatbots such as ChatGPT (OpenAI) have 
      garnered excitement about their potential for delegating writing tasks ordinarily 
      performed by humans. Many of these tasks (eg, writing recommendation letters) 
      have social and professional ramifications, making the potential social biases in 
      ChatGPT's underlying language model a serious concern. OBJECTIVE: Three 
      preregistered studies used the text analysis program Linguistic Inquiry and Word 
      Count to investigate gender bias in recommendation letters written by ChatGPT in 
      human-use sessions (N=1400 total letters). METHODS: We conducted analyses using 
      22 existing Linguistic Inquiry and Word Count dictionaries, as well as 6 newly 
      created dictionaries based on systematic reviews of gender bias in recommendation 
      letters, to compare recommendation letters generated for the 200 most 
      historically popular "male" and "female" names in the United States. Study 1 used 
      3 different letter-writing prompts intended to accentuate professional 
      accomplishments associated with male stereotypes, female stereotypes, or neither. 
      Study 2 examined whether lengthening each of the 3 prompts while holding the 
      between-prompt word count constant modified the extent of bias. Study 3 examined 
      the variability within letters generated for the same name and prompts. We 
      hypothesized that when prompted with gender-stereotyped professional 
      accomplishments, ChatGPT would evidence gender-based language differences 
      replicating those found in systematic reviews of human-written recommendation 
      letters (eg, more affiliative, social, and communal language for female names; 
      more agentic and skill-based language for male names). RESULTS: Significant 
      differences in language between letters generated for female versus male names 
      were observed across all prompts, including the prompt hypothesized to be 
      neutral, and across nearly all language categories tested. Historically female 
      names received significantly more social referents (5/6, 83% of prompts), 
      communal or doubt-raising language (4/6, 67% of prompts), personal pronouns (4/6, 
      67% of prompts), and clout language (5/6, 83% of prompts). Contradicting the 
      study hypotheses, some gender differences (eg, achievement language and agentic 
      language) were significant in both the hypothesized and nonhypothesized 
      directions, depending on the prompt. Heteroscedasticity between male and female 
      names was observed in multiple linguistic categories, with greater variance for 
      historically female names than for historically male names. CONCLUSIONS: ChatGPT 
      reproduces many gender-based language biases that have been reliably identified 
      in investigations of human-written reference letters, although these differences 
      vary across prompts and language categories. Caution should be taken when using 
      ChatGPT for tasks that have social consequences, such as reference letter 
      writing. The methods developed in this study may be useful for ongoing bias 
      testing among progressive generations of chatbots across a range of real-world 
      scenarios. TRIAL REGISTRATION: OSF Registries osf.io/ztv96; https://osf.io/ztv96.
CI  - ©Deanna M Kaplan, Roman Palitsky, Santiago J Arconada Alvarez, Nicole S Pozzo, 
      Morgan N Greenleaf, Ciara A Atkinson, Wilbur A Lam. Originally published in the 
      Journal of Medical Internet Research (https://www.jmir.org), 05.03.2024.
FAU - Kaplan, Deanna M
AU  - Kaplan DM
AUID- ORCID: 0000-0002-9300-3029
AD  - Department of Family and Preventive Medicine, Emory University School of 
      Medicine, Atlanta, GA, United States.
FAU - Palitsky, Roman
AU  - Palitsky R
AUID- ORCID: 0000-0002-0415-6411
AD  - Emory Spiritual Health, Woodruff Health Science Center, Emory University, 
      Atlanta, GA, United States.
FAU - Arconada Alvarez, Santiago J
AU  - Arconada Alvarez SJ
AUID- ORCID: 0000-0003-0737-6679
AD  - Emory University School of Medicine, Atlanta, GA, United States.
FAU - Pozzo, Nicole S
AU  - Pozzo NS
AUID- ORCID: 0009-0003-7325-6373
AD  - Department of Family and Preventive Medicine, Emory University School of 
      Medicine, Atlanta, GA, United States.
FAU - Greenleaf, Morgan N
AU  - Greenleaf MN
AUID- ORCID: 0000-0003-1569-5696
AD  - Emory University School of Medicine, Atlanta, GA, United States.
FAU - Atkinson, Ciara A
AU  - Atkinson CA
AUID- ORCID: 0000-0003-0835-7883
AD  - Department of Campus Recreation, University of Arizona, Tucson, AZ, United 
      States.
FAU - Lam, Wilbur A
AU  - Lam WA
AUID- ORCID: 0000-0002-0325-7990
AD  - Wallace H Coulter Department of Biomedical Engineering, Georgia Institute of 
      Technology and Emory University, Atlanta, GA, United States.
LA  - eng
PT  - Journal Article
DEP - 20240305
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - Female
MH  - Male
MH  - *Artificial Intelligence
MH  - *Sexism
MH  - Systematic Reviews as Topic
MH  - Language
MH  - Linguistics
PMC - PMC10951834
OTO - NOTNLM
OT  - AI
OT  - artificial intelligence
OT  - chatbot
OT  - chatbots
OT  - gender bias
OT  - gender-based language
OT  - generative AI
OT  - generative artificial intelligence
OT  - human written
OT  - language model
OT  - large language models
OT  - letters of recommendation
OT  - real-world
OT  - recommendation letter
OT  - scenario
COIS- Conflicts of Interest: None declared.
EDAT- 2024/03/05 12:43
MHDA- 2024/03/06 06:43
PMCR- 2024/03/05
CRDT- 2024/03/05 11:53
PHST- 2023/08/14 00:00 [received]
PHST- 2023/11/27 00:00 [accepted]
PHST- 2023/11/12 00:00 [revised]
PHST- 2024/03/06 06:43 [medline]
PHST- 2024/03/05 12:43 [pubmed]
PHST- 2024/03/05 11:53 [entrez]
PHST- 2024/03/05 00:00 [pmc-release]
AID - v26i1e51837 [pii]
AID - 10.2196/51837 [doi]
PST - epublish
SO  - J Med Internet Res. 2024 Mar 5;26:e51837. doi: 10.2196/51837.

PMID- 38009003
OWN - NLM
STAT- MEDLINE
DCOM- 20231229
LR  - 20240114
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 25
DP  - 2023 Dec 28
TI  - Evaluation of the Performance of Generative AI Large Language Models ChatGPT, 
      Google Bard, and Microsoft Bing Chat in Supporting Evidence-Based Dentistry: 
      Comparative Mixed Methods Study.
PG  - e51580
LID - 10.2196/51580 [doi]
LID - e51580
AB  - BACKGROUND: The increasing application of generative artificial intelligence 
      large language models (LLMs) in various fields, including dentistry, raises 
      questions about their accuracy. OBJECTIVE: This study aims to comparatively 
      evaluate the answers provided by 4 LLMs, namely Bard (Google LLC), ChatGPT-3.5 
      and ChatGPT-4 (OpenAI), and Bing Chat (Microsoft Corp), to clinically relevant 
      questions from the field of dentistry. METHODS: The LLMs were queried with 20 
      open-type, clinical dentistry-related questions from different disciplines, 
      developed by the respective faculty of the School of Dentistry, European 
      University Cyprus. The LLMs' answers were graded 0 (minimum) to 10 (maximum) 
      points against strong, traditionally collected scientific evidence, such as 
      guidelines and consensus statements, using a rubric, as if they were examination 
      questions posed to students, by 2 experienced faculty members. The scores were 
      statistically compared to identify the best-performing model using the Friedman 
      and Wilcoxon tests. Moreover, the evaluators were asked to provide a qualitative 
      evaluation of the comprehensiveness, scientific accuracy, clarity, and relevance 
      of the LLMs' answers. RESULTS: Overall, no statistically significant difference 
      was detected between the scores given by the 2 evaluators; therefore, an average 
      score was computed for every LLM. Although ChatGPT-4 statistically outperformed 
      ChatGPT-3.5 (P=.008), Bing Chat (P=.049), and Bard (P=.045), all models 
      occasionally exhibited inaccuracies, generality, outdated content, and a lack of 
      source references. The evaluators noted instances where the LLMs delivered 
      irrelevant information, vague answers, or information that was not fully 
      accurate. CONCLUSIONS: This study demonstrates that although LLMs hold promising 
      potential as an aid in the implementation of evidence-based dentistry, their 
      current limitations can lead to potentially harmful health care decisions if not 
      used judiciously. Therefore, these tools should not replace the dentist's 
      critical thinking and in-depth understanding of the subject matter. Further 
      research, clinical validation, and model improvements are necessary for these 
      tools to be fully integrated into dental practice. Dental practitioners must be 
      aware of the limitations of LLMs, as their imprudent use could potentially impact 
      patient care. Regulatory measures should be established to oversee the use of 
      these evolving technologies.
CI  - ©Kostis Giannakopoulos, Argyro Kavadella, Anas Aaqel Salim, Vassilis 
      Stamatopoulos, Eleftherios G Kaklamanos. Originally published in the Journal of 
      Medical Internet Research (https://www.jmir.org), 28.12.2023.
FAU - Giannakopoulos, Kostis
AU  - Giannakopoulos K
AUID- ORCID: 0000-0001-7008-7306
AD  - School of Dentistry, European University Cyprus, Nicosia, Cyprus.
FAU - Kavadella, Argyro
AU  - Kavadella A
AUID- ORCID: 0009-0003-0560-8373
AD  - School of Dentistry, European University Cyprus, Nicosia, Cyprus.
FAU - Aaqel Salim, Anas
AU  - Aaqel Salim A
AUID- ORCID: 0000-0002-7731-6666
AD  - School of Dentistry, European University Cyprus, Nicosia, Cyprus.
FAU - Stamatopoulos, Vassilis
AU  - Stamatopoulos V
AUID- ORCID: 0000-0002-9044-796X
AD  - Information Management Systems Institute, ATHENA Research and Innovation Center, 
      Athens, Greece.
FAU - Kaklamanos, Eleftherios G
AU  - Kaklamanos EG
AUID- ORCID: 0000-0002-0513-5110
AD  - School of Dentistry, European University Cyprus, Nicosia, Cyprus.
AD  - School of Dentistry, Aristotle University of Thessaloniki, Thessaloniki, Greece.
AD  - Mohammed Bin Rashid University of Medicine and Health Sciences, Dubai, United 
      Arab Emirates.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20231228
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Dentists
MH  - Evidence-Based Dentistry
MH  - Professional Role
MH  - Search Engine
MH  - Language
PMC - PMC10784979
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - Google Bard
OT  - Microsoft Bing
OT  - artificial intelligence
OT  - clinical decision-making
OT  - clinical practice
OT  - clinical practice guidelines
OT  - dental practice
OT  - dental professional
OT  - evidence-based dentistry
OT  - generative pretrained transformers
OT  - large language models
COIS- Conflicts of Interest: None declared.
EDAT- 2023/11/27 06:47
MHDA- 2023/12/29 06:43
PMCR- 2023/12/28
CRDT- 2023/11/27 03:40
PHST- 2023/08/04 00:00 [received]
PHST- 2023/11/20 00:00 [accepted]
PHST- 2023/10/15 00:00 [revised]
PHST- 2023/12/29 06:43 [medline]
PHST- 2023/11/27 06:47 [pubmed]
PHST- 2023/11/27 03:40 [entrez]
PHST- 2023/12/28 00:00 [pmc-release]
AID - v25i1e51580 [pii]
AID - 10.2196/51580 [doi]
PST - epublish
SO  - J Med Internet Res. 2023 Dec 28;25:e51580. doi: 10.2196/51580.

PMID- 38405784
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240301
DP  - 2024 Feb 13
TI  - Evaluating Large Language Models in Extracting Cognitive Exam Dates and Scores.
LID - 2023.07.10.23292373 [pii]
LID - 10.1101/2023.07.10.23292373 [doi]
AB  - IMPORTANCE: Large language models (LLMs) are crucial for medical tasks. Ensuring 
      their reliability is vital to avoid false results. Our study assesses two 
      state-of-the-art LLMs (ChatGPT and LlaMA-2) for extracting clinical information, 
      focusing on cognitive tests like MMSE and CDR. OBJECTIVE: Evaluate ChatGPT and 
      LlaMA-2 performance in extracting MMSE and CDR scores, including their associated 
      dates. METHODS: Our data consisted of 135,307 clinical notes (Jan 12th, 2010 to 
      May 24th, 2023) mentioning MMSE, CDR, or MoCA. After applying inclusion criteria 
      34,465 notes remained, of which 765 underwent ChatGPT (GPT-4) and LlaMA-2, and 22 
      experts reviewed the responses. ChatGPT successfully extracted MMSE and CDR 
      instances with dates from 742 notes. We used 20 notes for fine-tuning and 
      training the reviewers. The remaining 722 were assigned to reviewers, with 309 
      each assigned to two reviewers simultaneously. Inter-rater-agreement (Fleiss' 
      Kappa), precision, recall, true/false negative rates, and accuracy were 
      calculated. Our study follows TRIPOD reporting guidelines for model validation. 
      RESULTS: For MMSE information extraction, ChatGPT (vs. LlaMA-2) achieved accuracy 
      of 83% (vs. 66.4%), sensitivity of 89.7% (vs. 69.9%), true-negative rates of 96% 
      (vs 60.0%), and precision of 82.7% (vs 62.2%). For CDR the results were lower 
      overall, with accuracy of 87.1% (vs. 74.5%), sensitivity of 84.3% (vs. 39.7%), 
      true-negative rates of 99.8% (98.4%), and precision of 48.3% (vs. 16.1%). We 
      qualitatively evaluated the MMSE errors of ChatGPT and LlaMA-2 on double-reviewed 
      notes. LlaMA-2 errors included 27 cases of total hallucination, 19 cases of 
      reporting other scores instead of MMSE, 25 missed scores, and 23 cases of 
      reporting only the wrong date. In comparison, ChatGPT's errors included only 3 
      cases of total hallucination, 17 cases of wrong test reported instead of MMSE, 
      and 19 cases of reporting a wrong date. CONCLUSIONS: In this 
      diagnostic/prognostic study of ChatGPT and LlaMA-2 for extracting cognitive exam 
      dates and scores from clinical notes, ChatGPT exhibited high accuracy, with 
      better performance compared to LlaMA-2. The use of LLMs could benefit dementia 
      research and clinical care, by identifying eligible patients for treatments 
      initialization or clinical trial enrollments. Rigorous evaluation of LLMs is 
      crucial to understanding their capabilities and limitations.
FAU - Zhang, Hao
AU  - Zhang H
AD  - NYU Grossman School of Medicine.
FAU - Jethani, Neil
AU  - Jethani N
AUID- ORCID: 0000-0002-1364-7984
AD  - NYU Grossman School of Medicine.
FAU - Jones, Simon
AU  - Jones S
AD  - NYU Grossman School of Medicine.
FAU - Genes, Nicholas
AU  - Genes N
AUID- ORCID: 0000-0002-9836-2477
AD  - NYU Grossman School of Medicine.
FAU - Major, Vincent J
AU  - Major VJ
AUID- ORCID: 0000-0003-2604-3458
AD  - NYU Grossman School of Medicine.
FAU - Jaffe, Ian S
AU  - Jaffe IS
AUID- ORCID: 0000-0002-7309-308X
AD  - NYU Grossman School of Medicine.
FAU - Cardillo, Anthony B
AU  - Cardillo AB
AUID- ORCID: 0000-0003-1594-2562
AD  - NYU Grossman School of Medicine.
FAU - Heilenbach, Noah
AU  - Heilenbach N
AUID- ORCID: 0000-0002-6796-6163
AD  - NYU Grossman School of Medicine.
FAU - Ali, Nadia Fazal
AU  - Ali NF
AUID- ORCID: 0000-0001-6180-0173
AD  - NYU Grossman School of Medicine.
FAU - Bonanni, Luke J
AU  - Bonanni LJ
AUID- ORCID: 0000-0002-1730-0486
AD  - NYU Grossman School of Medicine.
FAU - Clayburn, Andrew J
AU  - Clayburn AJ
AUID- ORCID: 0000-0001-8729-1805
AD  - NYU Grossman School of Medicine.
FAU - Khera, Zain
AU  - Khera Z
AUID- ORCID: 0000-0001-8833-6382
AD  - NYU Grossman School of Medicine.
FAU - Sadler, Erica C
AU  - Sadler EC
AUID- ORCID: 0000-0001-7006-1659
AD  - NYU Grossman School of Medicine.
FAU - Prasad, Jaideep
AU  - Prasad J
AUID- ORCID: 0000-0001-8532-8336
AD  - NYU Grossman School of Medicine.
FAU - Schlacter, Jamie
AU  - Schlacter J
AUID- ORCID: 0000-0001-5825-8109
AD  - NYU Grossman School of Medicine.
FAU - Liu, Kevin
AU  - Liu K
AUID- ORCID: 0000-0002-4664-9695
AD  - NYU Grossman School of Medicine.
FAU - Silva, Benjamin
AU  - Silva B
AUID- ORCID: 0000-0001-6112-3387
AD  - NYU Grossman School of Medicine.
FAU - Montgomery, Sophie
AU  - Montgomery S
AUID- ORCID: 0000-0003-2606-2042
AD  - NYU Grossman School of Medicine.
FAU - Kim, Eric J
AU  - Kim EJ
AUID- ORCID: 0000-0001-8032-2090
AD  - NYU Grossman School of Medicine.
FAU - Lester, Jacob
AU  - Lester J
AUID- ORCID: 0000-0001-9079-2790
AD  - NYU Grossman School of Medicine.
FAU - Hill, Theodore M
AU  - Hill TM
AUID- ORCID: 0000-0002-0604-6451
AD  - NYU Grossman School of Medicine.
FAU - Avoricani, Alba
AU  - Avoricani A
AUID- ORCID: 0000-0002-7569-5025
AD  - NYU Grossman School of Medicine.
FAU - Chervonski, Ethan
AU  - Chervonski E
AUID- ORCID: 0000-0002-4404-0499
AD  - NYU Grossman School of Medicine.
FAU - Davydov, James
AU  - Davydov J
AD  - NYU Grossman School of Medicine.
FAU - Small, William
AU  - Small W
AD  - NYU Grossman School of Medicine.
FAU - Chakravartty, Eesha
AU  - Chakravartty E
AUID- ORCID: 0000-0001-6306-8246
AD  - NYU Grossman School of Medicine.
FAU - Grover, Himanshu
AU  - Grover H
AD  - NYU Grossman School of Medicine.
FAU - Dodson, John A
AU  - Dodson JA
AD  - NYU Grossman School of Medicine.
FAU - Brody, Abraham A
AU  - Brody AA
AUID- ORCID: 0000-0002-3405-7043
AD  - NYU Rory Meyers College of Nursing, NYU Grossman School of Medicine.
FAU - Aphinyanaphongs, Yindalon
AU  - Aphinyanaphongs Y
AUID- ORCID: 0000-0001-8605-5392
AD  - NYU Grossman School of Medicine.
FAU - Masurkar, Arjun
AU  - Masurkar A
AUID- ORCID: 0000-0002-2498-2059
AD  - NYU Grossman School of Medicine.
FAU - Razavian, Narges
AU  - Razavian N
AUID- ORCID: 0000-0002-9922-6370
AD  - NYU Grossman School of Medicine.
LA  - eng
GR  - P30 AG066512/AG/NIA NIH HHS/United States
GR  - R01 AG079175/AG/NIA NIH HHS/United States
GR  - R01 AG085617/AG/NIA NIH HHS/United States
PT  - Preprint
DEP - 20240213
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
PMC - PMC10888985
EDAT- 2024/02/26 06:42
MHDA- 2024/02/26 06:43
PMCR- 2024/02/23
CRDT- 2024/02/26 04:49
PHST- 2024/02/26 06:42 [pubmed]
PHST- 2024/02/26 06:43 [medline]
PHST- 2024/02/26 04:49 [entrez]
PHST- 2024/02/23 00:00 [pmc-release]
AID - 2023.07.10.23292373 [pii]
AID - 10.1101/2023.07.10.23292373 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2024 Feb 13:2023.07.10.23292373. doi: 
      10.1101/2023.07.10.23292373.

PMID- 37621662
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230826
IS  - 2054-5703 (Print)
IS  - 2054-5703 (Electronic)
IS  - 2054-5703 (Linking)
VI  - 10
IP  - 8
DP  - 2023 Aug
TI  - Why and how to embrace AI such as ChatGPT in your academic life.
PG  - 230658
LID - 10.1098/rsos.230658 [doi]
LID - 230658
AB  - Generative artificial intelligence (AI), including large language models (LLMs), 
      is poised to transform scientific research, enabling researchers to elevate their 
      research productivity. This article presents a how-to guide for employing LLMs in 
      academic settings, focusing on their unique strengths, constraints and 
      implications through the lens of philosophy of science and epistemology. Using 
      ChatGPT as a case study, I identify and elaborate on three attributes 
      contributing to its effectiveness-intelligence, versatility and 
      collaboration-accompanied by tips on crafting effective prompts, practical use 
      cases and a living resource online (https://osf.io/8vpwu/). Next, I evaluate the 
      limitations of generative AI and its implications for ethical use, equality and 
      education. Regarding ethical and responsible use, I argue from technical and 
      epistemic standpoints that there is no need to restrict the scope or nature of AI 
      assistance, provided that its use is transparently disclosed. A pressing 
      challenge, however, lies in detecting fake research, which can be mitigated by 
      embracing open science practices, such as transparent peer review and sharing 
      data, code and materials. Addressing equality, I contend that while generative AI 
      may promote equality for some, it may simultaneously exacerbate disparities for 
      others-an issue with potentially significant yet unclear ramifications as it 
      unfolds. Lastly, I consider the implications for education, advocating for active 
      engagement with LLMs and cultivating students' critical thinking and analytical 
      skills. The how-to guide seeks to empower researchers with the knowledge and 
      resources necessary to effectively harness generative AI while navigating the 
      complex ethical dilemmas intrinsic to its application.
CI  - © 2023 The Authors.
FAU - Lin, Zhicheng
AU  - Lin Z
AUID- ORCID: 0000-0002-6864-6559
AD  - Programme of Applied Psychology, School of Humanities and Social Science, The 
      Chinese University of Hong Kong, Shenzhen, Guangdong 518172, People's Republic of 
      China.
LA  - eng
PT  - Journal Article
DEP - 20230823
PL  - England
TA  - R Soc Open Sci
JT  - Royal Society open science
JID - 101647528
PMC - PMC10445029
OTO - NOTNLM
OT  - ChatGPT/bard
OT  - artificial intelligence
OT  - ethics
OT  - large language models
OT  - open science
OT  - productivity
EDAT- 2023/08/25 06:42
MHDA- 2023/08/25 06:43
PMCR- 2023/08/23
CRDT- 2023/08/25 03:49
PHST- 2023/05/26 00:00 [received]
PHST- 2023/08/03 00:00 [accepted]
PHST- 2023/08/25 06:43 [medline]
PHST- 2023/08/25 06:42 [pubmed]
PHST- 2023/08/25 03:49 [entrez]
PHST- 2023/08/23 00:00 [pmc-release]
AID - rsos230658 [pii]
AID - 10.1098/rsos.230658 [doi]
PST - epublish
SO  - R Soc Open Sci. 2023 Aug 23;10(8):230658. doi: 10.1098/rsos.230658. eCollection 
      2023 Aug.

PMID- 37727841
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230921
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 9
DP  - 2023 Sep
TI  - Efficacy of AI Chats to Determine an Emergency: A Comparison Between OpenAI's 
      ChatGPT, Google Bard, and Microsoft Bing AI Chat.
PG  - e45473
LID - 10.7759/cureus.45473 [doi]
LID - e45473
AB  - Background The escalating overload and saturation of emergency services, 
      primarily caused by non-urgent cases overwhelming the system, have spurred a 
      critical necessity for innovative solutions that can effectively differentiate 
      genuine emergencies from situations that could be managed through alternative 
      means, such as using AI chatbots.&nbsp;This study aims to evaluate and compare the 
      accuracy in differentiating between a medical emergency and a non-emergency of 
      three of the most popular AI chatbots at the moment. Methods In this study, 
      patient questions from the online forum r/AskDocs on Reddit were collected to 
      determine whether their clinical cases were emergencies. A total of 176 questions 
      were reviewed by the authors, with 75 deemed emergencies and 101 non-emergencies. 
      These questions were then posed to AI chatbots, including ChatGPT, Google Bard, 
      and Microsoft Bing AI, with their responses evaluated against each other and the 
      authors' responses. A criteria-based system categorized the AI chatbot answers as 
      "yes," "no," or "cannot determine." The performance of each AI chatbot was 
      compared in both emergency and non-emergency cases, and statistical analysis was 
      conducted to assess the significance of differences in their performance. Results 
      In general, AI chatbots considered around 12-15% more cases to be an emergency 
      than reviewers, while they considered a very low number of cases as non-emergency 
      compared to reviewers (around 35% fewer cases). Google Bard detected the most 
      true emergency cases (87%) and true non-emergency cases (36%). However, no real 
      difference in performance between the three AI chatbots was found in detecting 
      true emergencies (p-value = 0.35) and non-emergency cases (p-value = 0.16).&nbsp; 
      Conclusions These AI systems require further refinement to identify emergency 
      situations accurately, but they could potentially be an innovative tool for 
      emergency care and improving patient outcomes. The integration of AI chatbots 
      like ChatGPT, Google Bard, and Microsoft Bing Chat offers a promising avenue to 
      mitigate ED strain and enhance emergency management.
CI  - Copyright © 2023, Zúñiga Salazar et al.
FAU - Zúñiga Salazar, Gabriel
AU  - Zúñiga Salazar G
AD  - Facultad de Ciencias Médicas, Universidad Católica de Santiago de Guayaquil, 
      Guayaquil, ECU.
FAU - Zúñiga, Diego
AU  - Zúñiga D
AD  - Facultad de Ciencias Médicas, Universidad Católica de Santiago de Guayaquil, 
      Guayaquil, ECU.
FAU - Vindel, Carlos L
AU  - Vindel CL
AD  - Facultad de Ciencias Médicas, Universidad Católica de Santiago de Guayaquil, 
      Guayaquil, ECU.
FAU - Yoong, Ana M
AU  - Yoong AM
AD  - Facultad de Ciencias Médicas, Universidad Católica de Santiago de Guayaquil, 
      Guayaquil, ECU.
FAU - Hincapie, Sofia
AU  - Hincapie S
AD  - Facultad de Ciencias Médicas, Universidad Católica de Santiago de Guayaquil, 
      Guayaquil, ECU.
FAU - Zúñiga, Ana B
AU  - Zúñiga AB
AD  - Facultad de Ciencias Médicas, Universidad Católica de Santiago de Guayaquil, 
      Guayaquil, ECU.
FAU - Zúñiga, Paula
AU  - Zúñiga P
AD  - Facultad de Ciencias Médicas, Universidad Católica de Santiago de Guayaquil, 
      Guayaquil, ECU.
FAU - Salazar, Erin
AU  - Salazar E
AD  - Neurology, Hospital Luis Vernaza, Guayaquil, ECU.
FAU - Zúñiga, Byron
AU  - Zúñiga B
AD  - Nephrology, Hospital Luis Vernaza, Guayaquil, ECU.
LA  - eng
PT  - Journal Article
DEP - 20230918
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10506659
OTO - NOTNLM
OT  - ai &amp; robotics in healthcare
OT  - artificial intelligence
OT  - chatbot
OT  - chatgpt
OT  - emergency
OT  - emergency department
OT  - emergency room
OT  - google bard
OT  - microsoft bing
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/09/20 06:42
MHDA- 2023/09/20 06:43
PMCR- 2023/09/18
CRDT- 2023/09/20 04:00
PHST- 2023/09/18 00:00 [accepted]
PHST- 2023/09/20 06:43 [medline]
PHST- 2023/09/20 06:42 [pubmed]
PHST- 2023/09/20 04:00 [entrez]
PHST- 2023/09/18 00:00 [pmc-release]
AID - 10.7759/cureus.45473 [doi]
PST - epublish
SO  - Cureus. 2023 Sep 18;15(9):e45473. doi: 10.7759/cureus.45473. eCollection 2023 
      Sep.

PMID- 37578830
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231106
IS  - 2369-3762 (Print)
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Aug 14
TI  - The Role of Large Language Models in Medical Education: Applications and 
      Implications.
PG  - e50945
LID - 10.2196/50945 [doi]
LID - e50945
AB  - Large language models (LLMs) such as ChatGPT have sparked extensive discourse 
      within the medical education community, spurring both excitement and 
      apprehension. Written from the perspective of medical students, this editorial 
      offers insights gleaned through immersive interactions with ChatGPT, 
      contextualized by ongoing research into the imminent role of LLMs in health care. 
      Three distinct positive use cases for ChatGPT were identified: facilitating 
      differential diagnosis brainstorming, providing interactive practice cases, and 
      aiding in multiple-choice question review. These use cases can effectively help 
      students learn foundational medical knowledge during the preclinical curriculum 
      while reinforcing the learning of core Entrustable Professional Activities. 
      Simultaneously, we highlight key limitations of LLMs in medical education, 
      including their insufficient ability to teach the integration of contextual and 
      external information, comprehend sensory and nonverbal cues, cultivate rapport 
      and interpersonal interaction, and align with overarching medical education and 
      patient care goals. Through interacting with LLMs to augment learning during 
      medical school, students can gain an understanding of their strengths and 
      weaknesses. This understanding will be pivotal as we navigate a health care 
      landscape increasingly intertwined with LLMs and artificial intelligence.
CI  - ©Conrad W Safranek, Anne Elizabeth Sidamon-Eristoff, Aidan Gilson, David 
      Chartash. Originally published in JMIR Medical Education 
      (https://mededu.jmir.org), 14.08.2023.
FAU - Safranek, Conrad W
AU  - Safranek CW
AUID- ORCID: 0000-0003-1985-9432
AD  - Section for Biomedical Informatics and Data Science, Yale University School of 
      Medicine, New Haven, CT, United States.
FAU - Sidamon-Eristoff, Anne Elizabeth
AU  - Sidamon-Eristoff AE
AUID- ORCID: 0000-0001-7422-9703
AD  - Yale University School of Medicine, New Haven, CT, United States.
FAU - Gilson, Aidan
AU  - Gilson A
AUID- ORCID: 0000-0002-4770-4705
AD  - Section for Biomedical Informatics and Data Science, Yale University School of 
      Medicine, New Haven, CT, United States.
FAU - Chartash, David
AU  - Chartash D
AUID- ORCID: 0000-0002-0265-330X
AD  - Section for Biomedical Informatics and Data Science, Yale University School of 
      Medicine, New Haven, CT, United States.
AD  - School of Medicine, University College Dublin, National University of Ireland, 
      Dublin, Ireland.
LA  - eng
GR  - T32 GM136651/GM/NIGMS NIH HHS/United States
GR  - T35 DK104689/DK/NIDDK NIH HHS/United States
GR  - T35 HL007649/HL/NHLBI NIH HHS/United States
PT  - Editorial
DEP - 20230814
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
PMC - PMC10463084
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - LLM
OT  - artificial intelligence in health care
OT  - autoethnography
OT  - large language models
OT  - medical education
COIS- Conflicts of Interest: None declared.
EDAT- 2023/08/14 12:43
MHDA- 2023/08/14 12:44
PMCR- 2023/08/14
CRDT- 2023/08/14 11:53
PHST- 2023/07/17 00:00 [received]
PHST- 2023/07/26 00:00 [accepted]
PHST- 2023/07/26 00:00 [revised]
PHST- 2023/08/14 12:44 [medline]
PHST- 2023/08/14 12:43 [pubmed]
PHST- 2023/08/14 11:53 [entrez]
PHST- 2023/08/14 00:00 [pmc-release]
AID - v9i1e50945 [pii]
AID - 10.2196/50945 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Aug 14;9:e50945. doi: 10.2196/50945.

PMID- 37562028
OWN - NLM
STAT- Publisher
LR  - 20230810
IS  - 1744-5078 (Electronic)
IS  - 0927-3948 (Linking)
DP  - 2023 Aug 10
TI  - The Potential Role of Large Language Models in Uveitis Care: Perspectives After 
      ChatGPT and Bard Launch.
PG  - 1-5
LID - 10.1080/09273948.2023.2242462 [doi]
FAU - Tan Yip Ming, Collin
AU  - Tan Yip Ming C
AD  - Yong Loo Lin School of Medicine, National University of Singapore, Singapore, 
      Singapore.
FAU - Rojas-Carabali, William
AU  - Rojas-Carabali W
AD  - Lee Kong Chian School of Medicine, Nanyang Technological University, Singapore, 
      Singapore.
FAU - Cifuentes-González, Carlos
AU  - Cifuentes-González C
AUID- ORCID: 0000-0002-2703-0977
AD  - Neuroscience Research Group (NEUROS), Neurovitae Center for Neuroscience, 
      Institute of Translational Medicine (IMT), Escuela de Medicina y Ciencias de la 
      Salud, Universidad del Rosario, Bogotá, Colombia.
FAU - Agrawal, Rajdeep
AU  - Agrawal R
AD  - Lee Kong Chian School of Medicine, Nanyang Technological University, Singapore, 
      Singapore.
FAU - Thorne, Jennifer E
AU  - Thorne JE
AD  - Department of Ophthalmology, Wilmer Eye Institute, The Johns Hopkins Hospital, 
      Baltimor, Maryland, USA.
FAU - Tugal-Tutkun, Ilknur
AU  - Tugal-Tutkun I
AD  - Department of Ophthalmology, Istanbul Faculty of Medicine, Istanbul University, 
      Istanbul, Turkey.
AD  - Eye Protection Foundation Bayrampasa Eye Hospital, Istanbul, Turkey.
FAU - Nguyen, Quan Dong
AU  - Nguyen QD
AD  - Byers Eye Institute, Stanford University, Palo Alto, California, USA.
FAU - Gupta, Vishali
AU  - Gupta V
AD  - Advanced Eye Centre, Post-Graduate Institute of Medical Education and Research 
      (PGIMER), Chandigarh, India.
FAU - de-la-Torre, Alejandra
AU  - de-la-Torre A
AD  - Neuroscience Research Group (NEUROS), Neurovitae Center for Neuroscience, 
      Institute of Translational Medicine (IMT), Escuela de Medicina y Ciencias de la 
      Salud, Universidad del Rosario, Bogotá, Colombia.
FAU - Agrawal, Rupesh
AU  - Agrawal R
AD  - Lee Kong Chian School of Medicine, Nanyang Technological University, Singapore, 
      Singapore.
AD  - Department of Ophthalmology, Tan Tock Seng Hospital, Singapore.
AD  - Moorfields Eye Hospital, NHS Foundation Trust, London, UK.
AD  - Singapore Eye Research Institute, The Academia, Singapore, Singapore.
AD  - Duke NUS Medical School, Singapore, Singapore.
LA  - eng
PT  - Editorial
DEP - 20230810
PL  - England
TA  - Ocul Immunol Inflamm
JT  - Ocular immunology and inflammation
JID - 9312169
SB  - IM
OTO - NOTNLM
OT  - Bard
OT  - ChatGPT
OT  - LLMs
OT  - diagnosis
OT  - ophthalmology
OT  - treatment
OT  - uveitis
EDAT- 2023/08/10 18:42
MHDA- 2023/08/10 18:42
CRDT- 2023/08/10 17:13
PHST- 2023/08/10 18:42 [medline]
PHST- 2023/08/10 18:42 [pubmed]
PHST- 2023/08/10 17:13 [entrez]
AID - 10.1080/09273948.2023.2242462 [doi]
PST - aheadofprint
SO  - Ocul Immunol Inflamm. 2023 Aug 10:1-5. doi: 10.1080/09273948.2023.2242462.

PMID- 36920012
OWN - NLM
STAT- MEDLINE
DCOM- 20230316
LR  - 20230316
IS  - 1660-9379 (Print)
IS  - 1660-9379 (Linking)
VI  - 19
IP  - 818
DP  - 2023 Mar 15
TI  - [Artificial intelligence and psychiatry: questions from psychiatrists to 
      ChatGPT].
PG  - 532-536
LID - 10.53738/REVMED.2023.19.818.532 [doi]
AB  - Psychiatrists and psychotherapists specialising in the fields of addiction, 
      personality disorders, ADHD and suicidal crisis, we questioned the ChatGPT 
      artificial intelligence program in order to form an opinion on the quality of its 
      answers to questions on these subjects. Our aim is to satisfy our curiosity about 
      these emerging tools. On the other hand, we want to assess the relevance of the 
      answers in order to know whether relatives and patients can use them safely. In 
      this article, we comment on the question-and-answer dialogue with the artificial 
      intelligence program in the light of the literature.
FAU - Prada, Paco
AU  - Prada P
AD  - Unité de psychiatrie hospitalière, Service de psychiatrie de liaison et 
      d'intervention de crise, Département de psychiatrie, Hôpitaux universitaires de 
      Genève, 1211 Genève 14.
FAU - Perroud, Nader
AU  - Perroud N
AD  - Unité des troubles de la régulation émotionnelle, Service des spécialités 
      psychiatriques, Département de psychiatrie, Hôpitaux universitaires de Genève, 
      20bis rue de Lausanne, 1201 Genève.
FAU - Thorens, Gabriel
AU  - Thorens G
AD  - Service d'addictologie, Département de psychiatrie, Hôpitaux universitaires de 
      Genève, Rue de Grand-Pré 70, 1202 Genève.
LA  - fre
PT  - English Abstract
PT  - Journal Article
TT  - Intelligence artificielle et psychiatrie : questions de psychiatres à ChatGPT.
PL  - Switzerland
TA  - Rev Med Suisse
JT  - Revue medicale suisse
JID - 101219148
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Psychiatry
MH  - Personality Disorders
MH  - Attitude of Health Personnel
MH  - Psychotherapy
COIS- Les auteurs n’ont déclaré aucun conflit d’intérêts en lien avec cet article.
EDAT- 2023/03/16 06:00
MHDA- 2023/03/17 06:00
CRDT- 2023/03/15 08:43
PHST- 2023/03/15 08:43 [entrez]
PHST- 2023/03/16 06:00 [pubmed]
PHST- 2023/03/17 06:00 [medline]
AID - RMS0818-008 [pii]
AID - 10.53738/REVMED.2023.19.818.532 [doi]
PST - ppublish
SO  - Rev Med Suisse. 2023 Mar 15;19(818):532-536. doi: 
      10.53738/REVMED.2023.19.818.532.

PMID- 38155290
OWN - NLM
STAT- Publisher
LR  - 20231228
IS  - 1432-5241 (Electronic)
IS  - 0364-216X (Linking)
DP  - 2023 Dec 28
TI  - Dr. GAI: Significance of Generative AI in Plastic Surgery.
LID - 10.1007/s00266-023-03805-1 [doi]
AB  - In this letter to the editor, I offer a critique of the article titled 
      "Consulting the Digital Doctor: Google Versus ChatGPT as Sources of Information 
      on Breast Implant-Associated Anaplastic Large Cell Lymphoma and Breast Implant 
      Illness." While acknowledging the authors' pioneering effort to compare 
      informational outputs from Google and a generative AI (GAI)-ChatGPT, I raise 
      concerns about the methodology, lack of rigorous validation, potential biases, 
      and the overstatement of findings. The letter suggests that the authors' 
      conclusions about the superiority of ChatGPT in providing high-quality medical 
      information may be premature, given the limitations of the study design and the 
      evolving nature of artificial intelligence (AI) technology.No Level Assigned This 
      journal requires that authors assign a level of evidence to each submission to 
      which Evidence-Based Medicine rankings are applicable. This excludes Review 
      Articles, Book Reviews, and manuscripts that concern Basic Science, Animal 
      Studies, Cadaver Studies, and Experimental Studies. For a full description of 
      these Evidence-Based Medicine ratings, please refer to the Table of Contents or 
      the online Instructions to Authors www.springer.com/00266.
CI  - © 2023. Springer Science+Business Media, LLC, part of Springer Nature and 
      International Society of Aesthetic Plastic Surgery.
FAU - Ray, Partha Pratim
AU  - Ray PP
AUID- ORCID: 0000-0003-2306-2792
AD  - Department of Computer Applications, Sikkim University, 6th Mile, PO-Tadong, 
      Gangtok, Sikkim, 737102, India. ppray@cus.ac.in.
LA  - eng
PT  - Letter
DEP - 20231228
PL  - United States
TA  - Aesthetic Plast Surg
JT  - Aesthetic plastic surgery
JID - 7701756
SB  - IM
EDAT- 2023/12/29 00:42
MHDA- 2023/12/29 00:42
CRDT- 2023/12/28 23:28
PHST- 2023/11/03 00:00 [received]
PHST- 2023/11/29 00:00 [accepted]
PHST- 2023/12/29 00:42 [medline]
PHST- 2023/12/29 00:42 [pubmed]
PHST- 2023/12/28 23:28 [entrez]
AID - 10.1007/s00266-023-03805-1 [pii]
AID - 10.1007/s00266-023-03805-1 [doi]
PST - aheadofprint
SO  - Aesthetic Plast Surg. 2023 Dec 28. doi: 10.1007/s00266-023-03805-1.

PMID- 36912286
OWN - NLM
STAT- MEDLINE
DCOM- 20230522
LR  - 20230922
IS  - 1537-7385 (Electronic)
IS  - 0894-9115 (Linking)
VI  - 102
IP  - 6
DP  - 2023 Jun 1
TI  - Will ChatGPT Match to Your Program?
PG  - 545-547
LID - 10.1097/PHM.0000000000002238 [doi]
AB  - ChatGPT and other artificial intelligence word prediction large database models 
      are now readily available to the public. Program directors should be aware of the 
      general features of this technology and consider its effect in graduate medical 
      education, including the preparation of materials such as personal statements. 
      The authors provide a sample ChatGPT-generated personal statement and general 
      considerations for program directors and other graduate medical education 
      stakeholders. The authors advocate that programs and applicants will be best 
      served by transparent expectations about how/if programs will accept application 
      materials created using artificial intelligence, starting with this application 
      cycle. Graduate medical education will have many additional factors to consider 
      for the innovative use and safeguards for the ethical application of artificial 
      intelligence in clinical care and educational processes. However, the exponential 
      increase in the application of this technology requires an urgent review for 
      appropriate management of program procedures, iteration of policies, and a 
      meaningful national discussion.
CI  - Copyright © 2023 Wolters Kluwer Health, Inc. All rights reserved.
FAU - Zumsteg, Jennifer M
AU  - Zumsteg JM
AD  - From the UW Medicine Valley Medical Center, Renton, Washington (JMZ); Division of 
      Rehabilitation Psychology and Neuropsychology, Department of Rehabilitation 
      Medicine, University of Washington School of Medicine, Seattle, Washington (JMZ); 
      and Department of Rehabilitation Medicine, University of Washington School of 
      Medicine, Seattle, Washington (CJ).
FAU - Junn, Cherry
AU  - Junn C
LA  - eng
PT  - Journal Article
DEP - 20230313
PL  - United States
TA  - Am J Phys Med Rehabil
JT  - American journal of physical medicine &amp; rehabilitation
JID - 8803677
SB  - IM
MH  - Humans
MH  - *Internship and Residency
MH  - Artificial Intelligence
MH  - Education, Medical, Graduate
COIS- Financial disclosure statements have been obtained, and no conflicts of interest 
      have been reported by the authors or by any individuals in control of the content 
      of this article.
EDAT- 2023/03/14 06:00
MHDA- 2023/05/22 06:42
CRDT- 2023/03/13 07:03
PHST- 2023/05/22 06:42 [medline]
PHST- 2023/03/14 06:00 [pubmed]
PHST- 2023/03/13 07:03 [entrez]
AID - 00002060-202306000-00010 [pii]
AID - 10.1097/PHM.0000000000002238 [doi]
PST - ppublish
SO  - Am J Phys Med Rehabil. 2023 Jun 1;102(6):545-547. doi: 
      10.1097/PHM.0000000000002238. Epub 2023 Mar 13.

PMID- 36856927
OWN - NLM
STAT- MEDLINE
DCOM- 20230512
LR  - 20230512
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 51
IP  - 6
DP  - 2023 Jun
TI  - Potential Use of Chat GPT in Global Warming.
PG  - 1126-1127
LID - 10.1007/s10439-023-03171-8 [doi]
AB  - Climate change is a major global challenge that requires the integration of many 
      different scientific disciplines, including atmospheric science, oceanography, 
      and ecology. The complexity and scale of the problem require sophisticated tools 
      and techniques to understand, model, and project future climate conditions. 
      Artificial intelligence and natural language processing technologies, such as 
      ChatGPT, have the potential to play a critical role in advancing our 
      understanding of climate change and improving the accuracy of climate 
      projections. ChatGPT can be used in a variety of ways to aid climate research, 
      including in model parameterization, data analysis and interpretation, scenario 
      generation, and model evaluation. This technology provides researchers and 
      policy-makers with a powerful tool for generating and analyzing different climate 
      scenarios based on a wide range of data inputs, and for improving the accuracy of 
      climate projections. The author acknowledges asking chatGPT questions regarding 
      its uses for Climate Change Research. Some of the uses that it states are 
      possible now and some are potentials for the future. The author has analyzed and 
      edited the replies of chat GPT.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Biswas, Som S
AU  - Biswas SS
AUID- ORCID: 0000-0002-4038-5844
AD  - Le Bonheur Children's Hospital, The University of Tennessee Health Science 
      Center, Memphis, USA. ssbinmemphis@gmail.com.
LA  - eng
PT  - Letter
DEP - 20230301
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - *Global Warming
MH  - *Artificial Intelligence
MH  - Climate Change
MH  - Forecasting
OTO - NOTNLM
OT  - AI
OT  - Chat GPT
OT  - Climate change research
EDAT- 2023/03/02 06:00
MHDA- 2023/05/12 07:06
CRDT- 2023/03/01 11:18
PHST- 2023/02/15 00:00 [received]
PHST- 2023/02/19 00:00 [accepted]
PHST- 2023/05/12 07:06 [medline]
PHST- 2023/03/02 06:00 [pubmed]
PHST- 2023/03/01 11:18 [entrez]
AID - 10.1007/s10439-023-03171-8 [pii]
AID - 10.1007/s10439-023-03171-8 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2023 Jun;51(6):1126-1127. doi: 10.1007/s10439-023-03171-8. Epub 
      2023 Mar 1.

PMID- 37956228
OWN - NLM
STAT- MEDLINE
DCOM- 20231128
LR  - 20240327
IS  - 1549-960X (Electronic)
IS  - 1549-9596 (Linking)
VI  - 63
IP  - 22
DP  - 2023 Nov 27
TI  - ChatGPT in Drug Discovery: A Case Study on Anticocaine Addiction Drug Development 
      with Chatbots.
PG  - 7189-7209
LID - 10.1021/acs.jcim.3c01429 [doi]
AB  - The birth of ChatGPT, a cutting-edge language model-based chatbot developed by 
      OpenAI, ushered in a new era in AI. However, due to potential pitfalls, its role 
      in rigorous scientific research is not clear yet. This paper vividly showcases 
      its innovative application within the field of drug discovery. Focused 
      specifically on developing anticocaine addiction drugs, the study employs GPT-4 
      as a virtual guide, offering strategic and methodological insights to researchers 
      working on generative models for drug candidates. The primary objective is to 
      generate optimal drug-like molecules with desired properties. By leveraging the 
      capabilities of ChatGPT, the study introduces a novel approach to the drug 
      discovery process. This symbiotic partnership between AI and researchers 
      transforms how drug development is approached. Chatbots become facilitators, 
      steering researchers toward innovative methodologies and productive paths for 
      creating effective drug candidates. This research sheds light on the 
      collaborative synergy between human expertise and AI assistance, wherein 
      ChatGPT's cognitive abilities enhance the design and development of 
      pharmaceutical solutions. This paper not only explores the integration of 
      advanced AI in drug discovery but also reimagines the landscape by advocating for 
      AI-powered chatbots as trailblazers in revolutionizing therapeutic innovation.
FAU - Wang, Rui
AU  - Wang R
AUID- ORCID: 0000-0002-7402-6372
AD  - Department of Mathematics, Michigan State University, East Lansing, Michigan 
      48824, United States.
FAU - Feng, Hongsong
AU  - Feng H
AUID- ORCID: 0000-0001-8039-3059
AD  - Department of Mathematics, Michigan State University, East Lansing, Michigan 
      48824, United States.
FAU - Wei, Guo-Wei
AU  - Wei GW
AUID- ORCID: 0000-0002-5781-2937
AD  - Department of Mathematics, Michigan State University, East Lansing, Michigan 
      48824, United States.
AD  - Department of Biochemistry and Molecular Biology, Michigan State University, East 
      Lansing, Michigan 48824, United States.
AD  - Department of Electrical and Computer Engineering, Michigan State University, 
      East Lansing, Michigan 48824, United States.
LA  - eng
GR  - R01 AI164266/AI/NIAID NIH HHS/United States
GR  - R35 GM148196/GM/NIGMS NIH HHS/United States
PT  - Journal Article
DEP - 20231113
PL  - United States
TA  - J Chem Inf Model
JT  - Journal of chemical information and modeling
JID - 101230060
SB  - IM
UOF - ArXiv. 2023 Oct 19;:. PMID: 37645039
MH  - Humans
MH  - *Drug Development
MH  - Drug Discovery
MH  - *Substance-Related Disorders
MH  - Language
MH  - Research Personnel
EDAT- 2023/11/13 18:41
MHDA- 2023/11/28 06:42
CRDT- 2023/11/13 14:06
PHST- 2023/11/28 06:42 [medline]
PHST- 2023/11/13 18:41 [pubmed]
PHST- 2023/11/13 14:06 [entrez]
AID - 10.1021/acs.jcim.3c01429 [doi]
PST - ppublish
SO  - J Chem Inf Model. 2023 Nov 27;63(22):7189-7209. doi: 10.1021/acs.jcim.3c01429. 
      Epub 2023 Nov 13.

PMID- 38057467
OWN - NLM
STAT- Publisher
LR  - 20231206
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
DP  - 2023 Dec 5
TI  - Daily briefing: Happy birthday, ChatGPT!
LID - 10.1038/d41586-023-03878-7 [doi]
FAU - Krämer, Katrina
AU  - Krämer K
LA  - eng
PT  - News
DEP - 20231205
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
EDAT- 2023/12/07 00:42
MHDA- 2023/12/07 00:42
CRDT- 2023/12/06 23:38
PHST- 2023/12/07 00:42 [medline]
PHST- 2023/12/07 00:42 [pubmed]
PHST- 2023/12/06 23:38 [entrez]
AID - 10.1038/d41586-023-03878-7 [pii]
AID - 10.1038/d41586-023-03878-7 [doi]
PST - aheadofprint
SO  - Nature. 2023 Dec 5. doi: 10.1038/d41586-023-03878-7.

PMID- 37399360
OWN - NLM
STAT- MEDLINE
DCOM- 20230705
LR  - 20230705
IS  - 2632-1009 (Electronic)
IS  - 2632-1009 (Linking)
VI  - 30
IP  - 1
DP  - 2023 Jun
TI  - ChatGPT in glioma adjuvant therapy decision making: ready to assume the role of a 
      doctor in the tumour board?
LID - 10.1136/bmjhci-2023-100775 [doi]
LID - e100775
AB  - OBJECTIVE: To evaluate ChatGPT's performance in brain glioma adjuvant therapy 
      decision-making. METHODS: We randomly selected 10 patients with brain gliomas 
      discussed at our institution's central nervous system tumour board (CNS TB). 
      Patients' clinical status, surgical outcome, textual imaging information and 
      immuno-pathology results were provided to ChatGPT V.3.5 and seven CNS tumour 
      experts. The chatbot was asked to give the adjuvant treatment choice, and the 
      regimen while considering the patient's functional status. The experts rated the 
      artificial intelligence-based recommendations from 0 (complete disagreement) to 
      10 (complete agreement). An intraclass correlation coefficient agreement (ICC) 
      was used to measure the inter-rater agreement. RESULTS: Eight patients (80%) met 
      the criteria for glioblastoma and two (20%) were low-grade gliomas. The experts 
      rated the quality of ChatGPT recommendations as poor for diagnosis (median 3, IQR 
      1-7.8, ICC 0.9, 95% CI 0.7 to 1.0), good for treatment recommendation (7, IQR 
      6-8, ICC 0.8, 95% CI 0.4 to 0.9), good for therapy regimen (7, IQR 4-8, ICC 0.8, 
      95% CI 0.5 to 0.9), moderate for functional status consideration (6, IQR 1-7, ICC 
      0.7, 95% CI 0.3 to 0.9) and moderate for overall agreement with the 
      recommendations (5, IQR 3-7, ICC 0.7, 95% CI 0.3 to 0.9). No differences were 
      observed between the glioblastomas and low-grade glioma ratings. CONCLUSIONS: 
      ChatGPT performed poorly in classifying glioma types but was good for adjuvant 
      treatment recommendations as evaluated by CNS TB experts. Even though the ChatGPT 
      lacks the precision to replace expert opinion, it may serve as a promising 
      supplemental tool within a human-in-the-loop approach.
CI  - © Author(s) (or their employer(s)) 2023. Re-use permitted under CC BY-NC. No 
      commercial re-use. See rights and permissions. Published by BMJ.
FAU - Haemmerli, Julien
AU  - Haemmerli J
AUID- ORCID: 0000-0001-5998-8541
AD  - Department of Clinical Neurosciences, Division of Neurosurgery, Geneva University 
      Hospitals, Geneva, Switzerland julien.haemmerli@hcuge.ch.
FAU - Sveikata, Lukas
AU  - Sveikata L
AD  - Department of Clinical Neurosciences, Division of Neurology, Geneva University 
      Hospitals, Geneva, Switzerland.
AD  - Institute of Cardiology, Lithuanian University of Health Sciences, Kaunas, 
      Lithuania.
AD  - Faculty of Medicine, University of Geneva, Geneva, Switzerland.
FAU - Nouri, Aria
AU  - Nouri A
AD  - Department of Clinical Neurosciences, Division of Neurosurgery, Geneva University 
      Hospitals, Geneva, Switzerland.
FAU - May, Adrien
AU  - May A
AD  - Department of Clinical Neurosciences, Division of Neurosurgery, Geneva University 
      Hospitals, Geneva, Switzerland.
FAU - Egervari, Kristof
AU  - Egervari K
AD  - Department of Pathology and Immunology, Geneva University Hospitals, Geneva, 
      Switzerland.
FAU - Freyschlag, Christian
AU  - Freyschlag C
AD  - Department of Neurosurgery, Medical University of Innsbruck, Innsbruck, Austria.
FAU - Lobrinus, Johannes A
AU  - Lobrinus JA
AD  - Department of Pathology and Immunology, Geneva University Hospitals, Geneva, 
      Switzerland.
FAU - Migliorini, Denis
AU  - Migliorini D
AD  - Department of Oncology, Geneva University Hospitals, Geneva, Switzerland.
FAU - Momjian, Shahan
AU  - Momjian S
AD  - Department of Clinical Neurosciences, Division of Neurosurgery, Geneva University 
      Hospitals, Geneva, Switzerland.
FAU - Sanda, Nicolae
AU  - Sanda N
AD  - Department of Clinical Neurosciences, Division of Neurology, Geneva University 
      Hospitals, Geneva, Switzerland.
FAU - Schaller, Karl
AU  - Schaller K
AD  - Department of Clinical Neurosciences, Division of Neurosurgery, Geneva University 
      Hospitals, Geneva, Switzerland.
FAU - Tran, Sebastien
AU  - Tran S
AD  - Department of Radiation Oncology, Geneva University Hospitals, Geneva, 
      Switzerland.
FAU - Yeung, Jacky
AU  - Yeung J
AD  - Department of Neurosurgery, Yale University School of Medicine, New Haven, 
      Connecticut, USA.
FAU - Bijlenga, Philippe
AU  - Bijlenga P
AD  - Department of Clinical Neurosciences, Division of Neurosurgery, Geneva University 
      Hospitals, Geneva, Switzerland.
LA  - eng
PT  - Journal Article
PL  - England
TA  - BMJ Health Care Inform
JT  - BMJ health &amp; care informatics
JID - 101745500
SB  - IM
MH  - Humans
MH  - *Brain Neoplasms/drug therapy/pathology
MH  - Artificial Intelligence
MH  - *Glioma/pathology/surgery
MH  - Decision Making
PMC - PMC10314415
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Data Management
OT  - Deep Learning
OT  - Information Management
COIS- Competing interests: None declared.
EDAT- 2023/07/03 19:08
MHDA- 2023/07/05 06:42
PMCR- 2023/06/30
CRDT- 2023/07/03 15:02
PHST- 2023/04/03 00:00 [received]
PHST- 2023/06/21 00:00 [accepted]
PHST- 2023/07/05 06:42 [medline]
PHST- 2023/07/03 19:08 [pubmed]
PHST- 2023/07/03 15:02 [entrez]
PHST- 2023/06/30 00:00 [pmc-release]
AID - bmjhci-2023-100775 [pii]
AID - 10.1136/bmjhci-2023-100775 [doi]
PST - ppublish
SO  - BMJ Health Care Inform. 2023 Jun;30(1):e100775. doi: 10.1136/bmjhci-2023-100775.

PMID- 37336169
OWN - NLM
STAT- MEDLINE
DCOM- 20230807
LR  - 20230807
IS  - 1873-4499 (Electronic)
IS  - 0899-7071 (Linking)
VI  - 101
DP  - 2023 Sep
TI  - Decoding radiology reports: Potential application of OpenAI ChatGPT to enhance 
      patient understanding of diagnostic reports.
PG  - 137-141
LID - S0899-7071(23)00146-8 [pii]
LID - 10.1016/j.clinimag.2023.06.008 [doi]
AB  - PURPOSE: To evaluate the complexity of diagnostic radiology reports across major 
      imaging modalities and the ability of ChatGPT (Early March 2023 Version, OpenAI, 
      California, USA) to simplify these reports to the 8th grade reading level of the 
      average U.S. adult. METHODS: We randomly sampled 100 radiographs (XR), 100 
      ultrasound (US), 100 CT, and 100 MRI radiology reports from our institution's 
      database dated between 2022 and 2023 (N&nbsp;=&nbsp;400). These were processed by ChatGPT 
      using the prompt "Explain this radiology report to a patient in layman's terms in 
      second person: &lt;Report Text&gt;". Mean report length, Flesch reading ease score 
      (FRES), and Flesch-Kincaid reading level (FKRL) were calculated for each report 
      and ChatGPT output. T-tests were used to determine significance. RESULTS: Mean 
      report length was 164&nbsp;±&nbsp;117 words, FRES was 38.0&nbsp;±&nbsp;11.8, and FKRL was 10.4&nbsp;±&nbsp;1.9. 
      FKRL was significantly higher for CT and MRI than for US and XR. Only 60/400 
      (15%) had a FKRL &lt;8.5. The mean simplified ChatGPT output length was 103&nbsp;±&nbsp;36 
      words, FRES was 83.5&nbsp;±&nbsp;5.6, and FKRL was 5.8&nbsp;±&nbsp;1.1. This reflects a mean decrease 
      of 61 words (p&nbsp;&lt;&nbsp;0.01), increase in FRES of 45.5 (p&nbsp;&lt;&nbsp;0.01), and decrease in FKRL 
      of 4.6 (p&nbsp;&lt;&nbsp;0.01). All simplified outputs had FKRL &lt;8.5. DISCUSSION: Our study 
      demonstrates the effective use of ChatGPT when tasked with simplifying radiology 
      reports to below the 8th grade reading level. We report significant improvements 
      in FRES, FKRL, and word count, the last of which requires modality-specific 
      context.
CI  - Copyright © 2023 Elsevier Inc. All rights reserved.
FAU - Li, Hanzhou
AU  - Li H
AD  - Emory University School of Medicine, Department of Radiology and Imaging Science, 
      1364 Clifton Rd, Atlanta, GA 30322, United States of America. Electronic address: 
      Hli277@emory.edu.
FAU - Moon, John T
AU  - Moon JT
AD  - Emory University School of Medicine, Department of Radiology and Imaging Science, 
      1364 Clifton Rd, Atlanta, GA 30322, United States of America. Electronic address: 
      https://twitter.com/johntmoon.
FAU - Iyer, Deepak
AU  - Iyer D
AD  - Emory University School of Medicine, Department of Radiology and Imaging Science, 
      1364 Clifton Rd, Atlanta, GA 30322, United States of America. Electronic address: 
      https://twitter.com/d_iyer7.
FAU - Balthazar, Patricia
AU  - Balthazar P
AD  - Emory University School of Medicine, Department of Radiology and Imaging Science, 
      1364 Clifton Rd, Atlanta, GA 30322, United States of America. Electronic address: 
      https://twitter.com/PBalthazarMD.
FAU - Krupinski, Elizabeth A
AU  - Krupinski EA
AD  - Emory University School of Medicine, Department of Radiology and Imaging Science, 
      1364 Clifton Rd, Atlanta, GA 30322, United States of America. Electronic address: 
      https://twitter.com/EAKrup.
FAU - Bercu, Zachary L
AU  - Bercu ZL
AD  - Emory University School of Medicine, Department of Radiology and Imaging Science, 
      1364 Clifton Rd, Atlanta, GA 30322, United States of America. Electronic address: 
      https://twitter.com/ZachBercuMD.
FAU - Newsome, Janice M
AU  - Newsome JM
AD  - Emory University School of Medicine, Department of Radiology and Imaging Science, 
      1364 Clifton Rd, Atlanta, GA 30322, United States of America. Electronic address: 
      https://twitter.com/angiowoman.
FAU - Banerjee, Imon
AU  - Banerjee I
AD  - Mayo Clinic, Department of Radiology, Phoenix, AZ, United States of America. 
      Electronic address: https://twitter.com/ImonBanerjee6.
FAU - Gichoya, Judy W
AU  - Gichoya JW
AD  - Emory University School of Medicine, Department of Radiology and Imaging Science, 
      1364 Clifton Rd, Atlanta, GA 30322, United States of America. Electronic address: 
      https://twitter.com/judywawira.
FAU - Trivedi, Hari M
AU  - Trivedi HM
AD  - Emory University School of Medicine, Department of Radiology and Imaging Science, 
      1364 Clifton Rd, Atlanta, GA 30322, United States of America. Electronic address: 
      https://twitter.com/HariTrivediMD.
LA  - eng
PT  - Journal Article
DEP - 20230608
PL  - United States
TA  - Clin Imaging
JT  - Clinical imaging
JID - 8911831
SB  - IM
MH  - Adult
MH  - Humans
MH  - *Comprehension
MH  - Radiography
MH  - *Radiology
MH  - Magnetic Resonance Imaging
MH  - Databases, Factual
OTO - NOTNLM
OT  - 21st century cures act
OT  - Large language model
OT  - Natural language processing
OT  - Patient-centered reports
COIS- Declaration of competing interest Dr. Balthazar received research support from 
      the Association of University Radiologists GE Radiology Research Academic 
      Fellowship
EDAT- 2023/06/20 01:09
MHDA- 2023/08/07 06:42
CRDT- 2023/06/19 18:07
PHST- 2023/03/13 00:00 [received]
PHST- 2023/05/26 00:00 [revised]
PHST- 2023/06/06 00:00 [accepted]
PHST- 2023/08/07 06:42 [medline]
PHST- 2023/06/20 01:09 [pubmed]
PHST- 2023/06/19 18:07 [entrez]
AID - S0899-7071(23)00146-8 [pii]
AID - 10.1016/j.clinimag.2023.06.008 [doi]
PST - ppublish
SO  - Clin Imaging. 2023 Sep;101:137-141. doi: 10.1016/j.clinimag.2023.06.008. Epub 
      2023 Jun 8.

PMID- 37673708
OWN - NLM
STAT- Publisher
LR  - 20231005
IS  - 2090-2387 (Electronic)
IS  - 1687-1979 (Linking)
VI  - 24
IP  - 3
DP  - 2023 Aug
TI  - ChatGPT's ability to comprehend and answer cirrhosis related questions in Arabic.
PG  - 145-148
LID - S1687-1979(23)00058-8 [pii]
LID - 10.1016/j.ajg.2023.08.001 [doi]
AB  - BACKGROUND AND STUDY AIMS: Cirrhosis is a chronic progressive disease which 
      requires complex care. Its incidence is rising in the Arab countries making it 
      the 7th leading cause of death in the Arab League in 2010. ChatGPT is a large 
      language model with a growing body of literature demonstrating its ability to 
      answer clinical questions. We examined ChatGPT's accuracy in responding to 
      cirrhosis related questions in Arabic and compared its performance to English. 
      MATERIALS AND METHODS: ChatGPTs responses to 91 questions in Arabic and English 
      were graded by a transplant hepatologist fluent in both languages. Accuracy of 
      responses was assessed using the scale: 1. Comprehensive, 2. Correct but 
      inadequate, 3. Mixed with correct and incorrect/outdated data, and 4. Completely 
      incorrect.Accuracy of Arabic compared to English responses was assessed using the 
      scale: 1. Arabic response is more accurate, 2. Similar accuracy, 3. Arabic 
      response is less accurate. RESULTS: The model provided 22 (24.2%) comprehensive, 
      44 (48.4%) correct but inadequate, 13 (14.3%) mixed with correct and 
      incorrect/outdated data and 12 (13.2%) completely incorrect Arabic responses. 
      When comparing the accuracy of Arabic and English responses, 9 (9.9%) of the 
      Arabic responses were graded as more accurate, 52 (57.1%) similar in accuracy and 
      30 (33.0%) as less accurate compared to English. CONCLUSION: ChatGPT has the 
      potential to serve as an adjunct source of information for Arabic speaking 
      patients with cirrhosis. The model provided correct responses in Arabic to 72.5% 
      of questions, although its performance in Arabic was less accurate than in 
      English. The model produced completely incorrect responses to 13.2% of questions, 
      reinforcing its potential role as an adjunct and not replacement of care by 
      licensed healthcare professionals. Future studies to refine this technology are 
      needed to help Arabic speaking patients with cirrhosis across the globe 
      understand their disease and improve their outcomes.
CI  - Copyright © 2023 Pan-Arab Association of Gastroenterology. Published by Elsevier 
      B.V. All rights reserved.
FAU - Samaan, Jamil S
AU  - Samaan JS
AD  - Karsh Division of Gastroenterology and Hepatology, Department of Medicine, 
      Cedars-Sinai Medical Center, Los Angeles, CA, USA.
FAU - Yeo, Yee Hui
AU  - Yeo YH
AD  - Karsh Division of Gastroenterology and Hepatology, Department of Medicine, 
      Cedars-Sinai Medical Center, Los Angeles, CA, USA.
FAU - Ng, Wee Han
AU  - Ng WH
AD  - Bristol Medical School, University of Bristol, Bristol, UK.
FAU - Ting, Peng-Sheng
AU  - Ting PS
AD  - School of Medicine, Tulane University, New Orleans, LA, USA.
FAU - Trivedi, Hirsh
AU  - Trivedi H
AD  - Karsh Division of Gastroenterology and Hepatology, Department of Medicine, 
      Cedars-Sinai Medical Center, Los Angeles, CA, USA; Comprehensive Transplant 
      Center, Cedars-Sinai Medical Center, Los Angeles, CA, USA.
FAU - Vipani, Aarshi
AU  - Vipani A
AD  - Karsh Division of Gastroenterology and Hepatology, Department of Medicine, 
      Cedars-Sinai Medical Center, Los Angeles, CA, USA.
FAU - Yang, Ju Dong
AU  - Yang JD
AD  - Karsh Division of Gastroenterology and Hepatology, Department of Medicine, 
      Cedars-Sinai Medical Center, Los Angeles, CA, USA; Comprehensive Transplant 
      Center, Cedars-Sinai Medical Center, Los Angeles, CA, USA; Samuel Oschin 
      Comprehensive Cancer Institute, Cedars-Sinai Medical Center, Los Angeles, CA, 
      USA.
FAU - Liran, Omer
AU  - Liran O
AD  - Department of Psychiatry and Behavioral Sciences, Cedars-Sinai, Los Angeles, CA, 
      USA; Division of Health Services Research, Department of Medicine, Cedars-Sinai, 
      Los Angeles, CA, USA.
FAU - Spiegel, Brennan
AU  - Spiegel B
AD  - Karsh Division of Gastroenterology and Hepatology, Department of Medicine, 
      Cedars-Sinai Medical Center, Los Angeles, CA, USA; Division of Health Services 
      Research, Department of Medicine, Cedars-Sinai, Los Angeles, CA, USA.
FAU - Kuo, Alexander
AU  - Kuo A
AD  - Karsh Division of Gastroenterology and Hepatology, Department of Medicine, 
      Cedars-Sinai Medical Center, Los Angeles, CA, USA; Comprehensive Transplant 
      Center, Cedars-Sinai Medical Center, Los Angeles, CA, USA.
FAU - Ayoub, Walid S
AU  - Ayoub WS
AD  - Karsh Division of Gastroenterology and Hepatology, Department of Medicine, 
      Cedars-Sinai Medical Center, Los Angeles, CA, USA; Comprehensive Transplant 
      Center, Cedars-Sinai Medical Center, Los Angeles, CA, USA. Electronic address: 
      walid.ayoub@cshs.org.
LA  - eng
PT  - Journal Article
DEP - 20230904
PL  - Egypt
TA  - Arab J Gastroenterol
JT  - Arab journal of gastroenterology : the official publication of the Pan-Arab 
      Association of Gastroenterology
JID - 101298363
SB  - IM
OTO - NOTNLM
OT  - Arabic
OT  - ChatGPT
OT  - Cirrhosis
OT  - Disparity
OT  - Large language model
COIS- Declaration of competing interests The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2023/09/07 00:41
MHDA- 2023/09/07 00:41
CRDT- 2023/09/06 21:56
PHST- 2023/04/25 00:00 [received]
PHST- 2023/07/24 00:00 [revised]
PHST- 2023/08/18 00:00 [accepted]
PHST- 2023/09/07 00:41 [pubmed]
PHST- 2023/09/07 00:41 [medline]
PHST- 2023/09/06 21:56 [entrez]
AID - S1687-1979(23)00058-8 [pii]
AID - 10.1016/j.ajg.2023.08.001 [doi]
PST - ppublish
SO  - Arab J Gastroenterol. 2023 Aug;24(3):145-148. doi: 10.1016/j.ajg.2023.08.001. 
      Epub 2023 Sep 4.

PMID- 37405455
OWN - NLM
STAT- MEDLINE
DCOM- 20240318
LR  - 20240402
IS  - 1434-4726 (Electronic)
IS  - 0937-4477 (Linking)
VI  - 281
IP  - 4
DP  - 2024 Apr
TI  - Exploring the potential of Chat-GPT as a supportive tool for sialendoscopy 
      clinical decision making and patient information support.
PG  - 2081-2086
LID - 10.1007/s00405-023-08104-8 [doi]
AB  - INTRODUCTION: Sialendoscopy has emerged in the last decades as a groundbreaking 
      technique, offering a minimally invasive approach for exploring and managing 
      salivary gland disorders. More recently, the advent of chatbots, powered by 
      advanced natural processing language and artificial intelligence algorithms, has 
      revolutionized the way healthcare professionals and patients access and analyze 
      medical information and potentially will support soon the clinical 
      decision-making process. MATERIALS AND METHODS: A prospective, cross-sectional 
      study was designed to assess the level of agreement between Chat-GPT and 10 
      expert sialendoscopists aiming the capabilities of Chat-GPT to further improve 
      the management of salivary gland disorders. RESULTS: The mean level of agreement 
      was 3.4 (SD: 0.69; Min: 2, Max: 4) for Chat-GPT's answers while it was 4.1 (SD: 
      0.56; Min: 3, Max: 5) for the group of EESS (p &lt; 0.015). The overall Wilcoxon 
      signed-rank test yielded a significance level of p &lt; 0.026 when comparing the 
      level of agreement between Chat-GPT and EESS. The mean number of therapeutic 
      alternatives suggested by Chat-GPT was 3.33 (SD: 1.2; Min: 2, Max: 5), while it 
      was 2.6 (SD: 0.51; Min: 2, Max: 3) for the group of EESS; p = 0.286 (95% 
      CI -&nbsp;0.385 to 1.320). CONCLUSION: Chat-GPT represents a promising tool in the 
      clinical decision-making process within the salivary gland clinic, particularly 
      for patients who are candidates for sialendoscopy treatment. Additionally, it 
      serves as a valuable source of information for patients. However, further 
      development is necessary to enhance the reliability of these tools and ensure 
      their safety and optimal use in the clinical setting.
CI  - © 2023. The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, 
      part of Springer Nature.
FAU - Chiesa-Estomba, Carlos M
AU  - Chiesa-Estomba CM
AUID- ORCID: 0000-0001-9454-9464
AD  - Department of Otorhinolaryngology, Donostia University Hospital, Biodonostia 
      Research Institute, Osakidetza, 20014, San Sebastian, Spain. 
      chiesaestomba86@gmail.com.
AD  - Otorhinolaryngology Department, Faculty of Medicine, Deusto University, Bilbo, 
      Spain. chiesaestomba86@gmail.com.
AD  - Department of Otorhinolaryngology, Head and Neck Surgery, Hospital Universitari 
      Bellvitge, Barcelona, Spain. chiesaestomba86@gmail.com.
AD  - Institut d'Investigació Biomèdica de Bellvitge (IDIBELL), Barcelona, Spain. 
      chiesaestomba86@gmail.com.
AD  - Head &amp; Neck Study Group of Young-Otolaryngologists of the International 
      Federations of Oto-Rhino-Laryngological Societies (YO-IFOS), Paris, France. 
      chiesaestomba86@gmail.com.
AD  - Young Confederation of European Otorhinolaryngology, Head and Neck Surgery, 
      Vienna, Austria. chiesaestomba86@gmail.com.
FAU - Lechien, Jerome R
AU  - Lechien JR
AD  - Division of Laryngology and Broncho-Esophagology, Department of Otolaryngology 
      and Head and Neck Surgery, EpiCURA Hospital, UMONS Research Institute for Health 
      Sciences and Technology, University of Mons, Mons, Belgium.
AD  - Department of Otorhinolaryngology, Head and Neck Surgery, Hospital Universitari 
      Bellvitge, Barcelona, Spain.
AD  - Institut d'Investigació Biomèdica de Bellvitge (IDIBELL), Barcelona, Spain.
AD  - Head &amp; Neck Study Group of Young-Otolaryngologists of the International 
      Federations of Oto-Rhino-Laryngological Societies (YO-IFOS), Paris, France.
FAU - Vaira, Luigi A
AU  - Vaira LA
AD  - Maxillofacial Surgery Operative Unit, Department of Medicine, Surgery and 
      Pharmacy, University of Sassari, Sassari, Italy.
AD  - Biomedical Sciences Department, School of Biomedical Sciences, University of 
      Sassari, Sassari, Italy.
AD  - Department of Otorhinolaryngology, Head and Neck Surgery, Hospital Universitari 
      Bellvitge, Barcelona, Spain.
AD  - Institut d'Investigació Biomèdica de Bellvitge (IDIBELL), Barcelona, Spain.
AD  - Head &amp; Neck Study Group of Young-Otolaryngologists of the International 
      Federations of Oto-Rhino-Laryngological Societies (YO-IFOS), Paris, France.
FAU - Brunet, Aina
AU  - Brunet A
AD  - Department of Otorhinolaryngology, Head and Neck Surgery, Hospital Universitari 
      Bellvitge, Barcelona, Spain.
AD  - Institut d'Investigació Biomèdica de Bellvitge (IDIBELL), Barcelona, Spain.
FAU - Cammaroto, Giovanni
AU  - Cammaroto G
AD  - Department of Otorhinolaryngology, Head and Neck Surgery, Hospital Universitari 
      Bellvitge, Barcelona, Spain.
AD  - Institut d'Investigació Biomèdica de Bellvitge (IDIBELL), Barcelona, Spain.
AD  - Department of Head-Neck Surgery, Otolaryngology, Head-Neck and Oral Surgery Unit, 
      Morgagni Pierantoni Hospital, 47121, Forlì, Italy.
AD  - Head &amp; Neck Study Group of Young-Otolaryngologists of the International 
      Federations of Oto-Rhino-Laryngological Societies (YO-IFOS), Paris, France.
FAU - Mayo-Yanez, Miguel
AU  - Mayo-Yanez M
AD  - Department of Otorhinolaryngology, Head and Neck Surgery, Hospital Universitari 
      Bellvitge, Barcelona, Spain.
AD  - Institut d'Investigació Biomèdica de Bellvitge (IDIBELL), Barcelona, Spain.
AD  - Otorhinolaryngology, Head and Neck Surgery Department, Complexo Hospitalario 
      Universitario A Coruña (CHUAC), 15006, A Coruña, Galicia, Spain.
AD  - Head &amp; Neck Study Group of Young-Otolaryngologists of the International 
      Federations of Oto-Rhino-Laryngological Societies (YO-IFOS), Paris, France.
FAU - Sanchez-Barrueco, Alvaro
AU  - Sanchez-Barrueco A
AD  - Department of Otorhinolaryngology, Head and Neck Surgery, Hospital Universitari 
      Bellvitge, Barcelona, Spain.
AD  - Institut d'Investigació Biomèdica de Bellvitge (IDIBELL), Barcelona, Spain.
AD  - ENT and Cervicofacial Surgery Department, Hospital Universitario Fundación 
      Jiménez Díaz, Madrid, Spain.
AD  - Otorhinolaryngology Department, Faculty of Medicine, Universidad Alfonso X el 
      Sabio, Madrid, Spain.
FAU - Saga-Gutierrez, Carlos
AU  - Saga-Gutierrez C
AD  - Department of Otorhinolaryngology, Donostia University Hospital, Biodonostia 
      Research Institute, Osakidetza, 20014, San Sebastian, Spain.
AD  - Otorhinolaryngology Department, Faculty of Medicine, Deusto University, Bilbo, 
      Spain.
AD  - Department of Otorhinolaryngology, Head and Neck Surgery, Hospital Universitari 
      Bellvitge, Barcelona, Spain.
AD  - Institut d'Investigació Biomèdica de Bellvitge (IDIBELL), Barcelona, Spain.
LA  - eng
PT  - Journal Article
DEP - 20230705
PL  - Germany
TA  - Eur Arch Otorhinolaryngol
JT  - European archives of oto-rhino-laryngology : official journal of the European 
      Federation of Oto-Rhino-Laryngological Societies (EUFOS) : affiliated with the 
      German Society for Oto-Rhino-Laryngology - Head and Neck Surgery
JID - 9002937
RN  - EC 2.6.1.2 (Alanine Transaminase)
SB  - IM
EIN - Eur Arch Otorhinolaryngol. 2023 Oct 11;:. PMID: 37819549
MH  - Humans
MH  - Prospective Studies
MH  - *Artificial Intelligence
MH  - Cross-Sectional Studies
MH  - Reproducibility of Results
MH  - Endoscopy/methods
MH  - *Salivary Gland Diseases/surgery
MH  - Alanine Transaminase
OTO - NOTNLM
OT  - Chat-GPT
OT  - Chatbot
OT  - Gland
OT  - Salivary
OT  - Sialendoscopy
EDAT- 2023/07/05 13:05
MHDA- 2024/03/18 06:42
CRDT- 2023/07/05 11:05
PHST- 2023/06/19 00:00 [received]
PHST- 2023/06/29 00:00 [accepted]
PHST- 2024/03/18 06:42 [medline]
PHST- 2023/07/05 13:05 [pubmed]
PHST- 2023/07/05 11:05 [entrez]
AID - 10.1007/s00405-023-08104-8 [pii]
AID - 10.1007/s00405-023-08104-8 [doi]
PST - ppublish
SO  - Eur Arch Otorhinolaryngol. 2024 Apr;281(4):2081-2086. doi: 
      10.1007/s00405-023-08104-8. Epub 2023 Jul 5.

PMID- 36906947
OWN - NLM
STAT- MEDLINE
DCOM- 20230404
LR  - 20230404
IS  - 1873-5223 (Electronic)
IS  - 1471-5953 (Linking)
VI  - 68
DP  - 2023 Mar
TI  - Is ChatGPT a valid author?
PG  - 103600
LID - S1471-5953(23)00062-8 [pii]
LID - 10.1016/j.nepr.2023.103600 [doi]
AB  - This letter to the editors takes a deeper look at the validity and ethics of 
      authorship of a recently published article in Nurse Education in Practice in 
      which authorship was shared with a chatbox software program, ChatGPT 
      (https://doi.org/10.1016/j.nepr.2022.103537). In particular, a closer assessment 
      is made of the authorship of that article from the established principles of 
      authorship as delineated by the ICMJE.
CI  - Copyright © 2023 Elsevier Ltd. All rights reserved.
FAU - Teixeira da Silva, Jaime A
AU  - Teixeira da Silva JA
AD  - Independent researcher, Ikenobe 3011-2, Kagawa-ken 761-0799, Japan. Electronic 
      address: jaimetex@yahoo.com.
LA  - eng
PT  - Editorial
DEP - 20230307
PL  - Scotland
TA  - Nurse Educ Pract
JT  - Nurse education in practice
JID - 101090848
SB  - IM
MH  - Humans
MH  - *Editorial Policies
MH  - *Authorship
MH  - Publications
OTO - NOTNLM
OT  - Artificial intelligence (AI)
OT  - Authorship principles
OT  - COPE
OT  - Ethics
OT  - ICMJE
OT  - Responsibility
COIS- Conflicts of Interest The author, who declares no conflicts of interest, 
      contributed to the conceptual design, writing, editing, and takes responsibility 
      for the content of the paper (i.e., according to ICMJE recommendations).
EDAT- 2023/03/13 06:00
MHDA- 2023/04/04 06:42
CRDT- 2023/03/12 19:02
PHST- 2023/02/24 00:00 [received]
PHST- 2023/03/06 00:00 [accepted]
PHST- 2023/04/04 06:42 [medline]
PHST- 2023/03/13 06:00 [pubmed]
PHST- 2023/03/12 19:02 [entrez]
AID - S1471-5953(23)00062-8 [pii]
AID - 10.1016/j.nepr.2023.103600 [doi]
PST - ppublish
SO  - Nurse Educ Pract. 2023 Mar;68:103600. doi: 10.1016/j.nepr.2023.103600. Epub 2023 
      Mar 7.

PMID- 38164563
OWN - NLM
STAT- Publisher
LR  - 20240102
IS  - 1468-2079 (Electronic)
IS  - 0007-1161 (Linking)
DP  - 2023 Dec 11
TI  - Review of emerging trends and projection of future developments in large language 
      models research in ophthalmology.
LID - bjo-2023-324734 [pii]
LID - 10.1136/bjo-2023-324734 [doi]
AB  - BACKGROUND: Large language models (LLMs) are fast emerging as potent tools in 
      healthcare, including ophthalmology. This systematic review offers a twofold 
      contribution: it summarises current trends in ophthalmology-related LLM research 
      and projects future directions for this burgeoning field. METHODS: We 
      systematically searched across various databases (PubMed, Europe PMC, Scopus and 
      Web of Science) for articles related to LLM use in ophthalmology, published 
      between 1 January 2022 and 31 July 2023. Selected articles were summarised, and 
      categorised by type (editorial, commentary, original research, etc) and their 
      research focus (eg, evaluating ChatGPT's performance in ophthalmology 
      examinations or clinical tasks). FINDINGS: We identified 32 articles meeting our 
      criteria, published between January and July 2023, with a peak in June (n=12). 
      Most were original research evaluating LLMs' proficiency in clinically related 
      tasks (n=9). Studies demonstrated that ChatGPT-4.0 outperformed its predecessor, 
      ChatGPT-3.5, in ophthalmology exams. Furthermore, ChatGPT excelled in 
      constructing discharge notes (n=2), evaluating diagnoses (n=2) and answering 
      general medical queries (n=6). However, it struggled with generating scientific 
      articles or abstracts (n=3) and answering specific subdomain questions, 
      especially those regarding specific treatment options (n=2). ChatGPT's 
      performance relative to other LLMs (Google's Bard, Microsoft's Bing) varied by 
      study design. Ethical concerns such as data hallucination (n=27), authorship 
      (n=5) and data privacy (n=2) were frequently cited. INTERPRETATION: While LLMs 
      hold transformative potential for healthcare and ophthalmology, concerns over 
      accountability, accuracy and data security remain. Future research should focus 
      on application programming interface integration, comparative assessments of 
      popular LLMs, their ability to interpret image-based data and the establishment 
      of standardised evaluation frameworks.
CI  - © Author(s) (or their employer(s)) 2023. No commercial re-use. See rights and 
      permissions. Published by BMJ.
FAU - Wong, Matthew
AU  - Wong M
AD  - University of Cambridge, Cambridge, UK.
FAU - Lim, Zhi Wei
AU  - Lim ZW
AD  - Yong Loo Lin School of Medicine, National University of Singapore, Singapore.
FAU - Pushpanathan, Krithi
AU  - Pushpanathan K
AD  - Yong Loo Lin School of Medicine, National University of Singapore, Singapore.
AD  - Centre for Innovation and Precision Eye Health &amp; Department of Ophthalmology, 
      Yong Loo Lin School of Medicine, National University of Singapore, Singapore.
FAU - Cheung, Carol Y
AU  - Cheung CY
AUID- ORCID: 0000-0002-9672-1819
AD  - Ophthalmology and Visual Sciences, The Chinese University of Hong Kong, Hong 
      Kong, Hong Kong.
FAU - Wang, Ya Xing
AU  - Wang YX
AUID- ORCID: 0000-0003-2749-7793
AD  - Beijing Institute of Ophthalmology, Beijing Tongren Hospital, Capital University 
      of Medical Science, Beijing, China.
FAU - Chen, David
AU  - Chen D
AUID- ORCID: 0000-0002-2153-3100
AD  - Centre for Innovation and Precision Eye Health &amp; Department of Ophthalmology, 
      Yong Loo Lin School of Medicine, National University of Singapore, Singapore.
AD  - Department of Ophthalmology, National University Hospital, Singapore.
FAU - Tham, Yih Chung
AU  - Tham YC
AUID- ORCID: 0000-0002-6752-797X
AD  - Yong Loo Lin School of Medicine, National University of Singapore, Singapore 
      thamyc@nus.edu.sg.
AD  - Centre for Innovation and Precision Eye Health &amp; Department of Ophthalmology, 
      Yong Loo Lin School of Medicine, National University of Singapore, Singapore.
AD  - Singapore Eye Research Institute, Singapore National Eye Centre, Singapore.
LA  - eng
PT  - Journal Article
DEP - 20231211
PL  - England
TA  - Br J Ophthalmol
JT  - The British journal of ophthalmology
JID - 0421041
SB  - IM
COIS- Competing interests: None declared.
EDAT- 2024/01/02 11:44
MHDA- 2024/01/02 11:44
CRDT- 2024/01/02 03:49
PHST- 2023/10/11 00:00 [received]
PHST- 2023/11/14 00:00 [accepted]
PHST- 2024/01/02 11:44 [medline]
PHST- 2024/01/02 11:44 [pubmed]
PHST- 2024/01/02 03:49 [entrez]
AID - bjo-2023-324734 [pii]
AID - 10.1136/bjo-2023-324734 [doi]
PST - aheadofprint
SO  - Br J Ophthalmol. 2023 Dec 11:bjo-2023-324734. doi: 10.1136/bjo-2023-324734.

PMID- 36918736
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20230324
LR  - 20230324
IS  - 1546-170X (Electronic)
IS  - 1078-8956 (Linking)
VI  - 29
IP  - 3
DP  - 2023 Mar
TI  - Will ChatGPT transform healthcare?
PG  - 505-506
LID - 10.1038/s41591-023-02289-5 [doi]
LA  - eng
PT  - Editorial
PL  - United States
TA  - Nat Med
JT  - Nature medicine
JID - 9502015
SB  - IM
EDAT- 2023/03/16 06:00
MHDA- 2023/03/16 06:01
CRDT- 2023/03/15 01:05
PHST- 2023/03/16 06:00 [pubmed]
PHST- 2023/03/16 06:01 [medline]
PHST- 2023/03/15 01:05 [entrez]
AID - 10.1038/s41591-023-02289-5 [pii]
AID - 10.1038/s41591-023-02289-5 [doi]
PST - ppublish
SO  - Nat Med. 2023 Mar;29(3):505-506. doi: 10.1038/s41591-023-02289-5.

PMID- 37236498
OWN - NLM
STAT- MEDLINE
DCOM- 20230717
LR  - 20231121
IS  - 1873-6246 (Electronic)
IS  - 0301-0511 (Linking)
VI  - 181
DP  - 2023 Jul
TI  - Intelligence or artificial intelligence? More hard problems for authors of 
      Biological Psychology, the neurosciences, and everyone else.
PG  - 108590
LID - S0301-0511(23)00107-2 [pii]
LID - 10.1016/j.biopsycho.2023.108590 [doi]
FAU - Ritz, Thomas
AU  - Ritz T
AD  - Department of Psychology, Southern Methodist University, Dallas, TX, USA. 
      Electronic address: tritz@smu.edu.
LA  - eng
PT  - Editorial
DEP - 20230524
PL  - Netherlands
TA  - Biol Psychol
JT  - Biological psychology
JID - 0375566
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Intelligence
MH  - *Neurosciences
OTO - NOTNLM
OT  - Academic malpractice
OT  - Artificial text production
OT  - Authorship
OT  - ChatGPT
OT  - Large language models
COIS- Declaration of Competing Interest The author has no conflicts of interest to 
      declare.
EDAT- 2023/05/27 09:41
MHDA- 2023/07/17 06:42
CRDT- 2023/05/26 19:27
PHST- 2023/05/18 00:00 [received]
PHST- 2023/05/22 00:00 [accepted]
PHST- 2023/07/17 06:42 [medline]
PHST- 2023/05/27 09:41 [pubmed]
PHST- 2023/05/26 19:27 [entrez]
AID - S0301-0511(23)00107-2 [pii]
AID - 10.1016/j.biopsycho.2023.108590 [doi]
PST - ppublish
SO  - Biol Psychol. 2023 Jul;181:108590. doi: 10.1016/j.biopsycho.2023.108590. Epub 
      2023 May 24.

PMID- 37034476
OWN - NLM
STAT- MEDLINE
DCOM- 20230417
LR  - 20230627
IS  - 1482-1826 (Electronic)
IS  - 1482-1826 (Linking)
VI  - 26
DP  - 2023
TI  - Adapting artificial intelligence into the evolution of pharmaceutical sciences 
      and publishing: Technological darwinism.
PG  - 11349
LID - 10.3389/jpps.2023.11349 [doi]
LID - 11349
FAU - Davies, Neal M
AU  - Davies NM
AD  - Faculty of Pharmacy &amp; Pharmaceutical Sciences, University of Alberta, Edmonton, 
      AB, Canada.
LA  - eng
PT  - Editorial
DEP - 20230322
PL  - Switzerland
TA  - J Pharm Pharm Sci
JT  - Journal of pharmacy &amp; pharmaceutical sciences : a publication of the Canadian 
      Society for Pharmaceutical Sciences, Societe canadienne des sciences 
      pharmaceutiques
JID - 9807281
RN  - 0 (Pharmaceutical Preparations)
SB  - IM
MH  - *Artificial Intelligence
MH  - Pharmaceutical Preparations
MH  - *Publishing
MH  - *Drug Industry
PMC - PMC10075305
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial
OT  - evolution
OT  - intelligence
OT  - pharmaceutical
COIS- The author declares that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/04/11 06:00
MHDA- 2023/04/11 06:41
PMCR- 2023/03/22
CRDT- 2023/04/10 04:09
PHST- 2023/03/09 00:00 [received]
PHST- 2023/03/13 00:00 [accepted]
PHST- 2023/04/11 06:41 [medline]
PHST- 2023/04/10 04:09 [entrez]
PHST- 2023/04/11 06:00 [pubmed]
PHST- 2023/03/22 00:00 [pmc-release]
AID - 11349 [pii]
AID - 10.3389/jpps.2023.11349 [doi]
PST - epublish
SO  - J Pharm Pharm Sci. 2023 Mar 22;26:11349. doi: 10.3389/jpps.2023.11349. 
      eCollection 2023.

PMID- 38362894
OWN - NLM
STAT- Publisher
LR  - 20240216
IS  - 1469-2147 (Electronic)
IS  - 0963-1801 (Linking)
DP  - 2024 Feb 16
TI  - Rights and Wrongs in Talk of Mind-Reading Technology.
PG  - 1-11
LID - 10.1017/S0963180124000045 [doi]
AB  - This article examines the idea of mind-reading technology by focusing on an 
      interesting case of applying a large language model (LLM) to brain data. On the 
      face of it, experimental results appear to show that it is possible to 
      reconstruct mental contents directly from brain data by processing via a 
      chatGPT-like LLM. However, the author argues that this apparent conclusion is not 
      warranted. Through examining how LLMs work, it is shown that they are importantly 
      different from natural language. The former operates on the basis of nonrational 
      data transformations based on a large textual corpus. The latter has a rational 
      dimension, being based on reasons. Using this as a basis, it is argued that brain 
      data does not directly reveal mental content, but can be processed to ground 
      predictions indirectly about mental content. The author concludes that this is 
      impressive but different in principle from technology-mediated mind reading. The 
      applications of LLM-based brain data processing are nevertheless promising for 
      speech rehabilitation or novel communication methods.
FAU - Rainey, Stephen
AU  - Rainey S
AD  - Philosophy and Ethics of Technology Section, TU Delft, Delft, The Netherlands.
LA  - eng
PT  - Journal Article
DEP - 20240216
PL  - United States
TA  - Camb Q Healthc Ethics
JT  - Cambridge quarterly of healthcare ethics : CQ : the international journal of 
      healthcare ethics committees
JID - 9208482
SB  - IM
OTO - NOTNLM
OT  - brain data
OT  - chatGPT
OT  - fMRI
OT  - large language models
OT  - mind reading
OT  - reasons
EDAT- 2024/02/16 12:47
MHDA- 2024/02/16 12:47
CRDT- 2024/02/16 07:58
PHST- 2024/02/16 12:47 [medline]
PHST- 2024/02/16 12:47 [pubmed]
PHST- 2024/02/16 07:58 [entrez]
AID - S0963180124000045 [pii]
AID - 10.1017/S0963180124000045 [doi]
PST - aheadofprint
SO  - Camb Q Healthc Ethics. 2024 Feb 16:1-11. doi: 10.1017/S0963180124000045.

PMID- 37775381
OWN - NLM
STAT- MEDLINE
DCOM- 20231219
LR  - 20231221
IS  - 0219-3108 (Electronic)
IS  - 1015-9584 (Linking)
VI  - 46
IP  - 12
DP  - 2023 Dec
TI  - Can ChatGPT pass China's national medical licensing examination?
PG  - 6112-6113
LID - S1015-9584(23)01505-1 [pii]
LID - 10.1016/j.asjsur.2023.09.089 [doi]
FAU - Shang, Luxiang
AU  - Shang L
AD  - Department of Cardiology, The First Affiliated Hospital of Shandong First Medical 
      University, Shandong Provincial Qianfoshan Hospital, Shandong Medicine and Health 
      Key Laboratory of Cardiac Electrophysiology and Arrhythmia, Jinan, Shandong, 
      250014, China.
FAU - Xue, Mingyue
AU  - Xue M
AD  - Zane Cohen Centre for Digestive Diseases, Mount Sinai Hospital, Toronto, Canada.
FAU - Hou, Yinglong
AU  - Hou Y
AD  - Department of Cardiology, The First Affiliated Hospital of Shandong First Medical 
      University, Shandong Provincial Qianfoshan Hospital, Shandong Medicine and Health 
      Key Laboratory of Cardiac Electrophysiology and Arrhythmia, Jinan, Shandong, 
      250014, China. Electronic address: yinglonghou@hotmail.com.
FAU - Tang, Baopeng
AU  - Tang B
AD  - Department of Pacing and Electrophysiology, Xinjiang Key Laboratory of Cardiac 
      Electrophysiology and Remodeling, The First Affiliated Hospital of Xinjiang 
      Medical University, Urumqi, Xinjiang, 830054, China. Electronic address: 
      tangbaopeng1111@163.com.
LA  - eng
PT  - Letter
DEP - 20230927
PL  - Netherlands
TA  - Asian J Surg
JT  - Asian journal of surgery
JID - 8900600
SB  - IM
MH  - China
MH  - *Artificial Intelligence
MH  - *Licensure
MH  - *Educational Measurement
OTO - NOTNLM
OT  - ChatGPT
OT  - Medical education
OT  - National Medical Licensing Examination
COIS- Declaration of competing interest All authors report no conflict of interest.
EDAT- 2023/09/30 09:42
MHDA- 2023/12/17 09:43
CRDT- 2023/09/29 21:54
PHST- 2023/08/27 00:00 [received]
PHST- 2023/09/14 00:00 [accepted]
PHST- 2023/12/17 09:43 [medline]
PHST- 2023/09/30 09:42 [pubmed]
PHST- 2023/09/29 21:54 [entrez]
AID - S1015-9584(23)01505-1 [pii]
AID - 10.1016/j.asjsur.2023.09.089 [doi]
PST - ppublish
SO  - Asian J Surg. 2023 Dec;46(12):6112-6113. doi: 10.1016/j.asjsur.2023.09.089. Epub 
      2023 Sep 27.

PMID- 37703085
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231003
IS  - 2561-7605 (Electronic)
IS  - 2561-7605 (Linking)
VI  - 6
DP  - 2023 Sep 13
TI  - Shaping the Future of Older Adult Care: ChatGPT, Advanced AI, and the 
      Transformation of Clinical Practice.
PG  - e51776
LID - 10.2196/51776 [doi]
LID - e51776
AB  - As the older adult population in the United States grows, new approaches to 
      managing and streamlining clinical work are needed to accommodate their increased 
      demand for health care. Deep learning and generative artificial intelligence (AI) 
      have the potential to transform how care is delivered and how clinicians practice 
      in geriatrics. In this editorial, we explore the opportunities and limitations of 
      these technologies.
CI  - ©Kathleen Fear, Conrad Gleber. Originally published in JMIR Aging 
      (https://aging.jmir.org), 13.09.2023.
FAU - Fear, Kathleen
AU  - Fear K
AUID- ORCID: 0000-0003-4608-6949
AD  - UR Health Lab, University of Rochester Medical Center, Rochester, NY, United 
      States.
FAU - Gleber, Conrad
AU  - Gleber C
AUID- ORCID: 0009-0005-8241-944X
AD  - UR Health Lab, University of Rochester Medical Center, Rochester, NY, United 
      States.
AD  - Department of Medicine, University of Rochester Medical Center, Rochester, NY, 
      United States.
LA  - eng
PT  - Journal Article
DEP - 20230913
PL  - Canada
TA  - JMIR Aging
JT  - JMIR aging
JID - 101740387
PMC - PMC10534283
OTO - NOTNLM
OT  - ChatGPT
OT  - Generative Pre-trained Transformer
OT  - artificial intelligence
OT  - generative AI
OT  - large language models
COIS- Conflicts of Interest: None declared.
EDAT- 2023/09/13 12:43
MHDA- 2023/09/13 12:44
PMCR- 2023/09/13
CRDT- 2023/09/13 11:54
PHST- 2023/08/11 00:00 [received]
PHST- 2023/08/25 00:00 [accepted]
PHST- 2023/09/13 12:44 [medline]
PHST- 2023/09/13 12:43 [pubmed]
PHST- 2023/09/13 11:54 [entrez]
PHST- 2023/09/13 00:00 [pmc-release]
AID - v6i1e51776 [pii]
AID - 10.2196/51776 [doi]
PST - epublish
SO  - JMIR Aging. 2023 Sep 13;6:e51776. doi: 10.2196/51776.

PMID- 37323042
OWN - NLM
STAT- MEDLINE
DCOM- 20230619
LR  - 20230619
IS  - 0303-7339 (Print)
IS  - 0303-7339 (Linking)
VI  - 65
IP  - 4
DP  - 2023
TI  - [Artificial intelligence in psychiatry: co-creation of human and ChatGPT].
PG  - 241-243
AB  - BACKGROUND: Artificial intelligence (AI) can be a valuable addition to psychiatry 
      by helping to make diagnoses, personalize treatments, and support patients during 
      their recovery. However, it is important to consider the risks and ethical 
      implications of using this technology. AIM: In this article, we explore how AI 
      can change the future of psychiatry from a co-creation perspective, meaning that 
      people and machines work together to provide the best possible care. We provide 
      both critical and optimistic perspectives on how AI can influence psychiatry. 
      METHOD: A co-creation methodology was used to produce this essay, involving 
      interaction between my prompt and the text generated in response by the AI-based 
      chatbot ChatGPT. RESULTS: We describe how AI can be used to make diagnoses, 
      personalize treatments, and support patients during their recovery. We also 
      discuss the risks and ethical implications of using AI in psychiatry. CONCLUSION: 
      If we critically examine the risks and ethical implications of using AI in 
      psychiatry and promote co-creation between people and machines, AI can contribute 
      to improved care for patients in the future.
FAU - van Dellen, E
AU  - van Dellen E
LA  - dut
PT  - English Abstract
PT  - Journal Article
TT  - Kunstmatige intelligentie in de psychiatrie: cocreatie van mens en ChatGPT.
PL  - Netherlands
TA  - Tijdschr Psychiatr
JT  - Tijdschrift voor psychiatrie
JID - 0423731
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Psychiatry
EDAT- 2023/06/16 06:42
MHDA- 2023/06/19 13:08
CRDT- 2023/06/16 03:48
PHST- 2023/06/19 13:08 [medline]
PHST- 2023/06/16 06:42 [pubmed]
PHST- 2023/06/16 03:48 [entrez]
AID - TVPart_13153 [pii]
PST - ppublish
SO  - Tijdschr Psychiatr. 2023;65(4):241-243.

PMID- 36748354
OWN - NLM
STAT- Publisher
LR  - 20240216
IS  - 1545-5815 (Electronic)
IS  - 0898-9621 (Linking)
DP  - 2023 Feb 13
TI  - Letter to editor: NLP systems such as ChatGPT cannot be listed as an author 
      because these cannot fulfill widely adopted authorship criteria.
PG  - 1-3
LID - 10.1080/08989621.2023.2177160 [doi]
AB  - This letter to the editor suggests adding a technical point to the new editorial 
      policy expounded by Hosseini et al. on the mandatory disclosure of any use of 
      natural language processing (NLP) systems, or generative AI, in writing scholarly 
      publications. Such AI systems should naturally also be forbidden from being named 
      as authors, because they would not have fulfilled prevailing authorship 
      guidelines (such as the widely adopted ICMJE authorship criteria).
FAU - Yeo-Teh, Nicole Shu Ling
AU  - Yeo-Teh NSL
AUID- ORCID: 0000-0002-9153-9663
AD  - Research Compliance and Integrity Office, National University of Singapore, 
      Singapore, Singapore.
FAU - Tang, Bor Luen
AU  - Tang BL
AUID- ORCID: 0000-0002-1925-636X
AD  - Department of Biochemistry, Yong Loo Lin School of Medicine, National University 
      Health System, Singapore, Singapore.
LA  - eng
PT  - Journal Article
DEP - 20230213
PL  - United States
TA  - Account Res
JT  - Accountability in research
JID - 9100813
SB  - IM
OTO - NOTNLM
OT  - Authorship
OT  - ChatGPT
OT  - Generative AI
OT  - ICMJE guidelines
EDAT- 2023/02/08 06:00
MHDA- 2023/02/08 06:00
CRDT- 2023/02/07 04:23
PHST- 2023/02/08 06:00 [pubmed]
PHST- 2023/02/08 06:00 [medline]
PHST- 2023/02/07 04:23 [entrez]
AID - 10.1080/08989621.2023.2177160 [doi]
PST - aheadofprint
SO  - Account Res. 2023 Feb 13:1-3. doi: 10.1080/08989621.2023.2177160.

PMID- 38147047
OWN - NLM
STAT- Publisher
LR  - 20231226
IS  - 2192-5682 (Print)
IS  - 2192-5682 (Linking)
DP  - 2023 Dec 26
TI  - Artificially Intelligent Billing in Spine Surgery: An Analysis of a Large 
      Language Model.
PG  - 21925682231224753
LID - 10.1177/21925682231224753 [doi]
AB  - STUDY DESIGN: Retrospective cohort study. OBJECTIVES: This study assessed the 
      effectiveness of a popular large language model, ChatGPT-4, in predicting Current 
      Procedural Terminology (CPT) codes from surgical operative notes. By employing a 
      combination of prompt engineering, natural language processing (NLP), and machine 
      learning techniques on standard operative notes, the study sought to enhance 
      billing efficiency, optimize revenue collection, and reduce coding errors. 
      METHODS: The model was given 3 different types of prompts for 50 surgical 
      operative notes from 2 spine surgeons. The first trial was simply asking the 
      model to generate CPT codes for a given OP note. The second trial included 3 OP 
      notes and associated CPT codes to, and the third trial included a list of every 
      possible CPT code in the dataset to prime the model. CPT codes generated by the 
      model were compared to those generated by the billing department. Model 
      evaluation was performed in the form of calculating the area under the ROC 
      (AUROC), and area under precision-recall curves (AUPRC). RESULTS: The trial that 
      involved priming ChatGPT with a list of every possible CPT code performed the 
      best, with an AUROC of .87 and an AUPRC of .67, and an AUROC of .81 and AUPRC of 
      .76 when examining only the most common CPT codes. CONCLUSIONS: ChatGPT-4 can aid 
      in automating CPT billing from orthopedic surgery operative notes, driving down 
      healthcare expenditures and enhancing billing code precision as the model evolves 
      and fine-tuning becomes available.
FAU - Zaidat, Bashar
AU  - Zaidat B
AUID- ORCID: 0000-0002-8823-720X
AD  - Department of Orthopaedic Surgery, Icahn School of Medicine at Mount Sinai, New 
      York, NY, USA. RINGGOLD: 5925
FAU - Lahoti, Yash S
AU  - Lahoti YS
AD  - Department of Orthopaedic Surgery, Icahn School of Medicine at Mount Sinai, New 
      York, NY, USA. RINGGOLD: 5925
FAU - Yu, Alexander
AU  - Yu A
AUID- ORCID: 0000-0002-7246-2269
AD  - Department of Orthopaedic Surgery, Icahn School of Medicine at Mount Sinai, New 
      York, NY, USA. RINGGOLD: 5925
FAU - Mohamed, Kareem S
AU  - Mohamed KS
AD  - Department of Orthopaedic Surgery, Icahn School of Medicine at Mount Sinai, New 
      York, NY, USA. RINGGOLD: 5925
FAU - Cho, Samuel K
AU  - Cho SK
AD  - Department of Orthopaedic Surgery, Icahn School of Medicine at Mount Sinai, New 
      York, NY, USA. RINGGOLD: 5925
FAU - Kim, Jun S
AU  - Kim JS
AD  - Department of Orthopaedic Surgery, Icahn School of Medicine at Mount Sinai, New 
      York, NY, USA. RINGGOLD: 5925
LA  - eng
PT  - Journal Article
DEP - 20231226
PL  - England
TA  - Global Spine J
JT  - Global spine journal
JID - 101596156
OTO - NOTNLM
OT  - chatGPT
OT  - current procedural terminology
OT  - large language model
OT  - natural language processing
OT  - prompt engineering
OT  - spine
COIS- Declaration of conflicting interestsThe author(s) declared the following 
      potential conflicts of interest with respect to the research, authorship, and/or 
      publication of this article: Jun S. Kim, MD-Stryker: Paid consultant. Samuel 
      Kang-Wook Cho, MD, FAAOS-AAOS: Board or committee member, American Orthopaedic 
      Association: Board or committee member, AOSpine North America: Board or committee 
      member, Cervical Spine Research Society: Board or committee member, Globus 
      Medical: IP royalties, North American Spine Society: Board or committee member, 
      Scoliosis Research Society: Board or committee member, Stryker: Paid consultant. 
      The following individuals have no conflicts of interest or sources of support 
      that require acknowledgement: Bashar Zaidat, Yash S. Lahoti, Alexander Yu, Kareem 
      S. Mohamed.
EDAT- 2023/12/26 12:42
MHDA- 2023/12/26 12:42
CRDT- 2023/12/26 10:43
PHST- 2023/12/26 12:42 [medline]
PHST- 2023/12/26 12:42 [pubmed]
PHST- 2023/12/26 10:43 [entrez]
AID - 10.1177/21925682231224753 [doi]
PST - aheadofprint
SO  - Global Spine J. 2023 Dec 26:21925682231224753. doi: 10.1177/21925682231224753.

PMID- 37731643
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230922
IS  - 2234-943X (Print)
IS  - 2234-943X (Electronic)
IS  - 2234-943X (Linking)
VI  - 13
DP  - 2023
TI  - Applications of large language models in cancer care: current evidence and future 
      perspectives.
PG  - 1268915
LID - 10.3389/fonc.2023.1268915 [doi]
LID - 1268915
AB  - The development of large language models (LLMs) is a recent success in the field 
      of generative artificial intelligence (AI). They are computer models able to 
      perform a wide range of natural language processing tasks, including content 
      generation, question answering, or language translation. In recent months, a 
      growing number of studies aimed to assess their potential applications in the 
      field of medicine, including cancer care. In this mini review, we described the 
      present published evidence for using LLMs in oncology. All the available studies 
      assessed ChatGPT, an advanced language model developed by OpenAI, alone or 
      compared to other LLMs, such as Google Bard, Chatsonic, and Perplexity. Although 
      ChatGPT could provide adequate information on the screening or the management of 
      specific solid tumors, it also demonstrated a significant error rate and a 
      tendency toward providing obsolete data. Therefore, an accurate, expert-driven 
      verification process remains mandatory to avoid the potential for misinformation 
      and incorrect evidence. Overall, although this new generative AI-based technology 
      has the potential to revolutionize the field of medicine, including that of 
      cancer care, it will be necessary to develop rules to guide the application of 
      these tools to maximize benefits and minimize risks.
CI  - Copyright © 2023 Iannantuono, Bracken-Clarke, Floudas, Roselli, Gulley and 
      Karzai.
FAU - Iannantuono, Giovanni Maria
AU  - Iannantuono GM
AD  - Genitourinary Malignancies Branch, Center for Cancer Research, National Cancer 
      Institute, National Institutes of Health, Bethesda, MD, United States.
AD  - Medical Oncology Unit, Department of Systems Medicine, University of Rome Tor 
      Vergata, Rome, Italy.
FAU - Bracken-Clarke, Dara
AU  - Bracken-Clarke D
AD  - Center for Immuno-Oncology, Center for Cancer Research, National Cancer 
      Institute, National Institutes of Health, Bethesda, MD, United States.
FAU - Floudas, Charalampos S
AU  - Floudas CS
AD  - Center for Immuno-Oncology, Center for Cancer Research, National Cancer 
      Institute, National Institutes of Health, Bethesda, MD, United States.
FAU - Roselli, Mario
AU  - Roselli M
AD  - Medical Oncology Unit, Department of Systems Medicine, University of Rome Tor 
      Vergata, Rome, Italy.
FAU - Gulley, James L
AU  - Gulley JL
AD  - Center for Immuno-Oncology, Center for Cancer Research, National Cancer 
      Institute, National Institutes of Health, Bethesda, MD, United States.
FAU - Karzai, Fatima
AU  - Karzai F
AD  - Genitourinary Malignancies Branch, Center for Cancer Research, National Cancer 
      Institute, National Institutes of Health, Bethesda, MD, United States.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230904
PL  - Switzerland
TA  - Front Oncol
JT  - Frontiers in oncology
JID - 101568867
PMC - PMC10507617
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - cancer care
OT  - chatbot
OT  - large language models
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/09/21 06:42
MHDA- 2023/09/21 06:43
PMCR- 2023/01/01
CRDT- 2023/09/21 04:01
PHST- 2023/07/28 00:00 [received]
PHST- 2023/08/21 00:00 [accepted]
PHST- 2023/09/21 06:43 [medline]
PHST- 2023/09/21 06:42 [pubmed]
PHST- 2023/09/21 04:01 [entrez]
PHST- 2023/01/01 00:00 [pmc-release]
AID - 10.3389/fonc.2023.1268915 [doi]
PST - epublish
SO  - Front Oncol. 2023 Sep 4;13:1268915. doi: 10.3389/fonc.2023.1268915. eCollection 
      2023.

PMID- 38528008
OWN - NLM
STAT- MEDLINE
DCOM- 20240327
LR  - 20240328
IS  - 2045-2322 (Electronic)
IS  - 2045-2322 (Linking)
VI  - 14
IP  - 1
DP  - 2024 Mar 26
TI  - Risk and prosocial behavioural cues elicit human-like response patterns from AI 
      chatbots.
PG  - 7095
LID - 10.1038/s41598-024-55949-y [doi]
LID - 7095
AB  - Emotions, long deemed a distinctly human characteristic, guide a repertoire of 
      behaviors, e.g., promoting risk-aversion under negative emotional states or 
      generosity under positive ones. The question of whether Artificial Intelligence 
      (AI) can possess emotions remains elusive, chiefly due to the absence of an 
      operationalized consensus on what constitutes 'emotion' within AI. Adopting a 
      pragmatic approach, this study investigated the response patterns of AI 
      chatbots-specifically, large language models (LLMs)-to various emotional primes. 
      We engaged AI chatbots as one would human participants, presenting scenarios 
      designed to elicit positive, negative, or neutral emotional states. Multiple 
      accounts of OpenAI's ChatGPT Plus were then tasked with responding to inquiries 
      concerning investment decisions and prosocial behaviors. Our analysis revealed 
      that ChatGPT-4 bots, when primed with positive, negative, or neutral emotions, 
      exhibited distinct response patterns in both risk-taking and prosocial decisions, 
      a phenomenon less evident in the ChatGPT-3.5 iterations. This observation 
      suggests an enhanced capacity for modulating responses based on emotional cues in 
      more advanced LLMs. While these findings do not suggest the presence of emotions 
      in AI, they underline the feasibility of swaying AI responses by leveraging 
      emotional indicators.
CI  - © 2024. The Author(s).
FAU - Zhao, Yukun
AU  - Zhao Y
AD  - Positive Psychology Research Center, School of Social Sciences, Tsinghua 
      University, Beijing, China.
FAU - Huang, Zhen
AU  - Huang Z
AD  - Positive Psychology Research Center, School of Social Sciences, Tsinghua 
      University, Beijing, China.
FAU - Seligman, Martin
AU  - Seligman M
AD  - Department of Psychology, University of Pennsylvania, Philadelphia, USA.
FAU - Peng, Kaiping
AU  - Peng K
AD  - Department of Psychology, Tsinghua University, 5th Floor, Weiqing Building, 
      Beijing, 100084, China. pengkp@tsinghua.edu.cn.
LA  - eng
PT  - Journal Article
DEP - 20240326
PL  - England
TA  - Sci Rep
JT  - Scientific reports
JID - 101563288
SB  - IM
MH  - Humans
MH  - *Altruism
MH  - *Artificial Intelligence
MH  - Cues
MH  - Software
MH  - Affect
PMC - PMC10963757
COIS- The authors declare no competing interests.
EDAT- 2024/03/26 06:44
MHDA- 2024/03/27 06:44
PMCR- 2024/03/26
CRDT- 2024/03/26 00:15
PHST- 2023/05/12 00:00 [received]
PHST- 2024/02/29 00:00 [accepted]
PHST- 2024/03/27 06:44 [medline]
PHST- 2024/03/26 06:44 [pubmed]
PHST- 2024/03/26 00:15 [entrez]
PHST- 2024/03/26 00:00 [pmc-release]
AID - 10.1038/s41598-024-55949-y [pii]
AID - 55949 [pii]
AID - 10.1038/s41598-024-55949-y [doi]
PST - epublish
SO  - Sci Rep. 2024 Mar 26;14(1):7095. doi: 10.1038/s41598-024-55949-y.

PMID- 38510403
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240322
IS  - 2156-8650 (Electronic)
IS  - 2156-8650 (Linking)
VI  - 34
IP  - 1
DP  - 2024 Feb
TI  - ChatGPT-Based Learning: Generative Artificial Intelligence in Medical Education.
PG  - 215-217
LID - 10.1007/s40670-023-01934-5 [doi]
AB  - Large language models like ChatGPT are a type of machine learning model that can 
      offer a positive paradigm shift in case-based/problem-based learning (CBL/PBL). 
      ChatGPT may be able to augment the existing paradigm to work in conjunction with 
      the clinical-teacher in PBL/CBL case generation. It can develop realistic patient 
      cases that could be revised by clinical teachers to ensure accuracy and 
      relevance. Further, it can be directed to include specific case content in order 
      to facilitate the constructive alignment of the case with the broader learning 
      objectives of the curriculum. There is also the possibility of improving 
      engagement by 'gamifying' CBL/PBL. SUPPLEMENTARY INFORMATION: The online version 
      contains supplementary material available at 10.1007/s40670-023-01934-5.
CI  - © The Author(s) under exclusive licence to International Association of Medical 
      Science Educators 2023. Springer Nature or its licensor (e.g. a society or other 
      partner) holds exclusive rights to this article under a publishing agreement with 
      the author(s) or other rightsholder(s); author self-archiving of the accepted 
      manuscript version of this article is solely governed by the terms of such 
      publishing agreement and applicable law.
FAU - Stretton, Brandon
AU  - Stretton B
AUID- ORCID: 0000-0002-7939-3489
AD  - Faculty of Health and Medical Sciences, Adelaide Medical School, University of 
      Adelaide, Adelaide, SA 5000 Australia. ROR: https://ror.org/00892tw58. GRID: 
      grid.1010.0. ISNI: 0000 0004 1936 7304
FAU - Kovoor, Joshua
AU  - Kovoor J
AD  - Faculty of Health and Medical Sciences, Adelaide Medical School, University of 
      Adelaide, Adelaide, SA 5000 Australia. ROR: https://ror.org/00892tw58. GRID: 
      grid.1010.0. ISNI: 0000 0004 1936 7304
FAU - Arnold, Matthew
AU  - Arnold M
AD  - Faculty of Health and Medical Sciences, Adelaide Medical School, University of 
      Adelaide, Adelaide, SA 5000 Australia. ROR: https://ror.org/00892tw58. GRID: 
      grid.1010.0. ISNI: 0000 0004 1936 7304
FAU - Bacchi, Stephen
AU  - Bacchi S
AD  - Faculty of Health and Medical Sciences, Adelaide Medical School, University of 
      Adelaide, Adelaide, SA 5000 Australia. ROR: https://ror.org/00892tw58. GRID: 
      grid.1010.0. ISNI: 0000 0004 1936 7304
LA  - eng
PT  - Editorial
DEP - 20231108
PL  - United States
TA  - Med Sci Educ
JT  - Medical science educator
JID - 101625548
PMC - PMC10948641
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Case based learning
OT  - Medical curriculum
OT  - Medical education
COIS- Conflict of InterestThe authors declare no competing interests.
EDAT- 2024/03/21 06:43
MHDA- 2024/03/21 06:44
PMCR- 2025/02/01
CRDT- 2024/03/21 04:09
PHST- 2023/10/27 00:00 [accepted]
PHST- 2025/02/01 00:00 [pmc-release]
PHST- 2024/03/21 06:44 [medline]
PHST- 2024/03/21 06:43 [pubmed]
PHST- 2024/03/21 04:09 [entrez]
AID - 1934 [pii]
AID - 10.1007/s40670-023-01934-5 [doi]
PST - epublish
SO  - Med Sci Educ. 2023 Nov 8;34(1):215-217. doi: 10.1007/s40670-023-01934-5. 
      eCollection 2024 Feb.

PMID- 36841840
OWN - NLM
STAT- MEDLINE
DCOM- 20230228
LR  - 20240109
IS  - 1466-609X (Electronic)
IS  - 1364-8535 (Print)
IS  - 1364-8535 (Linking)
VI  - 27
IP  - 1
DP  - 2023 Feb 25
TI  - Can artificial intelligence help for scientific writing?
PG  - 75
LID - 10.1186/s13054-023-04380-2 [doi]
LID - 75
AB  - This paper discusses the use of Artificial Intelligence Chatbot in scientific 
      writing. ChatGPT is a type of chatbot, developed by OpenAI, that uses the 
      Generative Pre-trained Transformer (GPT) language model to understand and respond 
      to natural language inputs. AI chatbot and ChatGPT in particular appear to be 
      useful tools in scientific writing, assisting researchers and scientists in 
      organizing material, generating an initial draft and/or in proofreading. There is 
      no publication in the field of critical care medicine prepared using this 
      approach; however, this will be a possibility in the next future. ChatGPT work 
      should not be used as a replacement for human judgment and the output should 
      always be reviewed by experts before being used in any critical decision-making 
      or application. Moreover, several ethical issues arise about using these tools, 
      such as the risk of plagiarism and inaccuracies, as well as a potential imbalance 
      in its accessibility between high- and low-income countries, if the software 
      becomes paying. For this reason, a consensus on how to regulate the use of 
      chatbots in scientific writing will soon be required.
CI  - © 2023. The Author(s).
FAU - Salvagno, Michele
AU  - Salvagno M
AD  - Department of Intensive Care, Erasme Hospital, Université Libre de Bruxelles, 
      1070, Brussels, Belgium. michele.salvagno@ulb.be.
FAU - Taccone, Fabio Silvio
AU  - Taccone FS
AD  - Department of Intensive Care, Erasme Hospital, Université Libre de Bruxelles, 
      1070, Brussels, Belgium.
FAU - Gerli, Alberto Giovanni
AU  - Gerli AG
AD  - Department of Clinical Sciences and Community Health, Università Degli Studi di 
      Milano, 20122, Milan, Italy.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230225
PL  - England
TA  - Crit Care
JT  - Critical care (London, England)
JID - 9801902
SB  - IM
EIN - Crit Care. 2023 Mar 8;27(1):99. PMID: 36890525
CIN - Crit Care. 2023 Mar 21;27(1):120. PMID: 36945051
CIN - Med Teach. 2023 Sep;45(9):1063. PMID: 37036161
CIN - Crit Care. 2023 Apr 18;27(1):148. PMID: 37072798
CIN - Crit Care. 2023 May 10;27(1):180. PMID: 37165401
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Writing
PMC - PMC9960412
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Chatbots
OT  - Machine learning
OT  - Scientific writing
COIS- Not applicable.
EDAT- 2023/02/26 06:00
MHDA- 2023/03/03 06:00
PMCR- 2023/02/25
CRDT- 2023/02/25 23:47
PHST- 2023/01/31 00:00 [received]
PHST- 2023/02/21 00:00 [accepted]
PHST- 2023/02/25 23:47 [entrez]
PHST- 2023/02/26 06:00 [pubmed]
PHST- 2023/03/03 06:00 [medline]
PHST- 2023/02/25 00:00 [pmc-release]
AID - 10.1186/s13054-023-04380-2 [pii]
AID - 4380 [pii]
AID - 10.1186/s13054-023-04380-2 [doi]
PST - epublish
SO  - Crit Care. 2023 Feb 25;27(1):75. doi: 10.1186/s13054-023-04380-2.

PMID- 38228809
OWN - NLM
STAT- Publisher
LR  - 20240116
IS  - 1476-5608 (Electronic)
IS  - 1365-7852 (Linking)
DP  - 2024 Jan 16
TI  - Quality of information and appropriateness of Open AI outputs for prostate 
      cancer.
LID - 10.1038/s41391-024-00789-0 [doi]
AB  - Chat-GPT, a natural language processing (NLP) tool created by Open-AI, can 
      potentially be used as a quick source for obtaining information related to 
      prostate cancer. This study aims to analyze the quality and appropriateness of 
      Chat-GPT's responses to inquiries related to prostate cancer compared to those of 
      the European Urology Association's (EAU) 2023 prostate cancer guidelines. 
      Overall, 195 questions were prepared according to the recommendations gathered in 
      the prostate cancer section of the EAU 2023 Guideline. All questions were 
      systematically presented to Chat-GPT's August 3 Version, and two expert 
      urologists independently assessed and assigned scores ranging from 1 to 4 to each 
      response (1: completely correct, 2: correct but inadequate, 3: a mix of correct 
      and misleading information, and 4: completely incorrect). Sub-analysis per 
      chapter and per grade of recommendation were performed. Overall, 195 
      recommendations were evaluated. Overall, 50/195 (26%) were completely correct, 
      51/195 (26%) correct but inadequate, 47/195 (24%) a mix of correct and misleading 
      and 47/195 (24%) incorrect. When looking at different chapters Open AI was 
      particularly accurate in answering questions on follow-up and QoL. Worst 
      performance was recorded for the diagnosis and treatment chapters with 
      respectively 19% and 30% of the answers completely incorrect. When looking at the 
      strength of recommendation, no differences in terms of accuracy were recorded 
      when comparing weak and strong recommendations (p &gt; 0,05). Chat-GPT has a poor 
      accuracy when answering questions on the PCa EAU guidelines recommendations. 
      Future studies should assess its performance after adequate training.
CI  - © 2024. The Author(s), under exclusive licence to Springer Nature Limited.
FAU - Lombardo, Riccardo
AU  - Lombardo R
AUID- ORCID: 0000-0003-2890-3159
AD  - Department of Urology, 'Sapienza' University of Rome, Rome, Italy. 
      rlombardo@me.com.
FAU - Gallo, Giacomo
AU  - Gallo G
AD  - Department of Urology, 'Sapienza' University of Rome, Rome, Italy.
FAU - Stira, Jordi
AU  - Stira J
AD  - Department of Urology, 'Sapienza' University of Rome, Rome, Italy.
FAU - Turchi, Beatrice
AU  - Turchi B
AD  - Department of Urology, 'Sapienza' University of Rome, Rome, Italy.
FAU - Santoro, Giuseppe
AU  - Santoro G
AD  - Department of Urology, 'Sapienza' University of Rome, Rome, Italy.
FAU - Riolo, Sara
AU  - Riolo S
AD  - Department of Urology, 'Sapienza' University of Rome, Rome, Italy.
FAU - Romagnoli, Matteo
AU  - Romagnoli M
AD  - Department of Urology, 'Sapienza' University of Rome, Rome, Italy.
FAU - Cicione, Antonio
AU  - Cicione A
AD  - Department of Urology, 'Sapienza' University of Rome, Rome, Italy.
FAU - Tema, Giorgia
AU  - Tema G
AD  - Department of Urology, 'Sapienza' University of Rome, Rome, Italy.
FAU - Pastore, Antonio
AU  - Pastore A
AD  - Department of Urology, 'Sapienza' University of Rome, Rome, Italy.
FAU - Al Salhi, Yazan
AU  - Al Salhi Y
AD  - Department of Urology, 'Sapienza' University of Rome, Rome, Italy.
FAU - Fuschi, Andrea
AU  - Fuschi A
AD  - Department of Urology, 'Sapienza' University of Rome, Rome, Italy.
FAU - Franco, Giorgio
AU  - Franco G
AD  - Department of Urology, 'Sapienza' University of Rome, Rome, Italy.
FAU - Nacchia, Antonio
AU  - Nacchia A
AD  - Department of Urology, 'Sapienza' University of Rome, Rome, Italy.
FAU - Tubaro, Andrea
AU  - Tubaro A
AD  - Department of Urology, 'Sapienza' University of Rome, Rome, Italy.
FAU - De Nunzio, Cosimo
AU  - De Nunzio C
AUID- ORCID: 0000-0002-2190-512X
AD  - Department of Urology, 'Sapienza' University of Rome, Rome, Italy.
LA  - eng
PT  - Journal Article
DEP - 20240116
PL  - England
TA  - Prostate Cancer Prostatic Dis
JT  - Prostate cancer and prostatic diseases
JID - 9815755
SB  - IM
EDAT- 2024/01/17 00:42
MHDA- 2024/01/17 00:42
CRDT- 2024/01/16 23:24
PHST- 2023/12/13 00:00 [received]
PHST- 2024/01/05 00:00 [accepted]
PHST- 2023/12/22 00:00 [revised]
PHST- 2024/01/17 00:42 [medline]
PHST- 2024/01/17 00:42 [pubmed]
PHST- 2024/01/16 23:24 [entrez]
AID - 10.1038/s41391-024-00789-0 [pii]
AID - 10.1038/s41391-024-00789-0 [doi]
PST - aheadofprint
SO  - Prostate Cancer Prostatic Dis. 2024 Jan 16. doi: 10.1038/s41391-024-00789-0.

PMID- 38150678
OWN - NLM
STAT- MEDLINE
DCOM- 20231229
LR  - 20240106
IS  - 2066-8643 (Electronic)
IS  - 1844-4172 (Linking)
VI  - 25
IP  - 4
DP  - 2023 Dec 27
TI  - ChatGPT-assisted deep learning model for thyroid nodule analysis: beyond 
      artifical intelligence.
PG  - 375-383
LID - 10.11152/mu-4306 [doi]
AB  - AIMS: To develop a deep learning model, with the aid of ChatGPT, for thyroid 
      nodules, utilizing ultrasound images. The&nbsp;cytopathology of the fine needle 
      aspiration biopsy (FNAB) serves as the baseline. MATERIAL AND METHODS: After 
      securing IRB&nbsp;approval, a retrospective study was conducted, analyzing thyroid 
      ultrasound images and FNAB results from 1,061 patients between January 2017 and 
      January 2022. Detailed examinations of their demographic profiles, imaging 
      characteristics, and&nbsp;cytological features were conducted. The images were used 
      for training a deep learning model to identify various thyroid&nbsp;pathologies. 
      ChatGPT assisted in developing this model by aiding in code writing, 
      preprocessing, model optimization, and&nbsp;troubleshooting. RESULTS: The model 
      demonstrated an accuracy of 0.81 on the testing set, within a 95% confidence 
      interval of&nbsp;0.76 to 0.87. It presented remarkable results across thyroid 
      subgroups, particularly in the benign category, with high precision&nbsp;(0.78) and 
      recall (0.96), yielding a balanced F1-score of 0.86. The malignant category also 
      displayed high precision (0.82) and&nbsp;recall (0.92), with an F1-score of 0.87. 
      CONCLUSIONS: The study demonstrates the potential of artificial intelligence, 
      particularly&nbsp;ChatGPT, in aiding the creation of robust deep learning models for 
      medical image analysis.
FAU - Mese, Ismail
AU  - Mese I
AD  - Department of Radiology, Health Sciences University, Erenkoy Mental Health and 
      Neurology Training and Research Hospital. ismail_mese@yahoo.com.
FAU - Inan, Neslihan Gokmen
AU  - Inan NG
AD  - Department of Statistics, Mimar Sinan Fine Arts University, 3Department of 
      Radiology, Istanbul Medical Faculty, Istanbul University.
FAU - Kocadagli, Ozan
AU  - Kocadagli O
AD  - Department of Statistics, Mimar Sinan Fine Arts University, 3Department of 
      Radiology, Istanbul Medical Faculty, Istanbul University.
FAU - Salmaslioglu, Artur
AU  - Salmaslioglu A
AD  - Department of Radiology, Istanbul Medical Faculty, Istanbul University.
FAU - Yildirim, Duzgun
AU  - Yildirim D
AD  - Department of Radiology, Acibadem Mehmet Ali Aydinlar University, Istanbul.
LA  - eng
PT  - Journal Article
PL  - Romania
TA  - Med Ultrason
JT  - Medical ultrasonography
JID - 101522985
SB  - IM
MH  - Humans
MH  - *Thyroid Nodule/diagnostic imaging/pathology
MH  - Retrospective Studies
MH  - Artificial Intelligence
MH  - *Deep Learning
MH  - Sensitivity and Specificity
MH  - Ultrasonography/methods
MH  - Intelligence
MH  - *Thyroid Neoplasms/pathology
EDAT- 2023/12/27 18:41
MHDA- 2023/12/29 06:42
CRDT- 2023/12/27 16:33
PHST- 2023/12/29 06:42 [medline]
PHST- 2023/12/27 18:41 [pubmed]
PHST- 2023/12/27 16:33 [entrez]
AID - 10.11152/mu-4306 [doi]
PST - ppublish
SO  - Med Ultrason. 2023 Dec 27;25(4):375-383. doi: 10.11152/mu-4306.

PMID- 38329802
OWN - NLM
STAT- MEDLINE
DCOM- 20240213
LR  - 20240225
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 10
DP  - 2024 Feb 8
TI  - Comparison of the Performance of GPT-3.5 and GPT-4 With That of Medical Students 
      on the Written German Medical Licensing Examination: Observational Study.
PG  - e50965
LID - 10.2196/50965 [doi]
LID - e50965
AB  - BACKGROUND: The potential of artificial intelligence (AI)-based large language 
      models, such as ChatGPT, has gained significant attention in the medical field. 
      This enthusiasm is driven not only by recent breakthroughs and improved 
      accessibility, but also by the prospect of democratizing medical knowledge and 
      promoting equitable health care. However, the performance of ChatGPT is 
      substantially influenced by the input language, and given the growing public 
      trust in this AI tool compared to that in traditional sources of information, 
      investigating its medical accuracy across different languages is of particular 
      importance. OBJECTIVE: This study aimed to compare the performance of GPT-3.5 and 
      GPT-4 with that of medical students on the written German medical licensing 
      examination. METHODS: To assess GPT-3.5's and GPT-4's medical proficiency, we 
      used 937 original multiple-choice questions from 3 written German medical 
      licensing examinations in October 2021, April 2022, and October 2022. RESULTS: 
      GPT-4 achieved an average score of 85% and ranked in the 92.8th, 99.5th, and 
      92.6th percentiles among medical students who took the same examinations in 
      October 2021, April 2022, and October 2022, respectively. This represents a 
      substantial improvement of 27% compared to GPT-3.5, which only passed 1 out of 
      the 3 examinations. While GPT-3.5 performed well in psychiatry questions, GPT-4 
      exhibited strengths in internal medicine and surgery but showed weakness in 
      academic research. CONCLUSIONS: The study results highlight ChatGPT's remarkable 
      improvement from moderate (GPT-3.5) to high competency (GPT-4) in answering 
      medical licensing examination questions in German. While GPT-4's predecessor 
      (GPT-3.5) was imprecise and inconsistent, it demonstrates considerable potential 
      to improve medical education and patient care, provided that medically trained 
      users critically evaluate its results. As the replacement of search engines by AI 
      tools seems possible in the future, further studies with nonprofessional 
      questions are needed to assess the safety and accuracy of ChatGPT for the general 
      population.
CI  - ©Annika Meyer, Janik Riese, Thomas Streichert. Originally published in JMIR 
      Medical Education (https://mededu.jmir.org), 08.02.2024.
FAU - Meyer, Annika
AU  - Meyer A
AUID- ORCID: 0000-0002-8411-8799
AD  - Institute for Clinical Chemistry, University Hospital Cologne, Cologne, Germany.
FAU - Riese, Janik
AU  - Riese J
AUID- ORCID: 0000-0003-0701-060X
AD  - Department of General Surgery, Visceral, Thoracic and Vascular Surgery, 
      University Hospital Greifswald, Greifswald, Germany.
FAU - Streichert, Thomas
AU  - Streichert T
AUID- ORCID: 0000-0002-6588-720X
AD  - Institute for Clinical Chemistry, University Hospital Cologne, Cologne, Germany.
LA  - eng
PT  - Journal Article
PT  - Observational Study
DEP - 20240208
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Education, Medical
MH  - Language
MH  - *Students, Medical
MH  - *Educational Measurement
PMC - PMC10884900
OTO - NOTNLM
OT  - ChatGPT
OT  - LLM
OT  - artificial intelligence
OT  - general population
OT  - improvement
OT  - large language model
OT  - licensing exam
OT  - licensing examination
OT  - licensure examination
OT  - medical accuracy
OT  - medical education
OT  - medical examinations
OT  - medical exams
OT  - patient care
OT  - public trust
OT  - trust
COIS- Conflicts of Interest: None declared.
EDAT- 2024/02/08 12:42
MHDA- 2024/02/09 06:43
PMCR- 2024/02/08
CRDT- 2024/02/08 11:54
PHST- 2023/07/18 00:00 [received]
PHST- 2023/12/11 00:00 [accepted]
PHST- 2023/11/14 00:00 [revised]
PHST- 2024/02/09 06:43 [medline]
PHST- 2024/02/08 12:42 [pubmed]
PHST- 2024/02/08 11:54 [entrez]
PHST- 2024/02/08 00:00 [pmc-release]
AID - v10i1e50965 [pii]
AID - 10.2196/50965 [doi]
PST - epublish
SO  - JMIR Med Educ. 2024 Feb 8;10:e50965. doi: 10.2196/50965.

PMID- 38549897
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240330
IS  - 0971-3026 (Print)
IS  - 1998-3808 (Electronic)
IS  - 0970-2016 (Linking)
VI  - 34
IP  - 2
DP  - 2024 Apr
TI  - Assessing the Capability of ChatGPT, Google Bard, and Microsoft Bing in Solving 
      Radiology Case Vignettes.
PG  - 276-282
LID - 10.1055/s-0043-1777746 [doi]
AB  - Background  The field of radiology relies on accurate interpretation of medical 
      images for effective diagnosis and patient care. Recent advancements in 
      artificial intelligence (AI) and natural language processing have sparked 
      interest in exploring the potential of AI models in assisting radiologists. 
      However, limited research has been conducted to assess the performance of AI 
      models in radiology case interpretation, particularly in comparison to human 
      experts. Objective  This study aimed to evaluate the performance of ChatGPT, 
      Google Bard, and Bing in solving radiology case vignettes (Fellowship of the 
      Royal College of Radiologists 2A [FRCR2A] examination style questions) by 
      comparing their responses to those provided by two radiology residents. Methods 
       A total of 120 multiple-choice questions based on radiology case vignettes were 
      formulated according to the pattern of FRCR2A examination. The questions were 
      presented to ChatGPT, Google Bard, and Bing. Two residents wrote the examination 
      with the same questions in 3 hours. The responses generated by the AI models were 
      collected and compared to the answer keys and explanation of the answers was 
      rated by the two radiologists. A cutoff of 60% was set as the passing score. 
      Results  The two residents (63.33 and 57.5%) outperformed the three AI models: 
      Bard (44.17%), Bing (53.33%), and ChatGPT (45%), but only one resident passed the 
      examination. The response patterns among the five respondents were significantly 
      different ( p  = 0.0117). In addition, the agreement among the generative AI 
      models was significant (intraclass correlation coefficient [ICC] = 0.628), but 
      there was no agreement between the residents (Kappa = -0.376). The explanation of 
      generative AI models in support of answer was 44.72% accurate. Conclusion  Humans 
      exhibited superior accuracy compared to the AI models, showcasing a stronger 
      comprehension of the subject matter. All three AI models included in the study 
      could not achieve the minimum percentage needed to pass an FRCR2A examination. 
      However, generative AI models showed significant agreement in their answers where 
      the residents exhibited low agreement, highlighting a lack of consistency in 
      their responses.
CI  - Indian Radiological Association. This is an open access article published by 
      Thieme under the terms of the Creative Commons 
      Attribution-NonDerivative-NonCommercial License, permitting copying and 
      reproduction so long as the original work is given appropriate credit. Contents 
      may not be used for commercial purposes, or adapted, remixed, transformed or 
      built upon. ( https://creativecommons.org/licenses/by-nc-nd/4.0/ ).
FAU - Sarangi, Pradosh Kumar
AU  - Sarangi PK
AUID- ORCID: 0000-0002-9434-946X
AD  - Department of Radiodiagnosis, All India Institute of Medical Sciences, Deoghar, 
      Jharkhand, India.
FAU - Narayan, Ravi Kant
AU  - Narayan RK
AUID- ORCID: 0000-0003-2510-6744
AD  - Department of Anatomy, ESIC Medical College &amp; Hospital, Bihta, Patna, Bihar, 
      India.
FAU - Mohakud, Sudipta
AU  - Mohakud S
AUID- ORCID: 0000-0003-4694-3322
AD  - Department of Radiodiagnosis, All India Institute of Medical Sciences, 
      Bhubaneswar, Odisha, India.
FAU - Vats, Aditi
AU  - Vats A
AUID- ORCID: 0009-0006-6873-9508
AD  - Department of Radiodiagnosis, All India Institute of Medical Sciences, 
      Bhubaneswar, Odisha, India.
FAU - Sahani, Debabrata
AU  - Sahani D
AUID- ORCID: 0009-0000-3227-221X
AD  - Department of Radiodiagnosis, All India Institute of Medical Sciences, 
      Bhubaneswar, Odisha, India.
FAU - Mondal, Himel
AU  - Mondal H
AUID- ORCID: 0000-0001-6950-5857
AD  - Department of Physiology, All India Institute of Medical Sciences, Deoghar, 
      Jharkhand, India.
LA  - eng
PT  - Journal Article
DEP - 20231229
PL  - Germany
TA  - Indian J Radiol Imaging
JT  - The Indian journal of radiology &amp; imaging
JID - 8503873
PMC - PMC10972658
OTO - NOTNLM
OT  - Bard
OT  - Bing
OT  - ChatGPT
OT  - FRCR2A
OT  - artificial intelligence
OT  - fellowship
OT  - natural language processing
OT  - radiology
COIS- Conflict of Interest None declared.
EDAT- 2024/03/29 06:46
MHDA- 2024/03/29 06:47
PMCR- 2023/12/01
CRDT- 2024/03/29 04:00
PHST- 2024/03/29 06:47 [medline]
PHST- 2024/03/29 06:46 [pubmed]
PHST- 2024/03/29 04:00 [entrez]
PHST- 2023/12/01 00:00 [pmc-release]
AID - IJRI-23-9-2963 [pii]
AID - 10.1055/s-0043-1777746 [doi]
PST - epublish
SO  - Indian J Radiol Imaging. 2023 Dec 29;34(2):276-282. doi: 10.1055/s-0043-1777746. 
      eCollection 2024 Apr.

PMID- 37943581
OWN - NLM
STAT- MEDLINE
DCOM- 20231110
LR  - 20231129
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 25
DP  - 2023 Nov 9
TI  - An AI Dietitian for Type 2 Diabetes Mellitus Management Based on Large Language 
      and Image Recognition Models: Preclinical Concept Validation Study.
PG  - e51300
LID - 10.2196/51300 [doi]
LID - e51300
AB  - BACKGROUND: Nutritional management for patients with diabetes in China is a 
      significant challenge due to the low supply of registered clinical dietitians. To 
      address this, an artificial intelligence (AI)-based nutritionist program that 
      uses advanced language and image recognition models was created. This program can 
      identify ingredients from images of a patient's meal and offer nutritional 
      guidance and dietary recommendations. OBJECTIVE: The primary objective of this 
      study is to evaluate the competence of the models that support this program. 
      METHODS: The potential of an AI nutritionist program for patients with type 2 
      diabetes mellitus (T2DM) was evaluated through a multistep process. First, a 
      survey was conducted among patients with T2DM and endocrinologists to identify 
      knowledge gaps in dietary practices. ChatGPT and GPT 4.0 were then tested through 
      the Chinese Registered Dietitian Examination to assess their proficiency in 
      providing evidence-based dietary advice. ChatGPT's responses to common questions 
      about medical nutrition therapy were compared with expert responses by 
      professional dietitians to evaluate its proficiency. The model's food 
      recommendations were scrutinized for consistency with expert advice. A deep 
      learning-based image recognition model was developed for food identification at 
      the ingredient level, and its performance was compared with existing models. 
      Finally, a user-friendly app was developed, integrating the capabilities of 
      language and image recognition models to potentially improve care for patients 
      with T2DM. RESULTS: Most patients (182/206, 88.4%) demanded more immediate and 
      comprehensive nutritional management and education. Both ChatGPT and GPT 4.0 
      passed the Chinese Registered Dietitian examination. ChatGPT's food 
      recommendations were mainly in line with best practices, except for certain foods 
      like root vegetables and dry beans. Professional dietitians' reviews of ChatGPT's 
      responses to common questions were largely positive, with 162 out of 168 
      providing favorable reviews. The multilabel image recognition model evaluation 
      showed that the Dino V2 model achieved an average F(1) score of 0.825, indicating 
      high accuracy in recognizing ingredients. CONCLUSIONS: The model evaluations were 
      promising. The AI-based nutritionist program is now ready for a supervised pilot 
      study.
CI  - ©Haonan Sun, Kai Zhang, Wei Lan, Qiufeng Gu, Guangxiang Jiang, Xue Yang, Wanli 
      Qin, Dongran Han. Originally published in the Journal of Medical Internet 
      Research (https://www.jmir.org), 09.11.2023.
FAU - Sun, Haonan
AU  - Sun H
AUID- ORCID: 0000-0003-2352-4758
AD  - School of Life Science, Beijing University of Chinese Medicine, Beijing, China.
FAU - Zhang, Kai
AU  - Zhang K
AUID- ORCID: 0009-0007-8118-3564
AD  - School of Life Science, Beijing University of Chinese Medicine, Beijing, China.
FAU - Lan, Wei
AU  - Lan W
AUID- ORCID: 0009-0006-7937-4743
AD  - Department of Pediatrics, Peking University Shenzhen Hospital, Shenzhen, China.
FAU - Gu, Qiufeng
AU  - Gu Q
AUID- ORCID: 0009-0009-3161-7197
AD  - Department of Pediatrics, Peking University Shenzhen Hospital, Shenzhen, China.
FAU - Jiang, Guangxiang
AU  - Jiang G
AUID- ORCID: 0009-0000-1224-3526
AD  - School of Life Science, Beijing University of Chinese Medicine, Beijing, China.
FAU - Yang, Xue
AU  - Yang X
AUID- ORCID: 0009-0007-7986-5478
AD  - School of Life Science, Beijing University of Chinese Medicine, Beijing, China.
FAU - Qin, Wanli
AU  - Qin W
AUID- ORCID: 0009-0008-5591-1860
AD  - School of Life Science, Beijing University of Chinese Medicine, Beijing, China.
FAU - Han, Dongran
AU  - Han D
AUID- ORCID: 0000-0003-3630-5036
AD  - School of Life Science, Beijing University of Chinese Medicine, Beijing, China.
LA  - eng
PT  - Journal Article
DEP - 20231109
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - *Nutritionists
MH  - *Diabetes Mellitus, Type 2/therapy
MH  - Artificial Intelligence
MH  - Pilot Projects
MH  - Language
MH  - Meals
PMC - PMC10667983
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - GPT 4.0
OT  - NLP
OT  - artificial intelligence
OT  - deep learning
OT  - diabetes
OT  - diabetic
OT  - diet
OT  - dietary
OT  - dietician
OT  - digital health
OT  - food
OT  - image recognition
OT  - ingredient recognition
OT  - language model
OT  - machine learning
OT  - meal
OT  - meals
OT  - medical nutrition therapy
OT  - natural language processing
OT  - nutrition
OT  - nutritional
OT  - recommendation
COIS- Conflicts of Interest: None declared.
EDAT- 2023/11/09 12:42
MHDA- 2023/11/10 06:45
PMCR- 2023/11/09
CRDT- 2023/11/09 11:53
PHST- 2023/07/27 00:00 [received]
PHST- 2023/10/06 00:00 [accepted]
PHST- 2023/09/18 00:00 [revised]
PHST- 2023/11/10 06:45 [medline]
PHST- 2023/11/09 12:42 [pubmed]
PHST- 2023/11/09 11:53 [entrez]
PHST- 2023/11/09 00:00 [pmc-release]
AID - v25i1e51300 [pii]
AID - 10.2196/51300 [doi]
PST - epublish
SO  - J Med Internet Res. 2023 Nov 9;25:e51300. doi: 10.2196/51300.

PMID- 37957964
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231119
IS  - 2227-9032 (Print)
IS  - 2227-9032 (Electronic)
IS  - 2227-9032 (Linking)
VI  - 11
IP  - 21
DP  - 2023 Oct 25
TI  - Comment on Sallam, M. ChatGPT Utility in Healthcare Education, Research, and 
      Practice: Systematic Review on the Promising Perspectives and Valid Concerns. 
      Healthcare 2023, 11, 887.
LID - 10.3390/healthcare11212819 [doi]
LID - 2819
AB  - We read with great interest and applaud the recently published review paper 
      regarding ChatGPT and its implications in research and education [...].
FAU - Moreno, Emilio
AU  - Moreno E
AD  - Human Anatomy Department, School of Medicine, Universidad Autonoma de Nuevo Leon, 
      Monterrey 64460, Mexico.
FAU - Alvarez-Lozada, Luis Adrian
AU  - Alvarez-Lozada LA
AD  - Human Anatomy Department, School of Medicine, Universidad Autonoma de Nuevo Leon, 
      Monterrey 64460, Mexico.
FAU - Arrambide-Garza, Francisco Javier
AU  - Arrambide-Garza FJ
AD  - Human Anatomy Department, School of Medicine, Universidad Autonoma de Nuevo Leon, 
      Monterrey 64460, Mexico.
FAU - Quiroga-Garza, Alejandro
AU  - Quiroga-Garza A
AUID- ORCID: 0000-0002-5398-247X
AD  - Human Anatomy Department, School of Medicine, Universidad Autonoma de Nuevo Leon, 
      Monterrey 64460, Mexico.
FAU - Elizondo-Omaña, Rodrigo Enrique
AU  - Elizondo-Omaña RE
AD  - Human Anatomy Department, School of Medicine, Universidad Autonoma de Nuevo Leon, 
      Monterrey 64460, Mexico.
LA  - eng
PT  - Journal Article
DEP - 20231025
PL  - Switzerland
TA  - Healthcare (Basel)
JT  - Healthcare (Basel, Switzerland)
JID - 101666525
CON - Healthcare (Basel). 11:887.
PMC - PMC10650921
COIS- The authors declare no conflict of interest.
EDAT- 2023/11/14 06:43
MHDA- 2023/11/14 06:44
PMCR- 2023/10/25
CRDT- 2023/11/14 02:05
PHST- 2023/07/20 00:00 [received]
PHST- 2023/10/13 00:00 [revised]
PHST- 2023/10/18 00:00 [accepted]
PHST- 2023/11/14 06:44 [medline]
PHST- 2023/11/14 06:43 [pubmed]
PHST- 2023/11/14 02:05 [entrez]
PHST- 2023/10/25 00:00 [pmc-release]
AID - healthcare11212819 [pii]
AID - healthcare-11-02819 [pii]
AID - 10.3390/healthcare11212819 [doi]
PST - epublish
SO  - Healthcare (Basel). 2023 Oct 25;11(21):2819. doi: 10.3390/healthcare11212819.

PMID- 38294325
OWN - NLM
STAT- MEDLINE
DCOM- 20240201
LR  - 20240206
IS  - 2638-6100 (Electronic)
IS  - 2638-6100 (Linking)
VI  - 6
IP  - 1
DP  - 2024 Jan
TI  - Performance of ChatGPT on the Brazilian Radiology and Diagnostic Imaging and 
      Mammography Board Examinations.
PG  - e230103
LID - 10.1148/ryai.230103 [doi]
LID - e230103
AB  - This prospective exploratory study conducted from January 2023 through May 2023 
      evaluated the ability of ChatGPT to answer questions from Brazilian radiology 
      board examinations, exploring how different prompt strategies can influence 
      performance using GPT-3.5 and GPT-4. Three multiple-choice board examinations 
      that did not include image-based questions were evaluated: (a) radiology and 
      diagnostic imaging, (b) mammography, and (c) neuroradiology. Five different 
      styles of zero-shot prompting were tested: (a) raw question, (b) brief 
      instruction, (c) long instruction, (d) chain-of-thought, and (e) 
      question-specific automatic prompt generation (QAPG). The QAPG and brief 
      instruction prompt strategies performed best for all examinations (P &lt; .05), 
      obtaining passing scores (≥60%) on the radiology and diagnostic imaging 
      examination when testing both versions of ChatGPT. The QAPG style achieved a 
      score of 60% for the mammography examination using GPT-3.5 and 76% using GPT-4. 
      GPT-4 achieved a score up to 65% in the neuroradiology examination. The long 
      instruction style consistently underperformed, implying that excessive detail 
      might harm performance. GPT-4's scores were less sensitive to prompt style 
      changes. The QAPG prompt style showed a high volume of the "A" option but no 
      statistical difference, suggesting bias was found. GPT-4 passed all three 
      radiology board examinations, and GPT-3.5 passed two of three examinations when 
      using an optimal prompt style. Keywords: ChatGPT, Artificial Intelligence, Board 
      Examinations, Radiology and Diagnostic Imaging, Mammography, Neuroradiology © 
      RSNA, 2023 See also the commentary by Trivedi and Gichoya in this issue.
FAU - Almeida, Leonardo C
AU  - Almeida LC
AUID- ORCID: 0009-0002-2634-9027
AD  - From the Department of Artificial Intelligence and Management (L.C.A., 
      E.M.J.M.F., N.A., F.C.K.), Graduate Program in Medicine (Clinical Radiology), 
      Universidade Federal de São Paulo (UNIFESP), Rua Botucatu, 740, 04023-062, São 
      Paulo, São Paulo, Brazil; AI Lab (L.C.A., E.M.J.M.F., P.E.A.K., F.C.K.), Dasa, 
      São Paulo, São Paulo, Brazil.
FAU - Farina, Eduardo M J M
AU  - Farina EMJM
AUID- ORCID: 0000-0002-3935-6077
AD  - From the Department of Artificial Intelligence and Management (L.C.A., 
      E.M.J.M.F., N.A., F.C.K.), Graduate Program in Medicine (Clinical Radiology), 
      Universidade Federal de São Paulo (UNIFESP), Rua Botucatu, 740, 04023-062, São 
      Paulo, São Paulo, Brazil; AI Lab (L.C.A., E.M.J.M.F., P.E.A.K., F.C.K.), Dasa, 
      São Paulo, São Paulo, Brazil.
FAU - Kuriki, Paulo E A
AU  - Kuriki PEA
AUID- ORCID: 0000-0002-1485-5750
AD  - From the Department of Artificial Intelligence and Management (L.C.A., 
      E.M.J.M.F., N.A., F.C.K.), Graduate Program in Medicine (Clinical Radiology), 
      Universidade Federal de São Paulo (UNIFESP), Rua Botucatu, 740, 04023-062, São 
      Paulo, São Paulo, Brazil; AI Lab (L.C.A., E.M.J.M.F., P.E.A.K., F.C.K.), Dasa, 
      São Paulo, São Paulo, Brazil.
FAU - Abdala, Nitamar
AU  - Abdala N
AUID- ORCID: 0000-0002-0421-0959
AD  - From the Department of Artificial Intelligence and Management (L.C.A., 
      E.M.J.M.F., N.A., F.C.K.), Graduate Program in Medicine (Clinical Radiology), 
      Universidade Federal de São Paulo (UNIFESP), Rua Botucatu, 740, 04023-062, São 
      Paulo, São Paulo, Brazil; AI Lab (L.C.A., E.M.J.M.F., P.E.A.K., F.C.K.), Dasa, 
      São Paulo, São Paulo, Brazil.
FAU - Kitamura, Felipe C
AU  - Kitamura FC
AUID- ORCID: 0000-0002-9992-5630
AD  - From the Department of Artificial Intelligence and Management (L.C.A., 
      E.M.J.M.F., N.A., F.C.K.), Graduate Program in Medicine (Clinical Radiology), 
      Universidade Federal de São Paulo (UNIFESP), Rua Botucatu, 740, 04023-062, São 
      Paulo, São Paulo, Brazil; AI Lab (L.C.A., E.M.J.M.F., P.E.A.K., F.C.K.), Dasa, 
      São Paulo, São Paulo, Brazil.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Radiol Artif Intell
JT  - Radiology. Artificial intelligence
JID - 101746556
SB  - IM
MH  - *Artificial Intelligence
MH  - Brazil
MH  - Prospective Studies
MH  - Radiography
MH  - Mammography
MH  - *Radiology
PMC - PMC10831524
OTO - NOTNLM
OT  - Artificial Intelligence
OT  - Board Examinations
OT  - ChatGPT
OT  - Mammography
OT  - Neuroradiology
OT  - Radiology and Diagnostic Imaging
COIS- Disclosures of conflicts of interest: C.C.A. No relevant relationships. 
      E.M.J.M.F. Consultant fees from Ionic Health; payment from Sharing Progress in 
      Cancer for two lectures; Radiology: Artificial Intelligence trainee editorial 
      board member. P.E.A.K. No relevant relationships. F.C.K. Consultant fees from 
      MD.ai and GE HealthCare; payment from Sharing Progress in Cancer for a lecture; 
      volunteers as the co-chair of the Machine Learning Education subcommittee for the 
      Society of Imaging Informatics in Medicine and as an early career consultant to 
      the editor for Radiology; became Radiology: Artificial Intelligence associate 
      editor after this manuscript was submitted and accepted.
EDAT- 2024/01/31 12:43
MHDA- 2024/02/01 06:42
PMCR- 2023/11/08
CRDT- 2024/01/31 09:53
PHST- 2024/02/01 06:42 [medline]
PHST- 2024/01/31 12:43 [pubmed]
PHST- 2024/01/31 09:53 [entrez]
PHST- 2023/11/08 00:00 [pmc-release]
AID - 10.1148/ryai.230103 [doi]
PST - ppublish
SO  - Radiol Artif Intell. 2024 Jan;6(1):e230103. doi: 10.1148/ryai.230103.

PMID- 38244054
OWN - NLM
STAT- Publisher
LR  - 20240120
IS  - 1543-2165 (Electronic)
IS  - 0003-9985 (Linking)
DP  - 2024 Jan 20
TI  - Assessment of Pathology Domain-Specific Knowledge of ChatGPT and Comparison to 
      Human Performance.
LID - 10.5858/arpa.2023-0296-OA [doi]
AB  - CONTEXT.—: Artificial intelligence algorithms hold the potential to fundamentally 
      change many aspects of society. Application of these tools, including the 
      publicly available ChatGPT, has demonstrated impressive domain-specific knowledge 
      in many areas, including medicine. OBJECTIVES.—: To understand the level of 
      pathology domain-specific knowledge for ChatGPT using different underlying large 
      language models, GPT-3.5 and the updated GPT-4. DESIGN.—: An international group 
      of pathologists (n = 15) was recruited to generate pathology-specific questions 
      at a similar level to those that could be seen on licensing (board) examinations. 
      The questions (n = 15) were answered by GPT-3.5, GPT-4, and a staff pathologist 
      that recently passed their Canadian pathology licensing exams. Participants were 
      instructed to score answers on a 5-point scale and to predict which answer was 
      written by ChatGPT. RESULTS.—: GPT-3.5 performed at a similar level to the staff 
      pathologist, while GPT-4 outperformed both. The overall score for both GPT-3.5 
      and GPT-4 was within the range of meeting expectations for a trainee writing 
      licensing examinations. In all but one question, the reviewers were able to 
      correctly identify the answers generated by GPT-3.5. CONCLUSIONS.—: By 
      demonstrating the ability of ChatGPT to answer pathology-specific questions at a 
      level similar to (GPT-3.5) or exceeding (GPT-4) a trained pathologist, this study 
      highlights the potential of large language models to be transformative in this 
      space. In the future, more advanced iterations of these algorithms with increased 
      domain-specific knowledge may have the potential to assist pathologists and 
      enhance pathology resident training.
CI  - © 2024 College of American Pathologists.
FAU - Wang, Andrew Y
AU  - Wang AY
AD  - From the Schulich School of Medicine and Dentistry, Western University, London, 
      Ontario, Canada (Wang, Wilsdon).
FAU - Lin, Sherman
AU  - Lin S
AD  - Department of Pathology and Laboratory Medicine, Western University and London 
      Health Sciences Centre, London, Ontario, Canada (Lin, Tran, Walsh, Goebel, 
      Cecchini).
FAU - Tran, Christopher
AU  - Tran C
AD  - Department of Pathology and Laboratory Medicine, Western University and London 
      Health Sciences Centre, London, Ontario, Canada (Lin, Tran, Walsh, Goebel, 
      Cecchini).
FAU - Homer, Robert J
AU  - Homer RJ
AD  - Department of Pathology, Yale School of Medicine, New Haven, Connecticut (Homer).
FAU - Wilsdon, Dan
AU  - Wilsdon D
AD  - From the Schulich School of Medicine and Dentistry, Western University, London, 
      Ontario, Canada (Wang, Wilsdon).
FAU - Walsh, Joanna C
AU  - Walsh JC
AD  - Department of Pathology and Laboratory Medicine, Western University and London 
      Health Sciences Centre, London, Ontario, Canada (Lin, Tran, Walsh, Goebel, 
      Cecchini).
FAU - Goebel, Emily A
AU  - Goebel EA
AD  - Department of Pathology and Laboratory Medicine, Western University and London 
      Health Sciences Centre, London, Ontario, Canada (Lin, Tran, Walsh, Goebel, 
      Cecchini).
FAU - Sansano, Irene
AU  - Sansano I
AD  - Department of Pathology, Hospital Universitari Vall d'Hebron, Barcelona, Spain 
      (Sansano).
FAU - Sonawane, Snehal
AU  - Sonawane S
AD  - Department of Pathology, University of Illinois at Chicago, Chicago (Sonawane).
FAU - Cockenpot, Vincent
AU  - Cockenpot V
AD  - Department of Pathology-Genetics and Immunology, Institut Curie, PSL Research 
      University, Paris, France (Cockenpot).
FAU - Mukhopadhyay, Sanjay
AU  - Mukhopadhyay S
AD  - Department of Anatomic Pathology, Cleveland Clinic, Cleveland, Ohio 
      (Mukhopadhyay).
FAU - Taskin, Toros
AU  - Taskin T
AD  - Department of Pathology, Agri Training and Research Hospital, Agri Ibrahim Cecen 
      University, Agri, Turkey (Taskin).
FAU - Zahra, Nusrat
AU  - Zahra N
AD  - Department of Pathology, Specialized Healthcare and Medical Education, Punjab, 
      Pakistan (Zahra).
FAU - Cima, Luca
AU  - Cima L
AD  - Pathology Unit, Department of Laboratory Medicine, Santa Chiara University 
      Hospital, APSS, Trento, Italy (Cima).
FAU - Semerci, Orhan
AU  - Semerci O
AD  - Department of Pathology, Trabzon Kanuni Training and Research Hospital, 
      University of Health Sciences, Trabzon, Turkey (Semerci).
FAU - Özamrak, Birsen Gizem
AU  - Özamrak BG
AD  - Department of Pathology, Izmir Provincial Directorate of Health, Health Sciences 
      University Izmir Tepecik Education and Research Hospital, Izmir, Turkey 
      (Özamrak).
FAU - Mishra, Pallavi
AU  - Mishra P
AD  - Department of Pathology, Queen Elizabeth Hospital, Lewisham and Greenwich NHS 
      Trust, London, United Kingdom (Mishra).
FAU - Vennavalli, Naga Sarika
AU  - Vennavalli NS
AD  - Department of Pathology, Yashoda Hospitals, Hyderabad, Telangana, India 
      (Vennavalli).
FAU - Chen, Po-Hsuan Cameron
AU  - Chen PC
AD  - Need Inc, Santa Monica, California (Chen).
FAU - Cecchini, Matthew J
AU  - Cecchini MJ
AD  - Department of Pathology and Laboratory Medicine, Western University and London 
      Health Sciences Centre, London, Ontario, Canada (Lin, Tran, Walsh, Goebel, 
      Cecchini).
LA  - eng
PT  - Journal Article
DEP - 20240120
PL  - United States
TA  - Arch Pathol Lab Med
JT  - Archives of pathology &amp; laboratory medicine
JID - 7607091
SB  - IM
EDAT- 2024/01/20 21:42
MHDA- 2024/01/20 21:42
CRDT- 2024/01/20 11:14
PHST- 2023/10/30 00:00 [accepted]
PHST- 2024/01/20 21:42 [medline]
PHST- 2024/01/20 21:42 [pubmed]
PHST- 2024/01/20 11:14 [entrez]
AID - 498573 [pii]
AID - 10.5858/arpa.2023-0296-OA [doi]
PST - aheadofprint
SO  - Arch Pathol Lab Med. 2024 Jan 20. doi: 10.5858/arpa.2023-0296-OA.

PMID- 37428336
OWN - NLM
STAT- MEDLINE
DCOM- 20240214
LR  - 20240214
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 52
IP  - 3
DP  - 2024 Mar
TI  - ChatGPT and Vaccines: Can AI Chatbots Boost Awareness and Uptake?
PG  - 446-450
LID - 10.1007/s10439-023-03305-y [doi]
AB  - The global COVID-19 pandemic has affected all spheres of human life, resulting in 
      millions of deaths and overwhelming medical facilities. Moreover, the world has 
      witnessed great financial hardship because of job losses resulting in economic 
      havoc. Many sections of society have contributed in different ways to slow the 
      spread of the virus and protect public health. For example, medical scientists 
      are praised for their efforts to develop COVID-19 vaccines. Clinical trials have 
      shown that the COVID-19 vaccines are highly effective in preventing symptomatic 
      COVID-19 infections. However, many people around the world have been hesitant to 
      get vaccinated. Vaccine misconceptions have emerged and increased due to a 
      combination of factors, including the availability of information on the Internet 
      and the influence of celebrities and opinion leaders. In this context, we have 
      analyzed ChatGPT responses to relevant queries on vaccine misconceptions. The 
      positive responses and supportive opinions provided by the AI chatbot could be 
      instrumental in shaping people's perceptions of vaccines and in encouraging users 
      to get vaccinated and reduce misconceptions.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Sohail, Shahab Saquib
AU  - Sohail SS
AD  - Department of Computer Science and Engineering, School of Engineering Sciences 
      and Technology, Jamia Hamdard, New Delhi, 110062, India.
FAU - Madsen, Dag Øivind
AU  - Madsen DØ
AUID- ORCID: 0000-0001-8735-3332
AD  - USN School of Business, University of South-Eastern Norway, 3511, Hønefoss, 
      Norway. dag.oivind.madsen@usn.no.
FAU - Farhat, Faiza
AU  - Farhat F
AD  - Department of Zoology, Aligarh Muslim University, Aligarh, U.P., 202002, India.
FAU - Alam, M Afshar
AU  - Alam MA
AD  - Department of Computer Science and Engineering, School of Engineering Sciences 
      and Technology, Jamia Hamdard, New Delhi, 110062, India.
LA  - eng
PT  - Letter
DEP - 20230710
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
RN  - 0 (COVID-19 Vaccines)
RN  - 0 (Vaccines)
SB  - IM
MH  - Humans
MH  - COVID-19 Vaccines
MH  - Pandemics/prevention &amp; control
MH  - *Vaccines
MH  - Biological Transport
MH  - *COVID-19/prevention &amp; control
OTO - NOTNLM
OT  - Artificial intelligence
OT  - COVID-19
OT  - ChatGPT
OT  - Vaccine
OT  - Vaccine hesitancy
EDAT- 2023/07/10 13:05
MHDA- 2024/02/12 15:42
CRDT- 2023/07/10 11:12
PHST- 2023/06/25 00:00 [received]
PHST- 2023/07/03 00:00 [accepted]
PHST- 2024/02/12 15:42 [medline]
PHST- 2023/07/10 13:05 [pubmed]
PHST- 2023/07/10 11:12 [entrez]
AID - 10.1007/s10439-023-03305-y [pii]
AID - 10.1007/s10439-023-03305-y [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2024 Mar;52(3):446-450. doi: 10.1007/s10439-023-03305-y. Epub 
      2023 Jul 10.

PMID- 38261307
OWN - NLM
STAT- Publisher
LR  - 20240123
IS  - 1827-1855 (Electronic)
IS  - 0390-5616 (Linking)
DP  - 2024 Jan 23
TI  - Large language model, AI and scientific research: why ChatGPT is only the 
      beginning.
LID - 10.23736/S0390-5616.23.06171-4 [doi]
AB  - ChatGPT, a conversational artificial intelligence model based on the generative 
      pre-trained transformer GPT architecture, has garnered widespread attention due 
      to its user-friendly nature and diverse capabilities. This technology enables 
      users of all backgrounds to effortlessly engage in human-like conversations and 
      receive coherent and intelligible responses. Beyond casual interactions, ChatGPT 
      offers compelling prospects for scientific research, facilitating tasks like 
      literature review and content summarization, ultimately expediting and enhancing 
      the academic writing process. Still, in the field of medicine and surgery, it has 
      already shown its endless potential in many tasks (enhancing decision-making 
      processes, aiding in surgical planning and simulation, providing real-time 
      assistance during surgery, improving postoperative care and rehabilitation, 
      contributing to training, education, research, and development). However, it is 
      crucial to acknowledge the model's limitations, encompassing knowledge 
      constraints and the potential for erroneous responses, as well as ethical and 
      legal considerations. This paper explores the potential benefits and pitfalls of 
      these innovative technologies in scientific research, shedding light on their 
      transformative impact while addressing concerns surrounding their use.
FAU - Zangrossi, Pietro
AU  - Zangrossi P
AD  - Department of Neurosurgery, Sant'Anna University Hospital, Ferrara, Italy - 
      pietro.zangrossi@edu.unife.it.
AD  - Department of Translational Medicine, University of Ferrara, Ferrara, Italy - 
      pietro.zangrossi@edu.unife.it.
FAU - Martini, Massimo
AU  - Martini M
AD  - R&amp;amp;D Department, Gate-away.com, Grottammare, Ascoli Piceno, Italy.
FAU - Guerrini, Francesco
AU  - Guerrini F
AD  - Department of Neurosurgery, San Matteo Polyclinic IRCCS Foundation, Pavia, Italy.
FAU - DE Bonis, Pasquale
AU  - DE Bonis P
AD  - Department of Neurosurgery, Sant'Anna University Hospital, Ferrara, Italy.
AD  - Department of Translational Medicine, University of Ferrara, Ferrara, Italy.
AD  - Unit of Minimally Invasive Neurosurgery, Ferrara University Hospital, Ferrara, 
      Italy.
FAU - Spena, Giannantonio
AU  - Spena G
AD  - Department of Neurosurgery, San Matteo Polyclinic IRCCS Foundation, Pavia, Italy.
LA  - eng
PT  - Journal Article
DEP - 20240123
PL  - Italy
TA  - J Neurosurg Sci
JT  - Journal of neurosurgical sciences
JID - 0432557
SB  - IM
EDAT- 2024/01/23 12:43
MHDA- 2024/01/23 12:43
CRDT- 2024/01/23 11:24
PHST- 2024/01/23 12:43 [medline]
PHST- 2024/01/23 12:43 [pubmed]
PHST- 2024/01/23 11:24 [entrez]
AID - S0390-5616.23.06171-4 [pii]
AID - 10.23736/S0390-5616.23.06171-4 [doi]
PST - aheadofprint
SO  - J Neurosurg Sci. 2024 Jan 23. doi: 10.23736/S0390-5616.23.06171-4.

PMID- 38277084
OWN - NLM
STAT- Publisher
LR  - 20240126
IS  - 1554-3528 (Electronic)
IS  - 1554-351X (Linking)
DP  - 2024 Jan 26
TI  - Can generative AI infer thinking style from language? Evaluating the utility of 
      AI as a psychological text analysis tool.
LID - 10.3758/s13428-024-02344-0 [doi]
AB  - Generative AI, short for Generative Artificial Intelligence, a class of 
      artificial intelligence systems, is not currently the choice technology for text 
      analysis, but prior work suggests it may have some utility to assess dynamics 
      like emotion. The current work builds upon this empirical foundation to consider 
      how analytic thinking scores from a large language model chatbot, ChatGPT, were 
      linked to analytic thinking scores from dictionary-based tools like Linguistic 
      Inquiry and Word Count (LIWC). Using over 16,000 texts from four samples and 
      tested against three prompts and two large language models (GPT-3.5, GPT-4), the 
      evidence suggests there were small associations between ChatGPT and LIWC analytic 
      thinking scores (meta-analytic effect sizes: .058 &lt; rs &lt; .304; ps &lt; .001). When 
      given the formula to calculate the LIWC analytic thinking index, ChatGPT 
      performed incorrect mathematical operations in 22% of the cases, suggesting basic 
      word and number processing may be unreliable with large language models. 
      Researchers should be cautious when using AI for text analysis.
CI  - © 2024. The Psychonomic Society, Inc.
FAU - Markowitz, David M
AU  - Markowitz DM
AUID- ORCID: 0000-0002-7159-7014
AD  - Department of Communication, Michigan State University, East Lansing, MI, USA. 
      dmm@msu.edu.
LA  - eng
PT  - Journal Article
DEP - 20240126
PL  - United States
TA  - Behav Res Methods
JT  - Behavior research methods
JID - 101244316
SB  - IM
OTO - NOTNLM
OT  - Analytic thinking
OT  - Generative AI
OT  - LIWC
OT  - Large language models
OT  - Text analysis
EDAT- 2024/01/26 12:45
MHDA- 2024/01/26 12:45
CRDT- 2024/01/26 11:08
PHST- 2024/01/15 00:00 [accepted]
PHST- 2024/01/26 12:45 [medline]
PHST- 2024/01/26 12:45 [pubmed]
PHST- 2024/01/26 11:08 [entrez]
AID - 10.3758/s13428-024-02344-0 [pii]
AID - 10.3758/s13428-024-02344-0 [doi]
PST - aheadofprint
SO  - Behav Res Methods. 2024 Jan 26. doi: 10.3758/s13428-024-02344-0.

PMID- 38133911
OWN - NLM
STAT- MEDLINE
DCOM- 20231225
LR  - 20240108
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Dec 22
TI  - Medical Student Experiences and Perceptions of ChatGPT and Artificial 
      Intelligence: Cross-Sectional Study.
PG  - e51302
LID - 10.2196/51302 [doi]
LID - e51302
AB  - BACKGROUND: Artificial intelligence (AI) has the potential to revolutionize the 
      way medicine is learned, taught, and practiced, and medical education must 
      prepare learners for these inevitable changes. Academic medicine has, however, 
      been slow to embrace recent AI advances. Since its launch in November 2022, 
      ChatGPT has emerged as a fast and user-friendly large language model that can 
      assist health care professionals, medical educators, students, trainees, and 
      patients. While many studies focus on the technology's capabilities, potential, 
      and risks, there is a gap in studying the perspective of end users. OBJECTIVE: 
      The aim of this study was to gauge the experiences and perspectives of graduating 
      medical students on ChatGPT and AI in their training and future careers. METHODS: 
      A cross-sectional web-based survey of recently graduated medical students was 
      conducted in an international academic medical center between May 5, 2023, and 
      June 13, 2023. Descriptive statistics were used to tabulate variable frequencies. 
      RESULTS: Of 325 applicants to the residency programs, 265 completed the survey 
      (an 81.5% response rate). The vast majority of respondents denied using ChatGPT 
      in medical school, with 20.4% (n=54) using it to help complete written 
      assessments and only 9.4% using the technology in their clinical work (n=25). 
      More students planned to use it during residency, primarily for exploring new 
      medical topics and research (n=168, 63.4%) and exam preparation (n=151, 57%). 
      Male students were significantly more likely to believe that AI will improve 
      diagnostic accuracy (n=47, 51.7% vs n=69, 39.7%; P=.001), reduce medical error 
      (n=53, 58.2% vs n=71, 40.8%; P=.002), and improve patient care (n=60, 65.9% vs 
      n=95, 54.6%; P=.007). Previous experience with AI was significantly associated 
      with positive AI perception in terms of improving patient care, decreasing 
      medical errors and misdiagnoses, and increasing the accuracy of diagnoses 
      (P=.001, P&lt;.001, P=.008, respectively). CONCLUSIONS: The surveyed medical 
      students had minimal formal and informal experience with AI tools and limited 
      perceptions of the potential uses of AI in health care but had overall positive 
      views of ChatGPT and AI and were optimistic about the future of AI in medical 
      education and health care. Structured curricula and formal policies and 
      guidelines are needed to adequately prepare medical learners for the forthcoming 
      integration of AI in medicine.
CI  - ©Saif M I Alkhaaldi, Carl H Kassab, Zakia Dimassi, Leen Oyoun Alsoud, Maha Al 
      Fahim, Cynthia Al Hageh, Halah Ibrahim. Originally published in JMIR Medical 
      Education (https://mededu.jmir.org), 22.12.2023.
FAU - Alkhaaldi, Saif M I
AU  - Alkhaaldi SMI
AUID- ORCID: 0009-0007-9443-7420
AD  - Khalifa University College of Medicine and Health Sciences, Abu Dhabi, United 
      Arab Emirates.
FAU - Kassab, Carl H
AU  - Kassab CH
AUID- ORCID: 0009-0007-0902-4104
AD  - Khalifa University College of Medicine and Health Sciences, Abu Dhabi, United 
      Arab Emirates.
FAU - Dimassi, Zakia
AU  - Dimassi Z
AUID- ORCID: 0000-0001-8729-1581
AD  - Department of Medical Science, Khalifa University College of Medicine and Health 
      Sciences, Abu Dhabi, United Arab Emirates.
FAU - Oyoun Alsoud, Leen
AU  - Oyoun Alsoud L
AUID- ORCID: 0009-0007-9361-9759
AD  - Department of Medical Science, Khalifa University College of Medicine and Health 
      Sciences, Abu Dhabi, United Arab Emirates.
FAU - Al Fahim, Maha
AU  - Al Fahim M
AUID- ORCID: 0000-0002-1595-6975
AD  - Education Institute, Sheikh Khalifa Medical City, Abu Dhabi, United Arab 
      Emirates.
FAU - Al Hageh, Cynthia
AU  - Al Hageh C
AUID- ORCID: 0000-0001-8386-4063
AD  - Department of Medical Science, Khalifa University College of Medicine and Health 
      Sciences, Abu Dhabi, United Arab Emirates.
FAU - Ibrahim, Halah
AU  - Ibrahim H
AUID- ORCID: 0000-0002-9240-7726
AD  - Department of Medical Science, Khalifa University College of Medicine and Health 
      Sciences, Abu Dhabi, United Arab Emirates.
LA  - eng
PT  - Journal Article
DEP - 20231222
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
SB  - IM
MH  - Humans
MH  - Male
MH  - *Students, Medical
MH  - Cross-Sectional Studies
MH  - Artificial Intelligence
MH  - *Medicine
MH  - Academic Medical Centers
PMC - PMC10770787
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - LLMs
OT  - artificial intelligence
OT  - cross-sectional study
OT  - education
OT  - health care professionals
OT  - large language models
OT  - medical education
OT  - medical student
OT  - medical students
OT  - medicine
OT  - risk
OT  - technology
OT  - training
COIS- Conflicts of Interest: None declared.
EDAT- 2023/12/22 12:43
MHDA- 2023/12/25 06:41
PMCR- 2023/12/22
CRDT- 2023/12/22 11:53
PHST- 2023/07/27 00:00 [received]
PHST- 2023/12/11 00:00 [accepted]
PHST- 2023/11/10 00:00 [revised]
PHST- 2023/12/25 06:41 [medline]
PHST- 2023/12/22 12:43 [pubmed]
PHST- 2023/12/22 11:53 [entrez]
PHST- 2023/12/22 00:00 [pmc-release]
AID - v9i1e51302 [pii]
AID - 10.2196/51302 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Dec 22;9:e51302. doi: 10.2196/51302.

PMID- 36702491
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20230131
LR  - 20230202
IS  - 1756-1833 (Electronic)
IS  - 0959-8138 (Linking)
VI  - 380
DP  - 2023 Jan 26
TI  - Sixty seconds on . . . ChatGPT.
PG  - 205
LID - 10.1136/bmj.p205 [doi]
FAU - Looi, Mun-Keat
AU  - Looi MK
AD  - The BMJ.
LA  - eng
PT  - Journal Article
DEP - 20230126
PL  - England
TA  - BMJ
JT  - BMJ (Clinical research ed.)
JID - 8900488
SB  - IM
EDAT- 2023/01/27 06:00
MHDA- 2023/01/31 06:00
CRDT- 2023/01/26 20:33
PHST- 2023/01/26 20:33 [entrez]
PHST- 2023/01/27 06:00 [pubmed]
PHST- 2023/01/31 06:00 [medline]
AID - 10.1136/bmj.p205 [doi]
PST - epublish
SO  - BMJ. 2023 Jan 26;380:205. doi: 10.1136/bmj.p205.

PMID- 36747099
OWN - NLM
STAT- Publisher
LR  - 20240216
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
DP  - 2023 Feb 3
TI  - Daily briefing: Science urgently needs a plan for ChatGPT.
LID - 10.1038/d41586-023-00360-2 [doi]
FAU - Graham, Flora
AU  - Graham F
LA  - eng
PT  - News
DEP - 20230203
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
EDAT- 2023/02/08 06:00
MHDA- 2023/02/08 06:00
CRDT- 2023/02/07 00:05
PHST- 2023/02/07 00:05 [entrez]
PHST- 2023/02/08 06:00 [pubmed]
PHST- 2023/02/08 06:00 [medline]
AID - 10.1038/d41586-023-00360-2 [pii]
AID - 10.1038/d41586-023-00360-2 [doi]
PST - aheadofprint
SO  - Nature. 2023 Feb 3. doi: 10.1038/d41586-023-00360-2.

PMID- 36690769
OWN - NLM
STAT- Publisher
LR  - 20240216
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
DP  - 2023 Jan 20
TI  - Daily briefing: ChatGPT listed as author on research papers.
LID - 10.1038/d41586-023-00188-w [doi]
FAU - Graham, Flora
AU  - Graham F
LA  - eng
PT  - News
DEP - 20230120
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
EDAT- 2023/01/24 06:00
MHDA- 2023/01/24 06:00
CRDT- 2023/01/23 23:21
PHST- 2023/01/24 06:00 [pubmed]
PHST- 2023/01/24 06:00 [medline]
PHST- 2023/01/23 23:21 [entrez]
AID - 10.1038/d41586-023-00188-w [pii]
AID - 10.1038/d41586-023-00188-w [doi]
PST - aheadofprint
SO  - Nature. 2023 Jan 20. doi: 10.1038/d41586-023-00188-w.

PMID- 37738926
OWN - NLM
STAT- MEDLINE
DCOM- 20231120
LR  - 20231121
IS  - 1578-1747 (Electronic)
IS  - 0211-139X (Linking)
VI  - 58
IP  - 6
DP  - 2023 Nov-Dec
TI  - [Artificial intelligence in geriatrics: ChatGPT and AI impact].
PG  - 101403
LID - S0211-139X(23)00124-5 [pii]
LID - 10.1016/j.regg.2023.101403 [doi]
FAU - Fontecha-Gómez, B J
AU  - Fontecha-Gómez BJ
AD  - Servicio de Geriatría y Cuidados Paliativos, Consorci Sanitari Integral, 
      L'Hospitalet de Llobregat, Barcelona, España. Electronic address: 
      bfontecha@csi.cat.
FAU - Betancor-Santana, É
AU  - Betancor-Santana É
AD  - Servicio de Geriatría y Cuidados Paliativos, Consorci Sanitari Integral, 
      L'Hospitalet de Llobregat, Barcelona, España.
LA  - spa
PT  - Journal Article
TT  - Inteligencia artificial en geriatría. Impacto de ChatGPT e IA.
DEP - 20230920
PL  - Spain
TA  - Rev Esp Geriatr Gerontol
JT  - Revista espanola de geriatria y gerontologia
JID - 8009022
SB  - IM
MH  - Humans
MH  - Aged
MH  - *Artificial Intelligence
MH  - *Geriatrics
EDAT- 2023/09/23 11:42
MHDA- 2023/11/20 06:54
CRDT- 2023/09/22 18:11
PHST- 2023/07/24 00:00 [received]
PHST- 2023/07/28 00:00 [accepted]
PHST- 2023/11/20 06:54 [medline]
PHST- 2023/09/23 11:42 [pubmed]
PHST- 2023/09/22 18:11 [entrez]
AID - S0211-139X(23)00124-5 [pii]
AID - 10.1016/j.regg.2023.101403 [doi]
PST - ppublish
SO  - Rev Esp Geriatr Gerontol. 2023 Nov-Dec;58(6):101403. doi: 
      10.1016/j.regg.2023.101403. Epub 2023 Sep 20.

PMID- 37567593
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20230814
LR  - 20230814
IS  - 1756-1833 (Electronic)
IS  - 0959-8138 (Linking)
VI  - 382
DP  - 2023 Aug 11
TI  - When I use a word . . . ChatGPT: a differential diagnosis.
PG  - 1862
LID - 10.1136/bmj.p1862 [doi]
FAU - Aronson, Jeffrey K
AU  - Aronson JK
AUID- ORCID: 0000-0003-1139-655X
AD  - Centre for Evidence Based Medicine, Nuffield Department of Primary Care Health 
      Sciences, University of Oxford, Oxford, UK.
LA  - eng
PT  - Editorial
DEP - 20230811
PL  - England
TA  - BMJ
JT  - BMJ (Clinical research ed.)
JID - 8900488
SB  - IM
COIS- Competing interests: JKA has composed crossword puzzles that have appeared in The 
      Listener, The Oxford Times, The Daily Telegraph, and currently the Times Literary 
      Supplement and hopes that no one is using ChatGPT to try to solve them.
EDAT- 2023/08/12 10:41
MHDA- 2023/08/14 06:41
CRDT- 2023/08/11 20:43
PHST- 2023/08/14 06:41 [medline]
PHST- 2023/08/12 10:41 [pubmed]
PHST- 2023/08/11 20:43 [entrez]
AID - 10.1136/bmj.p1862 [doi]
PST - epublish
SO  - BMJ. 2023 Aug 11;382:1862. doi: 10.1136/bmj.p1862.

PMID- 37171282
OWN - NLM
STAT- MEDLINE
DCOM- 20230523
LR  - 20230601
IS  - 1526-4610 (Electronic)
IS  - 0017-8748 (Linking)
VI  - 63
IP  - 5
DP  - 2023 May
TI  - The role of artificial intelligence in headache medicine: Potential and peril.
PG  - 694-696
LID - 10.1111/head.14495 [doi]
FAU - Cohen, Fred
AU  - Cohen F
AUID- ORCID: 0000-0003-3436-2846
AD  - Center for Headache and Facial Pain, Department of Neurology, Icahn School of 
      Medicine at Mount Sinai, New York, New York, USA.
LA  - eng
PT  - Journal Article
DEP - 20230427
PL  - United States
TA  - Headache
JT  - Headache
JID - 2985091R
SB  - IM
CIN - Headache. 2023 May;63(5):571-572. PMID: 37102424
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Headache
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial
OT  - headache
OT  - intelligence
OT  - medicine
EDAT- 2023/05/12 13:08
MHDA- 2023/05/16 06:42
CRDT- 2023/05/12 10:13
PHST- 2023/02/17 00:00 [revised]
PHST- 2023/01/31 00:00 [received]
PHST- 2023/03/04 00:00 [accepted]
PHST- 2023/05/16 06:42 [medline]
PHST- 2023/05/12 13:08 [pubmed]
PHST- 2023/05/12 10:13 [entrez]
AID - 10.1111/head.14495 [doi]
PST - ppublish
SO  - Headache. 2023 May;63(5):694-696. doi: 10.1111/head.14495. Epub 2023 Apr 27.

PMID- 37336139
OWN - NLM
STAT- MEDLINE
DCOM- 20230710
LR  - 20231128
IS  - 1873-4529 (Electronic)
IS  - 0952-8180 (Linking)
VI  - 89
DP  - 2023 Oct
TI  - Artificial intelligence software can generate residency application personal 
      statements that program directors find acceptable and difficult to distinguish 
      from applicant compositions.
PG  - 111185
LID - S0952-8180(23)00135-6 [pii]
LID - 10.1016/j.jclinane.2023.111185 [doi]
AB  - STUDY OBJECTIVE: Create personal statements using an artificial intelligence 
      program for anesthesiology residency applications that residency program 
      directors rate as acceptable. STUDY DESIGN: Generate two personal statements and 
      survey program directors. SETTING: Anesthesiology residency training programs. 
      INTERVENTIONS: We instructed ChatGPT, a new artificial-intelligence software 
      program, to generate two 400-word personal statements using the common applicant 
      experiences of involvement in athletics or gourmet cooking. METHODS: We sent the 
      generated personal statements to anesthesia program directors and asked them if 
      the statements were acceptable for application to their individual programs, to 
      rate them as poor, good, or excellent, and determine if they could detect 
      anything in the statements that indicated they were not written by an applicant. 
      MEASUREMENTS: Ninety-four program directors received and opened the survey, and 
      31 responded. Twenty-eight (90%) responding directors found the personal 
      statement with athletic experience acceptable, with 22 (74%) rating it as good or 
      excellent. Nineteen (61%) program directors did not detect anything in the 
      statement to distinguish it from an applicant-written composition. Twenty-nine 
      (97%) program directors found the personal statement with cooking experience 
      acceptable, with 19 (63%) finding it good or excellent. Twenty-four (80%) 
      directors did not detect anything in the statement to distinguish it from an 
      applicant-written composition. CONCLUSIONS: ChatGPT can create personal 
      statements for residency applications that program directors find acceptable and 
      difficult to differentiate from personally crafted statements. Applicants may 
      stop using expensive contractor application services and start using artificial 
      intelligence software to create their personal statements because of its 
      quickness, low cost, and high quality.
CI  - Copyright © 2023 The Authors. Published by Elsevier Inc. All rights reserved.
FAU - Johnstone, Robert E
AU  - Johnstone RE
AD  - Department of Anesthesiology, West Virginia University, United States of America. 
      Electronic address: JohnstoneR@hsc.wvu.edu.
FAU - Neely, Grant
AU  - Neely G
AD  - Department of Anesthesiology, West Virginia University, United States of America.
FAU - Sizemore, Daniel C
AU  - Sizemore DC
AD  - Department of Anesthesiology, West Virginia University, United States of America.
LA  - eng
PT  - Journal Article
DEP - 20230619
PL  - United States
TA  - J Clin Anesth
JT  - Journal of clinical anesthesia
JID - 8812166
SB  - IM
MH  - Humans
MH  - *Internship and Residency
MH  - Artificial Intelligence
MH  - Surveys and Questionnaires
MH  - Software
MH  - *Anesthesiology/education
OTO - NOTNLM
OT  - Anesthesiology program
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Personal statement
OT  - Residency application
COIS- Declaration of Competing Interest The authors declare the following financial 
      interests/personal relationships which may be considered as potential competing 
      interests: Robert Johnstone reports a relationship with American Society of 
      Anesthesiologists that includes: board membership and travel reimbursement.
EDAT- 2023/06/20 01:09
MHDA- 2023/07/10 06:42
CRDT- 2023/06/19 18:06
PHST- 2023/04/01 00:00 [received]
PHST- 2023/06/08 00:00 [revised]
PHST- 2023/06/13 00:00 [accepted]
PHST- 2023/07/10 06:42 [medline]
PHST- 2023/06/20 01:09 [pubmed]
PHST- 2023/06/19 18:06 [entrez]
AID - S0952-8180(23)00135-6 [pii]
AID - 10.1016/j.jclinane.2023.111185 [doi]
PST - ppublish
SO  - J Clin Anesth. 2023 Oct;89:111185. doi: 10.1016/j.jclinane.2023.111185. Epub 2023 
      Jun 19.

PMID- 38194585
OWN - NLM
STAT- Publisher
LR  - 20240109
IS  - 1444-0938 (Electronic)
IS  - 0816-4622 (Linking)
DP  - 2024 Jan 9
TI  - Talking technology: exploring chatbots as a tool for cataract patient education.
PG  - 1-9
LID - 10.1080/08164622.2023.2298812 [doi]
AB  - CLINICAL RELEVANCE: Worldwide, millions suffer from cataracts, which impair 
      vision and quality of life. Cataract education improves outcomes, satisfaction, 
      and treatment adherence. Lack of health literacy, language and cultural barriers, 
      personal preferences, and limited resources may all impede effective 
      communication. BACKGROUND: AI can improve patient education by providing 
      personalised, interactive, and accessible information tailored to patient 
      understanding, interest, and motivation. AI chatbots can have human-like 
      conversations and give advice on numerous topics. METHODS: This study 
      investigated the efficacy of chatbots in cataract patient education relative to 
      traditional resources like the AAO website, focusing on information 
      accuracy,understandability, actionability, and readability. A descriptive 
      comparative design was used to analyse quantitative data from frequently asked 
      questions about cataracts answered by ChatGPT, Bard, Bing AI, and the AAO 
      website. SOLO taxonomy, PEMAT, and the Flesch-Kincaid ease score were used to 
      collect and analyse the data. RESULTS: Chatbots scored higher than AAO website on 
      cataract-related questions in terms of accuracy (mean SOLO score ChatGPT: 
      3.1 ± 0.31, Bard: 2.9 ± 0.72, Bing AI: 2.65 ± 0.49, AAO website: 2.4 ± 0.6, 
      (p &lt; 0.001)). For understandability (mean PEMAT-U score AAO website: 0,89 ± 0,04, 
      ChatGPT 0,84 ± 0,02, Bard: 0,84 ± 0,02, Bing AI: 0,81 ± 0,02, (p &lt; 0.001)), and 
      actionability (mean PEMAT-A score ChatGPT: 0.86 ± 0.03, Bard: 0.85 ± 0.06, Bing 
      AI: 0.81 ± 0.05, AAO website: 0.81 ± 0.06, (p &lt; 0.001)) AAO website scored better 
      than chatbots. Flesch-Kincaid readability ease analysis showed that Bard 
      (55,5 ± 8,48) had the highest mean score, followed by AAO website 
      (51,96 ± 12,46), Bing AI (41,77 ± 9,53), and ChatGPT (34,38 ± 9,75, (p &lt; 0.001)). 
      CONCLUSION: Chatbots have the potential to provide more detailed and accurate 
      data than the AAO website. On the other hand, the AAO website has the advantage 
      of providing information that is more understandable and practical. When patient 
      preferences are not taken into account, generalised or biased information can 
      decrease reliability.
FAU - Yılmaz, I Brahim Edhem
AU  - Yılmaz IBE
AUID- ORCID: 0000-0003-1154-425X
AD  - Ophthalmology Department, Kilis State Hospital, Kilis, Turkey.
FAU - Doğan, Levent
AU  - Doğan L
AUID- ORCID: 0000-0002-4849-3698
AD  - Ophthalmology Department, Kilis State Hospital, Kilis, Turkey.
LA  - eng
PT  - Journal Article
DEP - 20240109
PL  - United States
TA  - Clin Exp Optom
JT  - Clinical &amp; experimental optometry
JID - 8703442
SB  - IM
OTO - NOTNLM
OT  - Cataracts
OT  - chatbot
OT  - conversational artificial intelligence
OT  - health literacy
OT  - information accessibility
OT  - patient education
EDAT- 2024/01/09 18:41
MHDA- 2024/01/09 18:41
CRDT- 2024/01/09 16:02
PHST- 2024/01/09 18:41 [medline]
PHST- 2024/01/09 18:41 [pubmed]
PHST- 2024/01/09 16:02 [entrez]
AID - 10.1080/08164622.2023.2298812 [doi]
PST - aheadofprint
SO  - Clin Exp Optom. 2024 Jan 9:1-9. doi: 10.1080/08164622.2023.2298812.

PMID- 37905264
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231101
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 9
DP  - 2023 Sep
TI  - Decoding Applications of Artificial Intelligence in Rheumatology.
PG  - e46164
LID - 10.7759/cureus.46164 [doi]
LID - e46164
AB  - Artificial intelligence (AI) is not a newcomer in medicine. It has been employed 
      for image analysis, disease diagnosis, drug discovery, and improving overall 
      patient care. ChatGPT (Chat Generative Pre-trained Transformer,&nbsp;Inc., Delaware) 
      has renewed interest and enthusiasm in artificial intelligence. Algorithms, 
      machine learning, deep learning, and data analysis are some of the complex 
      terminologies often encountered when health professionals try to learn AI. In 
      this article, we try to review the practical applications of artificial 
      intelligence in vernacular language in the fields of medicine and rheumatology in 
      particular. From the standpoint of the everyday physician, we have endeavored to 
      encapsulate the influence of AI on the cutting edge of medical practice and the 
      potential revolutionary shift in the realm of rheumatology.
CI  - Copyright © 2023, Chinnadurai et al.
FAU - Chinnadurai, Saranya
AU  - Chinnadurai S
AD  - Rheumatology, Sri Ramachandra Institute of Higher Education and Research, 
      Chennai, IND.
FAU - Mahadevan, Sabarinath
AU  - Mahadevan S
AD  - Rheumatology, O.M. Health Care Clinic, Chennai, IND.
FAU - Navaneethakrishnan, Balakrishnan
AU  - Navaneethakrishnan B
AD  - Rheumatology, Madras Institute of Orthopaedics and Traumatology (MIOT) Hospital, 
      Chennai, IND.
FAU - Mamadapur, Mahabaleshwar
AU  - Mamadapur M
AD  - Rheumatology, Jagadguru Sri Shivarathreeshwara (JSS) Medical College, Mysore, 
      IND.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230928
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10613315
OTO - NOTNLM
OT  - ai
OT  - arthritis
OT  - autoimmune
OT  - chatgpt
OT  - musculoskeletal diseases
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/10/31 06:42
MHDA- 2023/10/31 06:43
PMCR- 2023/09/28
CRDT- 2023/10/31 04:07
PHST- 2023/09/27 00:00 [accepted]
PHST- 2023/10/31 06:43 [medline]
PHST- 2023/10/31 06:42 [pubmed]
PHST- 2023/10/31 04:07 [entrez]
PHST- 2023/09/28 00:00 [pmc-release]
AID - 10.7759/cureus.46164 [doi]
PST - epublish
SO  - Cureus. 2023 Sep 28;15(9):e46164. doi: 10.7759/cureus.46164. eCollection 2023 
      Sep.

PMID- 37843579
OWN - NLM
STAT- MEDLINE
DCOM- 20231027
LR  - 20231027
IS  - 2731-7099 (Electronic)
IS  - 2731-7080 (Linking)
VI  - 64
IP  - 11
DP  - 2023 Nov
TI  - [Clinical application of large language models : Does ChatGPT replace medical 
      report formulation? An experience report].
PG  - 1058-1064
LID - 10.1007/s00108-023-01600-3 [doi]
AB  - Artificial intelligence (AI)-based language models, such as ChatGPT offer an 
      enormous potential for research and medical care but also for clinical workflow 
      optimization by making medical documentation easier and more efficient in taking 
      over standardized routine tasks. With their ability to guess a text's content 
      using word statistics and thus outputting contextually relevant results in chat 
      dialogues, large language models (LLM) can provide appropriate summaries of 
      medical documentation for different target groups. For instance, text generation 
      in easy to understand language could potentially contribute to an increase in 
      patients' health literacy and, consequently, to increased adherence to treatment. 
      Subsequent, the function of AI-based chatbot models to improve user experiences 
      and enhance competence in the use of AI-based language models will be adressed. 
      Current limitations and chances in creating epicrises are presented as an 
      experience report. In the future, the implementation of local LLMs in medical 
      management systems (hospital information systems, HIS and practice administration 
      systems, PAS) and in conjunction with the electronic patient records (ePA) can 
      fundamentally change clinical and outpatient care.
CI  - © 2023. The Author(s), under exclusive licence to Springer Medizin Verlag GmbH, 
      ein Teil von Springer Nature.
FAU - Zernikow, Jasmin
AU  - Zernikow J
AD  - Klinik für Kardiologie, Angiologie und Intensivmedizin, Deutsches Herzzentrum der 
      Charité (DHZC), Charitéplatz&nbsp;1, 10117, Berlin, Deutschland.
AD  - Charité&nbsp;- Universitätsmedizin Berlin, corporate member of Freie Universität 
      Berlin and Humboldt-Universität zu Berlin, Charitéplatz&nbsp;1, 10117, Berlin, 
      Deutschland.
FAU - Grassow, Leonhard
AU  - Grassow L
AD  - Klinik für Kardiologie, Angiologie und Intensivmedizin, Deutsches Herzzentrum der 
      Charité (DHZC), Charitéplatz&nbsp;1, 10117, Berlin, Deutschland.
AD  - Deutsches Zentrum für Herz-Kreislauf-Forschung e. V. (DZHK), Berlin, Deutschland.
AD  - Arbeitsgruppe für kardiovaskuläre MRT, Experimental and Clinical Research Center, 
      Gemeinsame Einrichtung der Charité - Universitätsmedizin Berlin und des Max 
      Delbrück Center (MDC), Lindenberger Weg&nbsp;80, 13125, Berlin, Deutschland.
FAU - Gröschel, Jan
AU  - Gröschel J
AD  - Klinik für Kardiologie, Angiologie und Intensivmedizin, Deutsches Herzzentrum der 
      Charité (DHZC), Charitéplatz&nbsp;1, 10117, Berlin, Deutschland.
AD  - Charité&nbsp;- Universitätsmedizin Berlin, corporate member of Freie Universität 
      Berlin and Humboldt-Universität zu Berlin, Charitéplatz&nbsp;1, 10117, Berlin, 
      Deutschland.
AD  - Deutsches Zentrum für Herz-Kreislauf-Forschung e. V. (DZHK), Berlin, Deutschland.
AD  - Arbeitsgruppe für kardiovaskuläre MRT, Experimental and Clinical Research Center, 
      Gemeinsame Einrichtung der Charité - Universitätsmedizin Berlin und des Max 
      Delbrück Center (MDC), Lindenberger Weg&nbsp;80, 13125, Berlin, Deutschland.
FAU - Henrion, Philippe
AU  - Henrion P
AD  - Klinik für Kardiologie, Angiologie und Intensivmedizin, Deutsches Herzzentrum der 
      Charité (DHZC), Charitéplatz&nbsp;1, 10117, Berlin, Deutschland.
AD  - Charité&nbsp;- Universitätsmedizin Berlin, corporate member of Freie Universität 
      Berlin and Humboldt-Universität zu Berlin, Charitéplatz&nbsp;1, 10117, Berlin, 
      Deutschland.
FAU - Wetzel, Paul J
AU  - Wetzel PJ
AD  - Charité&nbsp;- Universitätsmedizin Berlin, corporate member of Freie Universität 
      Berlin and Humboldt-Universität zu Berlin, Charitéplatz&nbsp;1, 10117, Berlin, 
      Deutschland.
FAU - Spethmann, Sebastian
AU  - Spethmann S
AD  - Klinik für Kardiologie, Angiologie und Intensivmedizin, Deutsches Herzzentrum der 
      Charité (DHZC), Charitéplatz&nbsp;1, 10117, Berlin, Deutschland. 
      sebastian.spethmann@dhzc-charite.de.
AD  - Charité&nbsp;- Universitätsmedizin Berlin, corporate member of Freie Universität 
      Berlin and Humboldt-Universität zu Berlin, Charitéplatz&nbsp;1, 10117, Berlin, 
      Deutschland. sebastian.spethmann@dhzc-charite.de.
AD  - Deutsches Zentrum für Herz-Kreislauf-Forschung e. V. (DZHK), Berlin, Deutschland. 
      sebastian.spethmann@dhzc-charite.de.
LA  - ger
PT  - English Abstract
PT  - Journal Article
PT  - Review
TT  - Anwendung von „large language models“ in der Klinik : Ersetzt ChatGPT die 
      Arztbrieferstellung? Ein Erfahrungsbericht.
DEP - 20231016
PL  - Germany
TA  - Inn Med (Heidelb)
JT  - Innere Medizin (Heidelberg, Germany)
JID - 9918384885306676
RN  - EC 2.3.1.6 (Choline O-Acetyltransferase)
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Electronic Health Records
MH  - Ambulatory Care
MH  - Choline O-Acetyltransferase
MH  - Language
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Chatbots
OT  - Digital transformation
OT  - Patient empowerment
EDAT- 2023/10/16 12:42
MHDA- 2023/10/27 06:43
CRDT- 2023/10/16 11:04
PHST- 2023/09/14 00:00 [accepted]
PHST- 2023/10/27 06:43 [medline]
PHST- 2023/10/16 12:42 [pubmed]
PHST- 2023/10/16 11:04 [entrez]
AID - 10.1007/s00108-023-01600-3 [pii]
AID - 10.1007/s00108-023-01600-3 [doi]
PST - ppublish
SO  - Inn Med (Heidelb). 2023 Nov;64(11):1058-1064. doi: 10.1007/s00108-023-01600-3. 
      Epub 2023 Oct 16.

PMID- 37506622
OWN - NLM
STAT- MEDLINE
DCOM- 20230814
LR  - 20230814
IS  - 1532-2793 (Electronic)
IS  - 0260-6917 (Linking)
VI  - 129
DP  - 2023 Oct
TI  - Nursing education in the age of artificial intelligence powered Chatbots 
      (AI-Chatbots): Are we ready yet?
PG  - 105917
LID - S0260-6917(23)00211-3 [pii]
LID - 10.1016/j.nedt.2023.105917 [doi]
AB  - This article discusses the challenges and implications of artificial intelligence 
      powered chatbot (AI-Chatbots) in nursing education. Chat Generative Pre-trained 
      Transformer (ChatGPT) is an AI-Chatbot that can engage in detailed dialog and 
      pass qualification tests in various fields. It can be applied for drafting course 
      materials and administrative paperwork. Students can use it for personalized 
      self-paced learning. AI-Chatbot technology can be applied in problem-based 
      learning for hands-on practice experiences. There are concerns about 
      over-reliance on the technology, including issues with plagiarism and limiting 
      critical thinking skills. Educators must provide clear guidelines on appropriate 
      use and emphasize the importance of critical thinking and proper citation. 
      Educators must proactively adjust their curricula and pedagogy. AI-Chatbot 
      technology could transform the nursing profession by aiding and streamlining 
      administrative tasks, allowing nurses to focus on patient care. The use of 
      AI-Chatbots to socially assist patients and for therapeutic purposes in mental 
      health shows promise in improving well-being of patients, and potentially easing 
      shortage and burnout for healthcare workers. AI-Chatbots can help nursing 
      students and researchers to overcome technical barriers in nursing informatics, 
      increasing accessibility for individuals without technical background. AI-Chatbot 
      technology has potential in easing tasks for nurses, improving patient care, and 
      enhancing nursing education.
CI  - Copyright © 2023 The Authors. Published by Elsevier Ltd.. All rights reserved.
FAU - Tam, Wilson
AU  - Tam W
AD  - Alice Lee Centre for Nursing Studies, National University of Singapore, 
      Singapore.
FAU - Huynh, Tom
AU  - Huynh T
AD  - School of Science, Engineering and Technology, RMIT University, Viet Nam.
FAU - Tang, Arthur
AU  - Tang A
AD  - School of Science, Engineering and Technology, RMIT University, Viet Nam. 
      Electronic address: arthur.tang@rmit.edu.vn.
FAU - Luong, Stanley
AU  - Luong S
AD  - School of Science, Engineering and Technology, RMIT University, Viet Nam.
FAU - Khatri, Yunus
AU  - Khatri Y
AD  - School of Science, Engineering and Technology, RMIT University, Viet Nam.
FAU - Zhou, Wentao
AU  - Zhou W
AD  - Alice Lee Centre for Nursing Studies, National University of Singapore, 
      Singapore.
LA  - eng
PT  - Journal Article
DEP - 20230718
PL  - Scotland
TA  - Nurse Educ Today
JT  - Nurse education today
JID - 8511379
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Education, Nursing
MH  - Nursing
MH  - Burnout, Psychological
MH  - Curriculum
OTO - NOTNLM
OT  - AI-Chatbot
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Nursing education
COIS- Declaration of competing interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2023/07/29 06:42
MHDA- 2023/08/14 06:42
CRDT- 2023/07/28 18:09
PHST- 2023/03/13 00:00 [received]
PHST- 2023/06/26 00:00 [revised]
PHST- 2023/07/17 00:00 [accepted]
PHST- 2023/08/14 06:42 [medline]
PHST- 2023/07/29 06:42 [pubmed]
PHST- 2023/07/28 18:09 [entrez]
AID - S0260-6917(23)00211-3 [pii]
AID - 10.1016/j.nedt.2023.105917 [doi]
PST - ppublish
SO  - Nurse Educ Today. 2023 Oct;129:105917. doi: 10.1016/j.nedt.2023.105917. Epub 2023 
      Jul 18.

PMID- 37094759
OWN - NLM
STAT- MEDLINE
DCOM- 20230516
LR  - 20230801
IS  - 2173-5794 (Electronic)
IS  - 2173-5794 (Linking)
VI  - 98
IP  - 5
DP  - 2023 May
TI  - Artificial Intelligence and new language models in Ophthalmology: Complications 
      of the use of silicone oil in vitreoretinal surgery.
PG  - 298-303
LID - S2173-5794(23)00058-0 [pii]
LID - 10.1016/j.oftale.2023.04.011 [doi]
AB  - Artificial intelligence (AI) is an emerging technology that facilitates everyday 
      tasks and automates tasks in various fields such as medicine. However, the 
      emergence of a language model in academia has generated a lot of interest. This 
      paper evaluates the potential of ChatGPT, a language model developed by OpenAI, 
      and DALL-E 2, an image generator, in the writing of scientific articles in 
      ophthalmology. The selected topic is the complications of the use of silicone oil 
      in vitreoretinal surgery. ChatGPT was used to generate an abstract and a 
      structured article, suggestions for a title and bibliographical references. In 
      conclusion, despite the knowledge demonstrated by this tool, the scientific 
      accuracy and reliability on specific topics is insufficient for the automatic 
      generation of scientifically rigorous articles. In addition, scientists should be 
      aware of the possible ethical and legal implications of these tools.
CI  - Copyright © 2023 Sociedad Española de Oftalmología. Published by Elsevier España, 
      S.L.U. All rights reserved.
FAU - Valentín-Bravo, F J
AU  - Valentín-Bravo FJ
AD  - The Retina Clinic London, London, United Kingdom. Electronic address: 
      fjvb90@icloud.com.
FAU - Mateos-Álvarez, E
AU  - Mateos-Álvarez E
AD  - Escuela de doctorado de la Universidad de Valladolid, Valladolid, Spain.
FAU - Usategui-Martín, R
AU  - Usategui-Martín R
AD  - Instituto de Oftalmobiología Aplicada (IOBA), Universidad de Valladolid, 
      Valladolid, Spain.
FAU - Andrés-Iglesias, C
AU  - Andrés-Iglesias C
AD  - Instituto de Oftalmobiología Aplicada (IOBA), Universidad de Valladolid, 
      Valladolid, Spain.
FAU - Pastor-Jimeno, J C
AU  - Pastor-Jimeno JC
AD  - Instituto de Oftalmobiología Aplicada (IOBA), Universidad de Valladolid, 
      Valladolid, Spain; Red de Cooperación en la Investigación en Oftalmología 
      (Oftared), Instituto de Salud Carlos III, Madrid, Spain.
FAU - Pastor-Idoate, S
AU  - Pastor-Idoate S
AD  - Instituto de Oftalmobiología Aplicada (IOBA), Universidad de Valladolid, 
      Valladolid, Spain; Hospital Clínico Universitario de Valladolid, Valladolid, 
      Spain.
LA  - eng
PT  - Case Reports
DEP - 20230422
PL  - Spain
TA  - Arch Soc Esp Oftalmol (Engl Ed)
JT  - Archivos de la Sociedad Espanola de Oftalmologia
JID - 101715860
RN  - 0 (Silicone Oils)
SB  - IM
CIN - Arch Soc Esp Oftalmol (Engl Ed). 2023 Aug;98(8):486-487. PMID: 37353075
MH  - *Ophthalmology
MH  - Artificial Intelligence
MH  - Silicone Oils/adverse effects
MH  - *Vitreoretinal Surgery/adverse effects
MH  - Reproducibility of Results
MH  - Language
OTO - NOTNLM
OT  - Aceite de silicona
OT  - Artificial intelligence
OT  - ChatGPT
OT  - DALL-E
OT  - Inteligencia artificial
OT  - Language models
OT  - Modelos de lenguaje
OT  - Silicone oil
EDAT- 2023/04/25 00:41
MHDA- 2023/05/16 06:42
CRDT- 2023/04/24 07:24
PHST- 2023/01/31 00:00 [received]
PHST- 2023/03/22 00:00 [accepted]
PHST- 2023/05/16 06:42 [medline]
PHST- 2023/04/25 00:41 [pubmed]
PHST- 2023/04/24 07:24 [entrez]
AID - S2173-5794(23)00058-0 [pii]
AID - 10.1016/j.oftale.2023.04.011 [doi]
PST - ppublish
SO  - Arch Soc Esp Oftalmol (Engl Ed). 2023 May;98(5):298-303. doi: 
      10.1016/j.oftale.2023.04.011. Epub 2023 Apr 22.

PMID- 38499312
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20240320
LR  - 20240326
IS  - 1756-1833 (Electronic)
IS  - 0959-8138 (Linking)
VI  - 384
DP  - 2024 Mar 18
TI  - Sixty seconds on . . . ChatGPT and medical exams.
PG  - q675
LID - 10.1136/bmj.q675 [doi]
FAU - Wise, Jacqui
AU  - Wise J
AD  - Kent.
LA  - eng
PT  - Journal Article
DEP - 20240318
PL  - England
TA  - BMJ
JT  - BMJ (Clinical research ed.)
JID - 8900488
SB  - IM
EDAT- 2024/03/19 00:42
MHDA- 2024/03/19 00:43
CRDT- 2024/03/18 20:33
PHST- 2024/03/19 00:43 [medline]
PHST- 2024/03/19 00:42 [pubmed]
PHST- 2024/03/18 20:33 [entrez]
AID - 10.1136/bmj.q675 [doi]
PST - epublish
SO  - BMJ. 2024 Mar 18;384:q675. doi: 10.1136/bmj.q675.

PMID- 37848712
OWN - NLM
STAT- Publisher
LR  - 20231017
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
DP  - 2023 Oct 16
TI  - Daily briefing: ChatGPT use makes a mockery of grant applications.
LID - 10.1038/d41586-023-03254-5 [doi]
FAU - Graham, Flora
AU  - Graham F
LA  - eng
PT  - News
DEP - 20231016
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
EDAT- 2023/10/18 00:42
MHDA- 2023/10/18 00:42
CRDT- 2023/10/17 23:44
PHST- 2023/10/18 00:42 [medline]
PHST- 2023/10/18 00:42 [pubmed]
PHST- 2023/10/17 23:44 [entrez]
AID - 10.1038/d41586-023-03254-5 [pii]
AID - 10.1038/d41586-023-03254-5 [doi]
PST - aheadofprint
SO  - Nature. 2023 Oct 16. doi: 10.1038/d41586-023-03254-5.

PMID- 37127465
OWN - NLM
STAT- MEDLINE
DCOM- 20230524
LR  - 20230524
IS  - 1768-3122 (Electronic)
IS  - 0248-8663 (Linking)
VI  - 44
IP  - 5
DP  - 2023 May
TI  - [Chatbots and internal medicine: Future opportunities and challenges].
PG  - 209-211
LID - S0248-8663(23)00123-6 [pii]
LID - 10.1016/j.revmed.2023.04.001 [doi]
FAU - Galland, J
AU  - Galland J
AD  - Service de médecine interne, hôpital Fleyriat, centre hospitalier de 
      Bourg-en-Bresse, 900, route de Paris, 01012 Viriat cedex, France; Digital Medical 
      Hub SAS, Hôtel Dieu, Assistance publique-Hôpitaux de Paris, Paris, France. 
      Electronic address: joris.galland@dmh-aphp.fr.
LA  - fre
PT  - Journal Article
TT  - Les chatbots en médecine interne&nbsp;: opportunités et défis à venir.
DEP - 20230429
PL  - France
TA  - Rev Med Interne
JT  - La Revue de medecine interne
JID - 8101383
SB  - IM
MH  - Humans
MH  - *Internal Medicine
MH  - *Artificial Intelligence
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Chatbot
OT  - Intelligence artificielle
EDAT- 2023/05/02 00:42
MHDA- 2023/05/15 06:42
CRDT- 2023/05/01 21:57
PHST- 2023/03/31 00:00 [received]
PHST- 2023/04/01 00:00 [accepted]
PHST- 2023/05/15 06:42 [medline]
PHST- 2023/05/02 00:42 [pubmed]
PHST- 2023/05/01 21:57 [entrez]
AID - S0248-8663(23)00123-6 [pii]
AID - 10.1016/j.revmed.2023.04.001 [doi]
PST - ppublish
SO  - Rev Med Interne. 2023 May;44(5):209-211. doi: 10.1016/j.revmed.2023.04.001. Epub 
      2023 Apr 29.

PMID- 37791148
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231005
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 8
DP  - 2023 Aug
TI  - Artificial Intelligence in Childcare: Assessing the Performance and Acceptance of 
      ChatGPT Responses.
PG  - e44484
LID - 10.7759/cureus.44484 [doi]
LID - e44484
AB  - Purpose This study aimed to evaluate the performance and acceptance of responses 
      generated by ChatGPT-3.5 and GPT-4 to Japanese childcare-related questions to 
      assess their potential applicability and limitations in the childcare field, 
      specifically focusing on the accuracy, usefulness, and empathy of the generated 
      answers. Methods We evaluated answers in Japanese generated by GPT-3.5 and GPT-4 
      for two types of childcare-related questions. ① For the written examination 
      questions of Japan's childcare worker national examination for 2023's fiscal 
      year, we calculated the correct answer rates using official answers. ② We 
      selected one question from each of the seven categories from the child-rearing 
      questions posted on the Japanese National Childcare Workers Association's website 
      and had GPT-3.5 and GPT-4 generate answers. These were evaluated alongside 
      existing childcare worker answers by human professionals. Five childcare workers 
      then blindly selected what they considered the best answer among the three and 
      rated them on a five-point scale for 'accuracy,' 'usefulness,' and 'empathy.' 
      Results In the examination consisting of 160 written questions, both GPT-3.5 and 
      GPT-4 produced responses to all 155 questions, excluding four questions omitted 
      due to copyright concerns and one question deemed invalid due to inherent flaws 
      in the question itself, with correct answer rates of 30.3% for GPT-3.5 and 47.7% 
      for GPT-4 (p&lt;0.01). For the child-rearing Q&amp;A questions, childcare worker answers 
      by human professionals were chosen as the best answer most frequently (45.7%), 
      followed by GPT-3.5 (31.4%) and GPT-4 (22.9%). While GPT-3.5 received the highest 
      average rating for accuracy (3.69 points), childcare worker answers by human 
      professionals received the highest average ratings for usefulness and empathy 
      (both 3.57 points). Conclusions Both GPT-3.5 and GPT-4 failed to meet the passing 
      criteria in Japan's childcare worker national examination, and for the 
      child-rearing questions, GPT-3.5 was rated higher in accuracy despite lower 
      correct answer rates. Over half of the childcare workers considered the 
      ChatGPT-generated answers to be the best ones, yet concerns about accuracy were 
      observed, highlighting the potential risk of incorrect information in the 
      Japanese context.
CI  - Copyright © 2023, Kaneda et al.
FAU - Kaneda, Yudai
AU  - Kaneda Y
AD  - School of Medicine, Hokkaido University, Sapporo, JPN.
FAU - Namba, Mira
AU  - Namba M
AD  - School of Medicine, Keio University, Tokyo, JPN.
FAU - Kaneda, Uiri
AU  - Kaneda U
AD  - Faculty of Foreign Languages, Dokkyo University, Soka, JPN.
FAU - Tanimoto, Tetsuya
AU  - Tanimoto T
AD  - Internal Medicine, Jyoban Hospital of Tokiwa Foundation, Iwaki, JPN.
LA  - eng
PT  - Journal Article
DEP - 20230831
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10544433
OTO - NOTNLM
OT  - ai &amp; robotics healthcare
OT  - chatgpt
OT  - childcare
OT  - japan
OT  - performance and acceptance
COIS- The authors have declared financial relationships, which are detailed in the next 
      section.
EDAT- 2023/10/04 06:44
MHDA- 2023/10/04 06:45
PMCR- 2023/08/31
CRDT- 2023/10/04 04:18
PHST- 2023/08/31 00:00 [accepted]
PHST- 2023/10/04 06:45 [medline]
PHST- 2023/10/04 06:44 [pubmed]
PHST- 2023/10/04 04:18 [entrez]
PHST- 2023/08/31 00:00 [pmc-release]
AID - 10.7759/cureus.44484 [doi]
PST - epublish
SO  - Cureus. 2023 Aug 31;15(8):e44484. doi: 10.7759/cureus.44484. eCollection 2023 
      Aug.

PMID- 37056551
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230415
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 3
DP  - 2023 Mar
TI  - Atypical Nelson Syndrome Following Right Partial and Left Total Nephrectomy With 
      Incidental Bilateral Total Adrenalectomy of Renal Cell Carcinoma: A Chat 
      Generative Pre-Trained Transformer (ChatGPT)-Assisted Case Report and Literature 
      Review.
PG  - e36042
LID - 10.7759/cureus.36042 [doi]
LID - e36042
AB  - Nelson syndrome (NS) is a dangerous condition that can sometimes manifest after 
      bilateral adrenalectomy (BA), typically in treating Cushing's disease. It is 
      defined by the collection of systemic signs and symptoms that can arise in a 
      state where there are chronically and massively elevated levels of 
      adrenocorticotropic hormone (ACTH). Traditionally it may manifest from six months 
      to 24 years following the loss of both adrenal glands, with the meantime of 
      development being 15 years following BA. The diagnostic criteria are 
      controversial, with historically many different methods being used, ranging from 
      visual field defects and an enlarged pituitary corticotrophinoma to elevated 
      plasma ACTH levels and skin hyperpigmentation. What remains consistent between 
      criteria is that it is secondary to total BA, traditionally in treating 
      refractory Cushing's disease. We describe here a rare case of a patient diagnosed 
      with bilateral renal cell carcinoma (RCC) treated with right partial and left 
      total nephrectomy, and incidental BA, presenting with the symptoms and signs of 
      NS. Although NS classically presents following total BA for the treatment of 
      Cushing disease, further research is required to look for etiologies of 
      Nelson's-like pathology outside the context of Cushing's disease treatment, 
      thereby necessitating a change to the traditional diagnostic criteria for the 
      syndrome to identify cases that would otherwise go untreated. In addition, this 
      case report's outlining, drafting, and conclusions were written in part by or 
      with the support of Chat Generative Pre-Trained Transformer (ChatGPT), a large 
      language transformer open-source artificial intelligence.
CI  - Copyright © 2023, Schuppe et al.
FAU - Schuppe, Kyle
AU  - Schuppe K
AD  - Internal Medicine, Washington State University Elson S. Floyd College of 
      Medicine, Spokane, USA.
FAU - Burke, Skyler
AU  - Burke S
AD  - Internal Medicine, Washington State University Elson S. Floyd College of 
      Medicine, Spokane, USA.
FAU - Cohoe, Blake
AU  - Cohoe B
AD  - Internal Medicine, Washington State University Elson S. Floyd College of 
      Medicine, Spokane, USA.
FAU - Chang, Kevin
AU  - Chang K
AD  - Internal Medicine, Washington State University Elson S. Floyd College of 
      Medicine, Spokane, USA.
FAU - Lance, Raymond S
AU  - Lance RS
AD  - Urology, Washington State University Elson S. Floyd College of Medicine, Spokane, 
      USA.
FAU - Mroch, Henry
AU  - Mroch H
AD  - Nephrology, Washington State University Elson S. Floyd College of Medicine, 
      Spokane, USA.
LA  - eng
PT  - Case Reports
DEP - 20230312
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10089233
OTO - NOTNLM
OT  - adrenalectomy
OT  - adrenocorticotropic hormone
OT  - bilateral nephrectomy
OT  - chatgpt improved case report
OT  - cutaneous hyperpigmentation
OT  - immune check point inhibitor adverse side effect
OT  - nelson's syndrome
OT  - primary adrenal insufficiency
OT  - renal cell carcinoma
OT  - von hippel-lindau
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/04/15 06:00
MHDA- 2023/04/15 06:01
PMCR- 2023/03/12
CRDT- 2023/04/14 02:29
PHST- 2023/03/12 00:00 [accepted]
PHST- 2023/04/15 06:01 [medline]
PHST- 2023/04/14 02:29 [entrez]
PHST- 2023/04/15 06:00 [pubmed]
PHST- 2023/03/12 00:00 [pmc-release]
AID - 10.7759/cureus.36042 [doi]
PST - epublish
SO  - Cureus. 2023 Mar 12;15(3):e36042. doi: 10.7759/cureus.36042. eCollection 2023 
      Mar.

PMID- 38261400
OWN - NLM
STAT- In-Process
LR  - 20240403
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Linking)
VI  - 31
IP  - 4
DP  - 2024 Apr 3
TI  - Evaluating the ChatGPT family of models for biomedical reasoning and 
      classification.
PG  - 940-948
LID - 10.1093/jamia/ocad256 [doi]
AB  - OBJECTIVE: Large language models (LLMs) have shown impressive ability in 
      biomedical question-answering, but have not been adequately investigated for more 
      specific biomedical applications. This study investigates ChatGPT family of 
      models (GPT-3.5, GPT-4) in biomedical tasks beyond question-answering. MATERIALS 
      AND METHODS: We evaluated model performance with 11 122 samples for two 
      fundamental tasks in the biomedical domain-classification (n = 8676) and 
      reasoning (n = 2446). The first task involves classifying health advice in 
      scientific literature, while the second task is detecting causal relations in 
      biomedical literature. We used 20% of the dataset for prompt development, 
      including zero- and few-shot settings with and without chain-of-thought (CoT). We 
      then evaluated the best prompts from each setting on the remaining dataset, 
      comparing them to models using simple features (BoW with logistic regression) and 
      fine-tuned BioBERT models. RESULTS: Fine-tuning BioBERT produced the best 
      classification (F1: 0.800-0.902) and reasoning (F1: 0.851) results. Among LLM 
      approaches, few-shot CoT achieved the best classification (F1: 0.671-0.770) and 
      reasoning (F1: 0.682) results, comparable to the BoW model (F1: 0.602-0.753 and 
      0.675 for classification and reasoning, respectively). It took 78 h to obtain the 
      best LLM results, compared to 0.078 and 0.008 h for the top-performing BioBERT 
      and BoW models, respectively. DISCUSSION: The simple BoW model performed 
      similarly to the most complex LLM prompting. Prompt engineering required 
      significant investment. CONCLUSION: Despite the excitement around viral ChatGPT, 
      fine-tuning for two fundamental biomedical natural language processing tasks 
      remained the best strategy.
CI  - © The Author(s) 2024. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association. All rights reserved. For permissions, 
      please email: journals.permissions@oup.com.
FAU - Chen, Shan
AU  - Chen S
AUID- ORCID: 0000-0001-7999-7410
AD  - Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, Harvard 
      Medical School, Boston, MA 02115, United States.
AD  - Department of Radiation Oncology, Brigham and Women's Hospital/Dana-Farber Cancer 
      Institute, Boston, MA 02115, United States.
FAU - Li, Yingya
AU  - Li Y
AD  - Computational Health Informatics Program, Boston Children's Hospital, and Harvard 
      Medical School, Boston, MA 02115, United States.
FAU - Lu, Sheng
AU  - Lu S
AD  - Ubiquitous Knowledge Processing Lab (UKP Lab), Technical University of Darmstadt, 
      Darmstadt 64289, Germany.
FAU - Van, Hoang
AU  - Van H
AD  - Computational Health Informatics Program, Boston Children's Hospital, and Harvard 
      Medical School, Boston, MA 02115, United States.
FAU - Aerts, Hugo J W L
AU  - Aerts HJWL
AD  - Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, Harvard 
      Medical School, Boston, MA 02115, United States.
AD  - Department of Radiation Oncology, Brigham and Women's Hospital/Dana-Farber Cancer 
      Institute, Boston, MA 02115, United States.
AD  - Radiology and Nuclear Medicine, GROW &amp; CARIM, Maastricht University, Maastricht 
      6211 LK, Netherlands.
FAU - Savova, Guergana K
AU  - Savova GK
AD  - Computational Health Informatics Program, Boston Children's Hospital, and Harvard 
      Medical School, Boston, MA 02115, United States.
FAU - Bitterman, Danielle S
AU  - Bitterman DS
AD  - Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, Harvard 
      Medical School, Boston, MA 02115, United States.
AD  - Department of Radiation Oncology, Brigham and Women's Hospital/Dana-Farber Cancer 
      Institute, Boston, MA 02115, United States.
LA  - eng
GR  - R01 LM013486/LM/NLM NIH HHS/United States
GR  - R01GM114355/GF/NIH HHS/United States
GR  - R01GM114355/NH/NIH HHS/United States
PT  - Journal Article
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - biomedical research
OT  - classification
OT  - natural language processing
OT  - reasoning
EDAT- 2024/01/23 12:43
MHDA- 2024/01/23 12:43
CRDT- 2024/01/23 11:55
PHST- 2023/10/11 00:00 [received]
PHST- 2023/12/15 00:00 [revised]
PHST- 2023/12/19 00:00 [accepted]
PHST- 2024/01/23 12:43 [pubmed]
PHST- 2024/01/23 12:43 [medline]
PHST- 2024/01/23 11:55 [entrez]
AID - 7585396 [pii]
AID - 10.1093/jamia/ocad256 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2024 Apr 3;31(4):940-948. doi: 10.1093/jamia/ocad256.

PMID- 36943139
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20230329
LR  - 20230329
IS  - 1464-410X (Electronic)
IS  - 1464-4096 (Linking)
VI  - 131
IP  - 4
DP  - 2023 Apr
TI  - ChatGPT: what does it mean for scientific research and publishing?
PG  - 381-382
LID - 10.1111/bju.15995 [doi]
LA  - eng
PT  - News
PL  - England
TA  - BJU Int
JT  - BJU international
JID - 100886721
SB  - IM
EDAT- 2023/03/22 06:00
MHDA- 2023/03/24 06:00
CRDT- 2023/03/21 10:22
PHST- 2023/03/21 10:22 [entrez]
PHST- 2023/03/22 06:00 [pubmed]
PHST- 2023/03/24 06:00 [medline]
AID - 10.1111/bju.15995 [doi]
PST - ppublish
SO  - BJU Int. 2023 Apr;131(4):381-382. doi: 10.1111/bju.15995.

PMID- 37684390
OWN - NLM
STAT- Publisher
LR  - 20230908
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
DP  - 2023 Sep 7
TI  - Daily briefing: What's the endgame of OpenAI, the creator of ChatGPT?
LID - 10.1038/d41586-023-02849-2 [doi]
FAU - Graham, Flora
AU  - Graham F
LA  - eng
PT  - News
DEP - 20230907
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
EDAT- 2023/09/09 10:41
MHDA- 2023/09/09 10:41
CRDT- 2023/09/08 23:29
PHST- 2023/09/09 10:41 [medline]
PHST- 2023/09/09 10:41 [pubmed]
PHST- 2023/09/08 23:29 [entrez]
AID - 10.1038/d41586-023-02849-2 [pii]
AID - 10.1038/d41586-023-02849-2 [doi]
PST - aheadofprint
SO  - Nature. 2023 Sep 7. doi: 10.1038/d41586-023-02849-2.

PMID- 37433941
OWN - NLM
STAT- Publisher
LR  - 20230725
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
DP  - 2023 Jul 7
TI  - Daily briefing: The pros and cons of writing a paper with ChatGPT.
LID - 10.1038/d41586-023-02264-7 [doi]
FAU - Graham, Flora
AU  - Graham F
LA  - eng
PT  - News
DEP - 20230707
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
EDAT- 2023/07/12 01:07
MHDA- 2023/07/12 01:07
CRDT- 2023/07/11 23:29
PHST- 2023/07/12 01:07 [pubmed]
PHST- 2023/07/12 01:07 [medline]
PHST- 2023/07/11 23:29 [entrez]
AID - 10.1038/d41586-023-02264-7 [pii]
AID - 10.1038/d41586-023-02264-7 [doi]
PST - aheadofprint
SO  - Nature. 2023 Jul 7. doi: 10.1038/d41586-023-02264-7.

PMID- 37155982
OWN - NLM
STAT- MEDLINE
DCOM- 20230510
LR  - 20230516
IS  - 1538-0688 (Electronic)
IS  - 0190-535X (Linking)
VI  - 50
IP  - 3
DP  - 2023 Apr 21
TI  - Artificial Intelligence for Oncology Nursing Authors: Potential Utility and 
      Concerns About Large Language Model Chatbots.
PG  - 276-277
LID - 10.1188/23.ONF.276-277 [doi]
AB  - Artificial intelligence is a revolution in the computing and data scientist era 
      that has led to excitement and controversy in many fields, including research and 
      publishing. As we move further into the artificial intelligence.
FAU - Lyon, Debra
AU  - Lyon D
AD  - University of Florida.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Oncol Nurs Forum
JT  - Oncology nursing forum
JID - 7809033
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Oncology Nursing
MH  - Language
MH  - *Physicians
MH  - Publishing
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - chatbots
OT  - large language model
OT  - publishing
OT  - research
EDAT- 2023/05/08 18:42
MHDA- 2023/05/10 06:42
CRDT- 2023/05/08 16:53
PHST- 2023/05/10 06:42 [medline]
PHST- 2023/05/08 18:42 [pubmed]
PHST- 2023/05/08 16:53 [entrez]
AID - 10.1188/23.ONF.276-277 [doi]
PST - ppublish
SO  - Oncol Nurs Forum. 2023 Apr 21;50(3):276-277. doi: 10.1188/23.ONF.276-277.

PMID- 38445611
OWN - NLM
STAT- Publisher
LR  - 20240306
IS  - 1478-7083 (Electronic)
IS  - 0035-8843 (Linking)
DP  - 2024 Mar 6
TI  - The performance of large language models in intercollegiate Membership of the 
      Royal College of Surgeons examination.
LID - 10.1308/rcsann.2024.0023 [doi]
AB  - INTRODUCTION: Large language models (LLM), such as Chat Generative Pre-trained 
      Transformer (ChatGPT) and Bard utilise deep learning algorithms that have been 
      trained on a massive data set of text and code to generate human-like responses. 
      Several studies have demonstrated satisfactory performance on postgraduate 
      examinations, including the United States Medical Licensing Examination. We aimed 
      to evaluate artificial intelligence performance in Part A of the intercollegiate 
      Membership of the Royal College of Surgeons (MRCS) examination. METHODS: The MRCS 
      mock examination from Pastest, a commonly used question bank for examinees, was 
      used to assess the performance of three LLMs: GPT-3.5, GPT 4.0 and Bard. Three 
      hundred mock questions were input into the three LLMs, and the responses provided 
      by the LLMs were recorded and analysed. The pass mark was set at 70%. RESULTS: 
      The overall accuracies for GPT-3.5, GPT 4.0 and Bard were 67.33%, 71.67% and 
      65.67%, respectively (p = 0.27). The performances of GPT-3.5, GPT 4.0 and Bard in 
      Applied Basic Sciences were 68.89%, 72.78% and 63.33% (p = 0.15), respectively. 
      Furthermore, the three LLMs obtained correct answers in 65.00%, 70.00% and 69.17% 
      of the Principles of Surgery in General questions (p = 0.67). There were no 
      differences in performance in the overall and subcategories among the three LLMs. 
      CONCLUSIONS: Our findings demonstrated satisfactory performance for all three 
      LLMs in the MRCS Part A examination, with GPT 4.0 the only LLM that achieved the 
      pass mark set.
FAU - Chan, J
AU  - Chan J
AD  - Bristol Heart Institute, University of Bristol, UK.
FAU - Dong, T
AU  - Dong T
AD  - Bristol Heart Institute, University of Bristol, UK.
FAU - Angelini, G D
AU  - Angelini GD
AD  - Bristol Heart Institute, University of Bristol, UK.
LA  - eng
PT  - Journal Article
DEP - 20240306
PL  - England
TA  - Ann R Coll Surg Engl
JT  - Annals of the Royal College of Surgeons of England
JID - 7506860
SB  - IM
OTO - NOTNLM
OT  - Bard
OT  - ChatGPT
OT  - Large language models
OT  - MRCS
EDAT- 2024/03/06 12:42
MHDA- 2024/03/06 12:42
CRDT- 2024/03/06 08:16
PHST- 2024/03/06 12:42 [medline]
PHST- 2024/03/06 12:42 [pubmed]
PHST- 2024/03/06 08:16 [entrez]
AID - 10.1308/rcsann.2024.0023 [doi]
PST - aheadofprint
SO  - Ann R Coll Surg Engl. 2024 Mar 6. doi: 10.1308/rcsann.2024.0023.

PMID- 37976093
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231204
IS  - 2562-0959 (Electronic)
IS  - 2562-0959 (Linking)
VI  - 6
DP  - 2023 Nov 17
TI  - Evaluation of ChatGPT Dermatology Responses to Common Patient Queries.
PG  - e49280
LID - 10.2196/49280 [doi]
LID - e49280
FAU - Ferreira, Alana L
AU  - Ferreira AL
AUID- ORCID: 0000-0001-6494-9598
AD  - Department of Dermatology, Perelman School of Medicine, University of 
      Pennsylvania, Philadelphia, PA, United States.
FAU - Chu, Brian
AU  - Chu B
AUID- ORCID: 0000-0002-0803-5529
AD  - Department of Dermatology, Perelman School of Medicine, University of 
      Pennsylvania, Philadelphia, PA, United States.
FAU - Grant-Kels, Jane M
AU  - Grant-Kels JM
AUID- ORCID: 0000-0002-1844-8415
AD  - Department of Dermatology, University of Connecticut Health Center, Farmington, 
      CT, United States.
AD  - Department of Dermatology, University of Florida, Gainesville, FL, United States.
FAU - Ogunleye, Temitayo
AU  - Ogunleye T
AUID- ORCID: 0000-0002-9465-347X
AD  - Department of Dermatology, Perelman School of Medicine, University of 
      Pennsylvania, Philadelphia, PA, United States.
FAU - Lipoff, Jules B
AU  - Lipoff JB
AUID- ORCID: 0000-0002-0557-4260
AD  - Department of Dermatology, Lewis Katz School of Medicine, Temple University, 
      Philadelphia, PA, United States.
LA  - eng
PT  - Journal Article
DEP - 20231117
PL  - Canada
TA  - JMIR Dermatol
JT  - JMIR dermatology
JID - 101770607
PMC - PMC10692871
OTO - NOTNLM
OT  - AI
OT  - AI tool
OT  - ChatGPT
OT  - GPT-4
OT  - artificial intelligence
OT  - dermatologist
OT  - dermatology
OT  - information resource
OT  - medical advice
OT  - patient queries
OT  - response evaluation
OT  - skin
OT  - skin condition
OT  - tool
COIS- Conflicts of Interest: JMGK is a medical advisor to Dermasensor. The authors have 
      no further interests to declare.
EDAT- 2023/11/17 15:29
MHDA- 2023/11/17 15:30
PMCR- 2023/11/17
CRDT- 2023/11/17 11:54
PHST- 2023/05/23 00:00 [received]
PHST- 2023/10/30 00:00 [accepted]
PHST- 2023/10/24 00:00 [revised]
PHST- 2023/11/17 15:30 [medline]
PHST- 2023/11/17 15:29 [pubmed]
PHST- 2023/11/17 11:54 [entrez]
PHST- 2023/11/17 00:00 [pmc-release]
AID - v6i1e49280 [pii]
AID - 10.2196/49280 [doi]
PST - epublish
SO  - JMIR Dermatol. 2023 Nov 17;6:e49280. doi: 10.2196/49280.

PMID- 37615142
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20231102
LR  - 20240302
IS  - 0970-258X (Print)
IS  - 0970-258X (Linking)
VI  - 36
IP  - 1
DP  - 2023 Jan-Feb
TI  - Chatbots, ChatGPT, and Scholarly Manuscripts: WAME Recommendations on ChatGPT and 
      Chatbots in relation to scholarly publications.
PG  - 1-4
LID - 10.25259/NMJI_365_23 [pii]
FAU - Zielinski, Chris
AU  - Zielinski C
AD  - Vice President, WAME; Centre for Global Health, University of Winchester, UK.
FAU - Winker, Margaret
AU  - Winker M
AD  - President, WAME; Associate Editor, Journal of Gastroenterology and Hepatology; 
      Director, Jawaharlal Institute of Postgraduate Medical Education and Research, 
      Puducherry, India.
FAU - Aggarwal, Rakesh
AU  - Aggarwal R
AD  - President, WAME; Associate Editor, Journal of Gastroenterology and Hepatology; 
      Director, Jawaharlal Institute of Postgraduate Medical Education and Research, 
      Puducherry, India.
FAU - Ferris, Lorraine
AU  - Ferris L
AD  - WAME; Dalla Lana School of Public Health, University of Toronto, Canada.
FAU - Heinemann, Markus
AU  - Heinemann M
AD  - WAME; The Thoracic and Cardiovascular Surgeon, Manila, The Philippines.
FAU - Lapeña, Jose Florencio
AU  - Lapeña JF
AD  - WAME; Philippine Journal of Otolaryngology Head &amp; Neck Surgery University of the 
      Philippines, Manila, The Philippines.
FAU - Pai, Sanjay
AU  - Pai S
AD  - WAME; The National Medical Journal of India, India.
FAU - Ing, Edsel
AU  - Ing E
AD  - WAME; Canadian Journal of Ophthalmology; University of Toronto, Canada.
FAU - Citrome, Leslie
AU  - Citrome L
AD  - WAME; Current Medical Research and Opinion; Psychiatry for Clinical Therapeutics; 
      Psychiatry and Behavioral Sciences New York Medical College, USA on behalf of the 
      WAME Board.
LA  - eng
PT  - Editorial
PL  - India
TA  - Natl Med J India
JT  - The National medical journal of India
JID - 8809315
SB  - IM
EDAT- 2023/08/24 13:43
MHDA- 2023/08/24 13:44
CRDT- 2023/08/24 06:07
PHST- 2023/08/24 13:44 [medline]
PHST- 2023/08/24 13:43 [pubmed]
PHST- 2023/08/24 06:07 [entrez]
AID - 10.25259/NMJI_365_23 [pii]
AID - 10.25259/NMJI_365_23 [doi]
PST - ppublish
SO  - Natl Med J India. 2023 Jan-Feb;36(1):1-4. doi: 10.25259/NMJI_365_23.

PMID- 37505381
OWN - NLM
STAT- MEDLINE
DCOM- 20231102
LR  - 20240108
IS  - 1826-6983 (Electronic)
IS  - 0033-8362 (Linking)
VI  - 128
IP  - 11
DP  - 2023 Nov
TI  - A critical examination and suggestions for large language models for structured 
      reporting in radiology.
PG  - 1441-1442
LID - 10.1007/s11547-023-01688-5 [doi]
FAU - Ray, Partha Pratim
AU  - Ray PP
AUID- ORCID: 0000-0003-2306-2792
AD  - Sikkim University, Gangtok, India. ppray@cus.ac.in.
LA  - eng
PT  - Letter
DEP - 20230728
PL  - Italy
TA  - Radiol Med
JT  - La Radiologia medica
JID - 0177625
SB  - IM
MH  - Humans
MH  - Radiography
MH  - *Radiology
OTO - NOTNLM
OT  - ChatGPT
OT  - Generative AI
OT  - Large language model
OT  - Radiology
OT  - Structured reporting
EDAT- 2023/07/28 13:11
MHDA- 2023/11/02 12:42
CRDT- 2023/07/28 11:10
PHST- 2023/06/18 00:00 [received]
PHST- 2023/07/17 00:00 [accepted]
PHST- 2023/11/02 12:42 [medline]
PHST- 2023/07/28 13:11 [pubmed]
PHST- 2023/07/28 11:10 [entrez]
AID - 10.1007/s11547-023-01688-5 [pii]
AID - 10.1007/s11547-023-01688-5 [doi]
PST - ppublish
SO  - Radiol Med. 2023 Nov;128(11):1441-1442. doi: 10.1007/s11547-023-01688-5. Epub 
      2023 Jul 28.

PMID- 37384388
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230726
IS  - 2369-3762 (Print)
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Jun 29
TI  - Performance of GPT-3.5 and GPT-4 on the Japanese Medical Licensing Examination: 
      Comparison Study.
PG  - e48002
LID - 10.2196/48002 [doi]
LID - e48002
AB  - BACKGROUND: The competence of ChatGPT (Chat Generative Pre-Trained Transformer) 
      in non-English languages is not well studied. OBJECTIVE: This study compared the 
      performances of GPT-3.5 (Generative Pre-trained Transformer) and GPT-4 on the 
      Japanese Medical Licensing Examination (JMLE) to evaluate the reliability of 
      these models for clinical reasoning and medical knowledge in non-English 
      languages. METHODS: This study used the default mode of ChatGPT, which is based 
      on GPT-3.5; the GPT-4 model of ChatGPT Plus; and the 117th JMLE in 2023. A total 
      of 254 questions were included in the final analysis, which were categorized into 
      3 types, namely general, clinical, and clinical sentence questions. RESULTS: The 
      results indicated that GPT-4 outperformed GPT-3.5 in terms of accuracy, 
      particularly for general, clinical, and clinical sentence questions. GPT-4 also 
      performed better on difficult questions and specific disease questions. 
      Furthermore, GPT-4 achieved the passing criteria for the JMLE, indicating its 
      reliability for clinical reasoning and medical knowledge in non-English 
      languages. CONCLUSIONS: GPT-4 could become a valuable tool for medical education 
      and clinical support in non-English-speaking regions, such as Japan.
CI  - ©Soshi Takagi, Takashi Watari, Ayano Erabi, Kota Sakaguchi. Originally published 
      in JMIR Medical Education (https://mededu.jmir.org), 29.06.2023.
FAU - Takagi, Soshi
AU  - Takagi S
AUID- ORCID: 0009-0004-3211-1626
AD  - Faculty of Medicine, Shimane University, Izumo, Japan.
FAU - Watari, Takashi
AU  - Watari T
AUID- ORCID: 0000-0002-9322-8455
AD  - Faculty of Medicine, Shimane University, Izumo, Japan.
AD  - General Medicine Center, Shimane University Hospital, Izumo, Japan.
AD  - Department of Internal Medicine, University of Michigan Medical School, Ann 
      Arbor, MI, United States.
AD  - Medicine Service, VA Ann Arbor Healthcare System, Ann Arbor, MI, United States.
FAU - Erabi, Ayano
AU  - Erabi A
AUID- ORCID: 0009-0003-1871-3543
AD  - Faculty of Medicine, Shimane University, Izumo, Japan.
FAU - Sakaguchi, Kota
AU  - Sakaguchi K
AUID- ORCID: 0000-0002-5169-6613
AD  - General Medicine Center, Shimane University Hospital, Izumo, Japan.
LA  - eng
PT  - Journal Article
DEP - 20230629
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
PMC - PMC10365615
OTO - NOTNLM
OT  - AI
OT  - Chat Generative Pre-trained Transformer
OT  - ChatGPT
OT  - GPT-4
OT  - Generative Pre-trained Transformer 4
OT  - Japanese Medical Licensing Examination
OT  - artificial intelligence
OT  - clinical support
OT  - learning model
OT  - medical education
OT  - medical licensing
COIS- Conflicts of Interest: None declared.
EDAT- 2023/06/29 19:12
MHDA- 2023/06/29 19:13
PMCR- 2023/06/29
CRDT- 2023/06/29 12:07
PHST- 2023/04/07 00:00 [received]
PHST- 2023/06/14 00:00 [accepted]
PHST- 2023/05/11 00:00 [revised]
PHST- 2023/06/29 19:13 [medline]
PHST- 2023/06/29 19:12 [pubmed]
PHST- 2023/06/29 12:07 [entrez]
PHST- 2023/06/29 00:00 [pmc-release]
AID - v9i1e48002 [pii]
AID - 10.2196/48002 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Jun 29;9:e48002. doi: 10.2196/48002.

PMID- 36754723
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20230228
LR  - 20230228
IS  - 2589-7500 (Electronic)
IS  - 2589-7500 (Linking)
VI  - 5
IP  - 3
DP  - 2023 Mar
TI  - ChatGPT: friend or foe?
PG  - e102
LID - S2589-7500(23)00023-7 [pii]
LID - 10.1016/S2589-7500(23)00023-7 [doi]
FAU - The Lancet Digital Health
AU  - The Lancet Digital Health
LA  - eng
PT  - Editorial
DEP - 20230206
PL  - England
TA  - Lancet Digit Health
JT  - The Lancet. Digital health
JID - 101751302
SB  - IM
EDAT- 2023/02/09 06:00
MHDA- 2023/02/09 06:01
CRDT- 2023/02/08 22:01
PHST- 2023/02/09 06:00 [pubmed]
PHST- 2023/02/09 06:01 [medline]
PHST- 2023/02/08 22:01 [entrez]
AID - S2589-7500(23)00023-7 [pii]
AID - 10.1016/S2589-7500(23)00023-7 [doi]
PST - ppublish
SO  - Lancet Digit Health. 2023 Mar;5(3):e102. doi: 10.1016/S2589-7500(23)00023-7. Epub 
      2023 Feb 6.

PMID- 37704854
OWN - NLM
STAT- Publisher
LR  - 20231003
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
DP  - 2023 Sep 14
TI  - Why Japan is building its own version of ChatGPT.
LID - 10.1038/d41586-023-02868-z [doi]
FAU - Hornyak, Tim
AU  - Hornyak T
LA  - eng
PT  - News
DEP - 20230914
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
OTO - NOTNLM
OT  - Communication
OT  - Computer science
OT  - Machine learning
EDAT- 2023/09/14 00:42
MHDA- 2023/09/14 00:42
CRDT- 2023/09/13 23:33
PHST- 2023/09/14 00:42 [pubmed]
PHST- 2023/09/14 00:42 [medline]
PHST- 2023/09/13 23:33 [entrez]
AID - 10.1038/d41586-023-02868-z [pii]
AID - 10.1038/d41586-023-02868-z [doi]
PST - aheadofprint
SO  - Nature. 2023 Sep 14. doi: 10.1038/d41586-023-02868-z.

PMID- 37480927
OWN - NLM
STAT- Publisher
LR  - 20230722
IS  - 1943-4723 (Electronic)
IS  - 0002-8177 (Linking)
DP  - 2023 Jul 21
TI  - Transforming dentistry with ChatGPT: A guide to optimizing patient care.
LID - S0002-8177(23)00339-2 [pii]
LID - 10.1016/j.adaj.2023.06.003 [doi]
FAU - Tussie, Camila
AU  - Tussie C
LA  - eng
PT  - Editorial
DEP - 20230721
PL  - England
TA  - J Am Dent Assoc
JT  - Journal of the American Dental Association (1939)
JID - 7503060
SB  - IM
EDAT- 2023/07/23 01:11
MHDA- 2023/07/23 01:11
CRDT- 2023/07/22 18:45
PHST- 2023/04/10 00:00 [received]
PHST- 2023/05/23 00:00 [revised]
PHST- 2023/06/13 00:00 [accepted]
PHST- 2023/07/23 01:11 [medline]
PHST- 2023/07/23 01:11 [pubmed]
PHST- 2023/07/22 18:45 [entrez]
AID - S0002-8177(23)00339-2 [pii]
AID - 10.1016/j.adaj.2023.06.003 [doi]
PST - aheadofprint
SO  - J Am Dent Assoc. 2023 Jul 21:S0002-8177(23)00339-2. doi: 
      10.1016/j.adaj.2023.06.003.

PMID- 37045954
OWN - NLM
STAT- Publisher
LR  - 20230802
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
DP  - 2023 Apr 12
TI  - How I use ChatGPT responsibly in my teaching.
LID - 10.1038/d41586-023-01026-9 [doi]
FAU - Yang, Hong
AU  - Yang H
LA  - eng
PT  - News
DEP - 20230412
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
OTO - NOTNLM
OT  - Careers
OT  - Lab life
OT  - Research management
EDAT- 2023/04/13 06:00
MHDA- 2023/04/13 06:00
CRDT- 2023/04/12 23:22
PHST- 2023/04/13 06:00 [pubmed]
PHST- 2023/04/13 06:00 [medline]
PHST- 2023/04/12 23:22 [entrez]
AID - 10.1038/d41586-023-01026-9 [pii]
AID - 10.1038/d41586-023-01026-9 [doi]
PST - aheadofprint
SO  - Nature. 2023 Apr 12. doi: 10.1038/d41586-023-01026-9.

PMID- 36481949
OWN - NLM
STAT- Publisher
LR  - 20240216
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
DP  - 2022 Dec 8
TI  - Are ChatGPT and AlphaCode going to replace programmers?
LID - 10.1038/d41586-022-04383-z [doi]
FAU - Castelvecchi, Davide
AU  - Castelvecchi D
LA  - eng
PT  - News
DEP - 20221208
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
OTO - NOTNLM
OT  - Machine learning
OT  - Mathematics and computing
EDAT- 2022/12/10 06:00
MHDA- 2022/12/10 06:00
CRDT- 2022/12/09 00:24
PHST- 2022/12/10 06:00 [pubmed]
PHST- 2022/12/10 06:00 [medline]
PHST- 2022/12/09 00:24 [entrez]
AID - 10.1038/d41586-022-04383-z [pii]
AID - 10.1038/d41586-022-04383-z [doi]
PST - aheadofprint
SO  - Nature. 2022 Dec 8. doi: 10.1038/d41586-022-04383-z.

PMID- 37222278
OWN - NLM
STAT- MEDLINE
DCOM- 20230925
LR  - 20240311
IS  - 1546-3141 (Electronic)
IS  - 0361-803X (Linking)
VI  - 221
IP  - 4
DP  - 2023 Oct
TI  - Accuracy of Information Provided by ChatGPT Regarding Liver Cancer Surveillance 
      and Diagnosis.
PG  - 556-559
LID - 10.2214/AJR.23.29493 [doi]
FAU - Cao, Jennie J
AU  - Cao JJ
AD  - Stanford University School of Medicine, Stanford, CA.
FAU - Kwon, Daniel H
AU  - Kwon DH
AD  - University of California, San Francisco School of Medicine, San Francisco, CA.
FAU - Ghaziani, Tara T
AU  - Ghaziani TT
AD  - Stanford University School of Medicine, Stanford, CA.
FAU - Kwo, Paul
AU  - Kwo P
AD  - Stanford University School of Medicine, Stanford, CA.
FAU - Tse, Gary
AU  - Tse G
AD  - University of California, Los Angeles David Geffen School of Medicine, Los 
      Angeles, CA.
FAU - Kesselman, Andrew
AU  - Kesselman A
AD  - Stanford University School of Medicine, Stanford, CA.
FAU - Kamaya, Aya
AU  - Kamaya A
AD  - Stanford University School of Medicine, Stanford, CA.
FAU - Tse, Justin R
AU  - Tse JR
AD  - Stanford University School of Medicine, Stanford, CA, jrtse@stanford.edu.
LA  - eng
PT  - Journal Article
DEP - 20230524
PL  - United States
TA  - AJR Am J Roentgenol
JT  - AJR. American journal of roentgenology
JID - 7708173
SB  - IM
MH  - Humans
MH  - *Liver Neoplasms/diagnostic imaging
MH  - *Carcinoma, Hepatocellular
OAB - ChatGPT did not reliably provide accurate information to 20 questions about liver 
      cancer surveillance and diagnosis, as assessed by six physicians who actively 
      diagnose and/or treat liver cancer. Answers deemed inaccurate commonly related to 
      questions on specific LI-RADS categories and included contradictory or falsely 
      reassuring, if not wrong, information.
OABL- eng
EDAT- 2023/05/24 13:08
MHDA- 2023/09/25 06:42
CRDT- 2023/05/24 07:03
PHST- 2023/09/25 06:42 [medline]
PHST- 2023/05/24 13:08 [pubmed]
PHST- 2023/05/24 07:03 [entrez]
AID - 10.2214/AJR.23.29493 [doi]
PST - ppublish
SO  - AJR Am J Roentgenol. 2023 Oct;221(4):556-559. doi: 10.2214/AJR.23.29493. Epub 
      2023 May 24.

PMID- 37410934
OWN - NLM
STAT- MEDLINE
DCOM- 20231204
LR  - 20240218
IS  - 1572-0241 (Electronic)
IS  - 0002-9270 (Print)
IS  - 0002-9270 (Linking)
VI  - 118
IP  - 12
DP  - 2023 Dec 1
TI  - Evaluation of the Potential Utility of an Artificial Intelligence Chatbot in 
      Gastroesophageal Reflux Disease Management.
PG  - 2276-2279
LID - 10.14309/ajg.0000000000002397 [doi]
AB  - INTRODUCTION: Artificial intelligence chatbots could serve as an information 
      resource for patients and a tool for clinicians. Their ability to respond 
      appropriately to questions regarding gastroesophageal reflux disease is unknown. 
      METHODS: Twenty-three prompts regarding gastroesophageal reflux disease 
      management were submitted to ChatGPT, and responses were rated by 3 
      gastroenterologists and 8 patients. RESULTS: ChatGPT provided largely appropriate 
      responses (91.3%), although with some inappropriateness (8.7%) and inconsistency. 
      Most responses (78.3%) contained at least some specific guidance. Patients 
      considered this a useful tool (100%). DISCUSSION: ChatGPT's performance 
      demonstrates the potential for this technology in health care, although also its 
      limitations in its current state.
CI  - Copyright © 2023 by The American College of Gastroenterology.
FAU - Henson, Jacqueline B
AU  - Henson JB
AUID- ORCID: 0000-0003-3488-6615
AD  - Division of Gastroenterology, Department of Medicine, Duke University School of 
      Medicine, Durham, North Carolina, USA.
FAU - Glissen Brown, Jeremy R
AU  - Glissen Brown JR
AD  - Division of Gastroenterology, Department of Medicine, Duke University School of 
      Medicine, Durham, North Carolina, USA.
FAU - Lee, Joshua P
AU  - Lee JP
AD  - Division of Gastroenterology, Department of Medicine, Duke University School of 
      Medicine, Durham, North Carolina, USA.
FAU - Patel, Amit
AU  - Patel A
AD  - Division of Gastroenterology, Department of Medicine, Duke University School of 
      Medicine, Durham, North Carolina, USA.
AD  - Division of Gastroenterology, Durham Veterans Affairs Medical Center, Durham, 
      North Carolina, USA.
FAU - Leiman, David A
AU  - Leiman DA
AD  - Division of Gastroenterology, Department of Medicine, Duke University School of 
      Medicine, Durham, North Carolina, USA.
AD  - Duke Clinical Research Institute, Durham, North Carolina, USA.
LA  - eng
GR  - T32 DK007568/DK/NIDDK NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
DEP - 20230710
PL  - United States
TA  - Am J Gastroenterol
JT  - The American journal of gastroenterology
JID - 0421030
SB  - IM
MH  - Humans
MH  - Artificial Intelligence
MH  - Software
MH  - *Gastroenterologists
MH  - *Gastroesophageal Reflux/diagnosis/therapy
PMC - PMC10834834
MID - NIHMS1914808
COIS- Potential competing interests: JRGB has served as a consultant for Medtronic. The 
      other authors disclose no relevant conflicts of interest.
EDAT- 2023/07/06 19:12
MHDA- 2023/12/04 12:42
PMCR- 2024/12/01
CRDT- 2023/07/06 15:43
PHST- 2023/03/30 00:00 [received]
PHST- 2023/06/13 00:00 [accepted]
PHST- 2024/12/01 00:00 [pmc-release]
PHST- 2023/12/04 12:42 [medline]
PHST- 2023/07/06 19:12 [pubmed]
PHST- 2023/07/06 15:43 [entrez]
AID - 00000434-202312000-00031 [pii]
AID - 10.14309/ajg.0000000000002397 [doi]
PST - ppublish
SO  - Am J Gastroenterol. 2023 Dec 1;118(12):2276-2279. doi: 
      10.14309/ajg.0000000000002397. Epub 2023 Jul 10.

PMID- 37038563
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230412
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 3
DP  - 2023 Mar
TI  - A Rare Co-occurrence of Monkeypox Encephalitis and Neurosyphilis.
PG  - e35945
LID - 10.7759/cureus.35945 [doi]
LID - e35945
AB  - Monkeypox (MPOX according to the Centers for Disease Control and Prevention) has 
      been a disease of interest in populations with high-risk sexual behavior. As 
      sporadic outbreaks of MPOX have led to a worldwide spread, it has been declared a 
      public health emergency by the World Health Organization. Here, we describe the 
      case of a 44-year-old male with high-risk sexual behavior who presented with 
      typical rashes of MPOX and altered mental status. MPOX polymerase chain reaction 
      from the skin lesion and cerebrospinal fluid-Venereal Disease Research Laboratory 
      tests were positive, raising the possibility of concomitant infection with 
      neurosyphilis. The patient was treated with tecovirimat and aqueous penicillin G 
      resulting in an improvement in the patient's clinical condition. Our case 
      describes that MPOX has the potential to cause central nervous system 
      manifestations through possibly a direct viral invasion or an immune-meditated 
      insult.
CI  - Copyright © 2023, Sharma et al.
FAU - Sharma, Rohit
AU  - Sharma R
AD  - Medicine, Geisinger Health System, Wilkes-Barre, USA.
AD  - Clinical Research, Dresden International University, Dresden, DEU.
FAU - Nguyen-Luu, Tristan
AU  - Nguyen-Luu T
AD  - Internal Medicine, Geisinger Health System, Wilkes-Barre, USA.
FAU - Dhaubhadel, Pragya
AU  - Dhaubhadel P
AD  - Infectious Disease, Geisinger Health System, Scranton, USA.
FAU - Sharma, Amit
AU  - Sharma A
AD  - Infectious Disease, Geisinger Health System, Scranton, USA.
FAU - Naik, Roopa
AU  - Naik R
AD  - Internal Medicine, Geisinger Health System, Wilkes-Barre, USA.
LA  - eng
PT  - Case Reports
DEP - 20230309
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10082623
OTO - NOTNLM
OT  - chatgpt
OT  - chatgpt improved case report
OT  - monkeypox coinfection
OT  - monkeypox encephalitis
OT  - monkeypox virus
OT  - monkeypox-associated cns disease
OT  - neurosyphillis
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/04/12 06:00
MHDA- 2023/04/12 06:01
PMCR- 2023/03/09
CRDT- 2023/04/11 01:48
PHST- 2023/03/09 00:00 [accepted]
PHST- 2023/04/12 06:01 [medline]
PHST- 2023/04/11 01:48 [entrez]
PHST- 2023/04/12 06:00 [pubmed]
PHST- 2023/03/09 00:00 [pmc-release]
AID - 10.7759/cureus.35945 [doi]
PST - epublish
SO  - Cureus. 2023 Mar 9;15(3):e35945. doi: 10.7759/cureus.35945. eCollection 2023 Mar.

PMID- 36517680
OWN - NLM
STAT- Publisher
LR  - 20240216
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
DP  - 2022 Dec 12
TI  - Daily briefing: Will ChatGPT kill the essay assignment?
LID - 10.1038/d41586-022-04437-2 [doi]
FAU - Graham, Flora
AU  - Graham F
LA  - eng
PT  - News
DEP - 20221212
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
EDAT- 2022/12/15 06:00
MHDA- 2022/12/15 06:00
CRDT- 2022/12/14 23:35
PHST- 2022/12/14 23:35 [entrez]
PHST- 2022/12/15 06:00 [pubmed]
PHST- 2022/12/15 06:00 [medline]
AID - 10.1038/d41586-022-04437-2 [pii]
AID - 10.1038/d41586-022-04437-2 [doi]
PST - aheadofprint
SO  - Nature. 2022 Dec 12. doi: 10.1038/d41586-022-04437-2.

PMID- 37863153
OWN - NLM
STAT- MEDLINE
DCOM- 20240214
LR  - 20240214
IS  - 1558-349X (Electronic)
IS  - 1546-1440 (Linking)
VI  - 21
IP  - 2
DP  - 2024 Feb
TI  - Enhancing Patient Communication With Chat-GPT in Radiology: Evaluating the 
      Efficacy and Readability of Answers to Common Imaging-Related Questions.
PG  - 353-359
LID - S1546-1440(23)00775-5 [pii]
LID - 10.1016/j.jacr.2023.09.011 [doi]
AB  - PURPOSE: To assess ChatGPT's accuracy, relevance, and readability in answering 
      patients' common imaging-related questions and examine the effect of a simple 
      prompt. METHODS: A total of 22 imaging-related questions were developed from 
      categories previously described as important to patients, as follows: safety, the 
      radiology report, the procedure, preparation before imaging, meaning of terms, 
      and medical staff. These questions were posed to ChatGPT with and without a short 
      prompt instructing the model to provide an accurate and easy-to-understand 
      response for the average person. Four board-certified radiologists evaluated the 
      answers for accuracy, consistency, and relevance. Two patient advocates also 
      reviewed responses for their utility for patients. Readability was assessed using 
      the Flesch Kincaid Grade Level. Statistical comparisons were performed using χ(2) 
      and paired t tests. RESULTS: A total of 264 answers were assessed for both 
      unprompted and prompted questions. Unprompted responses were accurate 83% of the 
      time (218 of 264), which did not significantly change for prompted responses (87% 
      [229 of 264]; P&nbsp;= .2). The consistency of the responses increased from 72% (63 of 
      88) to 86% (76 of 88) when prompts were given (P&nbsp;= .02). Nearly all responses 
      (99% [261 of 264]) were at least partially relevant for both question types. 
      Fewer unprompted responses were considered fully relevant at 67% (176 of 264), 
      although this increased significantly to 80% when prompts were given (210 of 264; 
      P&nbsp;= .001). The average Flesch Kincaid Grade Level was high at 13.6 [CI, 
      12.9-14.2], unchanged with the prompt (13.0 [CI, 12.41-13.60], P&nbsp;= .2). None of 
      the responses reached the eighth-grade readability level recommended for 
      patient-facing materials. DISCUSSION: ChatGPT demonstrates the potential to 
      respond accurately, consistently, and relevantly to patients' imaging-related 
      questions. However, imperfect accuracy and high complexity necessitate oversight 
      before implementation. Prompts reduced response variability and yielded 
      more-targeted information, but they did not improve readability. ChatGPT has the 
      potential to increase accessibility to health information and streamline the 
      production of patient-facing educational materials; however, its current 
      limitations require cautious implementation and further research.
CI  - Copyright © 2023. Published by Elsevier Inc.
FAU - Gordon, Emile B
AU  - Gordon EB
AD  - Department of Radiology, University of Pittsburgh Medical Center, Pittsburgh, 
      Pennsylvania; Clinical Associate, Department of Radiology, Duke University 
      Medical Center, Department of Radiology, Durham, North Carolina. Electronic 
      address: emile.gordon@duke.edu.
FAU - Towbin, Alexander J
AU  - Towbin AJ
AD  - Professor and Associate Chief, Department of Radiology (Clinical Operations and 
      Informatics), Neil D. Johnson Chair of Radiology Informatics, University of 
      Cincinnati, Cincinnati, Ohio.
FAU - Wingrove, Peter
AU  - Wingrove P
AD  - Department of Radiology, University of Pittsburgh Medical Center, Pittsburgh, 
      Pennsylvania.
FAU - Shafique, Umber
AU  - Shafique U
AD  - Assistant Professor, Department of Radiology, Indiana University School of 
      Medicine, Indianapolis, Indiana.
FAU - Haas, Brian
AU  - Haas B
AD  - Professor, Department of Radiology and Biomedical Imaging, University of 
      California San Francisco, San Francisco, California.
FAU - Kitts, Andrea B
AU  - Kitts AB
AD  - Lung Cancer Patient Advocate, Rescue Lung Society, Amesbury, Massachusetts.
FAU - Feldman, Jill
AU  - Feldman J
AD  - Lung Cancer Patient Advocate, EGFR (Epidermal Growth Factor Receptor) Resisters, 
      Deerfield, Illinois.
FAU - Furlan, Alessandro
AU  - Furlan A
AD  - Associate Professor, Department of Radiology, Section Chief, Abdominal Imaging, 
      and Medical Director, Radiology Practice and Operational Excellence, University 
      of Pittsburgh Medical Center, Pittsburgh, Pennsylvania.
LA  - eng
PT  - Journal Article
DEP - 20231018
PL  - United States
TA  - J Am Coll Radiol
JT  - Journal of the American College of Radiology : JACR
JID - 101190326
SB  - IM
MH  - Humans
MH  - *Comprehension
MH  - Radiography
MH  - *Radiology
MH  - Radiologists
MH  - Communication
OTO - NOTNLM
OT  - Communication
OT  - artificial intelligence
OT  - language model
EDAT- 2023/10/21 05:42
MHDA- 2024/02/12 15:42
CRDT- 2023/10/20 19:27
PHST- 2023/07/24 00:00 [received]
PHST- 2023/09/12 00:00 [revised]
PHST- 2023/09/20 00:00 [accepted]
PHST- 2024/02/12 15:42 [medline]
PHST- 2023/10/21 05:42 [pubmed]
PHST- 2023/10/20 19:27 [entrez]
AID - S1546-1440(23)00775-5 [pii]
AID - 10.1016/j.jacr.2023.09.011 [doi]
PST - ppublish
SO  - J Am Coll Radiol. 2024 Feb;21(2):353-359. doi: 10.1016/j.jacr.2023.09.011. Epub 
      2023 Oct 18.

PMID- 38470237
OWN - NLM
STAT- MEDLINE
DCOM- 20240313
LR  - 20240313
IS  - 1527-1315 (Electronic)
IS  - 0033-8419 (Linking)
VI  - 310
IP  - 3
DP  - 2024 Mar
TI  - Collaborative Enhancement of Consistency and Accuracy in US Diagnosis of Thyroid 
      Nodules Using Large Language Models.
PG  - e232255
LID - 10.1148/radiol.232255 [doi]
AB  - Background Large language models (LLMs) hold substantial promise for medical 
      imaging interpretation. However, there is a lack of studies on their feasibility 
      in handling reasoning questions associated with medical diagnosis. Purpose To 
      investigate the viability of leveraging three publicly available LLMs to enhance 
      consistency and diagnostic accuracy in medical imaging based on standardized 
      reporting, with pathology as the reference standard. Materials and Methods US 
      images of thyroid nodules with pathologic results were retrospectively collected 
      from a tertiary referral hospital between July 2022 and December 2022 and used to 
      evaluate malignancy diagnoses generated by three LLMs-OpenAI's ChatGPT 3.5, 
      ChatGPT 4.0, and Google's Bard. Inter- and intra-LLM agreement of diagnosis were 
      evaluated. Then, diagnostic performance, including accuracy, sensitivity, 
      specificity, and area under the receiver operating characteristic curve (AUC), 
      was evaluated and compared for the LLMs and three interactive approaches: human 
      reader combined with LLMs, image-to-text model combined with LLMs, and an 
      end-to-end convolutional neural network model. Results A total of 1161 US images 
      of thyroid nodules (498 benign, 663 malignant) from 725 patients (mean age, 42.2 
      years ± 14.1 [SD]; 516 women) were evaluated. ChatGPT 4.0 and Bard displayed 
      substantial to almost perfect intra-LLM agreement (κ range, 0.65-0.86 [95% CI: 
      0.64, 0.86]), while ChatGPT 3.5 showed fair to substantial agreement (κ range, 
      0.36-0.68 [95% CI: 0.36, 0.68]). ChatGPT 4.0 had an accuracy of 78%-86% (95% CI: 
      76%, 88%) and sensitivity of 86%-95% (95% CI: 83%, 96%), compared with 74%-86% 
      (95% CI: 71%, 88%) and 74%-91% (95% CI: 71%, 93%), respectively, for Bard. 
      Moreover, with ChatGPT 4.0, the image-to-text-LLM strategy exhibited an AUC (0.83 
      [95% CI: 0.80, 0.85]) and accuracy (84% [95% CI: 82%, 86%]) comparable to those 
      of the human-LLM interaction strategy with two senior readers and one junior 
      reader and exceeding those of the human-LLM interaction strategy with one junior 
      reader. Conclusion LLMs, particularly integrated with image-to-text approaches, 
      show potential in enhancing diagnostic medical imaging. ChatGPT 4.0 was optimal 
      for consistency and diagnostic accuracy when compared with Bard and ChatGPT 3.5. 
      © RSNA, 2024 Supplemental material is available for this article.
FAU - Wu, Shao-Hong
AU  - Wu SH
AUID- ORCID: 0000-0002-3291-6115
AD  - From the Department of Medical Ultrasonics, Ultrasomics Artificial Intelligence 
      X-Laboratory, Institute of Diagnostic and Interventional Ultrasound, First 
      Affiliated Hospital of Sun Yat-sen University, No. 58 Zhongshan Rd 2, Guangzhou 
      510080, People's Republic of China (S.H.W., W.J.T., M.D. Li, H.T.H., Z.R.H., 
      X.X.L., R.F.L., M.D. Lu, L.D.C., W.W.); and Department of Traditional Chinese 
      Medicine, First Affiliated Hospital of Sun Yat-sen University, Guangzhou, 
      People's Republic of China (X.Z.L.).
FAU - Tong, Wen-Juan
AU  - Tong WJ
AUID- ORCID: 0000-0003-0400-0908
AD  - From the Department of Medical Ultrasonics, Ultrasomics Artificial Intelligence 
      X-Laboratory, Institute of Diagnostic and Interventional Ultrasound, First 
      Affiliated Hospital of Sun Yat-sen University, No. 58 Zhongshan Rd 2, Guangzhou 
      510080, People's Republic of China (S.H.W., W.J.T., M.D. Li, H.T.H., Z.R.H., 
      X.X.L., R.F.L., M.D. Lu, L.D.C., W.W.); and Department of Traditional Chinese 
      Medicine, First Affiliated Hospital of Sun Yat-sen University, Guangzhou, 
      People's Republic of China (X.Z.L.).
FAU - Li, Ming-De
AU  - Li MD
AUID- ORCID: 0000-0003-0121-7968
AD  - From the Department of Medical Ultrasonics, Ultrasomics Artificial Intelligence 
      X-Laboratory, Institute of Diagnostic and Interventional Ultrasound, First 
      Affiliated Hospital of Sun Yat-sen University, No. 58 Zhongshan Rd 2, Guangzhou 
      510080, People's Republic of China (S.H.W., W.J.T., M.D. Li, H.T.H., Z.R.H., 
      X.X.L., R.F.L., M.D. Lu, L.D.C., W.W.); and Department of Traditional Chinese 
      Medicine, First Affiliated Hospital of Sun Yat-sen University, Guangzhou, 
      People's Republic of China (X.Z.L.).
FAU - Hu, Hang-Tong
AU  - Hu HT
AUID- ORCID: 0000-0002-5361-233X
AD  - From the Department of Medical Ultrasonics, Ultrasomics Artificial Intelligence 
      X-Laboratory, Institute of Diagnostic and Interventional Ultrasound, First 
      Affiliated Hospital of Sun Yat-sen University, No. 58 Zhongshan Rd 2, Guangzhou 
      510080, People's Republic of China (S.H.W., W.J.T., M.D. Li, H.T.H., Z.R.H., 
      X.X.L., R.F.L., M.D. Lu, L.D.C., W.W.); and Department of Traditional Chinese 
      Medicine, First Affiliated Hospital of Sun Yat-sen University, Guangzhou, 
      People's Republic of China (X.Z.L.).
FAU - Lu, Xiao-Zhou
AU  - Lu XZ
AUID- ORCID: 0000-0002-3013-5737
AD  - From the Department of Medical Ultrasonics, Ultrasomics Artificial Intelligence 
      X-Laboratory, Institute of Diagnostic and Interventional Ultrasound, First 
      Affiliated Hospital of Sun Yat-sen University, No. 58 Zhongshan Rd 2, Guangzhou 
      510080, People's Republic of China (S.H.W., W.J.T., M.D. Li, H.T.H., Z.R.H., 
      X.X.L., R.F.L., M.D. Lu, L.D.C., W.W.); and Department of Traditional Chinese 
      Medicine, First Affiliated Hospital of Sun Yat-sen University, Guangzhou, 
      People's Republic of China (X.Z.L.).
FAU - Huang, Ze-Rong
AU  - Huang ZR
AUID- ORCID: 0000-0003-3388-8571
AD  - From the Department of Medical Ultrasonics, Ultrasomics Artificial Intelligence 
      X-Laboratory, Institute of Diagnostic and Interventional Ultrasound, First 
      Affiliated Hospital of Sun Yat-sen University, No. 58 Zhongshan Rd 2, Guangzhou 
      510080, People's Republic of China (S.H.W., W.J.T., M.D. Li, H.T.H., Z.R.H., 
      X.X.L., R.F.L., M.D. Lu, L.D.C., W.W.); and Department of Traditional Chinese 
      Medicine, First Affiliated Hospital of Sun Yat-sen University, Guangzhou, 
      People's Republic of China (X.Z.L.).
FAU - Lin, Xin-Xin
AU  - Lin XX
AUID- ORCID: 0009-0003-4259-9453
AD  - From the Department of Medical Ultrasonics, Ultrasomics Artificial Intelligence 
      X-Laboratory, Institute of Diagnostic and Interventional Ultrasound, First 
      Affiliated Hospital of Sun Yat-sen University, No. 58 Zhongshan Rd 2, Guangzhou 
      510080, People's Republic of China (S.H.W., W.J.T., M.D. Li, H.T.H., Z.R.H., 
      X.X.L., R.F.L., M.D. Lu, L.D.C., W.W.); and Department of Traditional Chinese 
      Medicine, First Affiliated Hospital of Sun Yat-sen University, Guangzhou, 
      People's Republic of China (X.Z.L.).
FAU - Lu, Rui-Fang
AU  - Lu RF
AUID- ORCID: 0009-0005-7538-0233
AD  - From the Department of Medical Ultrasonics, Ultrasomics Artificial Intelligence 
      X-Laboratory, Institute of Diagnostic and Interventional Ultrasound, First 
      Affiliated Hospital of Sun Yat-sen University, No. 58 Zhongshan Rd 2, Guangzhou 
      510080, People's Republic of China (S.H.W., W.J.T., M.D. Li, H.T.H., Z.R.H., 
      X.X.L., R.F.L., M.D. Lu, L.D.C., W.W.); and Department of Traditional Chinese 
      Medicine, First Affiliated Hospital of Sun Yat-sen University, Guangzhou, 
      People's Republic of China (X.Z.L.).
FAU - Lu, Ming-De
AU  - Lu MD
AUID- ORCID: 0000-0002-9771-8144
AD  - From the Department of Medical Ultrasonics, Ultrasomics Artificial Intelligence 
      X-Laboratory, Institute of Diagnostic and Interventional Ultrasound, First 
      Affiliated Hospital of Sun Yat-sen University, No. 58 Zhongshan Rd 2, Guangzhou 
      510080, People's Republic of China (S.H.W., W.J.T., M.D. Li, H.T.H., Z.R.H., 
      X.X.L., R.F.L., M.D. Lu, L.D.C., W.W.); and Department of Traditional Chinese 
      Medicine, First Affiliated Hospital of Sun Yat-sen University, Guangzhou, 
      People's Republic of China (X.Z.L.).
FAU - Chen, Li-Da
AU  - Chen LD
AUID- ORCID: 0000-0001-9904-2195
AD  - From the Department of Medical Ultrasonics, Ultrasomics Artificial Intelligence 
      X-Laboratory, Institute of Diagnostic and Interventional Ultrasound, First 
      Affiliated Hospital of Sun Yat-sen University, No. 58 Zhongshan Rd 2, Guangzhou 
      510080, People's Republic of China (S.H.W., W.J.T., M.D. Li, H.T.H., Z.R.H., 
      X.X.L., R.F.L., M.D. Lu, L.D.C., W.W.); and Department of Traditional Chinese 
      Medicine, First Affiliated Hospital of Sun Yat-sen University, Guangzhou, 
      People's Republic of China (X.Z.L.).
FAU - Wang, Wei
AU  - Wang W
AUID- ORCID: 0000-0002-9485-583X
AD  - From the Department of Medical Ultrasonics, Ultrasomics Artificial Intelligence 
      X-Laboratory, Institute of Diagnostic and Interventional Ultrasound, First 
      Affiliated Hospital of Sun Yat-sen University, No. 58 Zhongshan Rd 2, Guangzhou 
      510080, People's Republic of China (S.H.W., W.J.T., M.D. Li, H.T.H., Z.R.H., 
      X.X.L., R.F.L., M.D. Lu, L.D.C., W.W.); and Department of Traditional Chinese 
      Medicine, First Affiliated Hospital of Sun Yat-sen University, Guangzhou, 
      People's Republic of China (X.Z.L.).
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Radiology
JT  - Radiology
JID - 0401260
SB  - IM
MH  - Humans
MH  - Female
MH  - Adult
MH  - *Thyroid Nodule/diagnostic imaging
MH  - Retrospective Studies
MH  - Language
MH  - Neural Networks, Computer
MH  - ROC Curve
EDAT- 2024/03/12 12:46
MHDA- 2024/03/13 06:46
CRDT- 2024/03/12 09:53
PHST- 2024/03/13 06:46 [medline]
PHST- 2024/03/12 12:46 [pubmed]
PHST- 2024/03/12 09:53 [entrez]
AID - 10.1148/radiol.232255 [doi]
PST - ppublish
SO  - Radiology. 2024 Mar;310(3):e232255. doi: 10.1148/radiol.232255.

PMID- 38568227
OWN - NLM
STAT- Publisher
LR  - 20240403
IS  - 1432-1459 (Electronic)
IS  - 0340-5354 (Linking)
DP  - 2024 Apr 3
TI  - ChatGPT vs. neurologists: a cross-sectional study investigating preference, 
      satisfaction ratings and perceived empathy in responses among people living with 
      multiple sclerosis.
LID - 10.1007/s00415-024-12328-x [doi]
AB  - BACKGROUND: ChatGPT is an open-source natural language processing software that 
      replies to users' queries. We conducted a cross-sectional study to assess people 
      living with Multiple Sclerosis' (PwMS) preferences, satisfaction, and empathy 
      toward two alternate responses to four frequently-asked questions, one authored 
      by a group of neurologists, the other by ChatGPT. METHODS: An online form was 
      sent through digital communication platforms. PwMS were blind to the author of 
      each response and were asked to express their preference for each alternate 
      response to the four questions. The overall satisfaction was assessed using a 
      Likert scale (1-5); the Consultation and Relational Empathy scale was employed to 
      assess perceived empathy. RESULTS: We included 1133 PwMS (age, 
      45.26 ± 11.50&nbsp;years; females, 68.49%). ChatGPT's responses showed significantly 
      higher empathy scores (Coeff = 1.38; 95% CI = 0.65, 2.11; p &gt; z &lt; 0.01), when 
      compared with neurologists' responses. No association was found between ChatGPT' 
      responses and mean satisfaction (Coeff = 0.03; 95% CI = -&nbsp;0.01, 0.07; p = 0.157). 
      College graduate, when compared with high school education responder, had 
      significantly lower likelihood to prefer ChatGPT response (IRR = 0.87; 95% 
      CI = 0.79, 0.95; p &lt; 0.01). CONCLUSIONS: ChatGPT-authored responses provided 
      higher empathy than neurologists. Although AI holds potential, physicians should 
      prepare to interact with increasingly digitized patients and guide them on 
      responsible AI use. Future development should consider tailoring AIs' responses 
      to individual characteristics. Within the progressive digitalization of the 
      population, ChatGPT could emerge as a helpful support in healthcare management 
      rather than an alternative.
CI  - © 2024. The Author(s).
FAU - Maida, Elisabetta
AU  - Maida E
AD  - Department of Advanced Medical and Surgical Sciences, University of Campania 
      "Luigi Vanvitelli", Via Pansini 5, 80131, Naples, Italy.
FAU - Moccia, Marcello
AU  - Moccia M
AD  - Department of Molecular Medicine and Medical Biotechnology, Federico II 
      University of Naples, Naples, Italy.
AD  - Multiple Sclerosis Unit, Policlinico Federico II University Hospital, Naples, 
      Italy.
FAU - Palladino, Raffaele
AU  - Palladino R
AD  - Department of Public Health, University "Federico II" of Naples, Naples, Italy.
AD  - Department of Primary Care and Public Health, Imperial College of London, London, 
      UK.
FAU - Borriello, Giovanna
AU  - Borriello G
AD  - Department of Human Neuroscience, Sapienza University of Rome, Rome, Italy.
FAU - Affinito, Giuseppina
AU  - Affinito G
AD  - Department of Public Health, University "Federico II" of Naples, Naples, Italy.
FAU - Clerico, Marinella
AU  - Clerico M
AD  - Dipartimento di Scienze Cliniche e Biologiche, Università Di Torino, Turin, 
      Italy.
FAU - Repice, Anna Maria
AU  - Repice AM
AD  - Department of Neurology 2 and Tuscan Region Multiple Sclerosis Referral Centre, 
      Careggi University Hospital, Florence, Italy.
FAU - Di Sapio, Alessia
AU  - Di Sapio A
AD  - Department of Neurology and Multiple Sclerosis Regional Referral Centre, AOU San 
      Luigi Gonzaga, Orbassano, Turin, Italy.
FAU - Iodice, Rosa
AU  - Iodice R
AD  - Department of Neurosciences, Reproductive Sciences and Odontostomatology, 
      University of Naples Federico II, Naples, Italy.
FAU - Spiezia, Antonio Luca
AU  - Spiezia AL
AD  - Multiple Sclerosis Unit, Policlinico Federico II University Hospital, Naples, 
      Italy.
FAU - Sparaco, Maddalena
AU  - Sparaco M
AD  - Department of Advanced Medical and Surgical Sciences, University of Campania 
      "Luigi Vanvitelli", Via Pansini 5, 80131, Naples, Italy.
FAU - Miele, Giuseppina
AU  - Miele G
AD  - Department of Advanced Medical and Surgical Sciences, University of Campania 
      "Luigi Vanvitelli", Via Pansini 5, 80131, Naples, Italy.
FAU - Bile, Floriana
AU  - Bile F
AD  - Department of Advanced Medical and Surgical Sciences, University of Campania 
      "Luigi Vanvitelli", Via Pansini 5, 80131, Naples, Italy.
FAU - Scandurra, Cristiano
AU  - Scandurra C
AD  - Department of Neurosciences, Reproductive Sciences and Odontostomatology, 
      University of Naples Federico II, Naples, Italy.
FAU - Ferraro, Diana
AU  - Ferraro D
AD  - Department of Neuroscience, Azienda Ospedaliero-Universitaria di Modena, Modena, 
      Emilia-Romagna, Italy.
AD  - Department of Biomedical, Metabolic and Neural Sciences, University of Modena and 
      Reggio Emilia, Modena, Italy.
FAU - Stromillo, Maria Laura
AU  - Stromillo ML
AD  - Department of Medicine, Surgery and Neuroscience, University of Siena, Siena, 
      Italy.
FAU - Docimo, Renato
AU  - Docimo R
AD  - Multiple Sclerosis Center, Department of Advanced Medical and Surgical Sciences, 
      University of Campania "Luigi Vanvitelli", Naples, Italy.
FAU - De Martino, Antonio
AU  - De Martino A
AD  - Institute of Neurology, University Magna Graecia of Catanzaro, Catanzaro, Italy.
FAU - Mancinelli, Luca
AU  - Mancinelli L
AD  - Neurology Unit, Bufalini Hospital, Local Health Agency of Romagna, Cesena, Italy.
FAU - Abbadessa, Gianmarco
AU  - Abbadessa G
AD  - Department of Advanced Medical and Surgical Sciences, University of Campania 
      "Luigi Vanvitelli", Via Pansini 5, 80131, Naples, Italy.
AD  - Department of Brain Sciences, Imperial College London, London, W120BZ, UK.
FAU - Smolik, Krzysztof
AU  - Smolik K
AD  - Department of Biomedical, Metabolic and Neural Sciences, University of Modena and 
      Reggio Emilia, Modena, Italy.
FAU - Lorusso, Lorenzo
AU  - Lorusso L
AD  - Neurology Unit-Neuroscience Department A.S.S.T.Lecco, Merate Hospital, 23807, 
      Merate, Italy.
FAU - Leone, Maurizio
AU  - Leone M
AD  - Neurology Unit, Fondazione IRCCS Casa Sollievo della Sofferenza, 71013, San 
      Giovanni Rotondo, Italy.
FAU - Leveraro, Elisa
AU  - Leveraro E
AD  - Department of Neuroscience, Rehabilitation, Ophthalmology, Genetics, Maternal and 
      Child Health (DiNOGMI), University of Genoa, Genoa, Italy.
AD  - Department of Neurology, IRCSS Ospedale Policlinico San Martino, Genoa, Italy.
FAU - Lauro, Francesca
AU  - Lauro F
AD  - Department of Neurosciences, Reproductive Sciences and Odontostomatology, 
      University of Naples Federico II, Naples, Italy.
FAU - Trojsi, Francesca
AU  - Trojsi F
AD  - Department of Advanced Medical and Surgical Sciences, University of Campania 
      "Luigi Vanvitelli", Via Pansini 5, 80131, Naples, Italy.
FAU - Streito, Lidia Mislin
AU  - Streito LM
AD  - Dipartimento di Scienze Cliniche e Biologiche, Università Di Torino, Turin, 
      Italy.
FAU - Gabriele, Francesca
AU  - Gabriele F
AD  - Department of Biotechnological and Applied Clinical Sciences, University of 
      L'Aquila, L'Aquila, Italy.
FAU - Marinelli, Fabiana
AU  - Marinelli F
AD  - Neurology Unit, Multiple Sclerosis Center, Fabrizio Spaziani Hospital, Frosinone, 
      Italy.
FAU - Ianniello, Antonio
AU  - Ianniello A
AD  - Department of Human Neuroscience, Sapienza University of Rome, Rome, Italy.
FAU - De Santis, Federica
AU  - De Santis F
AD  - Department of Neurology and Stroke Unit of Avezzano-Sulmona, ASL 1 
      Avezzano-Sulmona-L'Aquila, L'Aquila, Italy.
FAU - Foschi, Matteo
AU  - Foschi M
AD  - Department of Biotechnological and Applied Clinical Sciences, University of 
      L'Aquila, L'Aquila, Italy.
AD  - Department of Neuroscience, Multiple Sclerosis Center, S. Maria delle Croci 
      Hospital, AUSL Romagna, Ravenna, Italy.
FAU - De Stefano, Nicola
AU  - De Stefano N
AD  - Department of Medicine, Surgery and Neuroscience, University of Siena, Siena, 
      Italy.
FAU - Morra, Vincenzo Brescia
AU  - Morra VB
AD  - Department of Neurosciences, Reproductive Sciences and Odontostomatology, 
      University of Naples Federico II, Naples, Italy.
FAU - Bisecco, Alvino
AU  - Bisecco A
AD  - Multiple Sclerosis Center, Department of Advanced Medical and Surgical Sciences, 
      University of Campania "Luigi Vanvitelli", Naples, Italy.
FAU - Coghe, Giancarlo
AU  - Coghe G
AD  - Department of Medical Sciences and Public Health, Multiple Sclerosis Center, 
      Binaghi Hospital, ASL Cagliari, University of Cagliari, Cagliari, Italy.
FAU - Cocco, Eleonora
AU  - Cocco E
AD  - Department of Medical Sciences and Public Health, Multiple Sclerosis Center, 
      Binaghi Hospital, ASL Cagliari, University of Cagliari, Cagliari, Italy.
FAU - Romoli, Michele
AU  - Romoli M
AD  - Neurology Unit, Bufalini Hospital, Local Health Agency of Romagna, Cesena, Italy.
FAU - Corea, Francesco
AU  - Corea F
AD  - Dipartimento di Neurologia, Ospedale di Foligno, Azienda USL Umbria 2, Terni, 
      Italy.
FAU - Leocani, Letizia
AU  - Leocani L
AD  - Vita-Salute San Raffaele University, Milan, Italy.
AD  - Experimental Neurophysiology Unit, Institute of Experimental Neurology-INSPE, 
      IRCCS Scientific Institute San Raffaele, Milan, Italy.
FAU - Frau, Jessica
AU  - Frau J
AD  - Department of Medical Sciences and Public Health, Multiple Sclerosis Center, 
      Binaghi Hospital, ASL Cagliari, University of Cagliari, Cagliari, Italy.
FAU - Sacco, Simona
AU  - Sacco S
AD  - Department of Biotechnological and Applied Clinical Sciences, University of 
      L'Aquila, L'Aquila, Italy.
FAU - Inglese, Matilde
AU  - Inglese M
AD  - Department of Neuroscience, Rehabilitation, Ophthalmology, Genetics, Maternal and 
      Child Health (DiNOGMI), University of Genoa, Genoa, Italy.
AD  - Department of Neurology, IRCSS Ospedale Policlinico San Martino, Genoa, Italy.
FAU - Carotenuto, Antonio
AU  - Carotenuto A
AD  - Department of Neurosciences, Reproductive Sciences and Odontostomatology, 
      University of Naples Federico II, Naples, Italy.
FAU - Lanzillo, Roberta
AU  - Lanzillo R
AD  - Department of Neurosciences, Reproductive Sciences and Odontostomatology, 
      University of Naples Federico II, Naples, Italy.
FAU - Padovani, Alessandro
AU  - Padovani A
AD  - Unit of Neurology, Azienda Socio-Sanitaria Territoriale Spedali Civili, Brescia, 
      Italy.
AD  - Department of Clinical and Experimental Sciences, University of Brescia, Brescia, 
      Italy.
FAU - Triassi, Maria
AU  - Triassi M
AD  - Department of Public Health, University "Federico II" of Naples, Naples, Italy.
FAU - Bonavita, Simona
AU  - Bonavita S
AUID- ORCID: 0000-0002-8561-9720
AD  - Department of Advanced Medical and Surgical Sciences, University of Campania 
      "Luigi Vanvitelli", Via Pansini 5, 80131, Naples, Italy. 
      simona.bonavita@unicampania.it.
FAU - Lavorgna, Luigi
AU  - Lavorgna L
AD  - Department of Advanced Medical and Surgical Sciences, University of Campania 
      "Luigi Vanvitelli", Via Pansini 5, 80131, Naples, Italy.
CN  - Digital Technologies, Web, Social Media Study Group of the Italian Society of 
      Neurology (SIN)
LA  - eng
PT  - Journal Article
DEP - 20240403
PL  - Germany
TA  - J Neurol
JT  - Journal of neurology
JID - 0423161
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Large language model
OT  - Machine learning
OT  - Multiple sclerosis
EDAT- 2024/04/03 12:48
MHDA- 2024/04/03 12:48
CRDT- 2024/04/03 11:04
PHST- 2024/01/15 00:00 [received]
PHST- 2024/03/12 00:00 [accepted]
PHST- 2024/03/11 00:00 [revised]
PHST- 2024/04/03 12:48 [medline]
PHST- 2024/04/03 12:48 [pubmed]
PHST- 2024/04/03 11:04 [entrez]
AID - 10.1007/s00415-024-12328-x [pii]
AID - 10.1007/s00415-024-12328-x [doi]
PST - aheadofprint
SO  - J Neurol. 2024 Apr 3. doi: 10.1007/s00415-024-12328-x.

PMID- 38320079
STAT- Publisher
PB  - Canadian Agency for Drugs and Technologies in Health
CTI - CADTH Health Technology Review
DP  - 2023 Nov
BTI - Implications of ChatGPT on Radiology Workflow: CADTH Health Technology Review
LA  - eng
PT  - Review
PT  - Book
PL  - Ottawa (ON)
RF  - 44
EDAT- 2023/11/01 00:00
CRDT- 2023/11/01 00:00
AID - NBK599981 [bookaccession]

PMID- 37663854
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20230905
LR  - 20230905
IS  - 2296-2565 (Electronic)
IS  - 2296-2565 (Linking)
VI  - 11
DP  - 2023
TI  - Brave (in a) new world: an ethical perspective on chatbots for medical advice.
PG  - 1254334
LID - 10.3389/fpubh.2023.1254334 [doi]
LID - 1254334
FAU - Erren, Thomas C
AU  - Erren TC
AD  - University of Cologne, University Hospital of Cologne, Cologne, North 
      Rhine-Westphalia, Germany.
FAU - Lewis, Philip
AU  - Lewis P
AD  - University of Cologne, University Hospital of Cologne, Cologne, North 
      Rhine-Westphalia, Germany.
FAU - Shaw, David M
AU  - Shaw DM
AD  - Care and Public Health Research Institute, Maastricht University, Maastricht, 
      Netherlands.
AD  - Institute for Biomedical Ethics, University of Basel, Basel, Switzerland.
LA  - eng
PT  - Journal Article
DEP - 20230817
PL  - Switzerland
TA  - Front Public Health
JT  - Frontiers in public health
JID - 101616579
SB  - IM
PMC - PMC10470018
OTO - NOTNLM
OT  - ChatGPT
OT  - chatbot
OT  - confidentiality and privacy
OT  - ethics
OT  - hallucination
OT  - medical advice
OT  - risks
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/09/04 06:42
MHDA- 2023/09/04 06:43
PMCR- 2023/08/17
CRDT- 2023/09/04 05:05
PHST- 2023/07/06 00:00 [received]
PHST- 2023/07/31 00:00 [accepted]
PHST- 2023/09/04 06:43 [medline]
PHST- 2023/09/04 06:42 [pubmed]
PHST- 2023/09/04 05:05 [entrez]
PHST- 2023/08/17 00:00 [pmc-release]
AID - 10.3389/fpubh.2023.1254334 [doi]
PST - epublish
SO  - Front Public Health. 2023 Aug 17;11:1254334. doi: 10.3389/fpubh.2023.1254334. 
      eCollection 2023.

PMID- 38500671
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240320
IS  - 2624-8212 (Electronic)
IS  - 2624-8212 (Linking)
VI  - 7
DP  - 2024
TI  - Dawn of the dialogue: AI's leap from lab to living room.
PG  - 1308156
LID - 10.3389/frai.2024.1308156 [doi]
LID - 1308156
AB  - Prior to the advent of mainstream Large Language Models, e.g., ChatGPT, there 
      were two contexts of AI use: theoretical and technical. The former involves the 
      mathematics behind AI constructs, as well as new AI research; the latter 
      encompasses the substance of AI use, i.e., programming, training, execution, etc. 
      With the recent proliferation of Large Language Models for content generation, 
      such as texts, images, and videos, there arises a new context of AI use: 
      practical. This aspect of AI use is unique, in that practical users do not need 
      theoretical or technical AI knowledge to prosper: they need only know how to 
      prompt. In effect, the practical context of AI use is a black-box approach. These 
      three contexts of AI converge in a unique intersection of AI knowledge. This 
      emerging AI perspective is important to consider, as most AI users, now and in 
      the future, will possess no deep knowledge of AI.
CI  - Copyright © 2024 Procko, Elvira and Ochoa.
FAU - Procko, Tyler Thomas
AU  - Procko TT
AD  - Department of Electrical Engineering and Computer Science, Embry-Riddle 
      Aeronautical University, Daytona Beach, FL, United States.
FAU - Elvira, Timothy
AU  - Elvira T
AD  - Department of Electrical Engineering and Computer Science, Embry-Riddle 
      Aeronautical University, Daytona Beach, FL, United States.
FAU - Ochoa, Omar
AU  - Ochoa O
AD  - Department of Electrical Engineering and Computer Science, Embry-Riddle 
      Aeronautical University, Daytona Beach, FL, United States.
LA  - eng
PT  - Journal Article
DEP - 20240304
PL  - Switzerland
TA  - Front Artif Intell
JT  - Frontiers in artificial intelligence
JID - 101770551
PMC - PMC10944963
OTO - NOTNLM
OT  - AI evolution
OT  - Artificial Intelligence
OT  - ChatGPT
OT  - Large Language Models
OT  - generative AI
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2024/03/19 06:44
MHDA- 2024/03/19 06:45
PMCR- 2024/03/04
CRDT- 2024/03/19 03:38
PHST- 2023/10/06 00:00 [received]
PHST- 2024/02/19 00:00 [accepted]
PHST- 2024/03/19 06:45 [medline]
PHST- 2024/03/19 06:44 [pubmed]
PHST- 2024/03/19 03:38 [entrez]
PHST- 2024/03/04 00:00 [pmc-release]
AID - 10.3389/frai.2024.1308156 [doi]
PST - epublish
SO  - Front Artif Intell. 2024 Mar 4;7:1308156. doi: 10.3389/frai.2024.1308156. 
      eCollection 2024.

PMID- 38353440
OWN - NLM
STAT- MEDLINE
DCOM- 20240215
LR  - 20240215
IS  - 1660-9379 (Print)
IS  - 1660-9379 (Linking)
VI  - 20
IP  - 861
DP  - 2024 Feb 14
TI  - [ChatGPT in clinical practice: prospects and challenges].
PG  - 363-366
LID - 10.53738/REVMED.2024.20.861.363 [doi]
AB  - Virtually unknown to the greater public before November 2022, ChatGPT was made 
      available in open access in Autumn 2022, driving the perspective of artificial 
      intelligence integration to the forefront of daily life. The field of medicine 
      hasn't been left aside, and sparks as much interest as it does questions. 
      Although this tool has considerable potential for use in clinical practice, it, 
      like others, has limitations that need to be clearly understood to avoid misuse. 
      In addition, the legal framework and issues of data confidentiality are currently 
      poorly defined, and clinicians will need to keep a close eye on legislative 
      developments in this area.
FAU - Roustan, Dimitri
AU  - Roustan D
AD  - Service de médecine interne, Centre hospitalier universitaire vaudois, 1011 
      Lausanne.
FAU - Galland-Decker, Coralie
AU  - Galland-Decker C
AUID- ORCID: 0000-0001-8897-8473
AD  - Direction médicale, Centre hospitalier universitaire vaudois, 1011 Lausanne.
AD  - Direction de l'innovation et de la recherche clinique, Centre hospitalier 
      universitaire vaudois, 1011 Lausanne.
FAU - Marinoni, Chiara
AU  - Marinoni C
AD  - Direction médicale, Centre hospitalier universitaire vaudois, 1011 Lausanne.
AD  - Direction de l'innovation et de la recherche clinique, Centre hospitalier 
      universitaire vaudois, 1011 Lausanne.
FAU - Bastardot, François
AU  - Bastardot F
AUID- ORCID: 0000-0003-4060-0353
AD  - Direction médicale, Centre hospitalier universitaire vaudois, 1011 Lausanne.
AD  - Direction de l'innovation et de la recherche clinique, Centre hospitalier 
      universitaire vaudois, 1011 Lausanne.
LA  - fre
PT  - English Abstract
PT  - Journal Article
TT  - ChatGPT en pratique clinique : perspectives et limites.
PL  - Switzerland
TA  - Rev Med Suisse
JT  - Revue medicale suisse
JID - 101219148
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Medicine
MH  - Seasons
COIS- Les auteurs n’ont déclaré aucun conflit d’intérêts en relation avec cet article.
EDAT- 2024/02/14 12:50
MHDA- 2024/02/15 06:43
CRDT- 2024/02/14 08:13
PHST- 2024/02/15 06:43 [medline]
PHST- 2024/02/14 12:50 [pubmed]
PHST- 2024/02/14 08:13 [entrez]
AID - RMS0861-010 [pii]
AID - 10.53738/REVMED.2024.20.861.363 [doi]
PST - ppublish
SO  - Rev Med Suisse. 2024 Feb 14;20(861):363-366. doi: 
      10.53738/REVMED.2024.20.861.363.

PMID- 38296195
OWN - NLM
STAT- Publisher
LR  - 20240216
IS  - 1097-6787 (Electronic)
IS  - 0190-9622 (Linking)
DP  - 2024 Feb 1
TI  - Assessing the accuracy, usefulness, and readability of 
      artificial-intelligence-generated responses to common dermatologic surgery 
      questions for patient education: A double-blinded comparative study of ChatGPT 
      and Google Bard.
LID - S0190-9622(24)00138-5 [pii]
LID - 10.1016/j.jaad.2024.01.037 [doi]
FAU - Robinson, Michelle A
AU  - Robinson MA
AD  - Department of Dermatology, Johns Hopkins School of Medicine, Baltimore, Maryland. 
      Electronic address: mmcnal11@jhmi.edu.
FAU - Belzberg, Micah
AU  - Belzberg M
AD  - Department of Dermatology, Johns Hopkins School of Medicine, Baltimore, Maryland.
FAU - Thakker, Sach
AU  - Thakker S
AD  - Georgetown University School of Medicine, Washington, DC.
FAU - Bibee, Kristin
AU  - Bibee K
AD  - Department of Dermatology, Johns Hopkins School of Medicine, Baltimore, Maryland.
FAU - Merkel, Emily
AU  - Merkel E
AD  - Department of Dermatology, Johns Hopkins School of Medicine, Baltimore, Maryland.
FAU - MacFarlane, Deborah F
AU  - MacFarlane DF
AD  - Department of Dermatology, the University of Texas MD Anderson Cancer Center, 
      Houston, Texas.
FAU - Lim, Jordan
AU  - Lim J
AD  - Department of Dermatology, Emory University School of Medicine, Atlanta, Georgia.
FAU - Scott, Jeffrey F
AU  - Scott JF
AD  - Department of Dermatology, Johns Hopkins School of Medicine, Baltimore, Maryland.
FAU - Deng, Min
AU  - Deng M
AD  - Department of Dermatology, MedStar Washington Hospital Center, Georgetown 
      University Hospital, Washington, DC.
FAU - Lewin, Jesse
AU  - Lewin J
AD  - Kimberly and Eric J. Waldman Department of Dermatology, Icahn School of Medicine 
      at Mount Sinai, New York, New York.
FAU - Soleymani, David
AU  - Soleymani D
AD  - Dermio Dermatology, Munster, Indiana.
FAU - Rosenfeld, David
AU  - Rosenfeld D
AD  - Dermio Dermatology, Munster, Indiana.
FAU - Liu, Rosemarie
AU  - Liu R
AD  - Metro Mohs Surgery Center, Springfield, Virginia.
FAU - Liu, Tin Yan Alvin
AU  - Liu TYA
AD  - Department of Ophthalmology, Johns Hopkins School of Medicine, Baltimore, 
      Maryland.
FAU - Ng, Elise
AU  - Ng E
AD  - Department of Ophthalmology, Johns Hopkins School of Medicine, Baltimore, 
      Maryland.
LA  - eng
PT  - Journal Article
DEP - 20240201
PL  - United States
TA  - J Am Acad Dermatol
JT  - Journal of the American Academy of Dermatology
JID - 7907132
SB  - IM
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - Google Bard
OT  - LLMs
OT  - Mohs surgery
OT  - artificial intelligence chatbots
OT  - dermatologic surgery
OT  - health care information delivery
OT  - large language models
OT  - patient education
COIS- Conflicts of interest None disclosed.
EDAT- 2024/02/01 00:43
MHDA- 2024/02/01 00:43
CRDT- 2024/01/31 19:31
PHST- 2023/10/10 00:00 [received]
PHST- 2023/12/26 00:00 [revised]
PHST- 2024/01/14 00:00 [accepted]
PHST- 2024/02/01 00:43 [pubmed]
PHST- 2024/02/01 00:43 [medline]
PHST- 2024/01/31 19:31 [entrez]
AID - S0190-9622(24)00138-5 [pii]
AID - 10.1016/j.jaad.2024.01.037 [doi]
PST - aheadofprint
SO  - J Am Acad Dermatol. 2024 Feb 1:S0190-9622(24)00138-5. doi: 
      10.1016/j.jaad.2024.01.037.

PMID- 37869501
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231031
IS  - 2297-1769 (Print)
IS  - 2297-1769 (Electronic)
IS  - 2297-1769 (Linking)
VI  - 10
DP  - 2023
TI  - ChatGPT and scientific papers in veterinary neurology; is the genie out of the 
      bottle?
PG  - 1272755
LID - 10.3389/fvets.2023.1272755 [doi]
LID - 1272755
FAU - Abani, Samira
AU  - Abani S
AD  - Department of Small Animal Medicine and Surgery, University of Veterinary 
      Medicine Hannover, Hannover, Germany.
AD  - Centre for Systems Neuroscience, University of Veterinary Medicine Hannover, 
      Hannover, Germany.
FAU - Volk, Holger Andreas
AU  - Volk HA
AD  - Department of Small Animal Medicine and Surgery, University of Veterinary 
      Medicine Hannover, Hannover, Germany.
AD  - Centre for Systems Neuroscience, University of Veterinary Medicine Hannover, 
      Hannover, Germany.
FAU - De Decker, Steven
AU  - De Decker S
AD  - Department of Veterinary Clinical Science and Services, Royal Veterinary College, 
      University of London, London, United Kingdom.
FAU - Fenn, Joe
AU  - Fenn J
AD  - Department of Veterinary Clinical Science and Services, Royal Veterinary College, 
      University of London, London, United Kingdom.
FAU - Rusbridge, Clare
AU  - Rusbridge C
AD  - Faculty of Health and Medical Sciences, School of Veterinary Medicine, University 
      of Surrey, Guildford, United Kingdom.
FAU - Charalambous, Marios
AU  - Charalambous M
AD  - Department of Small Animal Medicine and Surgery, University of Veterinary 
      Medicine Hannover, Hannover, Germany.
FAU - Goncalves, Rita
AU  - Goncalves R
AD  - Department of Veterinary Science, Small Animal Teaching Hospital, University of 
      Liverpool, Neston, United Kingdom.
FAU - Gutierrez-Quintana, Rodrigo
AU  - Gutierrez-Quintana R
AD  - Small Animal Hospital, School of Biodiversity, One Health and Veterinary 
      Medicine, University of Glasgow, Glasgow, United Kingdom.
FAU - Loderstedt, Shenja
AU  - Loderstedt S
AD  - Department of Small Animal Medicine, Leipzig University, Leipzig, Germany.
FAU - Flegel, Thomas
AU  - Flegel T
AD  - Department of Small Animal Medicine, Leipzig University, Leipzig, Germany.
FAU - Ros, Carlos
AU  - Ros C
AD  - Memvet Referral Veterinary Center, Palma de Mallorca, Spain.
FAU - von Klopmann, Thilo
AU  - von Klopmann T
AD  - Department of Neurology, Small Animal Clinic Hofheim, Hofheim, Germany.
FAU - Schenk, Henning Christian
AU  - Schenk HC
AD  - Department of Neurology, Lüneburg Small Animal Clinic, Lüneburg, Germany.
FAU - Kornberg, Marion
AU  - Kornberg M
AD  - AniCura Small Animal Clinic, Trier, Germany.
FAU - Meyerhoff, Nina
AU  - Meyerhoff N
AD  - Department of Small Animal Medicine and Surgery, University of Veterinary 
      Medicine Hannover, Hannover, Germany.
FAU - Tipold, Andrea
AU  - Tipold A
AD  - Department of Small Animal Medicine and Surgery, University of Veterinary 
      Medicine Hannover, Hannover, Germany.
AD  - Centre for Systems Neuroscience, University of Veterinary Medicine Hannover, 
      Hannover, Germany.
FAU - Nessler, Jasmin Nicole
AU  - Nessler JN
AD  - Department of Small Animal Medicine and Surgery, University of Veterinary 
      Medicine Hannover, Hannover, Germany.
LA  - eng
PT  - Journal Article
DEP - 20231005
PL  - Switzerland
TA  - Front Vet Sci
JT  - Frontiers in veterinary science
JID - 101666658
PMC - PMC10585059
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence (AI)
OT  - ethics
OT  - generative AI
OT  - integrity
OT  - machine learning
OT  - plagiarism
OT  - scientific writing
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest. The author(s) declared that they were an editorial board 
      member of Frontiers, at the time of submission. This had no impact on the peer 
      review process and the final decision.
EDAT- 2023/10/23 06:46
MHDA- 2023/10/23 06:47
PMCR- 2023/01/01
CRDT- 2023/10/23 04:54
PHST- 2023/08/04 00:00 [received]
PHST- 2023/09/18 00:00 [accepted]
PHST- 2023/10/23 06:47 [medline]
PHST- 2023/10/23 06:46 [pubmed]
PHST- 2023/10/23 04:54 [entrez]
PHST- 2023/01/01 00:00 [pmc-release]
AID - 10.3389/fvets.2023.1272755 [doi]
PST - epublish
SO  - Front Vet Sci. 2023 Oct 5;10:1272755. doi: 10.3389/fvets.2023.1272755. 
      eCollection 2023.

PMID- 37852648
OWN - NLM
STAT- MEDLINE
DCOM- 20231207
LR  - 20231217
IS  - 1535-5675 (Electronic)
IS  - 0091-4916 (Linking)
VI  - 51
IP  - 4
DP  - 2023 Dec 5
TI  - ChatGPT in Nuclear Medicine Education.
PG  - 344
LID - 10.2967/jnmt.123.266334 [doi]
FAU - Kleebayoon, Amnuay
AU  - Kleebayoon A
FAU - Wiwanitkit, Viroj
AU  - Wiwanitkit V
LA  - eng
PT  - Letter
DEP - 20231205
PL  - United States
TA  - J Nucl Med Technol
JT  - Journal of nuclear medicine technology
JID - 0430303
SB  - IM
MH  - *Nuclear Medicine
MH  - Radionuclide Imaging
EDAT- 2023/10/19 00:44
MHDA- 2023/12/07 12:43
CRDT- 2023/10/18 20:43
PHST- 2023/07/12 00:00 [received]
PHST- 2023/07/13 00:00 [revised]
PHST- 2023/12/07 12:43 [medline]
PHST- 2023/10/19 00:44 [pubmed]
PHST- 2023/10/18 20:43 [entrez]
AID - jnmt.123.266334 [pii]
AID - 10.2967/jnmt.123.266334 [doi]
PST - epublish
SO  - J Nucl Med Technol. 2023 Dec 5;51(4):344. doi: 10.2967/jnmt.123.266334.

PMID- 37845528
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20231023
LR  - 20231023
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
VI  - 622
IP  - 7983
DP  - 2023 Oct
TI  - How ChatGPT is transforming the postdoc experience.
PG  - 655-657
LID - 10.1038/d41586-023-03235-8 [doi]
FAU - Nordling, Linda
AU  - Nordling L
LA  - eng
PT  - News
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
OTO - NOTNLM
OT  - Careers
OT  - Lab life
OT  - Machine learning
OT  - Scientific community
EDAT- 2023/10/17 00:42
MHDA- 2023/10/17 00:43
CRDT- 2023/10/16 23:40
PHST- 2023/10/17 00:43 [medline]
PHST- 2023/10/17 00:42 [pubmed]
PHST- 2023/10/16 23:40 [entrez]
AID - 10.1038/d41586-023-03235-8 [pii]
AID - 10.1038/d41586-023-03235-8 [doi]
PST - ppublish
SO  - Nature. 2023 Oct;622(7983):655-657. doi: 10.1038/d41586-023-03235-8.

PMID- 37443308
OWN - NLM
STAT- Publisher
LR  - 20230719
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
DP  - 2023 Jul 13
TI  - ChatGPT gives an extra productivity boost to weaker writers.
LID - 10.1038/d41586-023-02270-9 [doi]
FAU - Lenharo, Mariana
AU  - Lenharo M
LA  - eng
PT  - News
DEP - 20230713
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
OTO - NOTNLM
OT  - Computer science
OT  - Machine learning
OT  - Publishing
EDAT- 2023/07/14 13:05
MHDA- 2023/07/14 13:05
CRDT- 2023/07/13 23:55
PHST- 2023/07/14 13:05 [pubmed]
PHST- 2023/07/14 13:05 [medline]
PHST- 2023/07/13 23:55 [entrez]
AID - 10.1038/d41586-023-02270-9 [pii]
AID - 10.1038/d41586-023-02270-9 [doi]
PST - aheadofprint
SO  - Nature. 2023 Jul 13. doi: 10.1038/d41586-023-02270-9.

PMID- 37074116
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20230421
LR  - 20231024
IS  - 2573-7732 (Electronic)
IS  - 2573-7732 (Linking)
VI  - 7
IP  - 4
DP  - 2023 Apr 1
TI  - I Haven't Been Replaced by ChatGPT.
PG  - 286-287
LID - 10.4049/immunohorizons.2300024 [doi]
FAU - Kaplan, Mark H
AU  - Kaplan MH
AD  - ImmunoHorizons On Twitter @statfourwork.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Immunohorizons
JT  - ImmunoHorizons
JID - 101708159
SB  - IM
PMC - PMC10579842
EDAT- 2023/04/19 12:42
MHDA- 2023/04/19 12:43
PMCR- 2023/04/19
CRDT- 2023/04/19 09:42
PHST- 2023/04/19 12:43 [medline]
PHST- 2023/04/19 12:42 [pubmed]
PHST- 2023/04/19 09:42 [entrez]
PHST- 2023/04/19 00:00 [pmc-release]
AID - 263630 [pii]
AID - immunohorizons_2300024 [pii]
AID - 10.4049/immunohorizons.2300024 [doi]
PST - ppublish
SO  - Immunohorizons. 2023 Apr 1;7(4):286-287. doi: 10.4049/immunohorizons.2300024.

PMID- 37660692
OWN - NLM
STAT- Publisher
LR  - 20230903
IS  - 1421-9786 (Electronic)
IS  - 1015-9770 (Linking)
DP  - 2023 Sep 2
TI  - Artificial Intelligence and Cerebrovascular Diseases: ChatGPT model.
LID - 10.1159/000533967 [doi]
FAU - Altunisik, Erman
AU  - Altunisik E
LA  - eng
PT  - Letter
DEP - 20230902
PL  - Switzerland
TA  - Cerebrovasc Dis
JT  - Cerebrovascular diseases (Basel, Switzerland)
JID - 9100851
SB  - IM
EDAT- 2023/09/04 00:41
MHDA- 2023/09/04 00:41
CRDT- 2023/09/03 18:23
PHST- 2023/07/12 00:00 [received]
PHST- 2023/08/30 00:00 [accepted]
PHST- 2023/09/04 00:41 [medline]
PHST- 2023/09/04 00:41 [pubmed]
PHST- 2023/09/03 18:23 [entrez]
AID - 000533967 [pii]
AID - 10.1159/000533967 [doi]
PST - aheadofprint
SO  - Cerebrovasc Dis. 2023 Sep 2. doi: 10.1159/000533967.

PMID- 38536805
OWN - NLM
STAT- MEDLINE
DCOM- 20240329
LR  - 20240329
IS  - 1932-6203 (Electronic)
IS  - 1932-6203 (Linking)
VI  - 19
IP  - 3
DP  - 2024
TI  - Powerful tool or too powerful? Early public discourse about ChatGPT across 4 
      million tweets.
PG  - e0296882
LID - 10.1371/journal.pone.0296882 [doi]
LID - e0296882
AB  - BACKGROUND: This paper investigates initial exuberance and emotions surrounding 
      ChatGPT's first three months of launch (1 December 2022-1 March 2023). The 
      impetus for studying active discussions surrounding its implications, fears, and 
      opinions is motivated by its nascent popularity and potential to disrupt existing 
      professions; compounded by its significance as a crucial inflexion point in 
      history. Capturing the public zeitgeist on new innovations-much like the advent 
      of the printing press, radio, newspapers, or the internet-provides a 
      retrospective overview of public sentiments, common themes, and issues. 
      OBJECTIVES: Since launch, few big data studies delved into initial public 
      discourse surrounding the chatbot. This report firstly identifies 
      highest-engagement issues and themes that generated the most interaction; 
      secondly, identifies the highest-engaged keywords on both sides of the sentiment 
      valence scale (positive and negative) associated with ChatGPT. METHODS: We 
      interrogate a large twitter corpus (n = 4,251,662) of all publicly available 
      English-language tweets containing the ChatGPT keyword. Our first research aim 
      utilizes a prominent peaks model (upper-quartile significance threshold of 
      prominence&gt;20,000). Our second research aim utilized sentiment analysis to 
      identify, week-on-week, highest-frequency negative, and positive keywords and 
      emojis. RESULTS: Six prominent peaks were identified with the following themes: 
      'hype and hesitance', 'utility and misuse in professional and academic settings', 
      'demographic bias', 'philosophical thought experiments on morality' and 
      'artificial intelligence as a mirror of human knowledge'. Of high-frequency 
      valence, negativity included credibility concerns, implicit bias, environmental 
      ethics, employment rights of data annotators and programmers, the ethicality of 
      neural network datasets. Positivity included excitement over application, 
      especially in coding, as a creative tool, education, and personal productivity. 
      CONCLUSIONS: Overall, sentiments and themes were double-edged, expressing 
      excitement over this powerful new tool and wariness toward its potential for 
      misuse.
CI  - Copyright: © 2024 Ng, Chow. This is an open access article distributed under the 
      terms of the Creative Commons Attribution License, which permits unrestricted 
      use, distribution, and reproduction in any medium, provided the original author 
      and source are credited.
FAU - Ng, Reuben
AU  - Ng R
AUID- ORCID: 0000-0002-1186-0570
AD  - Lee Kuan Yew School of Public Policy, National University of Singapore, 
      Singapore, Singapore.
AD  - Lloyd's Register Institute for the Public Understanding of Risk, National 
      University of Singapore, Singapore, Singapore.
FAU - Chow, Ting Yu Joanne
AU  - Chow TYJ
AUID- ORCID: 0000-0002-1223-0765
AD  - Lee Kuan Yew School of Public Policy, National University of Singapore, 
      Singapore, Singapore.
LA  - eng
PT  - Journal Article
DEP - 20240327
PL  - United States
TA  - PLoS One
JT  - PloS one
JID - 101285081
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Retrospective Studies
MH  - *Social Media
MH  - Emotions
MH  - Internet
PMC - PMC10971662
COIS- The authors have declared that no competing interests exist.
EDAT- 2024/03/27 18:44
MHDA- 2024/03/29 06:46
PMCR- 2024/03/27
CRDT- 2024/03/27 13:34
PHST- 2023/11/23 00:00 [received]
PHST- 2023/12/14 00:00 [accepted]
PHST- 2024/03/29 06:46 [medline]
PHST- 2024/03/27 18:44 [pubmed]
PHST- 2024/03/27 13:34 [entrez]
PHST- 2024/03/27 00:00 [pmc-release]
AID - PONE-D-23-39031 [pii]
AID - 10.1371/journal.pone.0296882 [doi]
PST - epublish
SO  - PLoS One. 2024 Mar 27;19(3):e0296882. doi: 10.1371/journal.pone.0296882. 
      eCollection 2024.

PMID- 37556434
OWN - NLM
STAT- MEDLINE
DCOM- 20230811
LR  - 20230811
IS  - 1932-6203 (Electronic)
IS  - 1932-6203 (Linking)
VI  - 18
IP  - 8
DP  - 2023
TI  - Distinguishing ChatGPT(-3.5, -4)-generated and human-written papers through 
      Japanese stylometric analysis.
PG  - e0288453
LID - 10.1371/journal.pone.0288453 [doi]
LID - e0288453
AB  - In the first half of 2023, text-generative artificial intelligence (AI), 
      including ChatGPT from OpenAI, has attracted considerable attention worldwide. In 
      this study, first, we compared Japanese stylometric features of texts generated 
      by ChatGPT, equipped with GPT-3.5 and GPT-4, and those written by humans. In this 
      work, we performed multi-dimensional scaling (MDS) to confirm the distributions 
      of 216 texts of three classes (72 academic papers written by 36 single authors, 
      72 texts generated by GPT-3.5, and 72 texts generated by GPT-4 on the basis of 
      the titles of the aforementioned papers) focusing on the following stylometric 
      features: (1) bigrams of parts-of-speech, (2) bigram of postpositional particle 
      words, (3) positioning of commas, and (4) rate of function words. MDS revealed 
      distinct distributions at each stylometric feature of GPT (3.5 and 4) and human. 
      Although GPT-4 is more powerful than GPT-3.5 because it has more parameters, both 
      GPT (3.5 and 4) distributions are overlapping. These results indicate that 
      although the number of parameters may increase in the future, GPT-generated texts 
      may not be close to that written by humans in terms of stylometric features. 
      Second, we verified the classification performance of random forest (RF) 
      classifier for two classes (GPT and human) focusing on Japanese stylometric 
      features. This study revealed the high performance of RF in each stylometric 
      feature: The RF classifier focusing on the rate of function words achieved 98.1% 
      accuracy. Furthermore the RF classifier focusing on all stylometric features 
      reached 100% in terms of all performance indexes (accuracy, recall, precision, 
      and F1 score). This study concluded that at this stage we human discriminate 
      ChatGPT from human limited to Japanese language.
CI  - Copyright: © 2023 Zaitsu, Jin. This is an open access article distributed under 
      the terms of the Creative Commons Attribution License, which permits unrestricted 
      use, distribution, and reproduction in any medium, provided the original author 
      and source are credited.
FAU - Zaitsu, Wataru
AU  - Zaitsu W
AUID- ORCID: 0000-0003-1017-7283
AD  - Department of Psychological Counselling, Faculty of Psychology, Mejiro 
      University, Tokyo, Japan.
FAU - Jin, Mingzhe
AU  - Jin M
AD  - Institute of Interdisciplinary Research, Kyoto University of Advanced Science, 
      Kyoto, Japan.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20230809
PL  - United States
TA  - PLoS One
JT  - PloS one
JID - 101285081
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Random Forest
MH  - *Writing
PMC - PMC10411719
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/08/09 18:42
MHDA- 2023/08/11 06:43
PMCR- 2023/08/09
CRDT- 2023/08/09 13:33
PHST- 2023/04/12 00:00 [received]
PHST- 2023/06/27 00:00 [accepted]
PHST- 2023/08/11 06:43 [medline]
PHST- 2023/08/09 18:42 [pubmed]
PHST- 2023/08/09 13:33 [entrez]
PHST- 2023/08/09 00:00 [pmc-release]
AID - PONE-D-23-10817 [pii]
AID - 10.1371/journal.pone.0288453 [doi]
PST - epublish
SO  - PLoS One. 2023 Aug 9;18(8):e0288453. doi: 10.1371/journal.pone.0288453. 
      eCollection 2023.

PMID- 37595113
OWN - NLM
STAT- Publisher
LR  - 20230818
IS  - 1097-6817 (Electronic)
IS  - 0194-5998 (Linking)
DP  - 2023 Aug 18
TI  - Accuracy of ChatGPT-Generated Information on Head and Neck and Oromaxillofacial 
      Surgery: A Multicenter Collaborative Analysis.
LID - 10.1002/ohn.489 [doi]
AB  - OBJECTIVE: To investigate the accuracy of Chat-Based Generative Pre-trained 
      Transformer (ChatGPT) in answering questions and solving clinical scenarios of 
      head and neck surgery. STUDY DESIGN: Observational and valuative study. SETTING: 
      Eighteen surgeons from 14 Italian head and neck surgery units. METHODS: A total 
      of 144 clinical questions encompassing different subspecialities of head and neck 
      surgery and 15 comprehensive clinical scenarios were developed. Questions and 
      scenarios were inputted into ChatGPT4, and the resulting answers were evaluated 
      by the researchers using accuracy (range 1-6), completeness (range 1-3), and 
      references' quality Likert scales. RESULTS: The overall median score of 
      open-ended questions was 6 (interquartile range[IQR]: 5-6) for accuracy and 3 
      (IQR: 2-3) for completeness. Overall, the reviewers rated the answer as entirely 
      or nearly entirely correct in 87.2% of cases and as comprehensive and covering 
      all aspects of the question in 73% of cases. The artificial intelligence (AI) 
      model achieved a correct response in 84.7% of the closed-ended questions (11 
      wrong answers). As for the clinical scenarios, ChatGPT provided a fully or nearly 
      fully correct diagnosis in 81.7% of cases. The proposed diagnostic or therapeutic 
      procedure was judged to be complete in 56.7% of cases. The overall quality of the 
      bibliographic references was poor, and sources were nonexistent in 46.4% of the 
      cases. CONCLUSION: The results generally demonstrate a good level of accuracy in 
      the AI's answers. The AI's ability to resolve complex clinical scenarios is 
      promising, but it still falls short of being considered a reliable support for 
      the decision-making process of specialists in head-neck surgery.
CI  - © 2023 The Authors. Otolaryngology-Head and Neck Surgery published by Wiley 
      Periodicals LLC on behalf of American Academy of Otolaryngology-Head and Neck 
      Surgery Foundation.
FAU - Vaira, Luigi Angelo
AU  - Vaira LA
AUID- ORCID: 0000-0002-7789-145X
AD  - Maxillofacial Surgery Operative Unit, Department of Medicine, Surgery and 
      Pharmacy, University of Sassari, Sassari, Italy.
AD  - Biomedical Sciences Department, PhD School of Biomedical Science, University of 
      Sassari, Sassari, Italy.
FAU - Lechien, Jerome R
AU  - Lechien JR
AD  - Department of Anatomy and Experimental Oncology, Mons School of Medicine, UMONS, 
      Research Institute for Health Sciences and Technology, University of Mons 
      (UMons), Mons, Belgium.
AD  - Department of Otolaryngology-Head Neck Surgery, Elsan Polyclinic of Poitiers, 
      Poitiers, France.
FAU - Abbate, Vincenzo
AU  - Abbate V
AD  - Head and Neck Section, Department of Neurosciences, Reproductive and 
      Odontostomatological Science, Federico II University of Naples, Naples, Italy.
FAU - Allevi, Fabiana
AU  - Allevi F
AD  - Maxillofacial Surgery Department, ASSt Santi Paolo e Carlo, University of Milan, 
      Milan, Italy.
FAU - Audino, Giovanni
AU  - Audino G
AD  - Head and Neck Section, Department of Neurosciences, Reproductive and 
      Odontostomatological Science, Federico II University of Naples, Naples, Italy.
FAU - Beltramini, Giada Anna
AU  - Beltramini GA
AD  - Department of Biomedical, Surgical and Dental Sciences, University of Milan, 
      Milan, Italy.
AD  - Maxillofacial and Dental Unit, Fondazione IRCCS Cà Granda Ospedale Maggiore 
      Policlinico, Milan, Italy.
FAU - Bergonzani, Michela
AU  - Bergonzani M
AD  - Maxillo-Facial Surgery Division, Head and Neck Department, University Hospital of 
      Parma, Parma, Italy.
FAU - Bolzoni, Alessandro
AU  - Bolzoni A
AD  - Department of Biomedical, Surgical and Dental Sciences, University of Milan, 
      Milan, Italy.
FAU - Committeri, Umberto
AU  - Committeri U
AD  - Head and Neck Section, Department of Neurosciences, Reproductive and 
      Odontostomatological Science, Federico II University of Naples, Naples, Italy.
FAU - Crimi, Salvatore
AU  - Crimi S
AD  - Operative Unit of Maxillofacial Surgery, Policlinico San Marco, University of 
      Catania, Catania, Italy.
FAU - Gabriele, Guido
AU  - Gabriele G
AD  - Department of Maxillofacial Surgery, University of Siena, Siena, Italy.
FAU - Lonardi, Fabio
AU  - Lonardi F
AD  - Department of Maxillofacial Surgery, University of Verona, Verona, Italy.
FAU - Maglitto, Fabio
AU  - Maglitto F
AD  - Maxillo-Facial Surgery Unit, University of Bari "Aldo Moro", Bari, Italy.
FAU - Petrocelli, Marzia
AU  - Petrocelli M
AD  - Maxillofacial Surgery Operative Unit, Bellaria and Maggiore Hospital, Bologna, 
      Italy.
FAU - Pucci, Resi
AU  - Pucci R
AD  - Maxillofacial Surgery Unit, San Camillo-Forlanini Hospital, Rome, Italy.
FAU - Saponaro, Gianmarco
AU  - Saponaro G
AD  - Maxillo-Facial Surgery Unit, IRCSS "A. Gemelli" Foundation-Catholic, University 
      of the Sacred Heart, Rome, Italy.
FAU - Tel, Alessandro
AU  - Tel A
AD  - Department of Head and Neck Surgery and Neuroscience, Clinic of Maxillofacial 
      Surgery, University Hospital of Udine, Udine, Italy.
FAU - Vellone, Valentino
AU  - Vellone V
AD  - Maxillofacial Surgery Unit, "S. Maria" Hospital, Terni, Italy.
FAU - Chiesa-Estomba, Carlos Miguel
AU  - Chiesa-Estomba CM
AD  - Department of Otorhinolaryngology-Head and Neck Surgery, Hospital Universitario 
      Donostia, San Sebastian, Spain.
FAU - Boscolo-Rizzo, Paolo
AU  - Boscolo-Rizzo P
AD  - Department of Medical, Surgical and Health Sciences, Section of Otolaryngology, 
      University of Trieste, Trieste, Italy.
FAU - Salzano, Giovanni
AU  - Salzano G
AD  - Head and Neck Section, Department of Neurosciences, Reproductive and 
      Odontostomatological Science, Federico II University of Naples, Naples, Italy.
FAU - De Riu, Giacomo
AU  - De Riu G
AD  - Maxillofacial Surgery Operative Unit, Department of Medicine, Surgery and 
      Pharmacy, University of Sassari, Sassari, Italy.
LA  - eng
PT  - Journal Article
DEP - 20230818
PL  - England
TA  - Otolaryngol Head Neck Surg
JT  - Otolaryngology--head and neck surgery : official journal of American Academy of 
      Otolaryngology-Head and Neck Surgery
JID - 8508176
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - maxillofacial surgery
OT  - otorhinolaryngology
EDAT- 2023/08/18 18:41
MHDA- 2023/08/18 18:41
CRDT- 2023/08/18 15:23
PHST- 2023/06/16 00:00 [revised]
PHST- 2023/04/27 00:00 [received]
PHST- 2023/07/14 00:00 [accepted]
PHST- 2023/08/18 18:41 [medline]
PHST- 2023/08/18 18:41 [pubmed]
PHST- 2023/08/18 15:23 [entrez]
AID - 10.1002/ohn.489 [doi]
PST - aheadofprint
SO  - Otolaryngol Head Neck Surg. 2023 Aug 18. doi: 10.1002/ohn.489.

PMID- 37257813
OWN - NLM
STAT- MEDLINE
DCOM- 20230717
LR  - 20231121
IS  - 1873-6246 (Electronic)
IS  - 0301-0511 (Linking)
VI  - 181
DP  - 2023 Jul
TI  - Generative artificial intelligence in publishing - Reflection and discussion.
PG  - 108595
LID - S0301-0511(23)00112-6 [pii]
LID - 10.1016/j.biopsycho.2023.108595 [doi]
FAU - Dien, Joseph
AU  - Dien J
AD  - Department of Human Development and Quantitative Methodology, University of 
      Maryland, 3304 Benjamin Building, College Park, MD 20742, USA. Electronic 
      address: jdien07@mac.com.
FAU - Ritz, Thomas
AU  - Ritz T
AD  - Department of Psychology, Southern Methodist University, P.O. Box 750442, Dallas, 
      TX 75275-0442, USA.
LA  - eng
PT  - Editorial
DEP - 20230529
PL  - Netherlands
TA  - Biol Psychol
JT  - Biological psychology
JID - 0375566
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Publishing
OTO - NOTNLM
OT  - Academic Misconduct
OT  - Artificial Intelligence
OT  - ChatGPT
OT  - Large Language Models
OT  - Plagiarism
COIS- Declaration of Competing Interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2023/06/01 01:08
MHDA- 2023/07/17 06:42
CRDT- 2023/05/31 19:29
PHST- 2023/05/26 00:00 [received]
PHST- 2023/05/27 00:00 [accepted]
PHST- 2023/07/17 06:42 [medline]
PHST- 2023/06/01 01:08 [pubmed]
PHST- 2023/05/31 19:29 [entrez]
AID - S0301-0511(23)00112-6 [pii]
AID - 10.1016/j.biopsycho.2023.108595 [doi]
PST - ppublish
SO  - Biol Psychol. 2023 Jul;181:108595. doi: 10.1016/j.biopsycho.2023.108595. Epub 
      2023 May 29.

PMID- 37461512
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240315
DP  - 2023 Jul 8
TI  - Leveraging Generative AI to Prioritize Drug Repurposing Candidates: Validating 
      Identified Candidates for Alzheimer's Disease in Real-World Clinical Datasets.
LID - 2023.07.07.23292388 [pii]
LID - 10.1101/2023.07.07.23292388 [doi]
AB  - Drug repurposing represents an attractive alternative to the costly and 
      time-consuming process of new drug development, particularly for serious, 
      widespread conditions with limited effective treatments, such as Alzheimer's 
      disease (AD). Emerging generative artificial intelligence (GAI) technologies like 
      ChatGPT offer the promise of expediting the review and summary of scientific 
      knowledge. To examine the feasibility of using GAI for identifying drug 
      repurposing candidates, we iteratively tasked ChatGPT with proposing the twenty 
      most promising drugs for repurposing in AD, and tested the top ten for risk of 
      incident AD in exposed and unexposed individuals over age 65 in two large 
      clinical datasets: 1) Vanderbilt University Medical Center and 2) the All of Us 
      Research Program. Among the candidates suggested by ChatGPT, metformin, 
      simvastatin, and losartan were associated with lower AD risk in meta-analysis. 
      These findings suggest GAI technologies can assimilate scientific insights from 
      an extensive Internet-based search space, helping to prioritize drug repurposing 
      candidates and facilitate the treatment of diseases.
FAU - Yan, Chao
AU  - Yan C
FAU - Grabowska, Monika E
AU  - Grabowska ME
AUID- ORCID: 0000-0003-0708-676X
FAU - Dickson, Alyson L
AU  - Dickson AL
FAU - Li, Bingshan
AU  - Li B
FAU - Wen, Zhexing
AU  - Wen Z
FAU - Roden, Dan M
AU  - Roden DM
FAU - Stein, C Michael
AU  - Stein CM
FAU - Embí, Peter J
AU  - Embí PJ
FAU - Peterson, Josh F
AU  - Peterson JF
FAU - Feng, QiPing
AU  - Feng Q
FAU - Malin, Bradley A
AU  - Malin BA
FAU - Wei, Wei-Qi
AU  - Wei WQ
LA  - eng
GR  - F30 AG080885/AG/NIA NIH HHS/United States
GR  - R01 HL163854/HL/NHLBI NIH HHS/United States
PT  - Preprint
DEP - 20230708
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
UIN - NPJ Digit Med. 2024 Feb 26;7(1):46. PMID: 38409350
PMC - PMC10350158
EDAT- 2023/07/18 06:42
MHDA- 2023/07/18 06:43
PMCR- 2023/07/16
CRDT- 2023/07/18 03:37
PHST- 2023/07/18 06:43 [medline]
PHST- 2023/07/18 06:42 [pubmed]
PHST- 2023/07/18 03:37 [entrez]
PHST- 2023/07/16 00:00 [pmc-release]
AID - 2023.07.07.23292388 [pii]
AID - 10.1101/2023.07.07.23292388 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2023 Jul 8:2023.07.07.23292388. doi: 
      10.1101/2023.07.07.23292388.

PMID- 37668714
OWN - NLM
STAT- MEDLINE
DCOM- 20231101
LR  - 20231106
IS  - 1432-069X (Electronic)
IS  - 0340-3696 (Linking)
VI  - 315
IP  - 10
DP  - 2023 Dec
TI  - Assessing ChatGPT responses to common patient queries regarding basal cell 
      carcinoma.
PG  - 2979-2981
LID - 10.1007/s00403-023-02705-3 [doi]
FAU - Trager, Megan H
AU  - Trager MH
AUID- ORCID: 0000-0002-7330-1627
AD  - Department of Dermatology, Columbia University Irving Medical Center, Herbert 
      Irving Pavilion, 12th Floor, New York, NY, 10032, USA.
FAU - Queen, Dawn
AU  - Queen D
AUID- ORCID: 0000-0001-5665-102X
AD  - Department of Dermatology, Columbia University Irving Medical Center, Herbert 
      Irving Pavilion, 12th Floor, New York, NY, 10032, USA.
FAU - Bordone, Lindsey A
AU  - Bordone LA
AUID- ORCID: 0000-0001-8700-890X
AD  - Department of Dermatology, Columbia University Irving Medical Center, Herbert 
      Irving Pavilion, 12th Floor, New York, NY, 10032, USA.
FAU - Geskin, Larisa J
AU  - Geskin LJ
AUID- ORCID: 0000-0001-7348-2571
AD  - Department of Dermatology, Columbia University Irving Medical Center, Herbert 
      Irving Pavilion, 12th Floor, New York, NY, 10032, USA.
FAU - Samie, Faramarz H
AU  - Samie FH
AUID- ORCID: 0000-0003-0595-1457
AD  - Department of Dermatology, Columbia University Irving Medical Center, Herbert 
      Irving Pavilion, 12th Floor, New York, NY, 10032, USA. fs2614@cumc.columbia.edu.
LA  - eng
PT  - Letter
DEP - 20230905
PL  - Germany
TA  - Arch Dermatol Res
JT  - Archives of dermatological research
JID - 8000462
SB  - IM
MH  - Humans
MH  - *Carcinoma, Basal Cell/diagnosis/epidemiology
MH  - *Skin Neoplasms/diagnosis
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Basal cell carcinoma
OT  - ChatGPT
EDAT- 2023/09/05 12:42
MHDA- 2023/11/01 12:42
CRDT- 2023/09/05 11:11
PHST- 2023/05/08 00:00 [received]
PHST- 2023/08/13 00:00 [accepted]
PHST- 2023/07/28 00:00 [revised]
PHST- 2023/11/01 12:42 [medline]
PHST- 2023/09/05 12:42 [pubmed]
PHST- 2023/09/05 11:11 [entrez]
AID - 10.1007/s00403-023-02705-3 [pii]
AID - 10.1007/s00403-023-02705-3 [doi]
PST - ppublish
SO  - Arch Dermatol Res. 2023 Dec;315(10):2979-2981. doi: 10.1007/s00403-023-02705-3. 
      Epub 2023 Sep 5.

PMID- 38450533
OWN - NLM
STAT- Publisher
LR  - 20240307
IS  - 0974-7559 (Electronic)
IS  - 0019-6061 (Linking)
DP  - 2024 Mar 7
TI  - ChatGPT in Pediatrics: Unraveling Its Significance as a Clinical Decision Support 
      Tool.
LID - S097475591600610 [pii]
AB  - The integration of artificial intelligence in pediatrics holds transformative 
      potential, reshaping healthcare through innovative approaches to diagnosis, 
      treatment planning, and tailored clinical decision support. In the evaluation of 
      ChatGPT's performance in pediatric case scenarios, the model displayed varying 
      levels of proficiency suggesting the need for continuous refinement and 
      collaboration with senior pediatricians for reliable pediatric decision support.
FAU - Andykarayalar, Ramanath
AU  - Andykarayalar R
AD  - Department of Pediatrics, Panimalar Medical College Hospital and Research 
      Institute, Chennai Tamil Nadu.
FAU - Surapaneni, Krishna Mohan
AU  - Surapaneni KM
AD  - Department of Biochemistry, Panimalar Medical College Hospital and Research 
      Institute, Chennai Tamil Nadu. Correspondence to: Dr. Krishna Mohan Surapaneni, 
      Departments of Biochemistry, Panimalar Medical College Hospital and Research 
      Institute, Varadharajapuram, Poonamallee, Chennai, Tamil Nadu, India. 
      krishnamohan.surapaneni@gmail.com.
LA  - eng
PT  - Journal Article
DEP - 20240307
PL  - India
TA  - Indian Pediatr
JT  - Indian pediatrics
JID - 2985062R
SB  - IM
EDAT- 2024/03/07 06:43
MHDA- 2024/03/07 06:43
CRDT- 2024/03/07 05:37
PHST- 2024/03/07 06:43 [medline]
PHST- 2024/03/07 06:43 [pubmed]
PHST- 2024/03/07 05:37 [entrez]
AID - S097475591600610 [pii]
PST - aheadofprint
SO  - Indian Pediatr. 2024 Mar 7:S097475591600610.

PMID- 37410672
OWN - NLM
STAT- MEDLINE
DCOM- 20230925
LR  - 20230925
IS  - 1469-0756 (Electronic)
IS  - 0032-5473 (Linking)
VI  - 99
IP  - 1176
DP  - 2023 Sep 21
TI  - ChatGPT: the threats to medical education.
PG  - 1130-1131
LID - 10.1093/postmj/qgad046 [doi]
AB  - While it offers abundant advantages, ChatGPT threatens to significantly harm the 
      educational attainment, and the intellectual life, of students of medicine and 
      the subjects that compliment it. This technology poses a serious threat to the 
      ability of such students to deliver safe and effective medical care once they 
      graduate to clinical practice. Institutions that providemedical education must 
      react to the existence, availability, and rapidly increasing competency of GPT 
      models. This article suggests an intervention by which this could be, at least 
      partially, achieved.
CI  - © The Author(s) 2023. Published by Oxford University Press on behalf of 
      Postgraduate Medical Journal. All rights reserved. For permissions, please 
      e-mail: journals.permissions@oup.com.
FAU - Armitage, Richard C
AU  - Armitage RC
AUID- ORCID: 0000-0003-1165-6753
AD  - Academic Unit of Population and Lifespan Sciences, School of Medicine, University 
      of Nottingham, Nottingham, NG5 1PB, United Kingdom.
LA  - eng
PT  - Journal Article
PL  - England
TA  - Postgrad Med J
JT  - Postgraduate medical journal
JID - 0234135
SB  - IM
MH  - Humans
MH  - *Education, Medical
MH  - *Medicine
MH  - Educational Status
MH  - Students
MH  - *Academic Success
OTO - NOTNLM
OT  - artificial intelligence
OT  - emerging technology
OT  - large language modes
OT  - medical education
EDAT- 2023/07/06 19:12
MHDA- 2023/09/25 06:42
CRDT- 2023/07/06 13:13
PHST- 2023/05/01 00:00 [received]
PHST- 2023/05/13 00:00 [accepted]
PHST- 2023/09/25 06:42 [medline]
PHST- 2023/07/06 19:12 [pubmed]
PHST- 2023/07/06 13:13 [entrez]
AID - 7220360 [pii]
AID - 10.1093/postmj/qgad046 [doi]
PST - ppublish
SO  - Postgrad Med J. 2023 Sep 21;99(1176):1130-1131. doi: 10.1093/postmj/qgad046.

PMID- 37598184
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231121
IS  - 2754-6993 (Electronic)
IS  - 2754-6993 (Linking)
VI  - 9
IP  - 1
DP  - 2023 Aug 19
TI  - ChatGPT: these are not hallucinations - they're fabrications and falsifications.
PG  - 52
LID - 10.1038/s41537-023-00379-4 [doi]
LID - 52
FAU - Emsley, Robin
AU  - Emsley R
AD  - Editor, Schizophrenia, . rae@sun.ac.za.
LA  - eng
PT  - Editorial
DEP - 20230819
PL  - Germany
TA  - Schizophrenia (Heidelb)
JT  - Schizophrenia (Heidelberg, Germany)
JID - 9918367987006676
PMC - PMC10439949
COIS- The author declares no competing interests.
EDAT- 2023/08/20 00:41
MHDA- 2023/08/20 00:42
PMCR- 2023/08/19
CRDT- 2023/08/19 23:17
PHST- 2023/07/17 00:00 [received]
PHST- 2023/07/18 00:00 [accepted]
PHST- 2023/08/20 00:42 [medline]
PHST- 2023/08/20 00:41 [pubmed]
PHST- 2023/08/19 23:17 [entrez]
PHST- 2023/08/19 00:00 [pmc-release]
AID - 10.1038/s41537-023-00379-4 [pii]
AID - 379 [pii]
AID - 10.1038/s41537-023-00379-4 [doi]
PST - epublish
SO  - Schizophrenia (Heidelb). 2023 Aug 19;9(1):52. doi: 10.1038/s41537-023-00379-4.

PMID- 36854734
OWN - NLM
STAT- Publisher
LR  - 20240216
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
DP  - 2023 Feb 28
TI  - Quick uptake of ChatGPT, and more - this week's best science graphics.
LID - 10.1038/d41586-023-00603-2 [doi]
LA  - eng
PT  - News
DEP - 20230228
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
OTO - NOTNLM
OT  - Computer science
OT  - Publishing
OT  - Sustainability
EDAT- 2023/03/01 06:00
MHDA- 2023/03/01 06:00
CRDT- 2023/02/28 23:43
PHST- 2023/02/28 23:43 [entrez]
PHST- 2023/03/01 06:00 [pubmed]
PHST- 2023/03/01 06:00 [medline]
AID - 10.1038/d41586-023-00603-2 [pii]
AID - 10.1038/d41586-023-00603-2 [doi]
PST - aheadofprint
SO  - Nature. 2023 Feb 28. doi: 10.1038/d41586-023-00603-2.

PMID- 38144532
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231225
IS  - 2234-943X (Print)
IS  - 2234-943X (Electronic)
IS  - 2234-943X (Linking)
VI  - 13
DP  - 2023
TI  - Corrigendum: Commentary: AI-based online chat and the future of oncology care: a 
      promising technology or a solution in search of a problem?
PG  - 1334176
LID - 10.3389/fonc.2023.1334176 [doi]
LID - 1334176
AB  - [This corrects the article DOI: 10.3389/fonc.2023.1239932.].
CI  - Copyright © 2023 Zhang, Guan, Chen and Tong.
FAU - Zhang, Hui
AU  - Zhang H
AD  - Department of Rehabilitation and Elderly Care, Gannan Healthcare Vocational 
      College, Ganzhou, China.
FAU - Guan, Yongfu
AU  - Guan Y
AD  - Department of Rehabilitation and Elderly Care, Gannan Healthcare Vocational 
      College, Ganzhou, China.
FAU - Chen, Jinping
AU  - Chen J
AD  - Department of Rehabilitation and Elderly Care, Gannan Healthcare Vocational 
      College, Ganzhou, China.
FAU - Tong, Wenting
AU  - Tong W
AD  - Department of Pharmacy, Gannan Healthcare Vocational College, Ganzhou, China.
LA  - eng
PT  - Published Erratum
DEP - 20231207
PL  - Switzerland
TA  - Front Oncol
JT  - Frontiers in oncology
JID - 101568867
EFR - Front Oncol. 2023 Sep 07;13:1239932. PMID: 37746294
PMC - PMC10746848
OTO - NOTNLM
OT  - ChatGPT
OT  - data privacy
OT  - global healthcare resource allocation
OT  - language bias
OT  - legal and ethical challenges
EDAT- 2023/12/25 06:41
MHDA- 2023/12/25 06:42
PMCR- 2023/12/07
CRDT- 2023/12/25 04:37
PHST- 2023/11/09 00:00 [received]
PHST- 2023/11/24 00:00 [accepted]
PHST- 2023/12/25 06:42 [medline]
PHST- 2023/12/25 06:41 [pubmed]
PHST- 2023/12/25 04:37 [entrez]
PHST- 2023/12/07 00:00 [pmc-release]
AID - 10.3389/fonc.2023.1334176 [doi]
PST - epublish
SO  - Front Oncol. 2023 Dec 7;13:1334176. doi: 10.3389/fonc.2023.1334176. eCollection 
      2023.

PMID- 36760131
OWN - NLM
STAT- Publisher
LR  - 20240216
IS  - 1758-1109 (Electronic)
IS  - 1357-633X (Linking)
DP  - 2023 Feb 9
TI  - Can advanced technologies help address the global increase in demand for 
      specialized medical care and improve telehealth services?
PG  - 1357633X231155520
LID - 10.1177/1357633X231155520 [doi]
FAU - Lahat, Adi
AU  - Lahat A
AUID- ORCID: 0000-0003-1513-7280
AD  - Department of Gastroenterology, 26744Chaim Sheba Medical Center, affiliated with 
      Tel Aviv University, Tel Aviv, Israel.
FAU - Klang, Eyal
AU  - Klang E
AD  - The Sami Sagol AI Hub, ARC innovation center, 26744Chaim Sheba Medical Center, 
      Affiliated with Tel-Aviv University, Tel Aviv, Israel.
LA  - eng
PT  - Journal Article
DEP - 20230209
PL  - England
TA  - J Telemed Telecare
JT  - Journal of telemedicine and telecare
JID - 9506702
SB  - IM
OTO - NOTNLM
OT  - Telemedicine
OT  - artificial intelligence (AI)
OT  - chatGPT
OT  - large language models (LLM)
OT  - telehealth
EDAT- 2023/02/11 06:00
MHDA- 2023/02/11 06:00
CRDT- 2023/02/10 01:43
PHST- 2023/02/10 01:43 [entrez]
PHST- 2023/02/11 06:00 [pubmed]
PHST- 2023/02/11 06:00 [medline]
AID - 10.1177/1357633X231155520 [doi]
PST - aheadofprint
SO  - J Telemed Telecare. 2023 Feb 9:1357633X231155520. doi: 10.1177/1357633X231155520.

PMID- 37095351
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20230518
LR  - 20230518
IS  - 1546-1696 (Electronic)
IS  - 1087-0156 (Linking)
VI  - 41
IP  - 5
DP  - 2023 May
TI  - Drug discovery companies are customizing ChatGPT: here's how.
PG  - 585-586
LID - 10.1038/s41587-023-01788-7 [doi]
FAU - Savage, Neil
AU  - Savage N
AD  - , Lowell, MA, USA.
LA  - eng
PT  - News
PL  - United States
TA  - Nat Biotechnol
JT  - Nature biotechnology
JID - 9604648
SB  - IM
EDAT- 2023/04/25 00:41
MHDA- 2023/04/25 00:42
CRDT- 2023/04/24 11:30
PHST- 2023/04/25 00:42 [medline]
PHST- 2023/04/25 00:41 [pubmed]
PHST- 2023/04/24 11:30 [entrez]
AID - 10.1038/s41587-023-01788-7 [pii]
AID - 10.1038/s41587-023-01788-7 [doi]
PST - ppublish
SO  - Nat Biotechnol. 2023 May;41(5):585-586. doi: 10.1038/s41587-023-01788-7.

PMID- 38395327
OWN - NLM
STAT- Publisher
LR  - 20240223
IS  - 1879-1891 (Electronic)
IS  - 0002-9394 (Linking)
DP  - 2024 Feb 21
TI  - Comment on "Large Language Models in Ophthalmology Scientific Writing: Ethical 
      Considerations Blurred Lines or Not at All?".
LID - S0002-9394(24)00071-0 [pii]
LID - 10.1016/j.ajo.2023.10.026 [doi]
FAU - Metze, Konradin
AU  - Metze K
AD  - Faculty of Medical Sciences, State University of Campinas, Campinas, SP, Brazil. 
      Electronic address: kmetze@fcm.unicamp.br.
FAU - Lorand-Metze, Irene
AU  - Lorand-Metze I
AD  - Faculty of Medical Sciences, State University of Campinas, Campinas, SP, Brazil.
FAU - Morandin-Reis, Rosana C
AU  - Morandin-Reis RC
AD  - Faculty of Medical Sciences, State University of Campinas, Campinas, SP, Brazil.
FAU - Florindo, João B
AU  - Florindo JB
AD  - Institute of Mathematics, Statistics, and Scientific Computing.
LA  - eng
PT  - Letter
DEP - 20240221
PL  - United States
TA  - Am J Ophthalmol
JT  - American journal of ophthalmology
JID - 0370500
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - hallucination
COIS- Disclosure of conflict of interests The authors have no conflicts of interests to 
      disclose
EDAT- 2024/02/24 11:42
MHDA- 2024/02/24 11:42
CRDT- 2024/02/23 19:18
PHST- 2023/10/13 00:00 [received]
PHST- 2023/10/23 00:00 [accepted]
PHST- 2024/02/24 11:42 [medline]
PHST- 2024/02/24 11:42 [pubmed]
PHST- 2024/02/23 19:18 [entrez]
AID - S0002-9394(24)00071-0 [pii]
AID - 10.1016/j.ajo.2023.10.026 [doi]
PST - aheadofprint
SO  - Am J Ophthalmol. 2024 Feb 21:S0002-9394(24)00071-0. doi: 
      10.1016/j.ajo.2023.10.026.

PMID- 37285189
OWN - NLM
STAT- MEDLINE
DCOM- 20230609
LR  - 20230709
IS  - 2057-5858 (Electronic)
IS  - 2057-5858 (Linking)
VI  - 9
IP  - 6
DP  - 2023 Jun
TI  - Navigating the AI frontier: ethical considerations and best practices in 
      microbial genomics research.
LID - 10.1099/mgen.0.001049 [doi]
LID - mgen001049
FAU - Page, Andrew J
AU  - Page AJ
AD  - Theiagen Genomics, Highlands Ranch, Colorado, USA.
AD  - University of East Anglia, Norfolk, UK.
FAU - Tumelty, Niamh M
AU  - Tumelty NM
AD  - London School of Economics and Political Science, London, UK.
FAU - Sheppard, Samuel K
AU  - Sheppard SK
AD  - Department of Biology, Ineos Oxford Institute, University of Oxford, Oxford, UK.
LA  - eng
PT  - Editorial
PL  - England
TA  - Microb Genom
JT  - Microbial genomics
JID - 101671820
SB  - IM
MH  - *Genomics
MH  - *Artificial Intelligence
PMC - PMC10327496
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - LLM
OT  - ethics
COIS- NMT has a part-time role as managing director of the LSE Press which is part of 
      the London School of Economics and Political Science. The other authors have no 
      conflicts.
EDAT- 2023/06/07 13:10
MHDA- 2023/06/09 06:41
PMCR- 2023/06/07
CRDT- 2023/06/07 11:53
PHST- 2023/06/09 06:41 [medline]
PHST- 2023/06/07 13:10 [pubmed]
PHST- 2023/06/07 11:53 [entrez]
PHST- 2023/06/07 00:00 [pmc-release]
AID - 001049 [pii]
AID - 10.1099/mgen.0.001049 [doi]
PST - ppublish
SO  - Microb Genom. 2023 Jun;9(6):mgen001049. doi: 10.1099/mgen.0.001049.

PMID- 38441296
OWN - NLM
STAT- Publisher
LR  - 20240305
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Linking)
DP  - 2024 Mar 4
TI  - Large language models and generative AI in telehealth: a responsible use lens.
LID - ocae035 [pii]
LID - 10.1093/jamia/ocae035 [doi]
AB  - OBJECTIVE: This scoping review aims to assess the current research landscape of 
      the application and use of large language models (LLMs) and generative Artificial 
      Intelligence (AI), through tools such as ChatGPT in telehealth. Additionally, the 
      review seeks to identify key areas for future research, with a particular focus 
      on AI ethics considerations for responsible use and ensuring trustworthy AI. 
      MATERIALS AND METHODS: Following the scoping review methodological framework, a 
      search strategy was conducted across 6 databases. To structure our review, we 
      employed AI ethics guidelines and principles, constructing a concept matrix for 
      investigating the responsible use of AI in telehealth. Using the concept matrix 
      in our review enabled the identification of gaps in the literature and informed 
      future research directions. RESULTS: Twenty studies were included in the review. 
      Among the included studies, 5 were empirical, and 15 were reviews and 
      perspectives focusing on different telehealth applications and healthcare 
      contexts. Benefit and reliability concepts were frequently discussed in these 
      studies. Privacy, security, and accountability were peripheral themes, with 
      transparency, explainability, human agency, and contestability lacking conceptual 
      or empirical exploration. CONCLUSION: The findings emphasized the potential of 
      LLMs, especially ChatGPT, in telehealth. They provide insights into understanding 
      the use of LLMs, enhancing telehealth services, and taking ethical considerations 
      into account. By proposing three future research directions with a focus on 
      responsible use, this review further contributes to the advancement of this 
      emerging phenomenon of healthcare AI.
CI  - © The Author(s) 2024. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association.
FAU - Pool, Javad
AU  - Pool J
AD  - ARC Industrial Transformation Training Centre for Information Resilience (CIRES), 
      The University of Queensland, Brisbane 4072, Australia.
AD  - School of Electrical Engineering and Computer Science, The University of 
      Queensland, Brisbane 4072, Australia.
FAU - Indulska, Marta
AU  - Indulska M
AD  - ARC Industrial Transformation Training Centre for Information Resilience (CIRES), 
      The University of Queensland, Brisbane 4072, Australia.
AD  - Business School, The University of Queensland, Brisbane 4072, Australia.
FAU - Sadiq, Shazia
AU  - Sadiq S
AD  - ARC Industrial Transformation Training Centre for Information Resilience (CIRES), 
      The University of Queensland, Brisbane 4072, Australia.
AD  - School of Electrical Engineering and Computer Science, The University of 
      Queensland, Brisbane 4072, Australia.
LA  - eng
GR  - IC200100022/ARC Industrial Transformation Training Centre for Information 
      Resilience/
PT  - Journal Article
DEP - 20240304
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - large language models
OT  - responsible use
OT  - telehealth
EDAT- 2024/03/05 12:43
MHDA- 2024/03/05 12:43
CRDT- 2024/03/05 10:03
PHST- 2023/12/18 00:00 [received]
PHST- 2024/02/05 00:00 [revised]
PHST- 2024/02/14 00:00 [accepted]
PHST- 2024/03/05 12:43 [medline]
PHST- 2024/03/05 12:43 [pubmed]
PHST- 2024/03/05 10:03 [entrez]
AID - 7618853 [pii]
AID - 10.1093/jamia/ocae035 [doi]
PST - aheadofprint
SO  - J Am Med Inform Assoc. 2024 Mar 4:ocae035. doi: 10.1093/jamia/ocae035.

PMID- 38366218
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20240229
LR  - 20240229
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
VI  - 626
IP  - 8001
DP  - 2024 Feb
TI  - What the EU's tough AI law means for research and ChatGPT.
PG  - 938-939
LID - 10.1038/d41586-024-00497-8 [doi]
FAU - Gibney, Elizabeth
AU  - Gibney E
LA  - eng
PT  - News
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
OTO - NOTNLM
OT  - Machine learning
OT  - Politics
EDAT- 2024/02/17 12:44
MHDA- 2024/02/17 12:45
CRDT- 2024/02/17 00:10
PHST- 2024/02/17 12:45 [medline]
PHST- 2024/02/17 12:44 [pubmed]
PHST- 2024/02/17 00:10 [entrez]
AID - 10.1038/d41586-024-00497-8 [pii]
AID - 10.1038/d41586-024-00497-8 [doi]
PST - ppublish
SO  - Nature. 2024 Feb;626(8001):938-939. doi: 10.1038/d41586-024-00497-8.

PMID- 37817721
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20231012
LR  - 20231018
IS  - 0030-9982 (Print)
IS  - 0030-9982 (Linking)
VI  - 73
IP  - 9
DP  - 2023 Sep
TI  - Chatgpt: A New Era In Research Writing Assistance.
PG  - 1929-1930
LID - 10.47391/JPMA.9183 [doi]
FAU - Osama, Muhammad
AU  - Osama M
AD  - Foundation University, Islamabad,Pakistan.
FAU - Afridi, Sabah
AU  - Afridi S
AD  - Foundation University, Islamabad,Pakistan.
LA  - eng
PT  - Journal Article
PL  - Pakistan
TA  - J Pak Med Assoc
JT  - JPMA. The Journal of the Pakistan Medical Association
JID - 7501162
SB  - IM
EDAT- 2023/10/11 06:45
MHDA- 2023/10/11 06:46
CRDT- 2023/10/11 03:37
PHST- 2023/10/11 06:46 [medline]
PHST- 2023/10/11 06:45 [pubmed]
PHST- 2023/10/11 03:37 [entrez]
AID - 9183/2618 [pii]
AID - 10.47391/JPMA.9183 [doi]
PST - ppublish
SO  - J Pak Med Assoc. 2023 Sep;73(9):1929-1930. doi: 10.47391/JPMA.9183.

PMID- 37703484
OWN - NLM
STAT- Publisher
LR  - 20231020
IS  - 1546-3141 (Electronic)
IS  - 0361-803X (Linking)
VI  - 221
IP  - 5
DP  - 2023 Nov
TI  - Improving Accuracy in ChatGPT.
PG  - 705
LID - 10.2214/AJR.23.29868 [doi]
FAU - Elek, Alperen
AU  - Elek A
AD  - Ege University Faculty of Medicine, Izmir, Turkey, alperenelek13@gmail.com.
LA  - eng
PT  - Journal Article
DEP - 20230913
PL  - United States
TA  - AJR Am J Roentgenol
JT  - AJR. American journal of roentgenology
JID - 7708173
SB  - IM
EDAT- 2023/09/13 18:41
MHDA- 2023/09/13 18:41
CRDT- 2023/09/13 15:42
PHST- 2023/09/13 18:41 [pubmed]
PHST- 2023/09/13 18:41 [medline]
PHST- 2023/09/13 15:42 [entrez]
AID - 10.2214/AJR.23.29868 [doi]
PST - ppublish
SO  - AJR Am J Roentgenol. 2023 Nov;221(5):705. doi: 10.2214/AJR.23.29868. Epub 2023 
      Sep 13.

PMID- 37565001
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230811
IS  - 1863-2521 (Print)
IS  - 1863-2548 (Electronic)
IS  - 1863-2521 (Linking)
VI  - 17
IP  - 4
DP  - 2023 Aug
TI  - Introducing Journal of Children's Orthopaedics' ChatGPT and generative AI policy.
PG  - 297-298
LID - 10.1177/18632521231191687 [doi]
FAU - Wientroub, Shlomo
AU  - Wientroub S
FAU - Hefti, Fritz
AU  - Hefti F
LA  - eng
PT  - Editorial
DEP - 20230728
PL  - England
TA  - J Child Orthop
JT  - Journal of children's orthopaedics
JID - 101313582
PMC - PMC10411371
EDAT- 2023/08/11 06:43
MHDA- 2023/08/11 06:44
PMCR- 2023/07/28
CRDT- 2023/08/11 04:08
PHST- 2023/08/11 06:44 [medline]
PHST- 2023/08/11 06:43 [pubmed]
PHST- 2023/08/11 04:08 [entrez]
PHST- 2023/07/28 00:00 [pmc-release]
AID - 10.1177_18632521231191687 [pii]
AID - 10.1177/18632521231191687 [doi]
PST - epublish
SO  - J Child Orthop. 2023 Jul 28;17(4):297-298. doi: 10.1177/18632521231191687. 
      eCollection 2023 Aug.

PMID- 37220943
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20230525
LR  - 20230530
IS  - 1756-1833 (Electronic)
IS  - 0959-8138 (Linking)
VI  - 381
DP  - 2023 May 23
TI  - ChatGPT: effective writing is succinct.
PG  - 1125
LID - 10.1136/bmj.p1125 [doi]
FAU - Kovoor, Joshua G
AU  - Kovoor JG
AD  - University of Adelaide, Adelaide, South Australia, Australia.
FAU - Gupta, Aashray K
AU  - Gupta AK
AD  - University of Adelaide, Adelaide, South Australia, Australia.
FAU - Bacchi, Stephen
AU  - Bacchi S
AD  - University of Adelaide, Adelaide, South Australia, Australia.
LA  - eng
PT  - Letter
DEP - 20230523
PL  - England
TA  - BMJ
JT  - BMJ (Clinical research ed.)
JID - 8900488
SB  - IM
COIS- Competing interests: None declared.
EDAT- 2023/05/24 01:06
MHDA- 2023/05/24 01:07
CRDT- 2023/05/23 20:43
PHST- 2023/05/24 01:07 [medline]
PHST- 2023/05/24 01:06 [pubmed]
PHST- 2023/05/23 20:43 [entrez]
AID - 10.1136/bmj.p1125 [doi]
PST - epublish
SO  - BMJ. 2023 May 23;381:1125. doi: 10.1136/bmj.p1125.

PMID- 38206246
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20240226
LR  - 20240226
IS  - 1526-3231 (Electronic)
IS  - 0749-8063 (Linking)
VI  - 40
IP  - 3
DP  - 2024 Mar
TI  - ChatGPT and Impacting Medical Literature.
PG  - 655
LID - S0749-8063(23)00736-3 [pii]
LID - 10.1016/j.arthro.2023.08.069 [doi]
FAU - Kleebayoon, Amnuay
AU  - Kleebayoon A
AD  - Samraong, Cambodia.
FAU - Wiwanitkit, Viroj
AU  - Wiwanitkit V
AD  - Pune, India; Joesph Ayobabalola University, Ikeji-Arakeji, Nigeria.
LA  - eng
PT  - Comment
PT  - Letter
DEP - 20240111
PL  - United States
TA  - Arthroscopy
JT  - Arthroscopy : the journal of arthroscopic &amp; related surgery : official 
      publication of the Arthroscopy Association of North America and the International 
      Arthroscopy Association
JID - 8506498
SB  - IM
CON - Arthroscopy. 2023 May;39(5):1121-1122. PMID: 36797148
EDAT- 2024/01/11 12:42
MHDA- 2024/01/11 12:43
CRDT- 2024/01/11 10:30
PHST- 2023/08/18 00:00 [received]
PHST- 2023/08/31 00:00 [accepted]
PHST- 2024/01/11 12:43 [medline]
PHST- 2024/01/11 12:42 [pubmed]
PHST- 2024/01/11 10:30 [entrez]
AID - S0749-8063(23)00736-3 [pii]
AID - 10.1016/j.arthro.2023.08.069 [doi]
PST - ppublish
SO  - Arthroscopy. 2024 Mar;40(3):655. doi: 10.1016/j.arthro.2023.08.069. Epub 2024 Jan 
      11.

PMID- 37647848
OWN - NLM
STAT- MEDLINE
DCOM- 20231003
LR  - 20231011
IS  - 1578-8865 (Electronic)
IS  - 1138-3593 (Linking)
VI  - 49
IP  - 7
DP  - 2023 Oct
TI  - [Artificial intelligence, ChatGPT and primary care].
PG  - 102069
LID - S1138-3593(23)00149-1 [pii]
LID - 10.1016/j.semerg.2023.102069 [doi]
FAU - Eguia, Hans
AU  - Eguia H
AD  - Rudkøbing lægehuset, Dinamarca, Miembro del grupo de trabajo de nuevas 
      tecnologías SEMERGEN, miembro DSAM - Dinamarca. Electronic address: 
      heguia@uoc.edu.
FAU - Sanz García, Javier Francisco
AU  - Sanz García JF
AD  - Conselleria de Sanitat Valenciana, Coordinador del grupo de trabajo de nuevas 
      tecnologías SEMERGEN. Electronic address: https://twitter.com/@javikin84.
LA  - spa
PT  - Editorial
TT  - Inteligencia artificial, ChatGPT y atención primaria.
DEP - 20230828
PL  - Spain
TA  - Semergen
JT  - Semergen
JID - 9610769
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Primary Health Care
EDAT- 2023/08/31 00:42
MHDA- 2023/10/03 06:47
CRDT- 2023/08/30 18:09
PHST- 2023/07/12 00:00 [received]
PHST- 2023/07/13 00:00 [accepted]
PHST- 2023/10/03 06:47 [medline]
PHST- 2023/08/31 00:42 [pubmed]
PHST- 2023/08/30 18:09 [entrez]
AID - S1138-3593(23)00149-1 [pii]
AID - 10.1016/j.semerg.2023.102069 [doi]
PST - ppublish
SO  - Semergen. 2023 Oct;49(7):102069. doi: 10.1016/j.semerg.2023.102069. Epub 2023 Aug 
      28.

PMID- 38537293
OWN - NLM
STAT- Publisher
LR  - 20240327
IS  - 1361-6560 (Electronic)
IS  - 0031-9155 (Linking)
DP  - 2024 Mar 27
TI  - Advancing medical imaging with language models: featuring a spotlight on ChatGPT.
LID - 10.1088/1361-6560/ad387d [doi]
AB  - This review paper aims to serve as a comprehensive guide and instructional 
      resource for researchers seeking to effectively implement language models in 
      medical imaging research. First, we presented the fundamental principles and 
      evolution of language models, dedicating particular attention to large language 
      models. We then reviewed the current literature on how language models are being 
      used to improve medical imaging, emphasizing a range of applications such as 
      image captioning, report generation, report classification, findings extraction, 
      visual question response systems, interpretable diagnosis and so on. Notably, the 
      capabilities of ChatGPT were spotlighted for researchers to explore its further 
      applications. Furthermore, we covered the advantageous impacts of accurate and 
      efficient language models in medical imaging analysis, such as the enhancement of 
      clinical workflow efficiency, reduction of diagnostic errors, and assistance of 
      clinicians in providing timely and accurate diagnoses. Overall, our goal is to 
      have better integration of language models with medical imaging, thereby 
      inspiring new ideas and innovations. It is our aspiration that this review can 
      serve as a useful resource for researchers in this field, stimulating continued 
      investigative and innovative pursuits of the application of language models in 
      medical imaging.
CI  - Creative Commons Attribution license.
FAU - Hu, Mingzhe
AU  - Hu M
AUID- ORCID: 0000-0001-7523-8927
AD  - Computer Science and Informatics, Emory University, 400 Dowman Dr, Atlanta, GA 
      30307, Atlanta, Georgia, 30322-1007, UNITED STATES.
FAU - Qian, Joshua Yuan
AU  - Qian JY
AUID- ORCID: 0000-0002-3094-9052
AD  - Emory University School of Medicine, 2015 Uppergate Dr, Atlanta, GA 30307, 
      Atlanta, Georgia, 30303-3073, UNITED STATES.
FAU - Pan, Shaoyan
AU  - Pan S
AD  - Department of Computer Science and Informatics, Emory University, 1365 CLIFTON RD 
      NE, ATLANTA, Atlanta, Georgia, 30322-1007, UNITED STATES.
FAU - Li, Yuheng
AU  - Li Y
AD  - Department of Biomedical Engineering, Emory University, 313 Ferst Dr NW, Atlanta, 
      GA 30332, Atlanta, Georgia, 30322-1007, UNITED STATES.
FAU - Qiu, Richard L J
AU  - Qiu RLJ
AD  - Department of Radiology and Sciences Imaging Department of Radiology Oncology, 
      Emory University, 1365-C Clifton Road NE, Atlanta, GA, Atlanta, Georgia, 30322, 
      UNITED STATES.
FAU - Yang, Xiaofeng
AU  - Yang X
AUID- ORCID: 0000-0001-9023-5855
AD  - Department of Radiology Oncology, Emory University, 1365 Clifton Rd # 1-A, 
      Atlanta, GA 30322, Atlanta, Georgia, 30322-1007, UNITED STATES.
LA  - eng
PT  - Journal Article
DEP - 20240327
PL  - England
TA  - Phys Med Biol
JT  - Physics in medicine and biology
JID - 0401220
SB  - IM
OTO - NOTNLM
OT  - BERT
OT  - ChatGPT
OT  - large language model
OT  - medical imaging
OT  - multimodal learning
EDAT- 2024/03/28 00:44
MHDA- 2024/03/28 00:44
CRDT- 2024/03/27 18:53
PHST- 2024/03/28 00:44 [medline]
PHST- 2024/03/28 00:44 [pubmed]
PHST- 2024/03/27 18:53 [entrez]
AID - 10.1088/1361-6560/ad387d [doi]
PST - aheadofprint
SO  - Phys Med Biol. 2024 Mar 27. doi: 10.1088/1361-6560/ad387d.

PMID- 38457221
OWN - NLM
STAT- MEDLINE
DCOM- 20240311
LR  - 20240325
IS  - 2292-9495 (Electronic)
IS  - 2292-9495 (Linking)
VI  - 11
DP  - 2024 Mar 8
TI  - The Temperature Feature of ChatGPT: Modifying Creativity for Clinical Research.
PG  - e53559
LID - 10.2196/53559 [doi]
LID - e53559
AB  - More clinicians and researchers are exploring uses for large language model 
      chatbots, such as ChatGPT, for research, dissemination, and educational purposes. 
      Therefore, it becomes increasingly relevant to consider the full potential of 
      this tool, including the special features that are currently available through 
      the application programming interface. One of these features is a variable called 
      temperature, which changes the degree to which randomness is involved in the 
      model's generated output. This is of particular interest to clinicians and 
      researchers. By lowering this variable, one can generate more consistent outputs; 
      by increasing it, one can receive more creative responses. For clinicians and 
      researchers who are exploring these tools for a variety of tasks, the ability to 
      tailor outputs to be less creative may be beneficial for work that demands 
      consistency. Additionally, access to more creative text generation may enable 
      scientific authors to describe their research in more general language and 
      potentially connect with a broader public through social media. In this 
      viewpoint, we present the temperature feature, discuss potential uses, and 
      provide some examples.
CI  - ©Joshua Davis, Liesbet Van Bulck, Brigitte N Durieux, Charlotta Lindvall. 
      Originally published in JMIR Human Factors (https://humanfactors.jmir.org), 
      08.03.2024.
FAU - Davis, Joshua
AU  - Davis J
AUID- ORCID: 0000-0001-7324-6018
AD  - Department of Psychosocial Oncology and Palliative Care, Dana-Farber Cancer 
      Institute, Boston, MA, United States.
AD  - Albany Medical College, Albany, NY, United States.
FAU - Van Bulck, Liesbet
AU  - Van Bulck L
AUID- ORCID: 0000-0001-8975-4455
AD  - KU Leuven Department of Public Health and Primary Care, KU Leuven-University of 
      Leuven, Leuven, Belgium.
AD  - Research Foundation Flanders (FWO), Brussels, Belgium.
FAU - Durieux, Brigitte N
AU  - Durieux BN
AUID- ORCID: 0000-0001-6036-1420
AD  - Department of Psychosocial Oncology and Palliative Care, Dana-Farber Cancer 
      Institute, Boston, MA, United States.
FAU - Lindvall, Charlotta
AU  - Lindvall C
AUID- ORCID: 0000-0003-2090-2039
AD  - Department of Psychosocial Oncology and Palliative Care, Dana-Farber Cancer 
      Institute, Boston, MA, United States.
AD  - Department of Medicine, Brigham and Women's Hospital, Boston, MA, United States.
AD  - Harvard Medical School, Harvard University, Boston, MA, United States.
LA  - eng
GR  - T35 AG038027/AG/NIA NIH HHS/United States
PT  - Journal Article
DEP - 20240308
PL  - Canada
TA  - JMIR Hum Factors
JT  - JMIR human factors
JID - 101666561
SB  - IM
MH  - Humans
MH  - Temperature
MH  - Educational Status
MH  - *Language
MH  - Research Personnel
MH  - *Social Media
PMC - PMC10960206
OTO - NOTNLM
OT  - ChatGPT
OT  - LLM
OT  - LLMs
OT  - NLP
OT  - artificial intelligence
OT  - clinical communication
OT  - creative
OT  - creativity
OT  - customization
OT  - customize
OT  - customized
OT  - generation
OT  - generative
OT  - language model
OT  - language models
OT  - natural language processing
OT  - random
OT  - randomness
OT  - tailor
OT  - tailored
OT  - temperature
OT  - text
OT  - texts
OT  - textual
COIS- Conflicts of Interest: None declared.
EDAT- 2024/03/08 12:42
MHDA- 2024/03/11 06:42
PMCR- 2024/03/08
CRDT- 2024/03/08 11:54
PHST- 2023/10/11 00:00 [received]
PHST- 2024/01/24 00:00 [accepted]
PHST- 2023/12/11 00:00 [revised]
PHST- 2024/03/11 06:42 [medline]
PHST- 2024/03/08 12:42 [pubmed]
PHST- 2024/03/08 11:54 [entrez]
PHST- 2024/03/08 00:00 [pmc-release]
AID - v11i1e53559 [pii]
AID - 10.2196/53559 [doi]
PST - epublish
SO  - JMIR Hum Factors. 2024 Mar 8;11:e53559. doi: 10.2196/53559.

PMID- 37087108
OWN - NLM
STAT- MEDLINE
DCOM- 20230621
LR  - 20230701
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 30
IP  - 7
DP  - 2023 Jun 20
TI  - Using AI-generated suggestions from ChatGPT to optimize clinical decision 
      support.
PG  - 1237-1245
LID - 10.1093/jamia/ocad072 [doi]
AB  - OBJECTIVE: To determine if ChatGPT can generate useful suggestions for improving 
      clinical decision support (CDS) logic and to assess noninferiority compared to 
      human-generated suggestions. METHODS: We supplied summaries of CDS logic to 
      ChatGPT, an artificial intelligence (AI) tool for question answering that uses a 
      large language model, and asked it to generate suggestions. We asked human 
      clinician reviewers to review the AI-generated suggestions as well as 
      human-generated suggestions for improving the same CDS alerts, and rate the 
      suggestions for their usefulness, acceptance, relevance, understanding, workflow, 
      bias, inversion, and redundancy. RESULTS: Five clinicians analyzed 36 
      AI-generated suggestions and 29 human-generated suggestions for 7 alerts. Of the 
      20 suggestions that scored highest in the survey, 9 were generated by ChatGPT. 
      The suggestions generated by AI were found to offer unique perspectives and were 
      evaluated as highly understandable and relevant, with moderate usefulness, low 
      acceptance, bias, inversion, redundancy. CONCLUSION: AI-generated suggestions 
      could be an important complementary part of optimizing CDS alerts, can identify 
      potential improvements to alert logic and support their implementation, and may 
      even be able to assist experts in formulating their own suggestions for CDS 
      improvement. ChatGPT shows great potential for using large language models and 
      reinforcement learning from human feedback to improve CDS alert logic and 
      potentially other medical areas involving complex, clinical logic, a key step in 
      the development of an advanced learning health system.
CI  - © The Author(s) 2023. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association.
FAU - Liu, Siru
AU  - Liu S
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee, USA.
FAU - Wright, Aileen P
AU  - Wright AP
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee, USA.
AD  - Department of Medicine, Vanderbilt University Medical Center, Nashville, 
      Tennessee, USA.
FAU - Patterson, Barron L
AU  - Patterson BL
AD  - Department of Pediatrics, Vanderbilt University Medical Center, Nashville, 
      Tennessee, USA.
FAU - Wanderer, Jonathan P
AU  - Wanderer JP
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee, USA.
AD  - Department of Anesthesiology, Vanderbilt University Medical Center, Nashville, 
      Tennessee, USA.
FAU - Turer, Robert W
AU  - Turer RW
AUID- ORCID: 0000-0003-1387-640X
AD  - Department of Emergency Medicine, University of Texas Southwestern Medical 
      Center, Dallas, Texas, USA.
AD  - Clinical Informatics Center, University of Texas Southwestern Medical Center, 
      Dallas, Texas, USA.
FAU - Nelson, Scott D
AU  - Nelson SD
AUID- ORCID: 0000-0002-1941-1817
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee, USA.
FAU - McCoy, Allison B
AU  - McCoy AB
AUID- ORCID: 0000-0003-2292-9147
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee, USA.
FAU - Sittig, Dean F
AU  - Sittig DF
AUID- ORCID: 0000-0001-5811-8915
AD  - School of Biomedical Informatics, University of Texas Health Science Center, 
      Houston, Texas, USA.
FAU - Wright, Adam
AU  - Wright A
AUID- ORCID: 0000-0001-6844-145X
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee, USA.
LA  - eng
GR  - K99 LM014097/LM/NLM NIH HHS/United States
GR  - R01 LM013995/LM/NLM NIH HHS/United States
GR  - R01 AG062499/AG/NIA NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
MH  - Humans
MH  - Artificial Intelligence
MH  - *Decision Support Systems, Clinical
MH  - Language
MH  - *Learning Health System
MH  - Workflow
PMC - PMC10280357
OTO - NOTNLM
OT  - artificial intelligence
OT  - clinical decision support
OT  - large language model
COIS- The authors do not have conflicts of interest related to this study.
EDAT- 2023/04/23 00:41
MHDA- 2023/06/21 06:42
PMCR- 2023/04/22
CRDT- 2023/04/22 20:32
PHST- 2023/02/21 00:00 [received]
PHST- 2023/03/28 00:00 [revised]
PHST- 2023/04/11 00:00 [accepted]
PHST- 2023/06/21 06:42 [medline]
PHST- 2023/04/23 00:41 [pubmed]
PHST- 2023/04/22 20:32 [entrez]
PHST- 2023/04/22 00:00 [pmc-release]
AID - 7136722 [pii]
AID - ocad072 [pii]
AID - 10.1093/jamia/ocad072 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2023 Jun 20;30(7):1237-1245. doi: 10.1093/jamia/ocad072.

PMID- 38391760
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240225
IS  - 2076-3425 (Print)
IS  - 2076-3425 (Electronic)
IS  - 2076-3425 (Linking)
VI  - 14
IP  - 2
DP  - 2024 Feb 19
TI  - Revealing the Complexity of Fatigue: A Review of the Persistent Challenges and 
      Promises of Artificial Intelligence.
LID - 10.3390/brainsci14020186 [doi]
LID - 186
AB  - Part I reviews persistent challenges obstructing progress in understanding 
      complex fatigue's biology. Difficulties quantifying subjective symptoms, mapping 
      multi-factorial mechanisms, accounting for individual variation, enabling 
      invasive sensing, overcoming research/funding insularity, and more are discussed. 
      Part II explores how emerging artificial intelligence and machine and deep 
      learning techniques can help address limitations through pattern recognition of 
      complex physiological signatures as more objective biomarkers, predictive 
      modeling to capture individual differences, consolidation of disjointed findings 
      via data mining, and simulation to explore interventions. Conversational agents 
      like Claude and ChatGPT also have potential to accelerate human fatigue research, 
      but they currently lack capacities for robust autonomous contributions. 
      Envisioned is an innovation timeline where synergistic application of enhanced 
      neuroimaging, biosensors, closed-loop systems, and other advances combined with 
      AI analytics could catalyze transformative progress in elucidating fatigue neural 
      circuitry and treating associated conditions over the coming decades.
FAU - Rudroff, Thorsten
AU  - Rudroff T
AUID- ORCID: 0000-0002-2057-7793
AD  - Department of Health and Human Physiology, University of Iowa, Iowa City, IA 
      52242, USA.
AD  - Department of Neurology, University of Iowa Hospitals and Clinics, Iowa City, IA 
      52242, USA.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20240219
PL  - Switzerland
TA  - Brain Sci
JT  - Brain sciences
JID - 101598646
PMC - PMC10886506
OTO - NOTNLM
OT  - ChatGPT
OT  - Claude
OT  - artificial intelligence
OT  - deep learning
OT  - fatigue
OT  - machine learning
COIS- The author declares no conflicts of interest.
EDAT- 2024/02/23 12:42
MHDA- 2024/02/23 12:43
PMCR- 2024/02/19
CRDT- 2024/02/23 10:15
PHST- 2024/01/08 00:00 [received]
PHST- 2024/01/31 00:00 [revised]
PHST- 2024/02/16 00:00 [accepted]
PHST- 2024/02/23 12:43 [medline]
PHST- 2024/02/23 12:42 [pubmed]
PHST- 2024/02/23 10:15 [entrez]
PHST- 2024/02/19 00:00 [pmc-release]
AID - brainsci14020186 [pii]
AID - brainsci-14-00186 [pii]
AID - 10.3390/brainsci14020186 [doi]
PST - epublish
SO  - Brain Sci. 2024 Feb 19;14(2):186. doi: 10.3390/brainsci14020186.

PMID- 38259432
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240124
IS  - 2673-7647 (Electronic)
IS  - 2673-7647 (Linking)
VI  - 3
DP  - 2023
TI  - No-boundary thinking for artificial intelligence in bioinformatics and education.
PG  - 1332902
LID - 10.3389/fbinf.2023.1332902 [doi]
LID - 1332902
AB  - No-boundary thinking enables the scientific community to reflect in a thoughtful 
      manner and discover new opportunities, create innovative solutions, and break 
      through barriers that might have otherwise constrained their progress. This 
      concept encourages thinking without being confined by traditional rules, 
      limitations, or established norms, and a mindset that is not limited by previous 
      work, leading to fresh perspectives and innovative outcomes. So, where do we see 
      the field of artificial intelligence (AI) in bioinformatics going in the next 
      30&nbsp;years? That was the theme of a "No-Boundary Thinking" Session as part of the 
      Mid-South Computational Bioinformatics Society's (MCBIOS) 19th annual meeting in 
      Irving, Texas. This session addressed various areas of AI in an open discussion 
      and raised some perspectives on how popular tools like ChatGPT can be integrated 
      into bioinformatics, communicating with scientists in different fields to 
      properly utilize the potential of these algorithms, and how to continue 
      educational outreach to further interest of data science and informatics to the 
      next-generation of scientists.
CI  - Copyright © 2024 Patel, Pillai and Toby.
FAU - Patel, Prajay
AU  - Patel P
AD  - Chemistry Department, University of Dallas, Irving, TX, United States.
FAU - Pillai, Nisha
AU  - Pillai N
AD  - Department of Computer Science, Mississippi State University, Starkville, MS, 
      United States.
FAU - Toby, Inimary
AU  - Toby I
AD  - Biology Department, University of Dallas, Irving, TX, United States.
LA  - eng
PT  - Journal Article
DEP - 20240108
PL  - Switzerland
TA  - Front Bioinform
JT  - Frontiers in bioinformatics
JID - 9918227263306676
PMC - PMC10800434
OTO - NOTNLM
OT  - ChatGPT
OT  - NIBLSE
OT  - artificial intelligence
OT  - bioinformatics and computational biology
OT  - education -active learning
OT  - no-boundary thinking
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2024/01/23 12:43
MHDA- 2024/01/23 12:44
PMCR- 2024/01/08
CRDT- 2024/01/23 10:26
PHST- 2023/11/03 00:00 [received]
PHST- 2023/12/19 00:00 [accepted]
PHST- 2024/01/23 12:44 [medline]
PHST- 2024/01/23 12:43 [pubmed]
PHST- 2024/01/23 10:26 [entrez]
PHST- 2024/01/08 00:00 [pmc-release]
AID - 1332902 [pii]
AID - 10.3389/fbinf.2023.1332902 [doi]
PST - epublish
SO  - Front Bioinform. 2024 Jan 8;3:1332902. doi: 10.3389/fbinf.2023.1332902. 
      eCollection 2023.

PMID- 37941716
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231110
IS  - 2433-3298 (Electronic)
IS  - 2433-328X (Print)
IS  - 2433-328X (Linking)
VI  - 6
IP  - 4
DP  - 2023 Oct 16
TI  - Beyond the Pass Mark: Accuracy of ChatGPT and Bing in the National Medical 
      Licensure Examination in Japan.
PG  - 536-538
LID - 10.31662/jmaj.2023-0043 [doi]
FAU - Kataoka, Yuki
AU  - Kataoka Y
AD  - Department of Internal Medicine, Kyoto Min-iren Asukai Hospital, Kyoto, Japan.
AD  - Scientific Research Works Peer Support Group (SRWS-PSG), Osaka, Japan.
AD  - Section of Clinical Epidemiology, Department of Community Medicine, Kyoto 
      University Graduate School of Medicine, Kyoto, Japan.
AD  - Department of Healthcare Epidemiology, Kyoto University Graduate School of 
      Medicine/School of Public Health, Kyoto, Japan.
FAU - Yamamoto-Kataoka, Sachiko
AU  - Yamamoto-Kataoka S
AD  - Department of Health Informatics, Kyoto University Graduate School of 
      Medicine/School of Public Health, Kyoto, Japan.
FAU - So, Ryuhei
AU  - So R
AD  - Department of Psychiatry, Okayama Psychiatric Medical Center, Okayama, Japan.
FAU - Furukawa, Toshi A
AU  - Furukawa TA
AD  - Department of Health Promotion and Human Behavior, Kyoto University Graduate 
      School of Medicine/School of Public Health, Kyoto, Japan.
LA  - eng
PT  - Journal Article
DEP - 20230920
PL  - Japan
TA  - JMA J
JT  - JMA journal
JID - 101769797
PMC - PMC10628311
OTO - NOTNLM
OT  - ChatGPT
OT  - Evidence-based Medicine
OT  - Large Language Model
COIS- Yuki Kataoka: None declared; Sachiko Yamamoto-Kataoka: None declared; Ryuhei So: 
      RS has received research grants from the Japan Society for the Promotion of 
      Science (JSPS); Ministry of Health, Labor, and Welfare, Japan; Japan Agency for 
      Medical Research and Development; Osake-no-Kagaku Foundation; The Mental Health 
      Okamoto Memorial Foundation; and Kobayashi Magobe Memorial Medical Foundation; 
      and speaker’s honoraria from Otsuka Pharmaceutical Co., Ltd., Nippon Shinyaku 
      Co., Ltd. and Takeda Pharmaceutical Co., Ltd. outside the submitted work. RS also 
      reports an employment position at CureApp Inc., which develops software as 
      medical devices; Toshi A. Furukawa: TAF reports personal fees from 
      Boehringer-Ingelheim, DT Axis, Kyoto University Original, Shionogi and SONY, and 
      a grant from Shionogi, outside the submitted work; In addition, TAF has patents 
      2020-548587 and 2022-082495 pending, and intellectual properties for Kokoro-app 
      licensed to Mitsubishi-Tanabe.
EDAT- 2023/11/09 06:42
MHDA- 2023/11/09 06:43
PMCR- 2023/09/20
CRDT- 2023/11/09 04:10
PHST- 2023/03/22 00:00 [received]
PHST- 2023/06/21 00:00 [accepted]
PHST- 2023/11/09 06:43 [medline]
PHST- 2023/11/09 06:42 [pubmed]
PHST- 2023/11/09 04:10 [entrez]
PHST- 2023/09/20 00:00 [pmc-release]
AID - 10.31662/jmaj.2023-0043 [doi]
PST - ppublish
SO  - JMA J. 2023 Oct 16;6(4):536-538. doi: 10.31662/jmaj.2023-0043. Epub 2023 Sep 20.

PMID- 37284994
OWN - NLM
STAT- MEDLINE
DCOM- 20231109
LR  - 20231109
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 51
IP  - 12
DP  - 2023 Dec
TI  - Prompt Engineering with ChatGPT: A Guide for Academic Writers.
PG  - 2629-2633
LID - 10.1007/s10439-023-03272-4 [doi]
AB  - Prompt engineering is a relatively new discipline that refers to the practice of 
      developing and optimizing prompts to effectively utilize large language models, 
      particularly in natural language processing tasks. However, not many writers and 
      researchers are familiar about this discipline. Hence, in this paper, I aim to 
      highlight the significance of prompt engineering for academic writers and 
      researchers, particularly the fledgling, in the rapidly evolving world of 
      artificial intelligence. I also discuss the concepts of prompt engineering, large 
      language models, and the techniques and pitfalls of writing prompts. Here, I 
      contend that by acquiring prompt engineering skills, academic writers can 
      navigate the changing landscape and leverage large language models to enhance 
      their writing process. As artificial intelligence continues to advance and 
      penetrate the arena of academic writing, prompt engineering equips writers and 
      researchers with the essential skills to effectively harness the power of 
      language models. This enables them to confidently explore new opportunities, 
      enhance their writing endeavors, and remain at the forefront of utilizing 
      cutting-edge technologies in their academic pursuits.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Giray, Louie
AU  - Giray L
AUID- ORCID: 0000-0002-1940-035X
AD  - General Education Department, Colegio de Muntinlupa, Muntinlupa City, 
      Philippines. louiegiray@gmail.com.
LA  - eng
PT  - Letter
DEP - 20230607
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - *Artificial Intelligence
MH  - *Writing
OTO - NOTNLM
OT  - Academic writing
OT  - ChatGPT
OT  - Large language models
OT  - Natural language processing
OT  - Prompt engineering
OT  - Prompts
EDAT- 2023/06/07 13:10
MHDA- 2023/11/09 06:41
CRDT- 2023/06/07 11:11
PHST- 2023/05/31 00:00 [received]
PHST- 2023/06/01 00:00 [accepted]
PHST- 2023/11/09 06:41 [medline]
PHST- 2023/06/07 13:10 [pubmed]
PHST- 2023/06/07 11:11 [entrez]
AID - 10.1007/s10439-023-03272-4 [pii]
AID - 10.1007/s10439-023-03272-4 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2023 Dec;51(12):2629-2633. doi: 10.1007/s10439-023-03272-4. Epub 
      2023 Jun 7.

PMID- 37707390
OWN - NLM
STAT- MEDLINE
DCOM- 20231120
LR  - 20231120
IS  - 1938-1344 (Electronic)
IS  - 0190-6011 (Linking)
VI  - 53
IP  - 12
DP  - 2023 Dec
TI  - Pros and Cons of Using Artificial Intelligence Chatbots for Musculoskeletal 
      Rehabilitation Management.
PG  - 1-7
LID - 10.2519/jospt.2023.12000 [doi]
AB  - SYNOPSIS: Artificial intelligence (AI), specifically large language models 
      (LLMs), which focus on the interaction between computers and human language, can 
      influence musculoskeletal rehabilitation management. AI chatbots (eg, ChatGPT, 
      Microsoft Bing, and Google Bard) are a form of large language models designed to 
      understand, interpret, and generate text similar to what is produced by humans. 
      Since their release, chatbots have triggered controversy in the international 
      scientific community, including when they have passed university exams, generated 
      credible scientific abstracts, and shown potential for replacing humans in 
      scientific roles. The controversies extend to the field of musculoskeletal 
      rehabilitation. In this Viewpoint, we describe the potential applications and 
      limitations, and recommended actions for education, clinical practice, and 
      research when using AI chatbots for musculoskeletal rehabilitation management, 
      aspects that may have similar implications for the broader health care community. 
      J Orthop Sports Phys Ther 2023;53(12):1-7. Epub 14 September 2023. 
      doi:10.2519/jospt.2023.12000.
FAU - Rossettini, Giacomo
AU  - Rossettini G
FAU - Cook, Chad
AU  - Cook C
FAU - Palese, Alvisa
AU  - Palese A
FAU - Pillastrini, Paolo
AU  - Pillastrini P
FAU - Turolla, Andrea
AU  - Turolla A
LA  - eng
PT  - Journal Article
PL  - United States
TA  - J Orthop Sports Phys Ther
JT  - The Journal of orthopaedic and sports physical therapy
JID - 7908150
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Language
OTO - NOTNLM
OT  - ChatGPT
OT  - Google Bard
OT  - Microsoft Bing
OT  - artificial intelligence
OT  - clinical reasoning
OT  - musculoskeletal pain
EDAT- 2023/09/14 12:41
MHDA- 2023/11/20 06:54
CRDT- 2023/09/14 09:53
PHST- 2023/11/20 06:54 [medline]
PHST- 2023/09/14 12:41 [pubmed]
PHST- 2023/09/14 09:53 [entrez]
AID - 10.2519/jospt.2023.12000 [doi]
PST - ppublish
SO  - J Orthop Sports Phys Ther. 2023 Dec;53(12):1-7. doi: 10.2519/jospt.2023.12000.

PMID- 37786788
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231004
IS  - 2666-3287 (Electronic)
IS  - 2666-3287 (Linking)
VI  - 13
DP  - 2023 Dec
TI  - Digital health in dermatology.
PG  - 139
LID - 10.1016/j.jdin.2023.08.008 [doi]
FAU - Kantor, Jonathan
AU  - Kantor J
AD  - Department of Dermatology, Center for Global Health, and Center for Clinical 
      Epidemiology and Biostatistics, Perelman School of Medicine at the University of 
      Pennsylvania, Philadelphia, Pennsylvania; Florida Center for Dermatology, St 
      Augustine, Florida; and Alchemy Labs, Oxford, UK.
LA  - eng
PT  - Editorial
DEP - 20230820
PL  - United States
TA  - JAAD Int
JT  - JAAD international
JID - 101774762
PMC - PMC10542012
OTO - NOTNLM
OT  - ChatGPT
OT  - Google Bard
OT  - Microsoft Bing
OT  - artificial intelligence
OT  - copilot
OT  - digital health
OT  - large language models
OT  - machine learning
OT  - medical education
OT  - practice management
OT  - teledermatology
OT  - teledermoscopy
OT  - telemedicine
OT  - whole slide imaging
COIS- None disclosed.
EDAT- 2023/10/03 06:47
MHDA- 2023/10/03 06:48
PMCR- 2023/08/20
CRDT- 2023/10/03 03:50
PHST- 2023/10/03 06:48 [medline]
PHST- 2023/10/03 06:47 [pubmed]
PHST- 2023/10/03 03:50 [entrez]
PHST- 2023/08/20 00:00 [pmc-release]
AID - S2666-3287(23)00132-3 [pii]
AID - 10.1016/j.jdin.2023.08.008 [doi]
PST - epublish
SO  - JAAD Int. 2023 Aug 20;13:139. doi: 10.1016/j.jdin.2023.08.008. eCollection 2023 
      Dec.

PMID- 37268021
OWN - NLM
STAT- MEDLINE
DCOM- 20230920
LR  - 20230920
IS  - 1097-6787 (Electronic)
IS  - 0190-9622 (Linking)
VI  - 89
IP  - 4
DP  - 2023 Oct
TI  - Dermatology in the wake of an AI revolution: Who gets a say?
PG  - e159-e160
LID - S0190-9622(23)00992-1 [pii]
LID - 10.1016/j.jaad.2023.05.053 [doi]
FAU - Beltrami, Eric J
AU  - Beltrami EJ
AD  - University of Connecticut School of Medicine, Farmington, Connecticut.
FAU - Grant-Kels, Jane M
AU  - Grant-Kels JM
AD  - Department of Dermatology, University of Connecticut Health Center, Farmington, 
      Connecticut; Department of Dermatology, University of Florida, Gainesville, 
      Florida. Electronic address: grant@uchc.edu.
LA  - eng
PT  - Comment
PT  - Letter
DEP - 20230601
PL  - United States
TA  - J Am Acad Dermatol
JT  - Journal of the American Academy of Dermatology
JID - 7907132
SB  - IM
CON - J Am Acad Dermatol. 2023 Oct;89(4):e157-e158. PMID: 37263382
MH  - Humans
MH  - *Dermatology
MH  - *Artificial Intelligence
OTO - NOTNLM
OT  - ChatGPT
OT  - accessibility to dermatology
OT  - artificial intelligence
OT  - beneficence
OT  - clinical practice
OT  - ethics
OT  - justice
OT  - language models
OT  - nonmaleficence
COIS- Conflicts of interest Jane Grant-Kels: DermaSensor: advisory board member. This 
      company's specific technology is not discussed in this submission. Eric Beltrami 
      has no conflicts of interest to declare.
EDAT- 2023/06/03 11:42
MHDA- 2023/09/20 06:42
CRDT- 2023/06/02 19:21
PHST- 2023/05/22 00:00 [received]
PHST- 2023/05/22 00:00 [accepted]
PHST- 2023/09/20 06:42 [medline]
PHST- 2023/06/03 11:42 [pubmed]
PHST- 2023/06/02 19:21 [entrez]
AID - S0190-9622(23)00992-1 [pii]
AID - 10.1016/j.jaad.2023.05.053 [doi]
PST - ppublish
SO  - J Am Acad Dermatol. 2023 Oct;89(4):e159-e160. doi: 10.1016/j.jaad.2023.05.053. 
      Epub 2023 Jun 1.

PMID- 37684388
OWN - NLM
STAT- Publisher
LR  - 20231003
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
DP  - 2023 Sep 8
TI  - Scientific sleuths spot dishonest ChatGPT use in papers.
LID - 10.1038/d41586-023-02477-w [doi]
FAU - Conroy, Gemma
AU  - Conroy G
LA  - eng
PT  - News
DEP - 20230908
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
OTO - NOTNLM
OT  - Computer science
OT  - Peer review
OT  - Publishing
EDAT- 2023/09/09 10:41
MHDA- 2023/09/09 10:41
CRDT- 2023/09/08 23:29
PHST- 2023/09/09 10:41 [pubmed]
PHST- 2023/09/09 10:41 [medline]
PHST- 2023/09/08 23:29 [entrez]
AID - 10.1038/d41586-023-02477-w [pii]
AID - 10.1038/d41586-023-02477-w [doi]
PST - aheadofprint
SO  - Nature. 2023 Sep 8. doi: 10.1038/d41586-023-02477-w.

PMID- 37001998
OWN - NLM
STAT- Publisher
LR  - 20230331
IS  - 1544-1717 (Electronic)
IS  - 1544-1709 (Linking)
DP  - 2023 Mar 31
TI  - Why ChatGPT Should Not Be Used to Write Academic Scientific Manuscripts for 
      Publication.
LID - 2958 [pii]
LID - 10.1370/afm.2982 [doi]
AB  - Annals Online First article.
CI  - © 2023 Annals of Family Medicine, Inc.
LA  - eng
PT  - Editorial
DEP - 20230331
PL  - United States
TA  - Ann Fam Med
JT  - Annals of family medicine
JID - 101167762
SB  - IM
EDAT- 2023/04/01 06:00
MHDA- 2023/04/01 06:00
CRDT- 2023/03/31 21:52
PHST- 2023/03/20 00:00 [received]
PHST- 2023/03/20 00:00 [accepted]
PHST- 2023/03/31 21:52 [entrez]
PHST- 2023/04/01 06:00 [pubmed]
PHST- 2023/04/01 06:00 [medline]
AID - afm.2982 [pii]
AID - 10.1370/afm.2982 [doi]
PST - aheadofprint
SO  - Ann Fam Med. 2023 Mar 31:2958. doi: 10.1370/afm.2982.

PMID- 38418736
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20240307
LR  - 20240307
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
VI  - 627
IP  - 8002
DP  - 2024 Mar
TI  - Is ChatGPT making scientists hyper-productive? The highs and lows of using AI.
PG  - 16-17
LID - 10.1038/d41586-024-00592-w [doi]
FAU - Prillaman, McKenzie
AU  - Prillaman M
LA  - eng
PT  - News
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
OTO - NOTNLM
OT  - Computer science
OT  - Machine learning
OT  - Publishing
OT  - Scientific community
EDAT- 2024/02/29 00:43
MHDA- 2024/02/29 00:44
CRDT- 2024/02/28 23:30
PHST- 2024/02/29 00:44 [medline]
PHST- 2024/02/29 00:43 [pubmed]
PHST- 2024/02/28 23:30 [entrez]
AID - 10.1038/d41586-024-00592-w [pii]
AID - 10.1038/d41586-024-00592-w [doi]
PST - ppublish
SO  - Nature. 2024 Mar;627(8002):16-17. doi: 10.1038/d41586-024-00592-w.

PMID- 38114679
OWN - NLM
STAT- MEDLINE
DCOM- 20231221
LR  - 20231221
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
VI  - 624
IP  - 7992
DP  - 2023 Dec
TI  - Should scientists delegate their writing to ChatGPT?
PG  - 523
LID - 10.1038/d41586-023-04055-6 [doi]
FAU - Basgier, Christopher
AU  - Basgier C
FAU - Sharma, Shyam
AU  - Sharma S
LA  - eng
PT  - Letter
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
MH  - *Writing
MH  - *Natural Language Processing
MH  - *Research Personnel
MH  - *Deep Learning
OTO - NOTNLM
OT  - Ethics
OT  - Machine learning
EDAT- 2023/12/20 06:42
MHDA- 2023/12/21 06:43
CRDT- 2023/12/19 23:47
PHST- 2023/12/21 06:43 [medline]
PHST- 2023/12/20 06:42 [pubmed]
PHST- 2023/12/19 23:47 [entrez]
AID - 10.1038/d41586-023-04055-6 [pii]
AID - 10.1038/d41586-023-04055-6 [doi]
PST - ppublish
SO  - Nature. 2023 Dec;624(7992):523. doi: 10.1038/d41586-023-04055-6.

PMID- 37993616
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20231130
LR  - 20231216
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
VI  - 623
IP  - 7989
DP  - 2023 Nov
TI  - ChatGPT generates fake data set to support scientific hypothesis.
PG  - 895-896
LID - 10.1038/d41586-023-03635-w [doi]
FAU - Naddaf, Miryam
AU  - Naddaf M
LA  - eng
PT  - News
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
OTO - NOTNLM
OT  - Machine learning
OT  - Medical research
OT  - Scientific community
EDAT- 2023/11/23 00:41
MHDA- 2023/11/23 00:42
CRDT- 2023/11/22 23:43
PHST- 2023/11/23 00:42 [medline]
PHST- 2023/11/23 00:41 [pubmed]
PHST- 2023/11/22 23:43 [entrez]
AID - 10.1038/d41586-023-03635-w [pii]
AID - 10.1038/d41586-023-03635-w [doi]
PST - ppublish
SO  - Nature. 2023 Nov;623(7989):895-896. doi: 10.1038/d41586-023-03635-w.

PMID- 37197782
OWN - NLM
STAT- MEDLINE
DCOM- 20230519
LR  - 20230623
IS  - 1756-1833 (Electronic)
IS  - 0959-8138 (Linking)
VI  - 381
DP  - 2023 May 17
TI  - ChatGPT and other AI tools put students at risk of plagiarism allegations, MDU 
      warns.
PG  - 1133
LID - 10.1136/bmj.p1133 [doi]
FAU - Graham, Annie
AU  - Graham A
AD  - The BMJ.
LA  - eng
PT  - Journal Article
DEP - 20230517
PL  - England
TA  - BMJ
JT  - BMJ (Clinical research ed.)
JID - 8900488
SB  - IM
CIN - BMJ. 2023 Jun 20;381:1403. PMID: 37339814
MH  - Humans
MH  - *Plagiarism
MH  - *Students
MH  - Artificial Intelligence
EDAT- 2023/05/18 01:07
MHDA- 2023/05/19 06:42
CRDT- 2023/05/17 20:33
PHST- 2023/05/19 06:42 [medline]
PHST- 2023/05/18 01:07 [pubmed]
PHST- 2023/05/17 20:33 [entrez]
AID - 10.1136/bmj.p1133 [doi]
PST - epublish
SO  - BMJ. 2023 May 17;381:1133. doi: 10.1136/bmj.p1133.

PMID- 37772448
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240116
IS  - 1527-330X (Electronic)
IS  - 1090-820X (Linking)
VI  - 44
IP  - 2
DP  - 2024 Jan 16
TI  - Correction to Articles on the Performance of ChatGPT on Plastic Surgery 
      In-Service Training Examinations.
PG  - 232
LID - 10.1093/asj/sjad316 [doi]
LA  - eng
PT  - Published Erratum
PL  - England
TA  - Aesthet Surg J
JT  - Aesthetic surgery journal
JID - 9707469
SB  - IM
EFR - Aesthet Surg J. 2023 Nov 16;43(12):NP1078-NP1082. PMID: 37128784
EFR - Aesthet Surg J. 2023 Nov 16;43(12):NP1085-NP1089. PMID: 37140001
EDAT- 2023/09/29 06:44
MHDA- 2023/09/29 06:45
CRDT- 2023/09/29 05:30
PHST- 2023/09/29 06:45 [medline]
PHST- 2023/09/29 06:44 [pubmed]
PHST- 2023/09/29 05:30 [entrez]
AID - 7285931 [pii]
AID - 10.1093/asj/sjad316 [doi]
PST - ppublish
SO  - Aesthet Surg J. 2024 Jan 16;44(2):232. doi: 10.1093/asj/sjad316.

PMID- 36494443
OWN - NLM
STAT- Publisher
LR  - 20240216
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
DP  - 2022 Dec 9
TI  - AI bot ChatGPT writes smart essays - should professors worry?
LID - 10.1038/d41586-022-04397-7 [doi]
FAU - Stokel-Walker, Chris
AU  - Stokel-Walker C
LA  - eng
PT  - News
DEP - 20221209
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
OTO - NOTNLM
OT  - Computer science
OT  - Education
OT  - Lab life
OT  - Society
EDAT- 2022/12/10 06:00
MHDA- 2022/12/10 06:00
CRDT- 2022/12/09 23:32
PHST- 2022/12/10 06:00 [pubmed]
PHST- 2022/12/10 06:00 [medline]
PHST- 2022/12/09 23:32 [entrez]
AID - 10.1038/d41586-022-04397-7 [pii]
AID - 10.1038/d41586-022-04397-7 [doi]
PST - aheadofprint
SO  - Nature. 2022 Dec 9. doi: 10.1038/d41586-022-04397-7.

PMID- 37542362
OWN - NLM
STAT- MEDLINE
DCOM- 20230807
LR  - 20230926
IS  - 1553-3514 (Electronic)
IS  - 1553-3506 (Linking)
VI  - 30
IP  - 4
DP  - 2023 Aug
TI  - Editorial: Harnessing the Power of AI in Health Care: Benefits, Risks, and 
      Preparation.
PG  - 417-418
LID - 10.1177/15533506231190748 [doi]
FAU - Schijven, Marlies P
AU  - Schijven MP
AD  - Department of Surgery, Amsterdam UMC, University of Amsterdam, Amsterdam, The 
      Netherlands.
AD  - Amsterdam Gastroenterology and Metabolism, Amsterdam UMC, Amsterdam, The 
      Netherlands.
AD  - Amsterdam Public Health, Digital Health, Amsterdam UMC, Amsterdam, The 
      Netherlands.
FAU - Kroh, Matthew
AU  - Kroh M
AD  - Department of General Surgery, Cleveland Clinic, Digestive Disease Institute, 
      Cleveland, OH, USA.
LA  - eng
PT  - Editorial
PL  - United States
TA  - Surg Innov
JT  - Surgical innovation
JID - 101233809
SB  - IM
MH  - *Delivery of Health Care
MH  - *Artificial Intelligence
OTO - NOTNLM
OT  - artificial intelligence (AI)
OT  - augmented reality
OT  - chatGPT
OT  - digital
OT  - innovation
OT  - laparoscopy
OT  - machine learning
OT  - personalized medicine
OT  - robotics
OT  - surgery
EDAT- 2023/08/05 11:43
MHDA- 2023/08/07 06:42
CRDT- 2023/08/05 00:02
PHST- 2023/08/07 06:42 [medline]
PHST- 2023/08/05 11:43 [pubmed]
PHST- 2023/08/05 00:02 [entrez]
AID - 10.1177/15533506231190748 [doi]
PST - ppublish
SO  - Surg Innov. 2023 Aug;30(4):417-418. doi: 10.1177/15533506231190748.

PMID- 38026769
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231201
IS  - 0970-0358 (Print)
IS  - 1998-376X (Electronic)
IS  - 0970-0358 (Linking)
VI  - 56
IP  - 5
DP  - 2023 Oct
TI  - Leveraging Large Language Models (LLM) for the Plastic Surgery Resident Training: 
      Do They Have a Role?
PG  - 413-420
LID - 10.1055/s-0043-1772704 [doi]
AB  - Introduction  Large language models (LLMs) are designed for recognizing, 
      summarizing, translating, predicting, and generating text-based content from 
      knowledge gained from extensive data sets. ChatGPT4 (Generative Pre-trained 
      Transformer 4) (OpenAI, San Francisco, California, United States) is a 
      transformer-based LLM model pretrained on public data as well as data obtained 
      from third-party sources using deep learning techniques of fine tuning and 
      reinforcement learning from human feedback to predict the next text. We wanted to 
      explore the role of LLM as a teaching assistant (TA) in plastic surgery. Material 
      and Methods  TA roles were first identified in available literature, and based on 
      the roles, a list of suitable tasks was created where LLM could be used to 
      perform the task. Prompts designed to be fed in to the LLM (specifically ChatGPT) 
      to generate appropriate output, were then created and fed to the ChatGPT model. 
      The outputs generated were scored by evaluators and compared for interobserver 
      agreement. Results  A final set of eight TA roles were identified where a LLM 
      could be utilized to generate content. These contents were scored for usefulness 
      and accuracy. These were scored independently by the eight study authors in a 
      scoring sheet created for the study. Interobserver agreements for content 
      accuracy, usefulness, and clarity were 100% for content generated for the 
      following: interactive case studies (generation), simulation of preoperative 
      consultations, and generation of ethical considerations. Discussion  LLMs in 
      general and ChatGPT (on which this study is based) in specific, can generate 
      answers to questions and prompts based on huge amount of text fed into the model 
      for training the underlying language model. The answers generated have been found 
      to be accurate, readable, and even indistinguishable from human-generated text. 
      This capability of automated content synthesis can be exploited to generate 
      summaries to text, answer short and long answers, and generate case scenarios. We 
      could identify a few such scenarios where the LLM could in general be utilized to 
      play the role of a TA and aid plastic surgery residents in particular. In 
      addition, these models could also be used by students to obtain feedback and gain 
      reflection which itself stimulates critical thinking. Conclusion  Incorporating 
      LLMs into the educational arsenal of plastic surgery residency programs can 
      provide a dynamic, interactive, and individualized learning experience for 
      residents and prove to be worthy TAs of future.
CI  - Association of Plastic Surgeons of India. This is an open access article 
      published by Thieme under the terms of the Creative Commons 
      Attribution-NonDerivative-NonCommercial License, permitting copying and 
      reproduction so long as the original work is given appropriate credit. Contents 
      may not be used for commercial purposes, or adapted, remixed, transformed or 
      built upon. ( https://creativecommons.org/licenses/by-nc-nd/4.0/ ).
FAU - Mohapatra, Devi Prasad
AU  - Mohapatra DP
AUID- ORCID: 0000-0001-5490-5081
AD  - Department of Plastic Surgery, Jawaharlal Institute of Postgraduate Medical 
      Education and Research (JIPMER), Pondicherry, India.
FAU - Thiruvoth, Friji Meethale
AU  - Thiruvoth FM
AD  - Department of Plastic Surgery, Jawaharlal Institute of Postgraduate Medical 
      Education and Research (JIPMER), Pondicherry, India.
FAU - Tripathy, Satyaswarup
AU  - Tripathy S
AUID- ORCID: 0000-0003-3659-6064
AD  - Department of Plastic Surgery, Post Graduate Institute of Medical Education and 
      Research, Chandigarh, India.
FAU - Rajan, Sheeja
AU  - Rajan S
AUID- ORCID: 0000-0001-5421-6446
AD  - Department of Plastic Surgery, Government Medical College, Thrissur, Kerala, 
      India.
FAU - Vathulya, Madhubari
AU  - Vathulya M
AD  - Department of Burns and Plastic Surgery, All India Institute of Medical Sciences 
      (AIIMS), Rishikesh, Uttarakhand, India.
FAU - Lakshmi, Palukuri
AU  - Lakshmi P
AD  - Department of Plastic Surgery, Osmania General Hospital, Hyderabad, Telangana, 
      India.
FAU - Singh, Veena K
AU  - Singh VK
AUID- ORCID: 0000-0002-2120-6548
AD  - Department of Burns and Plastic Surgery, All India Institute of Medical Sciences 
      (AIIMS), Patna, Bihar, India.
FAU - Haq, Ansar Ul
AU  - Haq AU
AUID- ORCID: 0000-0003-3388-9435
AD  - Department of Burns and Plastic Surgery, All India Institute of Medical Sciences 
      (AIIMS), Rishikesh, Uttarakhand, India.
LA  - eng
PT  - Journal Article
DEP - 20230828
PL  - Germany
TA  - Indian J Plast Surg
JT  - Indian journal of plastic surgery : official publication of the Association of 
      Plastic Surgeons of India
JID - 8405356
PMC - PMC10663077
OTO - NOTNLM
OT  - ChatGPT in education
OT  - educational technology
OT  - future of surgical training
OT  - large language models (LLM)
OT  - plastic surgical education
COIS- Conflict of Interest None declared.
EDAT- 2023/11/29 18:42
MHDA- 2023/11/29 18:43
PMCR- 2023/08/01
CRDT- 2023/11/29 16:57
PHST- 2023/11/29 18:43 [medline]
PHST- 2023/11/29 18:42 [pubmed]
PHST- 2023/11/29 16:57 [entrez]
PHST- 2023/08/01 00:00 [pmc-release]
AID - IJPS-23-6-2230 [pii]
AID - 10.1055/s-0043-1772704 [doi]
PST - epublish
SO  - Indian J Plast Surg. 2023 Aug 28;56(5):413-420. doi: 10.1055/s-0043-1772704. 
      eCollection 2023 Oct.

PMID- 38114830
OWN - NLM
STAT- Publisher
LR  - 20231220
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
DP  - 2023 Dec 19
TI  - These scientists aren't using ChatGPT - here's why.
LID - 10.1038/d41586-023-04071-6 [doi]
FAU - Wong, Carissa
AU  - Wong C
LA  - eng
PT  - News
DEP - 20231219
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
OTO - NOTNLM
OT  - Machine learning
OT  - Scientific community
EDAT- 2023/12/20 06:42
MHDA- 2023/12/20 06:42
CRDT- 2023/12/20 00:01
PHST- 2023/12/20 06:42 [medline]
PHST- 2023/12/20 06:42 [pubmed]
PHST- 2023/12/20 00:01 [entrez]
AID - 10.1038/d41586-023-04071-6 [pii]
AID - 10.1038/d41586-023-04071-6 [doi]
PST - aheadofprint
SO  - Nature. 2023 Dec 19. doi: 10.1038/d41586-023-04071-6.

PMID- 37830256
OWN - NLM
STAT- MEDLINE
DCOM- 20240131
LR  - 20240131
IS  - 1898-018X (Electronic)
IS  - 1897-5593 (Print)
IS  - 1898-018X (Linking)
VI  - 30
IP  - 6
DP  - 2023
TI  - Beyond ChatGPT: What does GPT-4 add to healthcare? The dawn of a new era.
PG  - 1018-1025
LID - 10.5603/cj.97515 [doi]
AB  - Over the past few years, artificial intelligence (AI) has significantly improved 
      healthcare. Once the stuff of science fiction, AI is now widely used, even in our 
      daily lives - often without us thinking about it. All healthcare professionals - 
      especially executives and medical doctors - need to understand the capabilities 
      of advanced AI tools and other breakthrough innovations. This understanding will 
      allow them to recognize opportunities and threats emerging technologies can bring 
      to their organizations. We hope to contribute to a meaningful public discussion 
      about the role of this new type of AI and how our approach to healthcare and 
      medicine can best evolve with the rapid development of this technology. Since 
      medicine learns by example, only a few possible uses of AI in medicine are 
      provided, which merely outline the system's capabilities. Among the examples, it 
      is worth highlighting the roles of AI in medical notes, education, preventive 
      programs, consultation, triage and intervention. It is believed by the authors 
      that large language models such as chat generative pre-trained transformer 
      (ChatGPT) are reaching a level of maturity that will soon impact clinical 
      medicine as a whole and improve the delivery of individualized, compassionate, 
      and scalable healthcare. It is unlikely that AI will replace physicians in the 
      near future. The human aspects of care, including empathy, compassion, critical 
      thinking, and complex decision-making, are invaluable in providing holistic 
      patient care beyond diagnosis and treatment decisions. The GPT-4 has many 
      limitations and cannot replace direct contact between an experienced physician 
      and a patient for even the most seemingly simple consultations, not to mention 
      the ethical and legal aspects of responsibility for diagnosis.
FAU - Wójcik, Simona
AU  - Wójcik S
AD  - LUX MED Llc, Warsaw, Poland.
FAU - Rulkiewicz, Anna
AU  - Rulkiewicz A
AD  - LUX MED Llc, Warsaw, Poland.
FAU - Pruszczyk, Piotr
AU  - Pruszczyk P
AUID- ORCID: 0000-0002-9768-0000
AD  - Department of Internal Medicine and Cardiology with the Center for Diagnosis and 
      Treatment of Venous Thromboembolism, Medical University of Warsaw, Poland.
FAU - Lisik, Wojciech
AU  - Lisik W
AUID- ORCID: 0000-0003-3020-3979
AD  - Department of General and Transplantation Surgery, Medical University of Warsaw, 
      Poland.
FAU - Poboży, Marcin
AU  - Poboży M
AD  - Cichowski Pobozy Healthcare Facility, Maciejowice, Poland.
FAU - Domienik-Karłowicz, Justyna
AU  - Domienik-Karłowicz J
AUID- ORCID: 0000-0001-6122-9755
AD  - Department of Internal Medicine and Cardiology with the Center for Diagnosis and 
      Treatment of Venous Thromboembolism, Medical University of Warsaw, Poland. 
      jdomienik@tlen.pl.
AD  - LUX MED Llc, Warsaw, Poland. jdomienik@tlen.pl.
LA  - eng
PT  - Journal Article
DEP - 20231013
PL  - Poland
TA  - Cardiol J
JT  - Cardiology journal
JID - 101392712
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Educational Status
MH  - *Delivery of Health Care
PMC - PMC10713213
OTO - NOTNLM
OT  - AI in medicine
OT  - ChatGPT
OT  - artificial intelligence
OT  - health IT
OT  - innovations
EDAT- 2023/10/13 06:45
MHDA- 2024/01/31 06:42
PMCR- 2023/12/01
CRDT- 2023/10/13 05:31
PHST- 2023/09/20 00:00 [received]
PHST- 2023/10/03 00:00 [accepted]
PHST- 2024/01/31 06:42 [medline]
PHST- 2023/10/13 06:45 [pubmed]
PHST- 2023/10/13 05:31 [entrez]
PHST- 2023/12/01 00:00 [pmc-release]
AID - VM/OJS/J/97515 [pii]
AID - cardj-30-6-1018 [pii]
AID - 10.5603/cj.97515 [doi]
PST - ppublish
SO  - Cardiol J. 2023;30(6):1018-1025. doi: 10.5603/cj.97515. Epub 2023 Oct 13.

PMID- 37798200
OWN - NLM
STAT- MEDLINE
DCOM- 20231219
LR  - 20231219
IS  - 1399-0020 (Electronic)
IS  - 0901-5027 (Linking)
VI  - 53
IP  - 1
DP  - 2024 Jan
TI  - The impact and opportunities of large language models like ChatGPT in oral and 
      maxillofacial surgery: a narrative review.
PG  - 78-88
LID - S0901-5027(23)00216-3 [pii]
LID - 10.1016/j.ijom.2023.09.005 [doi]
AB  - Since its release at the end of 2022, the social response to ChatGPT, a large 
      language model (LLM), has been huge, as it has revolutionized the way we 
      communicate with computers. This review was performed to describe the technical 
      background of LLMs and to provide a review of the current literature on LLMs in 
      the field of oral and maxillofacial surgery (OMS). The PubMed, Scopus, and Web of 
      Science databases were searched for LLMs and OMS. Adjacent surgical disciplines 
      were included to cover the entire literature, and records from Google Scholar and 
      medRxiv were added. Out of the 57 records identified, 37 were included; 31 (84%) 
      were related to GPT-3.5, four (11%) to GPT-4, and two (5%) to both. Current 
      research on LLMs is mainly limited to research and scientific writing, patient 
      information/communication, and medical education. Classic OMS diseases are 
      underrepresented. The current literature related to LLMs in OMS has a limited 
      evidence level. There is a need to investigate the use of LLMs scientifically and 
      systematically in the core areas of OMS. Although LLMs are likely to add value 
      outside the operating room, the use of LLMs raises ethical and medical regulatory 
      issues that must first be addressed.
CI  - Copyright © 2023 The Author(s). Published by Elsevier Inc. All rights reserved.
FAU - Puladi, B
AU  - Puladi B
AD  - Department of Oral and Maxillofacial Surgery, University Hospital RWTH Aachen, 
      Aachen, Germany; Institute of Medical Informatics, University Hospital RWTH 
      Aachen, Aachen, Germany.
FAU - Gsaxner, C
AU  - Gsaxner C
AD  - Department of Oral and Maxillofacial Surgery, University Hospital RWTH Aachen, 
      Aachen, Germany; Institute of Medical Informatics, University Hospital RWTH 
      Aachen, Aachen, Germany; Institute of Computer Graphics and Vision, Graz 
      University of Technology, Graz, Austria; Department of Oral and Maxillofacial 
      Surgery, Medical University of Graz, Graz, Austria.
FAU - Kleesiek, J
AU  - Kleesiek J
AD  - Institute for AI in Medicine (IKIM), University Hospital Essen (AöR), Essen, 
      Germany.
FAU - Hölzle, F
AU  - Hölzle F
AD  - Department of Oral and Maxillofacial Surgery, University Hospital RWTH Aachen, 
      Aachen, Germany.
FAU - Röhrig, R
AU  - Röhrig R
AD  - Institute of Medical Informatics, University Hospital RWTH Aachen, Aachen, 
      Germany.
FAU - Egger, J
AU  - Egger J
AD  - Institute of Computer Graphics and Vision, Graz University of Technology, Graz, 
      Austria; Institute for AI in Medicine (IKIM), University Hospital Essen (AöR), 
      Essen, Germany. Electronic address: egger@tugraz.at.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20231003
PL  - Denmark
TA  - Int J Oral Maxillofac Surg
JT  - International journal of oral and maxillofacial surgery
JID - 8605826
SB  - IM
MH  - Humans
MH  - *Language
MH  - Communication
MH  - *Surgery, Oral
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Oral and Maxillofacial Surgery
OT  - Review
EDAT- 2023/10/06 00:43
MHDA- 2023/12/19 06:42
CRDT- 2023/10/05 21:59
PHST- 2023/06/30 00:00 [received]
PHST- 2023/09/14 00:00 [revised]
PHST- 2023/09/19 00:00 [accepted]
PHST- 2023/12/19 06:42 [medline]
PHST- 2023/10/06 00:43 [pubmed]
PHST- 2023/10/05 21:59 [entrez]
AID - S0901-5027(23)00216-3 [pii]
AID - 10.1016/j.ijom.2023.09.005 [doi]
PST - ppublish
SO  - Int J Oral Maxillofac Surg. 2024 Jan;53(1):78-88. doi: 
      10.1016/j.ijom.2023.09.005. Epub 2023 Oct 3.

PMID- 38178785
OWN - NLM
STAT- Publisher
LR  - 20240105
IS  - 1545-1569 (Electronic)
IS  - 1055-6656 (Linking)
DP  - 2024 Jan 5
TI  - Easing the Burden on Caregivers- Applications of Artificial Intelligence for 
      Physicians and Caregivers of Children with Cleft Lip and Palate.
PG  - 10556656231223596
LID - 10.1177/10556656231223596 [doi]
AB  - OBJECTIVE: Many caregivers of children with cleft lip and palate experience a 
      high level of anxiety throughout their child's medical and surgical care. We aim 
      to evaluate artificial intelligence (AI) as a tool to mitigate these feelings and 
      can aid clinicians in the development of robust pediatric educational materials 
      for caregivers and families. DESIGN: Thirteen of the most common postoperative 
      questions following cleft lip and/or palate repair were developed by an expert 
      panel of senior Pediatric Plastic Surgeons and were posed to ChatGPT. 
      Professional answers from the expert panel were provided and compared to 
      responses from ChatGPT. A literature review was also conducted to generate a new 
      support model for caregivers with children undergoing a surgical procedure. 
      SETTING: Department of Pediatric Plastic Surgery at a metropolitan Children's 
      Hospital. PARTICIPANTS: Senior Pediatric Plastic Surgeons at a metropolitan 
      Children's Hospital. INTERVENTIONS: None. MAIN OUTCOME MEASURE: The primary 
      outcome was to determine the ability of ChatGPT to respond to common 
      postoperative questions and to develop a model for AI assistance in 
      family-centered perioperative care. RESULTS: ChatGPT had a postoperative question 
      response accuracy rate of 69% when compared with subject matter expert responses, 
      with its greatest errors being information errors. An extensive literature search 
      revealed that AI can assist in multiple traditional perioperative strategies to 
      reduce caregivers and patient anxiety. CONCLUSIONS: Artificial Intelligence can 
      help to reduce the burden of generating patient education materials as well as 
      support caregivers in multiple aspects and perioperative care.
FAU - Chaker, Sara C
AU  - Chaker SC
AUID- ORCID: 0000-0002-5259-0941
AD  - Department of Plastic Surgery, Vanderbilt University Medical Center, Nashville, 
      TN, USA. RINGGOLD: 12328
FAU - Hung, Ya-Ching
AU  - Hung YC
AUID- ORCID: 0000-0003-1061-4252
AD  - Department of Plastic Surgery, Vanderbilt University Medical Center, Nashville, 
      TN, USA. RINGGOLD: 12328
AD  - Department of General Surgery, Sinai Hospital of Baltimore, Baltimore, MD, USA.
FAU - Saad, Mariam
AU  - Saad M
AD  - Department of Plastic Surgery, Vanderbilt University Medical Center, Nashville, 
      TN, USA. RINGGOLD: 12328
FAU - Golinko, Michael S
AU  - Golinko MS
AD  - Department of Plastic Surgery, Vanderbilt University Medical Center, Nashville, 
      TN, USA. RINGGOLD: 12328
AD  - Division of Pediatric Plastic Surgery, Cleft and Craniofacial Program, Monroe 
      Carell Jr. Children's Hospital at Vanderbilt, Nashville, TN, USA.
FAU - Galdyn, Izabela A
AU  - Galdyn IA
AD  - Department of Plastic Surgery, Vanderbilt University Medical Center, Nashville, 
      TN, USA. RINGGOLD: 12328
AD  - Division of Pediatric Plastic Surgery, Cleft and Craniofacial Program, Monroe 
      Carell Jr. Children's Hospital at Vanderbilt, Nashville, TN, USA.
LA  - eng
PT  - Journal Article
DEP - 20240105
PL  - United States
TA  - Cleft Palate Craniofac J
JT  - The Cleft palate-craniofacial journal : official publication of the American 
      Cleft Palate-Craniofacial Association
JID - 9102566
SB  - IM
OTO - NOTNLM
OT  - artificial intelligence
OT  - cleft lip and palate
OT  - quality improvement
COIS- Declaration of Conflicting InterestsThe authors declared no potential conflicts 
      of interest with respect to the research, authorship, and/or publication of this 
      article.
EDAT- 2024/01/05 06:43
MHDA- 2024/01/05 06:43
CRDT- 2024/01/05 03:30
PHST- 2024/01/05 06:43 [medline]
PHST- 2024/01/05 06:43 [pubmed]
PHST- 2024/01/05 03:30 [entrez]
AID - 10.1177/10556656231223596 [doi]
PST - aheadofprint
SO  - Cleft Palate Craniofac J. 2024 Jan 5:10556656231223596. doi: 
      10.1177/10556656231223596.

PMID- 37065364
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230418
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 3
DP  - 2023 Mar
TI  - Extreme Hyperthermia Due to Methamphetamine Toxicity Presenting As ST-Elevation 
      Myocardial Infarction on EKG: A Case Report Written With ChatGPT Assistance.
PG  - e36101
LID - 10.7759/cureus.36101 [doi]
LID - e36101
AB  - We present a case report of a 37-year-old male who presented to the emergency 
      department with altered mental status and electrocardiographic changes suggestive 
      of an ST-elevation myocardial infarction (STEMI). He was ultimately diagnosed 
      with extreme hyperthermia, secondary to drug use, which was managed promptly with 
      supportive measures resulting in a successful outcome. This case highlights the 
      importance of considering drug-induced hyperthermia as a potential cause of 
      altered mental status and EKG changes in patients, especially in those with a 
      history of drug abuse.
CI  - Copyright © 2023, Schussler et al.
FAU - Schussler, Jeffrey M
AU  - Schussler JM
AD  - Cardiology, Baylor University Medical Center, Dallas, USA.
AD  - Cardiology, Baylor Scott &amp; White Heart and Vascular Hospital, Dallas, USA.
FAU - Tomson, Cerin
AU  - Tomson C
AD  - Internal Medicine, Baylor University Medical Center, Dallas, USA.
FAU - Dresselhouse, Mark P
AU  - Dresselhouse MP
AD  - Emergency Medicine, Baylor University Medical Center, Dallas, USA.
LA  - eng
PT  - Case Reports
DEP - 20230313
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10097605
OTO - NOTNLM
OT  - chatgpt
OT  - methamphetamine
OT  - methamphetamine intoxication
OT  - st-elevation myocardial infarction (stemi)
OT  - st-segment elevation myocardial infarction (stemi)
OT  - stemi
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/04/18 06:00
MHDA- 2023/04/18 06:01
PMCR- 2023/03/13
CRDT- 2023/04/17 03:54
PHST- 2023/03/13 00:00 [accepted]
PHST- 2023/04/18 06:01 [medline]
PHST- 2023/04/17 03:54 [entrez]
PHST- 2023/04/18 06:00 [pubmed]
PHST- 2023/03/13 00:00 [pmc-release]
AID - 10.7759/cureus.36101 [doi]
PST - epublish
SO  - Cureus. 2023 Mar 13;15(3):e36101. doi: 10.7759/cureus.36101. eCollection 2023 
      Mar.

PMID- 38123858
OWN - NLM
STAT- Publisher
LR  - 20231222
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
DP  - 2023 Dec 20
TI  - What ChatGPT is and what it's not: a three minute guide.
LID - 10.1038/d41586-023-04156-2 [doi]
FAU - Van Noorden, Richard
AU  - Van Noorden R
FAU - Bundell, Shamini
AU  - Bundell S
LA  - eng
PT  - News
DEP - 20231220
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
OTO - NOTNLM
OT  - Computer science
EDAT- 2023/12/21 00:41
MHDA- 2023/12/21 00:41
CRDT- 2023/12/20 23:47
PHST- 2023/12/21 00:41 [pubmed]
PHST- 2023/12/21 00:41 [medline]
PHST- 2023/12/20 23:47 [entrez]
AID - 10.1038/d41586-023-04156-2 [pii]
AID - 10.1038/d41586-023-04156-2 [doi]
PST - aheadofprint
SO  - Nature. 2023 Dec 20. doi: 10.1038/d41586-023-04156-2.

PMID- 37974032
OWN - NLM
STAT- Publisher
LR  - 20231117
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
DP  - 2023 Nov 6
TI  - 'ChatGPT detector' catches AI-generated papers with unprecedented accuracy.
LID - 10.1038/d41586-023-03479-4 [doi]
FAU - Prillaman, McKenzie
AU  - Prillaman M
LA  - eng
PT  - News
DEP - 20231106
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
OTO - NOTNLM
OT  - Machine learning
OT  - Publishing
OT  - Technology
EDAT- 2023/11/17 15:29
MHDA- 2023/11/17 15:29
CRDT- 2023/11/17 01:42
PHST- 2023/11/17 15:29 [medline]
PHST- 2023/11/17 15:29 [pubmed]
PHST- 2023/11/17 01:42 [entrez]
AID - 10.1038/d41586-023-03479-4 [pii]
AID - 10.1038/d41586-023-03479-4 [doi]
PST - aheadofprint
SO  - Nature. 2023 Nov 6. doi: 10.1038/d41586-023-03479-4.

PMID- 38026315
OWN - NLM
STAT- MEDLINE
DCOM- 20231201
LR  - 20231201
IS  - 2296-2565 (Electronic)
IS  - 2296-2565 (Linking)
VI  - 11
DP  - 2023
TI  - AI chatbots and (mis)information in public health: impact on vulnerable 
      communities.
PG  - 1226776
LID - 10.3389/fpubh.2023.1226776 [doi]
LID - 1226776
FAU - Meyrowitsch, Dan W
AU  - Meyrowitsch DW
AD  - Global Health Section, Department of Public Health, University of Copenhagen, 
      Copenhagen, Denmark.
FAU - Jensen, Andreas K
AU  - Jensen AK
AD  - Section of Biostatistics, Department of Public Health, University of Copenhagen, 
      Copenhagen, Denmark.
FAU - Sørensen, Jane B
AU  - Sørensen JB
AD  - Global Health Section, Department of Public Health, University of Copenhagen, 
      Copenhagen, Denmark.
FAU - Varga, Tibor V
AU  - Varga TV
AD  - Section of Epidemiology, Department of Public Health, University of Copenhagen, 
      Copenhagen, Denmark.
LA  - eng
PT  - Journal Article
DEP - 20231031
PL  - Switzerland
TA  - Front Public Health
JT  - Frontiers in public health
JID - 101616579
SB  - IM
MH  - *Public Health
MH  - *Artificial Intelligence
MH  - Vulnerable Populations
MH  - *Disinformation
PMC - PMC10644115
OTO - NOTNLM
OT  - Artificial Intelligence
OT  - ChatGPT
OT  - Global South
OT  - LLM
OT  - chatbot
OT  - public health
OT  - vulnerable communities
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/11/29 18:41
MHDA- 2023/12/01 06:44
PMCR- 2023/10/31
CRDT- 2023/11/29 16:52
PHST- 2023/05/22 00:00 [received]
PHST- 2023/10/09 00:00 [accepted]
PHST- 2023/12/01 06:44 [medline]
PHST- 2023/11/29 18:41 [pubmed]
PHST- 2023/11/29 16:52 [entrez]
PHST- 2023/10/31 00:00 [pmc-release]
AID - 10.3389/fpubh.2023.1226776 [doi]
PST - epublish
SO  - Front Public Health. 2023 Oct 31;11:1226776. doi: 10.3389/fpubh.2023.1226776. 
      eCollection 2023.

PMID- 38001275
OWN - NLM
STAT- Publisher
LR  - 20231124
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
DP  - 2023 Nov 24
TI  - How ChatGPT and sounds from space brought a 'luminous jelly' to life.
LID - 10.1038/d41586-023-03392-w [doi]
FAU - Gould, Julie
AU  - Gould J
LA  - eng
PT  - News
DEP - 20231124
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
OTO - NOTNLM
OT  - Arts
OT  - Careers
OT  - Lab life
OT  - Organic chemistry
EDAT- 2023/11/25 07:42
MHDA- 2023/11/25 07:42
CRDT- 2023/11/24 23:36
PHST- 2023/11/25 07:42 [medline]
PHST- 2023/11/25 07:42 [pubmed]
PHST- 2023/11/24 23:36 [entrez]
AID - 10.1038/d41586-023-03392-w [pii]
AID - 10.1038/d41586-023-03392-w [doi]
PST - aheadofprint
SO  - Nature. 2023 Nov 24. doi: 10.1038/d41586-023-03392-w.

PMID- 37399112
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20230821
LR  - 20230830
IS  - 1748-880X (Electronic)
IS  - 0007-1285 (Print)
IS  - 0007-1285 (Linking)
VI  - 96
IP  - 1149
DP  - 2023 Sep
TI  - ChatGPT and radiologists: comment.
PG  - 20230442
LID - 10.1259/bjr.20230442 [doi]
LID - 20230442
FAU - Kleebayoon, Aamnuay
AU  - Kleebayoon A
AD  - Private Academic Consultant, Samraong, Cambodia.
FAU - Wiwanitkit, Viroj
AU  - Wiwanitkit V
AD  - Adjunct professor, Chandigarh University, Punjab, India.
AD  - Adjunct professor, Joseph Ayo Babalola University, Ikeji-Arakeji, Nigeria.
LA  - eng
PT  - Comment
PT  - Letter
DEP - 20230629
PL  - England
TA  - Br J Radiol
JT  - The British journal of radiology
JID - 0373125
SB  - IM
CON - Br J Radiol. 2023 Aug;96(1148):20230203. PMID: 37183840
PMC - PMC10461268
EDAT- 2023/07/03 19:08
MHDA- 2023/08/21 06:42
PMCR- 2024/09/01
CRDT- 2023/07/03 12:33
PHST- 2024/09/01 00:00 [pmc-release]
PHST- 2023/08/21 06:42 [medline]
PHST- 2023/07/03 19:08 [pubmed]
PHST- 2023/07/03 12:33 [entrez]
AID - 10.1259/bjr.20230442 [doi]
PST - ppublish
SO  - Br J Radiol. 2023 Sep;96(1149):20230442. doi: 10.1259/bjr.20230442. Epub 2023 Jun 
      29.

PMID- 37133539
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20230710
LR  - 20231211
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 51
IP  - 8
DP  - 2023 Aug
TI  - ChatGPT/GPT-4 and Spinal Surgeons.
PG  - 1657
LID - 10.1007/s10439-023-03223-z [doi]
FAU - Kleebayoon, Amnuay
AU  - Kleebayoon A
AD  - , Samraong, Cambodia. amnuaykleebai@gmail.com.
FAU - Wiwanitkit, Viroj
AU  - Wiwanitkit V
AD  - Chandigarh University, Mohali, Punjab, India.
AD  - Joesph Ayobabalola University, Ikeji-Arakeji, Nigeria.
LA  - eng
PT  - Letter
DEP - 20230503
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
EDAT- 2023/05/03 12:42
MHDA- 2023/05/03 12:43
CRDT- 2023/05/03 11:05
PHST- 2023/04/25 00:00 [received]
PHST- 2023/04/25 00:00 [accepted]
PHST- 2023/05/03 12:43 [medline]
PHST- 2023/05/03 12:42 [pubmed]
PHST- 2023/05/03 11:05 [entrez]
AID - 10.1007/s10439-023-03223-z [pii]
AID - 10.1007/s10439-023-03223-z [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2023 Aug;51(8):1657. doi: 10.1007/s10439-023-03223-z. Epub 2023 
      May 3.

PMID- 37026967
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20230721
LR  - 20230902
IS  - 1537-7385 (Electronic)
IS  - 0894-9115 (Linking)
VI  - 102
IP  - 8
DP  - 2023 Aug 1
TI  - Letter to the Editor on "Will ChatGPT Match to Your Program?".
PG  - e115-e116
LID - 10.1097/PHM.0000000000002259 [doi]
FAU - Nicolau, Eric
AU  - Nicolau E
FAU - Verduzco-Gutierrez, Monica
AU  - Verduzco-Gutierrez M
LA  - eng
PT  - Journal Article
DEP - 20230407
PL  - United States
TA  - Am J Phys Med Rehabil
JT  - American journal of physical medicine &amp; rehabilitation
JID - 8803677
SB  - IM
EDAT- 2023/04/08 06:00
MHDA- 2023/04/08 06:01
CRDT- 2023/04/07 10:13
PHST- 2023/04/08 06:01 [medline]
PHST- 2023/04/08 06:00 [pubmed]
PHST- 2023/04/07 10:13 [entrez]
AID - 00002060-202308000-00018 [pii]
AID - 10.1097/PHM.0000000000002259 [doi]
PST - ppublish
SO  - Am J Phys Med Rehabil. 2023 Aug 1;102(8):e115-e116. doi: 
      10.1097/PHM.0000000000002259. Epub 2023 Apr 7.

PMID- 37817033
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20231012
LR  - 20231012
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
VI  - 622
IP  - 7982
DP  - 2023 Oct
TI  - How ChatGPT and other AI tools could disrupt scientific publishing.
PG  - 234-236
LID - 10.1038/d41586-023-03144-w [doi]
FAU - Conroy, Gemma
AU  - Conroy G
LA  - eng
PT  - News
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
OTO - NOTNLM
OT  - Computer science
OT  - Machine learning
OT  - Peer review
OT  - Publishing
EDAT- 2023/10/11 00:42
MHDA- 2023/10/11 00:43
CRDT- 2023/10/10 23:46
PHST- 2023/10/11 00:43 [medline]
PHST- 2023/10/11 00:42 [pubmed]
PHST- 2023/10/10 23:46 [entrez]
AID - 10.1038/d41586-023-03144-w [pii]
AID - 10.1038/d41586-023-03144-w [doi]
PST - ppublish
SO  - Nature. 2023 Oct;622(7982):234-236. doi: 10.1038/d41586-023-03144-w.

PMID- 37804010
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20231102
LR  - 20231102
IS  - 1681-7168 (Electronic)
IS  - 1022-386X (Linking)
VI  - 33
IP  - 10
DP  - 2023 Oct
TI  - AI at Doorstep: ChatGPT and Academia.
PG  - 1085-1086
LID - 10.29271/jcpsp.2023.10.1085 [doi]
AB  - Null.
FAU - Khan, Sikandar Hayat
AU  - Khan SH
AD  - Department of Pathology, Combined Military Hospital, Multan, Pakistan.
LA  - eng
PT  - Editorial
PL  - Pakistan
TA  - J Coll Physicians Surg Pak
JT  - Journal of the College of Physicians and Surgeons--Pakistan : JCPSP
JID - 9606447
SB  - IM
EDAT- 2023/10/07 11:42
MHDA- 2023/10/07 11:43
CRDT- 2023/10/07 03:51
PHST- 2023/07/06 00:00 [received]
PHST- 2023/08/26 00:00 [accepted]
PHST- 2023/10/07 11:43 [medline]
PHST- 2023/10/07 11:42 [pubmed]
PHST- 2023/10/07 03:51 [entrez]
AID - 040579197 [pii]
AID - 10.29271/jcpsp.2023.10.1085 [doi]
PST - ppublish
SO  - J Coll Physicians Surg Pak. 2023 Oct;33(10):1085-1086. doi: 
      10.29271/jcpsp.2023.10.1085.

PMID- 37438635
OWN - NLM
STAT- Publisher
LR  - 20231220
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
DP  - 2023 Jul 12
TI  - ChatGPT can write a paper in an hour - but there are downsides.
LID - 10.1038/d41586-023-02298-x [doi]
FAU - Baker, Noah
AU  - Baker N
FAU - Thompson, Benjamin
AU  - Thompson B
FAU - Fox, Dan
AU  - Fox D
LA  - eng
PT  - News
DEP - 20230712
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
OTO - NOTNLM
OT  - Ageing
OT  - Authorship
OT  - Climate change
OT  - Climate sciences
OT  - Publishing
EDAT- 2023/07/13 01:06
MHDA- 2023/07/13 01:06
CRDT- 2023/07/12 23:38
PHST- 2023/07/13 01:06 [pubmed]
PHST- 2023/07/13 01:06 [medline]
PHST- 2023/07/12 23:38 [entrez]
AID - 10.1038/d41586-023-02298-x [pii]
AID - 10.1038/d41586-023-02298-x [doi]
PST - aheadofprint
SO  - Nature. 2023 Jul 12. doi: 10.1038/d41586-023-02298-x.

PMID- 38413129
OWN - NLM
STAT- MEDLINE
DCOM- 20240229
LR  - 20240321
IS  - 1975-5937 (Electronic)
IS  - 1975-5937 (Linking)
VI  - 21
DP  - 2024
TI  - ChatGPT (GPT-4) passed the Japanese National License Examination for Pharmacists 
      in 2022, answering all items including those with diagrams: a descriptive study.
PG  - 4
LID - 10.3352/jeehp.2024.21.4 [doi]
LID - 4
AB  - PURPOSE: The objective of this study was to assess the performance of ChatGPT 
      (GPT-4) on all items, including those with diagrams, in the Japanese National 
      License Examination for Pharmacists (JNLEP) and compare it with the previous 
      GPT-3.5 model’s performance. METHODS: The 107th JNLEP, conducted in 2022, with 
      344 items input into the GPT-4 model, was targeted for this study. Separately, 
      284 items, excluding those with diagrams, were entered into the GPT-3.5 model. 
      The answers were categorized and analyzed to determine accuracy rates based on 
      categories, subjects, and presence or absence of diagrams. The accuracy rates 
      were compared to the main passing criteria (overall accuracy rate ≥62.9%). 
      RESULTS: The overall accuracy rate for all items in the 107th JNLEP in GPT-4 was 
      72.5%, successfully meeting all the passing criteria. For the set of items 
      without diagrams, the accuracy rate was 80.0%, which was significantly higher 
      than that of the GPT-3.5 model (43.5%). The GPT-4 model demonstrated an accuracy 
      rate of 36.1% for items that included diagrams. CONCLUSION: Advancements that 
      allow GPT-4 to process images have made it possible for LLMs to answer all items 
      in medical-related license examinations. This study’s findings confirm that 
      ChatGPT (GPT-4) possesses sufficient knowledge to meet the passing criteria.
FAU - Sato, Hiroyasu
AU  - Sato H
AD  - Department of Pharmacy, Abashiri Kosei General Hospital, Abashiri, Japan.
FAU - Ogasawara, Katsuhiko
AU  - Ogasawara K
AD  - Graduate School of Health Sciences, Hokkaido University, Sapporo, Japan.
AD  - Graduate School of Engineering, Muroran Institute of Technology, Muroran, Japan
LA  - eng
PT  - Journal Article
DEP - 20240228
PL  - Korea (South)
TA  - J Educ Eval Health Prof
JT  - Journal of educational evaluation for health professions
JID - 101490061
SB  - IM
MH  - Humans
MH  - Japan
MH  - *Pharmacists
PMC - PMC10948916
OTO - NOTNLM
OT  - Japan
OT  - Pharmacists
OT  - Artificial intelligence
OT  - Pharmacy licensure
OT  - Task performance
COIS- Conflict of interest No potential conflict of interest relevant to this article 
      was reported.
EDAT- 2024/02/28 00:43
MHDA- 2024/02/29 06:43
PMCR- 2024/02/28
CRDT- 2024/02/27 20:43
PHST- 2023/12/29 00:00 [received]
PHST- 2024/02/28 00:00 [accepted]
PHST- 2024/02/29 06:43 [medline]
PHST- 2024/02/28 00:43 [pubmed]
PHST- 2024/02/27 20:43 [entrez]
PHST- 2024/02/28 00:00 [pmc-release]
AID - jeehp.2024.21.4 [pii]
AID - jeehp-21-04 [pii]
AID - 10.3352/jeehp.2024.21.4 [doi]
PST - ppublish
SO  - J Educ Eval Health Prof. 2024;21:4. doi: 10.3352/jeehp.2024.21.4. Epub 2024 Feb 
      28.

PMID- 38330366
OWN - NLM
STAT- Publisher
LR  - 20240208
IS  - 1939-2222 (Electronic)
IS  - 0022-1015 (Linking)
DP  - 2024 Feb 8
TI  - Do large language models show decision heuristics similar to humans? A case study 
      using GPT-3.5.
LID - 10.1037/xge0001547 [doi]
AB  - A Large Language Model (LLM) is an artificial intelligence system trained on vast 
      amounts of natural language data, enabling it to generate human-like responses to 
      written or spoken language input. Generative Pre-Trained Transformer (GPT)-3.5 is 
      an example of an LLM that supports a conversational agent called ChatGPT. In this 
      work, we used a series of novel prompts to determine whether ChatGPT shows 
      heuristics and other context-sensitive responses. We also tested the same prompts 
      on human participants. Across four studies, we found that ChatGPT was influenced 
      by random anchors in making estimates (anchoring, Study 1); it judged the 
      likelihood of two events occurring together to be higher than the likelihood of 
      either event occurring alone, and it was influenced by anecdotal information 
      (representativeness and availability heuristic, Study 2); it found an item to be 
      more efficacious when its features were presented positively rather than 
      negatively-even though both presentations contained statistically equivalent 
      information (framing effect, Study 3); and it valued an owned item more than a 
      newly found item even though the two items were objectively identical (endowment 
      effect, Study 4). In each study, human participants showed similar effects. 
      Heuristics and context-sensitive responses in humans are thought to be driven by 
      cognitive and affective processes such as loss aversion and effort reduction. The 
      fact that an LLM-which lacks these processes-also shows such responses invites 
      consideration of the possibility that language is sufficiently rich to carry 
      these effects and may play a role in generating these effects in humans. 
      (PsycInfo Database Record (c) 2024 APA, all rights reserved).
FAU - Suri, Gaurav
AU  - Suri G
AUID- ORCID: 0000-0002-0423-060X
AD  - Department of Psychology, San Francisco State University.
FAU - Slater, Lily R
AU  - Slater LR
AD  - Department of Psychology, San Francisco State University.
FAU - Ziaee, Ali
AU  - Ziaee A
AD  - Department of Psychology, San Francisco State University.
FAU - Nguyen, Morgan
AU  - Nguyen M
AD  - Department of Psychology, San Francisco State University.
LA  - eng
PT  - Journal Article
DEP - 20240208
PL  - United States
TA  - J Exp Psychol Gen
JT  - Journal of experimental psychology. General
JID - 7502587
SB  - IM
EDAT- 2024/02/08 18:42
MHDA- 2024/02/08 18:42
CRDT- 2024/02/08 16:34
PHST- 2024/02/08 18:42 [medline]
PHST- 2024/02/08 18:42 [pubmed]
PHST- 2024/02/08 16:34 [entrez]
AID - 2024-50870-001 [pii]
AID - 10.1037/xge0001547 [doi]
PST - aheadofprint
SO  - J Exp Psychol Gen. 2024 Feb 8. doi: 10.1037/xge0001547.

PMID- 38504411
OWN - NLM
STAT- Publisher
LR  - 20240320
IS  - 1938-7636 (Electronic)
IS  - 1938-6400 (Linking)
DP  - 2024 Mar 19
TI  - Foot and Ankle Patient Education Materials and Artificial Intelligence Chatbots: 
      A Comparative Analysis.
PG  - 19386400241235834
LID - 10.1177/19386400241235834 [doi]
AB  - BACKGROUND: The purpose of this study was to perform a comparative analysis of 
      foot and ankle patient education material generated by the AI chatbots, as they 
      compare to the American Orthopaedic Foot and Ankle Society (AOFAS)-recommended 
      patient education website, FootCareMD.org. METHODS: ChatGPT, Google Bard, and 
      Bing AI were used to generate patient educational materials on 10 of the most 
      common foot and ankle conditions. The content from these AI language model 
      platforms was analyzed and compared with that in FootCareMD.org for accuracy of 
      included information. Accuracy was determined for each of the 10 conditions on a 
      basis of included information regarding background, symptoms, causes, diagnosis, 
      treatments, surgical options, recovery procedures, and risks or preventions. 
      RESULTS: When compared to the reference standard of the AOFAS website 
      FootCareMD.org, the AI language model platforms consistently scored below 60% in 
      accuracy rates in all categories of the articles analyzed. ChatGPT was found to 
      contain an average of 46.2% of key content across all included conditions when 
      compared to FootCareMD.org. Comparatively, Google Bard and Bing AI contained 
      36.5% and 28.0% of information included on FootCareMD.org, respectively (P &lt; 
      .005). CONCLUSION: Patient education regarding common foot and ankle conditions 
      generated by AI language models provides limited content accuracy across all 3 AI 
      chatbot platforms. LEVEL OF EVIDENCE: Level IV.
FAU - Parekh, Aarav S
AU  - Parekh AS
AD  - Rothman Orthopaedic Institute, Philadelphia, Pennsylvania.
FAU - McCahon, Joseph A S
AU  - McCahon JAS
AUID- ORCID: 0000-0002-6655-5581
AD  - Jefferson Health NJ, Stratford, New Jersey.
FAU - Nghe, Amy
AU  - Nghe A
AD  - Rothman Orthopaedic Institute, Philadelphia, Pennsylvania.
FAU - Pedowitz, David I
AU  - Pedowitz DI
AD  - Rothman Orthopaedic Institute, Philadelphia, Pennsylvania.
FAU - Daniel, Joseph N
AU  - Daniel JN
AD  - Rothman Orthopaedic Institute, Philadelphia, Pennsylvania.
FAU - Parekh, Selene G
AU  - Parekh SG
AD  - Rothman Orthopaedic Institute, Philadelphia, Pennsylvania.
LA  - eng
PT  - Journal Article
DEP - 20240319
PL  - United States
TA  - Foot Ankle Spec
JT  - Foot &amp; ankle specialist
JID - 101473598
SB  - IM
OTO - NOTNLM
OT  - Bing
OT  - ChatGPT
OT  - Google Bard
OT  - artificial intelligence
OT  - large language models
OT  - patient education
COIS- Declaration of Conflicting InterestsThe author(s) declared no potential conflicts 
      of interest with respect to the research, authorship, and/or publication of this 
      article.
EDAT- 2024/03/20 06:45
MHDA- 2024/03/20 06:45
CRDT- 2024/03/20 00:59
PHST- 2024/03/20 06:45 [medline]
PHST- 2024/03/20 06:45 [pubmed]
PHST- 2024/03/20 00:59 [entrez]
AID - 10.1177/19386400241235834 [doi]
PST - aheadofprint
SO  - Foot Ankle Spec. 2024 Mar 19:19386400241235834. doi: 10.1177/19386400241235834.

PMID- 37327133
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230619
IS  - 0351-0026 (Print)
IS  - 1854-2476 (Electronic)
IS  - 0351-0026 (Linking)
VI  - 62
IP  - 3
DP  - 2023 Sep
TI  - New Challenges in Scientific Publications: Referencing, Artificial Intelligence 
      and ChatGPT.
PG  - 109-112
LID - 10.2478/sjph-2023-0015 [doi]
AB  - The COVID-19 pandemic has led to a surge in scientific publications, some of 
      which have bypassed the usual peer-review processes, leading to an increase in 
      unsupported claims being referenced. Therefore, the need for references in 
      scientific articles is increasingly being questioned. The practice of relying 
      solely on quantitative measures, such as impact factor, is also considered 
      inadequate by many experts. This can lead to researchers choosing research ideas 
      that are likely to generate favourable metrics instead of interesting and 
      important topics. Evaluating the quality and scientific value of articles 
      requires a rethinking of current approaches, with a move away from purely 
      quantitative methods. Artificial intelligence (AI)-based tools are making 
      scientific writing easier and less time-consuming, which is likely to further 
      increase the number of scientific publications, potentially leading to higher 
      quality articles. AI tools for searching, analysing, synthesizing, evaluating and 
      writing scientific literature are increasingly being developed. These tools 
      deeply analyse the content of articles, consider their scientific impact, and 
      prioritize the retrieved literature based on this information, presenting it in 
      simple visual graphs. They also help authors to quickly and easily analyse and 
      synthesize knowledge from the literature, prepare summaries of key information, 
      aid in organizing references, and improve manuscript language. The language model 
      ChatGPT has already greatly changed the way people communicate with computers, 
      bringing it closer to human communication. However, while AI tools are helpful, 
      they must be used carefully and ethically. In summary, AI has already changed the 
      way we write articles, and its use in scientific publishing will continue to 
      enhance and streamline the process.
CI  - © 2023 Igor Švab et al., published by Sciendo.
FAU - Švab, Igor
AU  - Švab I
AUID- ORCID: 0000-0003-1303-4974
AD  - Department of Family Medicine, Medical Faculty, University of Ljubljana, 
      Poljanski nasip 58, 1000 Ljubljana, Slovenia.
AD  - National Institute of Public Health, Trubarjeva 2, 1000 Ljubljana, Slovenia.
FAU - Klemenc-Ketiš, Zalika
AU  - Klemenc-Ketiš Z
AUID- ORCID: 0000-0002-0270-1754
AD  - Department of Family Medicine, Medical Faculty, University of Ljubljana, 
      Poljanski nasip 58, 1000 Ljubljana, Slovenia.
AD  - Department of Family Medicine, Medical Faculty, University of Maribor, Taborska 
      8, 2000 Maribor, Slovenia.
AD  - Ljubljana Community Health Centre, Metelkova 9, 1000 Ljubljana, Slovenia.
FAU - Zupanič, Saša
AU  - Zupanič S
AUID- ORCID: 0000-0002-7378-9976
AD  - National Institute of Public Health, Trubarjeva 2, 1000 Ljubljana, Slovenia.
LA  - eng
PT  - Editorial
DEP - 20230613
PL  - Poland
TA  - Zdr Varst
JT  - Zdravstveno varstvo
JID - 9412992
PMC - PMC10263368
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Peer review
OT  - Referencing
OT  - Research assessment
OT  - Scientific articles
COIS- CONFLICTS OF INTEREST The authors declare that no conflicts of interest exist.
EDAT- 2023/06/16 19:16
MHDA- 2023/06/16 19:17
PMCR- 2023/06/13
CRDT- 2023/06/16 13:04
PHST- 2023/04/17 00:00 [received]
PHST- 2023/05/03 00:00 [accepted]
PHST- 2023/06/16 19:17 [medline]
PHST- 2023/06/16 19:16 [pubmed]
PHST- 2023/06/16 13:04 [entrez]
PHST- 2023/06/13 00:00 [pmc-release]
AID - sjph-2023-0015 [pii]
AID - 10.2478/sjph-2023-0015 [doi]
PST - epublish
SO  - Zdr Varst. 2023 Jun 13;62(3):109-112. doi: 10.2478/sjph-2023-0015. eCollection 
      2023 Sep.

PMID- 38082605
OWN - NLM
STAT- MEDLINE
DCOM- 20231216
LR  - 20240129
IS  - 2694-0604 (Electronic)
IS  - 2375-7477 (Linking)
VI  - 2023
DP  - 2023 Jul
TI  - ChatGPT for phenotypes extraction: one model to rule them all?
PG  - 1-4
LID - 10.1109/EMBC40787.2023.10340611 [doi]
AB  - Information Extraction (IE) is a core task in Natural Language Processing (NLP) 
      where the objective is to identify factual knowledge in textual documents (often 
      unstructured), and feed downstream use cases with the resulting output. In 
      genomic medicine for instance, being able to extract the most precise list of 
      phenotypes associated to a patient allows to improve genetic disease diagnostic, 
      which represents a vital step in the modern deep phenotyping approach. As most of 
      the phenotypic information lies in clinical reports, the challenge is to build an 
      IE pipeline to automatically recognize phenotype concepts from free-text notes. A 
      new machine learning paradigm around large language models (LLM) has given rise 
      of an increasing number of academic works on this topic lately, where 
      sophisticated combinations of different technics have been employed to improve 
      the phenotypes extraction accuracy. Even more recently released, the ChatGPT(1) 
      application nevertheless raises the question of the relevance of these approches 
      compared to this new generic one based on an instruction-oriented LLM. In this 
      paper, we propose a rigorous evaluation of ChatGPT and the current 
      state-of-the-art solutions on this specific task, and discuss the possible 
      impacts and the technical evolutions to consider in the medical domain.Clinical 
      relevance- Deep phenotyping on electronic health records has proven its ability 
      to improve genetic diagnosis by clinical exomes [10]. Thus, comparing 
      state-of-the-art solutions in order to derive insights and improving research 
      paths is essential.
FAU - Labbe, Thomas
AU  - Labbe T
FAU - Castel, Pierre
AU  - Castel P
FAU - Sanner, Jean-Michel
AU  - Sanner JM
FAU - Saleh, Majd
AU  - Saleh M
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Annu Int Conf IEEE Eng Med Biol Soc
JT  - Annual International Conference of the IEEE Engineering in Medicine and Biology 
      Society. IEEE Engineering in Medicine and Biology Society. Annual International 
      Conference
JID - 101763872
SB  - IM
MH  - Humans
MH  - *Information Storage and Retrieval
MH  - *Machine Learning
MH  - Language
MH  - Phenotype
MH  - Electronic Health Records
EDAT- 2023/12/12 06:42
MHDA- 2023/12/17 09:42
CRDT- 2023/12/12 01:03
PHST- 2023/12/17 09:42 [medline]
PHST- 2023/12/12 06:42 [pubmed]
PHST- 2023/12/12 01:03 [entrez]
AID - 10.1109/EMBC40787.2023.10340611 [doi]
PST - ppublish
SO  - Annu Int Conf IEEE Eng Med Biol Soc. 2023 Jul;2023:1-4. doi: 
      10.1109/EMBC40787.2023.10340611.

PMID- 37077585
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230421
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 3
DP  - 2023 Mar
TI  - Appendix Playing Hide and Seek: A Variation to Amyand's Hernia.
PG  - e36326
LID - 10.7759/cureus.36326 [doi]
LID - e36326
AB  - Amyand's hernia is a rare condition where the appendix becomes trapped in the 
      inguinal hernia sac, leading to severe complications if left untreated. Treatment 
      typically involves surgical repair of the hernia, with the removal of the 
      appendix if necessary.&nbsp;This case report presents a 65-year-old male with 
      compromised cardiac status and a right inguinal hernia, confirmed by ultrasound. 
      The surgery was performed under local anesthesia, and the appendix was normal and 
      reduced back. The patient was discharged on the next day of surgery after an 
      uneventful course in the hospital. There is a difference of opinion regarding the 
      need for an appendectomy in an Amyand's hernia with a normal appendix, with the 
      appendix dancing in and out of the inguinal canal while coughing on the table. 
      The decision to remove or leave a normal appendix in this situation should be 
      based on several factors, including the patient's age, appendix anatomy, and 
      extent of intraoperative inflammation. In conclusion, local anesthesia can be a 
      safe and effective option for patients who are not fit for general or spinal 
      anesthesia. The decision to remove or leave a normal appendix in Amyand's hernia 
      should be based on several factors.
CI  - Copyright © 2023, Bawa et al.
FAU - Bawa, Ashvind
AU  - Bawa A
AD  - Department of General Surgery, Dayanand Medical College and Hospital, Ludhiana, 
      IND.
FAU - Kansal, Rohin
AU  - Kansal R
AD  - Department of General Surgery, Dayanand Medical College and Hospital, Ludhiana, 
      IND.
FAU - Sharma, Sonalika
AU  - Sharma S
AD  - Department of General Surgery, Dayanand Medical College and Hospital, Ludhiana, 
      IND.
FAU - Rengan, Vinayak
AU  - Rengan V
AD  - Department of General Surgery, Dr. Mehta's Hospital, Chennai, IND.
FAU - Meenashi Sundaram, Pravin
AU  - Meenashi Sundaram P
AD  - Department of General Surgery, Dr. Rengan's Surgical Center, Chennai, IND.
LA  - eng
PT  - Case Reports
DEP - 20230318
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10108743
OTO - NOTNLM
OT  - amyand’s hernia
OT  - chatgpt
OT  - chatgpt improved case report
OT  - mesh repair
OT  - tension free mesh repair
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/04/20 06:42
MHDA- 2023/04/20 06:43
PMCR- 2023/03/18
CRDT- 2023/04/20 02:23
PHST- 2023/03/18 00:00 [accepted]
PHST- 2023/04/20 06:43 [medline]
PHST- 2023/04/20 06:42 [pubmed]
PHST- 2023/04/20 02:23 [entrez]
PHST- 2023/03/18 00:00 [pmc-release]
AID - 10.7759/cureus.36326 [doi]
PST - epublish
SO  - Cureus. 2023 Mar 18;15(3):e36326. doi: 10.7759/cureus.36326. eCollection 2023 
      Mar.

PMID- 37566133
OWN - NLM
STAT- MEDLINE
DCOM- 20230918
LR  - 20230922
IS  - 1432-1041 (Electronic)
IS  - 0031-6970 (Linking)
VI  - 79
IP  - 10
DP  - 2023 Oct
TI  - Will artificial intelligence chatbots replace clinical pharmacologists? An 
      exploratory study in clinical practice.
PG  - 1375-1384
LID - 10.1007/s00228-023-03547-8 [doi]
AB  - PURPOSE: Recently, there has been a growing interest in using ChatGPT for various 
      applications in Medicine. We evaluated the interest of OpenAI chatbot (GPT 4.0) 
      for drug information activities at Toulouse Pharmacovigilance Center. METHODS: 
      Based on a series of 50 randomly selected questions sent to our pharmacovigilance 
      center by healthcare professionals or patients, we compared the level of 
      responses from the chatbot GPT 4.0 with those provided by specialists in 
      pharmacovigilance. RESULTS: Chatbot answers were globally not acceptable. 
      Responses to inquiries regarding the assessment of drug causality were not 
      consistently precise or clinically meaningful. CONCLUSION: The interest of 
      chatbot assistance needs to be confirmed or rejected through further studies 
      conducted in other pharmacovigilance centers.
CI  - © 2023. The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, 
      part of Springer Nature.
FAU - Montastruc, François
AU  - Montastruc F
AD  - Department of Medical and Clinical Pharmacology, Centre of Pharmacovigilance and 
      Pharmacoepidemiology, Faculty of Medicine, Toulouse University Hospital (CHU), 
      Toulouse, France.
FAU - Storck, Wilhelm
AU  - Storck W
AD  - Department of Medical and Clinical Pharmacology, Centre of Pharmacovigilance and 
      Pharmacoepidemiology, Faculty of Medicine, Toulouse University Hospital (CHU), 
      Toulouse, France.
FAU - de Canecaude, Claire
AU  - de Canecaude C
AD  - Department of Medical and Clinical Pharmacology, Centre of Pharmacovigilance and 
      Pharmacoepidemiology, Faculty of Medicine, Toulouse University Hospital (CHU), 
      Toulouse, France.
FAU - Victor, Léa
AU  - Victor L
AD  - Department of Medical and Clinical Pharmacology, Centre of Pharmacovigilance and 
      Pharmacoepidemiology, Faculty of Medicine, Toulouse University Hospital (CHU), 
      Toulouse, France.
FAU - Li, Julien
AU  - Li J
AD  - Department of Medical and Clinical Pharmacology, Centre of Pharmacovigilance and 
      Pharmacoepidemiology, Faculty of Medicine, Toulouse University Hospital (CHU), 
      Toulouse, France.
FAU - Cesbron, Candice
AU  - Cesbron C
AD  - Department of Medical and Clinical Pharmacology, Centre of Pharmacovigilance and 
      Pharmacoepidemiology, Faculty of Medicine, Toulouse University Hospital (CHU), 
      Toulouse, France.
FAU - Zelmat, Yoann
AU  - Zelmat Y
AD  - Department of Medical and Clinical Pharmacology, Centre of Pharmacovigilance and 
      Pharmacoepidemiology, Faculty of Medicine, Toulouse University Hospital (CHU), 
      Toulouse, France.
FAU - Barus, Romain
AU  - Barus R
AD  - Department of Medical and Clinical Pharmacology, Centre of Pharmacovigilance and 
      Pharmacoepidemiology, Faculty of Medicine, Toulouse University Hospital (CHU), 
      Toulouse, France. romain.barus@univ-tlse3.fr.
LA  - eng
PT  - Journal Article
DEP - 20230811
PL  - Germany
TA  - Eur J Clin Pharmacol
JT  - European journal of clinical pharmacology
JID - 1256165
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Physicians
MH  - Software
MH  - Health Personnel
MH  - Pharmacovigilance
OTO - NOTNLM
OT  - Adverse drug reaction
OT  - ChatGPT
OT  - Drug information service
OT  - Pharmacovigilance
OT  - Safety
EDAT- 2023/08/11 12:42
MHDA- 2023/09/18 12:43
CRDT- 2023/08/11 11:04
PHST- 2023/06/13 00:00 [received]
PHST- 2023/07/30 00:00 [accepted]
PHST- 2023/09/18 12:43 [medline]
PHST- 2023/08/11 12:42 [pubmed]
PHST- 2023/08/11 11:04 [entrez]
AID - 10.1007/s00228-023-03547-8 [pii]
AID - 10.1007/s00228-023-03547-8 [doi]
PST - ppublish
SO  - Eur J Clin Pharmacol. 2023 Oct;79(10):1375-1384. doi: 10.1007/s00228-023-03547-8. 
      Epub 2023 Aug 11.

PMID- 37210278
OWN - NLM
STAT- MEDLINE
DCOM- 20231024
LR  - 20231025
IS  - 1471-6771 (Electronic)
IS  - 0007-0912 (Linking)
VI  - 131
IP  - 2
DP  - 2023 Aug
TI  - Assessment of ChatGPT success with specialty medical knowledge using 
      anaesthesiology board examination practice questions.
PG  - e31-e34
LID - S0007-0912(23)00192-7 [pii]
LID - 10.1016/j.bja.2023.04.017 [doi]
FAU - Shay, Denys
AU  - Shay D
AD  - Department of Epidemiology, Harvard T.H. Chan School of Public Health, Boston, 
      MA, USA; Department of Anesthesia, Critical Care and Pain Medicine, Beth Israel 
      Deaconess Medical Center, Harvard Medical School, Boston, MA, USA; Center for 
      Anesthesia Research Excellence, Beth Israel Deaconess Medical Center, Harvard 
      Medical School, Boston, MA, USA.
FAU - Kumar, Bhawesh
AU  - Kumar B
AD  - Department of Biostatistics, Harvard T.H. Chan School of Public Health, Boston, 
      MA, USA.
FAU - Bellamy, David
AU  - Bellamy D
AD  - Department of Epidemiology, Harvard T.H. Chan School of Public Health, Boston, 
      MA, USA; Department of Biostatistics, Harvard T.H. Chan School of Public Health, 
      Boston, MA, USA.
FAU - Palepu, Anil
AU  - Palepu A
AD  - Harvard-MIT Health Sciences and Technology, Massachusetts Institute of 
      Technology, Cambridge, MA, USA.
FAU - Dershwitz, Mark
AU  - Dershwitz M
AD  - Department of Anesthesiology &amp; Perioperative Medicine, University of 
      Massachusetts Chan Medical School, Worcester, MA, USA.
FAU - Walz, Jens M
AU  - Walz JM
AD  - Department of Anesthesiology &amp; Perioperative Medicine, University of 
      Massachusetts Chan Medical School, Worcester, MA, USA.
FAU - Schaefer, Maximilian S
AU  - Schaefer MS
AD  - Department of Anesthesia, Critical Care and Pain Medicine, Beth Israel Deaconess 
      Medical Center, Harvard Medical School, Boston, MA, USA; Center for Anesthesia 
      Research Excellence, Beth Israel Deaconess Medical Center, Harvard Medical 
      School, Boston, MA, USA; Department of Anesthesiology, Dusseldorf University 
      Hospital, Dusseldorf, Germany.
FAU - Beam, Andrew
AU  - Beam A
AD  - Department of Epidemiology, Harvard T.H. Chan School of Public Health, Boston, 
      MA, USA. Electronic address: andrew_beam@hms.harvard.edu.
LA  - eng
PT  - Letter
DEP - 20230518
PL  - England
TA  - Br J Anaesth
JT  - British journal of anaesthesia
JID - 0372541
SB  - IM
MH  - Humans
MH  - *Anesthesiology
MH  - *Artificial Intelligence
MH  - Academic Performance
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - board examination
OT  - large language models
OT  - medical knowledge
OT  - multiple choice questions
OT  - specialty qualifications
EDAT- 2023/05/21 01:05
MHDA- 2023/10/23 00:44
CRDT- 2023/05/20 21:59
PHST- 2023/04/13 00:00 [received]
PHST- 2023/04/14 00:00 [accepted]
PHST- 2023/10/23 00:44 [medline]
PHST- 2023/05/21 01:05 [pubmed]
PHST- 2023/05/20 21:59 [entrez]
AID - S0007-0912(23)00192-7 [pii]
AID - 10.1016/j.bja.2023.04.017 [doi]
PST - ppublish
SO  - Br J Anaesth. 2023 Aug;131(2):e31-e34. doi: 10.1016/j.bja.2023.04.017. Epub 2023 
      May 18.

PMID- 38317003
OWN - NLM
STAT- Publisher
LR  - 20240207
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
DP  - 2024 Feb 5
TI  - 'Obviously ChatGPT' - how reviewers accused me of scientific fraud.
LID - 10.1038/d41586-024-00349-5 [doi]
FAU - Wolkovich, E M
AU  - Wolkovich EM
LA  - eng
PT  - News
DEP - 20240205
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
OTO - NOTNLM
OT  - Authorship
OT  - Careers
OT  - Ethics
OT  - Lab life
OT  - Machine learning
EDAT- 2024/02/06 00:42
MHDA- 2024/02/06 00:42
CRDT- 2024/02/05 23:40
PHST- 2024/02/06 00:42 [pubmed]
PHST- 2024/02/06 00:42 [medline]
PHST- 2024/02/05 23:40 [entrez]
AID - 10.1038/d41586-024-00349-5 [pii]
AID - 10.1038/d41586-024-00349-5 [doi]
PST - aheadofprint
SO  - Nature. 2024 Feb 5. doi: 10.1038/d41586-024-00349-5.

PMID- 37968529
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20231117
LR  - 20231118
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
VI  - 623
IP  - 7987
DP  - 2023 Nov
TI  - Why teachers should explore ChatGPT's potential - despite the risks.
PG  - 457-458
LID - 10.1038/d41586-023-03505-5 [doi]
LA  - eng
PT  - News
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
OTO - NOTNLM
OT  - Computer science
OT  - Education
OT  - Machine learning
OT  - Society
EDAT- 2023/11/16 06:45
MHDA- 2023/11/16 06:46
CRDT- 2023/11/16 00:04
PHST- 2023/11/16 06:46 [medline]
PHST- 2023/11/16 06:45 [pubmed]
PHST- 2023/11/16 00:04 [entrez]
AID - 10.1038/d41586-023-03505-5 [pii]
AID - 10.1038/d41586-023-03505-5 [doi]
PST - ppublish
SO  - Nature. 2023 Nov;623(7987):457-458. doi: 10.1038/d41586-023-03505-5.

PMID- 37812094
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20231010
LR  - 20231018
IS  - 1536-0075 (Electronic)
IS  - 1526-5161 (Linking)
VI  - 23
IP  - 10
DP  - 2023 Oct
TI  - The Hidden Costs of ChatGPT: A Call for Greater Transparency.
PG  - 47-49
LID - 10.1080/15265161.2023.2250335 [doi]
FAU - Elmore, Matthew
AU  - Elmore M
AD  - Duke University.
LA  - eng
PT  - Journal Article
DEP - 20231009
PL  - United States
TA  - Am J Bioeth
JT  - The American journal of bioethics : AJOB
JID - 100898738
SB  - IM
CIN - Am J Bioeth. 2023 Oct;23(10):1-5. PMID: 37831940
EDAT- 2023/10/09 12:42
MHDA- 2023/10/09 12:43
CRDT- 2023/10/09 10:13
PHST- 2023/10/09 12:43 [medline]
PHST- 2023/10/09 12:42 [pubmed]
PHST- 2023/10/09 10:13 [entrez]
AID - 10.1080/15265161.2023.2250335 [doi]
PST - ppublish
SO  - Am J Bioeth. 2023 Oct;23(10):47-49. doi: 10.1080/15265161.2023.2250335. Epub 2023 
      Oct 9.

PMID- 37541730
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20230807
LR  - 20230807
IS  - 1701-2163 (Print)
IS  - 1701-2163 (Linking)
VI  - 45
IP  - 8
DP  - 2023 Aug
TI  - [Divulgation de recours à l'intelligence artificielle ou ChatGPT dans les 
      manuscrits].
PG  - 545-546
LID - S1701-2163(23)00410-3 [pii]
LID - 10.1016/j.jogc.2023.05.030 [doi]
FAU - Tulandi, Togas
AU  - Tulandi T
LA  - fre
PT  - Editorial
PL  - Netherlands
TA  - J Obstet Gynaecol Can
JT  - Journal of obstetrics and gynaecology Canada : JOGC = Journal d'obstetrique et 
      gynecologie du Canada : JOGC
JID - 101126664
SB  - IM
EDAT- 2023/08/05 05:41
MHDA- 2023/08/07 06:42
CRDT- 2023/08/04 20:57
PHST- 2023/08/07 06:42 [medline]
PHST- 2023/08/05 05:41 [pubmed]
PHST- 2023/08/04 20:57 [entrez]
AID - S1701-2163(23)00410-3 [pii]
AID - 10.1016/j.jogc.2023.05.030 [doi]
PST - ppublish
SO  - J Obstet Gynaecol Can. 2023 Aug;45(8):545-546. doi: 10.1016/j.jogc.2023.05.030.

PMID- 37144055
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230507
IS  - 2757-8038 (Electronic)
IS  - 2757-8038 (Linking)
VI  - 24
IP  - 2
DP  - 2023 Mar
TI  - AI and Psychiatry: The ChatGPT Perspective.
PG  - 41-42
LID - 10.5152/alphapsychiatry.2023.010223 [doi]
FAU - Okan, Çalıyurt
AU  - Okan Ç
AD  - Department of Psychiatry, Trakya University School of Medicine, Edirne, Turkey.
LA  - eng
PT  - Editorial
DEP - 20230301
PL  - Turkey
TA  - Alpha Psychiatry
JT  - Alpha psychiatry
JID - 9918284277106676
PMC - PMC10151963
EDAT- 2023/05/05 06:42
MHDA- 2023/05/05 06:43
PMCR- 2023/03/01
CRDT- 2023/05/05 03:56
PHST- 2023/05/05 06:43 [medline]
PHST- 2023/05/05 06:42 [pubmed]
PHST- 2023/05/05 03:56 [entrez]
PHST- 2023/03/01 00:00 [pmc-release]
AID - ap-24-2-41 [pii]
AID - 10.5152/alphapsychiatry.2023.010223 [doi]
PST - epublish
SO  - Alpha Psychiatry. 2023 Mar 1;24(2):41-42. doi: 
      10.5152/alphapsychiatry.2023.010223. eCollection 2023 Mar.

PMID- 37869810
OWN - NLM
STAT- MEDLINE
DCOM- 20231101
LR  - 20231101
IS  - 1879-8365 (Electronic)
IS  - 0926-9630 (Linking)
VI  - 309
DP  - 2023 Oct 20
TI  - Clinical Acronym Disambiguation via ChatGPT and BING.
PG  - 78-82
LID - 10.3233/SHTI230743 [doi]
AB  - Clinical texts are written with acronyms, abbreviations and medical jargon 
      expressions to save time. This hinders full comprehension not just for medical 
      experts but also laypeople. This paper attempts to disambiguate acronyms with 
      their given context by comparing a web mining approach via the search engine BING 
      and a conversational agent approach using ChatGPT with the aim to see, if these 
      methods can supply a viable resolution for the input acronym. Both approaches are 
      automated via application programming interfaces. Possible term candidates are 
      extracted using natural language processing-oriented functionality. The 
      conversational agent approach surpasses the baseline for web mining without 
      plausibility thresholds in precision, recall and F1-measure, while scoring 
      similarly only in precision for high threshold values.
FAU - Kugic, Amila
AU  - Kugic A
AD  - Institute for Medical Informatics, Statistics and Documentation, Medical 
      University of Graz, Austria.
FAU - Kreuzthaler, Markus
AU  - Kreuzthaler M
AD  - Institute for Medical Informatics, Statistics and Documentation, Medical 
      University of Graz, Austria.
FAU - Schulz, Stefan
AU  - Schulz S
AD  - Institute for Medical Informatics, Statistics and Documentation, Medical 
      University of Graz, Austria.
LA  - eng
PT  - Journal Article
PL  - Netherlands
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
MH  - *Natural Language Processing
MH  - *Software
MH  - Search Engine
MH  - Communication
MH  - Writing
OTO - NOTNLM
OT  - Artificial Intelligence
OT  - Electronic Health Records
OT  - Natural Language Processing
EDAT- 2023/10/23 06:47
MHDA- 2023/11/01 12:42
CRDT- 2023/10/23 05:01
PHST- 2023/11/01 12:42 [medline]
PHST- 2023/10/23 06:47 [pubmed]
PHST- 2023/10/23 05:01 [entrez]
AID - SHTI230743 [pii]
AID - 10.3233/SHTI230743 [doi]
PST - ppublish
SO  - Stud Health Technol Inform. 2023 Oct 20;309:78-82. doi: 10.3233/SHTI230743.

PMID- 38443210
OWN - NLM
STAT- MEDLINE
DCOM- 20240325
LR  - 20240325
IS  - 1476-5411 (Electronic)
IS  - 1367-0484 (Linking)
VI  - 47
IP  - 2
DP  - 2024 Apr
TI  - Are artificial intelligence chatbots a reliable source of information about 
      contact lenses?
PG  - 102130
LID - S1367-0484(24)00013-4 [pii]
LID - 10.1016/j.clae.2024.102130 [doi]
AB  - INTRODUCTION: Artificial Intelligence (AI) chatbots are able to explain complex 
      concepts using plain language. The aim of this study was to assess the accuracy 
      of three AI chatbots answering common questions related to contact lens (CL) 
      wear. METHODS: Three open access AI chatbots were compared: Perplexity, Open 
      Assistant and ChatGPT 3.5. Ten general CL questions were asked to all AI chatbots 
      on the same day in two different countries, with the questions asked in Spanish 
      from Spain and in English from the U.K. Two independent optometrists with 
      experience working in each country assessed the accuracy of the answers provided. 
      Also, the AI chatbots' responses were assessed if their outputs showed any bias 
      towards (or against) any eye care professional (ECP). RESULTS: The answers 
      obtained by the same AI chatbots were different in Spain and the U.K. Also, 
      statistically significant differences were found between the AI chatbots for 
      accuracy. In the U.K., ChatGPT 3.5 was the most and Open Assistant least accurate 
      (p&nbsp;&lt;&nbsp;0.01). In Spain, Perplexity and ChatGPT were statistically more accurate 
      than Open Assistant (p&nbsp;&lt;&nbsp;0.01). All the AI chatbots presented bias, except 
      ChatGPT 3.5 in Spain. CONCLUSIONS: AI chatbots do not always consider local CL 
      legislation, and their accuracy seems to be dependent on the language used to 
      interact with them. Hence, at this time, although some AI chatbots might be a 
      good source of information for general CL related questions, they cannot replace 
      an ECP.
CI  - Copyright © 2024 The Authors. Published by Elsevier Ltd.. All rights reserved.
FAU - García-Porta, Nery
AU  - García-Porta N
AD  - Applied Physics Department, Optics and Optometry Faculty, University of Santiago 
      de Compostela, Spain; Institute of Materials (iMATUS) of the University of 
      Santiago de Compostela, Spain. Electronic address: nery.garcia.porta@usc.es.
FAU - Vaughan, Megan
AU  - Vaughan M
AD  - Anglia Ruskin University, Cambridge, UK.
FAU - Rendo-González, Sofia
AU  - Rendo-González S
AD  - Applied Physics Department, Optics and Optometry Faculty, University of Santiago 
      de Compostela, Spain.
FAU - Gómez-Varela, Ana I
AU  - Gómez-Varela AI
AD  - Applied Physics Department, Optics and Optometry Faculty, University of Santiago 
      de Compostela, Spain; Institute of Materials (iMATUS) of the University of 
      Santiago de Compostela, Spain.
FAU - O'Donnell, Autumn
AU  - O'Donnell A
AD  - University College Cork, Ireland.
FAU - de-Moura, Joaquim
AU  - de-Moura J
AD  - Varpa group, INIBIC, University of A Coruña, Spain.
FAU - Novo-Bujan, Jorge
AU  - Novo-Bujan J
AD  - Varpa group, INIBIC, University of A Coruña, Spain.
FAU - Ortega-Hortas, Marcos
AU  - Ortega-Hortas M
AD  - Varpa group, INIBIC, University of A Coruña, Spain.
LA  - eng
PT  - Journal Article
DEP - 20240304
PL  - England
TA  - Cont Lens Anterior Eye
JT  - Contact lens &amp; anterior eye : the journal of the British Contact Lens Association
JID - 9712714
SB  - IM
MH  - Humans
MH  - Artificial Intelligence
MH  - *Contact Lenses
MH  - Language
MH  - *Optometrists
MH  - Information Sources
OTO - NOTNLM
OT  - Artificial intelligence chatbots
OT  - Contact lens opticians
OT  - Contact lenses
OT  - Eye care professionals
OT  - Ophthalmologists
OT  - Optometrists
EDAT- 2024/03/06 00:41
MHDA- 2024/03/25 06:43
CRDT- 2024/03/05 21:55
PHST- 2023/09/14 00:00 [received]
PHST- 2024/02/12 00:00 [revised]
PHST- 2024/02/20 00:00 [accepted]
PHST- 2024/03/25 06:43 [medline]
PHST- 2024/03/06 00:41 [pubmed]
PHST- 2024/03/05 21:55 [entrez]
AID - S1367-0484(24)00013-4 [pii]
AID - 10.1016/j.clae.2024.102130 [doi]
PST - ppublish
SO  - Cont Lens Anterior Eye. 2024 Apr;47(2):102130. doi: 10.1016/j.clae.2024.102130. 
      Epub 2024 Mar 4.

PMID- 37690015
OWN - NLM
STAT- MEDLINE
DCOM- 20231106
LR  - 20231108
IS  - 1531-6564 (Electronic)
IS  - 0363-5023 (Linking)
VI  - 48
IP  - 11
DP  - 2023 Nov
TI  - Evaluation of Online Artificial Intelligence-Generated Information on Common Hand 
      Procedures.
PG  - 1122-1127
LID - S0363-5023(23)00414-8 [pii]
LID - 10.1016/j.jhsa.2023.08.003 [doi]
AB  - PURPOSE: The purpose of this study was to analyze the quality and readability of 
      the information generated by an online artificial intelligence (AI) platform 
      regarding 4 common hand surgeries and to compare AI-generated responses to those 
      provided in the informational articles published by the American Society for 
      Surgery of the Hand (ASSH) HandCare website. METHODS: An open AI model (ChatGPT) 
      was used to answer questions commonly asked by patients on 4 common hand 
      surgeries (carpal tunnel release, cubital tunnel release, trigger finger release, 
      and distal radius fracture fixation). These answers were evaluated for medical 
      accuracy, quality and readability and compared to answers derived from the ASSH 
      HandCare materials. RESULTS: For the AI model, the Journal of the American 
      Medical Association benchmark criteria score was 0/4, and the DISCERN score was 
      58 (considered good). The areas in which the AI model lost points were primarily 
      related to the lack of attribution, reliability and currency of the source 
      material. For AI responses, the mean Flesch Kinkaid Reading Ease score was 15, 
      and the Flesch Kinkaid Grade Level was 34, which is considered to be college 
      level. For comparison, ASSH HandCare materials scored 3/4 on the Journal of the 
      American Medical Association Benchmark, 71 on DISCERN (excellent), 9 on Flesch 
      Kinkaid Grade Level, and 60 on Flesch Kinkaid Reading Ease score (eighth/ninth 
      grade level). CONCLUSION: An AI language model (ChatGPT) provided generally 
      high-quality answers to frequently asked questions relating to the common hand 
      procedures queried, but it is unclear when or where these answers came from 
      without citations to source material. Furthermore, a high reading level was 
      required to comprehend the information presented. The AI software repeatedly 
      referenced the need to discuss these questions with a surgeon, the importance of 
      shared decision-making and individualized care, and compliance with surgeon 
      treatment recommendations. CLINICAL RELEVANCE: As novel AI applications become 
      increasingly mainstream, hand surgeons must understand the limitations and 
      ramifications these technologies have for patient care.
CI  - Copyright © 2023 American Society for Surgery of the Hand. Published by Elsevier 
      Inc. All rights reserved.
FAU - Crook, Bryan S
AU  - Crook BS
AD  - Department of Orthopaedic Surgery, Duke University Hospital, Durham, NC. 
      Electronic address: bryan.crook@duke.edu.
FAU - Park, Caroline N
AU  - Park CN
AD  - Department of Orthopaedic Surgery, Duke University Hospital, Durham, NC.
FAU - Hurley, Eoghan T
AU  - Hurley ET
AD  - Department of Orthopaedic Surgery, Duke University Hospital, Durham, NC.
FAU - Richard, Marc J
AU  - Richard MJ
AD  - Department of Orthopaedic Surgery, Duke University Hospital, Durham, NC.
FAU - Pidgeon, Tyler S
AU  - Pidgeon TS
AD  - Department of Orthopaedic Surgery, Duke University Hospital, Durham, NC.
LA  - eng
PT  - Journal Article
DEP - 20230909
PL  - United States
TA  - J Hand Surg Am
JT  - The Journal of hand surgery
JID - 7609631
SB  - IM
MH  - Humans
MH  - United States
MH  - *Health Literacy
MH  - Artificial Intelligence
MH  - Reproducibility of Results
MH  - Hand/surgery
MH  - Comprehension
MH  - Internet
OTO - NOTNLM
OT  - Artificial intelligence
OT  - health literacy
OT  - internet
OT  - patient education
OT  - readability
EDAT- 2023/09/10 12:41
MHDA- 2023/11/06 06:42
CRDT- 2023/09/10 10:31
PHST- 2023/05/06 00:00 [received]
PHST- 2023/07/25 00:00 [revised]
PHST- 2023/08/02 00:00 [accepted]
PHST- 2023/11/06 06:42 [medline]
PHST- 2023/09/10 12:41 [pubmed]
PHST- 2023/09/10 10:31 [entrez]
AID - S0363-5023(23)00414-8 [pii]
AID - 10.1016/j.jhsa.2023.08.003 [doi]
PST - ppublish
SO  - J Hand Surg Am. 2023 Nov;48(11):1122-1127. doi: 10.1016/j.jhsa.2023.08.003. Epub 
      2023 Sep 9.

PMID- 36865238
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230712
DP  - 2023 Feb 20
TI  - Fighting reviewer fatigue or amplifying bias? Considerations and recommendations 
      for use of ChatGPT and other Large Language Models in scholarly peer review.
LID - rs.3.rs-2587766 [pii]
LID - 10.21203/rs.3.rs-2587766/v1 [doi]
AB  - Background: The emergence of systems based on large language models (LLMs) such 
      as OpenAI's ChatGPT has created a range of discussions in scholarly circles. 
      Since LLMs generate grammatically correct and mostly relevant (yet sometimes 
      outright wrong, irrelevant or biased) outputs in response to provided prompts, 
      using them in various writing tasks including writing peer review reports could 
      result in improved productivity. Given the significance of peer reviews in the 
      existing scholarly publication landscape, exploring challenges and opportunities 
      of using LLMs in peer review seems urgent. After the generation of the first 
      scholarly outputs with LLMs, we anticipate that peer review reports too would be 
      generated with the help of these systems. However, there are currently no 
      guidelines on how these systems should be used in review tasks. Methods: To 
      investigate the potential impact of using LLMs on the peer review process, we 
      used five core themes within discussions about peer review suggested by Tennant 
      and Ross-Hellauer. These include 1) reviewers' role, 2) editors' role, 3) 
      functions and quality of peer reviews, 4) reproducibility, and 5) the social and 
      epistemic functions of peer reviews. We provide a small-scale exploration of 
      ChatGPT's performance regarding identified issues. Results: LLMs have the 
      potential to substantially alter the role of both peer reviewers and editors. 
      Through supporting both actors in efficiently writing constructive reports or 
      decision letters, LLMs can facilitate higher quality review and address issues of 
      review shortage. However, the fundamental opacity of LLMs' inner workings and 
      development, raise questions and concerns about potential biases and the 
      reliability of review reports. Additionally, as editorial work has a prominent 
      function in defining and shaping epistemic communities, as well as negotiating 
      normative frameworks within such communities, partly outsourcing this work to 
      LLMs might have unforeseen consequences for social and epistemic relations within 
      academia. Regarding performance, we identified major enhancements in only a few 
      weeks (between December 2022 and January 2023) and expect ChatGPT to continue 
      improving. Conclusions: We believe that LLMs are likely to have a profound impact 
      on academia and scholarly communication. While they have the potential to address 
      several current issues within the scholarly communication system, many 
      uncertainties remain and their use is not without risks. In particular, concerns 
      about the amplification of existing biases and inequalities in access to 
      appropriate infrastructure warrant further attention. For the moment, we 
      recommend that if LLMs are used to write scholarly reviews, reviewers should 
      disclose their use and accept full responsibility for their reports' accuracy, 
      tone, reasoning and originality.
FAU - Hosseini, Mohammad
AU  - Hosseini M
AUID- ORCID: 0000-0002-2385-985X
AD  - Northwestern University Feinberg School of Medicine.
FAU - Horbach, Serge P J M
AU  - Horbach SPJM
AD  - Aarhus Universitet.
LA  - eng
GR  - UL1 TR001422/TR/NCATS NIH HHS/United States
PT  - Preprint
DEP - 20230220
PL  - United States
TA  - Res Sq
JT  - Research square
JID - 101768035
UIN - Res Integr Peer Rev. 2023 May 18;8(1):4. PMID: 37198671
PMC - PMC9980209
COIS- Competing interests The authors have no competing interests.
EDAT- 2023/03/04 06:00
MHDA- 2023/03/04 06:01
PMCR- 2023/03/02
CRDT- 2023/03/03 02:29
PHST- 2023/03/03 02:29 [entrez]
PHST- 2023/03/04 06:00 [pubmed]
PHST- 2023/03/04 06:01 [medline]
PHST- 2023/03/02 00:00 [pmc-release]
AID - rs.3.rs-2587766 [pii]
AID - 10.21203/rs.3.rs-2587766/v1 [doi]
PST - epublish
SO  - Res Sq [Preprint]. 2023 Feb 20:rs.3.rs-2587766. doi: 10.21203/rs.3.rs-2587766/v1.

PMID- 37644984
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230831
IS  - 2296-858X (Print)
IS  - 2296-858X (Electronic)
IS  - 2296-858X (Linking)
VI  - 10
DP  - 2023
TI  - Editorial: Personalized medicine-Where do we stand regarding bench to bedside 
      translation?
PG  - 1243896
LID - 10.3389/fmed.2023.1243896 [doi]
LID - 1243896
FAU - Raghavendran, Hanumantha Rao Balaji
AU  - Raghavendran HRB
AD  - Biomaterials Laboratory, Faculty of Clinical Research, Sri Ramachandra Institute 
      of Higher Education and Research, Chennai, India.
FAU - Kumaramanickavel, Govindasamy
AU  - Kumaramanickavel G
AD  - Narayana Nethralaya, Narayana Health City, Bengaluru, Karnataka, India.
FAU - Iwata, Takeshi
AU  - Iwata T
AD  - Molecular and Cellular Biology Division, National Institute of Sensory Organs, 
      National Hospital Organization Tokyo Medical Center, Tokyo, Japan.
LA  - eng
PT  - Editorial
DEP - 20230814
PL  - Switzerland
TA  - Front Med (Lausanne)
JT  - Frontiers in medicine
JID - 101648047
CON - Editorial on the Research Topic Personalized medicine—Where do we stand regarding 
      bench to bedside translation?
PMC - PMC10461804
OTO - NOTNLM
OT  - ChatGPT
OT  - lateral sclerosis (ALS)
OT  - osteoarthritis
OT  - personalized medicine
OT  - ulcer prophylaxis
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/08/30 06:47
MHDA- 2023/08/30 06:48
PMCR- 2023/08/14
CRDT- 2023/08/30 03:45
PHST- 2023/06/21 00:00 [received]
PHST- 2023/07/24 00:00 [accepted]
PHST- 2023/08/30 06:48 [medline]
PHST- 2023/08/30 06:47 [pubmed]
PHST- 2023/08/30 03:45 [entrez]
PHST- 2023/08/14 00:00 [pmc-release]
AID - 10.3389/fmed.2023.1243896 [doi]
PST - epublish
SO  - Front Med (Lausanne). 2023 Aug 14;10:1243896. doi: 10.3389/fmed.2023.1243896. 
      eCollection 2023.

PMID- 38076260
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231211
IS  - 2296-858X (Print)
IS  - 2296-858X (Electronic)
IS  - 2296-858X (Linking)
VI  - 10
DP  - 2023
TI  - Exploring large language model for next generation of artificial intelligence in 
      ophthalmology.
PG  - 1291404
LID - 10.3389/fmed.2023.1291404 [doi]
LID - 1291404
AB  - In recent years, ophthalmology has advanced significantly, thanks to rapid 
      progress in artificial intelligence (AI) technologies. Large language models 
      (LLMs) like ChatGPT have emerged as powerful tools for natural language 
      processing. This paper finally includes 108 studies, and explores LLMs' potential 
      in the next generation of AI in ophthalmology. The results encompass a diverse 
      range of studies in the field of ophthalmology, highlighting the versatile 
      applications of LLMs. Subfields encompass general ophthalmology, retinal 
      diseases, anterior segment diseases, glaucoma, and ophthalmic plastics. Results 
      show LLMs' competence in generating informative and contextually relevant 
      responses, potentially reducing diagnostic errors and improving patient outcomes. 
      Overall, this study highlights LLMs' promising role in shaping AI's future in 
      ophthalmology. By leveraging AI, ophthalmologists can access a wealth of 
      information, enhance diagnostic accuracy, and provide better patient care. 
      Despite challenges, continued AI advancements and ongoing research will pave the 
      way for the next generation of AI-assisted ophthalmic practices.
CI  - Copyright © 2023 Jin, Yuan, Wu, Grzybowski and Ye.
FAU - Jin, Kai
AU  - Jin K
AD  - Eye Center, The Second Affiliated Hospital, School of Medicine, Zhejiang 
      University, Hangzhou, China.
FAU - Yuan, Lu
AU  - Yuan L
AD  - Department of Ophthalmology, The Children's Hospital, Zhejiang University School 
      of Medicine, National Clinical Research Center for Child Health, Hangzhou, China.
FAU - Wu, Hongkang
AU  - Wu H
AD  - Eye Center, The Second Affiliated Hospital, School of Medicine, Zhejiang 
      University, Hangzhou, China.
FAU - Grzybowski, Andrzej
AU  - Grzybowski A
AD  - Institute for Research in Ophthalmology, Foundation for Ophthalmology 
      Development, Poznan, Poland.
FAU - Ye, Juan
AU  - Ye J
AD  - Eye Center, The Second Affiliated Hospital, School of Medicine, Zhejiang 
      University, Hangzhou, China.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20231123
PL  - Switzerland
TA  - Front Med (Lausanne)
JT  - Frontiers in medicine
JID - 101648047
PMC - PMC10701277
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - diagnostic accuracy and efficacy
OT  - large language model
OT  - ophthalmology
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/12/11 12:42
MHDA- 2023/12/11 12:43
PMCR- 2023/11/23
CRDT- 2023/12/11 06:07
PHST- 2023/09/09 00:00 [received]
PHST- 2023/10/20 00:00 [accepted]
PHST- 2023/12/11 12:43 [medline]
PHST- 2023/12/11 12:42 [pubmed]
PHST- 2023/12/11 06:07 [entrez]
PHST- 2023/11/23 00:00 [pmc-release]
AID - 10.3389/fmed.2023.1291404 [doi]
PST - epublish
SO  - Front Med (Lausanne). 2023 Nov 23;10:1291404. doi: 10.3389/fmed.2023.1291404. 
      eCollection 2023.
</pre>
      
    </div>
  </main>


  
  


  


</body></html>