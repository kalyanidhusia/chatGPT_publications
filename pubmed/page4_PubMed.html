<!DOCTYPE html>
<!-- saved from url=(0075)https://pubmed.ncbi.nlm.nih.gov/?term=chatGPT&page=4&format=pubmed&size=200 -->
<html lang="en"><head itemscope="" itemtype="http://schema.org/WebPage" prefix="og: http://ogp.me/ns#"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <!-- Mobile properties -->
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov/">
  <link rel="preconnect" href="https://www.ncbi.nlm.nih.gov/">
  <link rel="preconnect" href="https://www.google-analytics.com/">

  
  
    <link rel="stylesheet" href="./page4_PubMed_files/output.5ecf62baa0fa.css" type="text/css">
  

  <link rel="stylesheet" href="./page4_PubMed_files/output.452c70ce66f7.css" type="text/css">

  
    
  

  
    <link rel="stylesheet" href="./page4_PubMed_files/output.97c300a159d1.css" type="text/css">
  

  


    <title>chatGPT - Search Results - PubMed</title>

  
  
  <!-- Favicons -->
  <link rel="shortcut icon" type="image/ico" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.ico">
  <link rel="icon" type="image/png" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.png">

  <!-- 192x192, as recommended for Android
  http://updates.html5rocks.com/2014/11/Support-for-theme-color-in-Chrome-39-for-Android
  -->
  <link rel="icon" type="image/png" sizes="192x192" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-192.png">

  <!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
  <link rel="apple-touch-icon-precomposed" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-57.png">
  <!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
  <link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-72.png">
  <!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
  <link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-114.png">
  <!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://cdn.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-144.png">


  <!-- For Pinger + Google Optimize integration (NS-820) -->
  <meta name="ncbi_sg_optimize_id" content="">

  <!-- Mobile browser address bar color -->
  <meta name="theme-color" content="#20558a">

  <!-- Preserve the Referrer when going from HTTPS to HTTP -->
  <meta name="referrer" content="origin-when-cross-origin">

  <meta name="ncbi_pinger_gtm_track" content="true">
<!-- Logging params: Pinger defaults -->

  
    <meta name="ncbi_app" content="pubmed">
  

  
    <meta name="ncbi_db" content="pubmed">
  

  
    <meta name="ncbi_phid" content="658B00010FEE1FF500003989DEB7A16A.1.m_7">
  

  
    <meta name="ncbi_pinger_stat_url" content="https://www.ncbi.nlm.nih.gov/stat">
  

  
    <meta name="log_category" content="literature">
  

  
    <meta name="ncbi_cost_center" content="pubmed">
  



  <!-- Logging params: Pinger custom -->
  
    <meta name="log_op" content="search">
  
    <meta name="log_query" content="chatGPT">
  
    <meta name="ncbi_pdid" content="searchresult">
  
    <meta name="ncbi_pageno" content="4">
  
    <meta name="log_resultcount" content="2844">
  
    <meta name="log_userterm" content="chatGPT">
  
    <meta name="log_processedquery" content="&quot;chatGPT&quot;[All Fields]">
  
    <meta name="log_filtersactive" content="False">
  
    <meta name="log_filters" content="">
  
    <meta name="ncbi_log_query" content="chatGPT">
  
    <meta name="log_proximity_search_active" content="False">
  
    <meta name="log_format" content="pubmed">
  
    <meta name="log_sortorder" content="relevance">
  
    <meta name="log_pagesize" content="200">
  
    <meta name="log_displayeduids" content="37500980,37221834,37274428,37120563,37094282,37716431,37614494,37247851,37509379,37736448,37671207,37368470,37071280,38364879,37309705,37389908,38562449,38444627,37988149,37904734,37066228,37273063,37768724,38435794,37401955,38374067,38445975,37516804,37217092,37519497,38308014,38239905,38112605,38503659,37606000,37601325,37487184,37115245,38295336,38275279,37250832,38559518,38265047,37181697,38418378,38062632,37979017,36813155,38362184,37550893,37423350,38539117,38217478,37865883,37456464,38355517,37566815,36589923,37667724,38521243,37694729,38215452,37548379,36929393,38349133,37908933,37882183,38488302,37974429,37965416,37259767,38170831,38066714,37950660,37565917,37493845,37879261,37771867,37531256,37142479,37043716,38341993,38337594,38249202,38058315,38128909,37562022,37467806,37387096,37227901,38550240,38126511,37968408,37829968,38204561,37310252,37167941,38522424,38412022,37939645,37808173,37314466,37671567,37629452,37095802,37561097,38509629,37263772,38527444,37891086,37521206,38046759,37528607,36789422,37256656,37075729,37724135,37469634,37347508,38490569,38453462,37922198,37529703,37244834,37404248,38528129,38183235,38022227,38015610,37566454,37636841,37887080,38217966,38555637,38449683,38169077,38361805,37430793,38239420,37846274,38502320,37385685,37285018,37339728,36819954,37980605,37890504,38531823,37606976,38486738,37994523,37611254,38171421,36865144,37095665,37949111,37546795,37088277,37227477,37207982,37101311,38483426,37717655,38168838,38550977,38215796,38038222,37229911,37862879,37052880,38336588,38259300,37724211,37699796,37001483,36971685,37988948,37651381,38547497,37898100,37541814,37090396,37920024,37674966,37253791,38446539,37907728,37698823,37269717,37440646,38472675,38306961,38199794,37459740,38335017,38310152,38233511,37294147,37191485,38455449">
  
    <meta name="ncbi_search_id" content="R3Cs2GC7H0x0KE8U7UASSA:deef7cbfe7e81e7152f8e0e261e5ab1a">
  
    <meta name="ncbi_adj_nav_search_id" content="eHvHYkxDXFIsEPP8mTB5Bg:fbd847f89c96214ac23b7c62d7cb721a">
  



  <!-- Social meta tags for unfurling urls -->
  
<meta name="description" content="chatGPT - Search Results - PubMed"><meta name="robots" content="noindex,follow,noarchive"><meta property="og:title" content="chatGPT - Search Results - PubMed"><meta property="og:url" content="https://pubmed.ncbi.nlm.nih.gov/?term=chatGPT&amp;page=4&amp;format=pubmed&amp;size=200"><meta property="og:description" content="chatGPT - Search Results - PubMed"><meta property="og:image" content="https://cdn.ncbi.nlm.nih.gov/pubmed/persistent/pubmed-meta-image-v2.jpg"><meta property="og:image:secure_url" content="https://cdn.ncbi.nlm.nih.gov/pubmed/persistent/pubmed-meta-image-v2.jpg"><meta property="og:type" content="website"><meta property="og:site_name" content="PubMed"><meta name="twitter:domain" content="pubmed.ncbi.nlm.nih.gov"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="chatGPT - Search Results - PubMed"><meta name="twitter:url" content="https://pubmed.ncbi.nlm.nih.gov/?term=chatGPT&amp;page=4&amp;format=pubmed&amp;size=200"><meta name="twitter:description" content="chatGPT - Search Results - PubMed"><meta name="twitter:image" content="https://cdn.ncbi.nlm.nih.gov/pubmed/persistent/pubmed-meta-image-v2.jpg">


  <!-- OpenSearch XML -->
  <link rel="search" type="application/opensearchdescription+xml" href="https://cdn.ncbi.nlm.nih.gov/pubmed/persistent/opensearch.xml" title="PubMed search">

  <!-- Disables severely broken elements when no JS -->
  <noscript>
    <link rel="stylesheet" type="text/css" href="https://cdn.ncbi.nlm.nih.gov/pubmed/09ad9aad-98d9-47ec-b2ea-fb4dba3d550d/core/no-script.css">
  </noscript>

  
    <link rel="canonical" href="https://pubmed.ncbi.nlm.nih.gov/?term=chatGPT&amp;page=4&amp;format=pubmed&amp;size=200">
  


</head>
<body>

  
  <main class="search-page" id="search-page">
    <div class="search-results" id="search-results">
      
        <pre class="search-results-chunk">PMID- 37500980
OWN - NLM
STAT- MEDLINE
DCOM- 20240214
LR  - 20240214
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Print)
IS  - 0090-6964 (Linking)
VI  - 52
IP  - 3
DP  - 2024 Mar
TI  - AI-ChatGPT/GPT-4: An Booster for the Development of Physical Medicine and 
      Rehabilitation in the New Era!
PG  - 462-466
LID - 10.1007/s10439-023-03314-x [doi]
AB  - Artificial intelligence (AI) has been driving the continuous development of the 
      Physical Medicine and Rehabilitation (PM&amp;R) fields. The latest release of 
      ChatGPT/GPT-4 has shown us that AI can potentially transform the healthcare 
      industry. In this study, we propose various ways in which ChatGPT/GPT-4 can 
      display its talents in the field of PM&amp;R in future. ChatGPT/GPT-4 is an essential 
      tool for Physiatrists in the new era.
CI  - © 2023. The Author(s).
FAU - Peng, Shengxin
AU  - Peng S
AD  - School of Rehabilitation Medicine of Binzhou Medical University, Yantai, China.
FAU - Wang, Deqiang
AU  - Wang D
AD  - School of Rehabilitation Medicine of Binzhou Medical University, Yantai, China.
FAU - Liang, Yuanhao
AU  - Liang Y
AD  - Weifang Medical University, Weifang, China.
FAU - Xiao, Wenshan
AU  - Xiao W
AD  - Shandong First Medical University, Jinan, China.
FAU - Zhang, Yixiang
AU  - Zhang Y
AD  - Weifang Medical University, Weifang, China.
FAU - Liu, Lei
AU  - Liu L
AUID- ORCID: 0000-0002-6915-1929
AD  - Department of Painology, The First Affiliated Hospital of Shandong First Medical 
      University (Shandong Provincial Qianfoshan Hospital), Jinan, 250014, China. 
      fort0825@sina.com.
LA  - eng
GR  - 2022cxgx020510/2022 Shandong Province Key R&amp;D Program/
PT  - Letter
DEP - 20230727
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - *Artificial Intelligence
MH  - *Physical and Rehabilitation Medicine
MH  - Physical Examination
PMC - PMC10859338
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - GPT-4
OT  - Physical medicine and rehabilitation
COIS- All authors declare no conflict of interest. No benefits in any form have been or 
      will be received from a commercial party related directly or indirectly to the 
      subject of this manuscript.
EDAT- 2023/07/28 01:08
MHDA- 2024/02/12 15:42
PMCR- 2023/07/27
CRDT- 2023/07/27 23:34
PHST- 2023/07/03 00:00 [received]
PHST- 2023/07/06 00:00 [accepted]
PHST- 2024/02/12 15:42 [medline]
PHST- 2023/07/28 01:08 [pubmed]
PHST- 2023/07/27 23:34 [entrez]
PHST- 2023/07/27 00:00 [pmc-release]
AID - 10.1007/s10439-023-03314-x [pii]
AID - 3314 [pii]
AID - 10.1007/s10439-023-03314-x [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2024 Mar;52(3):462-466. doi: 10.1007/s10439-023-03314-x. Epub 
      2023 Jul 27.

PMID- 37221834
OWN - NLM
STAT- MEDLINE
DCOM- 20230725
LR  - 20230727
IS  - 2287-285X (Electronic)
IS  - 2287-2728 (Print)
IS  - 2287-2728 (Linking)
VI  - 29
IP  - 3
DP  - 2023 Jul
TI  - Letter 2 regarding "Assessing the performance of ChatGPT in answering questions 
      regarding cirrhosis and hepatocellular carcinoma".
PG  - 815-816
LID - 10.3350/cmh.2023.0170 [doi]
FAU - Kleebayoon, Amnuay
AU  - Kleebayoon A
AD  - Samraong, Cambodia.
FAU - Wiwanitkit, Viroj
AU  - Wiwanitkit V
AD  - Chandigarh University, Punjab, India.
AD  - Joesph Ayobabalola University, Ikeji-Arakeji, Nigeria.
LA  - eng
PT  - Comment
PT  - Journal Article
DEP - 20230524
PL  - Korea (South)
TA  - Clin Mol Hepatol
JT  - Clinical and molecular hepatology
JID - 101586730
SB  - IM
CON - Clin Mol Hepatol. 2023 Jul;29(3):721-732. PMID: 36946005
CIN - Clin Mol Hepatol. 2023 Jul;29(3):823-824. PMID: 37254485
MH  - Humans
MH  - *Carcinoma, Hepatocellular
MH  - *Liver Neoplasms
MH  - Liver Cirrhosis
PMC - PMC10366795
OTO - NOTNLM
OT  - Carcinoma
OT  - ChatGPT
OT  - Performance
COIS- Conflicts of Interest The authors have no conflicts to disclose.
EDAT- 2023/05/24 06:42
MHDA- 2023/07/25 06:43
PMCR- 2023/07/01
CRDT- 2023/05/24 03:08
PHST- 2023/05/18 00:00 [received]
PHST- 2023/05/23 00:00 [accepted]
PHST- 2023/07/25 06:43 [medline]
PHST- 2023/05/24 06:42 [pubmed]
PHST- 2023/05/24 03:08 [entrez]
PHST- 2023/07/01 00:00 [pmc-release]
AID - cmh.2023.0170 [pii]
AID - cmh-2023-0170 [pii]
AID - 10.3350/cmh.2023.0170 [doi]
PST - ppublish
SO  - Clin Mol Hepatol. 2023 Jul;29(3):815-816. doi: 10.3350/cmh.2023.0170. Epub 2023 
      May 24.

PMID- 37274428
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230606
IS  - 1178-2390 (Print)
IS  - 1178-2390 (Electronic)
IS  - 1178-2390 (Linking)
VI  - 16
DP  - 2023
TI  - Using ChatGPT in Medical Research: Current Status and Future Directions.
PG  - 1513-1520
LID - 10.2147/JMDH.S413470 [doi]
AB  - OBJECTIVE: This review aims to evaluate the current evidence on the use of the 
      Generative Pre-trained Transformer (ChatGPT) in medical research, including but 
      not limited to treatment, diagnosis, or medication provision. METHODS: This 
      review follows the Preferred Reporting Items for Systematic Reviews and 
      Meta-Analyses (PRISMA) guidelines. We searched Google Scholar, Web of Science, 
      PubMed, and Medline to identify studies published between 2022 and 2023 that 
      aimed to utilize ChatGPT in medical research. All identified references were 
      stored in EndNote. RESULTS: We initially identified 114 articles, out of which 
      six studies met the inclusion and exclusion criteria for full-text screening. 
      Among the six studies, two focused on drug development (33.33%), two on 
      literature review writing (33.33%), and one each on medical report improvement, 
      provision of medical information, improving research conduct, data analysis, and 
      personalized medicine (16.67% each). CONCLUSION: ChatGPT has the potential to 
      revolutionize medical research in various ways. However, its accuracy, 
      originality, academic integrity, and ethical issues must be thoroughly discussed 
      and improved before its widespread implementation in clinical research and 
      medical practice.
CI  - © 2023 Ruksakulpiwat et al.
FAU - Ruksakulpiwat, Suebsarn
AU  - Ruksakulpiwat S
AUID- ORCID: 0000-0003-2168-5195
AD  - Department of Medical Nursing, Faculty of Nursing, Mahidol University, Bangkok, 
      Thailand.
FAU - Kumar, Ayanesh
AU  - Kumar A
AD  - School of Medicine, Case Western Reserve University, Cleveland, OH, USA.
FAU - Ajibade, Anuoluwapo
AU  - Ajibade A
AUID- ORCID: 0000-0003-4915-5698
AD  - College of Art and Science, Department of Anthropology, Case Western Reserve 
      University, Cleveland, OH, USA.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230530
PL  - New Zealand
TA  - J Multidiscip Healthc
JT  - Journal of multidisciplinary healthcare
JID - 101512691
PMC - PMC10239248
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - medical research
OT  - review
COIS- The authors report no conflicts of interest in this work.
EDAT- 2023/06/05 13:04
MHDA- 2023/06/05 13:05
PMCR- 2023/05/30
CRDT- 2023/06/05 12:02
PHST- 2023/03/28 00:00 [received]
PHST- 2023/05/17 00:00 [accepted]
PHST- 2023/06/05 13:05 [medline]
PHST- 2023/06/05 13:04 [pubmed]
PHST- 2023/06/05 12:02 [entrez]
PHST- 2023/05/30 00:00 [pmc-release]
AID - 413470 [pii]
AID - 10.2147/JMDH.S413470 [doi]
PST - epublish
SO  - J Multidiscip Healthc. 2023 May 30;16:1513-1520. doi: 10.2147/JMDH.S413470. 
      eCollection 2023.

PMID- 37120563
OWN - NLM
STAT- MEDLINE
DCOM- 20230502
LR  - 20230503
IS  - 2046-4053 (Electronic)
IS  - 2046-4053 (Linking)
VI  - 12
IP  - 1
DP  - 2023 Apr 29
TI  - Are ChatGPT and large language models "the answer" to bringing us closer to 
      systematic review automation?
PG  - 72
LID - 10.1186/s13643-023-02243-z [doi]
LID - 72
AB  - In this commentary, we discuss ChatGPT and our perspectives on its utility to 
      systematic reviews (SRs) through the appropriateness and applicability of its 
      responses to SR related prompts. The advancement of artificial intelligence 
      (AI)-assisted technologies leave many wondering about the current capabilities, 
      limitations, and opportunities for integration AI into scientific endeavors. 
      Large language models (LLM)-such as ChatGPT, designed by OpenAI-have recently 
      gained widespread attention with their ability to respond to various prompts in a 
      natural-sounding way. Systematic reviews (SRs) utilize secondary data and often 
      require many months and substantial financial resources to complete, making them 
      attractive grounds for developing AI-assistive technologies. On February 6, 2023, 
      PICO Portal developers hosted a webinar to explore ChatGPT's responses to tasks 
      related to SR methodology. Our experience from exploring the responses of ChatGPT 
      suggest that while ChatGPT and LLMs show some promise for aiding in SR-related 
      tasks, the technology is in its infancy and needs much development for such 
      applications. Furthermore, we advise that great caution should be taken by 
      non-content experts in using these tools due to much of the output appearing, at 
      a high level, to be valid, while much is erroneous and in need of active vetting.
CI  - © 2023. The Author(s).
FAU - Qureshi, Riaz
AU  - Qureshi R
AUID- ORCID: 0000-0002-6670-4874
AD  - University of Colorado Anschutz Medical Campus, Aurora, CO, USA. 
      riaz.qureshi@cuanschutz.edu.
AD  - PICO Portal, New York, NY, USA. riaz.qureshi@cuanschutz.edu.
FAU - Shaughnessy, Daniel
AU  - Shaughnessy D
AD  - University of Colorado Anschutz Medical Campus, Aurora, CO, USA.
FAU - Gill, Kayden A R
AU  - Gill KAR
AD  - PICO Portal, New York, NY, USA.
AD  - University of Pittsburgh, Pittsburgh, PA, USA.
FAU - Robinson, Karen A
AU  - Robinson KA
AD  - PICO Portal, New York, NY, USA.
AD  - Johns Hopkins University, Baltimore, MD, USA.
FAU - Li, Tianjing
AU  - Li T
AD  - University of Colorado Anschutz Medical Campus, Aurora, CO, USA.
AD  - PICO Portal, New York, NY, USA.
FAU - Agai, Eitan
AU  - Agai E
AD  - PICO Portal, New York, NY, USA.
LA  - eng
PT  - Journal Article
DEP - 20230429
PL  - England
TA  - Syst Rev
JT  - Systematic reviews
JID - 101580575
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Automation
MH  - Language
MH  - *Self-Help Devices
MH  - Technology
MH  - Systematic Reviews as Topic
PMC - PMC10148473
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Large language models
OT  - Methodology
OT  - Systematic review
COIS- RQ, KG, TL, and KR provide consultative services to PICO Portal. EA is the 
      founder and owner of PICO Portal. PICO Portal itself has no affiliation with 
      ChatGPT. DS has no relevant interests.
EDAT- 2023/04/30 00:42
MHDA- 2023/05/01 12:43
PMCR- 2023/04/29
CRDT- 2023/04/29 23:17
PHST- 2023/03/21 00:00 [received]
PHST- 2023/04/20 00:00 [accepted]
PHST- 2023/05/01 12:43 [medline]
PHST- 2023/04/30 00:42 [pubmed]
PHST- 2023/04/29 23:17 [entrez]
PHST- 2023/04/29 00:00 [pmc-release]
AID - 10.1186/s13643-023-02243-z [pii]
AID - 2243 [pii]
AID - 10.1186/s13643-023-02243-z [doi]
PST - epublish
SO  - Syst Rev. 2023 Apr 29;12(1):72. doi: 10.1186/s13643-023-02243-z.

PMID- 37094282
OWN - NLM
STAT- MEDLINE
DCOM- 20240115
LR  - 20240115
IS  - 1873-1953 (Electronic)
IS  - 1474-5151 (Linking)
VI  - 23
IP  - 1
DP  - 2024 Jan 12
TI  - What if your patient switches from Dr. Google to Dr. ChatGPT? A vignette-based 
      survey of the trustworthiness, value, and danger of ChatGPT-generated responses 
      to health questions.
PG  - 95-98
LID - 10.1093/eurjcn/zvad038 [doi]
AB  - ChatGPT is a new artificial intelligence system that revolutionizes the way how 
      information can be sought and obtained. In this study, the trustworthiness, 
      value, and danger of ChatGPT-generated responses on four vignettes that 
      represented virtual patient questions were evaluated by 20 experts in the domain 
      of congenital heart disease, atrial fibrillation, heart failure, or cholesterol. 
      Experts generally considered ChatGPT-generated responses trustworthy and 
      valuable, with few considering them dangerous. Forty percent of the experts found 
      ChatGPT responses more valuable than Google. Experts appreciated the 
      sophistication and nuances in the responses but also recognized that responses 
      were often incomplete and sometimes misleading.
CI  - © The Author(s) 2023. Published by Oxford University Press on behalf of the 
      European Society of Cardiology.
FAU - Van Bulck, Liesbet
AU  - Van Bulck L
AUID- ORCID: 0000-0001-8975-4455
AD  - KU Leuven Department of Public Health and Primary Care, KU Leuven - University of 
      Leuven, Kapucijnenvoer 35 PB7001, 3000 Leuven, Belgium.
AD  - Research Foundation Flanders (FWO), Leuvenseweg 38, 1000 Brussels, Belgium.
FAU - Moons, Philip
AU  - Moons P
AUID- ORCID: 0000-0002-8609-4516
AD  - KU Leuven Department of Public Health and Primary Care, KU Leuven - University of 
      Leuven, Kapucijnenvoer 35 PB7001, 3000 Leuven, Belgium.
AD  - Institute of Health and Care Sciences, University of Gothenburg, Arvid Wallgrens 
      backe 1, 413 46 Gothenburg, Sweden.
AD  - Department of Paediatrics and Child Health, University of Cape Town, Klipfontein 
      Rd, Rondebosch, 7700 Cape Town, South Africa.
LA  - eng
GR  - 1159522N/Research Foundation Flanders/
PT  - Journal Article
PL  - England
TA  - Eur J Cardiovasc Nurs
JT  - European journal of cardiovascular nursing
JID - 101128793
SB  - IM
MH  - Humans
MH  - Artificial Intelligence
MH  - Search Engine
MH  - *Atrial Fibrillation
MH  - *Heart Failure
MH  - Patients
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Language models
OT  - Natural language processing
OT  - Nurses
OT  - Nursing
OT  - Patient information
OT  - Safety
OT  - ‌Chatbot
COIS- Conflict of interest: None declared.
EDAT- 2023/04/24 18:42
MHDA- 2024/01/15 12:42
CRDT- 2023/04/24 04:13
PHST- 2023/04/05 00:00 [received]
PHST- 2023/04/17 00:00 [revised]
PHST- 2023/04/20 00:00 [accepted]
PHST- 2024/01/15 12:42 [medline]
PHST- 2023/04/24 18:42 [pubmed]
PHST- 2023/04/24 04:13 [entrez]
AID - 7140165 [pii]
AID - 10.1093/eurjcn/zvad038 [doi]
PST - ppublish
SO  - Eur J Cardiovasc Nurs. 2024 Jan 12;23(1):95-98. doi: 10.1093/eurjcn/zvad038.

PMID- 37716431
OWN - NLM
STAT- MEDLINE
DCOM- 20240206
LR  - 20240206
IS  - 2468-6530 (Electronic)
IS  - 2468-6530 (Linking)
VI  - 8
IP  - 2
DP  - 2024 Feb
TI  - The Use of Large Language Models to Generate Education Materials about Uveitis.
PG  - 195-201
LID - S2468-6530(23)00449-9 [pii]
LID - 10.1016/j.oret.2023.09.008 [doi]
AB  - OBJECTIVE: To assess large language models in generating readable uveitis 
      information and in improving the readability of online health information. 
      DESIGN: Evaluation of technology. SUBJECTS: Not applicable. METHODS: ChatGPT and 
      Bard were asked the following prompts: (prompt A) "considering that the average 
      American reads at a 6th grade level, using the Flesch-Kincaid Grade Level (FKGL) 
      formula, can you write patient-targeted health information on uveitis of around 
      6th grade level?" and (prompt B) "can you write patient-targeted health 
      information on uveitis that is easy to understand by an average American?" 
      Additionally, ChatGPT and Bard were asked the following prompt from the 
      first-page results of Google when the term "uveitis" was searched: "Considering 
      that the average American reads at a 6th grade level, using the FKGL formula, can 
      you rewrite the following text to 6th grade level: [insert text]." The 
      readability of each response was analyzed and compared using several metrics 
      described below. MAIN OUTCOME MEASURES: The FKGL is a highly validated 
      readability assessment tool that assigns a grade level to a given text, the total 
      number of words, sentences, syllables, and complex words. Complex words were 
      defined as those with &gt; 2 syllables. RESULTS: ChatGPT and Bard generated 
      responses with lower FKGL scores (i.e., easier to understand) in response to 
      prompt A compared with prompt B. This was only significant for ChatGPT (P &lt; 
      0.0001). The mean FKGL of responses to ChatGPT (6.3 ± 1.2) was significantly 
      lower (P &lt; 0.0001) than Bard 10.5 ± 0.8. ChatGPT responses also contained less 
      complex words than Bard (P &lt; 0.0001). Online health information on uveitis had a 
      mean grade level of 11.0 ± 1.4. ChatGPT lowered the FKGL to 8.0 ± 1.0 (P &lt; 
      0.0001) when asked to rewrite the content. Bard was not able to do so (mean FKGL 
      of 11.1 ± 1.6). CONCLUSIONS: ChatGPT can aid clinicians in producing 
      easier-to-understand health information on uveitis for patients compared with 
      already-existing content. It can also help with reducing the difficulty of the 
      language used for uveitis health information targeted for patients. FINANCIAL 
      DISCLOSURE(S): Proprietary or commercial disclosure may be found in the Footnotes 
      and Disclosures at the end of this article.
CI  - Copyright © 2023 American Academy of Ophthalmology. Published by Elsevier Inc. 
      All rights reserved.
FAU - Kianian, Reza
AU  - Kianian R
AD  - Stein Eye Institute, Department of Ophthalmology, David Geffen School of 
      Medicine, University of California Los Angeles, Los Angeles, California.
FAU - Sun, Deyu
AU  - Sun D
AD  - Stein Eye Institute, Department of Ophthalmology, David Geffen School of 
      Medicine, University of California Los Angeles, Los Angeles, California.
FAU - Crowell, Eric L
AU  - Crowell EL
AD  - Mitchel and Shannon Wong Eye Institute, Dell Medical School at the University of 
      Texas at Austin, Austin, Texas.
FAU - Tsui, Edmund
AU  - Tsui E
AD  - Stein Eye Institute, Department of Ophthalmology, David Geffen School of 
      Medicine, University of California Los Angeles, Los Angeles, California. 
      Electronic address: ETsui@mednet.ucla.edu.
LA  - eng
PT  - Journal Article
DEP - 20230915
PL  - United States
TA  - Ophthalmol Retina
JT  - Ophthalmology. Retina
JID - 101695048
SB  - IM
MH  - Humans
MH  - United States
MH  - *Language
MH  - Comprehension
MH  - Reading
MH  - *Uveitis/diagnosis
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Bard
OT  - ChatGPT
OT  - Consumer health information
OT  - Readability
OT  - Uveitis
EDAT- 2023/09/17 00:41
MHDA- 2024/02/06 06:42
CRDT- 2023/09/16 19:13
PHST- 2023/07/16 00:00 [received]
PHST- 2023/09/08 00:00 [revised]
PHST- 2023/09/08 00:00 [accepted]
PHST- 2024/02/06 06:42 [medline]
PHST- 2023/09/17 00:41 [pubmed]
PHST- 2023/09/16 19:13 [entrez]
AID - S2468-6530(23)00449-9 [pii]
AID - 10.1016/j.oret.2023.09.008 [doi]
PST - ppublish
SO  - Ophthalmol Retina. 2024 Feb;8(2):195-201. doi: 10.1016/j.oret.2023.09.008. Epub 
      2023 Sep 15.

PMID- 37614494
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230825
IS  - 2473-974X (Electronic)
IS  - 2473-974X (Linking)
VI  - 7
IP  - 3
DP  - 2023 Jul-Sep
TI  - Diagnostic and Management Applications of ChatGPT in Structured Otolaryngology 
      Clinical Scenarios.
PG  - e67
LID - 10.1002/oto2.67 [doi]
LID - e67
AB  - OBJECTIVE: To evaluate the clinical applications and limitations of chat 
      generative pretrained transformer (ChatGPT) in otolaryngology. STUDY DESIGN: 
      Cross-sectional survey. SETTING: Tertiary academic center. METHODS: ChatGPT 4.0 
      was queried for diagnoses and management plans for 20 physician-written clinical 
      vignettes in otolaryngology. Attending physicians were then asked to rate the 
      difficulty of the clinical vignettes and agreement with the differential 
      diagnoses and management plans of ChatGPT responses on a 5-point Likert scale. 
      Summary statistics were calculated. Univariate ordinal regression was then 
      performed between vignette difficulty and quality of the diagnoses and management 
      plans. RESULTS: Eleven attending physicians completed the survey (61% response 
      rate). Overall, vignettes were rated as very easy to neutral difficulty (range of 
      median score: 1.00-4.00; overall median 2.00). There was a high agreement with 
      the differential diagnosis provided by ChatGPT (range of median score: 3.00-5.00; 
      overall median: 5.00). There was also high agreement with treatment plans (range 
      of median score: 3.00-5.00; overall median: 5.00). There was no association 
      between vignette difficulty and agreement with differential diagnosis or 
      treatment. Lower diagnosis scores had greater odds of having lower treatment 
      scores. CONCLUSION: Generative artificial intelligence models like ChatGPT are 
      being rapidly adopted in medicine. Performance with curated, easy-to-moderate 
      difficulty otolaryngology scenarios indicate high agreement with physicians for 
      diagnosis and management. However, a decreased quality in diagnosis is associated 
      with decreased quality in management. Further research is necessary on ChatGPT's 
      ability to handle unstructured clinical information.
CI  - © 2023 The Authors. OTO Open published by Wiley Periodicals LLC on behalf of 
      American Academy of Otolaryngology–Head and Neck Surgery Foundation.
FAU - Qu, Roy W
AU  - Qu RW
AUID- ORCID: 0000-0002-4689-819X
AD  - Department of Otolaryngology-Head and Neck Surgery Loma Linda University Medical 
      Center Loma Linda California USA.
FAU - Qureshi, Uneeb
AU  - Qureshi U
AUID- ORCID: 0000-0003-3185-0449
AD  - Department of Otolaryngology-Head and Neck Surgery Loma Linda University Medical 
      Center Loma Linda California USA.
FAU - Petersen, Garrett
AU  - Petersen G
AUID- ORCID: 0009-0004-5501-7114
AD  - Department of Otolaryngology-Head and Neck Surgery Loma Linda School of Medicine, 
      Loma Linda University Medical Center Loma Linda California USA.
FAU - Lee, Steve C
AU  - Lee SC
AUID- ORCID: 0000-0002-4460-4303
AD  - Department of Otolaryngology-Head and Neck Surgery Loma Linda University Medical 
      Center Loma Linda California USA.
LA  - eng
PT  - Journal Article
DEP - 20230822
PL  - United States
TA  - OTO Open
JT  - OTO open
JID - 101717942
PMC - PMC10442607
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - large language model
OT  - otolaryngology
COIS- The authors have no conflicts of interest to declare.
EDAT- 2023/08/24 06:42
MHDA- 2023/08/24 06:43
PMCR- 2023/08/22
CRDT- 2023/08/24 04:02
PHST- 2023/07/13 00:00 [received]
PHST- 2023/07/19 00:00 [accepted]
PHST- 2023/08/24 06:43 [medline]
PHST- 2023/08/24 06:42 [pubmed]
PHST- 2023/08/24 04:02 [entrez]
PHST- 2023/08/22 00:00 [pmc-release]
AID - OTO267 [pii]
AID - 10.1002/oto2.67 [doi]
PST - epublish
SO  - OTO Open. 2023 Aug 22;7(3):e67. doi: 10.1002/oto2.67. eCollection 2023 Jul-Sep.

PMID- 37247851
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20231004
LR  - 20231004
IS  - 1437-4331 (Electronic)
IS  - 1434-6621 (Linking)
VI  - 61
IP  - 11
DP  - 2023 Oct 26
TI  - ChatGPT, critical thing and ethical practice.
PG  - e221
LID - 10.1515/cclm-2023-0495 [doi]
FAU - Kleebayoon, Amnuay
AU  - Kleebayoon A
AUID- ORCID: 0000-0002-1976-2393
AD  - Private Academic Consultant, Samraong, Cambodia.
FAU - Wiwanitkit, Viroj
AU  - Wiwanitkit V
AD  - Chandigarh University, Ajitgarh, Punjab, India.
AD  - Joesph Ayobabalola University, Ikeji-Arakeji, Nigeria.
LA  - eng
PT  - Comment
PT  - Letter
DEP - 20230530
PL  - Germany
TA  - Clin Chem Lab Med
JT  - Clinical chemistry and laboratory medicine
JID - 9806306
SB  - IM
CON - Clin Chem Lab Med. 2023 Apr 25;61(7):1131-1132. PMID: 37092365
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - ethic
EDAT- 2023/05/30 01:06
MHDA- 2023/05/30 01:07
CRDT- 2023/05/29 20:13
PHST- 2023/05/12 00:00 [received]
PHST- 2023/05/15 00:00 [accepted]
PHST- 2023/05/30 01:07 [medline]
PHST- 2023/05/30 01:06 [pubmed]
PHST- 2023/05/29 20:13 [entrez]
AID - cclm-2023-0495 [pii]
AID - 10.1515/cclm-2023-0495 [doi]
PST - epublish
SO  - Clin Chem Lab Med. 2023 May 30;61(11):e221. doi: 10.1515/cclm-2023-0495. Print 
      2023 Oct 26.

PMID- 37509379
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230731
IS  - 2072-6694 (Print)
IS  - 2072-6694 (Electronic)
IS  - 2072-6694 (Linking)
VI  - 15
IP  - 14
DP  - 2023 Jul 22
TI  - Enhancing Triage Efficiency and Accuracy in Emergency Rooms for Patients with 
      Metastatic Prostate Cancer: A Retrospective Analysis of Artificial 
      Intelligence-Assisted Triage Using ChatGPT 4.0.
LID - 10.3390/cancers15143717 [doi]
LID - 3717
AB  - BACKGROUND: Accurate and efficient triage is crucial for prioritizing care and 
      managing resources in emergency rooms. This study investigates the effectiveness 
      of ChatGPT, an advanced artificial intelligence system, in assisting health 
      providers with decision-making for patients presenting with metastatic prostate 
      cancer, focusing on the potential to improve both patient outcomes and resource 
      allocation. METHODS: Clinical data from patients with metastatic prostate cancer 
      who presented to the emergency room between 1 May 2022 and 30 April 2023 were 
      retrospectively collected. The primary outcome was the sensitivity and 
      specificity of ChatGPT in determining whether a patient required admission or 
      discharge. The secondary outcomes included the agreement between ChatGPT and 
      emergency medicine physicians, the comprehensiveness of diagnoses, the accuracy 
      of treatment plans proposed by both parties, and the length of medical decision 
      making. RESULTS: Of the 147 patients screened, 56 met the inclusion criteria. 
      ChatGPT had a sensitivity of 95.7% in determining admission and a specificity of 
      18.2% in discharging patients. In 87.5% of cases, ChatGPT made the same primary 
      diagnoses as physicians, with more accurate terminology use (42.9% vs. 21.4%, p = 
      0.02) and more comprehensive diagnostic lists (median number of diagnoses: 3 vs. 
      2, p &lt; 0.001). Emergency Severity Index scores calculated by ChatGPT were not 
      associated with admission (p = 0.12), hospital stay length (p = 0.91) or ICU 
      admission (p = 0.54). Despite shorter mean word count (169 ± 66 vs. 272 ± 105, p 
      &lt; 0.001), ChatGPT was more likely to give additional treatment recommendations 
      than physicians (94.3% vs. 73.5%, p &lt; 0.001). CONCLUSIONS: Our 
      hypothesis-generating data demonstrated that ChatGPT is associated with a high 
      sensitivity in determining the admission of patients with metastatic prostate 
      cancer in the emergency room. It also provides accurate and comprehensive 
      diagnoses. These findings suggest that ChatGPT has the potential to assist health 
      providers in improving patient triage in emergency settings, and may enhance both 
      efficiency and quality of care provided by the physicians.
FAU - Gebrael, Georges
AU  - Gebrael G
AUID- ORCID: 0000-0002-4085-6415
AD  - Department of Oncology, Huntsman Cancer Institute, University of Utah, Salt Lake 
      City, UT 84112, USA.
FAU - Sahu, Kamal Kant
AU  - Sahu KK
AUID- ORCID: 0000-0002-0382-6882
AD  - Department of Oncology, Huntsman Cancer Institute, University of Utah, Salt Lake 
      City, UT 84112, USA.
FAU - Chigarira, Beverly
AU  - Chigarira B
AD  - Department of Oncology, Huntsman Cancer Institute, University of Utah, Salt Lake 
      City, UT 84112, USA.
FAU - Tripathi, Nishita
AU  - Tripathi N
AD  - Department of Oncology, Huntsman Cancer Institute, University of Utah, Salt Lake 
      City, UT 84112, USA.
FAU - Mathew Thomas, Vinay
AU  - Mathew Thomas V
AD  - Department of Oncology, Huntsman Cancer Institute, University of Utah, Salt Lake 
      City, UT 84112, USA.
FAU - Sayegh, Nicolas
AU  - Sayegh N
AUID- ORCID: 0000-0003-1924-8148
AD  - Department of Oncology, Huntsman Cancer Institute, University of Utah, Salt Lake 
      City, UT 84112, USA.
FAU - Maughan, Benjamin L
AU  - Maughan BL
AD  - Department of Oncology, Huntsman Cancer Institute, University of Utah, Salt Lake 
      City, UT 84112, USA.
FAU - Agarwal, Neeraj
AU  - Agarwal N
AUID- ORCID: 0000-0003-1076-0428
AD  - Department of Oncology, Huntsman Cancer Institute, University of Utah, Salt Lake 
      City, UT 84112, USA.
FAU - Swami, Umang
AU  - Swami U
AUID- ORCID: 0000-0003-3518-0411
AD  - Department of Oncology, Huntsman Cancer Institute, University of Utah, Salt Lake 
      City, UT 84112, USA.
FAU - Li, Haoran
AU  - Li H
AD  - Division of Medical Oncology, University of Kansas Cancer Center, Westwood, KS 
      66205, USA.
LA  - eng
PT  - Journal Article
DEP - 20230722
PL  - Switzerland
TA  - Cancers (Basel)
JT  - Cancers
JID - 101526829
PMC - PMC10378202
OTO - NOTNLM
OT  - ChatGPT 4.0
OT  - artificial intelligence
OT  - emergency room
OT  - medical decision-making
OT  - metastatic prostate cancer
OT  - triage
COIS- Neeraj Agarwal (lifetime): consultancy to Astellas, AstraZeneca, Aveo, Bayer, 
      Bristol Myers Squibb, Calithera, Clovis, Eisai, Eli Lilly, EMD Serono, Exelixis, 
      Foundation Medicine, Genentech, Gilead, Janssen, Merck, MEI Pharma, Nektar, 
      Novartis, Pfizer, Pharmacyclics, and Seattle Genetics outside the submitted work. 
      Research funding to Neeraj Agarwal’s institution: Astellas, Astra Zeneca, 
      Bavarian Nordic, Bayer, Bristol Myers Squibb, Calithera, Celldex, Clovis, Eisai, 
      Eli Lilly, EMD Serono, Exelixis, Genentech, Gilead, Glaxo Smith Kline, 
      Immunomedics, Janssen, Medivation, Merck, Nektar, New Link Genetics, Novartis, 
      Pfizer, Prometheus, Rexahn, Roche, Sanofi, Seattle Genetics, Takeda, and Tracon. 
      Umang Swami: consultancy to Astellas, Exelixis, Seattle Genetics, Imvax, Sanofi, 
      AstraZeneca and Gilead and research funding to institute from Janssen, Exelixis 
      and Astellas/Seattle Genetics. Benjamin Maughan: Consultancy to Abbive, Pfizer, 
      AVEO oncology, Janssen, Astellas, Bristol-Myers Squibb, Clovis, Tempus, Merck, 
      Exelixis, Bayer Oncology, Lilly, Sanofi, Telix and Peloton Therapeutics and 
      research funding to institute from Exelixis, Bavarian-Nordic, Clovis and 
      Bristol-Myers Squibb. The rest of authors declare no conflict of interest.
EDAT- 2023/07/29 11:44
MHDA- 2023/07/29 11:45
PMCR- 2023/07/22
CRDT- 2023/07/29 01:11
PHST- 2023/06/27 00:00 [received]
PHST- 2023/07/19 00:00 [revised]
PHST- 2023/07/20 00:00 [accepted]
PHST- 2023/07/29 11:45 [medline]
PHST- 2023/07/29 11:44 [pubmed]
PHST- 2023/07/29 01:11 [entrez]
PHST- 2023/07/22 00:00 [pmc-release]
AID - cancers15143717 [pii]
AID - cancers-15-03717 [pii]
AID - 10.3390/cancers15143717 [doi]
PST - epublish
SO  - Cancers (Basel). 2023 Jul 22;15(14):3717. doi: 10.3390/cancers15143717.

PMID- 37736448
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230923
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 8
DP  - 2023 Aug
TI  - Large Language Models in Hematology Case Solving: A Comparative Study of 
      ChatGPT-3.5, Google Bard, and Microsoft Bing.
PG  - e43861
LID - 10.7759/cureus.43861 [doi]
LID - e43861
AB  - Background Large language models (LLMs), such as ChatGPT-3.5, Google Bard, and 
      Microsoft Bing, have shown promising capabilities in various natural language 
      processing (NLP) tasks. However, their performance and accuracy in solving 
      domain-specific questions, particularly in the field of hematology, have not been 
      extensively investigated. Objective This study aimed to explore the capability of 
      LLMs, namely, ChatGPT-3.5, Google Bard, and Microsoft Bing (Precise), in solving 
      hematology-related cases and comparing their performance. Methods This was a 
      cross-sectional study conducted in the Department of Physiology and Pathology, 
      All India Institute of Medical Sciences, Deoghar, Jharkhand, India. We curated a 
      set of 50 cases on hematology covering a range of topics and complexities. The 
      dataset included queries related to blood disorders, hematologic malignancies, 
      laboratory test parameters, calculations, and treatment options. Each case and 
      related question was prepared with a set of correct answers to compare with. We 
      utilized ChatGPT-3.5, Google Bard Experiment, and Microsoft Bing (Precise) for 
      question-answering tasks. The answers were checked by two physiologists and one 
      pathologist. They rated the answers on a rating scale from one to five. The 
      average score of the three models was compared by Friedman's test with Dunn's 
      post-hoc test. The performance of the LLMs was compared with a median of 2.5 by a 
      one-sample median test as the curriculum from which the questions were curated 
      has a 50% pass grade. Results The scores among the three LLMs were significantly 
      different (p-value &lt; 0.0001) with the highest score by ChatGPT (3.15±1.19), 
      followed by Bard (2.23±1.17)&nbsp;and Bing (1.98±1.01). The score of ChatGPT was 
      significantly higher than 50% (p-value = 0.0004), Bard's score was close to 50% 
      (p-value = 0.38), and Bing's score was significantly lower than the pass score 
      (p-value = 0.0015). Conclusion The LLMs reveal significant differences in solving 
      case vignettes in hematology. ChatGPT exhibited the highest score, followed by 
      Google Bard and Microsoft Bing. The observed performance trends suggest that 
      ChatGPT holds promising potential in the medical domain. However, none of the 
      models was capable of answering all questions accurately. Further research and 
      optimization of language models can offer valuable contributions to healthcare 
      and medical education applications.
CI  - Copyright © 2023, Kumari et al.
FAU - Kumari, Amita
AU  - Kumari A
AD  - Physiology, All India Institute of Medical Sciences, Deoghar, Deoghar, IND.
FAU - Kumari, Anita
AU  - Kumari A
AD  - Physiology, All India Institute of Medical Sciences, Deoghar, Deoghar, IND.
FAU - Singh, Amita
AU  - Singh A
AD  - Physiology, All India Institute of Medical Sciences, Deoghar, Deoghar, IND.
FAU - Singh, Sanjeet K
AU  - Singh SK
AD  - Pathology, All India Institute of Medical Sciences, Deoghar, Deoghar, IND.
FAU - Juhi, Ayesha
AU  - Juhi A
AD  - Physiology, All India Institute of Medical Sciences, Deoghar, Deoghar, IND.
FAU - Dhanvijay, Anup Kumar D
AU  - Dhanvijay AKD
AD  - Physiology, All India Institute of Medical Sciences, Deoghar, Deoghar, IND.
FAU - Pinjar, Mohammed Jaffer
AU  - Pinjar MJ
AD  - Physiology, All India Institute of Medical Sciences, Deoghar, Deoghar, IND.
FAU - Mondal, Himel
AU  - Mondal H
AD  - Physiology, All India Institute of Medical Sciences, Deoghar, Deoghar, IND.
LA  - eng
PT  - Journal Article
DEP - 20230821
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10511207
OTO - NOTNLM
OT  - ai and robotics in healthcare
OT  - chatgpt
OT  - google bard
OT  - hematologic diseases
OT  - hematology
OT  - microsoft bing
OT  - natural language processing
OT  - pathologists
OT  - pathology
OT  - search engine
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/09/22 06:42
MHDA- 2023/09/22 06:43
PMCR- 2023/08/21
CRDT- 2023/09/22 03:46
PHST- 2023/08/21 00:00 [accepted]
PHST- 2023/09/22 06:43 [medline]
PHST- 2023/09/22 06:42 [pubmed]
PHST- 2023/09/22 03:46 [entrez]
PHST- 2023/08/21 00:00 [pmc-release]
AID - 10.7759/cureus.43861 [doi]
PST - epublish
SO  - Cureus. 2023 Aug 21;15(8):e43861. doi: 10.7759/cureus.43861. eCollection 2023 
      Aug.

PMID- 37671207
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230907
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 8
DP  - 2023 Aug
TI  - Performance of Large Language Models (ChatGPT, Bing Search, and Google Bard) in 
      Solving Case Vignettes in Physiology.
PG  - e42972
LID - 10.7759/cureus.42972 [doi]
LID - e42972
AB  - Background Large language models (LLMs) have emerged as powerful tools capable of 
      processing and generating human-like text. These LLMs, such as ChatGPT (OpenAI 
      Incorporated, Mission District, San Francisco, United States), Google Bard 
      (Alphabet Inc., CA, US),&nbsp;and Microsoft Bing (Microsoft Corporation, WA, US), have 
      been applied across various domains, demonstrating their potential to assist in 
      solving complex tasks and improving information accessibility. However, their 
      application in solving case&nbsp;vignettes in physiology has not been explored. This 
      study aimed to assess the performance of three LLMs, namely, ChatGPT (3.5; free 
      research version), Google Bard (Experiment), and Microsoft Bing (precise), in 
      answering cases vignettes in Physiology. Methods This cross-sectional study was 
      conducted in July 2023. A total of 77 case vignettes in physiology were prepared 
      by two physiologists and were validated by two other content experts. These cases 
      were presented to each LLM, and their responses were collected. Two physiologists 
      independently rated the answers provided by the LLMs based on their accuracy. The 
      ratings were measured on a scale from 0 to 4 according to the structure of the 
      observed learning outcome (pre-structural = 0, uni-structural = 1, 
      multi-structural = 2, relational = 3, extended-abstract). The scores among the 
      LLMs were compared by Friedman's test and inter-observer agreement was checked by 
      the intraclass correlation coefficient (ICC). Results The overall scores for 
      ChatGPT, Bing, and Bard in the study, with a total of 77 cases, were found to be 
      3.19±0.3, 2.15±0.6, and 2.91±0.5, respectively, p&lt;0.0001. Hence, ChatGPT 3.5 
      (free version) obtained the highest score, Bing (Precise) had the lowest score, 
      and Bard (Experiment) fell in between the two in terms of performance. The 
      average ICC values for ChatGPT, Bing, and Bard were 0.858 (95% CI: 0.777 to 0.91, 
      p&lt;0.0001), 0.975 (95% CI: 0.961 to 0.984, p&lt;0.0001), and 0.964 (95% CI: 0.944 to 
      0.977, p&lt;0.0001), respectively. Conclusion ChatGPT outperformed Bard and Bing in 
      answering case vignettes in physiology. Hence, students and teachers may think 
      about choosing LLMs for their educational purposes accordingly for case-based 
      learning in physiology. Further exploration of their capabilities is needed for 
      adopting those in medical education and support for clinical decision-making.
CI  - Copyright © 2023, Dhanvijay et al.
FAU - Dhanvijay, Anup Kumar D
AU  - Dhanvijay AKD
AD  - Physiology, All India Institute of Medical Sciences, Deoghar, Deoghar, IND.
FAU - Pinjar, Mohammed Jaffer
AU  - Pinjar MJ
AD  - Physiology, All India Institute of Medical Sciences, Deoghar, Deoghar, IND.
FAU - Dhokane, Nitin
AU  - Dhokane N
AD  - Physiology, Government Medical College, Sindhudurg, Oros, IND.
FAU - Sorte, Smita R
AU  - Sorte SR
AD  - Physiology, All India Institute of Medical Sciences, Nagpur, Nagpur, IND.
FAU - Kumari, Amita
AU  - Kumari A
AD  - Physiology, All India Institute of Medical Sciences, Deoghar, Deoghar, IND.
FAU - Mondal, Himel
AU  - Mondal H
AD  - Physiology, All India Institute of Medical Sciences, Deoghar, Deoghar, IND.
LA  - eng
PT  - Journal Article
DEP - 20230804
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10475852
OTO - NOTNLM
OT  - artificial intelligence
OT  - bard
OT  - bing
OT  - case vignette
OT  - chatgpt
OT  - language model
OT  - medical education
OT  - physiology
OT  - problem-based learning
OT  - self-directed learning (sdl)
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/09/06 06:42
MHDA- 2023/09/06 06:43
PMCR- 2023/08/04
CRDT- 2023/09/06 03:55
PHST- 2023/08/04 00:00 [accepted]
PHST- 2023/09/06 06:43 [medline]
PHST- 2023/09/06 06:42 [pubmed]
PHST- 2023/09/06 03:55 [entrez]
PHST- 2023/08/04 00:00 [pmc-release]
AID - 10.7759/cureus.42972 [doi]
PST - epublish
SO  - Cureus. 2023 Aug 4;15(8):e42972. doi: 10.7759/cureus.42972. eCollection 2023 Aug.

PMID- 37368470
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230714
IS  - 2562-7600 (Electronic)
IS  - 2562-7600 (Linking)
VI  - 6
DP  - 2023 Jun 27
TI  - Performance of the Large Language Model ChatGPT on the National Nurse 
      Examinations in Japan: Evaluation Study.
PG  - e47305
LID - 10.2196/47305 [doi]
LID - e47305
AB  - BACKGROUND: ChatGPT, a large language model, has shown good performance on 
      physician certification examinations and medical consultations. However, its 
      performance has not been examined in languages other than English or on nursing 
      examinations. OBJECTIVE: We aimed to evaluate the performance of ChatGPT on the 
      Japanese National Nurse Examinations. METHODS: We evaluated the percentages of 
      correct answers provided by ChatGPT (GPT-3.5) for all questions on the Japanese 
      National Nurse Examinations from 2019 to 2023, excluding inappropriate questions 
      and those containing images. Inappropriate questions were pointed out by a 
      third-party organization and announced by the government to be excluded from 
      scoring. Specifically, these include "questions with inappropriate question 
      difficulty" and "questions with errors in the questions or choices." These 
      examinations consist of 240 questions each year, divided into basic knowledge 
      questions that test the basic issues of particular importance to nurses and 
      general questions that test a wide range of specialized knowledge. Furthermore, 
      the questions had 2 types of formats: simple-choice and situation-setup 
      questions. Simple-choice questions are primarily knowledge-based and 
      multiple-choice, whereas situation-setup questions entail the candidate reading a 
      patient's and family situation's description, and selecting the nurse's action or 
      patient's response. Hence, the questions were standardized using 2 types of 
      prompts before requesting answers from ChatGPT. Chi-square tests were conducted 
      to compare the percentage of correct answers for each year's examination format 
      and specialty area related to the question. In addition, a Cochran-Armitage trend 
      test was performed with the percentage of correct answers from 2019 to 2023. 
      RESULTS: The 5-year average percentage of correct answers for ChatGPT was 75.1% 
      (SD 3%) for basic knowledge questions and 64.5% (SD 5%) for general questions. 
      The highest percentage of correct answers on the 2019 examination was 80% for 
      basic knowledge questions and 71.2% for general questions. ChatGPT met the 
      passing criteria for the 2019 Japanese National Nurse Examination and was close 
      to passing the 2020-2023 examinations, with only a few more correct answers 
      required to pass. ChatGPT had a lower percentage of correct answers in some 
      areas, such as pharmacology, social welfare, related law and regulations, 
      endocrinology/metabolism, and dermatology, and a higher percentage of correct 
      answers in the areas of nutrition, pathology, hematology, ophthalmology, 
      otolaryngology, dentistry and dental surgery, and nursing integration and 
      practice. CONCLUSIONS: ChatGPT only passed the 2019 Japanese National Nursing 
      Examination during the most recent 5 years. Although it did not pass the 
      examinations from other years, it performed very close to the passing level, even 
      in those containing questions related to psychology, communication, and nursing.
CI  - ©Kazuya Taira, Takahiro Itaya, Ayame Hanada. Originally published in JMIR Nursing 
      (https://nursing.jmir.org), 27.06.2023.
FAU - Taira, Kazuya
AU  - Taira K
AUID- ORCID: 0000-0002-1560-5454
AD  - Department of Human Health Sciences, Graduate School of Medicine, Kyoto 
      University, Kyoto, Japan.
FAU - Itaya, Takahiro
AU  - Itaya T
AUID- ORCID: 0000-0002-0560-8686
AD  - Department of Healthcare Epidemiology, Graduate School of Medicine and Public 
      Health, Kyoto University, Kyoto, Japan.
AD  - Department of Preventive Medicine and Public Health, School of Medicine, Keio 
      University, Tokyo, Japan.
FAU - Hanada, Ayame
AU  - Hanada A
AUID- ORCID: 0009-0002-1621-214X
AD  - Department of Human Health Sciences, Graduate School of Medicine, Kyoto 
      University, Kyoto, Japan.
LA  - eng
PT  - Journal Article
DEP - 20230627
PL  - Canada
TA  - JMIR Nurs
JT  - JMIR nursing
JID - 101771299
PMC - PMC10337249
OTO - NOTNLM
OT  - ChatGPT
OT  - Japan
OT  - National Nurse Examination
OT  - artificial intelligence
OT  - natural language processing
OT  - registered nurses
COIS- Conflicts of Interest: None declared.
EDAT- 2023/06/27 13:11
MHDA- 2023/06/27 13:12
PMCR- 2023/06/27
CRDT- 2023/06/27 11:53
PHST- 2023/03/20 00:00 [received]
PHST- 2023/05/27 00:00 [accepted]
PHST- 2023/05/20 00:00 [revised]
PHST- 2023/06/27 13:12 [medline]
PHST- 2023/06/27 13:11 [pubmed]
PHST- 2023/06/27 11:53 [entrez]
PHST- 2023/06/27 00:00 [pmc-release]
AID - v6i1e47305 [pii]
AID - 10.2196/47305 [doi]
PST - epublish
SO  - JMIR Nurs. 2023 Jun 27;6:e47305. doi: 10.2196/47305.

PMID- 37071280
OWN - NLM
STAT- MEDLINE
DCOM- 20230615
LR  - 20230615
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 51
IP  - 7
DP  - 2023 Jul
TI  - Will ChatGPT/GPT-4 be a Lighthouse to Guide Spinal Surgeons?
PG  - 1362-1365
LID - 10.1007/s10439-023-03206-0 [doi]
AB  - The advent of artificial intelligence (AI), particularly ChatGPT/GPT-4, has led 
      to advancements in various fields, including healthcare. This study explores the 
      prospective role of ChatGPT/GPT-4 in various facets of spinal surgical practice, 
      especially in supporting spinal surgeons during the perioperative management of 
      endoscopic spinal surgery for patients with lumbar disc herniation. The AI-driven 
      chatbot can facilitate communication between spinal surgeons, patients, and their 
      relatives, streamline the collection and analysis of patient data, and contribute 
      to the surgical planning process. Furthermore, ChatGPT/GPT-4 may enhance 
      intraoperative support by providing real-time surgical navigation information and 
      physiological parameter monitoring, as well as aiding in postoperative 
      rehabilitation guidance. However, the appropriate and supervised use of 
      ChatGPT/GPT-4 is essential, considering the potential risks associated with data 
      security and privacy. The study concludes that ChatGPT/GPT-4 can serve as a 
      valuable lighthouse for spinal surgeons if used correctly and responsibly.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - He, Yongbin
AU  - He Y
AD  - School of Sport Medicine and Rehabilitation, Beijing Sport University, Beijing, 
      China.
FAU - Tang, Haifeng
AU  - Tang H
AD  - School of Sport Medicine and Rehabilitation, Beijing Sport University, Beijing, 
      China.
FAU - Wang, Dongxue
AU  - Wang D
AD  - School of Sport Medicine and Rehabilitation, Beijing Sport University, Beijing, 
      China.
FAU - Gu, Shuqin
AU  - Gu S
AD  - Duke Human Vaccine Institute, Duke University Medical Center, Durham, NC, USA.
FAU - Ni, Guoxin
AU  - Ni G
AD  - Department of Rehabilitation Medicine, The First Affiliated Hospital of Xiamen 
      University, Xiamen, China. nigx@xmu.edu.cn.
FAU - Wu, Haiyang
AU  - Wu H
AD  - Department of Spine Surgery, Tianjin Huanhu Hospital, Graduate School of Tianjin 
      Medical University, Tianjin, China. wuhaiyang2021@tmu.edu.cn.
AD  - Duke Molecular Physiology Institute, Duke University School of Medicine, Durham, 
      NC, USA. wuhaiyang2021@tmu.edu.cn.
LA  - eng
GR  - 81871848/National Natural Science Foundation of China Project/
PT  - Letter
DEP - 20230418
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - Humans
MH  - Artificial Intelligence
MH  - *Surgeons
MH  - Neurosurgical Procedures
MH  - Software
MH  - *Surgery, Computer-Assisted
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Assistant
OT  - Endoscopic spinal surgery
OT  - GPT-4
OT  - Spinal surgeon
EDAT- 2023/04/19 06:00
MHDA- 2023/06/15 06:42
CRDT- 2023/04/18 11:23
PHST- 2023/04/10 00:00 [received]
PHST- 2023/04/11 00:00 [accepted]
PHST- 2023/06/15 06:42 [medline]
PHST- 2023/04/19 06:00 [pubmed]
PHST- 2023/04/18 11:23 [entrez]
AID - 10.1007/s10439-023-03206-0 [pii]
AID - 10.1007/s10439-023-03206-0 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2023 Jul;51(7):1362-1365. doi: 10.1007/s10439-023-03206-0. Epub 
      2023 Apr 18.

PMID- 38364879
OWN - NLM
STAT- Publisher
LR  - 20240322
IS  - 1532-8406 (Electronic)
IS  - 0883-5403 (Linking)
DP  - 2024 Feb 14
TI  - Assessing Ability for ChatGPT to Answer Total Knee Arthroplasty-Related 
      Questions.
LID - S0883-5403(24)00122-0 [pii]
LID - 10.1016/j.arth.2024.02.023 [doi]
AB  - BACKGROUND: Artificial intelligence in the field of orthopaedics has been a topic 
      of increasing interest and opportunity in recent years. Its applications are 
      widespread both for physicians and patients, including use in clinical 
      decision-making, in the operating room, and in research. In this study, we aimed 
      to assess the quality of ChatGPT answers when asked questions related to total 
      knee arthroplasty. METHODS: ChatGPT prompts were created by turning 15 of the 
      American Academy of Orthopaedic Surgeons Clinical Practice Guidelines into 
      questions. An online survey was created, which included screenshots of each 
      prompt and answers to the 15 questions. Surgeons were asked to grade ChatGPT 
      answers from 1 to 5 based on their characteristics: (1) relevance, (2) accuracy, 
      (3) clarity, (4) completeness, (5) evidence-based, and (6) consistency. There 
      were 11 Adult Joint Reconstruction fellowship-trained surgeons who completed the 
      survey. Questions were subclassified based on the subject of the prompt: (1) risk 
      factors, (2) implant/intraoperative, and (3) pain/functional outcomes. The 
      average and standard deviation for all answers, as well as for each subgroup, 
      were calculated. Inter-rater reliability (IRR) was also calculated. RESULTS: All 
      answer characteristics were graded as being above average (ie, a score &gt; 3). 
      Relevance demonstrated the highest scores (4.43 ± 0.77) by surgeons surveyed, and 
      consistency demonstrated the lowest scores (3.54 ± 1.10). ChatGPT prompts in the 
      Risk Factors group demonstrated the best responses, while those in the 
      Pain/Functional Outcome group demonstrated the lowest. The overall IRR was found 
      to be 0.33 (poor reliability), with the highest IRR for relevance (0.43) and the 
      lowest for evidence-based (0.28). CONCLUSIONS: ChatGPT can answer questions 
      regarding well-established clinical guidelines in total knee arthroplasty with 
      above-average accuracy but demonstrates variable reliability. This investigation 
      is the first step in understanding large language model artificial intelligence 
      like ChatGPT and how well they perform in the field of arthroplasty.
CI  - Copyright © 2024 Elsevier Inc. All rights reserved.
FAU - Magruder, Matthew L
AU  - Magruder ML
AD  - Department of Orthopaedic Surgery, Maimonides Medical Center, Brooklyn, New York.
FAU - Rodriguez, Ariel N
AU  - Rodriguez AN
AD  - Department of Orthopaedic Surgery, Maimonides Medical Center, Brooklyn, New York.
FAU - Wong, Jason C J
AU  - Wong JCJ
AD  - Department of Orthopaedic Surgery, Maimonides Medical Center, Brooklyn, New York.
FAU - Erez, Orry
AU  - Erez O
AD  - Department of Orthopaedic Surgery, Maimonides Medical Center, Brooklyn, New York.
FAU - Piuzzi, Nicolas S
AU  - Piuzzi NS
AD  - Department of Orthopaedic Surgery, Cleveland Clinic, Cleveland, Ohio.
FAU - Scuderi, Gil R
AU  - Scuderi GR
AD  - Department of Orthopaedic Surgery, Lenox Hill Hospital, Northwell Orthopaedic 
      Institute, New York, New York.
FAU - Slover, James D
AU  - Slover JD
AD  - Department of Orthopaedic Surgery, Lenox Hill Hospital, Northwell Orthopaedic 
      Institute, New York, New York.
FAU - Oh, Jason H
AU  - Oh JH
AD  - Department of Orthopaedic Surgery, Lenox Hill Hospital, Northwell Orthopaedic 
      Institute, New York, New York.
FAU - Schwarzkopf, Ran
AU  - Schwarzkopf R
AD  - Department of Orthopaedic Surgery, NYU Langone Orthopedics, NYU Langone Health, 
      New York, New York.
FAU - Chen, Antonia F
AU  - Chen AF
AD  - Department of Orthopaedic Surgery, Brigham and Women's Hospital, Boston, 
      Massachusetts.
FAU - Iorio, Richard
AU  - Iorio R
AD  - Department of Orthopaedic Surgery, Brigham and Women's Hospital, Boston, 
      Massachusetts.
FAU - Goodman, Stuart B
AU  - Goodman SB
AD  - Department of Orthopaedic Surgery, Stanford University School of Medicine, 
      Redwood City, California.
FAU - Mont, Michael A
AU  - Mont MA
AD  - Rubin Institute for Advanced Orthopedics, Sinai Hospital of Baltimore, Baltimore, 
      Maryland.
LA  - eng
PT  - Journal Article
DEP - 20240214
PL  - United States
TA  - J Arthroplasty
JT  - The Journal of arthroplasty
JID - 8703515
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - clinical practice guidelines
OT  - large language model
OT  - total knee arthroplasty
EDAT- 2024/02/17 10:42
MHDA- 2024/02/17 10:42
CRDT- 2024/02/16 19:13
PHST- 2023/12/09 00:00 [received]
PHST- 2024/01/19 00:00 [revised]
PHST- 2024/02/08 00:00 [accepted]
PHST- 2024/02/17 10:42 [pubmed]
PHST- 2024/02/17 10:42 [medline]
PHST- 2024/02/16 19:13 [entrez]
AID - S0883-5403(24)00122-0 [pii]
AID - 10.1016/j.arth.2024.02.023 [doi]
PST - aheadofprint
SO  - J Arthroplasty. 2024 Feb 14:S0883-5403(24)00122-0. doi: 
      10.1016/j.arth.2024.02.023.

PMID- 37309705
OWN - NLM
STAT- MEDLINE
DCOM- 20240304
LR  - 20240304
IS  - 1555-9823 (Electronic)
IS  - 0003-1348 (Linking)
VI  - 90
IP  - 4
DP  - 2024 Apr
TI  - The Utilization of ChatGPT in Reshaping Future Medical Education and Learning 
      Perspectives: A Curse or a Blessing?
PG  - 560-566
LID - 10.1177/00031348231180950 [doi]
AB  - BACKGROUND: ChatGPT has substantial potential to revolutionize medical education. 
      We aim to assess how medical students and laypeople evaluate information produced 
      by ChatGPT compared to an evidence-based resource on the diagnosis and management 
      of 5 common surgical conditions. METHODS: A 60-question anonymous online survey 
      was distributed to third- and fourth-year U.S. medical students and laypeople to 
      evaluate articles produced by ChatGPT and an evidence-based source on clarity, 
      relevance, reliability, validity, organization, and comprehensiveness. 
      Participants received 2 blinded articles, 1 from each source, for each surgical 
      condition. Paired-sample t-tests were used to compare ratings between the 2 
      sources. RESULTS: Of 56 survey participants, 50.9% (n = 28) were U.S. medical 
      students and 49.1% (n = 27) were from the general population. Medical students 
      reported that ChatGPT articles displayed significantly more clarity 
      (appendicitis: 4.39 vs 3.89, P = .020; diverticulitis: 4.54 vs 3.68, P &lt; .001; 
      SBO 4.43 vs 3.79, P = .003; GI bleed: 4.36 vs 3.93, P = .020) and better 
      organization (diverticulitis: 4.36 vs 3.68, P = .021; SBO: 4.39 vs 3.82, P = 
      .033) than the evidence-based source. However, for all 5 conditions, medical 
      students found evidence-based passages to be more comprehensive than ChatGPT 
      articles (cholecystitis: 4.04 vs 3.36, P = .009; appendicitis: 4.07 vs 3.36, P = 
      .015; diverticulitis: 4.07 vs 3.36, P = .015; small bowel obstruction: 4.11 vs 
      3.54, P = .030; upper GI bleed: 4.11 vs 3.29, P = .003). CONCLUSION: Medical 
      students perceived ChatGPT articles to be clearer and better organized than 
      evidence-based sources on the pathogenesis, diagnosis, and management of 5 common 
      surgical pathologies. However, evidence-based articles were rated as 
      significantly more comprehensive.
FAU - Breeding, Tessa
AU  - Breeding T
AD  - Kiran Patel College of Allopathic Medicine, NOVA Southeastern University, Fort 
      Lauderdale, FL, USA. RINGGOLD: 2814
FAU - Martinez, Brian
AU  - Martinez B
AD  - Kiran Patel College of Allopathic Medicine, NOVA Southeastern University, Fort 
      Lauderdale, FL, USA. RINGGOLD: 2814
FAU - Patel, Heli
AU  - Patel H
AD  - Kiran Patel College of Allopathic Medicine, NOVA Southeastern University, Fort 
      Lauderdale, FL, USA. RINGGOLD: 2814
FAU - Nasef, Hazem
AU  - Nasef H
AD  - Kiran Patel College of Allopathic Medicine, NOVA Southeastern University, Fort 
      Lauderdale, FL, USA. RINGGOLD: 2814
FAU - Arif, Hasan
AU  - Arif H
AD  - Kiran Patel College of Allopathic Medicine, NOVA Southeastern University, Fort 
      Lauderdale, FL, USA. RINGGOLD: 2814
FAU - Nakayama, Don
AU  - Nakayama D
AD  - Mercer University School of Medicine, Columbus, GA, USA.
AD  - Department of Pediatric Surgery, Piedmont Columbus Regional Hospital, Piedmont, 
      GA, USA. RINGGOLD: 602096
FAU - Elkbuli, Adel
AU  - Elkbuli A
AD  - Department of Surgery, Division of Trauma and Surgical Critical Care, Orlando 
      Regional Medical Center, Orlando, FL, USA. RINGGOLD: 25105
AD  - Department of Surgical Education, Orlando Regional Medical Center, Orlando, FL, 
      USA. RINGGOLD: 25105
LA  - eng
PT  - Journal Article
DEP - 20230613
PL  - United States
TA  - Am Surg
JT  - The American surgeon
JID - 0370522
SB  - IM
MH  - Humans
MH  - *Appendicitis
MH  - Reproducibility of Results
MH  - *Cholecystitis
MH  - *Diverticulitis
MH  - *Education, Medical
OTO - NOTNLM
OT  - ChatGPT
OT  - common surgical conditions
OT  - laypeople
OT  - medical education
OT  - medical students
COIS- Declaration of Conflicting InterestsThe author(s) declared no potential conflicts 
      of interest with respect to the research, authorship, and/or publication of this 
      article.
EDAT- 2023/06/13 06:42
MHDA- 2024/03/04 06:43
CRDT- 2023/06/13 05:27
PHST- 2024/03/04 06:43 [medline]
PHST- 2023/06/13 06:42 [pubmed]
PHST- 2023/06/13 05:27 [entrez]
AID - 10.1177/00031348231180950 [doi]
PST - ppublish
SO  - Am Surg. 2024 Apr;90(4):560-566. doi: 10.1177/00031348231180950. Epub 2023 Jun 
      13.

PMID- 37389908
OWN - NLM
STAT- MEDLINE
DCOM- 20230703
LR  - 20231122
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 25
DP  - 2023 Jun 30
TI  - Reliability of Medical Information Provided by ChatGPT: Assessment Against 
      Clinical Guidelines and Patient Information Quality Instrument.
PG  - e47479
LID - 10.2196/47479 [doi]
LID - e47479
AB  - BACKGROUND: ChatGPT-4 is the latest release of a novel artificial intelligence 
      (AI) chatbot able to answer freely formulated and complex questions. In the near 
      future, ChatGPT could become the new standard for health care professionals and 
      patients to access medical information. However, little is known about the 
      quality of medical information provided by the AI. OBJECTIVE: We aimed to assess 
      the reliability of medical information provided by ChatGPT. METHODS: Medical 
      information provided by ChatGPT-4 on the 5 hepato-pancreatico-biliary (HPB) 
      conditions with the highest global disease burden was measured with the Ensuring 
      Quality Information for Patients (EQIP) tool. The EQIP tool is used to measure 
      the quality of internet-available information and consists of 36 items that are 
      divided into 3 subsections. In addition, 5 guideline recommendations per analyzed 
      condition were rephrased as questions and input to ChatGPT, and agreement between 
      the guidelines and the AI answer was measured by 2 authors independently. All 
      queries were repeated 3 times to measure the internal consistency of ChatGPT. 
      RESULTS: Five conditions were identified (gallstone disease, pancreatitis, liver 
      cirrhosis, pancreatic cancer, and hepatocellular carcinoma). The median EQIP 
      score across all conditions was 16 (IQR 14.5-18) for the total of 36 items. 
      Divided by subsection, median scores for content, identification, and structure 
      data were 10 (IQR 9.5-12.5), 1 (IQR 1-1), and 4 (IQR 4-5), respectively. 
      Agreement between guideline recommendations and answers provided by ChatGPT was 
      60% (15/25). Interrater agreement as measured by the Fleiss κ was 0.78 (P&lt;.001), 
      indicating substantial agreement. Internal consistency of the answers provided by 
      ChatGPT was 100%. CONCLUSIONS: ChatGPT provides medical information of comparable 
      quality to available static internet information. Although currently of limited 
      quality, large language models could become the future standard for patients and 
      health care professionals to gather medical information.
CI  - ©Harriet Louise Walker, Shahi Ghani, Christoph Kuemmerli, Christian Andreas 
      Nebiker, Beat Peter Müller, Dimitri Aristotle Raptis, Sebastian Manuel Staubli. 
      Originally published in the Journal of Medical Internet Research 
      (https://www.jmir.org), 30.06.2023.
FAU - Walker, Harriet Louise
AU  - Walker HL
AUID- ORCID: 0009-0009-6278-6399
AD  - Royal Free London NHS Foundation Trust, London, United Kingdom.
FAU - Ghani, Shahi
AU  - Ghani S
AUID- ORCID: 0000-0001-7366-296X
AD  - Royal Free London NHS Foundation Trust, London, United Kingdom.
FAU - Kuemmerli, Christoph
AU  - Kuemmerli C
AUID- ORCID: 0000-0002-7109-3545
AD  - Clarunis - University Center for Gastrointestinal and Liver Diseases, Basel, 
      Switzerland.
FAU - Nebiker, Christian Andreas
AU  - Nebiker CA
AUID- ORCID: 0000-0002-7493-2850
AD  - Departement Chirurgie, Kantonsspital Aarau, Aarau, Switzerland.
FAU - Müller, Beat Peter
AU  - Müller BP
AUID- ORCID: 0000-0002-8552-8538
AD  - Clarunis - University Center for Gastrointestinal and Liver Diseases, Basel, 
      Switzerland.
FAU - Raptis, Dimitri Aristotle
AU  - Raptis DA
AUID- ORCID: 0000-0002-0898-3270
AD  - Organ Transplant Center of Excellence, King Faisal Specialist Hospital &amp; Research 
      Centre, Riyadh, Saudi Arabia.
FAU - Staubli, Sebastian Manuel
AU  - Staubli SM
AUID- ORCID: 0000-0002-0818-9835
AD  - Royal Free London NHS Foundation Trust, London, United Kingdom.
AD  - Clarunis - University Center for Gastrointestinal and Liver Diseases, Basel, 
      Switzerland.
LA  - eng
PT  - Journal Article
DEP - 20230630
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Reproducibility of Results
MH  - *Health Personnel
MH  - Internet
MH  - Language
PMC - PMC10365578
OTO - NOTNLM
OT  - ChatGPT
OT  - EQIP tool
OT  - artificial intelligence
OT  - bile
OT  - biliary
OT  - chatbot
OT  - chatbots
OT  - conversational agent
OT  - conversational agents
OT  - gall
OT  - gallstone
OT  - hepatic
OT  - internal medicine
OT  - internet information
OT  - liver
OT  - medical information
OT  - pancreas
OT  - pancreatic
OT  - pancreatitis
OT  - patient information
COIS- Conflicts of Interest: None declared.
EDAT- 2023/06/30 13:11
MHDA- 2023/07/03 06:42
PMCR- 2023/06/30
CRDT- 2023/06/30 11:53
PHST- 2023/04/07 00:00 [received]
PHST- 2023/06/15 00:00 [accepted]
PHST- 2023/06/07 00:00 [revised]
PHST- 2023/07/03 06:42 [medline]
PHST- 2023/06/30 13:11 [pubmed]
PHST- 2023/06/30 11:53 [entrez]
PHST- 2023/06/30 00:00 [pmc-release]
AID - v25i1e47479 [pii]
AID - 10.2196/47479 [doi]
PST - epublish
SO  - J Med Internet Res. 2023 Jun 30;25:e47479. doi: 10.2196/47479.

PMID- 38562449
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240402
IS  - 2331-8422 (Electronic)
IS  - 2331-8422 (Linking)
DP  - 2024 Mar 22
TI  - Bioinformatics and Biomedical Informatics with ChatGPT: Year One Review.
LID - arXiv:2403.15274v1
AB  - The year 2023 marked a significant surge in the exploration of applying large 
      language model (LLM) chatbots, notably ChatGPT, across various disciplines. We 
      surveyed the applications of ChatGPT in various sectors of bioinformatics and 
      biomedical informatics throughout the year, covering omics, genetics, biomedical 
      text mining, drug discovery, biomedical image understanding, bioinformatics 
      programming, and bioinformatics education. Our survey delineates the current 
      strengths and limitations of this chatbot in bioinformatics and offers insights 
      into potential avenues for future development.
FAU - Wang, Jinge
AU  - Wang J
FAU - Cheng, Zien
AU  - Cheng Z
FAU - Yao, Qiuming
AU  - Yao Q
FAU - Liu, Li
AU  - Liu L
FAU - Xu, Dong
AU  - Xu D
FAU - Hu, Gangqing
AU  - Hu G
LA  - eng
PT  - Preprint
DEP - 20240322
PL  - United States
TA  - ArXiv
JT  - ArXiv
JID - 101759493
PMC - PMC10984005
EDAT- 2024/04/02 06:46
MHDA- 2024/04/02 06:47
PMCR- 2024/03/22
CRDT- 2024/04/02 03:49
PHST- 2024/04/02 06:47 [medline]
PHST- 2024/04/02 06:46 [pubmed]
PHST- 2024/04/02 03:49 [entrez]
PHST- 2024/03/22 00:00 [pmc-release]
AID - 2403.15274 [pii]
PST - epublish
SO  - ArXiv [Preprint]. 2024 Mar 22:arXiv:2403.15274v1.

PMID- 38444627
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240307
IS  - 2352-5878 (Electronic)
IS  - 2352-5878 (Linking)
VI  - 40
DP  - 2024 Jun
TI  - Quality of the Information provided by ChatGPT for Patients in Breast Plastic 
      Surgery: Are we already in the future?
PG  - 99-105
LID - 10.1016/j.jpra.2024.02.001 [doi]
AB  - INTRODUCTION: In recent years, artificial intelligence (AI) has gained 
      popularity, even in the field of plastic surgery. It is increasingly common for 
      patients to use the internet to gather information about plastic surgery, and 
      AI-based chatbots, such as ChatGPT, could be employed to answer patients' 
      questions.The aim of this study was to evaluate the quality of medical 
      information provided by ChatGPT regarding three of the most common procedures in 
      breast plastic surgery: breast reconstruction, breast reduction, and augmentation 
      mammaplasty. METHODS: The quality of information was evaluated through the 
      expanded EQIP scale. Responses were collected from a pool made by ten resident 
      doctors in plastic surgery and then processed by SPSS software ver. 28.0. 
      RESULTS: The analysis of the contents provided by ChatGPT revealed sufficient 
      quality of information across all selected topics, with a high bias in terms of 
      distribution of the score between the different items. There was a critical lack 
      in the "Information data field" (0/6 score in all the 3 investigations) but a 
      very high overall evaluation concerning the "Structure data" (&gt;7/11 in all the 3 
      investigations). CONCLUSION: Currently, AI serves as a valuable tool for 
      patients; however, engineers and developers must address certain critical issues. 
      It is possible that models like ChatGPT will play an important role in improving 
      patient's consciousness about medical procedures and surgical interventions in 
      the future, but their role must be considered ancillary to that of surgeons.
CI  - © 2024 The Author(s).
FAU - Grippaudo, F R
AU  - Grippaudo FR
AD  - Department of Plastic Reconstructive and Aesthetic Surgery, Policlinico Umberto 
      I, Sapienza University of Rome, Viale del Policlinico 155, 00161, Rome, Italy.
FAU - Nigrelli, S
AU  - Nigrelli S
AD  - Department of Plastic Reconstructive and Aesthetic Surgery, Policlinico Umberto 
      I, Sapienza University of Rome, Viale del Policlinico 155, 00161, Rome, Italy.
FAU - Patrignani, A
AU  - Patrignani A
AD  - Department of Plastic Reconstructive and Aesthetic Surgery, Policlinico Umberto 
      I, Sapienza University of Rome, Viale del Policlinico 155, 00161, Rome, Italy.
FAU - Ribuffo, D
AU  - Ribuffo D
AD  - Department of Plastic Reconstructive and Aesthetic Surgery, Policlinico Umberto 
      I, Sapienza University of Rome, Viale del Policlinico 155, 00161, Rome, Italy.
LA  - eng
PT  - Journal Article
DEP - 20240215
PL  - Netherlands
TA  - JPRAS Open
JT  - JPRAS open
JID - 101680420
PMC - PMC10914413
OTO - NOTNLM
OT  - Artificial Intelligence
OT  - Augmentation mammaplasty, Breast reduction, Breast reconstruction
OT  - ChatGPT
OT  - EQIP Scale
COIS- The authors report no conflict of interest.
EDAT- 2024/03/06 06:44
MHDA- 2024/03/06 06:45
PMCR- 2024/02/15
CRDT- 2024/03/06 03:50
PHST- 2023/12/12 00:00 [received]
PHST- 2024/02/04 00:00 [accepted]
PHST- 2024/03/06 06:45 [medline]
PHST- 2024/03/06 06:44 [pubmed]
PHST- 2024/03/06 03:50 [entrez]
PHST- 2024/02/15 00:00 [pmc-release]
AID - S2352-5878(24)00019-6 [pii]
AID - 10.1016/j.jpra.2024.02.001 [doi]
PST - epublish
SO  - JPRAS Open. 2024 Feb 15;40:99-105. doi: 10.1016/j.jpra.2024.02.001. eCollection 
      2024 Jun.

PMID- 37988149
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231208
IS  - 2369-3762 (Print)
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Nov 21
TI  - The Intersection of ChatGPT, Clinical Medicine, and Medical Education.
PG  - e47274
LID - 10.2196/47274 [doi]
LID - e47274
AB  - As we progress deeper into the digital age, the robust development and 
      application of advanced artificial intelligence (AI) technology, specifically 
      generative language models like ChatGPT (OpenAI), have potential implications in 
      all sectors including medicine. This viewpoint article aims to present the 
      authors' perspective on the integration of AI models such as ChatGPT in clinical 
      medicine and medical education. The unprecedented capacity of ChatGPT to generate 
      human-like responses, refined through Reinforcement Learning with Human Feedback, 
      could significantly reshape the pedagogical methodologies within medical 
      education. Through a comprehensive review and the authors' personal experiences, 
      this viewpoint article elucidates the pros, cons, and ethical considerations of 
      using ChatGPT within clinical medicine and notably, its implications for medical 
      education. This exploration is crucial in a transformative era where AI could 
      potentially augment human capability in the process of knowledge creation and 
      dissemination, potentially revolutionizing medical education and clinical 
      practice. The importance of maintaining academic integrity and professional 
      standards is highlighted. The relevance of establishing clear guidelines for the 
      responsible and ethical use of AI technologies in clinical medicine and medical 
      education is also emphasized.
CI  - ©Rebecca Shin-Yee Wong, Long Chiau Ming, Raja Affendi Raja Ali. Originally 
      published in JMIR Medical Education (https://mededu.jmir.org), 21.11.2023.
FAU - Wong, Rebecca Shin-Yee
AU  - Wong RS
AUID- ORCID: 0000-0002-7738-9398
AD  - Department of Medical Education, School of Medical and Life Sciences, Sunway 
      University, Selangor, Malaysia.
AD  - Faculty of Medicine, Nursing and Health Sciences, SEGi University, Petaling Jaya, 
      Malaysia.
FAU - Ming, Long Chiau
AU  - Ming LC
AUID- ORCID: 0000-0002-6971-1383
AD  - School of Medical and Life Sciences, Sunway University, Selangor, Malaysia.
FAU - Raja Ali, Raja Affendi
AU  - Raja Ali RA
AUID- ORCID: 0000-0001-9431-4657
AD  - School of Medical and Life Sciences, Sunway University, Selangor, Malaysia.
AD  - GUT Research Group, Faculty of Medicine, Universiti Kebangsaan Malaysia, Kuala 
      Lumpur, Malaysia.
LA  - eng
PT  - Journal Article
DEP - 20231121
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
PMC - PMC10698645
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - OpenAI
OT  - artificial intelligence
OT  - clinical research
OT  - ethical considerations
OT  - large language model
COIS- Conflicts of Interest: None declared.
EDAT- 2023/11/21 12:42
MHDA- 2023/11/21 12:43
PMCR- 2023/11/21
CRDT- 2023/11/21 11:53
PHST- 2023/03/14 00:00 [received]
PHST- 2023/06/30 00:00 [accepted]
PHST- 2023/06/16 00:00 [revised]
PHST- 2023/11/21 12:43 [medline]
PHST- 2023/11/21 12:42 [pubmed]
PHST- 2023/11/21 11:53 [entrez]
PHST- 2023/11/21 00:00 [pmc-release]
AID - v9i1e47274 [pii]
AID - 10.2196/47274 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Nov 21;9:e47274. doi: 10.2196/47274.

PMID- 37904734
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240202
IS  - 2331-8422 (Electronic)
IS  - 2331-8422 (Linking)
DP  - 2023 Oct 17
TI  - Opportunities and Challenges for ChatGPT and Large Language Models in Biomedicine 
      and Health.
LID - arXiv:2306.10070v2
AB  - ChatGPT has drawn considerable attention from both the general public and domain 
      experts with its remarkable text generation capabilities. This has subsequently 
      led to the emergence of diverse applications in the field of biomedicine and 
      health. In this work, we examine the diverse applications of large language 
      models (LLMs), such as ChatGPT, in biomedicine and health. Specifically we 
      explore the areas of biomedical information retrieval, question answering, 
      medical text summarization, information extraction, and medical education, and 
      investigate whether LLMs possess the transformative power to revolutionize these 
      tasks or whether the distinct complexities of biomedical domain presents unique 
      challenges. Following an extensive literature survey, we find that significant 
      advances have been made in the field of text generation tasks, surpassing the 
      previous state-of-the-art methods. For other applications, the advances have been 
      modest. Overall, LLMs have not yet revolutionized biomedicine, but recent rapid 
      progress indicates that such methods hold great potential to provide valuable 
      means for accelerating discovery and improving health. We also find that the use 
      of LLMs, like ChatGPT, in the fields of biomedicine and health entails various 
      risks and challenges, including fabricated information in its generated 
      responses, as well as legal and privacy concerns associated with sensitive 
      patient data. We believe this survey can provide a comprehensive and timely 
      overview to biomedical researchers and healthcare practitioners on the 
      opportunities and challenges associated with using ChatGPT and other LLMs for 
      transforming biomedicine and health.
FAU - Tian, Shubo
AU  - Tian S
AD  - National Library of Medicine, National Institutes of Health.
FAU - Jin, Qiao
AU  - Jin Q
AD  - National Library of Medicine, National Institutes of Health.
FAU - Yeganova, Lana
AU  - Yeganova L
AD  - National Library of Medicine, National Institutes of Health.
FAU - Lai, Po-Ting
AU  - Lai PT
AD  - National Library of Medicine, National Institutes of Health.
FAU - Zhu, Qingqing
AU  - Zhu Q
AD  - National Library of Medicine, National Institutes of Health.
FAU - Chen, Xiuying
AU  - Chen X
AD  - King Abdullah University of Science and Technology.
FAU - Yang, Yifan
AU  - Yang Y
AD  - National Library of Medicine, National Institutes of Health.
FAU - Chen, Qingyu
AU  - Chen Q
AD  - National Library of Medicine, National Institutes of Health.
FAU - Kim, Won
AU  - Kim W
AD  - National Library of Medicine, National Institutes of Health.
FAU - Comeau, Donald C
AU  - Comeau DC
AD  - National Library of Medicine, National Institutes of Health.
FAU - Islamaj, Rezarta
AU  - Islamaj R
AD  - National Library of Medicine, National Institutes of Health.
FAU - Kapoor, Aadit
AU  - Kapoor A
AD  - National Library of Medicine, National Institutes of Health.
FAU - Gao, Xin
AU  - Gao X
AD  - King Abdullah University of Science and Technology.
FAU - Lu, Zhiyong
AU  - Lu Z
AD  - National Library of Medicine, National Institutes of Health.
LA  - eng
GR  - K99 LM014024/LM/NLM NIH HHS/United States
PT  - Preprint
DEP - 20231017
PL  - United States
TA  - ArXiv
JT  - ArXiv
JID - 101759493
UIN - Brief Bioinform. 2023 Nov 22;25(1):. PMID: 38168838
PMC - PMC10614979
OTO - NOTNLM
OT  - ChatGPT
OT  - biomedicine and health
OT  - generative AI
OT  - large language model
OT  - opportunities and challenges
EDAT- 2023/10/31 06:42
MHDA- 2023/10/31 06:43
PMCR- 2023/10/17
CRDT- 2023/10/31 03:50
PHST- 2023/10/31 06:42 [pubmed]
PHST- 2023/10/31 06:43 [medline]
PHST- 2023/10/31 03:50 [entrez]
PHST- 2023/10/17 00:00 [pmc-release]
AID - 2306.10070 [pii]
PST - epublish
SO  - ArXiv [Preprint]. 2023 Oct 17:arXiv:2306.10070v2.

PMID- 37066228
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231106
DP  - 2023 Apr 3
TI  - An exploratory survey about using ChatGPT in education, healthcare, and research.
LID - 2023.03.31.23287979 [pii]
LID - 10.1101/2023.03.31.23287979 [doi]
AB  - Objective ChatGPT is the first large language model (LLM) to reach a large, 
      mainstream audience. Its rapid adoption and exploration by the population at 
      large has sparked a wide range of discussions regarding its acceptable and 
      optimal integration in different areas. In a hybrid (virtual and in-person) panel 
      discussion event, we examined various perspectives regarding the use of ChatGPT 
      in education, research, and healthcare. Materials and Methods We surveyed 
      in-person and online attendees using an audience interaction platform (Slido). We 
      quantitatively analyzed received responses on questions about the use of ChatGPT 
      in various contexts. We compared pairwise categorical groups with Fisher's Exact. 
      Furthermore, we used qualitative methods to analyze and code discussions. Results 
      We received 420 responses from an estimated 844 participants (response rate 
      49.7%). Only 40% of the audience had tried ChatGPT. More trainees had tried 
      ChatGPT compared with faculty. Those who had used ChatGPT were more interested in 
      using it in a wider range of contexts going forwards. Of the three discussed 
      contexts, the greatest uncertainty was shown about using ChatGPT in education. 
      Pros and cons were raised during discussion for the use of this technology in 
      education, research, and healthcare. Discussion There was a range of perspectives 
      around the uses of ChatGPT in education, research, and healthcare, with still 
      much uncertainty around its acceptability and optimal uses. There were different 
      perspectives from respondents of different roles (trainee vs faculty vs staff). 
      More discussion is needed to explore perceptions around the use of LLMs such as 
      ChatGPT in vital sectors such as education, healthcare and research. Given 
      involved risks and unforeseen challenges, taking a thoughtful and measured 
      approach in adoption would reduce the likelihood of harm.
FAU - Hosseini, Mohammad
AU  - Hosseini M
AD  - Department of Preventive Medicine, Northwestern University Feinberg School of 
      Medicine, Chicago, IL.
FAU - Gao, Catherine A
AU  - Gao CA
AD  - Department of Medicine (Division of Pulmonary and Critical Care), Northwestern 
      University Feinberg School of Medicine, Chicago, IL.
FAU - Liebovitz, David
AU  - Liebovitz D
AD  - Department of Medicine (Divisions of General Internal Medicine and Health and 
      Biomedical Informatics), Northwestern University Feinberg School of Medicine, 
      Chicago, IL.
AD  - Center for Medical Education in Digital Health and Data Science, Northwestern 
      University Feinberg School of Medicine, Chicago, IL.
FAU - Carvalho, Alexandre
AU  - Carvalho A
AD  - Department of Medicine (Division of Infectious Diseases), Northwestern University 
      Feinberg School of Medicine, Chicago, IL.
AD  - Center for Pathogen Genomics &amp; Microbial Evolution, Northwestern University 
      Feinberg School of Medicine, Chicago, IL.
FAU - Ahmad, Faraz S
AU  - Ahmad FS
AD  - Department of Preventive Medicine, Northwestern University Feinberg School of 
      Medicine, Chicago, IL.
AD  - Department of Medicine (Division of Cardiology), Northwestern University Feinberg 
      School of Medicine, Chicago, IL.
AD  - Bluhm Cardiovascular Center for Artificial Intelligence, Northwestern Medicine, 
      Northwestern University Feinberg School of Medicine, Chicago, IL.
FAU - Luo, Yuan
AU  - Luo Y
AD  - Department of Preventive Medicine, Northwestern University Feinberg School of 
      Medicine, Chicago, IL.
FAU - MacDonald, Ngan
AU  - MacDonald N
AD  - Institute for Augmented Intelligence in Medicine, Northwestern University 
      Feinberg School of Medicine, Chicago, IL.
FAU - Holmes, Kristi
AU  - Holmes K
AD  - Department of Preventive Medicine, Northwestern University Feinberg School of 
      Medicine, Chicago, IL.
AD  - Galter Health Sciences Library and Learning Center, Northwestern University 
      Feinberg School of Medicine, Chicago, IL.
FAU - Kho, Abel
AU  - Kho A
AD  - Department of Medicine (Divisions of General Internal Medicine and Health and 
      Biomedical Informatics), Northwestern University Feinberg School of Medicine, 
      Chicago, IL.
AD  - Institute for Augmented Intelligence in Medicine, Northwestern University 
      Feinberg School of Medicine, Chicago, IL.
LA  - eng
GR  - F32 HL162377/HL/NHLBI NIH HHS/United States
GR  - K23 HL155970/HL/NHLBI NIH HHS/United States
GR  - UL1 TR001422/TR/NCATS NIH HHS/United States
PT  - Preprint
DEP - 20230403
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
UIN - PLoS One. 2023 Oct 5;18(10):e0292216. PMID: 37796786
PMC - PMC10104227
COIS- Conflicts of interest: The authors report no conflicting interests.
EDAT- 2023/04/18 06:00
MHDA- 2023/04/18 06:01
PMCR- 2023/04/14
CRDT- 2023/04/17 04:08
PHST- 2023/04/18 06:01 [medline]
PHST- 2023/04/17 04:08 [entrez]
PHST- 2023/04/18 06:00 [pubmed]
PHST- 2023/04/14 00:00 [pmc-release]
AID - 2023.03.31.23287979 [pii]
AID - 10.1101/2023.03.31.23287979 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2023 Apr 3:2023.03.31.23287979. doi: 
      10.1101/2023.03.31.23287979.

PMID- 37273063
OWN - NLM
STAT- Publisher
LR  - 20231024
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 51
IP  - 11
DP  - 2023 Nov
TI  - ChatGPTs' Journey in Medical Revolution: A Potential Panacea or a Hidden 
      Pathogen?
PG  - 2356-2358
LID - 10.1007/s10439-023-03264-4 [doi]
AB  - At the fascinating intersection of artificial intelligence and medicine, ChatGPT 
      morphs into a compact, personal digital physician. With a simple click, it 
      furnishes an abundance of health-related information, initial medical 
      consultations, and a plethora of disease management recommendations. Moreover, it 
      stands at the ready to provide immediate mental health assistance in times of 
      psychological distress. Yet, each innovation carries inherent challenges. As we 
      embrace the conveniences proffered by ChatGPT, it is imperative that we grapple 
      with associated issues such as data privacy, risk of misdiagnosis, complexities 
      in human-machine interaction, and particular situations that elude its 
      understanding. Let's probe further into this intriguing world, brimming with 
      contention and prospects, and observe how ChatGPT traverses the landscape of 
      digital health, uncovering the potential it holds for the future evolution of 
      medical practice.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Yang, Jing
AU  - Yang J
AUID- ORCID: 0000-0002-8132-8395
AD  - Department of Computer System and Technology, Faculty of Computer Science and 
      Information Technology, Universiti Malaya, 50603, Kuala Lumpur, Malaysia. 
      s2147529@siswa.um.edu.my.
LA  - eng
PT  - Letter
DEP - 20230605
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - Digital health
OT  - Revolution
EDAT- 2023/06/05 13:04
MHDA- 2023/06/05 13:04
CRDT- 2023/06/05 11:08
PHST- 2023/05/29 00:00 [received]
PHST- 2023/05/31 00:00 [accepted]
PHST- 2023/06/05 13:04 [pubmed]
PHST- 2023/06/05 13:04 [medline]
PHST- 2023/06/05 11:08 [entrez]
AID - 10.1007/s10439-023-03264-4 [pii]
AID - 10.1007/s10439-023-03264-4 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2023 Nov;51(11):2356-2358. doi: 10.1007/s10439-023-03264-4. Epub 
      2023 Jun 5.

PMID- 37768724
OWN - NLM
STAT- Publisher
LR  - 20231015
IS  - 2369-3762 (Print)
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Sep 28
TI  - Performance of ChatGPT on the Peruvian National Licensing Medical Examination: 
      Cross-Sectional Study.
PG  - e48039
LID - 10.2196/48039 [doi]
LID - e48039
AB  - BACKGROUND: ChatGPT has shown impressive performance in national medical 
      licensing examinations, such as the United States Medical Licensing Examination 
      (USMLE), even passing it with expert-level performance. However, there is a lack 
      of research on its performance in low-income countries' national licensing 
      medical examinations. In Peru, where almost one out of three examinees fails the 
      national licensing medical examination, ChatGPT has the potential to enhance 
      medical education. OBJECTIVE: We aimed to assess the accuracy of ChatGPT using 
      GPT-3.5 and GPT-4 on the Peruvian National Licensing Medical Examination (Examen 
      Nacional de Medicina [ENAM]). Additionally, we sought to identify factors 
      associated with incorrect answers provided by ChatGPT. METHODS: We used the ENAM 
      2022 data set, which consisted of 180 multiple-choice questions, to evaluate the 
      performance of ChatGPT. Various prompts were used, and accuracy was evaluated. 
      The performance of ChatGPT was compared to that of a sample of 1025 examinees. 
      Factors such as question type, Peruvian-specific knowledge, discrimination, 
      difficulty, quality of questions, and subject were analyzed to determine their 
      influence on incorrect answers. Questions that received incorrect answers 
      underwent a three-step process involving different prompts to explore the 
      potential impact of adding roles and context on ChatGPT's accuracy. RESULTS: 
      GPT-4 achieved an accuracy of 86% on the ENAM, followed by GPT-3.5 with 77%. The 
      accuracy obtained by the 1025 examinees was 55%. There was a fair agreement 
      (κ=0.38) between GPT-3.5 and GPT-4. Moderate-to-high-difficulty questions were 
      associated with incorrect answers in the crude and adjusted model for GPT-3.5 
      (odds ratio [OR] 6.6, 95% CI 2.73-15.95) and GPT-4 (OR 33.23, 95% CI 4.3-257.12). 
      After reinputting questions that received incorrect answers, GPT-3.5 went from 41 
      (100%) to 12 (29%) incorrect answers, and GPT-4 from 25 (100%) to 4 (16%). 
      CONCLUSIONS: Our study found that ChatGPT (GPT-3.5 and GPT-4) can achieve 
      expert-level performance on the ENAM, outperforming most of our examinees. We 
      found fair agreement between both GPT-3.5 and GPT-4. Incorrect answers were 
      associated with the difficulty of questions, which may resemble human 
      performance. Furthermore, by reinputting questions that initially received 
      incorrect answers with different prompts containing additional roles and context, 
      ChatGPT achieved improved accuracy.
CI  - ©Javier A Flores-Cohaila, Abigaíl García-Vicente, Sonia F Vizcarra-Jiménez, 
      Janith P De la Cruz-Galán, Jesús D Gutiérrez-Arratia, Blanca Geraldine Quiroga 
      Torres, Alvaro Taype-Rondan. Originally published in JMIR Medical Education 
      (https://mededu.jmir.org), 28.09.2023.
FAU - Flores-Cohaila, Javier A
AU  - Flores-Cohaila JA
AUID- ORCID: 0000-0002-9169-2094
AD  - Academic Department, USAMEDIC, Lima, Peru.
AD  - Facultad de Ciencias de la Salud, Carrera de Medicina, Universidad Científica del 
      Sur, Lima, Peru.
FAU - García-Vicente, Abigaíl
AU  - García-Vicente A
AUID- ORCID: 0000-0003-3679-4239
AD  - School of Medicine, Universidad Nacional de Piura, Piura, Peru.
AD  - Comité Permanente Académico, Sociedad Científica Médico Estudiantil Peruana, 
      Lima, Peru.
FAU - Vizcarra-Jiménez, Sonia F
AU  - Vizcarra-Jiménez SF
AUID- ORCID: 0000-0002-8030-4092
AD  - Comité Permanente Académico, Sociedad Científica Médico Estudiantil Peruana, 
      Lima, Peru.
AD  - Centro de Investigación de Estudiantes de Medicina, Tacna, Peru.
FAU - De la Cruz-Galán, Janith P
AU  - De la Cruz-Galán JP
AUID- ORCID: 0000-0001-7261-9038
AD  - Comité Permanente Académico, Sociedad Científica Médico Estudiantil Peruana, 
      Lima, Peru.
AD  - School of Medicine, Universidad de San Martin de Porres - Filial Norte, Chiclayo, 
      Peru.
FAU - Gutiérrez-Arratia, Jesús D
AU  - Gutiérrez-Arratia JD
AUID- ORCID: 0000-0003-4082-5966
AD  - Academic Department, USAMEDIC, Lima, Peru.
FAU - Quiroga Torres, Blanca Geraldine
AU  - Quiroga Torres BG
AUID- ORCID: 0000-0002-1141-1062
AD  - Comité Permanente Académico, Sociedad Científica Médico Estudiantil Peruana, 
      Lima, Peru.
FAU - Taype-Rondan, Alvaro
AU  - Taype-Rondan A
AUID- ORCID: 0000-0001-8758-0463
AD  - Unidad de Investigación Para la Generación y Síntesis de Evidencias en Salud, 
      Vicerrectorado de Investigación, Universidad San Ignacio de Loyola, Lima, Peru.
AD  - EviSalud - Evidencias en Salud, Lima, Peru.
LA  - eng
PT  - Journal Article
DEP - 20230928
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
PMC - PMC10570896
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - ENAM
OT  - Examen Nacional de Medicina
OT  - Peru
OT  - artificial intelligence
OT  - assessment
OT  - generative pre-trained transformer
OT  - learning model
OT  - licensing examination
OT  - medical education
OT  - medical examination
COIS- Conflicts of Interest: None declared.
EDAT- 2023/09/28 12:42
MHDA- 2023/09/28 12:42
PMCR- 2023/09/28
CRDT- 2023/09/28 11:54
PHST- 2023/04/09 00:00 [received]
PHST- 2023/09/05 00:00 [accepted]
PHST- 2023/06/16 00:00 [revised]
PHST- 2023/09/28 12:42 [medline]
PHST- 2023/09/28 12:42 [pubmed]
PHST- 2023/09/28 11:54 [entrez]
PHST- 2023/09/28 00:00 [pmc-release]
AID - v9i1e48039 [pii]
AID - 10.2196/48039 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Sep 28;9:e48039. doi: 10.2196/48039.

PMID- 38435794
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240305
IS  - 1865-5025 (Print)
IS  - 1865-5033 (Electronic)
IS  - 1865-5025 (Linking)
VI  - 17
IP  - 1
DP  - 2024 Feb
TI  - Incorporation of ChatGPT and Other Large Language Models into a Graduate Level 
      Computational Bioengineering Course.
PG  - 1-6
LID - 10.1007/s12195-024-00793-3 [doi]
AB  - The remarkable capabilities of generative artificial intelligence and large 
      language models (LLMs) such as ChatGPT have delighted users around the world. 
      Educators have regarded these tools as either a cause for great concern, an 
      opportunity to educate students on cutting-edge technology, or often some 
      combination of the two. Throughout the Fall 2023 semester, we explored the use of 
      ChatGPT (and Bard, among other LLMs) in a graduate level numerical and 
      statistical methods course for PhD-level bioengineers. In this article we share 
      examples of this ChatGPT content, our observations on what worked best in our 
      course, and speculate on how bioengineering students may be best served by this 
      technology in the future.
CI  - © The Author(s), under exclusive licence to Biomedical Engineering Society 2024.
FAU - King, Michael R
AU  - King MR
AD  - Department of Biomedical Engineering, Vanderbilt University, Nashville, TN 37235 
      USA. ROR: https://ror.org/02vm5rt34. GRID: grid.152326.1. ISNI: 0000 0001 2264 
      7217
FAU - Abdulrahman, Adam M
AU  - Abdulrahman AM
AD  - Department of Biomedical Engineering, Vanderbilt University, Nashville, TN 37235 
      USA. ROR: https://ror.org/02vm5rt34. GRID: grid.152326.1. ISNI: 0000 0001 2264 
      7217
AD  - Medical Scientist Training Program, Vanderbilt University School of Medicine, 
      Nashville, TN USA. GRID: grid.152326.1. ISNI: 0000 0001 2264 7217
FAU - Petrovic, Mark I
AU  - Petrovic MI
AD  - Department of Biomedical Engineering, Vanderbilt University, Nashville, TN 37235 
      USA. ROR: https://ror.org/02vm5rt34. GRID: grid.152326.1. ISNI: 0000 0001 2264 
      7217
AD  - Medical Scientist Training Program, Vanderbilt University School of Medicine, 
      Nashville, TN USA. GRID: grid.152326.1. ISNI: 0000 0001 2264 7217
FAU - Poley, Patricia L
AU  - Poley PL
AD  - Department of Biomedical Engineering, Vanderbilt University, Nashville, TN 37235 
      USA. ROR: https://ror.org/02vm5rt34. GRID: grid.152326.1. ISNI: 0000 0001 2264 
      7217
FAU - Hall, Sarah P
AU  - Hall SP
AD  - Department of Biomedical Engineering, Vanderbilt University, Nashville, TN 37235 
      USA. ROR: https://ror.org/02vm5rt34. GRID: grid.152326.1. ISNI: 0000 0001 2264 
      7217
FAU - Kulapatana, Surat
AU  - Kulapatana S
AD  - Department of Biomedical Engineering, Vanderbilt University, Nashville, TN 37235 
      USA. ROR: https://ror.org/02vm5rt34. GRID: grid.152326.1. ISNI: 0000 0001 2264 
      7217
AD  - Department of Physiology, Faculty of Medicine Siriraj Hospital, Mahidol 
      University, Bangkok, 10700 Thailand. GRID: grid.10223.32. ISNI: 0000 0004 1937 
      0490
FAU - Lamantia, Zachary E
AU  - Lamantia ZE
AD  - Department of Biomedical Engineering, Vanderbilt University, Nashville, TN 37235 
      USA. ROR: https://ror.org/02vm5rt34. GRID: grid.152326.1. ISNI: 0000 0001 2264 
      7217
LA  - eng
PT  - Editorial
DEP - 20240207
PL  - United States
TA  - Cell Mol Bioeng
JT  - Cellular and molecular bioengineering
JID - 101468590
PMC - PMC10902225
OTO - NOTNLM
OT  - Bard
OT  - ChatGPT
OT  - Higher education
OT  - Large language model
OT  - MATLAB
EDAT- 2024/03/04 06:44
MHDA- 2024/03/04 06:45
PMCR- 2025/02/07
CRDT- 2024/03/04 05:06
PHST- 2025/02/07 00:00 [pmc-release]
PHST- 2024/03/04 06:45 [medline]
PHST- 2024/03/04 06:44 [pubmed]
PHST- 2024/03/04 05:06 [entrez]
AID - 793 [pii]
AID - 10.1007/s12195-024-00793-3 [doi]
PST - epublish
SO  - Cell Mol Bioeng. 2024 Feb 7;17(1):1-6. doi: 10.1007/s12195-024-00793-3. 
      eCollection 2024 Feb.

PMID- 37401955
OWN - NLM
STAT- Publisher
LR  - 20231010
IS  - 2193-6226 (Electronic)
IS  - 2193-6218 (Linking)
VI  - 118
IP  - 7
DP  - 2023 Oct
TI  - [ChatGPT: curse or blessing in nursing care?].
PG  - 534-539
LID - 10.1007/s00063-023-01038-3 [doi]
AB  - Artificial intelligence (AI) has been used in healthcare for some years for risk 
      detection, diagnostics, documentation, education and training and other purposes. 
      A&nbsp;new open AI application is ChatGPT, which is accessible to everyone. The 
      application of ChatGPT as AI in education, training or studies is currently being 
      discussed from many perspectives. It is questionable whether ChatGPT can and 
      should also support nursing professions in health care. The aim of this review 
      article is to show and critically discuss possible areas of application of 
      ChatGPT in theory and practice with a&nbsp;focus on nursing practice, pedagogy, 
      nursing research and nursing development.
CI  - © 2023. The Author(s), under exclusive licence to Springer Medizin Verlag GmbH, 
      ein Teil von Springer Nature.
FAU - Krüger, Lars
AU  - Krüger L
AUID- ORCID: 0000-0003-4234-0022
AD  - Herz- und Diabeteszentrum NRW, Universitätsklinikum der Ruhr-Universität Bochum, 
      Bad Oeynhausen, Deutschland.
FAU - Krotsetis, Susanne
AU  - Krotsetis S
AD  - Pflegeentwicklung und Pflegewissenschaft angegliedert der Pflegedirektion, des 
      Universitätsklinikums Schleswig-Holstein, Campus Lübeck, Lübeck, Deutschland.
CN  - OpenAI’s Generative Pretrained Transformer 3 (GPT-3) Model
FAU - Nydahl, Peter
AU  - Nydahl P
AUID- ORCID: 0000-0002-5178-0364
AD  - Pflegeforschung und -entwicklung, Pflegedirektion, Universitätsklinikum 
      Schleswig-Holstein, Haus V40, Arnold-Heller-Str.&nbsp;3, 24105, Kiel, Deutschland. 
      peter.nydahl@uksh.de.
AD  - Universitätsinstitut für Pflegewissenschaft und -praxis, Paracelsus Medizinische 
      Privatuniversität, Salzburg, Österreich. peter.nydahl@uksh.de.
LA  - ger
PT  - English Abstract
PT  - Journal Article
PT  - Review
TT  - ChatGPT: Fluch oder Segen in der Pflege?
DEP - 20230704
PL  - Germany
TA  - Med Klin Intensivmed Notfmed
JT  - Medizinische Klinik, Intensivmedizin und Notfallmedizin
JID - 101575086
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Chatbot
OT  - Ethic
OT  - Evidence-based practice
OT  - Nursing
OT  - Teaching
OT  - Technical Support
EDAT- 2023/07/04 13:08
MHDA- 2023/07/04 13:08
CRDT- 2023/07/04 11:04
PHST- 2023/02/23 00:00 [received]
PHST- 2023/06/03 00:00 [accepted]
PHST- 2023/04/28 00:00 [revised]
PHST- 2023/07/04 13:08 [pubmed]
PHST- 2023/07/04 13:08 [medline]
PHST- 2023/07/04 11:04 [entrez]
AID - 10.1007/s00063-023-01038-3 [pii]
AID - 10.1007/s00063-023-01038-3 [doi]
PST - ppublish
SO  - Med Klin Intensivmed Notfmed. 2023 Oct;118(7):534-539. doi: 
      10.1007/s00063-023-01038-3. Epub 2023 Jul 4.

PMID- 38374067
OWN - NLM
STAT- MEDLINE
DCOM- 20240221
LR  - 20240325
IS  - 1472-6947 (Electronic)
IS  - 1472-6947 (Linking)
VI  - 24
IP  - 1
DP  - 2024 Feb 19
TI  - Exploring the potential of ChatGPT as an adjunct for generating diagnosis based 
      on chief complaint and cone beam CT radiologic findings.
PG  - 55
LID - 10.1186/s12911-024-02445-y [doi]
LID - 55
AB  - AIM: This study aimed to assess the performance of OpenAI's ChatGPT in generating 
      diagnosis based on chief complaint and cone beam computed tomography (CBCT) 
      radiologic findings. MATERIALS AND METHODS: 102 CBCT reports (48 with dental 
      diseases (DD) and 54 with neoplastic/cystic diseases (N/CD)) were collected. 
      ChatGPT was provided with chief complaint and CBCT radiologic findings. 
      Diagnostic outputs from ChatGPT were scored based on five-point Likert scale. For 
      diagnosis accuracy, the scoring was based on the accuracy of chief complaint 
      related diagnosis and chief complaint unrelated diagnoses (1-5 points); for 
      diagnosis completeness, the scoring was based on how many accurate diagnoses 
      included in ChatGPT's output for one case (1-5 points); for text quality, the 
      scoring was based on how many text errors included in ChatGPT's output for one 
      case (1-5 points). For 54&nbsp;N/CD cases, the consistence of the diagnosis generated 
      by ChatGPT with pathological diagnosis was also calculated. The constitution of 
      text errors in ChatGPT's outputs was evaluated. RESULTS: After subjective ratings 
      by expert reviewers on a five-point Likert scale, the final score of diagnosis 
      accuracy, diagnosis completeness and text quality of ChatGPT was 3.7, 4.5 and 4.6 
      for the 102 cases. For diagnostic accuracy, it performed significantly better on 
      N/CD (3.8/5) compared to DD (3.6/5). For 54&nbsp;N/CD cases, 21(38.9%) cases have 
      first diagnosis completely consistent with pathological diagnosis. No text errors 
      were observed in 88.7% of all the 390 text items. CONCLUSION: ChatGPT showed 
      potential in generating radiographic diagnosis based on chief complaint and 
      radiologic findings. However, the performance of ChatGPT varied with task 
      complexity, necessitating professional oversight due to a certain error rate.
CI  - © 2024. The Author(s).
FAU - Hu, Yanni
AU  - Hu Y
AD  - Department of Dentomaxillofacial Radiology, Nanjing Stomatological Hospital, 
      Affiliated Hospital of Medical School, Institute of Stomatology, Nanjing 
      University, Nanjing, Jiangsu, People's Republic of China.
FAU - Hu, Ziyang
AU  - Hu Z
AUID- ORCID: 0000-0002-2537-5701
AD  - Department of Dentomaxillofacial Radiology, Nanjing Stomatological Hospital, 
      Affiliated Hospital of Medical School, Institute of Stomatology, Nanjing 
      University, Nanjing, Jiangsu, People's Republic of China.
AD  - Department of Stomatology, Shenzhen Longhua District Central Hospital, Shenzhen, 
      People's Republic of China.
FAU - Liu, Wenjing
AU  - Liu W
AD  - Department of Dentomaxillofacial Radiology, Nanjing Stomatological Hospital, 
      Affiliated Hospital of Medical School, Institute of Stomatology, Nanjing 
      University, Nanjing, Jiangsu, People's Republic of China.
FAU - Gao, Antian
AU  - Gao A
AD  - Department of Dentomaxillofacial Radiology, Nanjing Stomatological Hospital, 
      Affiliated Hospital of Medical School, Institute of Stomatology, Nanjing 
      University, Nanjing, Jiangsu, People's Republic of China.
FAU - Wen, Shanhui
AU  - Wen S
AD  - Department of Dentomaxillofacial Radiology, Nanjing Stomatological Hospital, 
      Affiliated Hospital of Medical School, Institute of Stomatology, Nanjing 
      University, Nanjing, Jiangsu, People's Republic of China.
FAU - Liu, Shu
AU  - Liu S
AD  - Department of Dentomaxillofacial Radiology, Nanjing Stomatological Hospital, 
      Affiliated Hospital of Medical School, Institute of Stomatology, Nanjing 
      University, Nanjing, Jiangsu, People's Republic of China.
FAU - Lin, Zitong
AU  - Lin Z
AD  - Department of Dentomaxillofacial Radiology, Nanjing Stomatological Hospital, 
      Affiliated Hospital of Medical School, Institute of Stomatology, Nanjing 
      University, Nanjing, Jiangsu, People's Republic of China. linzitong_710@163.com.
LA  - eng
GR  - 82201135/National Natural Science Foundation of China/
GR  - M2021077/General project of Jiangsu Provincial Health Commission/
GR  - 0223A204/"2015" Cultivation Program for Reserve Talents for Academic Leaders of 
      Nanjing Stomatological School, Medical School of Nanjing University/
PT  - Journal Article
DEP - 20240219
PL  - England
TA  - BMC Med Inform Decis Mak
JT  - BMC medical informatics and decision making
JID - 101088682
SB  - IM
MH  - Humans
MH  - *Cone-Beam Computed Tomography
MH  - *Artificial Intelligence
MH  - *Diagnosis, Computer-Assisted
PMC - PMC10875853
OTO - NOTNLM
OT  - CBCT
OT  - Dental Disease
OT  - Diagnosis
OT  - Large language model
OT  - Neoplastic/cystic diseases
OT  - Radiologic finding
OT  - Radiologic impression
COIS- The research is not under publication consideration elsewhere. The authors have 
      stated explicitly that there are no conflicts of interest in connection with this 
      article
EDAT- 2024/02/20 11:50
MHDA- 2024/02/21 11:21
PMCR- 2024/02/19
CRDT- 2024/02/19 23:42
PHST- 2023/09/11 00:00 [received]
PHST- 2024/01/28 00:00 [accepted]
PHST- 2024/02/21 11:21 [medline]
PHST- 2024/02/20 11:50 [pubmed]
PHST- 2024/02/19 23:42 [entrez]
PHST- 2024/02/19 00:00 [pmc-release]
AID - 10.1186/s12911-024-02445-y [pii]
AID - 2445 [pii]
AID - 10.1186/s12911-024-02445-y [doi]
PST - epublish
SO  - BMC Med Inform Decis Mak. 2024 Feb 19;24(1):55. doi: 10.1186/s12911-024-02445-y.

PMID- 38445975
OWN - NLM
STAT- Publisher
LR  - 20240306
IS  - 1530-0293 (Electronic)
IS  - 0090-3493 (Linking)
DP  - 2024 Mar 6
TI  - Evaluation of ChatGPT in Predicting 6-Month Outcomes After Traumatic Brain 
      Injury.
LID - 10.1097/CCM.0000000000006236 [doi]
AB  - OBJECTIVES: To evaluate the capacity of ChatGPT, a widely accessible and uniquely 
      popular artificial intelligence-based chatbot, in predicting the 6-month outcome 
      following moderate-to-severe traumatic brain injury (TBI). DESIGN: Single-center 
      observational retrospective study. SETTING: Data are from a neuro-ICU from a 
      level 1 trauma center. PATIENTS: All TBI patients admitted to ICU between 
      September 2021 and October 2022 were included in a prospective database. 
      INTERVENTIONS: None. MEASUREMENTS AND MAIN RESULTS: Based on anonymized clinical, 
      imaging, and biological information available at the patients' hospital admission 
      and extracted from the database, clinical vignettes were retrospectively 
      submitted to ChatGPT for prediction of patients' outcomes. The predictions of two 
      intensivists (one neurointensivist and one non-neurointensivist) both from 
      another level 1 trauma center (Beaujon Hospital), were also collected as was the 
      International Mission on Prognosis and Analysis of Clinical Trials in Traumatic 
      Brain Injury (IMPACT) scoring. Each intensivist, as well as ChatGPT, made their 
      prognostic evaluations independently, without knowledge of the others' 
      predictions and of the patients' actual management and outcome. Both the 
      intensivists and ChatGPT were given access to the exact same set of information. 
      The main outcome was a 6-month-functional status dichotomized into favorable 
      (Glasgow Outcome Scale Extended [GOSE] ≥ 5) versus poor (GOSE &lt; 5). Prediction of 
      intracranial hypertension management, pulmonary infectious risk, and removal of 
      life-sustaining therapies was also investigated as secondary outcomes. Eighty 
      consecutive moderate-to-severe TBI patients were included. For the 6-month 
      outcome prognosis, area under the receiver operating characteristic curve 
      (AUC-ROC) for ChatGPT, the neurointensivist, the non-neurointensivist, and IMPACT 
      were, respectively, 0.62 (0.50-0.74), 0.70 (0.59-0.82), 0.71 (0.59-0.82), and 
      0.81 (0.72-0.91). ChatGPT had the highest sensitivity (100%), but the lowest 
      specificity (26%). For secondary outcomes, ChatGPT's prognoses were generally 
      less accurate than clinicians' prognoses, with lower AUC values for most 
      outcomes. CONCLUSIONS: This study does not support the use of ChatGPT for 
      prediction of outcomes after TBI.
CI  - Copyright © 2024 by the Society of Critical Care Medicine and Wolters Kluwer 
      Health, Inc. All Rights Reserved.
FAU - Gakuba, Clement
AU  - Gakuba C
AD  - CHU de Caen Normandie, Department of Anesthesiology and Critical Care Medicine, 
      Caen, France.
AD  - Normandie Univ, UNICAEN, INSERM, U1237, PhIND "Physiopathology and imaging of 
      Neurological Disorders", Institut Blood and Brain @ Caen-Normandie, Cyceron, 
      Caen, France.
FAU - Le Barbey, Charlene
AU  - Le Barbey C
AD  - CHU de Caen Normandie, Department of Anesthesiology and Critical Care Medicine, 
      Caen, France.
FAU - Sar, Alexandre
AU  - Sar A
AD  - CHU de Caen Normandie, Department of Anesthesiology and Critical Care Medicine, 
      Caen, France.
FAU - Bonnet, Gregory
AU  - Bonnet G
AD  - Normandie Univ, UNICAEN, ENSICAEN, CNRS, Department of Groupe de Recherche en 
      Informatique, Image, et Instrumentation de Caen (GREYC), Caen, France.
FAU - Cerasuolo, Damiano
AU  - Cerasuolo D
AD  - CHU de Caen Normandie, Department of Public Health, Caen, France.
AD  - Normandie Univ, UNICAEN, INSERM U1086, ANTICIPE, Caen, France.
FAU - Giabicani, Mikhael
AU  - Giabicani M
AD  - Department of Anaesthesiology and Critical Care, Beaujon Hospital, DMU Parabol, 
      AP-HP Nord, Paris, France.
FAU - Moyer, Jean-Denis
AU  - Moyer JD
AD  - CHU de Caen Normandie, Department of Anesthesiology and Critical Care Medicine, 
      Caen, France.
LA  - eng
PT  - Journal Article
DEP - 20240306
PL  - United States
TA  - Crit Care Med
JT  - Critical care medicine
JID - 0355501
SB  - IM
COIS- The authors have disclosed that they do not have any potential conflicts of 
      interest.
EDAT- 2024/03/06 12:44
MHDA- 2024/03/06 12:44
CRDT- 2024/03/06 09:33
PHST- 2024/03/06 12:44 [medline]
PHST- 2024/03/06 12:44 [pubmed]
PHST- 2024/03/06 09:33 [entrez]
AID - 00003246-990000000-00302 [pii]
AID - 10.1097/CCM.0000000000006236 [doi]
PST - aheadofprint
SO  - Crit Care Med. 2024 Mar 6. doi: 10.1097/CCM.0000000000006236.

PMID- 37516804
OWN - NLM
STAT- MEDLINE
DCOM- 20240221
LR  - 20240222
IS  - 1476-5608 (Electronic)
IS  - 1365-7852 (Linking)
VI  - 27
IP  - 1
DP  - 2024 Mar
TI  - Quality of information and appropriateness of ChatGPT outputs for urology 
      patients.
PG  - 103-108
LID - 10.1038/s41391-023-00705-y [doi]
AB  - BACKGROUND: The proportion of health-related searches on the internet is 
      continuously growing. ChatGPT, a natural language processing (NLP) tool created 
      by OpenAI, has been gaining increasing user attention and can potentially be used 
      as a source for obtaining information related to health concerns. This study aims 
      to analyze the quality and appropriateness of ChatGPT's responses to Urology case 
      studies compared to those of a urologist. METHODS: Data from 100 patient case 
      studies, comprising patient demographics, medical history, and urologic 
      complaints, were sequentially inputted into ChatGPT, one by one. A question was 
      posed to determine the most likely diagnosis, suggested examinations, and 
      treatment options. The responses generated by ChatGPT were then compared to those 
      provided by a board-certified urologist who was blinded to ChatGPT's responses 
      and graded on a 5-point Likert scale based on accuracy, comprehensiveness, and 
      clarity as criterias for appropriateness. The quality of information was graded 
      based on the section 2 of the DISCERN tool and readability assessments were 
      performed using the Flesch Reading Ease (FRE) and Flesch-Kincaid Reading Grade 
      Level (FKGL) formulas. RESULTS: 52% of all responses were deemed appropriate. 
      ChatGPT provided more appropriate responses for non-oncology conditions (58.5%) 
      compared to oncology (52.6%) and emergency urology cases (11.1%) (p = 0.03). The 
      median score of the DISCERN tool was 15 (IQR = 5.3) corresponding to a quality 
      score of poor. The ChatGPT responses demonstrated a college graduate reading 
      level, as indicated by the median FRE score of 18 (IQR = 21) and the median FKGL 
      score of 15.8 (IQR = 3). CONCLUSIONS: ChatGPT serves as an interactive tool for 
      providing medical information online, offering the possibility of enhancing 
      health outcomes and patient satisfaction. Nevertheless, the insufficient 
      appropriateness and poor quality of the responses on Urology cases emphasizes the 
      importance of thorough evaluation and use of NLP-generated outputs when 
      addressing health-related concerns.
CI  - © 2023. The Author(s), under exclusive licence to Springer Nature Limited.
FAU - Cocci, Andrea
AU  - Cocci A
AUID- ORCID: 0000-0003-0138-6294
AD  - Urology Section, University of Florence, Florence, Italy. cocci.andrea@gmail.com.
FAU - Pezzoli, Marta
AU  - Pezzoli M
AUID- ORCID: 0009-0007-7168-5499
AD  - Urology Section, University of Florence, Florence, Italy.
FAU - Lo Re, Mattia
AU  - Lo Re M
AD  - Urology Section, University of Florence, Florence, Italy.
FAU - Russo, Giorgio Ivan
AU  - Russo GI
AUID- ORCID: 0000-0003-4687-7353
AD  - Urology Section, University of Catania, Catania, Italy.
FAU - Asmundo, Maria Giovanna
AU  - Asmundo MG
AD  - Urology Section, University of Catania, Catania, Italy.
FAU - Fode, Mikkel
AU  - Fode M
AUID- ORCID: 0000-0002-8963-4581
AD  - Department of Clinical Medicine, University of Copenhagen, Copenhagen, Denmark.
AD  - Department of Urology, Copenhagen University Hospital, Herlev and Gentofte 
      Hospital, Copenhagen, Denmark.
FAU - Cacciamani, Giovanni
AU  - Cacciamani G
AD  - Institute of Urology, Keck School of Medicine, University of Southern California 
      (USC), Los Angeles, CA, USA.
FAU - Cimino, Sebastiano
AU  - Cimino S
AD  - Urology Section, University of Catania, Catania, Italy.
FAU - Minervini, Andrea
AU  - Minervini A
AD  - Urology Section, University of Florence, Florence, Italy.
FAU - Durukan, Emil
AU  - Durukan E
AUID- ORCID: 0000-0001-9221-8944
AD  - Department of Urology, Copenhagen University Hospital, Herlev and Gentofte 
      Hospital, Copenhagen, Denmark.
LA  - eng
PT  - Journal Article
DEP - 20230729
PL  - England
TA  - Prostate Cancer Prostatic Dis
JT  - Prostate cancer and prostatic diseases
JID - 9815755
SB  - IM
MH  - Male
MH  - Humans
MH  - *Urology
MH  - *Prostatic Neoplasms
MH  - Urologists
MH  - Educational Status
MH  - Internet
EDAT- 2023/07/30 01:06
MHDA- 2024/02/21 11:15
CRDT- 2023/07/29 23:21
PHST- 2023/05/30 00:00 [received]
PHST- 2023/07/17 00:00 [accepted]
PHST- 2023/06/22 00:00 [revised]
PHST- 2024/02/21 11:15 [medline]
PHST- 2023/07/30 01:06 [pubmed]
PHST- 2023/07/29 23:21 [entrez]
AID - 10.1038/s41391-023-00705-y [pii]
AID - 10.1038/s41391-023-00705-y [doi]
PST - ppublish
SO  - Prostate Cancer Prostatic Dis. 2024 Mar;27(1):103-108. doi: 
      10.1038/s41391-023-00705-y. Epub 2023 Jul 29.

PMID- 37217092
OWN - NLM
STAT- MEDLINE
DCOM- 20230904
LR  - 20231030
IS  - 1556-5653 (Electronic)
IS  - 0015-0282 (Linking)
VI  - 120
IP  - 3 Pt 2
DP  - 2023 Sep
TI  - The promise and peril of using a large language model to obtain clinical 
      information: ChatGPT performs strongly as a fertility counseling tool with 
      limitations.
PG  - 575-583
LID - S0015-0282(23)00522-8 [pii]
LID - 10.1016/j.fertnstert.2023.05.151 [doi]
AB  - OBJECTIVE: To compare the responses of the large language model-based "ChatGPT" 
      to reputable sources when given fertility-related clinical prompts. DESIGN: The 
      "Feb 13" version of ChatGPT by OpenAI was tested against established sources 
      relating to patient-oriented clinical information: 17 "frequently asked questions 
      (FAQs)" about infertility on the Centers for Disease Control (CDC) Website, 
      2&nbsp;validated fertility knowledge surveys, the Cardiff Fertility Knowledge Scale 
      and the Fertility and Infertility Treatment Knowledge Score, as well as the 
      American Society for Reproductive Medicine committee opinion "optimizing natural 
      fertility." SETTING: Academic medical center. PATIENT(S): Online AI Chatbot. 
      INTERVENTION(S): Frequently asked questions, survey questions and rephrased 
      summary statements were entered as prompts in the chatbot over a 1-week period in 
      February&nbsp;2023. MAIN OUTCOME MEASURE(S): For FAQs from CDC: words/response, 
      sentiment analysis polarity and objectivity, total factual statements, rate of 
      statements that were incorrect, referenced a source, or noted the value of 
      consulting providers. FOR FERTILITY KNOWLEDGE SURVEYS: Percentile according to 
      published population data. FOR COMMITTEE OPINION: Whether response to conclusions 
      rephrased as questions identified missing facts. RESULT(S): When administered the 
      CDC's 17 infertility FAQ's, ChatGPT produced responses of similar length (207.8 
      ChatGPT vs. 181.0 CDC words/response), factual content (8.65 factual 
      statements/response vs. 10.41), sentiment polarity (mean 0.11 vs. 0.11 on a scale 
      of -1 (negative) to 1 (positive)), and subjectivity (mean 0.42 vs. 0.35 on a 
      scale of 0 (objective) to 1 (subjective)). In total, 9 (6.12%) of 147 ChatGPT 
      factual statements were categorized as incorrect, and only 1 (0.68%) statement 
      cited a reference. ChatGPT would have been at the 87th percentile of Bunting's 
      2013 international cohort for the Cardiff Fertility&nbsp;Knowledge Scale and at the 
      95th percentile on the basis of Kudesia's 2017 cohort for the Fertility and 
      Infertility Treatment&nbsp;Knowledge Score. ChatGPT reproduced the missing facts for 
      all 7 summary statements from "optimizing natural fertility." CONCLUSION(S): A 
      February 2023 version of "ChatGPT" demonstrates the ability of generative 
      artificial intelligence to produce relevant, meaningful responses to 
      fertility-related clinical queries comparable to established sources. Although 
      performance may improve with medical domain-specific training, limitations such 
      as the inability to reliably cite sources and the unpredictable possibility of 
      fabricated information may limit its clinical use.
CI  - Copyright © 2023 The Authors. Published by Elsevier Inc. All rights reserved.
FAU - Chervenak, Joseph
AU  - Chervenak J
AD  - Albert Einstein College of Medicine/Montefiore's Institute for Reproductive 
      Medicine and Health, Hartsdale, New York. Electronic address: 
      joseph.chervenak@gmail.com.
FAU - Lieman, Harry
AU  - Lieman H
AD  - Albert Einstein College of Medicine/Montefiore's Institute for Reproductive 
      Medicine and Health, Hartsdale, New York.
FAU - Blanco-Breindel, Miranda
AU  - Blanco-Breindel M
AD  - Albert Einstein College of Medicine/Montefiore's Institute for Reproductive 
      Medicine and Health, Hartsdale, New York.
FAU - Jindal, Sangita
AU  - Jindal S
AD  - Albert Einstein College of Medicine/Montefiore's Institute for Reproductive 
      Medicine and Health, Hartsdale, New York.
LA  - eng
PT  - Journal Article
DEP - 20230520
PL  - United States
TA  - Fertil Steril
JT  - Fertility and sterility
JID - 0372772
SB  - IM
CIN - Fertil Steril. 2023 Sep;120(3 Pt 2):584-585. PMID: 37356469
CIN - Fertil Steril. 2023 Nov;120(5):1084. PMID: 37506761
MH  - Humans
MH  - *Artificial Intelligence
MH  - Counseling
MH  - Fertility
MH  - *Infertility/diagnosis/therapy
MH  - Language
OTO - NOTNLM
OT  - Artificial intelligence
OT  - counseling
OT  - fertility knowledge
OT  - natural language processing
OT  - online
EDAT- 2023/05/23 01:06
MHDA- 2023/09/04 06:42
CRDT- 2023/05/22 19:20
PHST- 2023/02/26 00:00 [received]
PHST- 2023/05/01 00:00 [revised]
PHST- 2023/05/12 00:00 [accepted]
PHST- 2023/09/04 06:42 [medline]
PHST- 2023/05/23 01:06 [pubmed]
PHST- 2023/05/22 19:20 [entrez]
AID - S0015-0282(23)00522-8 [pii]
AID - 10.1016/j.fertnstert.2023.05.151 [doi]
PST - ppublish
SO  - Fertil Steril. 2023 Sep;120(3 Pt 2):575-583. doi: 
      10.1016/j.fertnstert.2023.05.151. Epub 2023 May 20.

PMID- 37519497
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230801
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 6
DP  - 2023 Jun
TI  - Analysing the Applicability of ChatGPT, Bard, and Bing to Generate 
      Reasoning-Based Multiple-Choice Questions in Medical Physiology.
PG  - e40977
LID - 10.7759/cureus.40977 [doi]
LID - e40977
AB  - Background Artificial intelligence (AI) is evolving in the medical education 
      system. ChatGPT, Google Bard, and Microsoft Bing are AI-based models that can 
      solve problems in medical education. However, the applicability of AI to create 
      reasoning-based multiple-choice questions (MCQs) in the field of medical 
      physiology is yet to be explored. Objective We aimed to assess and compare the 
      applicability of ChatGPT, Bard, and Bing in generating reasoning-based MCQs for 
      MBBS (Bachelor of Medicine, Bachelor of Surgery) undergraduate students on the 
      subject of physiology. Methods The National Medical Commission of India has 
      developed an 11-module physiology curriculum with various competencies. Two 
      physiologists independently chose a competency from each module. The third 
      physiologist prompted all three AIs to generate five MCQs for each chosen 
      competency. The two physiologists who provided the competencies rated the MCQs 
      generated by the AIs on a scale of 0-3 for validity, difficulty, and reasoning 
      ability required to answer them. We analyzed the average of the two scores using 
      the Kruskal-Wallis test to compare the distribution across the total and 
      module-wise responses, followed by a post-hoc test for pairwise comparisons. We 
      used Cohen's Kappa (Κ) to assess the agreement in scores between the two raters. 
      We expressed the data as a median with an interquartile range. We determined 
      their statistical significance by a p-value &lt;0.05. Results ChatGPT and Bard 
      generated 110 MCQs for the chosen competencies. However, Bing provided only 100 
      MCQs as it failed to generate them for two competencies. The validity of the MCQs 
      was rated as 3 (3-3) for ChatGPT, 3 (1.5-3) for Bard, and 3 (1.5-3) for Bing, 
      showing a significant difference (p&lt;0.001) among the models. The difficulty of 
      the MCQs was rated as 1 (0-1) for ChatGPT, 1 (1-2) for Bard, and 1 (1-2) for 
      Bing, with a significant difference (p=0.006). The required reasoning ability to 
      answer the MCQs was rated as 1 (1-2) for ChatGPT, 1 (1-2) for Bard, and 1 (1-2) 
      for Bing, with no significant difference (p=0.235). K was ≥ 0.8 for all three 
      parameters across all three AI models. Conclusion AI still needs to evolve to 
      generate reasoning-based MCQs in medical physiology. ChatGPT, Bard, and Bing 
      showed certain limitations. Bing generated significantly least valid MCQs, while 
      ChatGPT generated significantly least difficult MCQs.
CI  - Copyright © 2023, Agarwal et al.
FAU - Agarwal, Mayank
AU  - Agarwal M
AD  - Physiology, All India Institute of Medical Sciences, Raebareli, IND.
FAU - Sharma, Priyanka
AU  - Sharma P
AD  - Physiology, School of Medical Sciences and Research, Sharda University, Greater 
      Noida, IND.
FAU - Goswami, Ayan
AU  - Goswami A
AD  - Physiology, Santiniketan Medical College, Bolpur, IND.
LA  - eng
PT  - Journal Article
DEP - 20230626
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10372539
OTO - NOTNLM
OT  - artificial intelligence
OT  - educational technology
OT  - examination questions
OT  - medical education
OT  - physiology
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/07/31 06:42
MHDA- 2023/07/31 06:43
PMCR- 2023/06/26
CRDT- 2023/07/31 04:38
PHST- 2023/06/26 00:00 [accepted]
PHST- 2023/07/31 06:43 [medline]
PHST- 2023/07/31 06:42 [pubmed]
PHST- 2023/07/31 04:38 [entrez]
PHST- 2023/06/26 00:00 [pmc-release]
AID - 10.7759/cureus.40977 [doi]
PST - epublish
SO  - Cureus. 2023 Jun 26;15(6):e40977. doi: 10.7759/cureus.40977. eCollection 2023 
      Jun.

PMID- 38308014
OWN - NLM
STAT- MEDLINE
DCOM- 20240205
LR  - 20240206
IS  - 2045-2322 (Electronic)
IS  - 2045-2322 (Linking)
VI  - 14
IP  - 1
DP  - 2024 Feb 2
TI  - A pilot study of measuring emotional response and perception of LLM-generated 
      questionnaire and human-generated questionnaires.
PG  - 2781
LID - 10.1038/s41598-024-53255-1 [doi]
LID - 2781
AB  - The advent of ChatGPT has sparked a heated debate surrounding natural language 
      processing technology and AI-powered chatbots, leading to extensive research and 
      applications across various disciplines. This pilot study aims to investigate the 
      impact of ChatGPT on users' experiences by administering two distinct 
      questionnaires, one generated by humans and the other by ChatGPT, along with an 
      Emotion Detecting Model. A total of 14 participants (7 female and 7 male) aged 
      between 18 and 35&nbsp;years were recruited, resulting in the collection of 8672 
      ChatGPT-associated data points and 8797 human-associated data points. Data 
      analysis was conducted using Analysis of Variance (ANOVA). The results indicate 
      that the utilization of ChatGPT enhances participants' happiness levels and 
      reduces their sadness levels. While no significant gender influences were 
      observed, variations were found about specific emotions. It is important to note 
      that the limited sample size, narrow age range, and potential cultural impacts 
      restrict the generalizability of the findings to a broader population. Future 
      research directions should explore the impact of incorporating additional 
      language models or chatbots on user emotions, particularly among specific age 
      groups such as older individuals and teenagers. As one of the pioneering works 
      evaluating the human perception of ChatGPT text and communication, it is 
      noteworthy that ChatGPT received positive evaluations and demonstrated 
      effectiveness in generating extensive questionnaires.
CI  - © 2024. The Author(s).
FAU - Zou, Zhao
AU  - Zou Z
AUID- ORCID: 0000-0002-2867-7246
AD  - School of Computer, Data and Mathematical Science, Western Sydney University, 
      Sydney, Australia.
FAU - Mubin, Omar
AU  - Mubin O
AUID- ORCID: 0000-0002-6435-6407
AD  - School of Computer, Data and Mathematical Science, Western Sydney University, 
      Sydney, Australia.
FAU - Alnajjar, Fady
AU  - Alnajjar F
AUID- ORCID: 0000-0001-6102-3765
AD  - College of Information Technology, United Arab Emirates University, Al Ain, 
      United Arab Emirates. fady.alnajjar@uaeu.ac.ae.
FAU - Ali, Luqman
AU  - Ali L
AUID- ORCID: 0000-0001-5996-7804
AD  - College of Information Technology, United Arab Emirates University, Al Ain, 
      United Arab Emirates.
LA  - eng
PT  - Journal Article
DEP - 20240202
PL  - England
TA  - Sci Rep
JT  - Scientific reports
JID - 101563288
SB  - IM
MH  - Adolescent
MH  - Humans
MH  - Female
MH  - Male
MH  - Young Adult
MH  - Adult
MH  - Pilot Projects
MH  - *Emotions
MH  - *Happiness
MH  - Sadness
MH  - Perception
PMC - PMC10837442
COIS- The authors declare no competing interests.
EDAT- 2024/02/03 00:41
MHDA- 2024/02/05 06:43
PMCR- 2024/02/02
CRDT- 2024/02/02 23:44
PHST- 2023/06/12 00:00 [received]
PHST- 2024/01/30 00:00 [accepted]
PHST- 2024/02/05 06:43 [medline]
PHST- 2024/02/03 00:41 [pubmed]
PHST- 2024/02/02 23:44 [entrez]
PHST- 2024/02/02 00:00 [pmc-release]
AID - 10.1038/s41598-024-53255-1 [pii]
AID - 53255 [pii]
AID - 10.1038/s41598-024-53255-1 [doi]
PST - epublish
SO  - Sci Rep. 2024 Feb 2;14(1):2781. doi: 10.1038/s41598-024-53255-1.

PMID- 38239905
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240121
IS  - 1664-0640 (Print)
IS  - 1664-0640 (Electronic)
IS  - 1664-0640 (Linking)
VI  - 14
DP  - 2023
TI  - ChatGPT is not ready yet for use in providing mental health assessment and 
      interventions.
PG  - 1277756
LID - 10.3389/fpsyt.2023.1277756 [doi]
LID - 1277756
AB  - BACKGROUND: Psychiatry is a specialized field of medicine that focuses on the 
      diagnosis, treatment, and prevention of mental health disorders. With 
      advancements in technology and the rise of artificial intelligence (AI), there 
      has been a growing interest in exploring the potential of AI language models 
      systems, such as Chat Generative Pre-training Transformer (ChatGPT), to assist in 
      the field of psychiatry. OBJECTIVE: Our study aimed to evaluates the 
      effectiveness, reliability and safeness of ChatGPT in assisting patients with 
      mental health problems, and to assess its potential as a collaborative tool for 
      mental health professionals through a simulated interaction with three distinct 
      imaginary patients. METHODS: Three imaginary patient scenarios (cases A, B, and 
      C) were created, representing different mental health problems. All three 
      patients present with, and seek to eliminate, the same chief complaint (i.e., 
      difficulty falling asleep and waking up frequently during the night in the last 
      2°weeks). ChatGPT was engaged as a virtual psychiatric assistant to provide 
      responses and treatment recommendations. RESULTS: In case A, the recommendations 
      were relatively appropriate (albeit non-specific), and could potentially be 
      beneficial for both users and clinicians. However, as complexity of clinical 
      cases increased (cases B and C), the information and recommendations generated by 
      ChatGPT became inappropriate, even dangerous; and the limitations of the program 
      became more glaring. The main strengths of ChatGPT lie in its ability to provide 
      quick responses to user queries and to simulate empathy. One notable limitation 
      is ChatGPT inability to interact with users to collect further information 
      relevant to the diagnosis and management of a patient's clinical condition. 
      Another serious limitation is ChatGPT inability to use critical thinking and 
      clinical judgment to drive patient's management. CONCLUSION: As for July 2023, 
      ChatGPT failed to give the simple medical advice given certain clinical 
      scenarios. This supports that the quality of ChatGPT-generated content is still 
      far from being a guide for users and professionals to provide accurate mental 
      health information. It remains, therefore, premature to conclude on the 
      usefulness and safety of ChatGPT in mental health practice.
CI  - Copyright © 2024 Dergaa, Fekih-Romdhane, Hallit, Loch, Glenn, Fessi, Ben Aissa, 
      Souissi, Guelmami, Swed, El Omri, Bragazzi and Ben Saad.
FAU - Dergaa, Ismail
AU  - Dergaa I
AD  - Primary Health Care Corporation (PHCC), Doha, Qatar.
AD  - Research Unit Physical Activity, Sport, and Health, UR18JS01, National 
      Observatory of Sport, Tunis, Tunisia.
AD  - High Institute of Sport and Physical Education, University of Sfax, Sfax, 
      Tunisia.
FAU - Fekih-Romdhane, Feten
AU  - Fekih-Romdhane F
AD  - The Tunisian Center of Early Intervention in Psychosis, Department of Psychiatry 
      "Ibn Omrane", Razi Hospital, Manouba, Tunisia.
AD  - Faculty of Medicine of Tunis, Tunis El Manar University, Tunis, Tunisia.
FAU - Hallit, Souheil
AU  - Hallit S
AD  - School of Medicine and Medical Sciences, Holy Spirit University of Kaslik, 
      Jounieh, Lebanon.
AD  - Psychology Department, College of Humanities, Effat University, Jeddah, Saudi 
      Arabia.
AD  - Applied Science Research Center, Applied Science Private University, Amman, 
      Jordan.
FAU - Loch, Alexandre Andrade
AU  - Loch AA
AD  - Laboratorio de Neurociencias (LIM 27), Hospital das Clínicas HCFMUSP, Faculdade 
      de Medicina, Instituto de Psiquiatria, Universidade de Sao Paulo, São Paulo, 
      Brazil.
AD  - Instituto Nacional de Biomarcadores em Neuropsiquiatria (INBION), Conselho 
      Nacional de Desenvolvimento Científico e Tecnológico, São Paulo, Brazil.
FAU - Glenn, Jordan M
AU  - Glenn JM
AD  - Neurotrack Technologies, Redwood City, CA, United States.
FAU - Fessi, Mohamed Saifeddin
AU  - Fessi MS
AD  - High Institute of Sport and Physical Education, University of Sfax, Sfax, 
      Tunisia.
FAU - Ben Aissa, Mohamed
AU  - Ben Aissa M
AD  - Department of Human and Social Sciences, Higher Institute of Sport and Physical 
      Education of Kef, University of Jendouba, Jendouba, Tunisia.
FAU - Souissi, Nizar
AU  - Souissi N
AD  - Research Unit Physical Activity, Sport, and Health, UR18JS01, National 
      Observatory of Sport, Tunis, Tunisia.
FAU - Guelmami, Noomen
AU  - Guelmami N
AD  - Department of Health Sciences (DISSAL), Postgraduate School of Public Health, 
      University of Genoa, Genoa, Italy.
FAU - Swed, Sarya
AU  - Swed S
AD  - Faculty of Medicine, Aleppo University, Aleppo, Syria.
FAU - El Omri, Abdelfatteh
AU  - El Omri A
AD  - Surgical Research Section, Department of Surgery, Hamad Medical Corporation, 
      Doha, Qatar.
FAU - Bragazzi, Nicola Luigi
AU  - Bragazzi NL
AD  - Laboratory for Industrial and Applied Mathematics, Department of Mathematics and 
      Statistics, York University, Toronto, ON, Canada.
FAU - Ben Saad, Helmi
AU  - Ben Saad H
AD  - Service of Physiology and Functional Explorations, Farhat HACHED Hospital, 
      University of Sousse, Sousse, Tunisia.
AD  - Heart Failure (LR12SP09) Research Laboratory, Farhat HACHED Hospital, University 
      of Sousse, Sousse, Tunisia.
LA  - eng
PT  - Journal Article
DEP - 20240104
PL  - Switzerland
TA  - Front Psychiatry
JT  - Frontiers in psychiatry
JID - 101545006
PMC - PMC10794665
OTO - NOTNLM
OT  - anxiety
OT  - chatbots
OT  - depression
OT  - insomnia
OT  - language models
OT  - mental health
OT  - patient care
OT  - psychiatric disorders
COIS- JG was employed by Neurotrack Technologies. The remaining authors declare that 
      the research was conducted in the absence of any commercial or financial 
      relationships that could be construed as a potential conflict of interest. The 
      author(s) declared that they were an editorial board member of Frontiers, at the 
      time of submission. This had no impact on the peer review process and the final 
      decision.
EDAT- 2024/01/19 06:43
MHDA- 2024/01/19 06:44
PMCR- 2024/01/04
CRDT- 2024/01/19 03:48
PHST- 2023/08/15 00:00 [received]
PHST- 2023/11/17 00:00 [accepted]
PHST- 2024/01/19 06:44 [medline]
PHST- 2024/01/19 06:43 [pubmed]
PHST- 2024/01/19 03:48 [entrez]
PHST- 2024/01/04 00:00 [pmc-release]
AID - 10.3389/fpsyt.2023.1277756 [doi]
PST - epublish
SO  - Front Psychiatry. 2024 Jan 4;14:1277756. doi: 10.3389/fpsyt.2023.1277756. 
      eCollection 2023.

PMID- 38112605
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240128
IS  - 2037-7452 (Print)
IS  - 2037-7460 (Electronic)
IS  - 2037-7452 (Linking)
VI  - 33
IP  - 4
DP  - 2023 Dec 15
TI  - ChatGPT in the development of medical questionnaires. The example of the low back 
      pain.
LID - 10.4081/ejtm.2023.12114 [doi]
LID - 12114
AB  - In the last year, Chat Generative Pre-Trained Transformer (ChatGPT), a web 
      software based on artificial intelligence has been showing high potential in 
      every field of knowledge. In the medical area, its possible application is an 
      object of many studies with promising results. We performed the current study to 
      investigate the possible usefulness of ChatGPT in assessing low back pain. We 
      asked ChatGPT to generate a questionnaire about this clinical condition and we 
      compared the obtained questions and results with the ones obtained by other 
      validated questionnaires: Oswestry Disability Index, Quebec Back Pain Disability 
      Scale, Roland-Morris Disability Questionnaire, and Numeric Rating Scale for pain. 
      We enrolled 20 subjects with low back pain and we found important consistencies 
      among the validated questionnaires. The ChatGPT questionnaire showed an 
      acceptable significant correlation only with Oswestry Disability Index and Quebec 
      Back Pain Disability Scale. ChatGPT showed some peculiarities, especially in the 
      assessment of quality of life and medical consultation and treatments. Our study 
      shows that ChatGPT can help evaluate patients, including multilevel perspectives. 
      However, its power is limited, and further research and validation are required.
FAU - Coraci, Daniele
AU  - Coraci D
AD  - Department of Neuroscience, Section of Rehabilitation, University of Padova, 
      Padua. danielecoraci@aol.com.
FAU - Maccarone, Maria Chiara
AU  - Maccarone MC
AD  - Department of Neuroscience, Section of Rehabilitation, University of Padova, 
      Padua. mariachiara.maccarone93@gmail.com.
FAU - Regazzo, Gianluca
AU  - Regazzo G
AD  - Department of Neuroscience, Section of Rehabilitation, University of Padova, 
      Padua. gianlucareg@gmail.com.
FAU - Accordi, Giorgia
AU  - Accordi G
AD  - Department of Neuroscience, Section of Rehabilitation, University of Padova, 
      Padua. giorgia.accordi@studenti.unipd.it.
FAU - Papathanasiou, Jannis V
AU  - Papathanasiou JV
AD  - Department of Kinesiotherapy, Faculty of Public Health, Medical University of 
      Sofia, Sofia, Bulgaria; Department of Medical Imaging, Allergology and 
      Physiotherapy, Faculty of Dental Medicine, Medical University of Plovdiv, 
      Plovdiv. giannipap@yahoo.co.uk.
FAU - Masiero, Stefano
AU  - Masiero S
AD  - Department of Neuroscience, Section of Rehabilitation, University of Padova, 
      Padua. stef.masiero@unipd.it.
LA  - eng
PT  - Journal Article
DEP - 20231215
PL  - Italy
TA  - Eur J Transl Myol
JT  - European journal of translational myology
JID - 101576208
PMC - PMC10811646
COIS- We confirm that we have read the Journal’s position on issues involved in ethical 
      publication and affirm that this report is consistent with those guidelines. 
      During the last year, one of the potential greatest revolutions impacting 
      humankind has been happening: the worldwide availability of chatbots based on 
      artificial intelligence (AI). In particular, on November 30th, 2022, Chat 
      Generative Pre-Trained Transformer (ChatGPT) was released. It is an online 
      software able to communicate in a human-similar way and to answer specific 
      questions. Furthermore, as an AI system, it can learn from the information that 
      the user provides and dynamically interact with the human being.2 This type of 
      chatbot distinguishes itself from simple web-based software because of its 
      adaptability. Indeed, it can tailor its responses to various situations and to 
      learn from errors and diverse inputs. This capability is advantageous for solving 
      a wide range of problems by retrieving information from a vast dataset. Its 
      practical applications are highly diverse and may virtually include every field 
      of knowledge. For work activities, it can solve equations or help in computer 
      programming; for leisure time, it can provide suggestions about a trip or invent 
      a game; for daily life, it can support text or email writing; and so on. It has, 
      at the moment, different limitations, due to the information that the ChatGPT 
      programmers used to train it, covering a time range until the end of 2021, and to 
      the immaturity of some procedures. For example, ChatGPT has some difficulties in 
      elaborating very long or highly specific texts. Additionally, too complex tasks 
      can lead to errors and the accuracy of the responses depends on the precision of 
      the questions.1 Despite these current limitations, the chatbot has demonstrated 
      remarkable potential as an assistive technology and our comprehension of its 
      capabilities is probably only in the early stages. In the few months of its 
      availability, even in the medical field, we have been observing a growing 
      utilization with extraordinary outcomes. The tool can combine different 
      information from literature and scientific databases, contributing to the 
      interpretation of research findings or the discovery of new solutions for 
      projects. Various studies have identified potential roles for chatbots in 
      supporting physicians' training, particularly in summarizing patient variables 
      and extracting relevant information from extensive datasets, like big data 
      analysis. Moreover, for medical students, chatbots can assist in research, essay 
      writing, or thesis work. In the medical field, this AI can also support 
      patient-physician communication, simplifying medical explanations with everyday 
      language, assessing and consolidating symptom descriptions, and facilitating 
      translations of medical data into various languages. ChatGPT can also be 
      beneficial for patients, providing suggestions for a health or dietary plan or 
      indicating the most appropriate medical specialist. Importantly, the chatbot 
      underscores its restricted role in its responses, emphasizing the importance of 
      the consultation of an irreplaceable human expert in cases that require 
      specialized medical attention. Besides the incredible positive impact on the work 
      and the study, the risks of misunderstood are always behind the corner. 
      Additionally, the peril of dehumanization of medical activity and the tendency to 
      reduce the effort toward effective work are the potential side effects of the 
      increasing use of AI. Moreover, the utilization of this tool for certain tasks 
      raises complex ethical concerns, like the production of scientific items sold as 
      authors’ original production but really made by a computer. Therefore, currently, 
      ChatGPT cannot replace human doctors and scientists. Nonetheless, we should avoid 
      prejudicial judgment and we need to study all the main real effects that the 
      chatbot may produce. Considering its medical applications, limited examples may 
      be found in questionnaire assessments or in constructing new specific 
      questionnaires. The existing questionnaires for understanding patients' 
      perspectives on diseases are well-established, validated, and easy to administer. 
      However, there is a risk of incompleteness in these questionnaires. Furthermore, 
      as patient needs continually evolve with societal changes, updating historical 
      questionnaires becomes desirable. Typically, questionnaire development starts 
      with collecting qualitative or semi-quantitative data from a large database 
      obtained through a survey. The first problems in this procedure are related to 
      the choice of the initial questions and the answer options used for the survey, 
      the language, and, especially, the lexicon. Even the communication channel and 
      the correct choice of the interviewed people may greatly affect the answers. 
      After data collection, a simplification process is necessary to construct the 
      actual questionnaire, which must undergo testing for validity and reliability.9 
      Once a questionnaire passes these stages, additional processes of cross-cultural 
      validation and adaptation are needed for translation and application in cultures 
      and languages different from those for which the questionnaire was originally 
      developed.9 This brief description of the intense phases of questionnaire 
      development suggests the possible aid of ChatGPT for this purpose. The chatbot 
      can combine data from other existing questionnaires, and scientific and not 
      academic information from the entire world, and can translate the document with 
      precision. Building upon these considerations, we aim to create a questionnaire 
      for the assessment of [low back pain (LBP)] using ChatGPT and to evaluate its 
      effectiveness by comparing it with routinely used validated questionnaires.
EDAT- 2023/12/19 19:54
MHDA- 2023/12/19 19:55
PMCR- 2023/12/18
CRDT- 2023/12/19 11:06
PHST- 2023/11/21 00:00 [received]
PHST- 2023/12/04 00:00 [accepted]
PHST- 2023/12/19 19:55 [medline]
PHST- 2023/12/19 19:54 [pubmed]
PHST- 2023/12/19 11:06 [entrez]
PHST- 2023/12/18 00:00 [pmc-release]
AID - 10.4081/ejtm.2023.12114 [doi]
PST - epublish
SO  - Eur J Transl Myol. 2023 Dec 15;33(4):12114. doi: 10.4081/ejtm.2023.12114.

PMID- 38503659
OWN - NLM
STAT- Publisher
LR  - 20240319
IS  - 1878-3562 (Electronic)
IS  - 1590-8658 (Linking)
DP  - 2024 Mar 18
TI  - Charting new AI education in gastroenterology: Cross-sectional evaluation of 
      ChatGPT and perplexity AI in medical residency exam.
LID - S1590-8658(24)00302-5 [pii]
LID - 10.1016/j.dld.2024.02.019 [doi]
AB  - BACKGROUND: Conversational chatbots, fueled by large language models, spark 
      debate over their potential in education and medical career exams. There is 
      debate in the literature about the scientific integrity of the outputs produced 
      by these chatbots. AIMS: This study evaluates ChatGPT 3.5 and Perplexity AI's 
      cross-sectional performance in responding to questions from the 2023 Italian 
      national residency admission exam (SSM23), comparing results and chatbots' 
      concordance with previous years SSMs. METHODS: Gastroenterology-related SSM23 
      questions were input into ChatGPT 3.5 and Perplexity AI, evaluating their 
      performance in correct responses and total scores. This process was repeated with 
      questions from the three preceding years. Additionally, chatbot concordance was 
      assessed using Cohen's method. RESULTS: In SSM23, ChatGPT 3.5 outperforms 
      Perplexity AI with 94.11% correct responses, demonstrating consistency across 
      years. Concordance weakened in 2023 (κ=0.203, P = 0.148), but ChatGPT 
      consistently maintains a high standard compared to Perplexity AI. CONCLUSION: 
      ChatGPT 3.5 and Perplexity AI exhibit promise in addressing gastroenterological 
      queries, emphasizing potential educational roles. However, their variable 
      performance mandates cautious use as supplementary tools alongside conventional 
      study methods. Clear guidelines are crucial for educators to balance traditional 
      approaches and innovative systems, enhancing educational standards.
CI  - Copyright © 2024 Editrice Gastroenterologica Italiana S.r.l. Published by 
      Elsevier Ltd. All rights reserved.
FAU - Gravina, Antonietta Gerarda
AU  - Gravina AG
AD  - Hepatogastroenterology Division, Department of Precision Medicine, University of 
      Campania Luigi Vanvitelli, Via Luigi de Crecchio, 80138, Naples, Italy.
FAU - Pellegrino, Raffaele
AU  - Pellegrino R
AD  - Hepatogastroenterology Division, Department of Precision Medicine, University of 
      Campania Luigi Vanvitelli, Via Luigi de Crecchio, 80138, Naples, Italy. 
      Electronic address: raffaele.pellegrino@unicampania.it.
FAU - Palladino, Giovanna
AU  - Palladino G
AD  - Hepatogastroenterology Division, Department of Precision Medicine, University of 
      Campania Luigi Vanvitelli, Via Luigi de Crecchio, 80138, Naples, Italy.
FAU - Imperio, Giuseppe
AU  - Imperio G
AD  - Hepatogastroenterology Division, Department of Precision Medicine, University of 
      Campania Luigi Vanvitelli, Via Luigi de Crecchio, 80138, Naples, Italy.
FAU - Ventura, Andrea
AU  - Ventura A
AD  - Hepatogastroenterology Division, Department of Precision Medicine, University of 
      Campania Luigi Vanvitelli, Via Luigi de Crecchio, 80138, Naples, Italy.
FAU - Federico, Alessandro
AU  - Federico A
AD  - Hepatogastroenterology Division, Department of Precision Medicine, University of 
      Campania Luigi Vanvitelli, Via Luigi de Crecchio, 80138, Naples, Italy.
LA  - eng
PT  - Journal Article
DEP - 20240318
PL  - Netherlands
TA  - Dig Liver Dis
JT  - Digestive and liver disease : official journal of the Italian Society of 
      Gastroenterology and the Italian Association for the Study of the Liver
JID - 100958385
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Chatbots
OT  - Education
OT  - Medical residency
COIS- Declaration of competing interest The authors declare that they have no conflicts 
      of interest to disclose.
EDAT- 2024/03/20 00:42
MHDA- 2024/03/20 00:42
CRDT- 2024/03/19 23:01
PHST- 2024/01/10 00:00 [received]
PHST- 2024/02/08 00:00 [revised]
PHST- 2024/02/28 00:00 [accepted]
PHST- 2024/03/20 00:42 [medline]
PHST- 2024/03/20 00:42 [pubmed]
PHST- 2024/03/19 23:01 [entrez]
AID - S1590-8658(24)00302-5 [pii]
AID - 10.1016/j.dld.2024.02.019 [doi]
PST - aheadofprint
SO  - Dig Liver Dis. 2024 Mar 18:S1590-8658(24)00302-5. doi: 10.1016/j.dld.2024.02.019.

PMID- 37606000
OWN - NLM
STAT- Publisher
LR  - 20230930
IS  - 1552-4876 (Electronic)
IS  - 1552-4868 (Linking)
VI  - 193
IP  - 3
DP  - 2023 Sep
TI  - Is artificial intelligence getting too much credit in medical genetics?
PG  - e32062
LID - 10.1002/ajmg.c.32062 [doi]
AB  - Artificial intelligence has lately proven useful in the field of medical 
      genetics. It is already being used to interpret genome sequences and diagnose 
      patients based on facial recognition. More recently, large-language models (LLMs) 
      such as ChatGPT have been tested for their capacity to provide medical genetics 
      information. It was found that ChatGPT performed similarly to human respondents 
      in factual and critical thinking questions, albeit with reduced accuracy in the 
      latter. In particular, ChatGPT's performance in questions related to calculating 
      the recurrence risk was dismal, despite only having to deal with a single 
      disease. To see if challenging ChatGPT with more difficult problems may reveal 
      its flaws and their bases, it was asked to solve recurrence risk problems dealing 
      with two diseases instead of one. Interestingly, it managed to correctly 
      understand the mode of inheritance of recessive diseases, yet it incorrectly 
      calculated the probability of having a healthy child. Other LLMs were also tested 
      and showed similar noise. This highlights a major limitation for clinical use. 
      While this shortcoming may be solved in the near future, LLMs may not be ready 
      yet to be used as an effective clinical tool in communicating medical genetics 
      information.
CI  - © 2023 Wiley Periodicals LLC.
FAU - Alkuraya, Imen F
AU  - Alkuraya IF
AUID- ORCID: 0009-0002-1764-7938
AD  - Abdulaziz International School, Riyadh, Saudi Arabia.
LA  - eng
PT  - Journal Article
DEP - 20230822
PL  - United States
TA  - Am J Med Genet C Semin Med Genet
JT  - American journal of medical genetics. Part C, Seminars in medical genetics
JID - 101235745
SB  - IM
OTO - NOTNLM
OT  - Bard
OT  - ChatGPT
OT  - Claude
OT  - benchmarking
OT  - large-language model
EDAT- 2023/08/22 06:42
MHDA- 2023/08/22 06:42
CRDT- 2023/08/22 05:53
PHST- 2023/08/08 00:00 [received]
PHST- 2023/08/09 00:00 [accepted]
PHST- 2023/08/22 06:42 [pubmed]
PHST- 2023/08/22 06:42 [medline]
PHST- 2023/08/22 05:53 [entrez]
AID - 10.1002/ajmg.c.32062 [doi]
PST - ppublish
SO  - Am J Med Genet C Semin Med Genet. 2023 Sep;193(3):e32062. doi: 
      10.1002/ajmg.c.32062. Epub 2023 Aug 22.

PMID- 37601325
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230823
IS  - 1178-2390 (Print)
IS  - 1178-2390 (Electronic)
IS  - 1178-2390 (Linking)
VI  - 16
DP  - 2023
TI  - Impact of ChatGPT on Teleconsultants in Healthcare: Perceptions of Healthcare 
      Experts in Saudi Arabia.
PG  - 2309-2321
LID - 10.2147/JMDH.S419847 [doi]
AB  - PURPOSE: This study aims to investigate the impact of ChatGPT on teleconsultants 
      in managing their operations and services. METHODS: A qualitative approach with 
      focus groups is adopted in this study. A total of 54 participants with varying 
      degrees of experience using AI such as ChatGPT in healthcare, including 11 
      physicians, 24 nurses, eight dieticians, six pharmacists, and five 
      physiotherapists providing teleconsultations participated in this study. RESULTS: 
      Twelve themes including informational support, diagnostic assistance, 
      communication, enhancing efficiency, cost and time saving, personalizing care, 
      multilingual support, assisting in medical research, decision-making, 
      documentation, continuing education, and enhanced team collaboration reflecting 
      positive impact were identified from the data analysis of seven focus groups. In 
      addition, six themes including misdiagnosis and errors, issues in personalized 
      care, ethical and legal issues, limited medical context/knowledge, communication 
      challenges, and increased dependency reflecting negative impact were identified. 
      CONCLUSION: Although ChatGPT has several advantages for teleconsultants in the 
      healthcare sector, it is associated with ethical issues.
CI  - © 2023 Alanzi.
FAU - Alanzi, Turki M
AU  - Alanzi TM
AUID- ORCID: 0000-0001-6598-1274
AD  - Health Information Management and Technology Department, College of Public 
      Health, Imam Abdulrahman Bin Faisal University, Dammam, Saudi Arabia.
LA  - eng
PT  - Journal Article
DEP - 20230814
PL  - New Zealand
TA  - J Multidiscip Healthc
JT  - Journal of multidisciplinary healthcare
JID - 101512691
PMC - PMC10438433
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - artificial intelligence
OT  - decision-making
OT  - healthcare
OT  - information
OT  - teleconsultants
COIS- The authors report no conflicts of interest in this work.
EDAT- 2023/08/21 06:43
MHDA- 2023/08/21 06:44
PMCR- 2023/08/14
CRDT- 2023/08/21 04:59
PHST- 2023/05/04 00:00 [received]
PHST- 2023/08/01 00:00 [accepted]
PHST- 2023/08/21 06:44 [medline]
PHST- 2023/08/21 06:43 [pubmed]
PHST- 2023/08/21 04:59 [entrez]
PHST- 2023/08/14 00:00 [pmc-release]
AID - 419847 [pii]
AID - 10.2147/JMDH.S419847 [doi]
PST - epublish
SO  - J Multidiscip Healthc. 2023 Aug 14;16:2309-2321. doi: 10.2147/JMDH.S419847. 
      eCollection 2023.

PMID- 37487184
OWN - NLM
STAT- Publisher
LR  - 20231020
IS  - 1536-0075 (Electronic)
IS  - 1526-5161 (Linking)
VI  - 23
IP  - 10
DP  - 2023 Oct
TI  - Ethics Education for Healthcare Professionals in the Era of ChatGPT and Other 
      Large Language Models: Do We Still Need It?
PG  - 17-27
LID - 10.1080/15265161.2023.2233358 [doi]
AB  - In this paper, we contend with whether we still need traditional ethics education 
      as part of healthcare professional training given the abilities of chatGPT 
      (generative pre-trained transformer) and other large language models (LLM). We 
      reflect on common programmatic goals to assess the current strengths and 
      limitations of LLMs in helping to build ethics competencies among future 
      clinicians. Through an actual case analysis, we highlight areas in which chatGPT 
      and other LLMs are conducive to common bioethics education goals. We also comment 
      on where such technologies remain an imperfect substitute for human-led ethics 
      teaching and learning. Finally, we conclude that the relative strengths of 
      chatGPT warrant its consideration as a teaching and learning tool in ethics 
      education in ways that account for current limitations and build in flexibility 
      as the technology evolves.
FAU - Rahimzadeh, Vasiliki
AU  - Rahimzadeh V
AUID- ORCID: 0000-0003-3537-7601
AD  - Baylor College of Medicine.
FAU - Kostick-Quenet, Kristin
AU  - Kostick-Quenet K
AUID- ORCID: 0000-0003-2510-0174
AD  - Baylor College of Medicine.
FAU - Blumenthal Barby, Jennifer
AU  - Blumenthal Barby J
AUID- ORCID: 0000-0003-1054-619X
AD  - Baylor College of Medicine.
FAU - McGuire, Amy L
AU  - McGuire AL
AUID- ORCID: 0000-0002-7819-519X
AD  - Baylor College of Medicine.
LA  - eng
PT  - Journal Article
DEP - 20230724
PL  - United States
TA  - Am J Bioeth
JT  - The American journal of bioethics : AJOB
JID - 100898738
SB  - IM
CIN - Am J Bioeth. 2023 Oct;23(10):63-65. PMID: 37812097
CIN - Am J Bioeth. 2023 Oct;23(10):86-88. PMID: 37812108
CIN - Am J Bioeth. 2023 Oct;23(10):68-70. PMID: 37812111
CIN - Am J Bioeth. 2023 Oct;23(10):42-44. PMID: 37812114
CIN - Am J Bioeth. 2023 Oct;23(10):58-60. PMID: 37812118
CIN - Am J Bioeth. 2023 Oct;23(10):89-91. PMID: 37812124
CIN - Am J Bioeth. 2023 Oct;23(10):1-5. PMID: 37831940
OTO - NOTNLM
OT  - bioethics
OT  - chatGPT
OT  - healthcare professionals
OT  - medical education
EDAT- 2023/07/24 19:10
MHDA- 2023/07/24 19:10
CRDT- 2023/07/24 16:33
PHST- 2023/07/24 19:10 [pubmed]
PHST- 2023/07/24 19:10 [medline]
PHST- 2023/07/24 16:33 [entrez]
AID - 10.1080/15265161.2023.2233358 [doi]
PST - ppublish
SO  - Am J Bioeth. 2023 Oct;23(10):17-27. doi: 10.1080/15265161.2023.2233358. Epub 2023 
      Jul 24.

PMID- 37115245
OWN - NLM
STAT- MEDLINE
DCOM- 20230605
LR  - 20230605
IS  - 2193-6226 (Electronic)
IS  - 2193-6218 (Linking)
VI  - 118
IP  - 5
DP  - 2023 Jun
TI  - [Artificial intelligence: How will ChatGPT and other AI applications change our 
      everyday medical practice?].
PG  - 366-371
LID - 10.1007/s00063-023-01019-6 [doi]
AB  - BACKGROUND: With the free provision of the chat robot "ChatGPT" by the company 
      OpenAI in November 2022, an application of artificial intelligence (AI) became 
      tangible for everyone. OBJECTIVES: An explanation of the basic functionality of 
      large language models (LLM) is given, followed by a presentation of application 
      options of ChatGPT in medicine, and an outlook and discussion of possible dangers 
      of AI applications. METHODS: Problem solving with ChatGPT using concrete 
      examples. Analysis and discussion of the available scientific literature. 
      RESULTS: There has been a significant increase in the use of AI applications in 
      scientific work, especially in scientific writing. Wide application of LLM in 
      writing medical documentation is conceivable. Technical functionality allows the 
      use of AI applications as a&nbsp;diagnostic support system. There is a&nbsp;risk of 
      spreading and entrenching inaccuracies and bias through application of LLM. 
      Regulation of this new technology is pending. CONCLUSION: AI applications such as 
      ChatGPT have the potential to permanently change everyday medical practice. An 
      examination of this technology and evaluation of opportunities and risks is 
      warranted.
CI  - © 2023. The Author(s), under exclusive licence to Springer Medizin Verlag GmbH, 
      ein Teil von Springer Nature.
FAU - Sonntagbauer, Michael
AU  - Sonntagbauer M
AD  - Klinik für Intensivmedizin, Universitätsklinikum Hamburg-Eppendorf, O 10, Raum 
      02.5.062.1, Martinistr.&nbsp;52, 20251, Hamburg, Deutschland. m.sonntagbauer@uke.de.
FAU - Haar, Markus
AU  - Haar M
AD  - Klinik für Intensivmedizin, Universitätsklinikum Hamburg-Eppendorf, O 10, Raum 
      02.5.062.1, Martinistr.&nbsp;52, 20251, Hamburg, Deutschland.
FAU - Kluge, Stefan
AU  - Kluge S
AD  - Klinik für Intensivmedizin, Universitätsklinikum Hamburg-Eppendorf, O 10, Raum 
      02.5.062.1, Martinistr.&nbsp;52, 20251, Hamburg, Deutschland.
LA  - ger
PT  - English Abstract
PT  - Journal Article
PT  - Review
TT  - Künstliche Intelligenz: Wie werden ChatGPT und andere KI-Anwendungen unseren 
      ärztlichen Alltag verändern?
DEP - 20230428
PL  - Germany
TA  - Med Klin Intensivmed Notfmed
JT  - Medizinische Klinik, Intensivmedizin und Notfallmedizin
JID - 101575086
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Documentation
MH  - *Medicine
OTO - NOTNLM
OT  - Big data
OT  - Diagnostic support systems
OT  - Digitization in medicine
OT  - Large language models
OT  - Machine learning
EDAT- 2023/04/28 12:42
MHDA- 2023/06/05 06:42
CRDT- 2023/04/28 11:05
PHST- 2023/04/17 00:00 [received]
PHST- 2023/04/19 00:00 [accepted]
PHST- 2023/06/05 06:42 [medline]
PHST- 2023/04/28 12:42 [pubmed]
PHST- 2023/04/28 11:05 [entrez]
AID - 10.1007/s00063-023-01019-6 [pii]
AID - 10.1007/s00063-023-01019-6 [doi]
PST - ppublish
SO  - Med Klin Intensivmed Notfmed. 2023 Jun;118(5):366-371. doi: 
      10.1007/s00063-023-01019-6. Epub 2023 Apr 28.

PMID- 38295336
OWN - NLM
STAT- Publisher
LR  - 20240131
IS  - 1545-1569 (Electronic)
IS  - 1055-6656 (Linking)
DP  - 2024 Jan 31
TI  - CLP-Related Information for Patients Provided by ChatGPT: Comment.
PG  - 10556656241229275
LID - 10.1177/10556656241229275 [doi]
FAU - Daungsupawong, Hinpetch
AU  - Daungsupawong H
AUID- ORCID: 0009-0002-5881-2709
AD  - Private Academic Consultant, Phonhong, Lao People's Democratic Republic.
FAU - Wiwanitkit, Viroj
AU  - Wiwanitkit V
AD  - Research Center, Chandigarh University, Mohali, Punjab, India.
LA  - eng
PT  - Letter
DEP - 20240131
PL  - United States
TA  - Cleft Palate Craniofac J
JT  - The Cleft palate-craniofacial journal : official publication of the American 
      Cleft Palate-Craniofacial Association
JID - 9102566
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - information
OT  - patient
COIS- Declaration of Conflicting InterestsThe authors declared no potential conflicts 
      of interest with respect to the research, authorship, and/or publication of this 
      article.
EDAT- 2024/01/31 18:42
MHDA- 2024/01/31 18:42
CRDT- 2024/01/31 16:03
PHST- 2024/01/31 18:42 [medline]
PHST- 2024/01/31 18:42 [pubmed]
PHST- 2024/01/31 16:03 [entrez]
AID - 10.1177/10556656241229275 [doi]
PST - aheadofprint
SO  - Cleft Palate Craniofac J. 2024 Jan 31:10556656241229275. doi: 
      10.1177/10556656241229275.

PMID- 38275279
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240220
IS  - 1477-9234 (Electronic)
IS  - 1477-9226 (Linking)
VI  - 53
IP  - 8
DP  - 2024 Feb 20
TI  - Enhancing catalysis studies with chat generative pre-trained transformer 
      (ChatGPT): Conversation with ChatGPT.
PG  - 3534-3547
LID - 10.1039/d3dt04178f [doi]
AB  - The progress made in natural language processing (NLP) and large language models 
      (LLMs), such as generative pre-trained transformers, (GPT) has provided exciting 
      opportunities for enhancing research across various fields. Within the realm of 
      catalysis studies, GPT-driven models present valuable support in expediting the 
      exploration and comprehension of catalytic processes. This research underscores 
      the significance of ChatGPT in catalysis research, emphasizing its prowess as a 
      valuable tool for furthering scientific inquiries. It suggests that for an 
      outstanding oxygen evolution reaction (OER) catalyst as a case study, scientists 
      can leverage ChatGPT to extract deeper insights and brainstorm innovative 
      approaches to grasp the mechanism better and refine current systems.
FAU - Ansari, Navid
AU  - Ansari N
AD  - Max Planck Institute for Informatics Saarbrücken, Germany.
FAU - Babaei, Vahid
AU  - Babaei V
AD  - Max Planck Institute for Informatics Saarbrücken, Germany.
FAU - Najafpour, Mohammad Mahdi
AU  - Najafpour MM
AUID- ORCID: 0000-0001-9732-0016
AD  - Department of Chemistry, Institute for Advanced Studies in Basic Sciences 
      (IASBS), Zanjan, 45137-66731, Iran. mmnajafpour@iasbs.ac.ir.
AD  - Center of Climate Change and Global Warming, Institute for Advanced Studies in 
      Basic Sciences (IASBS), Zanjan, 45137-66731, Iran.
AD  - Research Center for Basic Sciences &amp; Modern Technologies (RBST), Institute for 
      Advanced Studies in Basic Sciences (IASBS), Zanjan, 45137-66731, Iran.
LA  - eng
PT  - Journal Article
DEP - 20240220
PL  - England
TA  - Dalton Trans
JT  - Dalton transactions (Cambridge, England : 2003)
JID - 101176026
SB  - IM
EDAT- 2024/01/26 12:44
MHDA- 2024/01/26 12:45
CRDT- 2024/01/26 08:32
PHST- 2024/01/26 12:45 [medline]
PHST- 2024/01/26 12:44 [pubmed]
PHST- 2024/01/26 08:32 [entrez]
AID - 10.1039/d3dt04178f [doi]
PST - epublish
SO  - Dalton Trans. 2024 Feb 20;53(8):3534-3547. doi: 10.1039/d3dt04178f.

PMID- 37250832
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230531
IS  - 2169-7574 (Print)
IS  - 2169-7574 (Electronic)
IS  - 2169-7574 (Linking)
VI  - 11
IP  - 5
DP  - 2023 May
TI  - Artificial or Augmented Authorship? A Conversation with a Chatbot on Base of 
      Thumb Arthritis.
PG  - e4999
LID - 10.1097/GOX.0000000000004999 [doi]
LID - e4999
AB  - ChatGPT is an open artificial intelligence chat box that could revolutionize 
      academia and augment research writing. This study had an open conversation with 
      ChatGPT and invited the platform to evaluate this article through series of five 
      questions on base of thumb arthritis to test if its contributions and contents 
      merely add artificial unusable input or help us augment the quality of the 
      article. The information ChatGPT-3 provided was accurate, albeit surface-level, 
      and lacks analytical ability to dissect for important limitations about base of 
      thumb arthritis, which would not be conducive to potentiating creative ideas and 
      solutions in plastic surgery. ChatGPT failed to provide relevant references and 
      even "created" references instead of indicating its inability to perform the 
      task. This highlights that as an AI-generator for medical publishing text, 
      ChatGPT-3 should be used cautiously.
CI  - Copyright © 2023 The Authors. Published by Wolters Kluwer Health, Inc. on behalf 
      of The American Society of Plastic Surgeons.
FAU - Seth, Ishith
AU  - Seth I
AD  - From the Faculty of Science, Medicine, and Health, Monash University, Victoria, 
      Australia.
AD  - Faculty of Science, Medicine, and Health, University of Melbourne, Victoria, 
      Australia.
AD  - Department of Plastic Surgery, Peninsula Health, Melbourne, Victoria, Australia.
AD  - Peninsula Clinical School, Central Clinical School at Monash University, The 
      Alfred Centre, Melbourne, Victoria, Australia.
FAU - Sinkjær Kenney, Peter
AU  - Sinkjær Kenney P
AD  - Department of Plastic Surgery, Odense University Hospital, Odense, Denmark.
AD  - Department of Plastic and Breast Surgery, Aarhus University Hospital, Aarhus N, 
      Denmark.
FAU - Bulloch, Gabriella
AU  - Bulloch G
AD  - Faculty of Science, Medicine, and Health, University of Melbourne, Victoria, 
      Australia.
FAU - Hunter-Smith, David J
AU  - Hunter-Smith DJ
AD  - From the Faculty of Science, Medicine, and Health, Monash University, Victoria, 
      Australia.
AD  - Department of Plastic Surgery, Peninsula Health, Melbourne, Victoria, Australia.
AD  - Peninsula Clinical School, Central Clinical School at Monash University, The 
      Alfred Centre, Melbourne, Victoria, Australia.
FAU - Bo Thomsen, Jørn
AU  - Bo Thomsen J
AD  - Department of Plastic Surgery, Odense University Hospital, Odense, Denmark.
AD  - Research unit for Plastic Surgery, Department of Clinical Research, University of 
      Southern Denmark, Odense, Denmark.
FAU - Rozen, Warren M
AU  - Rozen WM
AD  - From the Faculty of Science, Medicine, and Health, Monash University, Victoria, 
      Australia.
AD  - Department of Plastic Surgery, Peninsula Health, Melbourne, Victoria, Australia.
AD  - Peninsula Clinical School, Central Clinical School at Monash University, The 
      Alfred Centre, Melbourne, Victoria, Australia.
LA  - eng
PT  - Journal Article
DEP - 20230526
PL  - United States
TA  - Plast Reconstr Surg Glob Open
JT  - Plastic and reconstructive surgery. Global open
JID - 101622231
PMC - PMC10219695
COIS- The authors have no financial interest to declare in relation to the content of 
      this article. Disclosure statements are at the end of this article, following the 
      correspondence information.
EDAT- 2023/05/30 13:07
MHDA- 2023/05/30 13:08
PMCR- 2023/05/26
CRDT- 2023/05/30 11:29
PHST- 2023/02/17 00:00 [received]
PHST- 2023/03/27 00:00 [accepted]
PHST- 2023/05/30 13:08 [medline]
PHST- 2023/05/30 13:07 [pubmed]
PHST- 2023/05/30 11:29 [entrez]
PHST- 2023/05/26 00:00 [pmc-release]
AID - 10.1097/GOX.0000000000004999 [doi]
PST - epublish
SO  - Plast Reconstr Surg Glob Open. 2023 May 26;11(5):e4999. doi: 
      10.1097/GOX.0000000000004999. eCollection 2023 May.

PMID- 38559518
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240403
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 16
IP  - 3
DP  - 2024 Mar
TI  - Assessing the Utility of ChatGPT in Simplifying Text Complexity of Patient 
      Educational Materials.
PG  - e55304
LID - 10.7759/cureus.55304 [doi]
LID - e55304
AB  - INTRODUCTION: AI chatbots are being increasingly used in healthcare settings. 
      There is growing interest in using AI to assist in patient education. Currently, 
      extensive healthcare information is found online but is often too complex to 
      understand. Our objective is to determine if physicians can recommend the free 
      version of ChatGPT version 3.5 (OpenAI, San Francisco, CA, USA) for patients to 
      simplify text from the American Academy of Ophthalmology (AAO) in English and 
      Spanish. This version of ChatGPT was assessed in this study due to its increased 
      accessibility across various patient populations. METHODS: Fifteen articles were 
      chosen from AAO in both languages and simplified with ChatGPT 10 times each. The 
      readability of original and simplified articles was assessed with the Flesch 
      Reading Ease and Gunning Fog Index for English and Fernández Huerta, Gutiérrez, 
      Szigriszt-Pazo, INFLESZ, and Legibilidad-µ for Spanish. Grade levels to assess 
      readability were calculated with Flesch Kincaid Grade Level and Crawford 
      Nivel-de-Grado. Mean, standard deviation, and two-tailed t-tests were performed 
      to assess differences before and after simplification. RESULTS: Average grade 
      levels before and after simplification were as follows: English 8.43±1.17 to 
      8.9±2.1 (p=0.41) and Spanish 5.3±0.34 to 4.1±1.1 (p=0.0001). Spanish articles 
      were significantly simplified per Legibilidad-µ (p=0.003). No significant 
      difference was noted for other scales. CONCLUSIONS: The readability of AAO 
      articles in English worsened without significance but significantly improved in 
      Spanish. This may result from simpler syllable structures and a lesser overall 
      vocabulary in Spanish. With increased testing, physicians can recommend ChatGPT 
      for Spanish-speaking patients to improve health literacy.
CI  - Copyright © 2024, Sudharshan et al.
FAU - Sudharshan, Rasika
AU  - Sudharshan R
AD  - Ophthalmology, University of Southern California (USC) Roski Eye Institute, Los 
      Angeles, USA.
FAU - Shen, Alena
AU  - Shen A
AD  - Ophthalmology, University of Southern California (USC) Roski Eye Institute, Los 
      Angeles, USA.
FAU - Gupta, Shreya
AU  - Gupta S
AD  - Ophthalmology, University of Southern California (USC) Roski Eye Institute, Los 
      Angeles, USA.
FAU - Zhang-Nunes, Sandy
AU  - Zhang-Nunes S
AD  - Ophthalmology, University of Southern California (USC) Roski Eye Institute, Los 
      Angeles, USA.
LA  - eng
PT  - Journal Article
DEP - 20240301
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10981786
OTO - NOTNLM
OT  - artificial intelligence
OT  - chatbots
OT  - chatgpt
OT  - health literacy
OT  - ophthalmology
OT  - ophthalmology education
OT  - patient education
OT  - readability
OT  - spanish-speaking patients
OT  - text simplification
COIS- The authors have declared that no competing interests exist.
EDAT- 2024/04/01 18:42
MHDA- 2024/04/01 18:43
PMCR- 2024/03/01
CRDT- 2024/04/01 17:15
PHST- 2024/02/29 00:00 [accepted]
PHST- 2024/04/01 18:43 [medline]
PHST- 2024/04/01 18:42 [pubmed]
PHST- 2024/04/01 17:15 [entrez]
PHST- 2024/03/01 00:00 [pmc-release]
AID - 10.7759/cureus.55304 [doi]
PST - epublish
SO  - Cureus. 2024 Mar 1;16(3):e55304. doi: 10.7759/cureus.55304. eCollection 2024 Mar.

PMID- 38265047
OWN - NLM
STAT- MEDLINE
DCOM- 20240228
LR  - 20240228
IS  - 1473-4877 (Electronic)
IS  - 0300-7995 (Linking)
VI  - 40
IP  - 3
DP  - 2024 Mar
TI  - Between human and AI: assessing the reliability of AI text detection tools.
PG  - 353-358
LID - 10.1080/03007995.2024.2310086 [doi]
AB  - OBJECTIVE: Large language models (LLMs) such as ChatGPT-4 have raised critical 
      questions regarding their distinguishability from human-generated content. In 
      this research, we evaluated the effectiveness of online detection tools in 
      identifying ChatGPT-4 vs human-written text. METHODS: A two texts produced by 
      ChatGPT-4 using differing prompts and one text created by a human author were 
      analytically assessed using the following online detection tools: GPTZero, 
      ZeroGPT, Writer ACD, and Originality. RESULTS: The findings revealed a notable 
      variance in the detection capabilities of the employed detection tools. GPTZero 
      and ZeroGPT exhibited inconsistent assessments regarding the AI-origin of the 
      texts. Writer ACD predominantly identified texts as human-written, whereas 
      Originality consistently recognized the AI-generated content in both samples from 
      ChatGPT-4. This highlights Originality's enhanced sensitivity to patterns 
      characteristic of AI-generated text. CONCLUSION: The study demonstrates that 
      while automatic detection tools may discern texts generated by ChatGPT-4 
      significant variability exists in their accuracy. Undoubtedly, there is an urgent 
      need for advanced detection tools to ensure the authenticity and integrity of 
      content, especially in scientific and academic research. However, our findings 
      underscore an urgent need for more refined detection methodologies to prevent the 
      misdetection of human-written content as AI-generated and vice versa.
FAU - Bellini, Valentina
AU  - Bellini V
AD  - Anesthesiology, Critical Care and Pain Medicine Division, Department of Medicine 
      and Surgery, University of Parma, Parma, Italy.
FAU - Semeraro, Federico
AU  - Semeraro F
AD  - Department of Anesthesia, Intensive Care and Prehospital Emergency, Maggiore 
      Hospital Carlo Alberto Pizzardi, Bologna, Italy.
FAU - Montomoli, Jonathan
AU  - Montomoli J
AD  - Department of Anesthesia and Intensive Care, Infermi Hospital, Romagna Local 
      Health Authority, Rimini, Italy.
FAU - Cascella, Marco
AU  - Cascella M
AD  - Anesthesia and Pain Medicine. Department of Medicine, Surgery and Dentistry 
      "Scuola Medica Salernitana", University of Salerno, Baronissi, Italy.
FAU - Bignami, Elena
AU  - Bignami E
AD  - Anesthesiology, Critical Care and Pain Medicine Division, Department of Medicine 
      and Surgery, University of Parma, Parma, Italy.
LA  - eng
PT  - Journal Article
DEP - 20240202
PL  - England
TA  - Curr Med Res Opin
JT  - Current medical research and opinion
JID - 0351014
SB  - IM
MH  - Humans
MH  - *Reproducibility of Results
OTO - NOTNLM
OT  - Anesthesia
OT  - ChatGPT-4
OT  - artificial intelligence
OT  - intensive care
OT  - large language model
EDAT- 2024/01/24 12:43
MHDA- 2024/02/28 06:45
CRDT- 2024/01/24 08:58
PHST- 2024/02/28 06:45 [medline]
PHST- 2024/01/24 12:43 [pubmed]
PHST- 2024/01/24 08:58 [entrez]
AID - 10.1080/03007995.2024.2310086 [doi]
PST - ppublish
SO  - Curr Med Res Opin. 2024 Mar;40(3):353-358. doi: 10.1080/03007995.2024.2310086. 
      Epub 2024 Feb 2.

PMID- 37181697
OWN - NLM
STAT- MEDLINE
DCOM- 20230921
LR  - 20230921
IS  - 2296-2565 (Electronic)
IS  - 2296-2565 (Linking)
VI  - 11
DP  - 2023
TI  - ChatGPT and the rise of large language models: the new AI-driven infodemic threat 
      in public health.
PG  - 1166120
LID - 10.3389/fpubh.2023.1166120 [doi]
LID - 1166120
AB  - Large Language Models (LLMs) have recently gathered attention with the release of 
      ChatGPT, a user-centered chatbot released by OpenAI. In this perspective article, 
      we retrace the evolution of LLMs to understand the revolution brought by ChatGPT 
      in the artificial intelligence (AI) field. The opportunities offered by LLMs in 
      supporting scientific research are multiple and various models have already been 
      tested in Natural Language Processing (NLP) tasks in this domain. The impact of 
      ChatGPT has been huge for the general public and the research community, with 
      many authors using the chatbot to write part of their articles and some papers 
      even listing ChatGPT as an author. Alarming ethical and practical challenges 
      emerge from the use of LLMs, particularly in the medical field for the potential 
      impact on public health. Infodemic is a trending topic in public health and the 
      ability of LLMs to rapidly produce vast amounts of text could leverage 
      misinformation spread at an unprecedented scale, this could create an "AI-driven 
      infodemic," a novel public health threat. Policies to contrast this phenomenon 
      need to be rapidly elaborated, the inability to accurately detect 
      artificial-intelligence-produced text is an unresolved issue.
CI  - Copyright © 2023 De Angelis, Baglivo, Arzilli, Privitera, Ferragina, Tozzi and 
      Rizzo.
FAU - De Angelis, Luigi
AU  - De Angelis L
AD  - Department of Translational Research and New Technologies in Medicine and 
      Surgery, University of Pisa, Pisa, Italy.
FAU - Baglivo, Francesco
AU  - Baglivo F
AD  - Department of Translational Research and New Technologies in Medicine and 
      Surgery, University of Pisa, Pisa, Italy.
FAU - Arzilli, Guglielmo
AU  - Arzilli G
AD  - Department of Translational Research and New Technologies in Medicine and 
      Surgery, University of Pisa, Pisa, Italy.
FAU - Privitera, Gaetano Pierpaolo
AU  - Privitera GP
AD  - Department of Translational Research and New Technologies in Medicine and 
      Surgery, University of Pisa, Pisa, Italy.
AD  - Training Office, National Institute of Health, Rome, Italy.
FAU - Ferragina, Paolo
AU  - Ferragina P
AD  - Department of Computer Science, University of Pisa, Pisa, Italy.
FAU - Tozzi, Alberto Eugenio
AU  - Tozzi AE
AD  - Fetal, Neonatal and Cardiologic Science Research Area, Predictive and Preventive 
      Medicine Research Unit, Bambino Gesù Children's Hospital, IRCCS, Rome, Italy.
FAU - Rizzo, Caterina
AU  - Rizzo C
AD  - Department of Translational Research and New Technologies in Medicine and 
      Surgery, University of Pisa, Pisa, Italy.
LA  - eng
PT  - Journal Article
DEP - 20230425
PL  - Switzerland
TA  - Front Public Health
JT  - Frontiers in public health
JID - 101616579
SB  - IM
MH  - *Artificial Intelligence
MH  - *Infodemic
MH  - Public Health
MH  - Language
MH  - Natural Language Processing
PMC - PMC10166793
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - infodemic
OT  - large language models
OT  - natural language processing
OT  - public health
COIS- AT received honoraria for education activities on digital health and 
      immunizations from Roche, AstraZeneca, Novartis, Merck, MSD, Pfizer, Sanofi. The 
      remaining authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/05/14 19:13
MHDA- 2023/05/16 06:42
PMCR- 2023/04/25
CRDT- 2023/05/14 12:22
PHST- 2023/02/14 00:00 [received]
PHST- 2023/04/11 00:00 [accepted]
PHST- 2023/05/14 19:13 [pubmed]
PHST- 2023/05/16 06:42 [medline]
PHST- 2023/05/14 12:22 [entrez]
PHST- 2023/04/25 00:00 [pmc-release]
AID - 10.3389/fpubh.2023.1166120 [doi]
PST - epublish
SO  - Front Public Health. 2023 Apr 25;11:1166120. doi: 10.3389/fpubh.2023.1166120. 
      eCollection 2023.

PMID- 38418378
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20240301
LR  - 20240301
IS  - 1471-1842 (Electronic)
IS  - 1471-1834 (Linking)
VI  - 41
IP  - 1
DP  - 2024 Mar
TI  - ChatGPT: Game-changer or wildcard for systematic searching?
PG  - 1-3
LID - 10.1111/hir.12517 [doi]
AB  - In this editorial, Anthea Sutton and Veronica Parisi reflect on ChatGPT, how it 
      may contribute to systematic searching, and provide their overview of some recent 
      training they attended on ChatGPT, AI and systematic literature reviews.
CI  - © 2024 Health Libraries Group.
FAU - Sutton, Anthea
AU  - Sutton A
AUID- ORCID: 0000-0003-2449-2516
AD  - School of Medicine and Population Health, University of Sheffield, Sheffield, UK.
FAU - Parisi, Veronica
AU  - Parisi V
AD  - Library, Culture, Collections &amp; Open Science, University College London, London, 
      UK.
LA  - eng
PT  - Editorial
PL  - England
TA  - Health Info Libr J
JT  - Health information and libraries journal
JID - 100970070
OTO - NOTNLM
OT  - artificial intelligence
OT  - automation
OT  - database searching
OT  - literature searching
EDAT- 2024/02/29 00:43
MHDA- 2024/02/29 00:44
CRDT- 2024/02/28 22:13
PHST- 2023/12/12 00:00 [received]
PHST- 2023/12/19 00:00 [accepted]
PHST- 2024/02/29 00:44 [medline]
PHST- 2024/02/29 00:43 [pubmed]
PHST- 2024/02/28 22:13 [entrez]
AID - 10.1111/hir.12517 [doi]
PST - ppublish
SO  - Health Info Libr J. 2024 Mar;41(1):1-3. doi: 10.1111/hir.12517.

PMID- 38062632
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20240214
LR  - 20240313
IS  - 1619-3997 (Electronic)
IS  - 0300-5577 (Linking)
VI  - 52
IP  - 2
DP  - 2024 Feb 26
TI  - Re: to the Letter to the Editor: "ChatGPT and artificial intelligence in the 
      Journal of Perinatal Medicine".
PG  - 247
LID - 10.1515/jpm-2023-0380 [doi]
FAU - Grünebaum, Amos
AU  - Grünebaum A
AD  - Donald and Barbara Zucker School of Medicine at Hofstra/Northwell, Uniondale, NY, 
      USA.
FAU - Chervenak, Frank A
AU  - Chervenak FA
AD  - Donald and Barbara Zucker School of Medicine at Hofstra/Northwell, Uniondale, NY, 
      USA.
FAU - Dudenhausen, Joachim
AU  - Dudenhausen J
AD  - Donald and Barbara Zucker School of Medicine at Hofstra/Northwell, Uniondale, NY, 
      USA.
AD  - Department of Obstetrics, Charité&nbsp;- University Medicine Berlin, Berlin, Germany.
LA  - eng
PT  - Letter
DEP - 20231211
PL  - Germany
TA  - J Perinat Med
JT  - Journal of perinatal medicine
JID - 0361031
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - Internet
OT  - computers
EDAT- 2023/12/08 06:42
MHDA- 2024/02/09 00:42
CRDT- 2023/12/08 00:43
PHST- 2023/09/13 00:00 [received]
PHST- 2023/09/29 00:00 [accepted]
PHST- 2024/02/09 00:42 [medline]
PHST- 2023/12/08 06:42 [pubmed]
PHST- 2023/12/08 00:43 [entrez]
AID - jpm-2023-0380 [pii]
AID - 10.1515/jpm-2023-0380 [doi]
PST - epublish
SO  - J Perinat Med. 2023 Dec 11;52(2):247. doi: 10.1515/jpm-2023-0380. Print 2024 Feb 
      26.

PMID- 37979017
OWN - NLM
STAT- MEDLINE
DCOM- 20240207
LR  - 20240207
IS  - 1970-9366 (Electronic)
IS  - 1828-0447 (Linking)
VI  - 19
IP  - 1
DP  - 2024 Jan
TI  - How accurate are the references generated by ChatGPT in internal medicine?
PG  - 247-249
LID - 10.1007/s11739-023-03484-5 [doi]
FAU - Sebo, Paul
AU  - Sebo P
AUID- ORCID: 0000-0001-7616-0017
AD  - University Institute for Primary Care (IuMFE), University of Geneva, Geneva, 
      Switzerland. paulsebo@hotmail.com.
LA  - eng
PT  - Letter
DEP - 20231118
PL  - Italy
TA  - Intern Emerg Med
JT  - Internal and emergency medicine
JID - 101263418
SB  - IM
MH  - *Internal Medicine
MH  - *Artificial Intelligence
OTO - NOTNLM
OT  - AI
OT  - Accuracy
OT  - ChatGPT
OT  - Fake
OT  - Journal
OT  - Publication
OT  - Reference
EDAT- 2023/11/18 12:42
MHDA- 2024/01/31 06:42
CRDT- 2023/11/18 11:06
PHST- 2023/10/08 00:00 [received]
PHST- 2023/11/07 00:00 [accepted]
PHST- 2024/01/31 06:42 [medline]
PHST- 2023/11/18 12:42 [pubmed]
PHST- 2023/11/18 11:06 [entrez]
AID - 10.1007/s11739-023-03484-5 [pii]
AID - 10.1007/s11739-023-03484-5 [doi]
PST - ppublish
SO  - Intern Emerg Med. 2024 Jan;19(1):247-249. doi: 10.1007/s11739-023-03484-5. Epub 
      2023 Nov 18.

PMID- 36813155
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20230320
LR  - 20230320
IS  - 1873-7544 (Electronic)
IS  - 0306-4522 (Linking)
VI  - 515
DP  - 2023 Apr 1
TI  - ChatGPT in Research: Balancing Ethics, Transparency and Advancement.
PG  - 71-73
LID - S0306-4522(23)00079-9 [pii]
LID - 10.1016/j.neuroscience.2023.02.008 [doi]
FAU - Graf, Akseli
AU  - Graf A
AD  - Institute of Psychopharmacology, Central Institute of Mental Health, Medical 
      Faculty Mannheim, University of Heidelberg, Mannheim, Germany. Electronic 
      address: Akseli.Graf@zi-mannheim.de.
FAU - Bernardi, Rick E
AU  - Bernardi RE
AD  - Institute of Psychopharmacology, Central Institute of Mental Health, Medical 
      Faculty Mannheim, University of Heidelberg, Mannheim, Germany.
LA  - eng
PT  - Journal Article
DEP - 20230221
PL  - United States
TA  - Neuroscience
JT  - Neuroscience
JID - 7605074
SB  - IM
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - ethics
OT  - large language models
EDAT- 2023/02/23 06:00
MHDA- 2023/02/23 06:01
CRDT- 2023/02/22 19:29
PHST- 2023/02/08 00:00 [received]
PHST- 2023/02/11 00:00 [accepted]
PHST- 2023/02/23 06:00 [pubmed]
PHST- 2023/02/23 06:01 [medline]
PHST- 2023/02/22 19:29 [entrez]
AID - S0306-4522(23)00079-9 [pii]
AID - 10.1016/j.neuroscience.2023.02.008 [doi]
PST - ppublish
SO  - Neuroscience. 2023 Apr 1;515:71-73. doi: 10.1016/j.neuroscience.2023.02.008. Epub 
      2023 Feb 21.

PMID- 38362184
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240217
IS  - 2378-8038 (Print)
IS  - 2378-8038 (Electronic)
IS  - 2378-8038 (Linking)
VI  - 9
IP  - 1
DP  - 2024 Feb
TI  - Can ChatGPT help patients answer their otolaryngology questions?
PG  - e1193
LID - 10.1002/lio2.1193 [doi]
LID - e1193
AB  - BACKGROUND: Over the past year, the world has been captivated by the potential of 
      artificial intelligence (AI). The appetite for AI in science, specifically 
      healthcare is huge. It is imperative to understand the credibility of large 
      language models in assisting the public in medical queries. OBJECTIVE: To 
      evaluate the ability of ChatGPT to provide reasonably accurate answers to public 
      queries within the domain of Otolaryngology. METHODS: Two board-certified 
      otolaryngologists (HZ, RS) inputted 30 text-based patient queries into the 
      ChatGPT-3.5 model. ChatGPT responses were rated by physicians on a scale 
      (accurate, partially accurate, incorrect), while a similar 3-point scale 
      involving confidence was given to layperson reviewers. Demographic data involving 
      gender and education level was recorded for the public reviewers. Inter-rater 
      agreement percentage was based on binomial distribution for calculating the 95% 
      confidence intervals and performing significance tests. Statistical significance 
      was defined as p &lt; .05 for two-sided tests. RESULTS: In testing patient queries, 
      both Otolaryngology physicians found that ChatGPT answered 98.3% of questions 
      correctly, but only 79.8% (range 51.7%-100%) of patients were confident that the 
      AI model was accurate in its responses (corrected agreement = 0.682; p &lt; .001). 
      Among the layperson responses, the corrected coefficient was of moderate 
      agreement (0.571; p &lt; .001). No correlation was noted among age, gender, or 
      education level for the layperson responses. CONCLUSION: ChatGPT is highly 
      accurate in responding to questions posed by the public with regards to 
      Otolaryngology from a physician standpoint. Public reviewers were not fully 
      confident in believing the AI model, with subjective concerns related to less 
      trust in AI answers compared to physician explanation. Larger evaluations with a 
      representative public sample and broader medical questions should immediately be 
      conducted by appropriate organizations, governing bodies, and/or governmental 
      agencies to instill public confidence in AI and ChatGPT as a medical resource. 
      LEVEL OF EVIDENCE: 4.
CI  - © 2023 The Authors. Laryngoscope Investigative Otolaryngology published by Wiley 
      Periodicals LLC on behalf of The Triological Society.
FAU - Zalzal, Habib G
AU  - Zalzal HG
AUID- ORCID: 0000-0002-0777-977X
AD  - Division of Otolaryngology-Head and Neck Surgery Children's National Hospital 
      Washington District of Columbia USA.
FAU - Abraham, Ariel
AU  - Abraham A
AD  - University of Maryland Maryland USA.
FAU - Cheng, Jenhao
AU  - Cheng J
AD  - Quality, Safety, Analytics Children's National Hospital Washington District of 
      Columbia USA.
FAU - Shah, Rahul K
AU  - Shah RK
AD  - Division of Otolaryngology-Head and Neck Surgery Children's National Hospital 
      Washington District of Columbia USA.
LA  - eng
PT  - Journal Article
DEP - 20231209
PL  - United States
TA  - Laryngoscope Investig Otolaryngol
JT  - Laryngoscope investigative otolaryngology
JID - 101684963
PMC - PMC10866598
OTO - NOTNLM
OT  - ChatGPT
OT  - OpenAI
OT  - artificial intelligence
OT  - large language model
OT  - machine learning
OT  - patient education
COIS- The authors have no financial or proprietary interests in any material discussed 
      in this article.
EDAT- 2024/02/16 06:43
MHDA- 2024/02/16 06:44
PMCR- 2023/12/09
CRDT- 2024/02/16 03:54
PHST- 2023/08/30 00:00 [received]
PHST- 2023/11/14 00:00 [revised]
PHST- 2023/11/22 00:00 [accepted]
PHST- 2024/02/16 06:44 [medline]
PHST- 2024/02/16 06:43 [pubmed]
PHST- 2024/02/16 03:54 [entrez]
PHST- 2023/12/09 00:00 [pmc-release]
AID - LIO21193 [pii]
AID - 10.1002/lio2.1193 [doi]
PST - epublish
SO  - Laryngoscope Investig Otolaryngol. 2023 Dec 9;9(1):e1193. doi: 10.1002/lio2.1193. 
      eCollection 2024 Feb.

PMID- 37550893
OWN - NLM
STAT- MEDLINE
DCOM- 20240111
LR  - 20240111
IS  - 1600-0579 (Electronic)
IS  - 1396-5883 (Linking)
VI  - 28
IP  - 1
DP  - 2024 Feb
TI  - ChatGPT-A double-edged sword for healthcare education? Implications for 
      assessments of dental students.
PG  - 206-211
LID - 10.1111/eje.12937 [doi]
AB  - INTRODUCTION: Open-source generative artificial intelligence (AI) applications 
      are fast-transforming access to information and allow students to prepare 
      assignments and offer quite accurate responses to a wide range of exam questions 
      which are routinely used in assessments of students across the board including 
      undergraduate dental students. This study aims to evaluate the performance of 
      Chat Generative Pre-trained Transformer (ChatGPT), a generative AI-based 
      application, on a wide range of assessments used in contemporary healthcare 
      education and discusses the implications for undergraduate dental education. 
      MATERIALS AND METHODS: This was an exploratory study investigating the accuracy 
      of ChatGPT to attempt a range of recognised assessments in healthcare education 
      curricula. A total of 50 independent items encompassing 50 different learning 
      outcomes (n = 10 per item) were developed by the research team. These included 10 
      separate items based on each of the five commonly used question formats including 
      multiple-choice questions (MCQs); short-answer questions (SAQs); short essay 
      questions (SEQs); single true/false questions; and fill in the blanks items. Chat 
      GPT was used to attempt each of these 50 questions. In addition, ChatGPT was used 
      to generate reflective reports based on multisource feedback; research 
      methodology; and critical appraisal of the literature. RESULTS: ChatGPT 
      application provided accurate responses to majority of knowledge-based 
      assessments based on MCQs, SAQs, SEQs, true/false and fill in the blanks items. 
      However, it was only able to answer text-based questions and did not allow 
      processing of questions based on images. Responses generated to written 
      assignments were also satisfactory apart from those for critical appraisal of 
      literature. Word count was the key limitation observed in outputs generated by 
      the free version of ChatGPT. CONCLUSION: Notwithstanding their current 
      limitations, generative AI-based applications have the potential to revolutionise 
      virtual learning. Instead of treating it as a threat, healthcare educators need 
      to adapt teaching and assessments in medical and dental education to the benefits 
      of the learners while mitigating against dishonest use of AI-based technology.
CI  - © 2023 The Authors. European Journal of Dental Education published by John Wiley 
      &amp; Sons Ltd.
FAU - Ali, Kamran
AU  - Ali K
AD  - College of Dental Medicine QU Health, Qatar University, Doha, Qatar.
FAU - Barhom, Noha
AU  - Barhom N
AD  - College of Dental Medicine QU Health, Qatar University, Doha, Qatar.
FAU - Tamimi, Faleh
AU  - Tamimi F
AD  - College of Dental Medicine QU Health, Qatar University, Doha, Qatar.
FAU - Duggal, Monty
AU  - Duggal M
AD  - College of Dental Medicine QU Health, Qatar University, Doha, Qatar.
LA  - eng
GR  - Open access funding was provided by the Qatar National Library/
PT  - Journal Article
DEP - 20230807
PL  - England
TA  - Eur J Dent Educ
JT  - European journal of dental education : official journal of the Association for 
      Dental Education in Europe
JID - 9712132
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Students, Dental
MH  - Education, Dental
MH  - Learning
MH  - Curriculum
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - dental education
OT  - education technology
OT  - machine learning
EDAT- 2023/08/08 06:42
MHDA- 2024/01/11 07:43
CRDT- 2023/08/08 00:52
PHST- 2023/07/08 00:00 [revised]
PHST- 2023/03/01 00:00 [received]
PHST- 2023/07/24 00:00 [accepted]
PHST- 2024/01/11 07:43 [medline]
PHST- 2023/08/08 06:42 [pubmed]
PHST- 2023/08/08 00:52 [entrez]
AID - 10.1111/eje.12937 [doi]
PST - ppublish
SO  - Eur J Dent Educ. 2024 Feb;28(1):206-211. doi: 10.1111/eje.12937. Epub 2023 Aug 7.

PMID- 37423350
OWN - NLM
STAT- MEDLINE
DCOM- 20231103
LR  - 20231113
IS  - 1558-349X (Electronic)
IS  - 1546-1440 (Linking)
VI  - 20
IP  - 10
DP  - 2023 Oct
TI  - ChatGPT-4 Assistance in Optimizing Emergency Department Radiology Referrals and 
      Imaging Selection.
PG  - 998-1003
LID - S1546-1440(23)00484-2 [pii]
LID - 10.1016/j.jacr.2023.06.009 [doi]
AB  - PURPOSE: The quality of radiology referrals influences patient management and 
      imaging interpretation by radiologists. The aim of this study was to evaluate 
      ChatGPT-4 as a decision support tool for selecting imaging examinations and 
      generating radiology referrals in the emergency department (ED). METHODS: Five 
      consecutive clinical notes from the ED were retrospectively extracted, for each 
      of the following pathologies: pulmonary embolism, obstructing kidney stones, 
      acute appendicitis, diverticulitis, small bowel obstruction, acute cholecystitis, 
      acute hip fracture, and testicular torsion. A total of 40 cases were included. 
      These notes were entered into ChatGPT-4, requesting recommendations on the most 
      appropriate imaging examinations and protocols. The chatbot was also asked to 
      generate radiology referrals. Two independent radiologists graded the referral on 
      a scale ranging from 1 to 5 for clarity, clinical relevance, and differential 
      diagnosis. The chatbot's imaging recommendations were compared with the ACR 
      Appropriateness Criteria (AC) and with the examinations performed in the ED. 
      Agreement between readers was assessed using linear weighted Cohen's κ 
      coefficient. RESULTS: ChatGPT-4's imaging recommendations aligned with the ACR AC 
      and ED examinations in all cases. Protocol discrepancies between ChatGPT and the 
      ACR AC were observed in two cases (5%). ChatGPT-4-generated referrals received 
      mean scores of 4.6 and 4.8 for clarity, 4.5 and 4.4 for clinical relevance, and 
      4.9 from both reviewers for differential diagnosis. Agreement between readers was 
      moderate for clinical relevance and clarity and substantial for differential 
      diagnosis grading. CONCLUSIONS: ChatGPT-4 has shown potential in aiding imaging 
      study selection for select clinical cases. As a complementary tool, large 
      language models may improve radiology referral quality. Radiologists should stay 
      informed about this technology and be mindful of potential challenges and risks.
CI  - Copyright © 2023 American College of Radiology. Published by Elsevier Inc. All 
      rights reserved.
FAU - Barash, Yiftach
AU  - Barash Y
AD  - Department of Diagnostic Imaging, Chaim Sheba Medical Center, Tel Hashomer, 
      Israel; Sackler School of Medicine, Tel Aviv University, Tel Aviv, Israel; 
      DeepVision Lab, Chaim Sheba Medical Center, Tel Hashomer, Israel. Electronic 
      address: yibarash@gmail.com.
FAU - Klang, Eyal
AU  - Klang E
AD  - Department of Diagnostic Imaging, Chaim Sheba Medical Center, Tel Hashomer, 
      Israel; Sackler School of Medicine, Tel Aviv University, Tel Aviv, Israel; Head, 
      Sami Sagol AI Hub, ARC, Chaim Sheba Medical Center, Tel Hashomer, Israel; 
      DeepVision Lab, Chaim Sheba Medical Center, Tel Hashomer, Israel.
FAU - Konen, Eli
AU  - Konen E
AD  - Sackler School of Medicine, Tel Aviv University, Tel Aviv, Israel; Head, 
      Department of Diagnostic Imaging, Chaim Sheba Medical Center, Tel Hashomer, 
      Israel.
FAU - Sorin, Vera
AU  - Sorin V
AD  - Department of Diagnostic Imaging, Chaim Sheba Medical Center, Tel Hashomer, 
      Israel; Sackler School of Medicine, Tel Aviv University, Tel Aviv, Israel; 
      DeepVision Lab, Chaim Sheba Medical Center, Tel Hashomer, Israel.
LA  - eng
PT  - Journal Article
DEP - 20230707
PL  - United States
TA  - J Am Coll Radiol
JT  - Journal of the American College of Radiology : JACR
JID - 101190326
SB  - IM
MH  - Humans
MH  - Retrospective Studies
MH  - Radiography
MH  - *Radiology
MH  - Emergency Service, Hospital
MH  - *Hip Fractures
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - Large language models
OT  - radiology
OT  - referrals
EDAT- 2023/07/10 00:41
MHDA- 2023/11/03 06:44
CRDT- 2023/07/09 19:24
PHST- 2023/05/09 00:00 [received]
PHST- 2023/06/19 00:00 [revised]
PHST- 2023/06/29 00:00 [accepted]
PHST- 2023/11/03 06:44 [medline]
PHST- 2023/07/10 00:41 [pubmed]
PHST- 2023/07/09 19:24 [entrez]
AID - S1546-1440(23)00484-2 [pii]
AID - 10.1016/j.jacr.2023.06.009 [doi]
PST - ppublish
SO  - J Am Coll Radiol. 2023 Oct;20(10):998-1003. doi: 10.1016/j.jacr.2023.06.009. Epub 
      2023 Jul 7.

PMID- 38539117
OWN - NLM
STAT- MEDLINE
DCOM- 20240329
LR  - 20240330
IS  - 1471-2288 (Electronic)
IS  - 1471-2288 (Linking)
VI  - 24
IP  - 1
DP  - 2024 Mar 27
TI  - Methodological insights into ChatGPT's screening performance in systematic 
      reviews.
PG  - 78
LID - 10.1186/s12874-024-02203-8 [doi]
LID - 78
AB  - BACKGROUND: The screening process for systematic reviews and meta-analyses in 
      medical research is a labor-intensive and time-consuming task. While machine 
      learning and deep learning have been applied to facilitate this process, these 
      methods often require training data and user annotation. This study aims to 
      assess the efficacy of ChatGPT, a large language model based on the Generative 
      Pretrained Transformers (GPT) architecture, in automating the screening process 
      for systematic reviews in radiology without the need for training data. METHODS: 
      A prospective simulation study was conducted between May 2nd and 24th, 2023, 
      comparing ChatGPT's performance in screening abstracts against that of general 
      physicians (GPs). A total of 1198 abstracts across three subfields of radiology 
      were evaluated. Metrics such as sensitivity, specificity, positive and negative 
      predictive values (PPV and NPV), workload saving, and others were employed. 
      Statistical analyses included the Kappa coefficient for inter-rater agreement, 
      ROC curve plotting, AUC calculation, and bootstrapping for p-values and 
      confidence intervals. RESULTS: ChatGPT completed the screening process within an 
      hour, while GPs took an average of 7-10 days. The AI model achieved a sensitivity 
      of 95% and an NPV of 99%, slightly outperforming the GPs' sensitive consensus 
      (i.e., including records if at least one person includes them). It also exhibited 
      remarkably low false negative counts and high workload savings, ranging from 40 
      to 83%. However, ChatGPT had lower specificity and PPV compared to human raters. 
      The average Kappa agreement between ChatGPT and other raters was 0.27. 
      CONCLUSIONS: ChatGPT shows promise in automating the article screening phase of 
      systematic reviews, achieving high sensitivity and workload savings. While not 
      entirely replacing human expertise, it could serve as an efficient first-line 
      screening tool, particularly in reducing the burden on human resources. Further 
      studies are needed to fine-tune its capabilities and validate its utility across 
      different medical subfields.
CI  - © 2024. The Author(s).
FAU - Issaiy, Mahbod
AU  - Issaiy M
AD  - Advanced Diagnostic and Interventional Radiology Research Center (ADIR), Tehran 
      University of Medical Science, Tehran, Iran.
FAU - Ghanaati, Hossein
AU  - Ghanaati H
AD  - Advanced Diagnostic and Interventional Radiology Research Center (ADIR), Tehran 
      University of Medical Science, Tehran, Iran.
FAU - Kolahi, Shahriar
AU  - Kolahi S
AD  - Advanced Diagnostic and Interventional Radiology Research Center (ADIR), Tehran 
      University of Medical Science, Tehran, Iran.
FAU - Shakiba, Madjid
AU  - Shakiba M
AD  - Advanced Diagnostic and Interventional Radiology Research Center (ADIR), Tehran 
      University of Medical Science, Tehran, Iran.
FAU - Jalali, Amir Hossein
AU  - Jalali AH
AD  - Advanced Diagnostic and Interventional Radiology Research Center (ADIR), Tehran 
      University of Medical Science, Tehran, Iran.
FAU - Zarei, Diana
AU  - Zarei D
AD  - Advanced Diagnostic and Interventional Radiology Research Center (ADIR), Tehran 
      University of Medical Science, Tehran, Iran.
FAU - Kazemian, Sina
AU  - Kazemian S
AD  - Cardiac Primary Prevention Research Center, Cardiovascular Diseases Research 
      Institute, Tehran University of Medical Sciences, Tehran, Iran.
FAU - Avanaki, Mahsa Alborzi
AU  - Avanaki MA
AD  - Advanced Diagnostic and Interventional Radiology Research Center (ADIR), Tehran 
      University of Medical Science, Tehran, Iran.
FAU - Firouznia, Kavous
AU  - Firouznia K
AD  - Advanced Diagnostic and Interventional Radiology Research Center (ADIR), Tehran 
      University of Medical Science, Tehran, Iran. k_firouznia@yahoo.com.
LA  - eng
PT  - Journal Article
DEP - 20240327
PL  - England
TA  - BMC Med Res Methodol
JT  - BMC medical research methodology
JID - 100968545
SB  - IM
MH  - Humans
MH  - Systematic Reviews as Topic
MH  - *Benchmarking
MH  - *Biomedical Research
MH  - Computer Simulation
MH  - Consensus
PMC - PMC10976661
OTO - NOTNLM
OT  - AI
OT  - Article screening
OT  - ChatGPT
OT  - GPT
OT  - Large language model
OT  - Radiology
OT  - Systematic review
COIS- The authors declare that they have no competing interests.
EDAT- 2024/03/28 06:44
MHDA- 2024/03/29 06:45
PMCR- 2024/03/27
CRDT- 2024/03/28 00:46
PHST- 2023/09/05 00:00 [received]
PHST- 2024/03/18 00:00 [accepted]
PHST- 2024/03/29 06:45 [medline]
PHST- 2024/03/28 06:44 [pubmed]
PHST- 2024/03/28 00:46 [entrez]
PHST- 2024/03/27 00:00 [pmc-release]
AID - 10.1186/s12874-024-02203-8 [pii]
AID - 2203 [pii]
AID - 10.1186/s12874-024-02203-8 [doi]
PST - epublish
SO  - BMC Med Res Methodol. 2024 Mar 27;24(1):78. doi: 10.1186/s12874-024-02203-8.

PMID- 38217478
OWN - NLM
STAT- MEDLINE
DCOM- 20240403
LR  - 20240403
IS  - 1550-9397 (Electronic)
IS  - 1550-9389 (Print)
IS  - 1550-9389 (Linking)
VI  - 20
IP  - 4
DP  - 2024 Apr 1
TI  - Evaluating insomnia queries from an artificial intelligence chatbot for patient 
      education.
PG  - 583-594
LID - 10.5664/jcsm.10948 [doi]
AB  - STUDY OBJECTIVES: We evaluated the accuracy of ChatGPT in addressing 
      insomnia-related queries for patient education and assessed ChatGPT's ability to 
      provide varied responses based on differing prompting scenarios. METHODS: Four 
      identical sets of 20 insomnia-related queries were posed to ChatGPT. Each set 
      differed by the context in which ChatGPT was prompted: no prompt, 
      patient-centered, physician-centered, and with references and statistics. 
      Responses were reviewed by 2 academic sleep surgeons, 1 academic sleep medicine 
      physician, and 2 sleep medicine fellows across 4 domains: clinical accuracy, 
      prompt adherence, referencing, and statistical precision, using a binary grading 
      system. Flesch-Kincaid grade-level scores were calculated to estimate the grade 
      level of the responses, with statistical differences between prompts analyzed via 
      analysis of variance and Tukey's test. Interrater reliability was calculated 
      using Fleiss's kappa. RESULTS: The study revealed significant variations in the 
      Flesch-Kincaid grade-level scores across 4 prompts: unprompted (13.2 ± 2.2), 
      patient-centered (8.1 ± 1.9), physician-centered (15.4 ± 2.8), and with 
      references and statistics (17.3 ± 2.3, P &lt; .001). Despite poor Fleiss kappa 
      scores, indicating low interrater reliability for clinical accuracy and 
      relevance, all evaluators agreed that the majority of ChatGPT's responses were 
      clinically accurate, with the highest variability on Form 4. The responses were 
      also uniformly relevant to the given prompts (100% agreement). Eighty percent of 
      the references ChatGPT cited were verified as both real and relevant, and only 
      25% of cited statistics were corroborated within referenced articles. 
      CONCLUSIONS: ChatGPT can be used to generate clinically accurate responses to 
      insomnia-related inquiries. CITATION: Alapati R, Campbell D, Molin N, et&nbsp;al. 
      Evaluating insomnia queries from an artificial intelligence chatbot for patient 
      education. J Clin Sleep Med. 2024;20(4):583-594.
CI  - © 2024 American Academy of Sleep Medicine.
FAU - Alapati, Rahul
AU  - Alapati R
AD  - Sidney Kimmel Medical College, Thomas Jefferson University, Philadelphia, 
      Pennsylvania.
FAU - Campbell, Daniel
AU  - Campbell D
AD  - Department of Otolaryngology, Thomas Jefferson University Hospitals, 
      Philadelphia, Pennsylvania.
FAU - Molin, Nicole
AU  - Molin N
AD  - Department of Otolaryngology, Thomas Jefferson University Hospitals, 
      Philadelphia, Pennsylvania.
AD  - Department of Neurology, Jefferson Sleep Disorders Center, Thomas Jefferson 
      University Hospitals, Philadelphia, Pennsylvania.
FAU - Creighton, Erin
AU  - Creighton E
AD  - Department of Otolaryngology, Thomas Jefferson University Hospitals, 
      Philadelphia, Pennsylvania.
AD  - Department of Neurology, Jefferson Sleep Disorders Center, Thomas Jefferson 
      University Hospitals, Philadelphia, Pennsylvania.
FAU - Wei, Zhikui
AU  - Wei Z
AD  - Department of Neurology, Jefferson Sleep Disorders Center, Thomas Jefferson 
      University Hospitals, Philadelphia, Pennsylvania.
FAU - Boon, Maurits
AU  - Boon M
AD  - Department of Otolaryngology, Thomas Jefferson University Hospitals, 
      Philadelphia, Pennsylvania.
FAU - Huntley, Colin
AU  - Huntley C
AD  - Department of Otolaryngology, Thomas Jefferson University Hospitals, 
      Philadelphia, Pennsylvania.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - J Clin Sleep Med
JT  - Journal of clinical sleep medicine : JCSM : official publication of the American 
      Academy of Sleep Medicine
JID - 101231977
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Sleep Initiation and Maintenance Disorders/diagnosis
MH  - Reproducibility of Results
MH  - Patient Education as Topic
MH  - Software
PMC - PMC10985291
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - insomnia
COIS- All authors have seen, read, and approved the manuscript. The authors report no 
      conflicts of interest.
EDAT- 2024/01/13 17:43
MHDA- 2024/04/03 06:45
PMCR- 2025/04/01
CRDT- 2024/01/13 08:32
PHST- 2024/04/03 06:45 [medline]
PHST- 2024/01/13 17:43 [pubmed]
PHST- 2024/01/13 08:32 [entrez]
PHST- 2025/04/01 00:00 [pmc-release]
AID - jcsm.10948 [pii]
AID - JC2300311 [pii]
AID - 10.5664/jcsm.10948 [doi]
PST - ppublish
SO  - J Clin Sleep Med. 2024 Apr 1;20(4):583-594. doi: 10.5664/jcsm.10948.

PMID- 37865883
OWN - NLM
STAT- MEDLINE
DCOM- 20231128
LR  - 20231205
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 25
DP  - 2023 Nov 16
TI  - A SWOT (Strengths, Weaknesses, Opportunities, and Threats) Analysis of ChatGPT in 
      the Medical Literature: Concise Review.
PG  - e49368
LID - 10.2196/49368 [doi]
LID - e49368
AB  - BACKGROUND: ChatGPT is a 175-billion-parameter natural language processing model 
      that is already involved in scientific content and publications. Its influence 
      ranges from providing quick access to information on medical topics, assisting in 
      generating medical and scientific articles and papers, performing medical data 
      analyses, and even interpreting complex data sets. OBJECTIVE: The future role of 
      ChatGPT remains uncertain and a matter of debate already shortly after its 
      release. This review aimed to analyze the role of ChatGPT in the medical 
      literature during the first 3 months after its release. METHODS: We performed a 
      concise review of literature published in PubMed from December 1, 2022, to March 
      31, 2023. To find all publications related to ChatGPT or considering ChatGPT, the 
      search term was kept simple ("ChatGPT" in AllFields). All publications available 
      as full text in German or English were included. All accessible publications were 
      evaluated according to specifications by the author team (eg, impact factor, 
      publication modus, article type, publication speed, and type of ChatGPT 
      integration or content). The conclusions of the articles were used for later SWOT 
      (strengths, weaknesses, opportunities, and threats) analysis. All data were 
      analyzed on a descriptive basis. RESULTS: Of 178 studies in total, 160 met the 
      inclusion criteria and were evaluated. The average impact factor was 4.423 (range 
      0-96.216), and the average publication speed was 16 (range 0-83) days. Among the 
      articles, there were 77 editorials (48,1%), 43 essays (26.9%), 21 studies 
      (13.1%), 6 reviews (3.8%), 6 case reports (3.8%), 6 news (3.8%), and 1 
      meta-analysis (0.6%). Of those, 54.4% (n=87) were published as open access, with 
      5% (n=8) provided on preprint servers. Over 400 quotes with information on 
      strengths, weaknesses, opportunities, and threats were detected. By far, most 
      (n=142, 34.8%) were related to weaknesses. ChatGPT excels in its ability to 
      express ideas clearly and formulate general contexts comprehensibly. It performs 
      so well that even experts in the field have difficulty identifying abstracts 
      generated by ChatGPT. However, the time-limited scope and the need for 
      corrections by experts were mentioned as weaknesses and threats of ChatGPT. 
      Opportunities include assistance in formulating medical issues for nonnative 
      English speakers, as well as the possibility of timely participation in the 
      development of such artificial intelligence tools since it is in its early stages 
      and can therefore still be influenced. CONCLUSIONS: Artificial intelligence tools 
      such as ChatGPT are already part of the medical publishing landscape. Despite 
      their apparent opportunities, policies and guidelines must be implemented to 
      ensure benefits in education, clinical practice, and research and protect against 
      threats such as scientific misconduct, plagiarism, and inaccuracy.
CI  - ©Daniel Gödde, Sophia Nöhl, Carina Wolf, Yannick Rupert, Lukas Rimkus, Jan 
      Ehlers, Frank Breuckmann, Timur Sellmann. Originally published in the Journal of 
      Medical Internet Research (https://www.jmir.org), 16.11.2023.
FAU - Gödde, Daniel
AU  - Gödde D
AUID- ORCID: 0000-0002-8430-1411
AD  - Department of Pathology and Molecularpathology, Helios University Hospital 
      Wuppertal, Witten/Herdecke University, Witten, Germany.
FAU - Nöhl, Sophia
AU  - Nöhl S
AUID- ORCID: 0009-0008-7515-8300
AD  - Faculty of Health, Witten/Herdecke University, Witten, Germany.
FAU - Wolf, Carina
AU  - Wolf C
AUID- ORCID: 0009-0003-0303-2825
AD  - Faculty of Health, Witten/Herdecke University, Witten, Germany.
FAU - Rupert, Yannick
AU  - Rupert Y
AUID- ORCID: 0009-0005-7430-2460
AD  - Faculty of Health, Witten/Herdecke University, Witten, Germany.
FAU - Rimkus, Lukas
AU  - Rimkus L
AUID- ORCID: 0009-0009-4468-7768
AD  - Faculty of Health, Witten/Herdecke University, Witten, Germany.
FAU - Ehlers, Jan
AU  - Ehlers J
AUID- ORCID: 0000-0001-6306-4173
AD  - Department of Didactics and Education Research in the Health Sector, Faculty of 
      Health, Witten/Herdecke University, Witten, Germany.
FAU - Breuckmann, Frank
AU  - Breuckmann F
AUID- ORCID: 0000-0001-7245-8000
AD  - Department of Cardiology and Vascular Medicine, West German Heart and Vascular 
      Center Essen, University Duisburg-Essen, Essen, Germany.
AD  - Department of Cardiology, Pneumology, Neurology and Intensive Care Medicine, 
      Klinik Kitzinger Land, Kitzingen, Germany.
FAU - Sellmann, Timur
AU  - Sellmann T
AUID- ORCID: 0000-0002-1471-6806
AD  - Department of Anaesthesiology I, Witten/Herdecke University, Witten, Germany.
AD  - Department of Anaesthesiology and Intensive Care Medicine, Evangelisches 
      Krankenhaus BETHESDA zu Duisburg, Duisburg, Germany.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20231116
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Data Analysis
MH  - Educational Status
MH  - Language
MH  - Natural Language Processing
PMC - PMC10690535
OTO - NOTNLM
OT  - ChatGPT
OT  - SWOT
OT  - artificial intelligence
OT  - chatbot
OT  - chatbots
OT  - concise review
OT  - education technology
OT  - machine learning
OT  - medical education
OT  - review methodology
OT  - review methods
COIS- Conflicts of Interest: None declared.
EDAT- 2023/10/22 12:42
MHDA- 2023/11/17 15:28
PMCR- 2023/11/16
CRDT- 2023/10/22 06:28
PHST- 2023/05/26 00:00 [received]
PHST- 2023/09/27 00:00 [accepted]
PHST- 2023/09/26 00:00 [revised]
PHST- 2023/11/17 15:28 [medline]
PHST- 2023/10/22 12:42 [pubmed]
PHST- 2023/10/22 06:28 [entrez]
PHST- 2023/11/16 00:00 [pmc-release]
AID - v25i1e49368 [pii]
AID - 10.2196/49368 [doi]
PST - epublish
SO  - J Med Internet Res. 2023 Nov 16;25:e49368. doi: 10.2196/49368.

PMID- 37456464
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230718
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 6
DP  - 2023 Jun
TI  - Implications of ChatGPT in Public Health Dentistry: A Systematic Review.
PG  - e40367
LID - 10.7759/cureus.40367 [doi]
LID - e40367
AB  - An artificial intelligence (AI) program called ChatGPT that generates text in 
      response to typed commands has proven to be highly popular, as evidenced by the 
      fact that OpenAI makes it available online. The goal of the present investigation 
      was to investigate ChatGPT's potential applications as an outstanding instance of 
      large language models (LLMs) in the fields of public dental health schooling, 
      writing for academic use, research in public dental health, and clinical practice 
      in public dental health based on the available data. Importantly, the goals of 
      the current review included locating any drawbacks and issues that might be 
      connected to using ChatGPT in the previously mentioned contexts in healthcare 
      settings. Using search phrases including chatGPT, implications, artificial 
      intelligence (AI), public health dentistry, public health, practice in public 
      health dentistry, education in public health dentistry, academic writing in 
      public health dentistry, etc., a thorough search was carried out on the Pubmed 
      database, the Embase database, the Ovid database, the Global Health database, 
      PsycINFO, and the Web of Science. The dates of publication were not restricted. 
      Systematic searches were carried out for all publications according to inclusion 
      and exclusion criteria between March 31, 2018, and March 31, 2023. Eighty-four 
      papers were obtained through a literature search using search terms. Sixteen 
      similar and duplicate papers were excluded and 68 distinct articles were 
      initially selected. Thirty-three articles were excluded after reviewing abstracts 
      and titles. Thirty-five papers were selected, for which full text was managed. 
      Four extra papers were found manually from references. Thirty-nine articles with 
      full texts were eligible for the study. Eighteen inadequate articles are excluded 
      from the final 21 studies that were finally selected for systemic review. 
      According to previously published studies, ChatGPT has demonstrated its 
      effectiveness in helping scholars with the authoring of scientific research and 
      dental studies.&nbsp;If the right structures are created, ChatGPT can offer suitable 
      responses and more time to concentrate on the phase of experimentation for 
      scientists. Risks include prejudice in the training data, undervaluing human 
      skills, the possibility of fraud in science, as well as legal and reproducibility 
      concerns. It was concluded that practice considering ChatGPT's potential 
      significance, the research's uniqueness, and the premise-the activity of the 
      human brain-remains. While there is no question about the superiority of 
      incorporating ChatGPT into the practice of public health dentistry, it does not, 
      in any way, take the place of a dentist since clinical practice involves more 
      than just making diagnoses; it also involves relating to clinical findings and 
      providing individualized patient care. Even though AI can be useful in a number 
      of ways, a dentist must ultimately make the decision because dentistry is a field 
      that involves several disciplines.
CI  - Copyright © 2023, Tiwari et al.
FAU - Tiwari, Anushree
AU  - Tiwari A
AD  - Clinical Quality and Value, American Academy of Orthopaedic Surgeons, Rosemont, 
      USA.
FAU - Kumar, Amit
AU  - Kumar A
AD  - Department of Dentistry, All India Institute of Medical Sciences, Patna, IND.
FAU - Jain, Shailesh
AU  - Jain S
AD  - Department of Prosthodontics and Crown and Bridge, School of Dental Sciences, 
      Sharda University, Greater Noida, IND.
FAU - Dhull, Kanika S
AU  - Dhull KS
AD  - Department of Pedodontics and Preventive Dentistry, Kalinga Institute of Dental 
      Sciences (KIIT) Deemed to be University, Bhubaneswar, IND.
FAU - Sajjanar, Arunkumar
AU  - Sajjanar A
AD  - Department of Pediatrics and Preventive Dentistry, Swargiya Dadasaheb Kalmegh 
      Smruti Dental College and Hospital, Nagpur, IND.
FAU - Puthenkandathil, Rahul
AU  - Puthenkandathil R
AD  - Department of Prosthodontics and Crown and Bridge, AB Shetty Memorial Institute 
      of Dental Sciences (ABSMIDS) Nitte (Deemed to be University), Mangalore, IND.
FAU - Paiwal, Kapil
AU  - Paiwal K
AD  - Department of Oral and Maxillofacial Pathology, Daswani Dental College and 
      Research Center, Kota, IND.
FAU - Singh, Ramanpal
AU  - Singh R
AD  - Oral Medicine and Radiology, New Horizon Dental College and Research Institute, 
      Bilaspur, IND.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230613
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10340128
OTO - NOTNLM
OT  - artificial intelligence
OT  - chatgpt
OT  - dentist
OT  - implications
OT  - public health dentistry
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/07/17 06:42
MHDA- 2023/07/17 06:43
PMCR- 2023/06/13
CRDT- 2023/07/17 04:23
PHST- 2023/05/04 00:00 [received]
PHST- 2023/06/10 00:00 [accepted]
PHST- 2023/07/17 06:43 [medline]
PHST- 2023/07/17 06:42 [pubmed]
PHST- 2023/07/17 04:23 [entrez]
PHST- 2023/06/13 00:00 [pmc-release]
AID - 10.7759/cureus.40367 [doi]
PST - epublish
SO  - Cureus. 2023 Jun 13;15(6):e40367. doi: 10.7759/cureus.40367. eCollection 2023 
      Jun.

PMID- 38355517
OWN - NLM
STAT- MEDLINE
DCOM- 20240216
LR  - 20240217
IS  - 1472-6920 (Electronic)
IS  - 1472-6920 (Linking)
VI  - 24
IP  - 1
DP  - 2024 Feb 14
TI  - Performance of ChatGPT on Chinese national medical licensing examinations: a 
      five-year examination evaluation study for physicians, pharmacists and nurses.
PG  - 143
LID - 10.1186/s12909-024-05125-7 [doi]
LID - 143
AB  - BACKGROUND: Large language models like ChatGPT have revolutionized the field of 
      natural language processing with their capability to comprehend and generate 
      textual content, showing great potential to play a role in medical education. 
      This study aimed to quantitatively evaluate and comprehensively analysis the 
      performance of ChatGPT on three types of national medical examinations in China, 
      including National Medical Licensing Examination (NMLE), National Pharmacist 
      Licensing Examination (NPLE), and National Nurse Licensing Examination (NNLE). 
      METHODS: We collected questions from Chinese NMLE, NPLE and NNLE from year 2017 
      to 2021. In NMLE and NPLE, each exam consists of 4 units, while in NNLE, each 
      exam consists of 2 units. The questions with figures, tables or chemical 
      structure were manually identified and excluded by clinician. We applied direct 
      instruction strategy via multiple prompts to force ChatGPT to generate the clear 
      answer with the capability to distinguish between single-choice and 
      multiple-choice questions. RESULTS: ChatGPT failed to pass the accuracy threshold 
      of 0.6 in any of the three types of examinations over the five years. 
      Specifically, in the NMLE, the highest recorded accuracy was 0.5467, which was 
      attained in both 2018 and 2021. In the NPLE, the highest accuracy was 0.5599 in 
      2017. In the NNLE, the most impressive result was shown in 2017, with an accuracy 
      of 0.5897, which is also the highest accuracy in our entire evaluation. ChatGPT's 
      performance showed no significant difference in different units, but significant 
      difference in different question types. ChatGPT performed well in a range of 
      subject areas, including clinical epidemiology, human parasitology, and 
      dermatology, as well as in various medical topics such as molecules, health 
      management and prevention, diagnosis and screening. CONCLUSIONS: These results 
      indicate ChatGPT failed the NMLE, NPLE and NNLE in China, spanning from year 2017 
      to 2021. but show great potential of large language models in medical education. 
      In the future high-quality medical data will be required to improve the 
      performance.
CI  - © 2024. The Author(s).
FAU - Zong, Hui
AU  - Zong H
AUID- ORCID: 0000-0002-9142-5017
AD  - Department of Urology and Institutes for Systems Genetics, Frontiers Science 
      Center for Disease-related Molecular Network, West China Hospital, Sichuan 
      University, No. 37, Guoxue Alley, Chengdu, 610212, China.
FAU - Li, Jiakun
AU  - Li J
AUID- ORCID: 0000-0003-4996-9907
AD  - Department of Urology and Institutes for Systems Genetics, Frontiers Science 
      Center for Disease-related Molecular Network, West China Hospital, Sichuan 
      University, No. 37, Guoxue Alley, Chengdu, 610212, China.
FAU - Wu, Erman
AU  - Wu E
AUID- ORCID: 0000-0002-2363-3738
AD  - Department of Urology and Institutes for Systems Genetics, Frontiers Science 
      Center for Disease-related Molecular Network, West China Hospital, Sichuan 
      University, No. 37, Guoxue Alley, Chengdu, 610212, China.
FAU - Wu, Rongrong
AU  - Wu R
AUID- ORCID: 0000-0003-3876-1609
AD  - Department of Urology and Institutes for Systems Genetics, Frontiers Science 
      Center for Disease-related Molecular Network, West China Hospital, Sichuan 
      University, No. 37, Guoxue Alley, Chengdu, 610212, China.
FAU - Lu, Junyu
AU  - Lu J
AD  - Department of Urology and Institutes for Systems Genetics, Frontiers Science 
      Center for Disease-related Molecular Network, West China Hospital, Sichuan 
      University, No. 37, Guoxue Alley, Chengdu, 610212, China.
FAU - Shen, Bairong
AU  - Shen B
AUID- ORCID: 0000-0003-2899-1531
AD  - Department of Urology and Institutes for Systems Genetics, Frontiers Science 
      Center for Disease-related Molecular Network, West China Hospital, Sichuan 
      University, No. 37, Guoxue Alley, Chengdu, 610212, China. 
      bairong.shen@scu.edu.cn.
LA  - eng
GR  - 32270690/National Natural Science Foundation of China/
PT  - Journal Article
DEP - 20240214
PL  - England
TA  - BMC Med Educ
JT  - BMC medical education
JID - 101088679
SB  - IM
MH  - China
MH  - Data Accuracy
MH  - *Artificial Intelligence
MH  - *Educational Measurement
MH  - *Licensure
MH  - Education, Nursing
MH  - Education, Pharmacy
MH  - Education, Medical
PMC - PMC10868058
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Medical education
OT  - Medical examination
OT  - Natural language processing
COIS- The authors declare no conflict of competing interests.
EDAT- 2024/02/15 00:42
MHDA- 2024/02/16 06:43
PMCR- 2024/02/14
CRDT- 2024/02/14 23:38
PHST- 2023/08/31 00:00 [received]
PHST- 2024/02/01 00:00 [accepted]
PHST- 2024/02/16 06:43 [medline]
PHST- 2024/02/15 00:42 [pubmed]
PHST- 2024/02/14 23:38 [entrez]
PHST- 2024/02/14 00:00 [pmc-release]
AID - 10.1186/s12909-024-05125-7 [pii]
AID - 5125 [pii]
AID - 10.1186/s12909-024-05125-7 [doi]
PST - epublish
SO  - BMC Med Educ. 2024 Feb 14;24(1):143. doi: 10.1186/s12909-024-05125-7.

PMID- 37566815
OWN - NLM
STAT- MEDLINE
DCOM- 20230814
LR  - 20231109
IS  - 1536-3708 (Electronic)
IS  - 0148-7043 (Linking)
VI  - 91
IP  - 3
DP  - 2023 Sep 1
TI  - Distinguishing Authentic Voices in the Age of ChatGPT: Comparing AI-Generated and 
      Applicant-Written Personal Statements for Plastic Surgery Residency Application.
PG  - 324-325
LID - 10.1097/SAP.0000000000003653 [doi]
AB  - BACKGROUND: ChatGPT, a generative artificial intelligence model, may be used by 
      future applicants in the plastic surgery residency match. METHODS: Ten personal 
      statements (5 generated by ChatGPT, 5 written by applicants) were rated by 10 
      reviewers, blinded to the source of the essay. RESULTS: A total of a 100 
      evaluations were collected. There was no significant difference in ratings for 
      readability, originality, authenticity, and overall quality (all P &gt; 0.05) when 
      comparing computer-generated and applicant essays. CONCLUSION: Personal 
      statements prepared by ChatGPT are indistinguishable from essays written by 
      actual applicants. This finding suggests that the current plastic surgery 
      application format be reevaluated to better aid in holistic evaluation of 
      students.
CI  - Copyright © 2023 Wolters Kluwer Health, Inc. All rights reserved.
FAU - Patel, Viren
AU  - Patel V
AD  - From the Department of Plastic Surgery, Cleveland Clinic, Cleveland, OH.
FAU - Deleonibus, Anthony
AU  - Deleonibus A
FAU - Wells, Michael W
AU  - Wells MW
FAU - Bernard, Steven L
AU  - Bernard SL
FAU - Schwarz, Graham S
AU  - Schwarz GS
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Ann Plast Surg
JT  - Annals of plastic surgery
JID - 7805336
SB  - IM
EIN - Ann Plast Surg. 2023 Nov 8;:null. PMID: 37937846
MH  - Humans
MH  - *Internship and Residency
MH  - *Surgery, Plastic/education
MH  - Artificial Intelligence
MH  - Writing
MH  - *Students, Medical
COIS- Conflicts of interest and sources of funding: none declared.
EDAT- 2023/08/11 18:42
MHDA- 2023/08/14 06:41
CRDT- 2023/08/11 16:42
PHST- 2023/08/14 06:41 [medline]
PHST- 2023/08/11 18:42 [pubmed]
PHST- 2023/08/11 16:42 [entrez]
AID - 00000637-202309000-00002 [pii]
AID - 10.1097/SAP.0000000000003653 [doi]
PST - ppublish
SO  - Ann Plast Surg. 2023 Sep 1;91(3):324-325. doi: 10.1097/SAP.0000000000003653.

PMID- 36589923
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230103
IS  - 2331-4737 (Print)
IS  - 2331-4737 (Electronic)
IS  - 2331-4737 (Linking)
VI  - 9
DP  - 2022
TI  - Rapamycin in the context of Pascal's Wager: generative pre-trained transformer 
      perspective.
PG  - 82-84
LID - 10.18632/oncoscience.571 [doi]
AB  - Large language models utilizing transformer neural networks and other deep 
      learning architectures demonstrated unprecedented results in many tasks 
      previously accessible only to human intelligence. In this article, we collaborate 
      with ChatGPT, an AI model developed by OpenAI to speculate on the applications of 
      Rapamycin, in the context of Pascal's Wager philosophical argument commonly 
      utilized to justify the belief in god. In response to the query "Write an 
      exhaustive research perspective on why taking Rapamycin may be more beneficial 
      than not taking Rapamycin from the perspective of Pascal's wager" ChatGPT 
      provided the pros and cons for the use of Rapamycin considering the preclinical 
      evidence of potential life extension in animals. This article demonstrates the 
      potential of ChatGPT to produce complex philosophical arguments and should not be 
      used for any off-label use of Rapamycin.
CN  - ChatGPT Generative Pre-trained Transformer
FAU - Zhavoronkov, Alex
AU  - Zhavoronkov A
AD  - Insilico Medicine, Hong Kong Science and Technology Park, Hong Kong.
LA  - eng
PT  - Journal Article
DEP - 20221221
PL  - United States
TA  - Oncoscience
JT  - Oncoscience
JID - 101636666
PMC - PMC9796173
OTO - NOTNLM
OT  - Pascal’s Wager
OT  - Rapamycin
OT  - artificial intelligence
OT  - longevity medicine
OT  - philosophy
COIS- CONFLICTS OF INTEREST Authors have no conflicts of interest to declare.
EDAT- 2023/01/03 06:00
MHDA- 2023/01/03 06:01
PMCR- 2022/12/21
CRDT- 2023/01/02 04:11
PHST- 2022/12/14 00:00 [received]
PHST- 2022/12/15 00:00 [accepted]
PHST- 2023/01/02 04:11 [entrez]
PHST- 2023/01/03 06:00 [pubmed]
PHST- 2023/01/03 06:01 [medline]
PHST- 2022/12/21 00:00 [pmc-release]
AID - 571 [pii]
AID - 10.18632/oncoscience.571 [doi]
PST - epublish
SO  - Oncoscience. 2022 Dec 21;9:82-84. doi: 10.18632/oncoscience.571. eCollection 
      2022.

PMID- 37667724
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230906
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 8
DP  - 2023 Aug
TI  - Assessing the Performance of GPT-3.5 and GPT-4 on the 2023 Japanese Nursing 
      Examination.
PG  - e42924
LID - 10.7759/cureus.42924 [doi]
LID - e42924
AB  - Purpose The purpose of this study was to evaluate the changes in capabilities 
      between the Generative Pre-trained Transformer (GPT)-3.5 and GPT-4 versions of 
      the large-scale language model ChatGPT within a Japanese medical context. Methods 
      The study involved ChatGPT versions 3.5 and 4 responding to questions from the 
      112th Japanese National Nursing Examination (JNNE). The study comprised three 
      analyses: correct answer rate and score rate calculations, comparisons between 
      GPT-3.5 and GPT-4, and comparisons of correct answer rates for conversation 
      questions. Results ChatGPT versions 3.5 and 4 responded to 237 out of 238 
      Japanese questions from the 112th JNNE. While GPT-3.5 achieved an overall 
      accuracy rate of 59.9%, failing to meet the passing standards in compulsory and 
      general/scenario-based questions, scoring 58.0% and 58.3%, respectively, GPT-4 
      had an accuracy rate of 79.7%, satisfying the passing standards by scoring 90.0% 
      and 77.7%, respectively. For each problem type, GPT-4 showed a higher accuracy 
      rate than GPT-3.5. Specifically, the accuracy rates for compulsory questions 
      improved from 58.0% with GPT-3.5 to 90.0% with GPT-4. For general questions, the 
      rates went from 64.6% with GPT-3.5 to 75.6% with GPT-4. In scenario-based 
      questions, the accuracy rates improved substantially from 51.7% with GPT-3.5 to 
      80.0% with GPT-4. For conversation questions, GPT-3.5 had an accuracy rate of 
      73.3% and GPT-4 had an accuracy rate of 93.3%. Conclusions The GPT-4 version of 
      ChatGPT displayed performance sufficient to pass the JNNE, significantly 
      improving from GPT-3.5. This suggests specialized medical training could make 
      such models beneficial in Japanese clinical settings, aiding decision-making. 
      However, user awareness and training are crucial, given potential inaccuracies in 
      ChatGPT's responses. Hence, responsible usage with an understanding of its 
      capabilities and limitations is vital to best support healthcare professionals 
      and patients.
CI  - Copyright © 2023, Kaneda et al.
FAU - Kaneda, Yudai
AU  - Kaneda Y
AD  - College of Medicine, Hokkaido University, Hokkaido, JPN.
FAU - Takahashi, Ryo
AU  - Takahashi R
AD  - Department of Rehabilitation Medicine, Sonodakai Joint Replacement Center 
      Hospital, Tokyo, JPN.
FAU - Kaneda, Uiri
AU  - Kaneda U
AD  - Department of Foreign Languages, Dokkyo University, Saitama, JPN.
FAU - Akashima, Shiori
AU  - Akashima S
AD  - Department of Obstetrics and Gynecology, Shonan Kamakura General Hospital, 
      Kanagawa, JPN.
FAU - Okita, Haruna
AU  - Okita H
AD  - College of Medicine, Tokyo Women's Medical University, Tokyo, JPN.
FAU - Misaki, Sadaya
AU  - Misaki S
AD  - Department of Rehabilitation Medicine, Sonoda Daiichi Hospital, Tokyo, JPN.
FAU - Yamashiro, Akimi
AU  - Yamashiro A
AD  - Department of Nutrition Science, Shokei Gakuin University, Miyagi, JPN.
FAU - Ozaki, Akihiko
AU  - Ozaki A
AD  - Department of Breast and Thyroid Surgery, Jyoban Hospital of Tokiwa Foundation, 
      Fukushima, JPN.
FAU - Tanimoto, Tetsuya
AU  - Tanimoto T
AD  - Department of Internal Medicine, Navitas Clinic, Kanagawa, JPN.
LA  - eng
PT  - Journal Article
DEP - 20230803
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10475149
OTO - NOTNLM
OT  - ai &amp; robotics healthcare
OT  - chatgpt
OT  - chatgpt-3.5
OT  - chatgpt-4
OT  - clinical applications
OT  - gpt-3.5
OT  - gpt-4
OT  - japan
OT  - national nursing examination
COIS- The authors have declared financial relationships, which are detailed in the next 
      section.
EDAT- 2023/09/05 06:42
MHDA- 2023/09/05 06:43
PMCR- 2023/08/03
CRDT- 2023/09/05 03:35
PHST- 2023/08/03 00:00 [accepted]
PHST- 2023/09/05 06:43 [medline]
PHST- 2023/09/05 06:42 [pubmed]
PHST- 2023/09/05 03:35 [entrez]
PHST- 2023/08/03 00:00 [pmc-release]
AID - 10.7759/cureus.42924 [doi]
PST - epublish
SO  - Cureus. 2023 Aug 3;15(8):e42924. doi: 10.7759/cureus.42924. eCollection 2023 Aug.

PMID- 38521243
OWN - NLM
STAT- Publisher
LR  - 20240324
IS  - 2468-7855 (Electronic)
IS  - 2468-7855 (Linking)
DP  - 2024 Mar 21
TI  - ChatGPT revisited: Using ChatGPT-4 for finding references and editing language in 
      medical scientific articles.
PG  - 101842
LID - S2468-7855(24)00078-8 [pii]
LID - 10.1016/j.jormas.2024.101842 [doi]
AB  - The attainment of academic superiority relies heavily upon the accessibility of 
      scholarly resources and the expression of research findings through faultless 
      language usage. Although modern tools, such as the Publish or Perish software 
      program, are proficient in sourcing academic papers based on specific keywords, 
      they often fall short of extracting comprehensive content, including crucial 
      references. The challenge of linguistic precision remains a prominent issue, 
      particularly for research papers composed by non-native English speakers who may 
      encounter word usage errors. This manuscript serves a twofold purpose: firstly, 
      it reassesses the effectiveness of ChatGPT-4 in the context of retrieving 
      pertinent references tailored to specific research topics. Secondly, it 
      introduces a suite of language editing services that are skilled in rectifying 
      word usage errors, ensuring the refined presentation of research outcomes. The 
      article also provides practical guidelines for formulating precise queries to 
      mitigate the risks of erroneous language usage and the inclusion of spurious 
      references. In the ever-evolving realm of academic discourse, leveraging the 
      potential of advanced AI, such as ChatGPT-4, can significantly enhance the 
      quality and impact of scientific publications.
CI  - Copyright © 2024 Elsevier Masson SAS. All rights reserved.
FAU - Alyasiri, Osamah Mohammed
AU  - Alyasiri OM
AD  - Karbala Technical Institute, Al-Furat Al-Awsat Technical University, Karbala 
      56001, Iraq; School of Computer Sciences, Universiti Sains Malaysia, Penang 
      11800, Malaysia. Electronic address: osama.alyasiri@atu.edu.iq.
FAU - Salman, Amer M
AU  - Salman AM
AD  - School of Mathematical Sciences, Universiti Sains Malaysia, Penang 11800, 
      Malaysia.
FAU - Akhtom, Dua'a
AU  - Akhtom D
AD  - School of Computer Sciences, Universiti Sains Malaysia, Penang 11800, Malaysia.
FAU - Salisu, Sani
AU  - Salisu S
AD  - School of Computer Sciences, Universiti Sains Malaysia, Penang 11800, Malaysia; 
      Department of Information Technology, Federal University Dutse, Dutse 720101, 
      Nigeria.
LA  - eng
PT  - Journal Article
DEP - 20240321
PL  - France
TA  - J Stomatol Oral Maxillofac Surg
JT  - Journal of stomatology, oral and maxillofacial surgery
JID - 101701089
SB  - IM
OTO - NOTNLM
OT  - AI finding references
OT  - ChatGPT-4
OT  - Language editing services
COIS- Declaration of competing interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2024/03/24 00:42
MHDA- 2024/03/24 00:42
CRDT- 2024/03/23 20:39
PHST- 2023/10/09 00:00 [received]
PHST- 2024/03/06 00:00 [revised]
PHST- 2024/03/20 00:00 [accepted]
PHST- 2024/03/24 00:42 [pubmed]
PHST- 2024/03/24 00:42 [medline]
PHST- 2024/03/23 20:39 [entrez]
AID - S2468-7855(24)00078-8 [pii]
AID - 10.1016/j.jormas.2024.101842 [doi]
PST - aheadofprint
SO  - J Stomatol Oral Maxillofac Surg. 2024 Mar 21:101842. doi: 
      10.1016/j.jormas.2024.101842.

PMID- 37694729
OWN - NLM
STAT- MEDLINE
DCOM- 20231109
LR  - 20231109
IS  - 1651-2251 (Electronic)
IS  - 0001-6489 (Linking)
VI  - 143
IP  - 9
DP  - 2023 Sep
TI  - Validity of the large language model ChatGPT (GPT4) as a patient information 
      source in otolaryngology by a variety of doctors in a tertiary 
      otorhinolaryngology department.
PG  - 779-782
LID - 10.1080/00016489.2023.2254809 [doi]
AB  - BACKGROUND: A high number of patients seek health information online, and large 
      language models (LLMs) may produce a rising amount of it. AIM: This study 
      evaluates the performance regarding health information provided by ChatGPT, a LLM 
      developed by OpenAI, focusing on its utility as a source for 
      otolaryngology-related patient information. MATERIAL AND METHOD: A variety of 
      doctors from a tertiary otorhinolaryngology department used a Likert scale to 
      assess the chatbot's responses in terms of accuracy, relevance, and depth. The 
      responses were also evaluated by ChatGPT. RESULTS: The composite mean of the 
      three categories was 3.41, with the highest performance noted in the relevance 
      category (mean = 3.71) when evaluated by the respondents. The accuracy and depth 
      categories yielded mean scores of 3.51 and 3.00, respectively. All the categories 
      were rated as 5 when evaluated by ChatGPT. CONCLUSION AND SIGNIFICANCE: Despite 
      its potential in providing relevant and accurate medical information, the 
      chatbot's responses lacked depth and were found to potentially perpetuate biases 
      due to its training on publicly available text. In conclusion, while LLMs show 
      promise in healthcare, further refinement is necessary to enhance response depth 
      and mitigate potential biases.
FAU - Nielsen, Jacob P S
AU  - Nielsen JPS
AD  - Department of Otorhinolaryngology-Head and Neck Surgery and Audiology, Copenhagen 
      University Hospital, Rigshospitalet, Copenhagen, Denmark.
FAU - von Buchwald, Christian
AU  - von Buchwald C
AD  - Department of Otorhinolaryngology-Head and Neck Surgery and Audiology, Copenhagen 
      University Hospital, Rigshospitalet, Copenhagen, Denmark.
FAU - Grønhøj, Christian
AU  - Grønhøj C
AD  - Department of Otorhinolaryngology-Head and Neck Surgery and Audiology, Copenhagen 
      University Hospital, Rigshospitalet, Copenhagen, Denmark.
LA  - eng
PT  - Editorial
DEP - 20230911
PL  - England
TA  - Acta Otolaryngol
JT  - Acta oto-laryngologica
JID - 0370354
SB  - IM
MH  - Humans
MH  - Information Sources
MH  - *Physicians
MH  - Hospital Departments
MH  - Language
MH  - *Otolaryngology
OTO - NOTNLM
OT  - ChatGPT
OT  - GPT4
OT  - chatbots
OT  - ear-nose-throat diseases
OT  - large language model
OT  - otolaryngology
OT  - patient information
OT  - validation study
EDAT- 2023/09/11 12:43
MHDA- 2023/11/09 06:42
CRDT- 2023/09/11 07:02
PHST- 2023/11/09 06:42 [medline]
PHST- 2023/09/11 12:43 [pubmed]
PHST- 2023/09/11 07:02 [entrez]
AID - 10.1080/00016489.2023.2254809 [doi]
PST - ppublish
SO  - Acta Otolaryngol. 2023 Sep;143(9):779-782. doi: 10.1080/00016489.2023.2254809. 
      Epub 2023 Sep 11.

PMID- 38215452
OWN - NLM
STAT- Publisher
LR  - 20240112
IS  - 1537-2677 (Electronic)
IS  - 0740-9303 (Linking)
DP  - 2024 Jan 12
TI  - Evaluating the Accuracy of ChatGPT and Google BARD in Fielding Oculoplastic 
      Patient Queries: A Comparative Study on Artificial versus Human Intelligence.
LID - 10.1097/IOP.0000000000002567 [doi]
AB  - PURPOSE: This study evaluates and compares the accuracy of responses from 2 
      artificial intelligence platforms to patients' oculoplastics-related questions. 
      METHODS: Questions directed toward oculoplastic surgeons were collected, 
      rephrased, and input independently into ChatGPT-3.5 and BARD chatbots, using the 
      prompt: "As an oculoplastic surgeon, how can I respond to my patient's 
      question?." Responses were independently evaluated by 4 experienced oculoplastic 
      specialists as comprehensive, correct but inadequate, mixed correct and 
      incorrect/outdated data, and completely incorrect. Additionally, the empathy 
      level, length, and automated readability index of the responses were assessed. 
      RESULTS: A total of 112 patient questions underwent evaluation. The rates of 
      comprehensive, correct but inadequate, mixed, and completely incorrect answers 
      for ChatGPT were 71.4%, 12.9%, 10.5%, and 5.1%, respectively, compared with 
      53.1%, 18.3%, 18.1%, and 10.5%, respectively, for BARD. ChatGPT showed more 
      empathy (48.9%) than BARD (13.2%). All graders found that ChatGPT outperformed 
      BARD in question categories of postoperative healing, medical eye conditions, and 
      medications. Categorizing questions by anatomy, ChatGPT excelled in answering 
      lacrimal questions (83.8%), while BARD performed best in the eyelid group 
      (60.4%). ChatGPT's answers were longer and potentially more challenging to 
      comprehend than BARD's. CONCLUSION: This study emphasizes the promising role of 
      artificial intelligence-powered chatbots in oculoplastic patient education and 
      support. With continued development, these chatbots may potentially assist 
      physicians and offer patients accurate information, ultimately contributing to 
      improved patient care while alleviating surgeon burnout. However, it is crucial 
      to highlight that artificial intelligence may be good at answering questions, but 
      physician oversight remains essential to ensure the highest standard of care and 
      address complex medical cases.
CI  - Copyright © 2024 The American Society of Ophthalmic Plastic and Reconstructive 
      Surgery, Inc.
FAU - Al-Sharif, Eman M
AU  - Al-Sharif EM
AD  - Division of Oculofacial Plastic and Reconstructive Surgery, Viterbi Family 
      Department of Ophthalmology, UC San Diego Shiley Eye Institute, La Jolla, 
      California, U.S.A.
AD  - Clinical Sciences Department, College of Medicine, Princess Nourah bint 
      Abdulrahman University, Riyadh, Saudi Arabia.
FAU - Penteado, Rafaella C
AU  - Penteado RC
AD  - Division of Oculofacial Plastic and Reconstructive Surgery, Viterbi Family 
      Department of Ophthalmology, UC San Diego Shiley Eye Institute, La Jolla, 
      California, U.S.A.
FAU - Dib El Jalbout, Nahia
AU  - Dib El Jalbout N
AD  - Division of Oculofacial Plastic and Reconstructive Surgery, Viterbi Family 
      Department of Ophthalmology, UC San Diego Shiley Eye Institute, La Jolla, 
      California, U.S.A.
FAU - Topilow, Nicole J
AU  - Topilow NJ
AD  - Division of Oculofacial Plastic and Reconstructive Surgery, Viterbi Family 
      Department of Ophthalmology, UC San Diego Shiley Eye Institute, La Jolla, 
      California, U.S.A.
FAU - Shoji, Marissa K
AU  - Shoji MK
AD  - Division of Oculofacial Plastic and Reconstructive Surgery, Viterbi Family 
      Department of Ophthalmology, UC San Diego Shiley Eye Institute, La Jolla, 
      California, U.S.A.
FAU - Kikkawa, Don O
AU  - Kikkawa DO
AD  - Division of Oculofacial Plastic and Reconstructive Surgery, Viterbi Family 
      Department of Ophthalmology, UC San Diego Shiley Eye Institute, La Jolla, 
      California, U.S.A.
AD  - Division of Plastic and Reconstructive Surgery, Department of Surgery, UC San 
      Diego School of Medicine, La Jolla, California, U.S.A.
FAU - Liu, Catherine Y
AU  - Liu CY
AD  - Division of Oculofacial Plastic and Reconstructive Surgery, Viterbi Family 
      Department of Ophthalmology, UC San Diego Shiley Eye Institute, La Jolla, 
      California, U.S.A.
FAU - Korn, Bobby S
AU  - Korn BS
AD  - Division of Oculofacial Plastic and Reconstructive Surgery, Viterbi Family 
      Department of Ophthalmology, UC San Diego Shiley Eye Institute, La Jolla, 
      California, U.S.A.
AD  - Division of Plastic and Reconstructive Surgery, Department of Surgery, UC San 
      Diego School of Medicine, La Jolla, California, U.S.A.
LA  - eng
PT  - Journal Article
DEP - 20240112
PL  - United States
TA  - Ophthalmic Plast Reconstr Surg
JT  - Ophthalmic plastic and reconstructive surgery
JID - 8508431
SB  - IM
COIS- B. S. K. Elsevier Royalties, Horizon Consultant. D. O. K. C. Y. L. Site principal 
      investigator for phase IV clinical trial- Horizon Therapeutics; Wolters Kluwers 
      Health Royalties. The other authors have no conflicts of interest to disclose.
EDAT- 2024/01/12 18:41
MHDA- 2024/01/12 18:41
CRDT- 2024/01/12 17:03
PHST- 2024/01/12 18:41 [medline]
PHST- 2024/01/12 18:41 [pubmed]
PHST- 2024/01/12 17:03 [entrez]
AID - 00002341-990000000-00314 [pii]
AID - 10.1097/IOP.0000000000002567 [doi]
PST - aheadofprint
SO  - Ophthalmic Plast Reconstr Surg. 2024 Jan 12. doi: 10.1097/IOP.0000000000002567.

PMID- 37548379
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230816
IS  - 1520-5126 (Electronic)
IS  - 0002-7863 (Linking)
VI  - 145
IP  - 32
DP  - 2023 Aug 16
TI  - ChatGPT Chemistry Assistant for Text Mining and the Prediction of MOF Synthesis.
PG  - 18048-18062
LID - 10.1021/jacs.3c05819 [doi]
AB  - We use prompt engineering to guide ChatGPT in the automation of text mining of 
      metal-organic framework (MOF) synthesis conditions from diverse formats and 
      styles of the scientific literature. This effectively mitigates ChatGPT's 
      tendency to hallucinate information, an issue that previously made the use of 
      large language models (LLMs) in scientific fields challenging. Our approach 
      involves the development of a workflow implementing three different processes for 
      text mining, programmed by ChatGPT itself. All of them enable parsing, searching, 
      filtering, classification, summarization, and data unification with different 
      trade-offs among labor, speed, and accuracy. We deploy this system to extract 
      26 257 distinct synthesis parameters pertaining to approximately 800 MOFs sourced 
      from peer-reviewed research articles. This process incorporates our ChemPrompt 
      Engineering strategy to instruct ChatGPT in text mining, resulting in impressive 
      precision, recall, and F1 scores of 90-99%. Furthermore, with the data set built 
      by text mining, we constructed a machine-learning model with over 87% accuracy in 
      predicting MOF experimental crystallization outcomes and preliminarily 
      identifying important factors in MOF crystallization. We also developed a 
      reliable data-grounded MOF chatbot to answer questions about chemical reactions 
      and synthesis procedures. Given that the process of using ChatGPT reliably mines 
      and tabulates diverse MOF synthesis information in a unified format while using 
      only narrative language requiring no coding expertise, we anticipate that our 
      ChatGPT Chemistry Assistant will be very useful across various other chemistry 
      subdisciplines.
FAU - Zheng, Zhiling
AU  - Zheng Z
AUID- ORCID: 0000-0001-6090-2258
AD  - Department of Chemistry, University of California, Berkeley, California 94720, 
      United States.
AD  - Kavli Energy Nanoscience Institute, University of California, Berkeley, 
      California 94720, United States.
AD  - Bakar Institute of Digital Materials for the Planet, College of Computing, Data 
      Science, and Society, University of California, Berkeley, California 94720, 
      United States.
FAU - Zhang, Oufan
AU  - Zhang O
FAU - Borgs, Christian
AU  - Borgs C
AD  - Bakar Institute of Digital Materials for the Planet, College of Computing, Data 
      Science, and Society, University of California, Berkeley, California 94720, 
      United States.
AD  - Department of Electrical Engineering and Computer Sciences, University of 
      California, Berkeley, California 94720, United States.
FAU - Chayes, Jennifer T
AU  - Chayes JT
AD  - Bakar Institute of Digital Materials for the Planet, College of Computing, Data 
      Science, and Society, University of California, Berkeley, California 94720, 
      United States.
AD  - Department of Electrical Engineering and Computer Sciences, University of 
      California, Berkeley, California 94720, United States.
AD  - Department of Mathematics, University of California, Berkeley, California 94720, 
      United States.
AD  - Department of Statistics, University of California, Berkeley, California 94720, 
      United States.
AD  - School of Information, University of California, Berkeley, California 94720, 
      United States.
FAU - Yaghi, Omar M
AU  - Yaghi OM
AUID- ORCID: 0000-0002-5611-3325
AD  - Department of Chemistry, University of California, Berkeley, California 94720, 
      United States.
AD  - Kavli Energy Nanoscience Institute, University of California, Berkeley, 
      California 94720, United States.
AD  - Bakar Institute of Digital Materials for the Planet, College of Computing, Data 
      Science, and Society, University of California, Berkeley, California 94720, 
      United States.
AD  - KACST-UC Berkeley Center of Excellence for Nanomaterials for Clean Energy 
      Applications, King Abdulaziz City for Science and Technology, Riyadh 11442, Saudi 
      Arabia.
LA  - eng
PT  - Journal Article
DEP - 20230807
PL  - United States
TA  - J Am Chem Soc
JT  - Journal of the American Chemical Society
JID - 7503056
SB  - IM
EDAT- 2023/08/07 13:10
MHDA- 2023/08/07 13:11
CRDT- 2023/08/07 08:03
PHST- 2023/08/07 13:11 [medline]
PHST- 2023/08/07 13:10 [pubmed]
PHST- 2023/08/07 08:03 [entrez]
AID - 10.1021/jacs.3c05819 [doi]
PST - ppublish
SO  - J Am Chem Soc. 2023 Aug 16;145(32):18048-18062. doi: 10.1021/jacs.3c05819. Epub 
      2023 Aug 7.

PMID- 36929393
OWN - NLM
STAT- MEDLINE
DCOM- 20230321
LR  - 20230331
IS  - 2515-5091 (Electronic)
IS  - 2515-5091 (Linking)
VI  - 7
IP  - 2
DP  - 2023 Mar 1
TI  - Using ChatGPT to evaluate cancer myths and misconceptions: artificial 
      intelligence and cancer information.
LID - 10.1093/jncics/pkad015 [doi]
LID - pkad015
AB  - Data about the quality of cancer information that chatbots and other artificial 
      intelligence systems provide are limited. Here, we evaluate the accuracy of 
      cancer information on ChatGPT compared with the National Cancer Institute's 
      (NCI's) answers by using the questions on the "Common Cancer Myths and 
      Misconceptions" web page. The NCI's answers and ChatGPT answers to each question 
      were blinded, and then evaluated for accuracy (accurate: yes vs no). Ratings were 
      evaluated independently for each question, and then compared between the blinded 
      NCI and ChatGPT answers. Additionally, word count and Flesch-Kincaid readability 
      grade level for each individual response were evaluated. Following expert review, 
      the percentage of overall agreement for accuracy was 100% for NCI answers and 
      96.9% for ChatGPT outputs for questions 1 through 13 (ĸ = ‒0.03, standard 
      error = 0.08). There were few noticeable differences in the number of words or 
      the readability of the answers from NCI or ChatGPT. Overall, the results suggest 
      that ChatGPT provides accurate information about common cancer myths and 
      misconceptions.
CI  - © The Author(s) 2023. Published by Oxford University Press.
FAU - Johnson, Skyler B
AU  - Johnson SB
AUID- ORCID: 0000-0002-8881-7706
AD  - Department of Radiation Oncology, University of Utah School of Medicine, Huntsman 
      Cancer Institute, Salt Lake City, UT, USA.
AD  - Cancer Control and Population Sciences, Huntsman Cancer Institute, Salt Lake 
      City, UT, USA.
FAU - King, Andy J
AU  - King AJ
AD  - Cancer Control and Population Sciences, Huntsman Cancer Institute, Salt Lake 
      City, UT, USA.
AD  - Department of Communication, University of Utah, Salt Lake City, UT, USA.
FAU - Warner, Echo L
AU  - Warner EL
AD  - Cancer Control and Population Sciences, Huntsman Cancer Institute, Salt Lake 
      City, UT, USA.
AD  - College of Nursing, University of Utah, Salt Lake City, UT, USA.
FAU - Aneja, Sanjay
AU  - Aneja S
AD  - Center for Outcomes Research and Evaluation, Yale School of Medicine, New Haven, 
      CT, USA.
AD  - Department of Therapeutic Radiology, Yale School of Medicine, New Haven, CT, USA.
FAU - Kann, Benjamin H
AU  - Kann BH
AD  - Department of Radiation Oncology, Dana-Farber Cancer Institute/Brigham and 
      Women's Hospital, Harvard Medical School, Boston, MA, USA.
FAU - Bylund, Carma L
AU  - Bylund CL
AD  - Department of Health Outcomes and Biomedical Informatics, University of Florida 
      College of Medicine, Gainesville, FL, USA.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - England
TA  - JNCI Cancer Spectr
JT  - JNCI cancer spectrum
JID - 101721827
SB  - IM
MH  - United States/epidemiology
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Neoplasms/diagnosis
MH  - National Cancer Institute (U.S.)
PMC - PMC10020140
COIS- All authors had full access to all the data in the study and take responsibility 
      for the integrity of the data and the accuracy of the data analysis. Skyler B. 
      Johnson, MD, has no financial conflicts of interest. All other researchers 
      reported no financial conflicts of interests.
EDAT- 2023/03/18 06:00
MHDA- 2023/03/22 06:00
PMCR- 2023/03/17
CRDT- 2023/03/17 10:05
PHST- 2023/01/11 00:00 [received]
PHST- 2023/02/13 00:00 [revised]
PHST- 2023/02/16 00:00 [accepted]
PHST- 2023/03/17 10:05 [entrez]
PHST- 2023/03/18 06:00 [pubmed]
PHST- 2023/03/22 06:00 [medline]
PHST- 2023/03/17 00:00 [pmc-release]
AID - 7078555 [pii]
AID - pkad015 [pii]
AID - 10.1093/jncics/pkad015 [doi]
PST - ppublish
SO  - JNCI Cancer Spectr. 2023 Mar 1;7(2):pkad015. doi: 10.1093/jncics/pkad015.

PMID- 38349133
OWN - NLM
STAT- In-Process
LR  - 20240403
IS  - 1728-7731 (Electronic)
IS  - 1726-4901 (Linking)
VI  - 87
IP  - 4
DP  - 2024 Apr 1
TI  - ChatGPT's innovative application in blood morphology recognition.
PG  - 428-433
LID - 10.1097/JCMA.0000000000001071 [doi]
AB  - BACKGROUND: Recently, the rapid advancement in generative artificial intelligence 
      (AI) technology, such as ChatGPT-4, has sparked discussions, particularly in 
      image recognition. Accurate results are critical for hematological diagnosis, 
      particularly for blood morphology identification. Despite advanced hematology 
      analyzers, reliance on professional hematopathologists for manual identification 
      remains in cases of abnormal or rare conditions, a process prone to human 
      subjectivity and potential errors. Consequently, this study aimed to investigate 
      the potential of ChatGPT-4 to assist with blood morphology identification. 
      METHODS: We conducted a retrospective study using blood images obtained from the 
      American Society of Hematology (ASH). These images comprised a range of normal 
      and abnormal morphologies. Each sample was analyzed by expert technicians 
      (control group) and classified using ChatGPT-4 (test group). RESULTS: Preliminary 
      results showed that ChatGPT-4 could identify normal blood cells with an accuracy 
      of 88%, exceeding the accuracy of identifying abnormal blood cells at a rate of 
      54%. Regarding identifying abnormal cells, the accuracy of ChatGPT-4 was slightly 
      higher than that of the manual method, which was 49.5%. CONCLUSION: This study 
      shows that although generative AI shows the potential for blood type 
      identification, it has not yet reached the point where it can replace the 
      professional judgment of medical staff. The results showed that ChatGPT-4 is 
      excellent for identifying red blood cell morphology, particularly inclusion 
      bodies. It can be used as an auxiliary tool for clinical diagnosis. However, the 
      overall recognition accuracy must be further improved. Our study produced 
      innovative results in this field, establishing a foundation for future studies 
      and highlighting the potential of generative AI in aiding blood morphology 
      recognition. Future research should focus on enhancing the effectiveness of AI to 
      improve overall standards of medical care.
CI  - Copyright © 2024, the Chinese Medical Association.
FAU - Yang, Wan-Hua
AU  - Yang WH
AD  - Department of Pathology and Laboratory, Taipei Veterans General Hospital Hsinchu 
      Branch, Hsinchu, Taiwan, ROC.
AD  - Department of Industrial Engineering and Management, Yuan Ze University, Taoyuan, 
      Taiwan, ROC.
AD  - Department of Medical Laboratory Science and Biotechnology, Yuanpei University of 
      Medical Technology, Hsinchu, Taiwan, ROC.
FAU - Yang, Yi-Ju
AU  - Yang YJ
AD  - Department of Pathology and Laboratory, Taipei Veterans General Hospital Hsinchu 
      Branch, Hsinchu, Taiwan, ROC.
FAU - Chen, Tzeng-Ji
AU  - Chen TJ
AD  - Department of Family Medicine, Taipei Veterans General Hospital Hsinchu Branch, 
      Hsinchu, Taiwan, ROC.
AD  - Department of Family Medicine, Taipei Veterans General Hospital, Taipei, Taiwan, 
      ROC.
AD  - Department of Post-Baccalaureate Medicine, National Chung Hsing University, 
      Taichung, Taiwan, ROC.
LA  - eng
PT  - Journal Article
DEP - 20240213
PL  - Netherlands
TA  - J Chin Med Assoc
JT  - Journal of the Chinese Medical Association : JCMA
JID - 101174817
SB  - IM
COIS- Conflicts of interest: Dr. Tzeng-Ji Chen, an editorial board member at Journal of 
      the Chinese Medical Association , had no role in the peer review process of or 
      decision to publish this article. The other authors declare that they have no 
      conflicts of interest related to the subject matter or materials discussed in 
      this article.
EDAT- 2024/02/13 12:48
MHDA- 2024/02/13 12:48
CRDT- 2024/02/13 09:03
PHST- 2024/02/13 12:48 [pubmed]
PHST- 2024/02/13 12:48 [medline]
PHST- 2024/02/13 09:03 [entrez]
AID - 02118582-990000000-00349 [pii]
AID - 10.1097/JCMA.0000000000001071 [doi]
PST - ppublish
SO  - J Chin Med Assoc. 2024 Apr 1;87(4):428-433. doi: 10.1097/JCMA.0000000000001071. 
      Epub 2024 Feb 13.

PMID- 37908933
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231102
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 9
DP  - 2023 Sep
TI  - Utilizing ChatGPT-4 for Providing Information on Periodontal Disease to Patients: 
      A DISCERN Quality Analysis.
PG  - e46213
LID - 10.7759/cureus.46213 [doi]
LID - e46213
AB  - BACKGROUND: Due to their ability to mimic human responses, anthropomorphic 
      entities such as ChatGPT have a higher likelihood of gaining people's trust. This 
      study aimed to evaluate the quality of information generated by ChatGPT-4, as an 
      artificial intelligence (AI) chatbot, on periodontal disease (PD) using the 
      DISCERN instrument. METHODS: Using Google Bard, the topics related to PD that had 
      the highest search volume according to Google Trends were identified. An 
      interactive dialogue was created by placing the topics in the standard question 
      pattern. As a patient with PD, detailed information was requested from ChatGPT-4 
      regarding the relevant topics. The 'regenerate response' feature was not 
      employed, and the initial response generated by ChatGPT-4 was carefully 
      considered for each topic as new prompts in the form of questions were entered. 
      The response to each question was independently assessed and rated by two 
      experienced raters using the DISCERN instrument. RESULTS: Based on the total 
      DISCERN scores, the qualities of the responses generated by ChatGPT-4 were 
      'good', except for the two responses that rater-2 scored as 'fair'. It was also 
      observed that the 'treatment choices' section of both raters had significantly 
      fewer scores than the other sections. In both weighted kappa and Krippendorff 
      alpha measures, the strength of agreement varied from 'substantial' to 
      'almost-perfect', and the correlation between values was statistically 
      significant. CONCLUSION: Despite some limitations in providing complete treatment 
      choice information according to the DISCERN instrument, it is considered valuable 
      for PD patients seeking information, as it consistently offered accurate guidance 
      in the majority of responses.
CI  - Copyright © 2023, Alan et al.
FAU - Alan, Raif
AU  - Alan R
AD  - Periodontology, Faculty of Dentistry, Canakkale Onsekiz Mart University, 
      Canakkale, TUR.
FAU - Alan, Betül Melek
AU  - Alan BM
AD  - General Dentistry, Private Practice, Canakkale, TUR.
LA  - eng
PT  - Journal Article
DEP - 20230929
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10613831
OTO - NOTNLM
OT  - artificial intelligence
OT  - chatbot
OT  - health information management
OT  - oral health
OT  - periodontal disease
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/11/01 06:43
MHDA- 2023/11/01 06:44
PMCR- 2023/09/29
CRDT- 2023/11/01 04:04
PHST- 2023/09/29 00:00 [accepted]
PHST- 2023/11/01 06:44 [medline]
PHST- 2023/11/01 06:43 [pubmed]
PHST- 2023/11/01 04:04 [entrez]
PHST- 2023/09/29 00:00 [pmc-release]
AID - 10.7759/cureus.46213 [doi]
PST - epublish
SO  - Cureus. 2023 Sep 29;15(9):e46213. doi: 10.7759/cureus.46213. eCollection 2023 
      Sep.

PMID- 37882183
OWN - NLM
STAT- MEDLINE
DCOM- 20240327
LR  - 20240327
IS  - 1938-2405 (Electronic)
IS  - 0191-3913 (Linking)
VI  - 61
IP  - 2
DP  - 2024 Mar-Apr
TI  - Assessment of the Responses of the Artificial Intelligence-based Chatbot 
      ChatGPT-4 to Frequently Asked Questions About Amblyopia and Childhood Myopia.
PG  - 86-89
LID - 10.3928/01913913-20231005-02 [doi]
AB  - PURPOSE: To assess the responses of the ChatGPT-4, the forerunner artificial 
      intelligence-based chatbot, to frequently asked questions regarding two common 
      pediatric ophthalmologic disorders, amblyopia and childhood myopia. METHODS: 
      Twenty-seven questions about amblyopia and 28 questions about childhood myopia 
      were asked of the ChatGPT twice (totally 110 questions). The responses were 
      evaluated by two pediatric ophthalmologists as acceptable, incomplete, or 
      unacceptable. RESULTS: There was remarkable agreement (96.4%) between the two 
      pediatric ophthalmologists on their assessment of the responses. Acceptable 
      responses were provided by the ChatGPT to 93 of 110 (84.6%) questions in total 
      (44 of 54 [81.5%] for amblyopia and 49 of 56 [87.5%] questions for childhood 
      myopia). Seven of 54 (12.9%) responses to questions on amblyopia were graded as 
      incomplete compared to 4 of 56 (7.1%) of questions on childhood myopia. The 
      ChatGPT gave inappropriate responses to three questions about amblyopia (5.6%) 
      and childhood myopia (5.4%). The most noticeable inappropriate responses were 
      related to the definition of reverse amblyopia and the threshold of refractive 
      error for prescription of spectacles to children with myopia. CONCLUSIONS: The 
      ChatGPT has the potential to serve as an adjunct informational tool for pediatric 
      ophthalmology patients and their caregivers by demonstrating a relatively good 
      performance in answering 84.6% of the most frequently asked questions about 
      amblyopia and childhood myopia. [J Pediatr Ophthalmol Strabismus. 
      2024;61(2):86-89.].
FAU - Nikdel, Mojgan
AU  - Nikdel M
FAU - Ghadimi, Hadi
AU  - Ghadimi H
FAU - Tavakoli, Mehdi
AU  - Tavakoli M
FAU - Suh, Donny W
AU  - Suh DW
LA  - eng
PT  - Journal Article
DEP - 20231026
PL  - United States
TA  - J Pediatr Ophthalmol Strabismus
JT  - Journal of pediatric ophthalmology and strabismus
JID - 7901143
SB  - IM
MH  - Humans
MH  - Child
MH  - Artificial Intelligence
MH  - *Amblyopia/diagnosis/therapy
MH  - *Myopia/diagnosis/therapy
MH  - *Refractive Errors
MH  - *Ophthalmologists
EDAT- 2023/10/26 12:42
MHDA- 2024/03/27 06:43
CRDT- 2023/10/26 06:47
PHST- 2024/03/27 06:43 [medline]
PHST- 2023/10/26 12:42 [pubmed]
PHST- 2023/10/26 06:47 [entrez]
AID - 10.3928/01913913-20231005-02 [doi]
PST - ppublish
SO  - J Pediatr Ophthalmol Strabismus. 2024 Mar-Apr;61(2):86-89. doi: 
      10.3928/01913913-20231005-02. Epub 2023 Oct 26.

PMID- 38488302
OWN - NLM
STAT- Publisher
LR  - 20240315
IS  - 1097-6817 (Electronic)
IS  - 0194-5998 (Linking)
DP  - 2024 Mar 15
TI  - ChatGPT for Automated Cross-Checking of Authors' Conflicts of Interest Against 
      Industry Payments.
LID - 10.1002/ohn.720 [doi]
AB  - OBJECTIVE: The Centers for Medicare &amp; Medicaid Services "OpenPayments" database 
      tracks industry payments to US physicians to improve research conflicts of 
      interest (COIs) transparency, but manual cross-checking of articles' authors 
      against this database is labor-intensive. This study aims to assess the potential 
      of large language models (LLMs) like ChatGPT to automate COI data analysis in 
      medical publications. STUDY DESIGN: An observational study analyzing the accuracy 
      of ChatGPT in automating the cross-checking of COI disclosures in medical 
      research articles against the OpenPayments database. SETTING: Publications 
      regarding Food and Drug Administration-approved biologics for chronic 
      rhinosinusitis with nasal polyposis: omalizumab, mepolizumab, and dupilumab. 
      METHODS: First, ChatGPT evaluated author affiliations from PubMed to identify 
      those based in the United States. Second, for author names matching 1 or multiple 
      payment recipients in OpenPayments, ChatGPT undertook a comparative analysis 
      between author affiliation and OpenPayments recipient metadata. Third, ChatGPT 
      scrutinized full article COI statements, producing an intricate matrix of 
      disclosures for each author against each relevant company (Sanofi, Regeneron, 
      Genentech, Novartis, and GlaxoSmithKline). A random subset of responses was 
      manually checked for accuracy. RESULTS: In total, 78 relevant articles and 294 
      unique US authors were included, leading to 980 LLM queries. Manual verification 
      showed accuracies of 100% (200/200; 95% confidence interval [CI]: 98.1%-100%) for 
      country analysis, 97.4% (113/116; 95% CI: 92.7%-99.1%) for matching author 
      affiliations with OpenPayments metadata, and 99.2% (1091/1100; 95% CI: 
      98.5%-99.6%) for COI statement data extraction. CONCLUSION: LLMs have robust 
      potential to automate author-company-specific COI cross-checking against the 
      OpenPayments database. Our findings pave the way for streamlined, efficient, and 
      accurate COI assessment that could be widely employed across medical research.
CI  - © 2024 American Academy of Otolaryngology-Head and Neck Surgery Foundation.
FAU - Safranek, Conrad
AU  - Safranek C
AUID- ORCID: 0000-0003-1985-9432
AD  - Department of Surgery, Division of Otolaryngology, Yale School of Medicine, New 
      Haven, Connecticut, USA.
AD  - Section for Biomedical Informatics and Data Science, Yale University School of 
      Medicine, New Haven, Connecticut, USA.
FAU - Liu, Christina
AU  - Liu C
AD  - Department of Surgery, Division of Otolaryngology, Yale School of Medicine, New 
      Haven, Connecticut, USA.
FAU - Richmond, Rhys
AU  - Richmond R
AD  - Department of Surgery, Division of Otolaryngology, Yale School of Medicine, New 
      Haven, Connecticut, USA.
FAU - Boyi, Trinithas
AU  - Boyi T
AD  - Department of Surgery, Division of Otolaryngology, Yale School of Medicine, New 
      Haven, Connecticut, USA.
FAU - Rimmer, Ryan
AU  - Rimmer R
AD  - Department of Surgery, Division of Otolaryngology, Yale School of Medicine, New 
      Haven, Connecticut, USA.
FAU - Manes, R Peter
AU  - Manes RP
AD  - Department of Surgery, Division of Otolaryngology, Yale School of Medicine, New 
      Haven, Connecticut, USA.
LA  - eng
PT  - Journal Article
DEP - 20240315
PL  - England
TA  - Otolaryngol Head Neck Surg
JT  - Otolaryngology--head and neck surgery : official journal of American Academy of 
      Otolaryngology-Head and Neck Surgery
JID - 8508176
SB  - IM
OTO - NOTNLM
OT  - CMS openpayments
OT  - ChatGPT
OT  - artificial intelligence
OT  - biologics
OT  - conflict of interest
OT  - data analysis automation
OT  - large language models
OT  - nasal polyps
OT  - pharmaceutical funding
EDAT- 2024/03/15 12:45
MHDA- 2024/03/15 12:45
CRDT- 2024/03/15 08:45
PHST- 2024/01/24 00:00 [revised]
PHST- 2023/12/03 00:00 [received]
PHST- 2024/02/17 00:00 [accepted]
PHST- 2024/03/15 12:45 [medline]
PHST- 2024/03/15 12:45 [pubmed]
PHST- 2024/03/15 08:45 [entrez]
AID - 10.1002/ohn.720 [doi]
PST - aheadofprint
SO  - Otolaryngol Head Neck Surg. 2024 Mar 15. doi: 10.1002/ohn.720.

PMID- 37974429
OWN - NLM
STAT- MEDLINE
DCOM- 20240227
LR  - 20240227
IS  - 1724-6016 (Electronic)
IS  - 1120-6721 (Linking)
VI  - 34
IP  - 2
DP  - 2024 Mar
TI  - Leveraging ChatGPT for ophthalmic education: A critical appraisal.
PG  - 323-327
LID - 10.1177/11206721231215862 [doi]
AB  - In recent years, the advent of artificial intelligence (AI) has transformed many 
      sectors, including medical education. This editorial critically appraises the 
      integration of ChatGPT, a state-of-the-art AI language model, into ophthalmic 
      education, focusing on its potential, limitations, and ethical considerations. 
      The application of ChatGPT in teaching and training ophthalmologists presents an 
      innovative method to offer real-time, customized learning experiences. Through a 
      systematic analysis of both experimental and clinical data, this editorial 
      examines how ChatGPT enhances engagement, understanding, and retention of complex 
      ophthalmological concepts. The study also evaluates the efficacy of ChatGPT in 
      simulating patient interactions and clinical scenarios, which can foster improved 
      diagnostic and interpersonal skills. Despite the promising advantages, concerns 
      regarding reliability, lack of personal touch, and potential biases in the 
      AI-generated content are scrutinized. Ethical considerations concerning data 
      privacy and potential misuse are also explored. The findings underline the need 
      for carefully designed integration, continuous evaluation, and adherence to 
      ethical guidelines to maximize benefits while mitigating risks. By shedding light 
      on these multifaceted aspects, this paper contributes to the ongoing discourse on 
      the incorporation of AI in medical education, offering valuable insights and 
      guidance for educators, practitioners, and policymakers aiming to leverage modern 
      technology for enhancing ophthalmic education.
FAU - Gurnani, Bharat
AU  - Gurnani B
AUID- ORCID: 0000-0003-0848-5172
AD  - Cataract, Cornea, Trauma, External Diseases, Ocular Surface and Refractive 
      Services, ASG Eye Hospital, Jodhpur, Rajasthan, India.
AD  - Sadguru Netra Chikitsalya, Shri Sadguru Seva Sangh Trust, Chitrakoot, Madhya 
      Pradesh, India.
FAU - Kaur, Kirandeep
AU  - Kaur K
AUID- ORCID: 0000-0002-0951-7415
AD  - Cataract, Pediatric Ophthalmology and Strabismus, ASG Eye Hospital, Jodhpur, 
      Rajasthan, India.
AD  - Children Eye Care Centre, Sadguru Netra Chikitsalya, Shri Sadguru Seva Sangh 
      Trust, Chitrakoot, Madhya Pradesh, India.
LA  - eng
PT  - Editorial
DEP - 20231116
PL  - United States
TA  - Eur J Ophthalmol
JT  - European journal of ophthalmology
JID - 9110772
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Reproducibility of Results
MH  - Eye
MH  - Language
MH  - *Ophthalmologists
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - ophthalmology education
COIS- Declaration of conflicting interestsThe author(s) declared no potential conflicts 
      of interest with respect to the research, authorship, and/or publication of this 
      article.
EDAT- 2023/11/17 15:24
MHDA- 2024/02/27 06:44
CRDT- 2023/11/17 03:42
PHST- 2024/02/27 06:44 [medline]
PHST- 2023/11/17 15:24 [pubmed]
PHST- 2023/11/17 03:42 [entrez]
AID - 10.1177/11206721231215862 [doi]
PST - ppublish
SO  - Eur J Ophthalmol. 2024 Mar;34(2):323-327. doi: 10.1177/11206721231215862. Epub 
      2023 Nov 16.

PMID- 37965416
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231116
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 10
DP  - 2023 Oct
TI  - Ectopic Pituitary Neuroendocrine Tumor: A Case Report Written With the Help of 
      ChatGPT.
PG  - e46999
LID - 10.7759/cureus.46999 [doi]
LID - e46999
AB  - ChatGPT (Chat Generative Pre-trained Transformer) is a chat robot program 
      developed by OpenAI (OpenAI Incorporated, Mission District, San Francisco, USA). 
      It is a natural-language processing tool driven by artificial intelligence 
      technology. It can complete tasks such as writing emails, video scripts, 
      copywriting, translation, coding, and writing papers. At present, several studies 
      have been conducted on the use of this tool for academic writing, so we report a 
      rare case of suprasellar ectopic pituitary neuroendocrine tumor (PitNET) 
      secreting growth hormones, in a female 53-year-old patient with facial changes 
      and hypertrophy of her hands and feet for six years. When asking questions on 
      unusual topics, ChatGPT can provide answers but not specific ones, and similar to 
      most machine learning solutions, verifying the correctness of information is&nbsp;a 
      problem. Question asked from ChatGPT: Summarize ectopic pituitary neuroendocrine 
      tumor. "Suprasellar heterotopic pituitary neuroendocrine tumors refer to tumors 
      formed by the heterotopic growth of pituitary neuroendocrine tumor cells in the 
      sellar region other than the pituitary glands. This tumor is common in 
      middle-aged women, and it often manifests as headache, visual impairment, and 
      endocrine dysfunction. Diagnosis is usually made by combining history, physical 
      examination, blood tests, and imaging. Treatment is primarily performed through 
      surgical resection of the tumor, radiotherapy, and drug therapy, and the 
      prognosis is mostly good." The content in quotation marks is generated by 
      ChatGPT.
CI  - Copyright © 2023, Li et al.
FAU - Li, Jun
AU  - Li J
AD  - Neurosurgery, Department of Neurosurgery, Fuzhou 900th Hospital, Fuzong Clinical 
      Medical College of Fujian Medical University, Fuzhou, CHN.
FAU - Zhong, Jiansheng
AU  - Zhong J
AD  - Neurosurgery, Department of Neurosurgery, Fuzhou 900th Hospital, Fuzong Clinical 
      Medical College of Fujian Medical University, Fuzhou, CHN.
FAU - Li, Ziqi
AU  - Li Z
AD  - Neurosurgery, Department of Neurosurgery, Oriental Hospital Affiliated to Xiamen 
      University, Fuzhou, CHN.
FAU - Xiao, Yong
AU  - Xiao Y
AD  - Neurosurgery, Central Institute for Mental Health, University of Heidelberg, 
      Heidelberg, DEU.
FAU - Wang, Shousen
AU  - Wang S
AD  - Neurosurgery, Department of Neurosurgery, Oriental Hospital Affiliated to Xiamen 
      University, Fuzhou, CHN.
LA  - eng
PT  - Case Reports
DEP - 20231013
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10641033
OTO - NOTNLM
OT  - artificial intelligence
OT  - brain tumor
OT  - chatgpt
OT  - ectopic pituitary neuroendocrine tumor
OT  - neuro-oncology
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/11/15 06:42
MHDA- 2023/11/15 06:43
PMCR- 2023/10/13
CRDT- 2023/11/15 04:26
PHST- 2023/10/12 00:00 [accepted]
PHST- 2023/11/15 06:43 [medline]
PHST- 2023/11/15 06:42 [pubmed]
PHST- 2023/11/15 04:26 [entrez]
PHST- 2023/10/13 00:00 [pmc-release]
AID - 10.7759/cureus.46999 [doi]
PST - epublish
SO  - Cureus. 2023 Oct 13;15(10):e46999. doi: 10.7759/cureus.46999. eCollection 2023 
      Oct.

PMID- 37259767
OWN - NLM
STAT- MEDLINE
DCOM- 20230710
LR  - 20231116
IS  - 1469-3178 (Electronic)
IS  - 1469-221X (Print)
IS  - 1469-221X (Linking)
VI  - 24
IP  - 7
DP  - 2023 Jul 5
TI  - The (mis)use of ChatGPT in science and education: Turing, Djerassi, "athletics" &amp; 
      ethics.
PG  - e57501
LID - 10.15252/embr.202357501 [doi]
LID - e57501
AB  - ChatGPT is an amazing advance in technology, but it poses problems for teachers 
      in universities and schools. How should use of ChatGPT by students be dealt with?
CI  - © 2023 The Authors.
FAU - Shaw, David
AU  - Shaw D
AUID- ORCID: 0000-0001-8180-6927
AD  - Institute for Biomedical Ethics, University of Basel, Basel, Switzerland.
AD  - Department of Health, Ethics and Society, Care and Public Health Research 
      Institute, Maastricht University, Maastricht, The Netherlands.
FAU - Morfeld, Peter
AU  - Morfeld P
AD  - Institute and Policlinic for Occupational Medicine, Environmental Medicine and 
      Prevention Research, University Hospital of Cologne, Cologne, Germany.
FAU - Erren, Thomas
AU  - Erren T
AD  - Institute and Policlinic for Occupational Medicine, Environmental Medicine and 
      Prevention Research, University Hospital of Cologne, Cologne, Germany.
LA  - eng
PT  - Journal Article
DEP - 20230601
PL  - England
TA  - EMBO Rep
JT  - EMBO reports
JID - 100963049
SB  - IM
MH  - Humans
MH  - *Schools
MH  - Universities
MH  - *Students
MH  - Technology
PMC - PMC10328063
EDAT- 2023/06/01 06:42
MHDA- 2023/07/10 06:42
PMCR- 2024/06/01
CRDT- 2023/06/01 04:09
PHST- 2023/05/16 00:00 [received]
PHST- 2023/05/17 00:00 [accepted]
PHST- 2024/06/01 00:00 [pmc-release]
PHST- 2023/07/10 06:42 [medline]
PHST- 2023/06/01 06:42 [pubmed]
PHST- 2023/06/01 04:09 [entrez]
AID - EMBR202357501 [pii]
AID - 10.15252/embr.202357501 [doi]
PST - ppublish
SO  - EMBO Rep. 2023 Jul 5;24(7):e57501. doi: 10.15252/embr.202357501. Epub 2023 Jun 1.

PMID- 38170831
OWN - NLM
STAT- Publisher
LR  - 20240403
IS  - 1546-3141 (Electronic)
IS  - 0361-803X (Linking)
DP  - 2024 Mar 13
TI  - Appropriateness of Information Provided by ChatGPT Regarding Breast Pathologic 
      Diagnoses.
PG  - 1-3
LID - 10.2214/AJR.23.30548 [doi]
FAU - Oluyemi, Eniola T
AU  - Oluyemi ET
AD  - Johns Hopkins University School of Medicine, Baltimore, MD.
FAU - Ambinder, Emily B
AU  - Ambinder EB
AD  - Johns Hopkins University School of Medicine, Baltimore, MD.
FAU - Sogunro, Olutayo
AU  - Sogunro O
AD  - Johns Hopkins University School of Medicine, Baltimore, MD.
FAU - White, Marissa J
AU  - White MJ
AD  - Johns Hopkins University School of Medicine, Baltimore, MD.
FAU - Yi, Paul H
AU  - Yi PH
AD  - University of Maryland School of Medicine, Baltimore, MD.
FAU - Myers, Kelly S
AU  - Myers KS
AD  - Johns Hopkins University School of Medicine, Baltimore, MD.
LA  - eng
PT  - Journal Article
DEP - 20240313
PL  - United States
TA  - AJR Am J Roentgenol
JT  - AJR. American journal of roentgenology
JID - 7708173
SB  - IM
OAB - A multidisciplinary physician team rated information provided by ChatGPT 
      regarding breast pathologic diagnoses. ChatGPT responses were mostly appropriate 
      regarding accuracy, consistency, definitions provided, and clinical significance 
      conveyed. Responses were scored lower in terms of management recommendations 
      provided, primarily related to low agreement with recommendations for high-risk 
      lesions.
OABL- eng
EDAT- 2024/01/04 01:18
MHDA- 2024/01/04 01:18
CRDT- 2024/01/03 14:33
PHST- 2024/01/04 01:18 [pubmed]
PHST- 2024/01/04 01:18 [medline]
PHST- 2024/01/03 14:33 [entrez]
AID - 10.2214/AJR.23.30548 [doi]
PST - aheadofprint
SO  - AJR Am J Roentgenol. 2024 Mar 13:1-3. doi: 10.2214/AJR.23.30548.

PMID- 38066714
OWN - NLM
STAT- MEDLINE
DCOM- 20240311
LR  - 20240311
IS  - 1552-4833 (Electronic)
IS  - 1552-4825 (Linking)
VI  - 194
IP  - 4
DP  - 2024 Apr
TI  - Genetic counselors' utilization of ChatGPT in professional practice: A 
      cross-sectional study.
PG  - e63493
LID - 10.1002/ajmg.a.63493 [doi]
AB  - PURPOSE: The precision medicine era has seen increased utilization of artificial 
      intelligence (AI) in the field of genetics. We sought to explore the ways that 
      genetic counselors (GCs) currently use the publicly accessible AI tool Chat 
      Generative Pre-trained Transformer (ChatGPT) in their work. METHODS: GCs in North 
      America were surveyed about how ChatGPT is used in different aspects of their 
      work. Descriptive statistics were reported through frequencies and means. 
      RESULTS: Of 118 GCs who completed the survey, 33.8% (40) reported using ChatGPT 
      in their work; 47.5% (19) use it in clinical practice, 35% (14) use it in 
      education, and 32.5% (13) use it in research. Most GCs (62.7%; 74) felt that it 
      saves time on administrative tasks but the majority (82.2%; 97) felt that a 
      paramount challenge was the risk of obtaining incorrect information. The majority 
      of GCs not using ChatGPT (58.9%; 46) felt it was not necessary for their work. 
      CONCLUSION: A considerable number of GCs in the field are using ChatGPT in 
      different ways, but it is primarily helpful with tasks that involve writing. It 
      has potential to streamline workflow issues encountered in clinical genetics, but 
      practitioners need to be informed and uniformly trained about its limitations.
CI  - © 2023 Wiley Periodicals LLC.
FAU - Ahimaz, Priyanka
AU  - Ahimaz P
AUID- ORCID: 0000-0001-5112-1599
AD  - Genetic Counseling Graduate Program, Vagelos College of Physicians and Surgeons, 
      Columbia University, New York, New York, USA.
AD  - Department of Pediatrics, Vagelos College of Physicians and Surgeons, Columbia 
      University, New York, New York, USA.
FAU - Bergner, Amanda L
AU  - Bergner AL
AD  - Genetic Counseling Graduate Program, Vagelos College of Physicians and Surgeons, 
      Columbia University, New York, New York, USA.
AD  - Department of Genetics and Development, Vagelos College of Physicians and 
      Surgeons, Columbia University, New York, New York, USA.
AD  - Department of Neurology, Vagelos College of Physicians and Surgeons, Columbia 
      University, New York, New York, USA.
FAU - Florido, Michelle E
AU  - Florido ME
AD  - Genetic Counseling Graduate Program, Vagelos College of Physicians and Surgeons, 
      Columbia University, New York, New York, USA.
AD  - Department of Genetics and Development, Vagelos College of Physicians and 
      Surgeons, Columbia University, New York, New York, USA.
FAU - Harkavy, Nina
AU  - Harkavy N
AD  - Genetic Counseling Graduate Program, Vagelos College of Physicians and Surgeons, 
      Columbia University, New York, New York, USA.
AD  - Department of Obstetrics and Gynecology, Vagelos College of Physicians and 
      Surgeons, Columbia University, New York, New York, USA.
FAU - Bhattacharyya, Sriya
AU  - Bhattacharyya S
AD  - Genetic Counseling Graduate Program, Vagelos College of Physicians and Surgeons, 
      Columbia University, New York, New York, USA.
AD  - Department of Psychiatry, Vagelos College of Physicians and Surgeons, Columbia 
      University, New York, New York, USA.
LA  - eng
PT  - Journal Article
DEP - 20231208
PL  - United States
TA  - Am J Med Genet A
JT  - American journal of medical genetics. Part A
JID - 101235741
RN  - EC 2.3.1.6 (Choline O-Acetyltransferase)
SB  - IM
MH  - Humans
MH  - Cross-Sectional Studies
MH  - *Artificial Intelligence
MH  - *Counselors
MH  - Professional Practice
MH  - Choline O-Acetyltransferase
OTO - NOTNLM
OT  - artificial intelligence
OT  - clinical genetics
OT  - genetic counselors
EDAT- 2023/12/09 10:46
MHDA- 2024/03/11 06:42
CRDT- 2023/12/09 00:23
PHST- 2023/11/21 00:00 [revised]
PHST- 2023/11/15 00:00 [received]
PHST- 2023/11/22 00:00 [accepted]
PHST- 2024/03/11 06:42 [medline]
PHST- 2023/12/09 10:46 [pubmed]
PHST- 2023/12/09 00:23 [entrez]
AID - 10.1002/ajmg.a.63493 [doi]
PST - ppublish
SO  - Am J Med Genet A. 2024 Apr;194(4):e63493. doi: 10.1002/ajmg.a.63493. Epub 2023 
      Dec 8.

PMID- 37950660
OWN - NLM
STAT- Publisher
LR  - 20231111
IS  - 1840-2445 (Electronic)
IS  - 1840-0132 (Linking)
VI  - 21
IP  - 1
DP  - 2024 Feb 1
TI  - ChatGPT's contributions to the evolution of neurosurgical practice and education: 
      a systematic review of benefits, concerns and limitations.
LID - 10.17392/1661-23 [doi]
AB  - Aim This study provides a comprehensive review of the current literature on the 
      use of ChatGPT, a generative Artificial Intelligence (AI) tool, in neurosurgery. 
      The study examines potential benefits and limitations of ChatGPT in neurosurgical 
      practice and education. Methods The study involved a systematic review of the 
      current literature on the use of AI in neurosurgery, with a focus on ChatGPT. The 
      Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) 
      guidelines were followed to ensure a comprehensive and transparent review 
      process. Thirteen studies met the inclusion criteria and were included in the 
      final analysis. The data extracted from the included studies were analysed and 
      synthesized to provide an overview of the current state of research on the use of 
      ChatGPT in neurosurgery. Results The ChatGPT showed a potential to complement and 
      enhance neurosurgical practice. However, there are risks and limitations 
      associated with its use, including question format limitations, validation 
      challenges, and algorithmic bias. The study highlights the importance of 
      validating machine-generated content for accuracy and addressing ethical concerns 
      associated with AI technologies. The study also identifies potential benefits of 
      ChatGPT, such as providing personalized treatment plans, supporting surgical 
      planning and navigation, and enhancing large data processing efficiency and 
      accuracy. Conclusion The integration of AI technologies into neurosurgery should 
      be approached with caution and careful consideration of ethical and validation 
      issues. Continued research and development of AI tools in neurosurgery can help 
      us further understand their potential benefits and limitations.
CI  - Copyright© by the Medical Assotiation of Zenica-Doboj Canton.
FAU - Bečulić, Hakija
AU  - Bečulić H
AD  - Department of Neurosurgery, Cantonal Hospital Zenica, Zenica, Bosnia and 
      Herzegovina.
AD  - Department of Anatomy, School of Medicine, University of Zenica, Zenica, Bosnia 
      and Herzegovina.
FAU - Begagić, Emir
AU  - Begagić E
AD  - Deparment of General Medicine, School of Medicine, University of Zenica, Zenica, 
      Bosnia and Herzegovina.
FAU - Skomorac, Rasim
AU  - Skomorac R
AD  - Department of Neurosurgery, Cantonal Hospital Zenica, Zenica, Bosnia and 
      Herzegovina.
AD  - Deparment of Surgery, School of Medicine, University of Zenica, Zenica, Bosnia 
      and Herzegovina.
FAU - Mašović, Anes
AU  - Mašović A
AD  - Department of Neurosurgery, Cantonal Hospital Zenica, Zenica, Bosnia and 
      Herzegovina.
FAU - Selimović, Edin
AU  - Selimović E
AD  - Deparment of Surgery, School of Medicine, University of Zenica, Zenica, Bosnia 
      and Herzegovina.
FAU - Pojskić, Mirza
AU  - Pojskić M
AD  - Department of Neurosurgery, University of Marburg, Marburg, Germany.
LA  - eng
PT  - Journal Article
DEP - 20240201
PL  - Bosnia and Herzegovina
TA  - Med Glas (Zenica)
JT  - Medicinski glasnik : official publication of the Medical Association of 
      Zenica-Doboj Canton, Bosnia and Herzegovina
JID - 101250177
SB  - IM
OTO - NOTNLM
OT  - artificial intelligence
OT  - decision support systems
OT  - ethics
OT  - machine learning
EDAT- 2023/11/11 20:50
MHDA- 2023/11/11 20:50
CRDT- 2023/11/11 07:33
PHST- 2023/09/29 00:00 [received]
PHST- 2023/10/12 00:00 [revised]
PHST- 2023/10/14 00:00 [accepted]
PHST- 2023/11/11 20:50 [medline]
PHST- 2023/11/11 20:50 [pubmed]
PHST- 2023/11/11 07:33 [entrez]
AID - 10.17392/1661-23 [doi]
PST - aheadofprint
SO  - Med Glas (Zenica). 2024 Feb 1;21(1). doi: 10.17392/1661-23.

PMID- 37565917
OWN - NLM
STAT- MEDLINE
DCOM- 20230814
LR  - 20231108
IS  - 1536-5964 (Electronic)
IS  - 0025-7974 (Print)
IS  - 0025-7974 (Linking)
VI  - 102
IP  - 32
DP  - 2023 Aug 11
TI  - ChatGPT performance in the medical specialty exam: An observational study.
PG  - e34673
LID - 10.1097/MD.0000000000034673 [doi]
LID - e34673
AB  - In our study, we aimed to evaluate the success of ChatGPT by determining its 
      performance in the last 5 medical specialty exams (MSE) conducted and its ranking 
      among the candidates of that year, and to determine its potential use in 
      healthcare services. Publicly available MSE questions and answer keys from the 
      last 5 years were scanned, a total of 1177 questions were included in the study, 
      all questions were asked to the ChatGPT (OpenAI; San Francisco, CA) GPT-3.5 
      series, which is the March 23, 2023 version. The average score and rank that 
      ChatGPT would receive if it had entered the exam that year were determined. 
      Questions were categorized as short question group, long question group, single 
      select multiple-choice questions, and multi-select multiple-choice questions. The 
      lowest success proportion was determined as 54.3%, and the highest success 
      proportion was 70.9% correct answer percentage. It achieved a sufficient result 
      as 1787th out of 22,214 people in its most successful exam, and 4428th out of 
      21,476 participants in its least successful one. No statistically significant 
      difference was found between the correct answers it gave to clinical and basic 
      science questions (P: .66). ChatGPT statistically significantly answered a higher 
      proportion of questions correctly in the short questions group compared to the 
      long questions group (P = .03), and in the single select multiple choice 
      questions group compared to the multi-select multiple choice questions group (P &lt; 
      .001). ChatGPT has been successful in the MSE, a challenging exam for doctors in 
      our country. However, it is a fact that ChatGPT is still behind the expert in the 
      field for now, and what will happen with program developments in the future is a 
      matter of curiosity for all of us.
CI  - Copyright © 2023 the Author(s). Published by Wolters Kluwer Health, Inc.
FAU - Oztermeli, Ayse Dilara
AU  - Oztermeli AD
AUID- ORCID: 0000-0003-1820-2877
AD  - Emergency Medicine Department, Gebze Fatih State Hospital, Kocaeli, Turkey.
FAU - Oztermeli, Ahmet
AU  - Oztermeli A
AD  - Orthopaedics and Traumatology Department, Gebze Fatih State Hospital, Kocaeli, 
      Turkey.
LA  - eng
PT  - Journal Article
PT  - Observational Study
PL  - United States
TA  - Medicine (Baltimore)
JT  - Medicine
JID - 2985248R
SB  - IM
MH  - Humans
MH  - *Population Health
MH  - *Medicine
MH  - *Physicians
MH  - Program Development
PMC - PMC10419419
COIS- The authors have no funding and conflicts of interest to disclose.
EDAT- 2023/08/11 12:42
MHDA- 2023/08/14 06:42
PMCR- 2023/08/11
CRDT- 2023/08/11 10:13
PHST- 2023/08/14 06:42 [medline]
PHST- 2023/08/11 12:42 [pubmed]
PHST- 2023/08/11 10:13 [entrez]
PHST- 2023/08/11 00:00 [pmc-release]
AID - 00005792-202308110-00076 [pii]
AID - 10.1097/MD.0000000000034673 [doi]
PST - ppublish
SO  - Medicine (Baltimore). 2023 Aug 11;102(32):e34673. doi: 
      10.1097/MD.0000000000034673.

PMID- 37493845
OWN - NLM
STAT- MEDLINE
DCOM- 20230905
LR  - 20230912
IS  - 1434-4726 (Electronic)
IS  - 0937-4477 (Linking)
VI  - 280
IP  - 10
DP  - 2023 Oct
TI  - "Vertigo, likely peripheral": the dizzying rise of ChatGPT.
PG  - 4687-4689
LID - 10.1007/s00405-023-08135-1 [doi]
AB  - PURPOSE: The use of artificial intelligence (AI) in medical decision-making has 
      once again come to the forefront with the prevalence of Natural Language 
      Processing (NLP). In this exploratory article, we tested one such model, ChatGPT, 
      for its ability to identify vestibular causes of dizziness METHODS: Eight 
      hypothetical scenarios were presented to ChatGPT, which included varying clinical 
      pictures and types of prompts. The responses given by ChatGPT were evaluated for 
      coherence, clarity, consistency, accuracy, appropriateness, and recognition of 
      limitations. ChatGPT provided coherent and logical responses. RESULTS: The model 
      accurately provided differentials for both vestibular and non-vestibular causes 
      of dizziness, with the correct diagnosis presented first in six of the cases, 
      with important limitations CONCLUSION: Being an AI tool, ChatGPT lacks the 
      ability to process certain nuances in clinical decision making, in both 
      identifying atypical dizziness, as well as in recommending further examination 
      steps to elucidate a clearer diagnosis. We believe that AI will continue to forge 
      ahead in the medical field. Merging the immense knowledge base of AI programming 
      with the nuances of clinical assessment and knowledge integration will surely 
      enhance patient care in the years to come.
CI  - © 2023. The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, 
      part of Springer Nature.
FAU - Chee, Jeremy
AU  - Chee J
AUID- ORCID: 0000-0002-4702-7951
AD  - Department of Otolaryngology-Head and Neck Surgery, National University Hospital, 
      1E Kent Ridge Rd, Singapore, 119228, Singapore. cheejeremy@gmail.com.
FAU - Kwa, Eunice Dawn
AU  - Kwa ED
AD  - Department of Otolaryngology-Head and Neck Surgery, National University Hospital, 
      1E Kent Ridge Rd, Singapore, 119228, Singapore.
AD  - Department of Otolaryngology-Head and Neck Surgery, National University of 
      Singapore, Singapore, Singapore.
FAU - Goh, Xueying
AU  - Goh X
AD  - Department of Otolaryngology-Head and Neck Surgery, National University Hospital, 
      1E Kent Ridge Rd, Singapore, 119228, Singapore.
AD  - Department of Otolaryngology-Head and Neck Surgery, National University of 
      Singapore, Singapore, Singapore.
LA  - eng
PT  - Journal Article
DEP - 20230726
PL  - Germany
TA  - Eur Arch Otorhinolaryngol
JT  - European archives of oto-rhino-laryngology : official journal of the European 
      Federation of Oto-Rhino-Laryngological Societies (EUFOS) : affiliated with the 
      German Society for Oto-Rhino-Laryngology - Head and Neck Surgery
JID - 9002937
SB  - IM
MH  - Humans
MH  - *Dizziness/diagnosis/etiology
MH  - Artificial Intelligence
MH  - Vertigo
MH  - Clinical Decision-Making
MH  - *Vestibule, Labyrinth
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Dizziness
OT  - Natural language processing
OT  - Vertigo
EDAT- 2023/07/26 13:07
MHDA- 2023/09/05 06:42
CRDT- 2023/07/26 11:15
PHST- 2023/06/17 00:00 [received]
PHST- 2023/07/13 00:00 [accepted]
PHST- 2023/09/05 06:42 [medline]
PHST- 2023/07/26 13:07 [pubmed]
PHST- 2023/07/26 11:15 [entrez]
AID - 10.1007/s00405-023-08135-1 [pii]
AID - 10.1007/s00405-023-08135-1 [doi]
PST - ppublish
SO  - Eur Arch Otorhinolaryngol. 2023 Oct;280(10):4687-4689. doi: 
      10.1007/s00405-023-08135-1. Epub 2023 Jul 26.

PMID- 37879261
OWN - NLM
STAT- MEDLINE
DCOM- 20231216
LR  - 20231216
IS  - 1528-3968 (Electronic)
IS  - 0029-6554 (Linking)
VI  - 71
IP  - 6
DP  - 2023 Nov-Dec
TI  - The application of Chat&nbsp;Generative Pre-trained Transformer in nursing education.
PG  - 102064
LID - S0029-6554(23)00169-0 [pii]
LID - 10.1016/j.outlook.2023.102064 [doi]
AB  - BACKGROUND: Nursing education is critical for nurses to deliver quality health 
      care. Incorporating AI into education can enhance the learning process and better 
      equip nurses for their health care roles. PURPOSE: This article explores the 
      potential applications and challenges of ChatGPT in nursing education. METHODS: A 
      comprehensive literature review was conducted to explore the potential benefits 
      and challenges of using ChatGPT in nursing education. DISCUSSION: ChatGPT, an 
      advanced large language model, has the potential to make valuable contributions 
      to nursing education in various ways, including personalized learning, simulation 
      scenarios, immediate feedback, and reducing educator workload. However, it is 
      important to address the various challenges and limitations in order to realize 
      its full potential. CONCLUSION: Nursing educators must carefully consider the 
      potential uses, benefits, challenges, drawbacks, and limitations of ChatGPT to 
      make informed decisions about its integration into nursing education.
CI  - Copyright © 2023 Elsevier Inc. All rights reserved.
FAU - Liu, Jialin
AU  - Liu J
AD  - Department of Medical Informatics, West China Medical School, Chengdu, Sichuan, 
      China; Department of Otolaryngology-Head and Neck Surgery, West China Hospital, 
      Sichuan University, Chengdu, Sichuan, China. Electronic address: DLJL8@163.com.
FAU - Liu, Fan
AU  - Liu F
AD  - Department of Nursing, West China Hospital of Stomatology, Sichuan University, 
      Chengdu, Sichuan, China.
FAU - Fang, Jinbo
AU  - Fang J
AD  - Department of Nursing, West China Hospital, West China School of Nursing, Sichuan 
      University, Chengdu, Sichuan, China.
FAU - Liu, Siru
AU  - Liu S
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, TN.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20231023
PL  - United States
TA  - Nurs Outlook
JT  - Nursing outlook
JID - 0401075
SB  - IM
MH  - Humans
MH  - *Education, Nursing
MH  - Educational Status
MH  - Faculty, Nursing
MH  - Language
MH  - Quality of Health Care
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Education
OT  - Large language model
OT  - Nursing
COIS- Declaration of Competing Interest The authors declare no conflicts of interest.
EDAT- 2023/10/26 00:42
MHDA- 2023/12/17 09:45
CRDT- 2023/10/25 18:08
PHST- 2023/07/19 00:00 [received]
PHST- 2023/09/12 00:00 [revised]
PHST- 2023/09/29 00:00 [accepted]
PHST- 2023/12/17 09:45 [medline]
PHST- 2023/10/26 00:42 [pubmed]
PHST- 2023/10/25 18:08 [entrez]
AID - S0029-6554(23)00169-0 [pii]
AID - 10.1016/j.outlook.2023.102064 [doi]
PST - ppublish
SO  - Nurs Outlook. 2023 Nov-Dec;71(6):102064. doi: 10.1016/j.outlook.2023.102064. Epub 
      2023 Oct 23.

PMID- 37771867
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231003
IS  - 2222-0682 (Print)
IS  - 2222-0682 (Electronic)
IS  - 2222-0682 (Linking)
VI  - 13
IP  - 4
DP  - 2023 Sep 20
TI  - ChatGPT in action: Harnessing artificial intelligence potential and addressing 
      ethical challenges in medicine, education, and scientific research.
PG  - 170-178
LID - 10.5662/wjm.v13.i4.170 [doi]
AB  - Artificial intelligence (AI) tools, like OpenAI's Chat Generative Pre-trained 
      Transformer (ChatGPT), hold considerable potential in healthcare, academia, and 
      diverse industries. Evidence demonstrates its capability at a medical student 
      level in standardized tests, suggesting utility in medical education, radiology 
      reporting, genetics research, data optimization, and drafting repetitive texts 
      such as discharge summaries. Nevertheless, these tools should augment, not 
      supplant, human expertise. Despite promising applications, ChatGPT confronts 
      limitations, including critical thinking tasks and generating false references, 
      necessitating stringent cross-verification. Ensuing concerns, such as potential 
      misuse, bias, blind trust, and privacy, underscore the need for transparency, 
      accountability, and clear policies. Evaluations of AI-generated content and 
      preservation of academic integrity are critical. With responsible use, AI can 
      significantly improve healthcare, academia, and industry without compromising 
      integrity and research quality. For effective and ethical AI deployment, 
      collaboration amongst AI developers, researchers, educators, and policymakers is 
      vital. The development of domain-specific tools, guidelines, regulations, and the 
      facilitation of public dialogue must underpin these endeavors to responsibly 
      harness AI's potential.
CI  - ©The Author(s) 2023. Published by Baishideng Publishing Group Inc. All rights 
      reserved.
FAU - Jeyaraman, Madhan
AU  - Jeyaraman M
AD  - Department of Orthopaedics, ACS Medical College and Hospital, Dr MGR Educational 
      and Research Institute, Chennai 600077, Tamil Nadu, India. 
      madhanjeyaraman@gmail.com.
FAU - Ramasubramanian, Swaminathan
AU  - Ramasubramanian S
AD  - Department of General Medicine, Government Medical College, Omandurar Government 
      Estate, Chennai 600018, Tamil Nadu, India.
FAU - Balaji, Sangeetha
AU  - Balaji S
AD  - Department of General Medicine, Government Medical College, Omandurar Government 
      Estate, Chennai 600018, Tamil Nadu, India.
FAU - Jeyaraman, Naveen
AU  - Jeyaraman N
AD  - Department of Orthopaedics, ACS Medical College and Hospital, Dr MGR Educational 
      and Research Institute, Chennai 600077, Tamil Nadu, India.
FAU - Nallakumarasamy, Arulkumar
AU  - Nallakumarasamy A
AD  - Department of Orthopaedics, ACS Medical College and Hospital, Dr MGR Educational 
      and Research Institute, Chennai 600077, Tamil Nadu, India.
FAU - Sharma, Shilpa
AU  - Sharma S
AD  - Department of Paediatric Surgery, All India Institute of Medical Sciences, Delhi 
      110029, New Delhi, India.
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20230920
PL  - United States
TA  - World J Methodol
JT  - World journal of methodology
JID - 101628739
PMC - PMC10523250
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Education
OT  - Open artificial intelligence
OT  - Research
COIS- Conflict-of-interest statement: The authors declare no competing interests.
EDAT- 2023/09/29 06:44
MHDA- 2023/09/29 06:45
PMCR- 2023/09/20
CRDT- 2023/09/29 03:57
PHST- 2023/05/02 00:00 [received]
PHST- 2023/06/29 00:00 [revised]
PHST- 2023/07/24 00:00 [accepted]
PHST- 2023/09/29 06:45 [medline]
PHST- 2023/09/29 06:44 [pubmed]
PHST- 2023/09/29 03:57 [entrez]
PHST- 2023/09/20 00:00 [pmc-release]
AID - 10.5662/wjm.v13.i4.170 [doi]
PST - epublish
SO  - World J Methodol. 2023 Sep 20;13(4):170-178. doi: 10.5662/wjm.v13.i4.170. 
      eCollection 2023 Sep 20.

PMID- 37531256
OWN - NLM
STAT- MEDLINE
DCOM- 20231010
LR  - 20231018
IS  - 1460-2423 (Electronic)
IS  - 0959-6658 (Linking)
VI  - 33
IP  - 8
DP  - 2023 Oct 6
TI  - Can ChatGPT pass Glycobiology?
PG  - 606-614
LID - 10.1093/glycob/cwad064 [doi]
AB  - The release of text-generating applications based on interactive Large Language 
      Models (LLMs) in late 2022 triggered an unprecedented and ever-growing interest 
      worldwide. The almost instantaneous success of LLMs stimulated lively discussions 
      in public media and in academic fora alike not only on the value and potentials 
      of such tools in all areas of knowledge and information acquisition and 
      distribution but also on the dangers posed by their uncontrolled and 
      indiscriminate use. This conversation is now particularly active in the higher 
      education sector, where LLMs are seen as a potential threat to academic integrity 
      at all levels, from facilitating cheating by students in assignments to 
      plagiarizing academic writing in the case of researchers and administrators. 
      Within this framework, we are interested in testing the boundaries of the LLM 
      ChatGPT (www.openai.com) in areas of our scientific interest and expertise and in 
      analyzing the results from different perspectives, i.e. of a final year BSc 
      student, of a research scientist, and of a lecturer in higher education. To this 
      end, in this paper, we present and discuss a systematic evaluation on how ChatGPT 
      addresses progressively complex scientific writing tasks and exam-type questions 
      in Carbohydrate Chemistry and Glycobiology. The results of this project allowed 
      us to gain insight on: (i) the strengths and limitations of the ChatGPT model to 
      provide relevant and (most importantly) correct scientific information, (ii) the 
      format(s) and complexity of the query required to obtain the desired output, and 
      (iii) strategies to integrate LLMs in teaching and learning.
CI  - © The Author(s) 2023. Published by Oxford University Press. All rights reserved. 
      For permissions, please e-mail: journals.permissions@oup.com.
FAU - Williams, Devin Ormsby
AU  - Williams DO
AD  - Department of Chemistry.
FAU - Fadda, Elisa
AU  - Fadda E
AD  - Department of Chemistry.
AD  - Hamilton Institute, Maynooth University, Maynooth, co. Kildare, Ireland.
LA  - eng
PT  - Journal Article
PL  - England
TA  - Glycobiology
JT  - Glycobiology
JID - 9104124
SB  - IM
MH  - Humans
MH  - *Glycomics/education
MH  - *Artificial Intelligence
MH  - Writing
MH  - *Educational Measurement
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - Glycobiology
OT  - LLM
OT  - higher education
EDAT- 2023/08/02 19:15
MHDA- 2023/10/09 06:41
CRDT- 2023/08/02 12:42
PHST- 2023/05/25 00:00 [received]
PHST- 2023/06/30 00:00 [revised]
PHST- 2023/07/12 00:00 [accepted]
PHST- 2023/10/09 06:41 [medline]
PHST- 2023/08/02 19:15 [pubmed]
PHST- 2023/08/02 12:42 [entrez]
AID - 7235670 [pii]
AID - 10.1093/glycob/cwad064 [doi]
PST - ppublish
SO  - Glycobiology. 2023 Oct 6;33(8):606-614. doi: 10.1093/glycob/cwad064.

PMID- 37142479
OWN - NLM
STAT- MEDLINE
DCOM- 20230703
LR  - 20231120
IS  - 1472-6491 (Electronic)
IS  - 1472-6483 (Linking)
VI  - 47
IP  - 1
DP  - 2023 Jul
TI  - Artificial intelligence in scientific writing: a friend or a foe?
PG  - 3-9
LID - S1472-6483(23)00219-5 [pii]
LID - 10.1016/j.rbmo.2023.04.009 [doi]
AB  - The generative pre-trained transformer, ChatGPT, is a chatbot that could serve as 
      a powerful tool in scientific writing. ChatGPT is a so-called large language 
      model (LLM) that is trained to mimic the statistical patterns of language in an 
      enormous database of human-generated text combined from text in books, articles 
      and websites across a wide range of domains. ChatGPT can assist scientists with 
      material organization, draft creation and proofreading, making it a valuable tool 
      in research and publishing. This paper discusses the use of this artificial 
      intelligence (AI) chatbot in academic writing by presenting one simplified 
      example. Specifically, it reflects our experience of using ChatGPT to draft a 
      scientific article for Reproductive BioMedicine Online and highlights the pros, 
      cons and concerns associated with using LLM-based AI for generating a manuscript.
CI  - Copyright © 2023 Reproductive Healthcare Ltd. Published by Elsevier Ltd. All 
      rights reserved.
FAU - Altmäe, Signe
AU  - Altmäe S
AD  - Department of Biochemistry and Molecular Biology, Faculty of Sciences, University 
      of Granada, Granada, Spain; Instituto de Investigación Biosanitaria ibs.GRANADA, 
      Granada, Spain; Division of Obstetrics and Gynecology, Department of Clinical 
      Science, Intervention and Technology (CLINTEC), Karolinska Institutet and 
      Karolinska University Hospital, Stockholm, Sweden. Electronic address: 
      signealtmae@ugr.es.
FAU - Sola-Leyva, Alberto
AU  - Sola-Leyva A
AD  - Department of Biochemistry and Molecular Biology, Faculty of Sciences, University 
      of Granada, Granada, Spain; Instituto de Investigación Biosanitaria ibs.GRANADA, 
      Granada, Spain.
FAU - Salumets, Andres
AU  - Salumets A
AD  - Division of Obstetrics and Gynecology, Department of Clinical Science, 
      Intervention and Technology (CLINTEC), Karolinska Institutet and Karolinska 
      University Hospital, Stockholm, Sweden; Competence Centre on Health Technologies, 
      Tartu, Estonia; Department of Obstetrics and Gynaecology, Institute of Clinical 
      Medicine, University of Tartu, Tartu, Estonia.
LA  - eng
PT  - Journal Article
DEP - 20230420
PL  - Netherlands
TA  - Reprod Biomed Online
JT  - Reproductive biomedicine online
JID - 101122473
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Software
MH  - Databases, Factual
MH  - *Physicians
MH  - Writing
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Chatbot
OT  - Large language model
OT  - Scientific writing
EDAT- 2023/05/05 00:42
MHDA- 2023/07/03 06:41
CRDT- 2023/05/04 21:57
PHST- 2023/04/12 00:00 [received]
PHST- 2023/04/12 00:00 [accepted]
PHST- 2023/07/03 06:41 [medline]
PHST- 2023/05/05 00:42 [pubmed]
PHST- 2023/05/04 21:57 [entrez]
AID - S1472-6483(23)00219-5 [pii]
AID - 10.1016/j.rbmo.2023.04.009 [doi]
PST - ppublish
SO  - Reprod Biomed Online. 2023 Jul;47(1):3-9. doi: 10.1016/j.rbmo.2023.04.009. Epub 
      2023 Apr 20.

PMID- 37043716
OWN - NLM
STAT- MEDLINE
DCOM- 20230427
LR  - 20230929
IS  - 1538-9855 (Electronic)
IS  - 0363-3624 (Linking)
VI  - 48
IP  - 3
DP  - 2023 May-Jun 01
TI  - The ChatGPT Storm and What Faculty Can Do.
PG  - 119-124
LID - 10.1097/NNE.0000000000001390 [doi]
AB  - BACKGROUND: ChatGPT, an artificial intelligence-driven, pretrained, deep learning 
      language model, can generate natural language text in response to a given query. 
      Its rapid growth has led to concerns about ethical use in academia. PROBLEM: The 
      exponential rise in the popularity of ChatGPT, and concerns of academic integrity 
      with its use, has raised concerns among faculty for how to best address this 
      issue. APPROACH: Faculty should understand the potential benefits and limitations 
      of ChatGPT and create assignments that emphasize self-reflection, critical 
      thinking, problem solving, and independent learning. Students must be taught how 
      to critically evaluate information and how to make informed decisions. 
      CONCLUSIONS: ChatGPT has the potential to revolutionize nursing education. 
      However, it is critical for faculty to be familiar with its capabilities and 
      limitations in order to foster effective, yet ethical and responsible 
      utilization, while preparing students for the dynamic, rapidly advancing 
      technological landscape in nursing and health care.
CI  - Copyright © 2023 Wolters Kluwer Health, Inc. All rights reserved.
FAU - Sun, Grace H
AU  - Sun GH
AD  - Associate Professor (Dr Sun), Department of Advanced Practice Registered Nurse 
      Studies, and Associate Professor (Dr Hoelscher), Department of Leadership 
      Studies-Program Director MSN Informatics, Texas Tech University Health Sciences 
      Center School of Nursing, Lubbock.
FAU - Hoelscher, Stephanie H
AU  - Hoelscher SH
LA  - eng
PT  - Journal Article
DEP - 20230227
PL  - United States
TA  - Nurse Educ
JT  - Nurse educator
JID - 7701902
MH  - Humans
MH  - Artificial Intelligence
MH  - Nursing Education Research
MH  - *Education, Nursing
MH  - Faculty, Nursing
MH  - *Students, Nursing
COIS- The authors declare no conflicts of interest.
EDAT- 2023/04/13 06:00
MHDA- 2023/04/27 06:42
CRDT- 2023/04/12 16:12
PHST- 2023/04/27 06:42 [medline]
PHST- 2023/04/13 06:00 [pubmed]
PHST- 2023/04/12 16:12 [entrez]
AID - 00006223-202305000-00001 [pii]
AID - 10.1097/NNE.0000000000001390 [doi]
PST - ppublish
SO  - Nurse Educ. 2023 May-Jun 01;48(3):119-124. doi: 10.1097/NNE.0000000000001390. 
      Epub 2023 Feb 27.

PMID- 38341993
OWN - NLM
STAT- Publisher
LR  - 20240211
IS  - 1532-8171 (Electronic)
IS  - 0735-6757 (Linking)
VI  - 79
DP  - 2024 Feb 7
TI  - Human intelligence versus Chat-GPT: who performs better in correctly classifying 
      patients in triage?
PG  - 44-47
LID - S0735-6757(24)00066-4 [pii]
LID - 10.1016/j.ajem.2024.02.008 [doi]
AB  - INTRODUCTION: Chat-GPT is rapidly emerging as a promising and potentially 
      revolutionary tool in medicine. One of its possible applications is the 
      stratification of patients according to the severity of clinical conditions and 
      prognosis during the triage evaluation in the emergency department (ED). METHODS: 
      Using a randomly selected sample of 30 vignettes recreated from real clinical 
      cases, we compared the concordance in risk stratification of ED patients between 
      healthcare personnel and Chat-GPT. The concordance was assessed with Cohen's 
      kappa, and the performance was evaluated with the area under the receiver 
      operating characteristic curve (AUROC) curves. Among the outcomes, we considered 
      mortality within 72&nbsp;h, the need for hospitalization, and the presence of a severe 
      or time-dependent condition. RESULTS: The concordance in triage code assignment 
      between triage nurses and Chat-GPT was 0.278 (unweighted Cohen's kappa; 95% 
      confidence intervals: 0.231-0.388). For all outcomes, the ROC values were higher 
      for the triage nurses. The most relevant difference was found in 72-h mortality, 
      where triage nurses showed an AUROC of 0.910 (0.757-1.000) compared to only 0.669 
      (0.153-1.000) for Chat-GPT. CONCLUSIONS: The current level of Chat-GPT 
      reliability is insufficient to make it a valid substitute for the expertise of 
      triage nurses in prioritizing ED patients. Further developments are required to 
      enhance the safety and effectiveness of AI for risk stratification of ED 
      patients.
CI  - Copyright © 2024 Elsevier Inc. All rights reserved.
FAU - Zaboli, Arian
AU  - Zaboli A
AD  - Innovation, Research and Teaching Service (SABES-ASDAA), Teaching Hospital of the 
      Paracelsus Medical Private University (PMU), Bolzano, Italy. Electronic address: 
      zaboliarian@gmail.com.
FAU - Brigo, Francesco
AU  - Brigo F
AD  - Innovation, Research and Teaching Service (SABES-ASDAA), Teaching Hospital of the 
      Paracelsus Medical Private University (PMU), Bolzano, Italy.
FAU - Sibilio, Serena
AU  - Sibilio S
AD  - Department of Emergency Medicine, Hospital of Merano-Meran (SABES-ASDAA), 
      Merano-Meran, Italy; Lehrkrankenhaus der Paracelsus Medizinischen 
      Privatuniversität, Salzburg, Austria.
FAU - Mian, Michael
AU  - Mian M
AD  - Innovation, Research and Teaching Service (SABES-ASDAA), Teaching Hospital of the 
      Paracelsus Medical Private University (PMU), Bolzano, Italy; College of Health 
      Care-Professions Claudiana, Bozen, Italy.
FAU - Turcato, Gianni
AU  - Turcato G
AD  - Department of Internal Medicine, Intermediate Care Unit, Hospital Alto Vicentino 
      (AULSS-7), Santorso, Italy.
LA  - eng
PT  - Journal Article
DEP - 20240207
PL  - United States
TA  - Am J Emerg Med
JT  - The American journal of emergency medicine
JID - 8309942
SB  - IM
OTO - NOTNLM
OT  - Advanced nurse practice
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Manchester triage system
OT  - Nursing
OT  - Triage
COIS- Declaration of competing interest The authors declare that they have no conflict 
      of interest.
EDAT- 2024/02/12 05:43
MHDA- 2024/02/12 05:43
CRDT- 2024/02/11 18:05
PHST- 2023/12/18 00:00 [received]
PHST- 2024/02/02 00:00 [revised]
PHST- 2024/02/04 00:00 [accepted]
PHST- 2024/02/12 05:43 [medline]
PHST- 2024/02/12 05:43 [pubmed]
PHST- 2024/02/11 18:05 [entrez]
AID - S0735-6757(24)00066-4 [pii]
AID - 10.1016/j.ajem.2024.02.008 [doi]
PST - aheadofprint
SO  - Am J Emerg Med. 2024 Feb 7;79:44-47. doi: 10.1016/j.ajem.2024.02.008.

PMID- 38337594
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240212
IS  - 2077-0383 (Print)
IS  - 2077-0383 (Electronic)
IS  - 2077-0383 (Linking)
VI  - 13
IP  - 3
DP  - 2024 Feb 4
TI  - Artificial Intelligence Language Model Performance for Rapid Intraoperative 
      Queries in Plastic Surgery: ChatGPT and the Deep Inferior Epigastric Perforator 
      Flap.
LID - 10.3390/jcm13030900 [doi]
LID - 900
AB  - Background: The integration of artificial intelligence in healthcare has led to 
      the development of large language models that can address various medical 
      queries, including intraoperatively. This study investigates the potential of 
      ChatGPT in addressing intraoperative questions during the deep inferior 
      epigastric perforator flap procedure. Methods: A series of six intraoperative 
      questions specific to the DIEP flap procedure, derived from real-world clinical 
      scenarios, were proposed to ChatGPT. A panel of four experienced board-certified 
      plastic surgeons evaluated ChatGPT's performance in providing accurate, relevant, 
      and comprehensible responses. Results: The Likert scale demonstrated to be 
      medically accurate, systematic in presentation, and logical when providing 
      alternative solutions. The mean readability score of the Flesch Reading Ease 
      Score was 28.7 (±0.8), the Flesch-Kincaid Grade Level was 12.4 (±0.5), and the 
      Coleman-Liau Index was 14.5 (±0.5). Suitability-wise, the DISCERN score of 
      ChatGPT was 48 (±2.5) indicating suitable and comprehensible language for 
      experts. Conclusions: Generative AI tools such as ChatGPT can serve as a 
      supplementary tool for surgeons to offer valuable insights and foster 
      intraoperative problem-solving abilities. However, it lacks consideration of 
      individual patient factors and surgical nuances. Nevertheless, further refinement 
      of its training data and rigorous scrutiny under experts to ensure the accuracy 
      and up-to-date nature of the information holds the potential for it to be 
      utilized in the surgical field.
FAU - Atkinson, Connor J
AU  - Atkinson CJ
AD  - Department of Plastic and Reconstructive Surgery, Frankston Hospital, Peninsula 
      Health, Frankston, VIC 3199, Australia.
FAU - Seth, Ishith
AU  - Seth I
AUID- ORCID: 0000-0001-5444-8925
AD  - Department of Plastic and Reconstructive Surgery, Frankston Hospital, Peninsula 
      Health, Frankston, VIC 3199, Australia.
AD  - Faculty of Medicine and Surgery, Monash University, Clayton, VIC 3800, Australia.
AD  - Faculty of Medicine and Surgery, The University of Melbourne, Parkville, VIC 
      3052, Australia.
FAU - Xie, Yi
AU  - Xie Y
AD  - Department of Plastic and Reconstructive Surgery, Frankston Hospital, Peninsula 
      Health, Frankston, VIC 3199, Australia.
FAU - Ross, Richard J
AU  - Ross RJ
AD  - Department of Plastic and Reconstructive Surgery, Frankston Hospital, Peninsula 
      Health, Frankston, VIC 3199, Australia.
FAU - Hunter-Smith, David J
AU  - Hunter-Smith DJ
AD  - Department of Plastic and Reconstructive Surgery, Frankston Hospital, Peninsula 
      Health, Frankston, VIC 3199, Australia.
AD  - Faculty of Medicine and Surgery, Monash University, Clayton, VIC 3800, Australia.
FAU - Rozen, Warren M
AU  - Rozen WM
AUID- ORCID: 0000-0002-4092-182X
AD  - Department of Plastic and Reconstructive Surgery, Frankston Hospital, Peninsula 
      Health, Frankston, VIC 3199, Australia.
AD  - Faculty of Medicine and Surgery, Monash University, Clayton, VIC 3800, Australia.
FAU - Cuomo, Roberto
AU  - Cuomo R
AUID- ORCID: 0000-0002-8396-095X
AD  - Plastic Surgery Unit, Department of Medicine, Surgery and Neuroscience, 
      University of Siena, 53100 Siena, Italy.
LA  - eng
PT  - Journal Article
DEP - 20240204
PL  - Switzerland
TA  - J Clin Med
JT  - Journal of clinical medicine
JID - 101606588
PMC - PMC10856538
OTO - NOTNLM
OT  - ChatGPT
OT  - DIEP
OT  - artificial intelligence
OT  - intraoperative
OT  - large language model
OT  - plastic surgery
COIS- The authors declare no conflicts of interest.
EDAT- 2024/02/10 10:44
MHDA- 2024/02/10 10:45
PMCR- 2024/02/04
CRDT- 2024/02/10 01:04
PHST- 2024/01/03 00:00 [received]
PHST- 2024/01/23 00:00 [revised]
PHST- 2024/02/02 00:00 [accepted]
PHST- 2024/02/10 10:45 [medline]
PHST- 2024/02/10 10:44 [pubmed]
PHST- 2024/02/10 01:04 [entrez]
PHST- 2024/02/04 00:00 [pmc-release]
AID - jcm13030900 [pii]
AID - jcm-13-00900 [pii]
AID - 10.3390/jcm13030900 [doi]
PST - epublish
SO  - J Clin Med. 2024 Feb 4;13(3):900. doi: 10.3390/jcm13030900.

PMID- 38249202
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240123
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 12
DP  - 2023 Dec
TI  - Assessing ChatGPT's Proficiency in Simplifying Radiological Reports for 
      Healthcare Professionals&nbsp;and&nbsp;Patients.
PG  - e50881
LID - 10.7759/cureus.50881 [doi]
LID - e50881
AB  - Background Clear communication of radiological findings is crucial for effective 
      healthcare decision-making. However, radiological reports are often complex with 
      technical terminology, making them challenging for non-radiology healthcare 
      professionals and patients to comprehend.&nbsp;Large language models like ChatGPT 
      (Chat Generative Pre-trained Transformer, by OpenAI, San Francisco, CA) offer a 
      potential solution by translating intricate reports into simplified language. 
      This study aimed to assess the capability of ChatGPT-3.5 in simplifying 
      radiological reports to facilitate improved understanding by healthcare 
      professionals and patients. Materials and methods Nine radiological reports were 
      taken for this study spanning various imaging modalities and medical conditions. 
      These reports were used to ask ChatGPT a set of seven questions (describe the 
      procedure, mention the key findings, express in a simple language, suggestions 
      for further investigation, need of further investigation, grammatical or typing 
      errors, and translation into Hindi). A total of eight radiologists rated the 
      generated content in detailing, summarizing, simplifying content and language, 
      factual correctness, further investigation, grammatical errors, and translation 
      to Hindi. Results The highest score was obtained for detailing the report (94.17% 
      accuracy) and the lowest score was for drawing conclusions for the patient (85% 
      accuracy); case-wise scores were similar (p-value = 0.97). The Hindi translation 
      by ChatGPT was not suitable for patient communication. Conclusion The current 
      free version of ChatGPT-3.5 was able to simplify radiological reports 
      effectively, removing technical jargon while preserving essential diagnostic 
      information. The free version adeptly simplifies radiological reports, enhancing 
      accessibility for healthcare professionals and patients. Hence, it has the 
      potential to enhance medical communication, facilitating informed decision-making 
      by healthcare professionals and patients.
CI  - Copyright © 2023, Sarangi et al.
FAU - Sarangi, Pradosh Kumar
AU  - Sarangi PK
AD  - Radiodiagnosis, All India Institute of Medical Sciences, Deoghar, Deoghar, IND.
FAU - Lumbani, Amrita
AU  - Lumbani A
AD  - Physiology, Mayo Institute of Medical Sciences, Barabanki, IND.
FAU - Swarup, M Sarthak
AU  - Swarup MS
AD  - Radiodiagnosis, Vardhman Mahavir Medical College and Safdarjung Hospital, New 
      Delhi, IND.
FAU - Panda, Suvankar
AU  - Panda S
AD  - Radiodiagnosis, SCB (Srirama Chandra Bhanja) Medical College and Hospital, 
      Cuttack, IND.
FAU - Sahoo, Smruti Snigdha
AU  - Sahoo SS
AD  - Radiodiagnosis, SCB (Srirama Chandra Bhanja) Medical College and Hospital, 
      Cuttack, IND.
FAU - Hui, Pratisruti
AU  - Hui P
AD  - Radiodiagnosis, All India Institute of Medical Sciences, Kalyani, Kalyani, IND.
FAU - Choudhary, Anish
AU  - Choudhary A
AD  - Radiodiagnosis, Central Institute of Psychiatry, Ranchi, IND.
FAU - Mohakud, Sudipta
AU  - Mohakud S
AD  - Radiodiagnosis, All India Institute of Medical Sciences, Bhubaneswar, 
      Bhubaneswar, IND.
FAU - Patel, Ranjan Kumar
AU  - Patel RK
AD  - Radiodiagnosis, All India Institute of Medical Sciences, Bhubaneswar, 
      Bhubaneswar, IND.
FAU - Mondal, Himel
AU  - Mondal H
AD  - Physiology, All India Institute of Medical Sciences, Deoghar, Deoghar, IND.
LA  - eng
PT  - Journal Article
DEP - 20231221
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10799309
OTO - NOTNLM
OT  - artificial intelligence
OT  - chatgpt
OT  - health education
OT  - health literacy
OT  - healthcare communication
OT  - hindi translation
OT  - large lqnguage model
OT  - natural language processing
OT  - patient-centered care
OT  - radiological report
COIS- The authors have declared that no competing interests exist.
EDAT- 2024/01/22 06:42
MHDA- 2024/01/22 06:43
PMCR- 2023/12/21
CRDT- 2024/01/22 04:49
PHST- 2023/12/21 00:00 [accepted]
PHST- 2024/01/22 06:43 [medline]
PHST- 2024/01/22 06:42 [pubmed]
PHST- 2024/01/22 04:49 [entrez]
PHST- 2023/12/21 00:00 [pmc-release]
AID - 10.7759/cureus.50881 [doi]
PST - epublish
SO  - Cureus. 2023 Dec 21;15(12):e50881. doi: 10.7759/cureus.50881. eCollection 2023 
      Dec.

PMID- 38058315
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231208
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 11
DP  - 2023 Nov
TI  - ChatGPT in Answering Queries Related to Lifestyle-Related Diseases and Disorders.
PG  - e48296
LID - 10.7759/cureus.48296 [doi]
LID - e48296
AB  - Background Lifestyle-related diseases and disorders have become a significant 
      global health burden. However, the majority of the population ignores or do not 
      consult doctors for such disease or disorders. Artificial intelligence (AI)-based 
      large language model (LLM) like ChatGPT (GPT3.5) is capable of generating 
      customized queries of a user. Hence, it can act as a virtual telehealth agent. 
      Its capability to answer lifestyle-related diseases or disorders has not been 
      explored. Objective This study aimed to evaluate the effectiveness of ChatGPT, an 
      LLM, in providing answers to queries related to lifestyle-related diseases or 
      disorders. Methods A set of 20 lifestyle-related disease or disorder cases 
      covering a wide range of topics such as obesity, diabetes, cardiovascular health, 
      and mental health were prepared with four questions. The case and questions were 
      presented to ChatGPT and asked for the answers to those questions. Two physicians 
      rated the content on a three-point Likert-like scale ranging from accurate (2), 
      partially accurate (1), and inaccurate (0). Further, the content was rated as 
      adequate (2), inadequate (1), and misguiding (0) for testing the applicability of 
      the guides for patients. The readability of the text was analyzed by the 
      Flesch-Kincaid Ease Score (FKES).&nbsp; Results Among 20 cases, the average score of 
      accuracy was 1.83±0.37 and guidance was 1.9±0.21. Both the scores were higher 
      than the hypothetical median of 1.5 (p=0.004&nbsp;and p&lt;0.0001, respectively). ChatGPT 
      answered the questions with a natural tone in 11 cases and nine with a positive 
      tone. The text was understandable for college graduates with a mean FKES of 
      27.8±5.74. Conclusion The analysis of content accuracy revealed that ChatGPT 
      provided reasonably accurate information in the majority of the cases, 
      successfully addressing queries related to lifestyle-related diseases or 
      disorders. Hence, initial guidance can be obtained by patients when they get 
      little time to consult a doctor or wait for an appointment to consult a doctor 
      for suggestions about their condition.
CI  - Copyright © 2023, Mondal et al.
FAU - Mondal, Himel
AU  - Mondal H
AD  - Physiology, All India Institute of Medical Sciences, Deoghar, IND.
FAU - Dash, Ipsita
AU  - Dash I
AD  - Biochemistry, Saheed Laxman Nayak Medical College and Hospital, Koraput, IND.
FAU - Mondal, Shaikat
AU  - Mondal S
AD  - Physiology, Raiganj Government Medical College and Hospital, Raiganj, IND.
FAU - Behera, Joshil Kumar
AU  - Behera JK
AD  - Physiology, Nagaland Institute of Medical Science and Research, Kohima, IND.
LA  - eng
PT  - Journal Article
DEP - 20231105
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10696911
OTO - NOTNLM
OT  - artificial intelligence
OT  - chatgpt
OT  - education
OT  - healthcare
OT  - internet
OT  - language model
OT  - lifestyle
OT  - non-communicable disease
OT  - patient
OT  - public health education
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/12/07 06:42
MHDA- 2023/12/07 06:43
PMCR- 2023/11/05
CRDT- 2023/12/07 04:00
PHST- 2023/11/04 00:00 [accepted]
PHST- 2023/12/07 06:43 [medline]
PHST- 2023/12/07 06:42 [pubmed]
PHST- 2023/12/07 04:00 [entrez]
PHST- 2023/11/05 00:00 [pmc-release]
AID - 10.7759/cureus.48296 [doi]
PST - epublish
SO  - Cureus. 2023 Nov 5;15(11):e48296. doi: 10.7759/cureus.48296. eCollection 2023 
      Nov.

PMID- 38128909
OWN - NLM
STAT- Publisher
LR  - 20231221
IS  - 1545-1569 (Electronic)
IS  - 1055-6656 (Linking)
DP  - 2023 Dec 21
TI  - The Quality of CLP-Related Information for Patients Provided by ChatGPT.
PG  - 10556656231222387
LID - 10.1177/10556656231222387 [doi]
AB  - OBJECTIVE: To assess the quality, reliability, readability, and similarity of the 
      data that a recently created NLP-based artificial intelligence model ChatGPT 4 
      provides to users in Cleft Lip and Palate (CLP)-related information. DESIGN: In 
      the evaluation of the responses provided by the OpenAI ChatGPT to the CLP-related 
      50 questions, several tools were utilized, including the Ensuring Quality 
      Information for Patients (EQIP) tool, Reliability Scoring System (Adapted from 
      DISCERN), Flesh Reading Ease Formula (FRES) and Flesch-Kinkaid Reading Grade 
      Level (FKRGL) formulas, Global Quality Scale (GQS), and Similarity Index with 
      plagiarism-detection tool. Jamovi (The Jamovi Project, 2022, version 2.3; Sydney, 
      Australia) software was used for all statistical analyses. RESULTS: Based on the 
      reliability and GQS values, ChatGPT demonstrated high reliability and good 
      quality attributable to CLP. Furthermore, according to the FRES results, 
      ChatGPT's readability is difficult, and the similarity index values of this 
      software exhibit an acceptable level of similarity ratio. There is no significant 
      difference in EQIP, Reliability Score System, FRES, FKGRL, GQS, and Similarity 
      Index values among the two categories. CONCLUSION: OpenAI ChatGPT provides a 
      highly reliable, high-quality, but challenging to read, and acceptable similarity 
      rate in providing information related to CLP. Ensuring that information obtained 
      through these models is verified and assessed by a qualified medical expert is 
      crucial.
FAU - Duran, Gökhan Serhat
AU  - Duran GS
AD  - Department of Orthodontics, Gulhane Faculty of Dental Medicine, University of 
      Health Sciences, Ankara, Türkiye. RINGGOLD: 448249
FAU - Yurdakurban, Ebru
AU  - Yurdakurban E
AUID- ORCID: 0000-0001-9477-6894
AD  - Department of Orthodontics, Gulhane Faculty of Dental Medicine, University of 
      Health Sciences, Ankara, Türkiye. RINGGOLD: 448249
FAU - Topsakal, Kübra Gülnur
AU  - Topsakal KG
AUID- ORCID: 0000-0002-2717-3492
AD  - Department of Orthodontics, Gulhane Faculty of Dental Medicine, University of 
      Health Sciences, Ankara, Türkiye. RINGGOLD: 448249
LA  - eng
PT  - Journal Article
DEP - 20231221
PL  - United States
TA  - Cleft Palate Craniofac J
JT  - The Cleft palate-craniofacial journal : official publication of the American 
      Cleft Palate-Craniofacial Association
JID - 9102566
SB  - IM
OTO - NOTNLM
OT  - artificial intelligence
OT  - cleft lip and palate
OT  - natural language processing
COIS- Declaration of Conflicting InterestsThe authors declared no potential conflicts 
      of interest with respect to the research, authorship, and/or publication of this 
      article.
EDAT- 2023/12/22 00:42
MHDA- 2023/12/22 00:42
CRDT- 2023/12/21 19:52
PHST- 2023/12/22 00:42 [medline]
PHST- 2023/12/22 00:42 [pubmed]
PHST- 2023/12/21 19:52 [entrez]
AID - 10.1177/10556656231222387 [doi]
PST - aheadofprint
SO  - Cleft Palate Craniofac J. 2023 Dec 21:10556656231222387. doi: 
      10.1177/10556656231222387.

PMID- 37562022
OWN - NLM
STAT- MEDLINE
DCOM- 20240219
LR  - 20240219
IS  - 1527-330X (Electronic)
IS  - 1090-820X (Linking)
VI  - 44
IP  - 3
DP  - 2024 Feb 15
TI  - Large Language Models and Artificial Intelligence: A Primer for Plastic Surgeons 
      on the Demonstrated and Potential Applications, Promises, and Limitations of 
      ChatGPT.
PG  - 329-343
LID - 10.1093/asj/sjad260 [doi]
AB  - BACKGROUND: The rapidly evolving field of artificial intelligence (AI) holds 
      great potential for plastic surgeons. ChatGPT, a recently released AI large 
      language model (LLM), promises applications across many disciplines, including 
      healthcare. OBJECTIVES: The aim of this article was to provide a primer for 
      plastic surgeons on AI, LLM, and ChatGPT, including an analysis of current 
      demonstrated and proposed clinical applications. METHODS: A systematic review was 
      performed identifying medical and surgical literature on ChatGPT's proposed 
      clinical applications. Variables assessed included applications investigated, 
      command tasks provided, user input information, AI-emulated human skills, output 
      validation, and reported limitations. RESULTS: The analysis included 175 articles 
      reporting on 13 plastic surgery applications and 116 additional clinical 
      applications, categorized by field and purpose. Thirty-four applications within 
      plastic surgery are thus proposed, with relevance to different target audiences, 
      including attending plastic surgeons (n = 17, 50%), trainees/educators (n = 8, 
      24.0%), researchers/scholars (n = 7, 21%), and patients (n = 2, 6%). The 15 
      identified limitations of ChatGPT were categorized by training data, algorithm, 
      and ethical considerations. CONCLUSIONS: Widespread use of ChatGPT in plastic 
      surgery will depend on rigorous research of proposed applications to validate 
      performance and address limitations. This systemic review aims to guide research, 
      development, and regulation to safely adopt AI in plastic surgery.
CI  - © The Author(s) 2023. Published by Oxford University Press on behalf of The 
      Aesthetic Society. All rights reserved. For permissions, please e-mail: 
      journals.permissions@oup.com.
FAU - Abi-Rafeh, Jad
AU  - Abi-Rafeh J
AUID- ORCID: 0000-0002-7483-1515
FAU - Xu, Hong Hao
AU  - Xu HH
AUID- ORCID: 0000-0002-0742-3618
FAU - Kazan, Roy
AU  - Kazan R
FAU - Tevlin, Ruth
AU  - Tevlin R
FAU - Furnas, Heather
AU  - Furnas H
LA  - eng
PT  - Journal Article
PT  - Systematic Review
PL  - England
TA  - Aesthet Surg J
JT  - Aesthetic surgery journal
JID - 9707469
SB  - IM
MH  - Humans
MH  - Artificial Intelligence
MH  - Algorithms
MH  - *Surgeons
MH  - *Plastic Surgery Procedures
MH  - Language
EDAT- 2023/08/10 18:41
MHDA- 2024/02/19 06:44
CRDT- 2023/08/10 17:12
PHST- 2024/02/19 06:44 [medline]
PHST- 2023/08/10 18:41 [pubmed]
PHST- 2023/08/10 17:12 [entrez]
AID - 7240719 [pii]
AID - 10.1093/asj/sjad260 [doi]
PST - ppublish
SO  - Aesthet Surg J. 2024 Feb 15;44(3):329-343. doi: 10.1093/asj/sjad260.

PMID- 37467806
OWN - NLM
STAT- MEDLINE
DCOM- 20231023
LR  - 20231023
IS  - 1527-9995 (Electronic)
IS  - 0090-4295 (Linking)
VI  - 180
DP  - 2023 Oct
TI  - Caution! AI Bot Has Entered the Patient Chat: ChatGPT Has Limitations in 
      Providing Accurate Urologic Healthcare Advice.
PG  - 278-284
LID - S0090-4295(23)00597-6 [pii]
LID - 10.1016/j.urology.2023.07.010 [doi]
AB  - OBJECTIVE: To conduct the first study examining the accuracy of ChatGPT, an 
      artificial intelligence (AI) chatbot, derived patient counseling responses based 
      on clinical care guidelines in urology using a validated questionnaire. METHODS: 
      We asked ChatGPT a set of 13 urological guideline-based questions three times. 
      Answers were evaluated for appropriateness and using Brief DISCERN (BD), a 
      validated healthcare information assessment questionnaire. Data analysis included 
      descriptive statistics and Student's t test (SAS Studio). RESULTS: 60% (115/195) 
      of ChatGPT responses were deemed appropriate. Variability existed between 
      responses to the same prompt, with 25% of the 13 question sets having discordant 
      appropriateness designations. The average BD score was 16.8&nbsp;±&nbsp;3.59. Only 7 (54%) 
      of 13 topics and 21 (54%) of 39 responses met the BD cut-off score of ≥16 to 
      denote good-quality content. Appropriateness was associated with higher overall 
      and Relevance domain scores (both P&nbsp;&lt;&nbsp;.01). The lowest BD domain scores were for 
      Source categories, since ChatGPT does not provide references by default. With 
      prompting, 92.3% had ≥1 incorrect, misinterpreted, or nonfunctional citations. 
      CONCLUSION: While ChatGPT provides appropriate responses to urological questions 
      more than half of the time, it misinterprets clinical care guidelines, dismisses 
      important contextual information, conceals its sources, and provides 
      inappropriate references. Chatbot models hold great promise, but users should be 
      cautious when interpreting healthcare-related advice from existing AI models. 
      Additional training and modifications are needed before these AI models will be 
      ready for reliable use by patients and providers.
CI  - Copyright © 2023 Elsevier Inc. All rights reserved.
FAU - Whiles, Bristol B
AU  - Whiles BB
AD  - Department of Urology, University of Florida, Gainesville, FL. Electronic 
      address: bristolwhiles@gmail.com.
FAU - Bird, Vincent G
AU  - Bird VG
AD  - Department of Urology, University of Florida, Gainesville, FL.
FAU - Canales, Benjamin K
AU  - Canales BK
AD  - Department of Urology, University of Florida, Gainesville, FL.
FAU - DiBianco, John M
AU  - DiBianco JM
AD  - Department of Urology, University of Florida, Gainesville, FL.
FAU - Terry, Russell S
AU  - Terry RS
AD  - Department of Urology, University of Florida, Gainesville, FL.
LA  - eng
PT  - Journal Article
DEP - 20230717
PL  - United States
TA  - Urology
JT  - Urology
JID - 0366151
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Urology
MH  - Software
MH  - Data Analysis
MH  - Health Facilities
COIS- Declaration of Competing Interest The authors have no conflict of interest to 
      declare.
EDAT- 2023/07/20 01:07
MHDA- 2023/10/23 00:44
CRDT- 2023/07/19 19:22
PHST- 2023/04/25 00:00 [received]
PHST- 2023/06/20 00:00 [revised]
PHST- 2023/07/05 00:00 [accepted]
PHST- 2023/10/23 00:44 [medline]
PHST- 2023/07/20 01:07 [pubmed]
PHST- 2023/07/19 19:22 [entrez]
AID - S0090-4295(23)00597-6 [pii]
AID - 10.1016/j.urology.2023.07.010 [doi]
PST - ppublish
SO  - Urology. 2023 Oct;180:278-284. doi: 10.1016/j.urology.2023.07.010. Epub 2023 Jul 
      17.

PMID- 37387096
OWN - NLM
STAT- MEDLINE
DCOM- 20230703
LR  - 20230703
IS  - 1879-8365 (Electronic)
IS  - 0926-9630 (Linking)
VI  - 305
DP  - 2023 Jun 29
TI  - Training ChatGPT Models in Assisting Urologists in Daily Practice.
PG  - 576-579
LID - 10.3233/SHTI230562 [doi]
AB  - Artificial Intelligence (AI) has shown the ability to enhance the accuracy and 
      efficiency of physicians. ChatGPT is an AI chatbot that can interact with humans 
      through text, over the internet. It is trained with machine learning algorithms, 
      using large datasets. In this study, we compare the performance of using a 
      ChatGPT API 3.5 Turbo model to a general model, in assisting urologists in 
      obtaining accurate, valid medical information. The API was accessed through a 
      Python script that was applied specifically for this study based on 2023 EAU 
      guidelines in PDF format. This custom-trained model leads to providing doctors 
      with more precise, prompt answers about specific urologic subjects, thus helping 
      them, ultimately, providing better patient care.
FAU - Manolitsis, Ioannis
AU  - Manolitsis I
AD  - Second Department of Urology, National and Kapodistrian University of Athens, 
      Sismanogleio General Hospital, Athens, Greece.
FAU - Feretzakis, Georgios
AU  - Feretzakis G
AD  - School of Science and Technology, Hellenic Open University, Patras, Greece.
AD  - Sismanogleio General Hospital, Department of Quality Control, Research and 
      Continuing Education, Marousi, Greece.
FAU - Tzelves, Lazaros
AU  - Tzelves L
AD  - Second Department of Urology, National and Kapodistrian University of Athens, 
      Sismanogleio General Hospital, Athens, Greece.
FAU - Kalles, Dimitris
AU  - Kalles D
AD  - School of Science and Technology, Hellenic Open University, Patras, Greece.
FAU - Katsimperis, Stamatis
AU  - Katsimperis S
AD  - Second Department of Urology, National and Kapodistrian University of Athens, 
      Sismanogleio General Hospital, Athens, Greece.
FAU - Angelopoulos, Panagiotis
AU  - Angelopoulos P
AD  - Second Department of Urology, National and Kapodistrian University of Athens, 
      Sismanogleio General Hospital, Athens, Greece.
FAU - Anastasiou, Athanasios
AU  - Anastasiou A
AD  - National Technical University of Athens (NTUA).
FAU - Koutsouris, Dimitrios
AU  - Koutsouris D
AD  - National Technical University of Athens (NTUA).
FAU - Kosmidis, Thanos
AU  - Kosmidis T
AD  - CareAcross Ltd, London, United Kingdom.
FAU - Verykios, Vassilios S
AU  - Verykios VS
AD  - School of Science and Technology, Hellenic Open University, Patras, Greece.
FAU - Skolarikos, Andreas
AU  - Skolarikos A
AD  - Second Department of Urology, National and Kapodistrian University of Athens, 
      Sismanogleio General Hospital, Athens, Greece.
FAU - Varkarakis, Ioannis
AU  - Varkarakis I
AD  - Second Department of Urology, National and Kapodistrian University of Athens, 
      Sismanogleio General Hospital, Athens, Greece.
LA  - eng
PT  - Journal Article
PL  - Netherlands
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
MH  - Humans
MH  - *Urologists
MH  - Artificial Intelligence
MH  - *Physicians
MH  - Algorithms
MH  - Culture
OTO - NOTNLM
OT  - Artificial Intelligence
OT  - ChatGPT
OT  - Large Language Models
OT  - Urology
EDAT- 2023/06/30 06:42
MHDA- 2023/07/03 06:41
CRDT- 2023/06/30 04:24
PHST- 2023/07/03 06:41 [medline]
PHST- 2023/06/30 06:42 [pubmed]
PHST- 2023/06/30 04:24 [entrez]
AID - SHTI230562 [pii]
AID - 10.3233/SHTI230562 [doi]
PST - ppublish
SO  - Stud Health Technol Inform. 2023 Jun 29;305:576-579. doi: 10.3233/SHTI230562.

PMID- 37227901
OWN - NLM
STAT- MEDLINE
DCOM- 20230725
LR  - 20231127
IS  - 1728-7731 (Electronic)
IS  - 1726-4901 (Linking)
VI  - 86
IP  - 7
DP  - 2023 Jul 1
TI  - Performance of ChatGPT on the pharmacist licensing examination in Taiwan.
PG  - 653-658
LID - 10.1097/JCMA.0000000000000942 [doi]
AB  - BACKGROUND: ChatGPT is an artificial intelligence model trained for 
      conversations. ChatGPT has been widely applied in general medical education and 
      cardiology, but its application in pharmacy has been lacking. This study examined 
      the accuracy of ChatGPT on the Taiwanese Pharmacist Licensing Examination and 
      investigated its potential role in pharmacy education. METHODS: ChatGPT was used 
      on the first Taiwanese Pharmacist Licensing Examination in 2023 in Mandarin and 
      English. The questions were entered manually one by one. Graphical questions, 
      chemical formulae, and tables were excluded. Textual questions were scored 
      according to the number of correct answers. Chart question scores were determined 
      by multiplying the number and the correct rate of text questions. This study was 
      conducted from March 5 to March 10, 2023, by using ChatGPT 3.5. RESULTS: The 
      correct rate of ChatGPT in Chinese and English questions was 54.4% and 56.9% in 
      the first stage, and 53.8% and 67.6% in the second stage. On the Chinese test, 
      only pharmacology and pharmacochemistry sections received passing scores. The 
      English test scores were higher than the Chinese test scores across all subjects 
      and were significantly higher in dispensing pharmacy and clinical pharmacy as 
      well as therapeutics. CONCLUSION: ChatGPT 3.5 failed the Taiwanese Pharmacist 
      Licensing Examination. Although it is not able to pass the examination, it can be 
      improved quickly through deep learning. It reminds us that we should not only use 
      multiple-choice questions to assess a pharmacist's ability, but also use more 
      variety of evaluations in the future. Pharmacy education should be changed in 
      line with the examination, and students must be able to use AI technology for 
      self-learning. More importantly, we need to help students develop humanistic 
      qualities and strengthen their ability to interact with patients, so that they 
      can become warm-hearted healthcare professionals.
CI  - Copyright © 2023, the Chinese Medical Association.
FAU - Wang, Ying-Mei
AU  - Wang YM
AD  - Department of Medical Education and Research, Taipei Veterans General Hospital 
      Hsinchu Branch, Hsinchu, Taiwan, ROC.
AD  - Department of Pharmacy, Taipei Veterans General Hospital Hsinchu Branch, Hsinchu, 
      Taiwan, ROC.
AD  - School of Medicine, National Tsing Hua University, Hsinchu, Taiwan, ROC.
FAU - Shen, Hung-Wei
AU  - Shen HW
AD  - Department of Pharmacy, Taipei Veterans General Hospital Hsinchu Branch, Hsinchu, 
      Taiwan, ROC.
FAU - Chen, Tzeng-Ji
AU  - Chen TJ
AD  - Department of Family Medicine, Taipei Veterans General Hospital Hsinchu Branch, 
      Hsinchu, Taiwan, ROC.
AD  - Department of Family Medicine, Taipei Veterans General Hospital, Taipei, Taiwan, 
      ROC.
AD  - Department of Post-Baccalaureate Medicine, National Chung Hsing University, 
      Taichung, Taiwan, ROC.
LA  - eng
PT  - Journal Article
DEP - 20230705
PL  - Netherlands
TA  - J Chin Med Assoc
JT  - Journal of the Chinese Medical Association : JCMA
JID - 101174817
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Asian People
MH  - Health Personnel
MH  - Pharmacists/standards
MH  - Taiwan
MH  - *Pharmacy/standards
MH  - *Education, Pharmacy/methods
MH  - *Licensure
COIS- Conflicts of interest: Dr. Tzeng-Ji Chen, an editorial board member at Journal of 
      the Chinese Medical Association, had no role in the peer review process of or 
      decision to publish this article. The other authors declare that they have no 
      conflicts of interest related to the subject matter or materials discussed in 
      this article.
EDAT- 2023/05/25 19:12
MHDA- 2023/07/17 06:42
CRDT- 2023/05/25 12:45
PHST- 2023/07/17 06:42 [medline]
PHST- 2023/05/25 19:12 [pubmed]
PHST- 2023/05/25 12:45 [entrez]
AID - 02118582-202307000-00007 [pii]
AID - 10.1097/JCMA.0000000000000942 [doi]
PST - ppublish
SO  - J Chin Med Assoc. 2023 Jul 1;86(7):653-658. doi: 10.1097/JCMA.0000000000000942. 
      Epub 2023 Jul 5.

PMID- 38550240
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240329
IS  - 2352-3409 (Electronic)
IS  - 2352-3409 (Linking)
VI  - 54
DP  - 2024 Jun
TI  - The TrollLabs open hackathon dataset: Generative AI and large language models for 
      prototyping in engineering design.
PG  - 110332
LID - 10.1016/j.dib.2024.110332 [doi]
LID - 110332
AB  - The TrollLabs Open dataset includes comprehensive information that offers a 
      comparison of design practices and outcomes between human participants and 
      Generative AI during a hackathon event. The dataset was curated through the 
      running of a prototyping hackathon designed to assess the abilities and 
      performance of generative AI, specifically ChatGPT, in the early stages of 
      engineering design. This assessment involved comparing ChatGPT's performance to 
      that of experienced engineering students in a hackathon setting, where 
      participants competed by making a prototype that fires a NERF dart as far as 
      possible. In this setup, all ideas, concepts, strategies, and actions undertaken 
      by the AI-controlled team were autonomously generated by the ChatGPT, without 
      human intervention or guidance, but implemented by two participants. Five 
      self-directed baseline teams competed against the AI team. The dataset comprises 
      116 prototype entries and 433 edges (connection) that enable comparative analysis 
      of design practices and performance between the team instructed solely by 
      generative AI and baseline teams of experienced engineering design students. 
      Prototypes and their attribute data were captured using Pro2booth, an online 
      prototype capture platform running on participants' phones and computers. The 
      dataset includes a transcript of the conversation between ChatGPT and the team 
      responsible for implementing its recommendations, featuring 97 exchanges of 
      prompts and responses. It contains the initial prompt used to instruct the AI, 
      the objective and rules of the hackathon and the objective performance of teams, 
      showing the ChatGPT team finishing 2(nd) among six teams. To the authors' 
      knowledge, the TrollLabs Open dataset is the first and only open resource that 
      directly compares the performance of generative AI with human teams in an 
      engineering design context. Thus, it is intended to be a valuable resource to 
      design researchers, engineering and design students, educators, and industry 
      professionals seeking to find strategies for implementing generative AI tools in 
      their design processes. By offering a comprehensive data collection, the dataset 
      enables external researchers to conduct in-depth analyses that could highlight 
      the practical implications of integrating generative AI in design practices, 
      possibly providing an overview of its limitations and presenting recommendations 
      for improved integration in the design process.
CI  - © 2024 The Author(s).
FAU - Ege, Daniel Nygård
AU  - Ege DN
AD  - Norwegian University of Science and Technology, Richard Birkelands vei 2B, 
      Trondheim 7034, Norway.
FAU - Øvrebø, Henrik H
AU  - Øvrebø HH
AD  - Norwegian University of Science and Technology, Richard Birkelands vei 2B, 
      Trondheim 7034, Norway.
FAU - Stubberud, Vegar
AU  - Stubberud V
AD  - Norwegian University of Science and Technology, Richard Birkelands vei 2B, 
      Trondheim 7034, Norway.
FAU - Berg, Martin F
AU  - Berg MF
AD  - Norwegian University of Science and Technology, Richard Birkelands vei 2B, 
      Trondheim 7034, Norway.
FAU - Elverum, Christer
AU  - Elverum C
AD  - Norwegian University of Science and Technology, Richard Birkelands vei 2B, 
      Trondheim 7034, Norway.
FAU - Steinert, Martin
AU  - Steinert M
AD  - Norwegian University of Science and Technology, Richard Birkelands vei 2B, 
      Trondheim 7034, Norway.
FAU - Vestad, Håvard
AU  - Vestad H
AD  - Norwegian University of Science and Technology, Richard Birkelands vei 2B, 
      Trondheim 7034, Norway.
LA  - eng
PT  - Journal Article
DEP - 20240316
PL  - Netherlands
TA  - Data Brief
JT  - Data in brief
JID - 101654995
PMC - PMC10973971
OTO - NOTNLM
OT  - ChatGPT
OT  - Engineering Design
OT  - Generative AI
OT  - Prototyping
EDAT- 2024/03/29 06:46
MHDA- 2024/03/29 06:47
PMCR- 2024/03/16
CRDT- 2024/03/29 04:03
PHST- 2024/02/02 00:00 [received]
PHST- 2024/03/05 00:00 [revised]
PHST- 2024/03/11 00:00 [accepted]
PHST- 2024/03/29 06:47 [medline]
PHST- 2024/03/29 06:46 [pubmed]
PHST- 2024/03/29 04:03 [entrez]
PHST- 2024/03/16 00:00 [pmc-release]
AID - S2352-3409(24)00301-9 [pii]
AID - 110332 [pii]
AID - 10.1016/j.dib.2024.110332 [doi]
PST - epublish
SO  - Data Brief. 2024 Mar 16;54:110332. doi: 10.1016/j.dib.2024.110332. eCollection 
      2024 Jun.

PMID- 38126511
OWN - NLM
STAT- Publisher
LR  - 20231221
IS  - 1531-4995 (Electronic)
IS  - 0023-852X (Linking)
DP  - 2023 Dec 21
TI  - Exploring the Role of Artificial Intelligence Chatbots in Preoperative Counseling 
      for Head and Neck Cancer Surgery.
LID - 10.1002/lary.31243 [doi]
AB  - OBJECTIVE: To evaluate the potential use of artificial intelligence (AI) 
      chatbots, such as ChatGPT, in preoperative counseling for patients undergoing 
      head and neck cancer surgery. STUDY DESIGN: Cross-Sectional Survey Study. 
      SETTING: Single institution tertiary care center. METHODS: ChatGPT was used to 
      generate presurgical educational information including indications, risks, and 
      recovery time for five common head and neck surgeries. Chatbot-generated 
      information was compared with information gathered from a simple browser search 
      (first publicly available website excluding scholarly articles). The accuracy of 
      the information, readability, thoroughness, and number of errors were compared by 
      five experienced head and neck surgeons in a blinded fashion. Each surgeon then 
      chose a preference between the two information sources for each surgery. RESULTS: 
      With the exception of total word count, ChatGPT-generated pre-surgical 
      information has similar readability, content of knowledge, accuracy, 
      thoroughness, and numbers of medical errors when compared to publicly available 
      websites. Additionally, ChatGPT was preferred 48% of the time by experienced head 
      and neck surgeons. CONCLUSION: Head and neck surgeons rated ChatGPT-generated and 
      readily available online educational materials similarly. Further refinement in 
      AI technology may soon open more avenues for patient counseling. Future 
      investigations into the medical safety of AI counseling and exploring patients' 
      perspectives would be of strong interest. LEVEL OF EVIDENCE: N/A. Laryngoscope, 
      2023.
CI  - © 2023 The American Laryngological, Rhinological and Otological Society, Inc.
FAU - Lee, Jason C
AU  - Lee JC
AUID- ORCID: 0000-0001-9117-4492
AD  - Department of Otolaryngology, University of Kansas Medical Center, Kansas City, 
      Kansas, U.S.A.
FAU - Hamill, Chelsea S
AU  - Hamill CS
AD  - Department of Otolaryngology, University of Kansas Medical Center, Kansas City, 
      Kansas, U.S.A.
FAU - Shnayder, Yelizaveta
AU  - Shnayder Y
AUID- ORCID: 0000-0001-8972-175X
AD  - Department of Otolaryngology, University of Kansas Medical Center, Kansas City, 
      Kansas, U.S.A.
FAU - Buczek, Erin
AU  - Buczek E
AD  - Department of Otolaryngology, University of Kansas Medical Center, Kansas City, 
      Kansas, U.S.A.
FAU - Kakarala, Kiran
AU  - Kakarala K
AD  - Department of Otolaryngology, University of Kansas Medical Center, Kansas City, 
      Kansas, U.S.A.
FAU - Bur, Andrés M
AU  - Bur AM
AUID- ORCID: 0000-0001-6879-6453
AD  - Department of Otolaryngology, University of Kansas Medical Center, Kansas City, 
      Kansas, U.S.A.
LA  - eng
PT  - Journal Article
DEP - 20231221
PL  - United States
TA  - Laryngoscope
JT  - The Laryngoscope
JID - 8607378
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - chatbot
OT  - head and neck surgery
OT  - patient counseling
EDAT- 2023/12/21 12:42
MHDA- 2023/12/21 12:42
CRDT- 2023/12/21 08:03
PHST- 2023/10/25 00:00 [revised]
PHST- 2023/07/06 00:00 [received]
PHST- 2023/11/30 00:00 [accepted]
PHST- 2023/12/21 12:42 [medline]
PHST- 2023/12/21 12:42 [pubmed]
PHST- 2023/12/21 08:03 [entrez]
AID - 10.1002/lary.31243 [doi]
PST - aheadofprint
SO  - Laryngoscope. 2023 Dec 21. doi: 10.1002/lary.31243.

PMID- 37968408
OWN - NLM
STAT- MEDLINE
DCOM- 20240105
LR  - 20240212
IS  - 1432-5195 (Electronic)
IS  - 0341-2695 (Linking)
VI  - 48
IP  - 1
DP  - 2024 Jan
TI  - Does Google's Bard Chatbot perform better than ChatGPT on the European hand 
      surgery exam?
PG  - 151-158
LID - 10.1007/s00264-023-06034-y [doi]
AB  - PURPOSE: According to a previous research, the chatbot ChatGPT® V3.5 was unable 
      to pass the first part of the European Board of Hand Surgery (EBHS) diploma 
      examination. This study aimed to investigate whether Google's chatbot Bard® would 
      have superior performance compared to ChatGPT on the EBHS diploma examination. 
      METHODS: Chatbots were asked to answer 18 EBHS multiple choice questions (MCQs) 
      published in the Journal of Hand Surgery (European Volume) in five trials (A1 to 
      A5). After A3, chatbots received correct answers, and after A4, incorrect 
      answers. Consequently, their ability to modify their response was measured and 
      compared. RESULTS: Bard® scored 3/18 (A1), 1/18 (A2), 4/18 (A3) and 2/18 (A4 and 
      A5). The average percentage of correct answers was 61.1% for A1, 62.2% for A2, 
      64.4% for A3, 65.6% for A4, 63.3% for A5 and 63.3% for all trials combined. 
      Agreement was moderate from A1 to A5 (kappa = 0.62 (IC95% = [0.51; 0.73])) as 
      well as from A1 to A3 (kappa = 0.60 (IC95% = [0.47; 0.74])). The formulation of 
      Bard® responses was homogeneous, but its learning capacity is still developing. 
      CONCLUSIONS: The main hypothesis of our study was not proved since Bard did not 
      score significantly higher than ChatGPT when answering the MCQs of the EBHS 
      diploma exam.&nbsp;In conclusion, neither ChatGPT® nor Bard®, in their current 
      versions, can pass the first part of the EBHS diploma exam.
CI  - © 2023. The Author(s) under exclusive licence to SICOT aisbl.
FAU - Thibaut, Goetsch
AU  - Thibaut G
AD  - Department of Public Health, Strasbourg University Hospital, FMTS, GMRC, 1 avenue 
      de l'hôpital, 67000, Strasbourg cedex, France.
FAU - Dabbagh, Armaghan
AU  - Dabbagh A
AD  - Faculty of Medicine, University of Toronto, Toronto, ON, Canada.
FAU - Liverneaux, Philippe
AU  - Liverneaux P
AUID- ORCID: 0000-0002-5509-8995
AD  - ICube CNRS UMR7357, Strasbourg University, 2-4 rue Boussingault, 67000, 
      Strasbourg, France. philippe.liverneaux@chru-strasbourg.fr.
AD  - Department of Hand Surgery, Strasbourg University Hospitals, FMTS, 1 avenue 
      Molière, 67200, Strasbourg, France. philippe.liverneaux@chru-strasbourg.fr.
LA  - eng
PT  - Journal Article
DEP - 20231115
PL  - Germany
TA  - Int Orthop
JT  - International orthopaedics
JID - 7705431
SB  - IM
MH  - Humans
MH  - *Search Engine
MH  - *Software
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Bard
OT  - ChatGPT
OT  - Chatbot
OT  - Hand Surgery
OT  - Multiple-choice question
EDAT- 2023/11/16 00:42
MHDA- 2024/01/05 06:42
CRDT- 2023/11/15 23:56
PHST- 2023/10/07 00:00 [received]
PHST- 2023/11/01 00:00 [accepted]
PHST- 2024/01/05 06:42 [medline]
PHST- 2023/11/16 00:42 [pubmed]
PHST- 2023/11/15 23:56 [entrez]
AID - 10.1007/s00264-023-06034-y [pii]
AID - 10.1007/s00264-023-06034-y [doi]
PST - ppublish
SO  - Int Orthop. 2024 Jan;48(1):151-158. doi: 10.1007/s00264-023-06034-y. Epub 2023 
      Nov 15.

PMID- 37829968
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231020
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 9
DP  - 2023 Sep
TI  - ChatGPT Conquers the Saudi Medical Licensing Exam: Exploring the Accuracy of 
      Artificial Intelligence in Medical Knowledge Assessment and Implications for 
      Modern Medical Education.
PG  - e45043
LID - 10.7759/cureus.45043 [doi]
LID - e45043
AB  - Background The application of artificial intelligence (AI) in education is 
      undergoing rapid advancements, with models such as ChatGPT-4 showing potential in 
      medical education. This study aims to evaluate the proficiency of ChatGPT-4 in 
      answering Saudi Medical Licensing Exam (SMLE) questions. Methodology A dataset of 
      220 questions across four medical disciplines was used. The model was trained 
      using a specific code to answer the questions accurately, and its performance was 
      assessed using key performance indicators, difficulty level, and exam sections. 
      Results ChatGPT-4 demonstrated an overall accuracy of 88.6%. It showed high 
      proficiency with Easy and Average questions, but accuracy decreased for Hard 
      questions. Performance was consistent across all disciplines, indicating a broad 
      knowledge base. However, an error analysis revealed areas for further refinement, 
      particularly with category (Option) A questions across all sections. Conclusions 
      This study underscores the potential of ChatGPT-4 as an AI-assisted tool in 
      medical education, demonstrating high proficiency in answering SMLE questions. 
      Future research is recommended to expand the scope of training and evaluation as 
      well as to enhance the model's performance on complex clinical questions.
CI  - Copyright © 2023, Aljindan et al.
FAU - Aljindan, Fahad K
AU  - Aljindan FK
AD  - Department of Plastic Surgery, King Abdullah Medical City, Makkah, SAU.
FAU - Al Qurashi, Abdullah A
AU  - Al Qurashi AA
AD  - College of Medicine, King Saud Bin Abdulaziz University for Health Sciences, 
      Jeddah, SAU.
FAU - Albalawi, Ibrahim Abdullah S
AU  - Albalawi IAS
AD  - College of Medicine, Tabuk University for Health Sciences, Tabuk, SAU.
FAU - Alanazi, Abeer Mohammed M
AU  - Alanazi AMM
AD  - Department of Pediatrics, Faculty of Medicine, University of Tabuk, Tabuk, SAU.
FAU - Aljuhani, Hussam Abdulkhaliq M
AU  - Aljuhani HAM
AD  - Faculty of Medicine, Ibn Sina National College, Jeddah, SAU.
FAU - Falah Almutairi, Faisal
AU  - Falah Almutairi F
AD  - College of Medicine, Unaizah College of Medicine and Medical Sciences, Qassim 
      University, Unaizah, SAU.
FAU - Aldamigh, Omar A
AU  - Aldamigh OA
AD  - College of Medicine, King Faisal University, Dammam, SAU.
FAU - Halawani, Ibrahim R
AU  - Halawani IR
AD  - Faculty of Medicine, King Abdulaziz University, Jeddah, SAU.
FAU - K Zino Alarki, Subhi M
AU  - K Zino Alarki SM
AD  - Department of Surgery, King Khalid University Hospital, Riyadh, SAU.
LA  - eng
PT  - Journal Article
DEP - 20230911
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10566535
OTO - NOTNLM
OT  - ai in healthcare
OT  - artificial intelligence
OT  - chatgpt-4
OT  - medical education
OT  - saudi medical licensing exam
OT  - smle
OT  - standardized medical exam
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/10/13 06:46
MHDA- 2023/10/13 06:47
PMCR- 2023/09/11
CRDT- 2023/10/13 04:13
PHST- 2023/09/11 00:00 [accepted]
PHST- 2023/10/13 06:47 [medline]
PHST- 2023/10/13 06:46 [pubmed]
PHST- 2023/10/13 04:13 [entrez]
PHST- 2023/09/11 00:00 [pmc-release]
AID - 10.7759/cureus.45043 [doi]
PST - epublish
SO  - Cureus. 2023 Sep 11;15(9):e45043. doi: 10.7759/cureus.45043. eCollection 2023 
      Sep.

PMID- 38204561
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240112
IS  - 0253-8253 (Print)
IS  - 2227-0426 (Electronic)
IS  - 0253-8253 (Linking)
VI  - 2023
IP  - 4
DP  - 2023
TI  - Exploring polycystic disease solutions with ChatGPT: the role of AI in patient 
      support and empowerment.
PG  - 35
LID - 10.5339/qmj.2023.35 [doi]
LID - 35
FAU - Jerry, Jackson Keefer
AU  - Jerry JK
AD  - Internal Medicine, PSG Institute of Medical Sciences and Research, India Email: 
      jkjerry 2023@gmail.com.
LA  - eng
PT  - Journal Article
DEP - 20240110
PL  - Qatar
TA  - Qatar Med J
JT  - Qatar medical journal
JID - 8101648
PMC - PMC10776889
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - gynecology
OT  - polycystic ovarian disease
COIS- No conflict of interest to declared.
EDAT- 2024/01/11 07:42
MHDA- 2024/01/11 07:43
PMCR- 2024/01/10
CRDT- 2024/01/11 04:01
PHST- 2023/08/17 00:00 [received]
PHST- 2023/11/09 00:00 [accepted]
PHST- 2024/01/11 07:43 [medline]
PHST- 2024/01/11 07:42 [pubmed]
PHST- 2024/01/11 04:01 [entrez]
PHST- 2024/01/10 00:00 [pmc-release]
AID - qmj.2023.35 [pii]
AID - 10.5339/qmj.2023.35 [doi]
PST - epublish
SO  - Qatar Med J. 2024 Jan 10;2023(4):35. doi: 10.5339/qmj.2023.35. eCollection 2023.

PMID- 37310252
OWN - NLM
STAT- MEDLINE
DCOM- 20230615
LR  - 20230620
IS  - 1527-1315 (Electronic)
IS  - 0033-8419 (Linking)
VI  - 307
IP  - 5
DP  - 2023 Jun
TI  - How AI Responds to Common Lung Cancer Questions: ChatGPT vs Google Bard.
PG  - e230922
LID - 10.1148/radiol.230922 [doi]
AB  - Background The recent release of large language models (LLMs) for public use, 
      such as ChatGPT and Google Bard, has opened up a multitude of potential benefits 
      as well as challenges. Purpose To evaluate and compare the accuracy and 
      consistency of responses generated by publicly available ChatGPT-3.5 and Google 
      Bard to non-expert questions related to lung cancer prevention, screening, and 
      terminology commonly used in radiology reports based on the recommendation of 
      Lung Imaging Reporting and Data System (Lung-RADS) v2022 from American College of 
      Radiology and Fleischner society. Materials and Methods Forty of the exact same 
      questions were created and presented to ChatGPT-3.5 and Google Bard experimental 
      version as well as Bing and Google search engines by three different authors of 
      this paper. Each answer was reviewed by two radiologists for accuracy. Responses 
      were scored as correct, partially correct, incorrect, or unanswered. Consistency 
      was also evaluated among the answers. Here, consistency was defined as the 
      agreement between the three answers provided by ChatGPT-3.5, Google Bard 
      experimental version, Bing, and Google search engines regardless of whether the 
      concept conveyed was correct or incorrect. The accuracy among different tools 
      were evaluated using Stata. Results ChatGPT-3.5 answered 120 questions with 85 
      (70.8%) correct, 14 (11.7%) partially correct, and 21 (17.5%) incorrect. Google 
      Bard did not answer 23 (19.1%) questions. Among the 97 questions answered by 
      Google Bard, 62 (51.7%) were correct, 11 (9.2%) were partially correct, and 24 
      (20%) were incorrect. Bing answered 120 questions with 74 (61.7%) correct, 13 
      (10.8%) partially correct, and 33 (27.5%) incorrect. Google search engine 
      answered 120 questions with 66 (55%) correct, 27 (22.5%) partially correct, and 
      27 (22.5%) incorrect. The ChatGPT-3.5 is more likely to provide correct or 
      partially answer than Google Bard, approximately by 1.5 folds (OR = 1.55, P = 
      0.004). ChatGPT-3.5 and Google search engine were more likely to be consistent 
      than Google Bard by approximately 7 and 29 folds (OR = 6.65, P = 0.002 for 
      ChatGPT and OR = 28.83, P = 0.002 for Google search engine, respectively). 
      Conclusion Although ChatGPT-3.5 had a higher accuracy in comparison with the 
      other tools, neither ChatGPT nor Google Bard, Bing and Google search engines 
      answered all questions correctly and with 100% consistency.
FAU - Rahsepar, Amir Ali
AU  - Rahsepar AA
AUID- ORCID: 0000-0002-6228-4673
AD  - Department of Radiological Sciences, Division of Cardiothoracic Imaging, David 
      Geffen School of Medicine at UCLA, Los Angeles, CA, USA.
FAU - Tavakoli, Neda
AU  - Tavakoli N
AUID- ORCID: 0000-0002-1541-5917
AD  - School of Computational Science and Engineering, Georgia Institute of Technology, 
      Atlanta, Georgia, USA.
FAU - Kim, Grace Hyun J
AU  - Kim GHJ
AUID- ORCID: 0000-0003-1225-3489
AD  - Center for Computer Vision and Imaging Biomarkers, Dept of Radiological Sciences 
      David Geffen School of Medicine at UCLA, Los Angeles, CA, USA.
AD  - Dept of Biostatistics Fielding School of Public at UCLA, Los Angeles, CA, USA.
FAU - Hassani, Cameron
AU  - Hassani C
AUID- ORCID: 0000-0002-2831-5384
AD  - Department of Radiological Sciences, Division of Cardiothoracic Imaging, David 
      Geffen School of Medicine at UCLA, Los Angeles, CA, USA.
FAU - Abtin, Fereidoun
AU  - Abtin F
AUID- ORCID: 0000-0003-2927-0883
AD  - Department of Radiological Sciences, Division of Cardiothoracic Imaging, David 
      Geffen School of Medicine at UCLA, Los Angeles, CA, USA.
FAU - Bedayat, Arash
AU  - Bedayat A
AUID- ORCID: 0000-0001-8769-0224
AD  - Department of Radiological Sciences, Division of Cardiothoracic Imaging, David 
      Geffen School of Medicine at UCLA, Los Angeles, CA, USA.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Radiology
JT  - Radiology
JID - 0401260
SB  - IM
MH  - Humans
MH  - *Lung Neoplasms/diagnostic imaging
MH  - Search Engine
MH  - Tomography, X-Ray Computed
MH  - Language
MH  - Artificial Intelligence
EDAT- 2023/06/13 13:12
MHDA- 2023/06/15 06:42
CRDT- 2023/06/13 10:05
PHST- 2023/06/15 06:42 [medline]
PHST- 2023/06/13 13:12 [pubmed]
PHST- 2023/06/13 10:05 [entrez]
AID - 10.1148/radiol.230922 [doi]
PST - ppublish
SO  - Radiology. 2023 Jun;307(5):e230922. doi: 10.1148/radiol.230922.

PMID- 37167941
OWN - NLM
STAT- MEDLINE
DCOM- 20230515
LR  - 20230515
IS  - 1175-8716 (Electronic)
IS  - 0028-8446 (Linking)
VI  - 136
IP  - 1575
DP  - 2023 May 12
TI  - The impact of AI and ChatGPT on research reporting.
PG  - 60-64
AB  - ChatGPT and the newest GPT-4 are AI language models developed by OpenAI that have 
      gained attention for their potential applications in biomedical research 
      reporting. The models can assist researchers in various stages of writing 
      scientific articles, including literature search, outlining, writing different 
      sections, formatting, and translation. The use of ChatGPT or GPT-4 in research 
      reporting has the potential to speed up the writing process, but its limitations, 
      such as incorrect answers and biases, should also be considered. There is ongoing 
      debate over the issue of AI authorship in scientific papers, with some publishers 
      allowing it to be listed as a contributor in the acknowledgements section, while 
      others do not allow it to be listed as an author. The use of ChatGPT or GPT-4 in 
      research reporting is a recent development, and further studies and discussions 
      are needed to determine their potential and limitations in this field.
CI  - © PMA.
FAU - Mojadeddi, Zubair M
AU  - Mojadeddi ZM
AD  - Center for Perioperative Optimization, Department of Surgery, Herlev and Gentofte 
      Hospital, University of Copenhagen, Copenhagen, Denmark.
FAU - Rosenberg, Jacob
AU  - Rosenberg J
AD  - Center for Perioperative Optimization, Department of Surgery, Herlev and Gentofte 
      Hospital, University of Copenhagen, Copenhagen, Denmark; Department of Clinical 
      Medicine, Faculty of Health and Medical Sciences, University of Copenhagen, 
      Denmark.
LA  - eng
PT  - Journal Article
DEP - 20230512
PL  - New Zealand
TA  - N Z Med J
JT  - The New Zealand medical journal
JID - 0401067
SB  - IM
MH  - Humans
MH  - New Zealand
MH  - *Authorship
MH  - *Biomedical Research
MH  - Research Personnel
MH  - Artificial Intelligence
COIS- Nil
EDAT- 2023/05/12 01:07
MHDA- 2023/05/15 06:42
CRDT- 2023/05/11 18:13
PHST- 2023/05/15 06:42 [medline]
PHST- 2023/05/12 01:07 [pubmed]
PHST- 2023/05/11 18:13 [entrez]
PST - epublish
SO  - N Z Med J. 2023 May 12;136(1575):60-64.

PMID- 38522424
OWN - NLM
STAT- Publisher
LR  - 20240324
IS  - 1743-1328 (Electronic)
IS  - 0161-6412 (Linking)
DP  - 2024 Mar 24
TI  - Artificial intelligence performance in clinical neurology queries: the ChatGPT 
      model.
PG  - 1-7
LID - 10.1080/01616412.2024.2334118 [doi]
AB  - INTRODUCTION: The use of artificial intelligence technology is progressively 
      expanding and advancing in the health and biomedical literature. Since its 
      launch, ChatGPT has rapidly gained popularity and become one of the 
      fastest-growing artificial intelligence applications in history. This study 
      evaluated the accuracy and comprehensiveness of ChatGPT-generated responses to 
      medical queries in clinical neurology. METHODS: We directed 216 questions from 
      different subspecialties to ChatGPT. The questions were classified into three 
      categories: multiple-choice, descriptive, and binary (yes/no answers). Each 
      question in all categories was subjectively rated as easy, medium, or hard 
      according to its difficulty level. Questions that also tested for intuitive 
      clinical thinking and reasoning ability were evaluated in a separate category. 
      RESULTS: ChatGPT correctly answered 141 questions (65.3%). No significant 
      difference was detected in the accuracy and comprehensiveness scale scores or 
      correct answer rates in comparisons made according to the question style or 
      difficulty level. However, a comparative analysis assessing question 
      characteristics revealed significantly lower accuracy and comprehensiveness scale 
      scores and correct answer rates for questions based on interpretations that 
      required critical thinking (p = 0.007, 0.007, and 0.001, respectively). 
      CONCLUSION: ChatGPT had a moderate overall performance in clinical neurology and 
      demonstrated inadequate performance in answering questions that required 
      interpretation and critical thinking. It also displayed limited performance in 
      specific subspecialties. It is essential to acknowledge the limitations of 
      artificial intelligence and diligently verify medical information produced by 
      such models using reliable sources.
FAU - Altunisik, Erman
AU  - Altunisik E
AUID- ORCID: 0000-0002-5996-2090
AD  - Department of Neurology, Adiyaman University Faculty of Medicine, Adiyaman, 
      Turkey.
FAU - Firat, Yasemin Ekmekyapar
AU  - Firat YE
AUID- ORCID: 0000-0002-2104-6003
AD  - Department of Neurology, Sanko University Faculty of Medicine, Gaziantep, Turkey.
FAU - Cengiz, Emine Kilicparlar
AU  - Cengiz EK
AUID- ORCID: 0000-0001-8894-4433
AD  - Medical Doctor Emine Kilicparlar Cengiz. Department of Neurology, Ersin Arslan 
      Training and Research Hospital, Gaziantep, Turkey.
FAU - Comruk, Gulsum Bayana
AU  - Comruk GB
AUID- ORCID: 0000-0002-9175-6553
AD  - Medical Doctor Gulsum Bayana Comruk. Department of Neurology, Hatay Public 
      Hospital, Hatay, Turkey.
LA  - eng
PT  - Journal Article
DEP - 20240324
PL  - England
TA  - Neurol Res
JT  - Neurological research
JID - 7905298
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - accuracy
OT  - artificial intelligence
OT  - clinical neurology
OT  - comprehensiveness
EDAT- 2024/03/25 00:42
MHDA- 2024/03/25 00:42
CRDT- 2024/03/24 19:35
PHST- 2024/03/25 00:42 [medline]
PHST- 2024/03/25 00:42 [pubmed]
PHST- 2024/03/24 19:35 [entrez]
AID - 10.1080/01616412.2024.2334118 [doi]
PST - aheadofprint
SO  - Neurol Res. 2024 Mar 24:1-7. doi: 10.1080/01616412.2024.2334118.

PMID- 38412022
OWN - NLM
STAT- MEDLINE
DCOM- 20240228
LR  - 20240315
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 10
DP  - 2024 Feb 27
TI  - Using ChatGPT-Like Solutions to Bridge the Communication Gap Between Patients 
      With Rheumatoid Arthritis and Health Care Professionals.
PG  - e48989
LID - 10.2196/48989 [doi]
LID - e48989
AB  - The communication gap between patients and health care professionals has led to 
      increased disputes and resource waste in the medical domain. The development of 
      artificial intelligence and other technologies brings new possibilities to solve 
      this problem. This viewpoint paper proposes a new relationship between patients 
      and health care professionals-"shared decision-making"-allowing both sides to 
      obtain a deeper understanding of the disease and reach a consensus during 
      diagnosis and treatment. Then, this paper discusses the important impact of 
      ChatGPT-like solutions in treating rheumatoid arthritis using methotrexate from 
      clinical and patient perspectives. For clinical professionals, ChatGPT-like 
      solutions could provide support in disease diagnosis, treatment, and clinical 
      trials, but attention should be paid to privacy, confidentiality, and regulatory 
      norms. For patients, ChatGPT-like solutions allow easy access to massive amounts 
      of information; however, the information should be carefully managed to ensure 
      safe and effective care. To ensure the effective application of ChatGPT-like 
      solutions in improving the relationship between patients and health care 
      professionals, it is essential to establish a comprehensive database and provide 
      legal, ethical, and other support. Above all, ChatGPT-like solutions could 
      benefit patients and health care professionals if they ensure evidence-based 
      solutions and data protection and collaborate with regulatory authorities and 
      regulatory evolution.
CI  - ©Chih-Wei Chen, Paul Walter, James Cheng-Chung Wei. Originally published in JMIR 
      Medical Education (https://mededu.jmir.org), 27.02.2024.
FAU - Chen, Chih-Wei
AU  - Chen CW
AUID- ORCID: 0000-0003-4004-7826
AD  - National Applied Research Laboratories, Taipei, Taiwan.
AD  - National Council for Sustainable Development, Taipei, Taiwan.
AD  - Institute of Medicine, Chung Shan Medical University, Taichung, Taiwan.
AD  - Faculty of Engineering Sciences, University College London (UCL), London, United 
      Kingdom.
FAU - Walter, Paul
AU  - Walter P
AUID- ORCID: 0009-0002-5852-8177
AD  - National Applied Research Laboratories, Taipei, Taiwan.
AD  - Faculty of Pharmacy, Paris-Saclay University, Orsay, France.
AD  - Mines Saint-Etienne, Saint-Etienne, France.
FAU - Wei, James Cheng-Chung
AU  - Wei JC
AUID- ORCID: 0000-0002-1235-0679
AD  - Institute of Medicine, Chung Shan Medical University, Taichung, Taiwan.
AD  - Department of Allergy, Immunology &amp; Rheumatology, Chung Shan Medical University 
      Hospital, Taichung, Taiwan.
LA  - eng
PT  - Journal Article
DEP - 20240227
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
RN  - YL5FZ2Y5U1 (Methotrexate)
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Arthritis, Rheumatoid/diagnosis
MH  - Methotrexate/therapeutic use
MH  - Communication
MH  - Health Personnel
PMC - PMC10933717
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - communication gap
OT  - data management
OT  - privacy
OT  - rheumatoid arthritis
COIS- Conflicts of Interest: None declared.
EDAT- 2024/02/27 12:47
MHDA- 2024/02/28 06:43
PMCR- 2024/02/27
CRDT- 2024/02/27 11:54
PHST- 2023/05/14 00:00 [received]
PHST- 2024/02/05 00:00 [accepted]
PHST- 2023/10/09 00:00 [revised]
PHST- 2024/02/28 06:43 [medline]
PHST- 2024/02/27 12:47 [pubmed]
PHST- 2024/02/27 11:54 [entrez]
PHST- 2024/02/27 00:00 [pmc-release]
AID - v10i1e48989 [pii]
AID - 10.2196/48989 [doi]
PST - epublish
SO  - JMIR Med Educ. 2024 Feb 27;10:e48989. doi: 10.2196/48989.

PMID- 37939645
OWN - NLM
STAT- MEDLINE
DCOM- 20231205
LR  - 20240125
IS  - 1878-0539 (Electronic)
IS  - 1748-6815 (Linking)
VI  - 87
DP  - 2023 Dec
TI  - Integrating artificial intelligence in orthognathic surgery: A case study of 
      ChatGPT's role in enhancing physician-patient consultations for dentofacial 
      deformities.
PG  - 405-407
LID - S1748-6815(23)00667-8 [pii]
LID - 10.1016/j.bjps.2023.10.097 [doi]
AB  - Orthognathic surgery, a multidisciplinary treatment for dentofacial deformities, 
      presents complex preoperative preparations and follow-up procedures. This study 
      aims to evaluate the effectiveness of ChatGPT-4, an artificial intelligence-based 
      language model, as a supportive tool during patient consultations for 
      orthognathic surgery. Nine critical questions that candidates for orthognathic 
      surgery should ask during a consultation were identified and posed to ChatGPT-4. 
      The responses were subsequently assessed by experienced plastic surgeons and 
      collaborating orthodontists at a leading orthognathic surgery center. Evaluations 
      focused on the accuracy, clarity, and comprehensibility of the information 
      provided. ChatGPT-4 generated comprehensive, clear, and accurate responses, 
      offering critical technical information to guide patients through the 
      complexities of orthognathic surgery. However, it consistently underscored the 
      necessity of individualized responses and emphasized that specialized medical 
      consultation is crucial for treatment and follow-up plans. While ChatGPT-4 shows 
      promise as a reliable informational resource, it cannot fully replace the nuanced 
      physician-patient relationship, particularly in situations requiring emotional 
      intelligence and specialized expertise. ChatGPT-4 can serve as an informative and 
      guiding assistant during the consultation process for orthognathic surgery, 
      although it cannot substitute for direct medical consultation. This tool could be 
      an asset for both patients and physicians in managing the intricate treatment 
      process of orthognathic surgery.
CI  - Copyright © 2023 British Association of Plastic, Reconstructive and Aesthetic 
      Surgeons. Published by Elsevier Ltd. All rights reserved.
FAU - Alten, Aytaç
AU  - Alten A
AD  - Istanbul University, Istanbul Faculty of Medicine, Plastic Reconstructive and 
      Aesthetic Surgery Department, İstanbul Tıp Fakültesi Çapa - Fatih, Istanbul, 
      Türkiye. Electronic address: altenaytac@istanbul.edu.tr.
FAU - Gündeş, Elif
AU  - Gündeş E
AD  - Istanbul University, Istanbul Faculty of Medicine, Plastic Reconstructive and 
      Aesthetic Surgery Department, İstanbul Tıp Fakültesi Çapa - Fatih, Istanbul, 
      Türkiye. Electronic address: elifgundes@istanbul.edu.tr.
FAU - Tuncer, Eren
AU  - Tuncer E
AD  - Başakşehir Çam and Sakura State Hospital Plastic Reconstructive and Aesthetic 
      Surgery Department, G-434 Street No: 2L, Başakşehir Neighborhood, Başakşehir, 
      Istanbul, Türkiye. Electronic address: erentuncr@gmail.com.
FAU - Kozanoğlu, Erol
AU  - Kozanoğlu E
AD  - Istanbul University, Istanbul Faculty of Medicine, Plastic Reconstructive and 
      Aesthetic Surgery Department, İstanbul Tıp Fakültesi Çapa - Fatih, Istanbul, 
      Türkiye. Electronic address: erol.kozanoglu@istanbul.edu.tr.
FAU - Akalın, Bora Edim
AU  - Akalın BE
AD  - Istanbul University, Istanbul Faculty of Medicine, Plastic Reconstructive and 
      Aesthetic Surgery Department, İstanbul Tıp Fakültesi Çapa - Fatih, Istanbul, 
      Türkiye. Electronic address: bora.akalin@istanbul.edu.tr.
FAU - Emekli, Ufuk
AU  - Emekli U
AD  - Istanbul University, Istanbul Faculty of Medicine, Plastic Reconstructive and 
      Aesthetic Surgery Department, İstanbul Tıp Fakültesi Çapa - Fatih, Istanbul, 
      Türkiye. Electronic address: ufukemekli@yahoo.com.
LA  - eng
PT  - Journal Article
DEP - 20231018
PL  - Netherlands
TA  - J Plast Reconstr Aesthet Surg
JT  - Journal of plastic, reconstructive &amp; aesthetic surgery : JPRAS
JID - 101264239
SB  - IM
MH  - Humans
MH  - Artificial Intelligence
MH  - *Orthognathic Surgery
MH  - *Dentofacial Deformities
MH  - Referral and Consultation
MH  - *Surgeons
OTO - NOTNLM
OT  - Artificial intelligence (AI)
OT  - ChatGPT
OT  - Dentofacial deformity
OT  - Orthognathic surgery
OT  - Patient consultation
COIS- Declaration of Competing Interest None declared.
EDAT- 2023/11/09 00:42
MHDA- 2023/12/05 12:44
CRDT- 2023/11/08 18:11
PHST- 2023/09/14 00:00 [received]
PHST- 2023/10/10 00:00 [revised]
PHST- 2023/10/15 00:00 [accepted]
PHST- 2023/12/05 12:44 [medline]
PHST- 2023/11/09 00:42 [pubmed]
PHST- 2023/11/08 18:11 [entrez]
AID - S1748-6815(23)00667-8 [pii]
AID - 10.1016/j.bjps.2023.10.097 [doi]
PST - ppublish
SO  - J Plast Reconstr Aesthet Surg. 2023 Dec;87:405-407. doi: 
      10.1016/j.bjps.2023.10.097. Epub 2023 Oct 18.

PMID- 37808173
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231030
IS  - 1733-134X (Print)
IS  - 1899-0967 (Electronic)
IS  - 1733-134X (Linking)
VI  - 88
DP  - 2023
TI  - Will ChatGPT pass the Polish specialty exam in radiology and diagnostic imaging? 
      Insights into strengths and limitations.
PG  - e430-e434
LID - 10.5114/pjr.2023.131215 [doi]
AB  - PURPOSE: Rapid development of artificial intelligence has aroused curiosity 
      regarding its potential applications in medical field. The purpose of this 
      article was to present the performance of ChatGPT, a state-of-the-art language 
      model in relation to pass rate of national specialty examination (PES) in 
      radiology and imaging diagnostics within Polish education system. Additionally, 
      the study aimed to identify the strengths and limitations of the model through a 
      detailed analysis of issues raised by exam questions. MATERIAL AND METHODS: The 
      present study utilized a PES exam consisting of 120 questions, provided by 
      Medical Exami-nations Center in Lodz. Questions were administered using 
      openai.com platform that grants free access to GPT-3.5 model. All questions were 
      categorized according to Bloom's taxonomy to assess their complexity and 
      difficulty. Following the answer to each exam question, ChatGPT was asked to rate 
      its confidence on a scale of 1 to 5 to evaluate the accuracy of its response. 
      RESULTS: ChatGPT did not reach the pass rate threshold of PES exam (52%); 
      however, it was close in certain question categories. No significant differences 
      were observed in the percentage of correct answers across question types and 
      sub-types. CONCLUSIONS: The performance of the ChatGPT model in the pass rate of 
      PES exam in radiology and imaging diagnostics in Poland is yet to be determined, 
      which requires further research on improved versions of ChatGPT.
CI  - © Pol J Radiol 2023.
FAU - Kufel, Jakub
AU  - Kufel J
AD  - Department of Biophysics, Faculty of Medical Sciences in Zabrze, Medical 
      University of Silesia, Zabrze, Poland.
FAU - Paszkiewicz, Iga
AU  - Paszkiewicz I
AD  - Tytus Chałubiński Hospital, Zakopane, Poland.
FAU - Bielówka, Michał
AU  - Bielówka M
AD  - Professor Zbigniew Religa Student Scientific Association at the Department of 
      Biophysics, Faculty of Medical Sciences in Zabrze, Medical University of Silesia, 
      Poland.
FAU - Bartnikowska, Wiktoria
AU  - Bartnikowska W
AD  - Faculty of Medical Sciences in Katowice, Medical University of Silesia, Katowice, 
      Poland.
FAU - Janik, Michał
AU  - Janik M
AD  - Professor Zbigniew Religa Student Scientific Association at the Department of 
      Biophysics, Faculty of Medical Sciences in Zabrze, Medical University of Silesia, 
      Poland.
FAU - Stencel, Magdalena
AU  - Stencel M
AD  - Professor Zbigniew Religa Student Scientific Association at the Department of 
      Biophysics, Faculty of Medical Sciences in Zabrze, Medical University of Silesia, 
      Poland.
FAU - Czogalik, Łukasz
AU  - Czogalik Ł
AD  - Professor Zbigniew Religa Student Scientific Association at the Department of 
      Biophysics, Faculty of Medical Sciences in Zabrze, Medical University of Silesia, 
      Poland.
FAU - Gruszczyńska, Katarzyna
AU  - Gruszczyńska K
AD  - Department of Radiology and Nuclear Medicine, Faculty of Medical Sciences in 
      Katowice, Medical University of Silesia, Katowice, Poland.
FAU - Mielcarska, Sylwia
AU  - Mielcarska S
AD  - Department of Medical and Molecular Biology, Faculty of Medical Sciences in 
      Zabrze, Medical University of Silesia, Zabrze, Poland.
LA  - eng
PT  - Journal Article
DEP - 20230918
PL  - Poland
TA  - Pol J Radiol
JT  - Polish journal of radiology
JID - 101175532
PMC - PMC10551734
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - deep learning
OT  - large language model
COIS- The authors report no conflict of interest.
EDAT- 2023/10/09 06:41
MHDA- 2023/10/09 06:42
PMCR- 2023/01/01
CRDT- 2023/10/09 05:32
PHST- 2023/06/06 00:00 [received]
PHST- 2023/06/07 00:00 [accepted]
PHST- 2023/10/09 06:42 [medline]
PHST- 2023/10/09 06:41 [pubmed]
PHST- 2023/10/09 05:32 [entrez]
PHST- 2023/01/01 00:00 [pmc-release]
AID - 51387 [pii]
AID - 10.5114/pjr.2023.131215 [doi]
PST - epublish
SO  - Pol J Radiol. 2023 Sep 18;88:e430-e434. doi: 10.5114/pjr.2023.131215. eCollection 
      2023.

PMID- 37314466
OWN - NLM
STAT- MEDLINE
DCOM- 20240115
LR  - 20240115
IS  - 1432-5241 (Electronic)
IS  - 0364-216X (Print)
IS  - 0364-216X (Linking)
VI  - 47
IP  - 6
DP  - 2023 Dec
TI  - Evaluation of the Artificial Intelligence Chatbot on Breast Reconstruction and 
      Its Efficacy in Surgical Research: A Case Study.
PG  - 2360-2369
LID - 10.1007/s00266-023-03443-7 [doi]
AB  - BACKGROUND: ChatGPT is an open-source artificial intelligence (AI) chatbot that 
      uses deep learning to produce human-like text dialog. Its potential applications 
      in the scientific community are vast; however, its efficacy on performing 
      comprehensive literature searches, data analysis and report writing in aesthetic 
      plastic surgery topics remains unknown. This study aims to evaluate both the 
      accuracy and comprehensiveness of ChatGPT's responses to assess its suitability 
      for use in aesthetic plastic surgery research. METHODS: Six questions were 
      prompted to ChatGPT on post-mastectomy breast reconstruction. First two questions 
      focused on the current evidence and options for breast reconstruction 
      post-mastectomy, and remaining four questions focused specifically on autologous 
      breast reconstruction. Using the Likert framework, the responses provided by 
      ChatGPT were qualitatively assessed for accuracy and information content by two 
      specialist plastic surgeons with extensive experience in the field. RESULTS: 
      ChatGPT provided relevant, accurate information; however, it lacked depth. It 
      could provide no more than a superficial overview in response to more esoteric 
      questions and generated incorrect references. It created non-existent references, 
      cited wrong journal and date, which poses a significant challenge in maintaining 
      academic integrity and caution of its use in academia. CONCLUSION: While ChatGPT 
      demonstrated proficiency in summarizing existing knowledge, it created fictitious 
      references which poses a significant concern of its use in academia and 
      healthcare. Caution should be exercised in interpreting its responses in the 
      aesthetic plastic surgical field and should only be used for such with sufficient 
      oversight. LEVEL OF EVIDENCE IV: This journal requires that authors assign a 
      level of evidence to each article. For a full description of these Evidence-Based 
      Medicine ratings, please refer to the Table of Contents or the online 
      Instructions to Authors www.springer.com/00266 .
CI  - © 2023. Crown.
FAU - Xie, Yi
AU  - Xie Y
AD  - Department of Plastic Surgery, Peninsula Health, Melbourne, Victoria, 3199, 
      Australia.
FAU - Seth, Ishith
AU  - Seth I
AUID- ORCID: 0000-0001-5444-8925
AD  - Department of Plastic Surgery, Peninsula Health, Melbourne, Victoria, 3199, 
      Australia. ishithseth1@gmail.com.
AD  - Faculty of Medicine, Monash University, Melbourne, Victoria, 3004, Australia. 
      ishithseth1@gmail.com.
FAU - Rozen, Warren M
AU  - Rozen WM
AD  - Department of Plastic Surgery, Peninsula Health, Melbourne, Victoria, 3199, 
      Australia.
AD  - Faculty of Medicine, Monash University, Melbourne, Victoria, 3004, Australia.
FAU - Hunter-Smith, David J
AU  - Hunter-Smith DJ
AD  - Department of Plastic Surgery, Peninsula Health, Melbourne, Victoria, 3199, 
      Australia.
AD  - Faculty of Medicine, Monash University, Melbourne, Victoria, 3004, Australia.
LA  - eng
PT  - Journal Article
DEP - 20230614
PL  - United States
TA  - Aesthetic Plast Surg
JT  - Aesthetic plastic surgery
JID - 7701756
SB  - IM
MH  - Humans
MH  - Female
MH  - Artificial Intelligence
MH  - *Breast Neoplasms
MH  - Mastectomy
MH  - Software
MH  - *Mammaplasty
PMC - PMC10784397
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Breast reconstruction
OT  - ChatGPT
OT  - Chatbot
COIS- The authors declare that they have no conflicts of interest to disclose.
EDAT- 2023/06/14 13:07
MHDA- 2024/01/15 12:42
PMCR- 2023/06/14
CRDT- 2023/06/14 11:05
PHST- 2023/03/06 00:00 [received]
PHST- 2023/05/27 00:00 [accepted]
PHST- 2024/01/15 12:42 [medline]
PHST- 2023/06/14 13:07 [pubmed]
PHST- 2023/06/14 11:05 [entrez]
PHST- 2023/06/14 00:00 [pmc-release]
AID - 10.1007/s00266-023-03443-7 [pii]
AID - 3443 [pii]
AID - 10.1007/s00266-023-03443-7 [doi]
PST - ppublish
SO  - Aesthetic Plast Surg. 2023 Dec;47(6):2360-2369. doi: 10.1007/s00266-023-03443-7. 
      Epub 2023 Jun 14.

PMID- 37671567
OWN - NLM
STAT- MEDLINE
DCOM- 20230925
LR  - 20231012
IS  - 1530-0374 (Electronic)
IS  - 1072-3714 (Linking)
VI  - 30
IP  - 10
DP  - 2023 Oct 1
TI  - Appropriateness of premature ovarian insufficiency recommendations provided by 
      ChatGPT.
PG  - 1033-1037
LID - 10.1097/GME.0000000000002246 [doi]
AB  - OBJECTIVE: This study aimed to evaluate the appropriateness of ChatGPT's 
      responses to frequently asked queries regarding the prevention and treatment of 
      premature ovarian insufficiency (POI). METHODS: A set of 25 questions covering 
      topics related to disease risk factors, screening, symptoms, treatment, and 
      treatment adverse effects were posed to ChatGPT, and the responses were evaluated 
      by two experienced obstetrician/gynecologists. RESULTS: Of the responses given by 
      ChatGPT, 19 of 25 (76%) were deemed appropriate, five (20%) were rated as 
      inappropriate, and the remaining one (4%) was considered unreliable. There was no 
      question that ChatGPT answered completely incorrectly; answers that were 
      considered inappropriate included partially correct information. CONCLUSIONS: The 
      study's findings suggest that ChatGPT provides patients with mostly accurate 
      information about the POI but might present significantly inaccurate information. 
      However, it is important to note that further research is needed to validate the 
      use of artificial intelligence chatbots in the context of reproductive health, 
      especially for individuals who may be highly impacted by the emotional and 
      psychological effects of POI. In addition, given the complexity and individuality 
      of medical care, AI chatbots should not be considered a replacement for medical 
      professionals but rather a supplementary tool that can help patients access 
      reliable information and support. Overall, this study contributes to the growing 
      body of research on AI chatbots and their potential use in reproductive health, 
      highlighting both the benefits and limitations of these technologies.
CI  - Copyright © 2023 by The Menopause Society.
FAU - Sütcüoğlu, Bengü Mutlu
AU  - Sütcüoğlu BM
AD  - From the Department of Obstetrics and Gynaecology, Lokman Hekim University, 
      Ankara, Turkey.
FAU - Güler, Melike
AU  - Güler M
LA  - eng
PT  - Journal Article
DEP - 20230905
PL  - United States
TA  - Menopause
JT  - Menopause (New York, N.Y.)
JID - 9433353
SB  - IM
MH  - Humans
MH  - Female
MH  - Artificial Intelligence
MH  - *Menopause, Premature
MH  - *Primary Ovarian Insufficiency/drug therapy
MH  - *Drug-Related Side Effects and Adverse Reactions
MH  - Emotions
COIS- Financial disclosure/conflicts of interest: None reported.
EDAT- 2023/09/06 06:42
MHDA- 2023/09/25 06:42
CRDT- 2023/09/06 05:26
PHST- 2023/09/25 06:42 [medline]
PHST- 2023/09/06 06:42 [pubmed]
PHST- 2023/09/06 05:26 [entrez]
AID - 00042192-202310000-00008 [pii]
AID - 10.1097/GME.0000000000002246 [doi]
PST - ppublish
SO  - Menopause. 2023 Oct 1;30(10):1033-1037. doi: 10.1097/GME.0000000000002246. Epub 
      2023 Sep 5.

PMID- 37629452
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230829
IS  - 2077-0383 (Print)
IS  - 2077-0383 (Electronic)
IS  - 2077-0383 (Linking)
VI  - 12
IP  - 16
DP  - 2023 Aug 20
TI  - Comparing Meta-Analyses with ChatGPT in the Evaluation of the Effectiveness and 
      Tolerance of Systemic Therapies in Moderate-to-Severe Plaque Psoriasis.
LID - 10.3390/jcm12165410 [doi]
LID - 5410
AB  - BACKGROUND: Meta-analyses (MAs) and network meta-analyses (NMAs) are high-quality 
      studies for assessing drug efficacy, but they are time-consuming and may be 
      affected by biases. The capacity of artificial intelligence to aggregate huge 
      amounts of information is emerging as particularly interesting for processing the 
      volume of information needed to generate MAs. In this study, we analyzed whether 
      the chatbot ChatGPT is able to summarize information in a useful fashion for 
      providers and patients in a way that matches up with the results of MAs/NMAs. 
      METHODS: We included 16 studies (13 NMAs and 3 MAs) that evaluate biologics (n = 
      6) and both biologic and systemic treatment (n = 10) for moderate-to-severe 
      psoriasis, published between January 2021 and May 2023. RESULTS: The conclusions 
      of the MAs/NMAs were compared to ChatGPT's answers to queries about the molecules 
      evaluated in the selected MAs/NMAs. The reproducibility between the results of 
      ChatGPT and the MAs/NMAs was random regarding drug safety. Regarding efficacy, 
      ChatGPT reached the same conclusion as 5 out of the 16 studies (four out of four 
      studies when three molecules were compared), gave acceptable answers in 7 out of 
      16 studies, and was inconclusive in 4 out of 16 studies. CONCLUSIONS: ChatGPT can 
      generate conclusions that are similar to MAs when the efficacy of fewer drugs is 
      compared but is still unable to summarize information in a way that matches up to 
      the results of MAs/NMAs when more than three molecules are compared.
FAU - Lam Hoai, Xuân-Lan
AU  - Lam Hoai XL
AD  - Department of Dermatology, St Pierre-Brugmann-HUDERF University Hospitals, 
      Université Libre de Bruxelles, 1050 Brussels, Belgium.
FAU - Simonart, Thierry
AU  - Simonart T
AD  - Department of Dermatology, Delta Hospital, CHIREC, Université Libre de Bruxelles, 
      1050 Brussels, Belgium.
LA  - eng
PT  - Journal Article
DEP - 20230820
PL  - Switzerland
TA  - J Clin Med
JT  - Journal of clinical medicine
JID - 101606588
PMC - PMC10455399
OTO - NOTNLM
OT  - artificial intelligence
OT  - meta-analysis
OT  - psoriasis
COIS- The authors declare no conflict of interest.
EDAT- 2023/08/26 10:43
MHDA- 2023/08/26 10:44
PMCR- 2023/08/20
CRDT- 2023/08/26 01:19
PHST- 2023/07/28 00:00 [received]
PHST- 2023/08/16 00:00 [revised]
PHST- 2023/08/17 00:00 [accepted]
PHST- 2023/08/26 10:44 [medline]
PHST- 2023/08/26 10:43 [pubmed]
PHST- 2023/08/26 01:19 [entrez]
PHST- 2023/08/20 00:00 [pmc-release]
AID - jcm12165410 [pii]
AID - jcm-12-05410 [pii]
AID - 10.3390/jcm12165410 [doi]
PST - epublish
SO  - J Clin Med. 2023 Aug 20;12(16):5410. doi: 10.3390/jcm12165410.

PMID- 37095802
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230426
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 3
DP  - 2023 Mar
TI  - Long-Term Survival of Patients With Glioblastoma of the Pineal Gland: A 
      ChatGPT-Assisted, Updated Case of a Multimodal Treatment Strategy Resulting in 
      Extremely Long Overall Survival at a Site With Historically Poor Outcomes.
PG  - e36590
LID - 10.7759/cureus.36590 [doi]
LID - e36590
AB  - We present an updated case report of a patient with glioblastoma isolated to the 
      pineal gland with an overall survival greater than five years and no progression 
      of focal central nervous system (CNS) deficits since initial presentation. The 
      patient underwent radiotherapy up to 60 Gy with concurrent and adjuvant 
      temozolomide with the use of non-standard treatment volumes that included the 
      ventricular system. The utilization of ventricular irradiation as well as the 
      addition of bevacizumab at disease recurrence may have encouraged this unusually 
      long survival by preventing/delaying leptomeningeal spread. We also present an 
      updated review of the literature, which shows a median survival of six months, 
      reinforcing the patients atypical disease trajectory. Finally, we utilize 
      OpenAI's language model ChatGPT to aid in synthesizing this manuscript. In doing 
      so, we demonstrate that ChatGPT is apt at creating concise summaries of relevant 
      literature and topic subjects, however its output is often repetitive with 
      similar sentence/paragraph structure, less than ideal grammar and poor syntax 
      requiring editing. Thus, in its current iteration, ChatGPT is a helpful aid that 
      cuts down on the time spent in data acquisition and processing but is not a 
      replacement for human input in the creation of quality medical literature.
CI  - Copyright © 2023, Cunningham et al.
FAU - Cunningham, Andrew R
AU  - Cunningham AR
AD  - Department of Radiation Oncology, Brody School of Medicine, East Carolina 
      University, Greenville, USA.
FAU - Behm, Hayley E
AU  - Behm HE
AD  - Department of Radiation Oncology, Brody School of Medicine, East Carolina 
      University, Greenville, USA.
FAU - Ju, Andrew
AU  - Ju A
AD  - Department of Radiation Oncology, Brody School of Medicine, East Carolina 
      University, Greenville, USA.
FAU - Peach, Matthew S
AU  - Peach MS
AD  - Department of Radiation Oncology, Brody School of Medicine, East Carolina 
      University, Greenville, USA.
LA  - eng
PT  - Case Reports
DEP - 20230323
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10122505
OTO - NOTNLM
OT  - bevacizumab
OT  - chatgpt
OT  - glioblastoma
OT  - leptomeningeal spread
OT  - pineal gland
OT  - radiotherapy
OT  - temozolomide
OT  - ventricular radiation
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/04/25 06:42
MHDA- 2023/04/25 06:43
PMCR- 2023/03/23
CRDT- 2023/04/25 02:04
PHST- 2023/03/23 00:00 [accepted]
PHST- 2023/04/25 06:43 [medline]
PHST- 2023/04/25 06:42 [pubmed]
PHST- 2023/04/25 02:04 [entrez]
PHST- 2023/03/23 00:00 [pmc-release]
AID - 10.7759/cureus.36590 [doi]
PST - epublish
SO  - Cureus. 2023 Mar 23;15(3):e36590. doi: 10.7759/cureus.36590. eCollection 2023 
      Mar.

PMID- 37561097
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230907
IS  - 2369-3762 (Print)
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Aug 21
TI  - Examining Real-World Medication Consultations and Drug-Herb Interactions: ChatGPT 
      Performance Evaluation.
PG  - e48433
LID - 10.2196/48433 [doi]
LID - e48433
AB  - BACKGROUND: Since OpenAI released ChatGPT, with its strong capability in handling 
      natural tasks and its user-friendly interface, it has garnered significant 
      attention. OBJECTIVE: A prospective analysis is required to evaluate the accuracy 
      and appropriateness of medication consultation responses generated by ChatGPT. 
      METHODS: A prospective cross-sectional study was conducted by the pharmacy 
      department of a medical center in Taiwan. The test data set comprised 
      retrospective medication consultation questions collected from February 1, 2023, 
      to February 28, 2023, along with common questions about drug-herb interactions. 
      Two distinct sets of questions were tested: real-world medication consultation 
      questions and common questions about interactions between traditional Chinese and 
      Western medicines. We used the conventional double-review mechanism. The 
      appropriateness of each response from ChatGPT was assessed by 2 experienced 
      pharmacists. In the event of a discrepancy between the assessments, a third 
      pharmacist stepped in to make the final decision. RESULTS: Of 293 real-world 
      medication consultation questions, a random selection of 80 was used to evaluate 
      ChatGPT's performance. ChatGPT exhibited a higher appropriateness rate in 
      responding to public medication consultation questions compared to those asked by 
      health care providers in a hospital setting (31/51, 61% vs 20/51, 39%; P=.01). 
      CONCLUSIONS: The findings from this study suggest that ChatGPT could potentially 
      be used for answering basic medication consultation questions. Our analysis of 
      the erroneous information allowed us to identify potential medical risks 
      associated with certain questions; this problem deserves our close attention.
CI  - ©Hsing-Yu Hsu, Kai-Cheng Hsu, Shih-Yen Hou, Ching-Lung Wu, Yow-Wen Hsieh, Yih-Dih 
      Cheng. Originally published in JMIR Medical Education (https://mededu.jmir.org), 
      21.08.2023.
FAU - Hsu, Hsing-Yu
AU  - Hsu HY
AUID- ORCID: 0000-0003-4424-9476
AD  - Department of Pharmacy, China Medical University Hospital, Taichung, Taiwan.
AD  - Graduate Institute of Clinical Pharmacy, College of Medicine, National Taiwan 
      University, Taipei, Taiwan.
FAU - Hsu, Kai-Cheng
AU  - Hsu KC
AUID- ORCID: 0000-0003-3640-1634
AD  - Artificial Intelligence Center, China Medical University Hospital, Taichung, 
      Taiwan.
AD  - Department of Medicine, China Medical University, Taichung, Taiwan.
FAU - Hou, Shih-Yen
AU  - Hou SY
AUID- ORCID: 0000-0002-1899-5574
AD  - Artificial Intelligence Center, China Medical University Hospital, Taichung, 
      Taiwan.
FAU - Wu, Ching-Lung
AU  - Wu CL
AD  - School of Pharmacy, College of Pharmacy, China Medical University, Taichung, 
      Taiwan.
FAU - Hsieh, Yow-Wen
AU  - Hsieh YW
AUID- ORCID: 0000-0002-0523-3482
AD  - Department of Pharmacy, China Medical University Hospital, Taichung, Taiwan.
AD  - School of Pharmacy, College of Pharmacy, China Medical University, Taichung, 
      Taiwan.
FAU - Cheng, Yih-Dih
AU  - Cheng YD
AUID- ORCID: 0000-0003-1542-6760
AD  - Department of Pharmacy, China Medical University Hospital, Taichung, Taiwan.
AD  - School of Pharmacy, College of Pharmacy, China Medical University, Taichung, 
      Taiwan.
LA  - eng
PT  - Journal Article
DEP - 20230821
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
PMC - PMC10477918
OTO - NOTNLM
OT  - ChatGPT
OT  - LLM
OT  - NLP
OT  - chat generative pre-trained transformer
OT  - drug-herb interactions
OT  - language models
OT  - large language model
OT  - natural language processing
OT  - pharmacist
OT  - real-world medication consultation questions
COIS- Conflicts of Interest: None declared.
EDAT- 2023/08/10 12:42
MHDA- 2023/08/10 12:43
PMCR- 2023/08/21
CRDT- 2023/08/10 10:43
PHST- 2023/04/24 00:00 [received]
PHST- 2023/07/25 00:00 [accepted]
PHST- 2023/06/23 00:00 [revised]
PHST- 2023/08/10 12:43 [medline]
PHST- 2023/08/10 12:42 [pubmed]
PHST- 2023/08/10 10:43 [entrez]
PHST- 2023/08/21 00:00 [pmc-release]
AID - v9i1e48433 [pii]
AID - 10.2196/48433 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Aug 21;9:e48433. doi: 10.2196/48433.

PMID- 38509629
OWN - NLM
STAT- MEDLINE
DCOM- 20240322
LR  - 20240328
IS  - 0031-7144 (Print)
IS  - 0031-7144 (Linking)
VI  - 79
IP  - 1
DP  - 2024 Feb 29
TI  - Comprehensive analysis of responses from ChatGPT to consumer inquiries regarding 
      over-the-counter medications.
PG  - 24-28
LID - 10.1691/ph.2024.3628 [doi]
AB  - Background: The use of generative artificial intelligence (AI) applications such 
      as ChatGPT is becoming increasingly popular. In Japan, consumers can purchase 
      most over-the-counter (OTC) drugs without having to consult a pharmacist, so they 
      may ask generative AI applications which OTC drugs they should purchase. This 
      study aimed to systematically evaluate responses from ChatGPT to consumer 
      inquiries about various OTC drugs. Methods: We selected 22 popular OTC drugs and 
      12 typical consumer characteristics, including physical and disease conditions 
      and concomitant medications. We input a total of 264 questions (i. e., all 
      combinations of drugs and characteristics) to ChatGPT in Japanese, asking whether 
      it is safe for consumers with each characteristic to take these OTC drugs. We 
      used the generic name for 10 of the 22 drugs and the brand name for the remaining 
      12. Responses were evaluated based on the following three criteria: 1) coherence 
      between the question and response, 2) scientific correctness, and 3) 
      appropriateness of the instructed actions. When we received a response that 
      satisfied all three criteria, we input the exact same question on a different day 
      to assess reproducibility. Results: The proportions of ChatGPT's answers that 
      satisfied criteria 1, 2, and 3 were 79.5%, 54.5%, and 49.6%, respectively. 
      However, the proportion of responses that satisfied all three criteria was only 
      20.8% (55/264); 61.8% (34/55) of these responses were reproduced when the same 
      question was input again on a different day. Compared with questions using 
      generic names, those using brand names resulted in lower coherence and scientific 
      correctness. Among the 12 characteristics, the appropriateness of the instructed 
      actions tended to be lower in responses to questions about driving and 
      concomitant medications. Conclusions: Our study revealed that ChatGPT was less 
      accurate in its responses and less consistent in its instructed actions compared 
      with the package inserts. Our findings suggest that Japanese consumers should not 
      consult ChatGPT regarding OTC medications, especially when using brand names.
FAU - Kiyomiya, K
AU  - Kiyomiya K
AD  - Division of Clinical Pharmacy , Keio University Faculty of Pharmacy; 
      Corresponding author: Keisuke Kiyomiya, Division of Clinical Pharmacy, Keio 
      University Faculty of Pharmacy, 1-5-30 Shibakoen, Minato-ku, Tokyo 105-8512, 
      Japan, Email: keisuke.kiyomiya@adst.keio.ac.jp.
FAU - Aomori, T
AU  - Aomori T
AD  - Division of Clinical Pharmacy, Keio University Faculty of Pharmacy; Department of 
      Pharmacy, Keio University Hospital.
FAU - Ohtani, H
AU  - Ohtani H
AD  - Division of Clinical Pharmacy, Keio University Faculty of Pharmacy; Department of 
      Pharmacy, Keio University Hospital; Department of Clinical Pharmacy, Keio 
      University School of Medicine, Tokyo, Japan.
LA  - eng
PT  - Journal Article
PL  - Germany
TA  - Pharmazie
JT  - Die Pharmazie
JID - 9800766
RN  - 0 (Nonprescription Drugs)
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Reproducibility of Results
MH  - Japan
MH  - *Pharmacists
MH  - Nonprescription Drugs
EDAT- 2024/03/21 06:43
MHDA- 2024/03/22 06:44
CRDT- 2024/03/21 00:54
PHST- 2024/03/22 06:44 [medline]
PHST- 2024/03/21 06:43 [pubmed]
PHST- 2024/03/21 00:54 [entrez]
AID - 10.1691/ph.2024.3628 [doi]
PST - ppublish
SO  - Pharmazie. 2024 Feb 29;79(1):24-28. doi: 10.1691/ph.2024.3628.

PMID- 37263772
OWN - NLM
STAT- Publisher
LR  - 20230601
IS  - 2047-9956 (Print)
IS  - 2047-9956 (Linking)
DP  - 2023 Jun 1
TI  - Performance and risks of ChatGPT used in drug information: an exploratory 
      real-world analysis.
LID - ejhpharm-2023-003750 [pii]
LID - 10.1136/ejhpharm-2023-003750 [doi]
AB  - OBJECTIVES: To investigate the performance and risk associated with the usage of 
      Chat Generative Pre-trained Transformer (ChatGPT) to answer drug-related 
      questions. METHODS: A sample of 50 drug-related questions were consecutively 
      collected and entered in the artificial intelligence software application 
      ChatGPT. Answers were documented and rated in a standardised consensus process by 
      six senior hospital pharmacists in the domains content (correct, incomplete, 
      false), patient management (possible, insufficient, not possible) and risk (no 
      risk, low risk, high risk). As reference, answers were researched in adherence to 
      the German guideline of drug information and stratified in four categories 
      according to the sources used. In addition, the reproducibility of ChatGPT's 
      answers was analysed by entering three questions at different timepoints 
      repeatedly (day 1, day 2, week 2, week 3). RESULTS: Overall, only 13 of 50 
      answers provided correct content and had enough information to initiate 
      management with no risk of patient harm. The majority of answers were either 
      false (38%, n=19) or had partly correct content (36%, n=18) and no references 
      were provided. A high risk of patient harm was likely in 26% (n=13) of the cases 
      and risk was judged low for 28% (n=14) of the cases. In all high-risk cases, 
      actions could have been initiated based on the provided information. The answers 
      of ChatGPT varied over time when entered repeatedly and only three out of 12 
      answers were identical, showing no reproducibility to low reproducibility. 
      CONCLUSION: In a real-world sample of 50 drug-related questions, ChatGPT answered 
      the majority of questions wrong or partly wrong. The use of artificial 
      intelligence applications in drug information is not possible as long as barriers 
      like wrong content, missing references and reproducibility remain.
CI  - © European Association of Hospital Pharmacists 2023. No commercial re-use. See 
      rights and permissions. Published by BMJ.
FAU - Morath, Benedict
AU  - Morath B
AUID- ORCID: 0000-0003-1926-0585
AD  - Hospital Pharmacy, Heidelberg University Hospital, Heidelberg, Germany 
      benedict.morath@med.uni-heidelberg.de.
FAU - Chiriac, Ute
AU  - Chiriac U
AD  - Hospital Pharmacy, Heidelberg University Hospital, Heidelberg, Germany.
FAU - Jaszkowski, Elena
AU  - Jaszkowski E
AD  - Hospital Pharmacy, Heidelberg University Hospital, Heidelberg, Germany.
FAU - Deiß, Carolin
AU  - Deiß C
AD  - Hospital Pharmacy, Heidelberg University Hospital, Heidelberg, Germany.
FAU - Nürnberg, Hannah
AU  - Nürnberg H
AD  - Hospital Pharmacy, Heidelberg University Hospital, Heidelberg, Germany.
FAU - Hörth, Katrin
AU  - Hörth K
AD  - Hospital Pharmacy, Heidelberg University Hospital, Heidelberg, Germany.
FAU - Hoppe-Tichy, Torsten
AU  - Hoppe-Tichy T
AD  - Hospital Pharmacy, Heidelberg University Hospital, Heidelberg, Germany.
FAU - Green, Kim
AU  - Green K
AD  - Hospital Pharmacy, Heidelberg University Hospital, Heidelberg, Germany.
LA  - eng
PT  - Journal Article
DEP - 20230601
PL  - England
TA  - Eur J Hosp Pharm
JT  - European journal of hospital pharmacy : science and practice
JID - 101578294
SB  - IM
OTO - NOTNLM
OT  - EVIDENCE-BASED MEDICINE
OT  - HEALTH SERVICES ADMINISTRATION
OT  - JOURNALISM, MEDICAL
OT  - Medical Informatics
OT  - PHARMACY SERVICE, HOSPITAL
COIS- Competing interests: None declared.
EDAT- 2023/06/02 01:07
MHDA- 2023/06/02 01:07
CRDT- 2023/06/01 21:38
PHST- 2023/03/02 00:00 [received]
PHST- 2023/05/09 00:00 [accepted]
PHST- 2023/06/02 01:07 [medline]
PHST- 2023/06/02 01:07 [pubmed]
PHST- 2023/06/01 21:38 [entrez]
AID - ejhpharm-2023-003750 [pii]
AID - 10.1136/ejhpharm-2023-003750 [doi]
PST - aheadofprint
SO  - Eur J Hosp Pharm. 2023 Jun 1:ejhpharm-2023-003750. doi: 
      10.1136/ejhpharm-2023-003750.

PMID- 38527444
OWN - NLM
STAT- Publisher
LR  - 20240325
IS  - 1423-0151 (Electronic)
IS  - 1011-7571 (Linking)
DP  - 2024 Mar 25
TI  - The Emerging Role of AI in Patient Education: A Comparative Analysis of LLM 
      Accuracy for Pelvic Organ Prolapse.
LID - 10.1159/000538538 [doi]
AB  - OBJECTIVE: This study aimed to evaluate the accuracy, completeness, precision, 
      and readability of outputs generated by three Large Language Models (LLMs): GPT 
      by OpenAI, BARD by Google, and Bing by Microsoft, in comparison to patient 
      education material on Pelvic Organ Prolapse (POP) provided by the Royal College 
      of Obstetricians and Gynecologists (RCOG). METHODS: A total of 15 questions were 
      retrieved from the RCOG website and input into the three LLMs. Two independent 
      reviewers evaluated the outputs for accuracy, completeness, and precision. 
      Readability was assessed using the Simplified Measure of Gobbledygook (SMOG) 
      score and the Flesch-Kincaid Grade Level (FKGL) score. RESULTS: Significant 
      differences were observed in completeness and precision metrics. ChatGPT ranked 
      highest in completeness (66.7%), while Bing led in precision (100%). No 
      significant differences were observed in accuracy across all models. In terms of 
      readability, ChatGPT exhibited higher difficulty than BARD, Bing, and the 
      original RCOG answers. CONCLUSION: While all models displayed a variable degree 
      of correctness, ChatGPT excelled in completeness, significantly surpassing BARD 
      and Bing. However, Bing led in precision, providing the most relevant and concise 
      answers. Regarding readability, ChatGPT exhibited higher difficulty. The study 
      found that while all LLMs showed varying degrees of correctness in answering RCOG 
      questions on patient information for Pelvic Organ Prolapse (POP), ChatGPT was the 
      most comprehensive, but its answers were harder to read. Bing, on the other hand, 
      was the most precise. The findings highlight the potential of LLMs in health 
      information dissemination and the need for careful interpretation of their 
      outputs.
CI  - The Author(s). Published by S. Karger AG, Basel.
FAU - Rahimli Ocakoglu, Sakine
AU  - Rahimli Ocakoglu S
FAU - Coskun, Burhan
AU  - Coskun B
LA  - eng
PT  - Journal Article
DEP - 20240325
PL  - Switzerland
TA  - Med Princ Pract
JT  - Medical principles and practice : international journal of the Kuwait University, 
      Health Science Centre
JID - 8901334
SB  - IM
EDAT- 2024/03/26 00:42
MHDA- 2024/03/26 00:42
CRDT- 2024/03/25 19:27
PHST- 2023/11/06 00:00 [received]
PHST- 2024/03/21 00:00 [accepted]
PHST- 2024/03/26 00:42 [medline]
PHST- 2024/03/26 00:42 [pubmed]
PHST- 2024/03/25 19:27 [entrez]
AID - 000538538 [pii]
AID - 10.1159/000538538 [doi]
PST - aheadofprint
SO  - Med Princ Pract. 2024 Mar 25. doi: 10.1159/000538538.

PMID- 37891086
OWN - NLM
STAT- MEDLINE
DCOM- 20240305
LR  - 20240305
IS  - 1535-6302 (Electronic)
IS  - 0363-0188 (Linking)
VI  - 53
IP  - 2
DP  - 2024 Mar-Apr
TI  - Assessing appropriate responses to ACR urologic imaging scenarios using ChatGPT 
      and Bard.
PG  - 226-229
LID - S0363-0188(23)00175-5 [pii]
LID - 10.1067/j.cpradiol.2023.10.022 [doi]
AB  - Artificial intelligence (AI) has recently become a trending tool and topic 
      regarding productivity especially with publicly available free services such as 
      ChatGPT and Bard. In this report, we investigate if two widely available chatbots 
      chatGPT and Bard, are able to show consistent accurate responses for the best 
      imaging modality for urologic clinical situations and if they are in line with 
      American College of Radiology (ACR) Appropriateness Criteria (AC). All clinical 
      scenarios provided by the ACR were inputted into ChatGPT and Bard with result 
      compared to the ACR AC and recorded. Both chatbots had an appropriate imaging 
      modality rate of of 62% and no significant difference in proportion of correct 
      imaging modality was found overall between the two services (p&gt;0.05). The results 
      of our study found that both ChatGPT and Bard are similar in their ability to 
      suggest the most appropriate imaging modality in a variety of urologic scenarios 
      based on ACR AC criteria. Nonetheless, both chatbots lack consistent accuracy and 
      further development is necessary for implementation in clinical settings. For 
      proper use of these AI services in clinical decision making, further developments 
      are needed to improve the workflow of physicians.
CI  - Copyright © 2023 Elsevier Inc. All rights reserved.
FAU - Doddi, Sishir
AU  - Doddi S
AD  - University of Toledo College of Medicine, Toledo, OH, United States. Electronic 
      address: sishir.doddi@utoledo.edu.
FAU - Hibshman, Taryn
AU  - Hibshman T
AD  - University of Toledo College of Medicine, Toledo, OH, United States.
FAU - Salichs, Oscar
AU  - Salichs O
AD  - University of Toledo College of Medicine, Toledo, OH, United States.
FAU - Bera, Kaustav
AU  - Bera K
AD  - Department of Radiology, University Hospitals Cleveland Medical Center, 
      Cleveland, OH.
FAU - Tippareddy, Charit
AU  - Tippareddy C
AD  - Department of Radiology, University Hospitals Cleveland Medical Center, 
      Cleveland, OH.
FAU - Ramaiya, Nikhil
AU  - Ramaiya N
AD  - Department of Radiology, University Hospitals Cleveland Medical Center, 
      Cleveland, OH.
FAU - Tirumani, Sree Harsha
AU  - Tirumani SH
AD  - Department of Radiology, University Hospitals Cleveland Medical Center, 
      Cleveland, OH.
LA  - eng
PT  - Journal Article
DEP - 20231020
PL  - United States
TA  - Curr Probl Diagn Radiol
JT  - Current problems in diagnostic radiology
JID - 7607123
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Diagnostic Imaging
MH  - Health Services Accessibility
MH  - *Physicians
MH  - Workflow
EDAT- 2023/10/28 11:42
MHDA- 2024/03/05 06:47
CRDT- 2023/10/27 22:57
PHST- 2023/10/04 00:00 [received]
PHST- 2023/10/18 00:00 [revised]
PHST- 2023/10/18 00:00 [accepted]
PHST- 2024/03/05 06:47 [medline]
PHST- 2023/10/28 11:42 [pubmed]
PHST- 2023/10/27 22:57 [entrez]
AID - S0363-0188(23)00175-5 [pii]
AID - 10.1067/j.cpradiol.2023.10.022 [doi]
PST - ppublish
SO  - Curr Probl Diagn Radiol. 2024 Mar-Apr;53(2):226-229. doi: 
      10.1067/j.cpradiol.2023.10.022. Epub 2023 Oct 20.

PMID- 37521206
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230801
IS  - 2229-5178 (Print)
IS  - 2249-5673 (Electronic)
IS  - 2229-5178 (Linking)
VI  - 14
IP  - 4
DP  - 2023 Jul-Aug
TI  - ChatGPT- Quo Vadis?
PG  - 457-458
LID - 10.4103/idoj.idoj_344_23 [doi]
FAU - Kaliyadan, Feroze
AU  - Kaliyadan F
AD  - Department of Dermatology, Sree Narayana Institute of Medical Sciences, 
      Ernakulam, Kerala, India.
FAU - Seetharam, K A
AU  - Seetharam KA
AD  - Department of Dermatology, Venereology and Leprosy, GSL Medical College, 
      Rajahmundry, Andhra Pradesh, India.
LA  - eng
PT  - Editorial
DEP - 20230628
PL  - India
TA  - Indian Dermatol Online J
JT  - Indian dermatology online journal
JID - 101586880
PMC - PMC10373833
EDAT- 2023/07/31 06:42
MHDA- 2023/07/31 06:43
PMCR- 2023/06/28
CRDT- 2023/07/31 05:04
PHST- 2023/05/02 00:00 [received]
PHST- 2023/05/10 00:00 [revised]
PHST- 2023/05/10 00:00 [accepted]
PHST- 2023/07/31 06:43 [medline]
PHST- 2023/07/31 06:42 [pubmed]
PHST- 2023/07/31 05:04 [entrez]
PHST- 2023/06/28 00:00 [pmc-release]
AID - IDOJ-14-457 [pii]
AID - 10.4103/idoj.idoj_344_23 [doi]
PST - epublish
SO  - Indian Dermatol Online J. 2023 Jun 28;14(4):457-458. doi: 
      10.4103/idoj.idoj_344_23. eCollection 2023 Jul-Aug.

PMID- 38046759
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231205
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 11
DP  - 2023 Nov
TI  - AI-Generated Information for Vascular Patients: Assessing the Standard of 
      Procedure-Specific Information Provided by the ChatGPT AI-Language Model.
PG  - e49764
LID - 10.7759/cureus.49764 [doi]
LID - e49764
AB  - Introduction Ensuring access to high-quality information is paramount to 
      facilitating informed surgical decision-making. The use of the internet to access 
      health-related information is increasing, along with the growing prevalence of AI 
      language models such as ChatGPT. We aim to assess the standard of AI-generated 
      patient-facing information through a qualitative analysis of its readability and 
      quality. Materials and methods We performed a retrospective qualitative analysis 
      of information regarding three common vascular procedures: endovascular aortic 
      repair (EVAR), endovenous laser ablation (EVLA), and femoro-popliteal bypass 
      (FPBP). The ChatGPT responses were compared to patient information leaflets 
      provided by the vascular charity, Circulation Foundation UK. Readability was 
      assessed using four readability scores: the Flesch-Kincaid reading ease (FKRE) 
      score, the Flesch-Kincaid grade level (FKGL), the Gunning fog score (GFS), and 
      the simple measure of gobbledygook (SMOG) index. Quality was assessed using the 
      DISCERN tool by two independent assessors. Results The mean FKRE score was 33.3, 
      compared to 59.1 for the information provided by the Circulation Foundation 
      (SD=14.5, p=0.025) indicating poor readability of AI-generated information. The 
      FFKGL indicated that the expected grade of students likely to read and understand 
      ChatGPT responses was consistently higher than compared to information leaflets 
      at 12.7 vs. 9.4 (SD=1.9, p=0.002). Two metrics measure readability in terms of 
      the number of years of education required to understand a piece of writing: the 
      GFS and SMOG. Both scores indicated that AI-generated answers were less 
      accessible. The GFS for ChatGPT-provided information was 16.7 years versus 12.8 
      years for the leaflets (SD=2.2, p=0.002) and the SMOG index scores were 12.2 and 
      9.4 years for ChatGPT and the patient information leaflets, respectively (SD=1.7, 
      p=0.001). The DISCERN scores were consistently higher in human-generated patient 
      information leaflets compared to AI-generated information across all procedures; 
      the mean score for the information provided by ChatGPT was 50.3 vs. 56.0 for the 
      Circulation Foundation information leaflets (SD=3.38, p&lt;0.001). Conclusion We 
      concluded that AI-generated information about vascular surgical procedures is 
      currently poor in both the readability of text and the quality of information. 
      Patients should be directed to reputable, human-generated information sources 
      from trusted professional bodies to supplement direct education from the 
      clinician during the pre-procedure consultation process.
CI  - Copyright © 2023, Haidar et al.
FAU - Haidar, Omar
AU  - Haidar O
AD  - Vascular Surgery, Lister Hospital, Stevenage, GBR.
FAU - Jaques, Alexander
AU  - Jaques A
AD  - Vascular Surgery, Lister Hospital, Stevenage, GBR.
FAU - McCaughran, Pierre W
AU  - McCaughran PW
AD  - Vascular Surgery, Lister Hospital, Stevenage, GBR.
FAU - Metcalfe, Matthew J
AU  - Metcalfe MJ
AD  - Vascular Surgery, Lister Hospital, Stevenage, GBR.
LA  - eng
PT  - Journal Article
DEP - 20231130
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10691169
OTO - NOTNLM
OT  - ai
OT  - artificial intelligence
OT  - chatgpt
OT  - patient education
OT  - vascular
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/12/04 06:42
MHDA- 2023/12/04 06:43
PMCR- 2023/11/30
CRDT- 2023/12/04 05:08
PHST- 2023/11/30 00:00 [accepted]
PHST- 2023/12/04 06:43 [medline]
PHST- 2023/12/04 06:42 [pubmed]
PHST- 2023/12/04 05:08 [entrez]
PHST- 2023/11/30 00:00 [pmc-release]
AID - 10.7759/cureus.49764 [doi]
PST - epublish
SO  - Cureus. 2023 Nov 30;15(11):e49764. doi: 10.7759/cureus.49764. eCollection 2023 
      Nov.

PMID- 37528607
OWN - NLM
STAT- MEDLINE
DCOM- 20240315
LR  - 20240315
IS  - 2042-1818 (Electronic)
IS  - 0025-8024 (Linking)
VI  - 64
IP  - 2
DP  - 2024 Apr
TI  - ChatGPT: Forensic, legal, and ethical issues.
PG  - 150-156
LID - 10.1177/00258024231191829 [doi]
AB  - Artificial intelligence (AI) refers to a group of technologies that enable people 
      to perform a variety of activities, including observing, comprehending, analysing 
      and translating data, among other things. Nowadays, practically every school of 
      thought is interested in AI. One such innovation, a chatbot by the name of 
      ChatGPT (Chat Generative Pre-Trained Transformer), launched by OpenAI recently, 
      has taken the internet by storm. It had one million users within 1 week of its 
      launch. The present communication explores the practicability and versatility of 
      the ChatGPT in forensic examinations and scenarios, and also addresses the 
      ethical and legal issues surrounding its usage. The observations suggest that the 
      said technology, in its current form, has limited relevance in the realm of 
      forensic science and the law. Only human critical thinking, expertise, and 
      practical experience can provide the information and competencies needed in the 
      realms of forensics, research, clinical and legal practices. Thus, the ChatGPT 
      should be used with utmost caution in the disciplines of medicine, forensic 
      science and the law, irrespective of its many positive attributes.
FAU - Guleria, Ankita
AU  - Guleria A
AD  - Department of Anthropology, Panjab University, Chandigarh, India. RINGGOLD: 29750
FAU - Krishan, Kewal
AU  - Krishan K
AUID- ORCID: 0000-0001-5321-0958
AD  - Department of Anthropology, Panjab University, Chandigarh, India. RINGGOLD: 29750
FAU - Sharma, Vishal
AU  - Sharma V
AD  - Institute of Forensic Science and Criminology, Panjab University, Chandigarh, 
      India. RINGGOLD: 29750
FAU - Kanchan, Tanuj
AU  - Kanchan T
AUID- ORCID: 0000-0003-0346-1075
AD  - Department of Forensic Medicine and Toxicology, All India Institute of Medical 
      Sciences, Jodhpur, India.
LA  - eng
PT  - Journal Article
DEP - 20230801
PL  - England
TA  - Med Sci Law
JT  - Medicine, science, and the law
JID - 0400721
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Forensic Medicine
MH  - Forensic Sciences
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - crime investigation
OT  - ethics
OT  - forensic science
OT  - law
COIS- Declaration of conflicting interestsThe author(s) declare that there is no 
      conflict of interest regarding this manuscript.
EDAT- 2023/08/02 06:43
MHDA- 2024/03/15 06:44
CRDT- 2023/08/02 01:53
PHST- 2024/03/15 06:44 [medline]
PHST- 2023/08/02 06:43 [pubmed]
PHST- 2023/08/02 01:53 [entrez]
AID - 10.1177/00258024231191829 [doi]
PST - ppublish
SO  - Med Sci Law. 2024 Apr;64(2):150-156. doi: 10.1177/00258024231191829. Epub 2023 
      Aug 1.

PMID- 36789422
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230727
DP  - 2023 Jan 28
TI  - Analysis of large-language model versus human performance for genetics questions.
LID - 2023.01.27.23285115 [pii]
LID - 10.1101/2023.01.27.23285115 [doi]
AB  - Large-language models like ChatGPT have recently received a great deal of 
      attention. To assess ChatGPT in the field of genetics, we compared its 
      performance to human respondents in answering genetics questions (involving 
      13,636 responses) that had been posted on social media platforms starting in 
      2021. Overall, ChatGPT did not perform significantly differently than human 
      respondents, but did significantly better on memorization-type questions versus 
      critical thinking questions, frequently provided different answers when asked 
      questions multiple times, and provided plausible explanations for both correct 
      and incorrect answers.
FAU - Duong, Dat
AU  - Duong D
FAU - Solomon, Benjamin D
AU  - Solomon BD
LA  - eng
PT  - Preprint
DEP - 20230128
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
UIN - Eur J Hum Genet. 2023 May 29;:. PMID: 37246194
PMC - PMC9928145
EDAT- 2023/02/16 06:00
MHDA- 2023/02/16 06:01
PMCR- 2023/02/14
CRDT- 2023/02/15 02:13
PHST- 2023/02/15 02:13 [entrez]
PHST- 2023/02/16 06:00 [pubmed]
PHST- 2023/02/16 06:01 [medline]
PHST- 2023/02/14 00:00 [pmc-release]
AID - 2023.01.27.23285115 [pii]
AID - 10.1101/2023.01.27.23285115 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2023 Jan 28:2023.01.27.23285115. doi: 
      10.1101/2023.01.27.23285115.

PMID- 37256656
OWN - NLM
STAT- MEDLINE
DCOM- 20230602
LR  - 20230707
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 25
DP  - 2023 May 31
TI  - Open Science and Software Assistance: Commentary on "Artificial Intelligence Can 
      Generate Fraudulent but Authentic-Looking Scientific Medical Articles: Pandora's 
      Box Has Been Opened".
PG  - e49323
LID - 10.2196/49323 [doi]
LID - e49323
AB  - Májovský and colleagues have investigated the important issue of ChatGPT being 
      used for the complete generation of scientific works, including fake data and 
      tables. The issues behind why ChatGPT poses a significant concern to research 
      reach far beyond the model itself. Once again, the lack of reproducibility and 
      visibility of scientific works creates an environment where fraudulent or 
      inaccurate work can thrive. What are some of the ways in which we can handle this 
      new situation?
CI  - ©Pedro L Ballester. Originally published in the Journal of Medical Internet 
      Research (https://www.jmir.org), 31.05.2023.
FAU - Ballester, Pedro L
AU  - Ballester PL
AUID- ORCID: 0000-0001-9928-2527
AD  - Neuroscience Graduate Program, McMaster University, Hamilton, ON, Canada.
LA  - eng
PT  - Comment
PT  - Journal Article
DEP - 20230531
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
CON - J Med Internet Res. 2023 May 31;25:e46924. PMID: 37256685
MH  - Humans
MH  - *Artificial Intelligence
MH  - Reproducibility of Results
MH  - *Software
PMC - PMC10267777
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - artificial intelligence
OT  - open science
OT  - reproducibility
OT  - software assistance
COIS- Conflicts of Interest: None declared.
EDAT- 2023/05/31 13:11
MHDA- 2023/06/02 06:42
PMCR- 2023/05/31
CRDT- 2023/05/31 11:53
PHST- 2023/05/24 00:00 [received]
PHST- 2023/05/24 00:00 [accepted]
PHST- 2023/06/02 06:42 [medline]
PHST- 2023/05/31 13:11 [pubmed]
PHST- 2023/05/31 11:53 [entrez]
PHST- 2023/05/31 00:00 [pmc-release]
AID - v25i1e49323 [pii]
AID - 10.2196/49323 [doi]
PST - epublish
SO  - J Med Internet Res. 2023 May 31;25:e49323. doi: 10.2196/49323.

PMID- 37075729
OWN - NLM
STAT- MEDLINE
DCOM- 20230421
LR  - 20230421
IS  - 2158-1797 (Electronic)
IS  - 1548-8578 (Linking)
VI  - 44
IP  - 4
DP  - 2023 Apr
TI  - ChatGPT: Chances and Challenges for Dentistry.
PG  - 220-224
AB  - The artificial intelligence (AI) chatbot ChatGPT has generated both huge interest 
      and deep concern since its launch in November 2022.1 ChatGPT, a large language 
      model (LLM) with a conversational interface, has been trained on vast amounts of 
      human-generated text and has the ability to respond to questions and complete 
      various text-related tasks. The use of ChatGPT and similar LLMs in dentistry is 
      unlikely to significantly impact the daily routine of most dental healthcare 
      personnel but could streamline administrative workflows and potentially serve as 
      an additional tool for clinical decision support in the future. However, this is 
      contingent on the availability of comprehensive, up-to-date, and unbiased data. 
      The use of LLMs also causes privacy and cybersecurity concerns. It is therefore 
      crucial to implement robust data protection measures and strong defenses against 
      malicious use of LLMs. Although ChatGPT provides succinct answers to most 
      queries, its lack of reliability, transparency, and up-to-date knowledge compared 
      with conventional search engines is a major drawback, particularly for 
      health-related queries.
FAU - Eggmann, Florin
AU  - Eggmann F
AD  - Research Fellow, Department of Preventive and Restorative Sciences, Robert 
      Schattner Center, University of Pennsylvania School of Dental Medicine, 
      Philadelphia, Pennsylvania; Lecturer, Department of Periodontology, 
      Endodontology, and Cariology, University Center for Dental Medicine Basel UZB, 
      University of Basel, Basel, Switzerland.
FAU - Blatz, Markus B
AU  - Blatz MB
AD  - Professor of Restorative Dentistry, Chair, Department of Preventive and 
      Restorative Sciences, Robert Schattner Center, and Assistant Dean, Digital 
      Innovation and Professional Development, University of Pennsylvania School of 
      Dental Medicine, Philadelphia, Pennsylvania.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Compend Contin Educ Dent
JT  - Compendium of continuing education in dentistry (Jamesburg, N.J. : 1995)
JID - 9600713
MH  - Humans
MH  - *Artificial Intelligence
MH  - Reproducibility of Results
MH  - *Health Personnel
MH  - Software
MH  - Dentistry
EDAT- 2023/04/20 00:41
MHDA- 2023/04/21 06:41
CRDT- 2023/04/19 18:23
PHST- 2023/04/21 06:41 [medline]
PHST- 2023/04/20 00:41 [pubmed]
PHST- 2023/04/19 18:23 [entrez]
PST - ppublish
SO  - Compend Contin Educ Dent. 2023 Apr;44(4):220-224.

PMID- 37724135
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231102
IS  - 1179-1578 (Print)
IS  - 1179-1578 (Electronic)
IS  - 1179-1578 (Linking)
VI  - 16
DP  - 2023
TI  - A Cogitation on the ChatGPT Craze from the Perspective of Psychological Algorithm 
      Aversion and Appreciation.
PG  - 3837-3844
LID - 10.2147/PRBM.S430936 [doi]
AB  - In recent times, ChatGPT has garnered significant interest from the public, 
      sparking a range of reactions that encompass both aversion and appreciation. This 
      paper delves into the paradoxical attitudes of individuals towards ChatGPT, 
      highlighting the simultaneous existence of algorithmic aversion and appreciation. 
      A comprehensive analysis is conducted from the vantage points of psychology and 
      algorithmic decision-making, exploring the underlying causes of these conflicting 
      attitudes from three dimensions: self-performance, task types, and individual 
      factors. Subsequently, strategies to reconcile these opposing psychological 
      stances are proposed, delineated into two categories: flexible coping and 
      inflexible coping. In light of the ongoing advancements in artificial 
      intelligence, this paper posits recommendations for the attitudes and actions 
      that individuals ought to adopt in the face of artificial intelligence. 
      Regardless of whether one exhibits algorithm aversion or appreciation, the paper 
      underscores that coexisting with algorithms is an inescapable reality in the age 
      of artificial intelligence, necessitating the preservation of human advantages.
CI  - © 2023 Yu.
FAU - Yu, Hao
AU  - Yu H
AUID- ORCID: 0009-0002-5223-4055
AD  - Faculty of Education, Shaanxi Normal University, Xi'an, Shaanxi, People's 
      Republic of China.
LA  - eng
PT  - Journal Article
DEP - 20230913
PL  - New Zealand
TA  - Psychol Res Behav Manag
JT  - Psychology research and behavior management
JID - 101514563
PMC - PMC10505389
OTO - NOTNLM
OT  - ChatGPT
OT  - algorithm appreciation
OT  - algorithm aversion
OT  - algorithmic decision-making
OT  - artificial intelligence
OT  - contradictory psychology
COIS- The author reports no conflicts of interest in this work.
EDAT- 2023/09/19 12:42
MHDA- 2023/09/19 12:43
PMCR- 2023/09/13
CRDT- 2023/09/19 03:38
PHST- 2023/07/17 00:00 [received]
PHST- 2023/09/08 00:00 [accepted]
PHST- 2023/09/19 12:43 [medline]
PHST- 2023/09/19 12:42 [pubmed]
PHST- 2023/09/19 03:38 [entrez]
PHST- 2023/09/13 00:00 [pmc-release]
AID - 430936 [pii]
AID - 10.2147/PRBM.S430936 [doi]
PST - epublish
SO  - Psychol Res Behav Manag. 2023 Sep 13;16:3837-3844. doi: 10.2147/PRBM.S430936. 
      eCollection 2023.

PMID- 37469634
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230721
IS  - 2477-4073 (Electronic)
IS  - 2528-181X (Print)
IS  - 2477-4073 (Linking)
VI  - 9
IP  - 1
DP  - 2023
TI  - Exploring the future of nursing: Insights from the ChatGPT model.
PG  - 1-5
LID - 10.33546/bnj.2551 [doi]
AB  - This editorial aims to provide a comprehensive overview of the future of nursing 
      through the lens of the ChatGPT model, a state-of-the-art language processing 
      artificial intelligence (AI) developed by OpenAI. The edited chat transcripts 
      with ChatGPT may offer key trends and developments in nursing, such as the 
      increasing use of technology and digital tools, the integration of AI, and the 
      use of robotics in patient care, as well as insights into the implications of 
      these changes for nurses, patients, and the healthcare system as a whole. 
      However, the future of nursing is continuously evolving. Therefore, nurses need 
      to keep abreast of the latest developments and adapt to them while remaining 
      committed to providing quality care.
CI  - © The Author(s) 2023.
FAU - Gunawan, Joko
AU  - Gunawan J
AUID- ORCID: 0000-0001-6694-8679
AD  - Belitung Raya Foundation, Manggar, East Belitung, Bangka Belitung, Indonesia.
LA  - eng
PT  - Editorial
DEP - 20230212
PL  - Indonesia
TA  - Belitung Nurs J
JT  - Belitung nursing journal
JID - 101685037
PMC - PMC10353608
OTO - NOTNLM
OT  - ChatGPT
OT  - OpenAI
OT  - artificial intelligence
OT  - future of nursing
OT  - robotics
OT  - state-of-the-art language processing
COIS- None.
EDAT- 2023/07/20 06:42
MHDA- 2023/07/20 06:43
PMCR- 2023/02/12
CRDT- 2023/07/20 04:01
PHST- 2023/01/19 00:00 [received]
PHST- 2023/01/20 00:00 [revised]
PHST- 2023/01/20 00:00 [accepted]
PHST- 2023/07/20 06:43 [medline]
PHST- 2023/07/20 06:42 [pubmed]
PHST- 2023/07/20 04:01 [entrez]
PHST- 2023/02/12 00:00 [pmc-release]
AID - BNJ-9-1-001 [pii]
AID - 10.33546/bnj.2551 [doi]
PST - epublish
SO  - Belitung Nurs J. 2023 Feb 12;9(1):1-5. doi: 10.33546/bnj.2551. eCollection 2023.

PMID- 37347508
OWN - NLM
STAT- MEDLINE
DCOM- 20230626
LR  - 20231124
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 25
DP  - 2023 Jun 22
TI  - The ChatGPT (Generative Artificial Intelligence) Revolution Has Made Artificial 
      Intelligence Approachable for Medical Professionals.
PG  - e48392
LID - 10.2196/48392 [doi]
LID - e48392
AB  - In November 2022, OpenAI publicly launched its large language model (LLM), 
      ChatGPT, and reached the milestone of having over 100 million users in only 2 
      months. LLMs have been shown to be useful in a myriad of health care-related 
      tasks and processes. In this paper, I argue that attention to, public access to, 
      and debate about LLMs have initiated a wave of products and services using 
      generative artificial intelligence (AI), which had previously found it hard to 
      attract physicians. This paper describes what AI tools have become available 
      since the beginning of the ChatGPT revolution and contemplates how it they might 
      change physicians' perceptions about this breakthrough technology.
CI  - ©Bertalan Mesko. Originally published in the Journal of Medical Internet Research 
      (https://www.jmir.org), 22.06.2023.
FAU - Mesko, Bertalan
AU  - Mesko B
AUID- ORCID: 0000-0002-7005-7083
AD  - The Medical Futurist Institute, Budapest, Hungary.
AD  - Department of Behavioural Sciences, Semmelweis University, Budapest, Hungary.
LA  - eng
PT  - Journal Article
DEP - 20230622
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Language
MH  - *Physicians
MH  - Technology
PMC - PMC10337400
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - chatbot
OT  - computer generated
OT  - continuing education
OT  - conversation agents
OT  - conversational agent
OT  - curricula
OT  - curriculum
OT  - digital health
OT  - future
OT  - generated text
OT  - generative
OT  - language model
OT  - large language model
OT  - medical education
OT  - medical practice
OT  - professional development
OT  - technology
COIS- Conflicts of Interest: None declared.
EDAT- 2023/06/22 13:09
MHDA- 2023/06/26 06:41
PMCR- 2023/06/22
CRDT- 2023/06/22 11:52
PHST- 2023/04/21 00:00 [received]
PHST- 2023/06/07 00:00 [accepted]
PHST- 2023/06/02 00:00 [revised]
PHST- 2023/06/26 06:41 [medline]
PHST- 2023/06/22 13:09 [pubmed]
PHST- 2023/06/22 11:52 [entrez]
PHST- 2023/06/22 00:00 [pmc-release]
AID - v25i1e48392 [pii]
AID - 10.2196/48392 [doi]
PST - epublish
SO  - J Med Internet Res. 2023 Jun 22;25:e48392. doi: 10.2196/48392.

PMID- 38490569
OWN - NLM
STAT- Publisher
LR  - 20240315
IS  - 1532-8406 (Electronic)
IS  - 0883-5403 (Linking)
DP  - 2024 Mar 13
TI  - Use and Application of Large Language Models for Patient Questions following 
      Total Knee Arthroplasty.
LID - S0883-5403(24)00233-X [pii]
LID - 10.1016/j.arth.2024.03.017 [doi]
AB  - INTRODUCTION: A consumer-focused health care model not only allows unprecedented 
      access to information, but equally warrants consideration of the appropriateness 
      of providing accurate patient health information. Nurses play a large role in 
      influencing patient satisfaction following total knee arthroplasty (TKA), but 
      they come at a cost. A specific natural language artificial intelligence (AI) 
      model, ChatGPT (Generative Pretrained Transformer), has accumulated over 100 
      million users within months of launching. As such, we aimed to compare: 1) 
      orthopaedic surgeons' evaluation of the appropriateness of the answers to the 
      most frequently asked patient questions after TKA; and 2) patients' comfort level 
      in answering their postoperative questions by using answers provided by 
      arthroplasty-trained nurses and ChatGPT. METHODS: We prospectively created 60 
      questions based on the most commonly asked patient questions following TKA. There 
      were three fellowship-trained surgeons who assessed the answers provided by 
      arthroplasty-trained nurses and ChatGPT-4 to each of the questions. The surgeons 
      graded each set of responses based on clinical judgment as: 1) "appropriate," 2) 
      "inappropriate" if the response contained inappropriate information, or 3) 
      "unreliable," if the responses provided inconsistent content. Patients' comfort 
      level and trust in AI were assessed using research electronic data capture 
      (REDCap) hosted at our local hospital. RESULTS: The surgeons graded 44 out of 60 
      (73.3%) responses for the arthroplasty-trained nurses and 44 out of 60 (73.3%) 
      for ChatGPT to be "appropriate." There were four responses graded "inappropriate" 
      and one response graded "unreliable" provided by the nurses. For the ChatGPT 
      response, there were five responses graded "inappropriate" and no responses 
      graded "unreliable." There were 136 patients (53.8%) who were more comfortable 
      with the answers provided by ChatGPT compared to 86 patients (34.0%) who 
      preferred the answers from arthroplasty-trained nurses. Of the 253 patients, 233 
      (92.1%) were uncertain if they would trust AI to answer their postoperative 
      questions. There were 127 patients (50.2%) who answered that if they knew the 
      previous answer was provided by ChatGPT, their comfort level in trusting the 
      answer would change. CONCLUSION: One potential use of ChatGPT can be found in 
      providing appropriate answers to patient questions after TKA. At our institution, 
      cost expenditures can potentially be minimized while maintaining patient 
      satisfaction. Inevitably, successful implementation is dependent on the ability 
      to provide information that is credible and in accordance with the objectives of 
      both physicians and patients.
CI  - Copyright © 2024. Published by Elsevier Inc.
FAU - Bains, Sandeep S
AU  - Bains SS
AD  - LifeBridge Health, Sinai Hospital of Baltimore, Rubin Institute for Advanced 
      Orthopedics, Baltimore, MD.
FAU - Dubin, Jeremy A
AU  - Dubin JA
AD  - LifeBridge Health, Sinai Hospital of Baltimore, Rubin Institute for Advanced 
      Orthopedics, Baltimore, MD.
FAU - Hameed, Daniel
AU  - Hameed D
AD  - LifeBridge Health, Sinai Hospital of Baltimore, Rubin Institute for Advanced 
      Orthopedics, Baltimore, MD.
FAU - Sax, Oliver C
AU  - Sax OC
AD  - LifeBridge Health, Sinai Hospital of Baltimore, Rubin Institute for Advanced 
      Orthopedics, Baltimore, MD.
FAU - Douglas, Scott
AU  - Douglas S
AD  - LifeBridge Health, Sinai Hospital of Baltimore, Rubin Institute for Advanced 
      Orthopedics, Baltimore, MD.
FAU - Mont, Michael
AU  - Mont M
AD  - LifeBridge Health, Sinai Hospital of Baltimore, Rubin Institute for Advanced 
      Orthopedics, Baltimore, MD.
FAU - Nace, James
AU  - Nace J
AD  - LifeBridge Health, Sinai Hospital of Baltimore, Rubin Institute for Advanced 
      Orthopedics, Baltimore, MD.
FAU - Delanois, Ronald E
AU  - Delanois RE
AD  - LifeBridge Health, Sinai Hospital of Baltimore, Rubin Institute for Advanced 
      Orthopedics, Baltimore, MD. Electronic address: delanois@me.com.
LA  - eng
PT  - Journal Article
DEP - 20240313
PL  - United States
TA  - J Arthroplasty
JT  - The Journal of arthroplasty
JID - 8703515
SB  - IM
EDAT- 2024/03/16 05:42
MHDA- 2024/03/16 05:42
CRDT- 2024/03/15 20:32
PHST- 2023/12/15 00:00 [received]
PHST- 2024/03/06 00:00 [revised]
PHST- 2024/03/07 00:00 [accepted]
PHST- 2024/03/16 05:42 [medline]
PHST- 2024/03/16 05:42 [pubmed]
PHST- 2024/03/15 20:32 [entrez]
AID - S0883-5403(24)00233-X [pii]
AID - 10.1016/j.arth.2024.03.017 [doi]
PST - aheadofprint
SO  - J Arthroplasty. 2024 Mar 13:S0883-5403(24)00233-X. doi: 
      10.1016/j.arth.2024.03.017.

PMID- 38453462
OWN - NLM
STAT- Publisher
LR  - 20240307
IS  - 1759-8486 (Electronic)
IS  - 1759-8478 (Linking)
DP  - 2024 Mar 7
TI  - Exploring the use of ChatGPT in predicting anterior circulation stroke functional 
      outcomes after mechanical thrombectomy: a pilot study.
LID - jnis-2024-021556 [pii]
LID - 10.1136/jnis-2024-021556 [doi]
AB  - BACKGROUND: Accurate prediction of functional outcomes is crucial in stroke 
      management, but this remains challenging. OBJECTIVE: To evaluate the performance 
      of the generative language model ChatGPT in predicting the functional outcome of 
      patients with acute ischemic stroke (AIS) 3 months after mechanical thrombectomy 
      (MT) in order to assess whether ChatGPT can used to be accurately predict the 
      modified Rankin Scale (mRS) score at 3 months post-thrombectomy. METHODS: We 
      conducted a retrospective analysis of clinical, neuroimaging, and 
      procedure-related data from 163 patients with AIS undergoing MT. The agreement 
      between ChatGPT's exact and dichotomized predictions and actual mRS scores was 
      assessed using Cohen's κ. The added value of ChatGPT was measured by evaluating 
      the agreement of predicted dichotomized outcomes using an existing validated 
      score, the MT-DRAGON. RESULTS: ChatGPT demonstrated fair (κ=0.354, 95% CI 0.260 
      to 0.448) and good (κ=0.727, 95% CI 0.620 to 0.833) agreement with the true exact 
      and dichotomized mRS scores at 3 months, respectively, outperforming MT-DRAGON in 
      overall and subgroup predictions. ChatGPT agreement was higher for patients with 
      shorter last-time-seen-well-to-door delay, distal occlusions, and better modified 
      Thrombolysis in Cerebral Infarction scores. CONCLUSIONS: ChatGPT adequately 
      predicted short-term functional outcomes in post-thrombectomy patients with AIS 
      and was better than the existing risk score. Integrating AI models into clinical 
      practice holds promise for patient care, yet refining these models is crucial for 
      enhanced accuracy in stroke management.
CI  - © Author(s) (or their employer(s)) 2024. No commercial re-use. See rights and 
      permissions. Published by BMJ.
FAU - Pedro, Tiago
AU  - Pedro T
AUID- ORCID: 0000-0003-3953-9049
AD  - Department of Neuroradiology, Centro Hospitalar Universitário de São João, Porto, 
      Portugal tiagoliveirapedro@hotmail.com.
FAU - Sousa, José Maria
AU  - Sousa JM
AD  - Department of Neuroradiology, Centro Hospitalar Universitário de São João, Porto, 
      Portugal.
FAU - Fonseca, Luísa
AU  - Fonseca L
AD  - Department of Medicine, University of Porto, Porto, Portugal.
AD  - Department of Internal Medicine, Centro Hospitalar Universitário de São João, 
      Porto, Portugal.
FAU - Gama, Manuel G
AU  - Gama MG
AD  - Department of Medicine, University of Porto, Porto, Portugal.
AD  - Department of Internal Medicine, Centro Hospitalar Universitário de São João, 
      Porto, Portugal.
FAU - Moreira, Goreti
AU  - Moreira G
AD  - Department of Medicine, University of Porto, Porto, Portugal.
AD  - Department of Internal Medicine, Centro Hospitalar Universitário de São João, 
      Porto, Portugal.
FAU - Pintalhão, Mariana
AU  - Pintalhão M
AD  - Department of Medicine, University of Porto, Porto, Portugal.
AD  - Department of Internal Medicine, Centro Hospitalar Universitário de São João, 
      Porto, Portugal.
FAU - Chaves, Paulo C
AU  - Chaves PC
AD  - Department of Medicine, University of Porto, Porto, Portugal.
AD  - Department of Internal Medicine, Centro Hospitalar Universitário de São João, 
      Porto, Portugal.
FAU - Aires, Ana
AU  - Aires A
AD  - Department of Internal Medicine, Centro Hospitalar Universitário de São João, 
      Porto, Portugal.
AD  - Department of Neurology, Centro Hospitalar Universitário de São João, Porto, 
      Portugal.
FAU - Alves, Gonçalo
AU  - Alves G
AD  - Department of Neuroradiology, Centro Hospitalar Universitário de São João, Porto, 
      Portugal.
AD  - Centro de Referência de Neurorradiologia de Intervenção na Doença 
      Cerebrovascular, Centro Hospitalar Universitário de São João, Porto, Portugal.
FAU - Augusto, Luís
AU  - Augusto L
AD  - Department of Neuroradiology, Centro Hospitalar Universitário de São João, Porto, 
      Portugal.
AD  - Centro de Referência de Neurorradiologia de Intervenção na Doença 
      Cerebrovascular, Centro Hospitalar Universitário de São João, Porto, Portugal.
FAU - Pinheiro Albuquerque, Luís
AU  - Pinheiro Albuquerque L
AD  - Department of Neuroradiology, Centro Hospitalar Universitário de São João, Porto, 
      Portugal.
AD  - Centro de Referência de Neurorradiologia de Intervenção na Doença 
      Cerebrovascular, Centro Hospitalar Universitário de São João, Porto, Portugal.
FAU - Castro, Pedro
AU  - Castro P
AD  - Department of Neurology, Centro Hospitalar Universitário de São João, Porto, 
      Portugal.
AD  - Department of Clinical Neurosciences and Mental Health, University of Porto, 
      Porto, Portugal.
FAU - Silva, Maria Luís
AU  - Silva ML
AD  - Department of Neuroradiology, Centro Hospitalar Universitário de São João, Porto, 
      Portugal.
AD  - Centro de Referência de Neurorradiologia de Intervenção na Doença 
      Cerebrovascular, Centro Hospitalar Universitário de São João, Porto, Portugal.
LA  - eng
PT  - Journal Article
DEP - 20240307
PL  - England
TA  - J Neurointerv Surg
JT  - Journal of neurointerventional surgery
JID - 101517079
SB  - IM
OTO - NOTNLM
OT  - Stroke
COIS- Competing interests: None declared.
EDAT- 2024/03/08 00:42
MHDA- 2024/03/08 00:42
CRDT- 2024/03/07 21:38
PHST- 2024/01/31 00:00 [received]
PHST- 2024/02/27 00:00 [accepted]
PHST- 2024/03/08 00:42 [medline]
PHST- 2024/03/08 00:42 [pubmed]
PHST- 2024/03/07 21:38 [entrez]
AID - jnis-2024-021556 [pii]
AID - 10.1136/jnis-2024-021556 [doi]
PST - aheadofprint
SO  - J Neurointerv Surg. 2024 Mar 7:jnis-2024-021556. doi: 10.1136/jnis-2024-021556.

PMID- 37922198
OWN - NLM
STAT- MEDLINE
DCOM- 20231106
LR  - 20231107
IS  - 2050-084X (Electronic)
IS  - 2050-084X (Linking)
VI  - 12
DP  - 2023 Nov 3
TI  - ChatGPT identifies gender disparities in scientific peer review.
LID - 10.7554/eLife.90230 [doi]
LID - RP90230
AB  - The peer review process is a critical step in ensuring the quality of scientific 
      research. However, its subjectivity has raised concerns. To investigate this 
      issue, I examined over 500 publicly available peer review reports from 200 
      published neuroscience papers in 2022-2023. OpenAI's generative artificial 
      intelligence ChatGPT was used to analyze language use in these reports, which 
      demonstrated superior performance compared to traditional lexicon- and rule-based 
      language models. As expected, most reviews for these published papers were seen 
      as favorable by ChatGPT (89.8% of reviews), and language use was mostly polite 
      (99.8% of reviews). However, this analysis also demonstrated high levels of 
      variability in how each reviewer scored the same paper, indicating the presence 
      of subjectivity in the peer review process. The results further revealed that 
      female first authors received less polite reviews than their male peers, 
      indicating a gender bias in reviewing. In addition, published papers with a 
      female senior author received more favorable reviews than papers with a male 
      senior author, for which I discuss potential causes. Together, this study 
      highlights the potential of generative artificial intelligence in performing 
      natural language processing of specialized scientific texts. As a proof of 
      concept, I show that ChatGPT can identify areas of concern in scientific peer 
      review, underscoring the importance of transparent peer review in studying 
      equitability in scientific publishing.
CI  - © 2023, Verharen.
FAU - Verharen, Jeroen P H
AU  - Verharen JPH
AUID- ORCID: 0000-0001-7582-802X
AD  - Department of Molecular and Cell Biology and Helen Wills Neuroscience Institute, 
      University of California, Berkeley, Berkeley, United States.
LA  - eng
PT  - Journal Article
DEP - 20231103
PL  - England
TA  - Elife
JT  - eLife
JID - 101579614
SB  - IM
UOF - doi: 10.1101/2023.07.18.549552
UOF - doi: 10.7554/eLife.90230.1
UOF - doi: 10.7554/eLife.90230.2
MH  - Female
MH  - Male
MH  - Humans
MH  - *Publishing
MH  - *Artificial Intelligence
MH  - Sexism
MH  - Peer Review
MH  - Research Report
PMC - PMC10624422
OAB - Peer review is a vital step in ensuring the quality and accuracy of scientific 
      research before publication. Experts assess research manuscripts, advise journal 
      editors on publishing them, and provide authors with recommendations for 
      improvement. But some scientists have raised concerns about potential biases and 
      subjectivity in the peer review process. Author attributes, such as gender, 
      reputation, or how prestigious their institution is, may subconsciously influence 
      reviewers’ scores. Studying peer review to identify potential biases is 
      challenging. The language reviewers use is very technical, and some of their 
      commentary may be subjective and vary from reviewer to reviewer. The emergence of 
      OpenAI’s ChatGPT, which uses machine learning to process large amounts of 
      information, may provide a new tool to analyze peer review for signs of bias. 
      Verharen demonstrated that ChatGPT can be used to analyze peer review reports and 
      found potential indications of gender bias in scientific publishing. In the 
      experiments, Verharen asked ChatGPT to analyze more than 500 reviews of 200 
      neuroscience studies published in the scientific journal Nature Communications 
      over the past year. The experiments found no evidence that institutional 
      reputation influenced reviews. Yet, female first authors were more likely to 
      receive impolite comments from reviewers. Female senior authors were more likely 
      to receive higher review scores, which may indicate they had to clear a higher 
      bar for publication. The experiments indicate that ChatGPT could be used to 
      analyze peer review for fairness. Verharen suggests that reviewers might apply 
      this tool to ensure their reviews are polite and accurate reflections of their 
      opinions. Scientists or publishers might also use it for large-scale analyses of 
      peer review in individual journals or in scientific publishing more widely. 
      Journals might also use ChatGPT to assess the impact of bias-prevention 
      interventions on review fairness.
OABL- eng
OTO - NOTNLM
OT  - artificial intelligence
OT  - meta-science
OT  - natural language processing
OT  - neuroscience
OT  - none
OT  - peer review
COIS- JV No competing interests declared
EDAT- 2023/11/03 18:43
MHDA- 2023/11/06 06:43
PMCR- 2023/11/03
CRDT- 2023/11/03 12:52
PHST- 2023/11/06 06:43 [medline]
PHST- 2023/11/03 18:43 [pubmed]
PHST- 2023/11/03 12:52 [entrez]
PHST- 2023/11/03 00:00 [pmc-release]
AID - 90230 [pii]
AID - 10.7554/eLife.90230 [doi]
PST - epublish
SO  - Elife. 2023 Nov 3;12:RP90230. doi: 10.7554/eLife.90230.

PMID- 37529703
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230803
IS  - 1663-9812 (Print)
IS  - 1663-9812 (Electronic)
IS  - 1663-9812 (Linking)
VI  - 14
DP  - 2023
TI  - Future implications of ChatGPT in pharmaceutical industry: drug discovery and 
      development.
PG  - 1194216
LID - 10.3389/fphar.2023.1194216 [doi]
LID - 1194216
FAU - Zhao, Ailin
AU  - Zhao A
AD  - Department of Hematology, West China Hospital, Sichuan University, Chengdu, 
      Sichuan, China.
FAU - Wu, Yijun
AU  - Wu Y
AD  - Cancer Center, West China Hospital, Sichuan University, Chengdu, Sichuan, China.
LA  - eng
PT  - Journal Article
DEP - 20230717
PL  - Switzerland
TA  - Front Pharmacol
JT  - Frontiers in pharmacology
JID - 101548923
PMC - PMC10390092
OTO - NOTNLM
OT  - ChatGPT
OT  - academic writing
OT  - artificial intelligence
OT  - clinical drug
OT  - drug discovsry
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/08/02 06:43
MHDA- 2023/08/02 06:44
PMCR- 2023/07/17
CRDT- 2023/08/02 04:01
PHST- 2023/03/26 00:00 [received]
PHST- 2023/06/08 00:00 [accepted]
PHST- 2023/08/02 06:44 [medline]
PHST- 2023/08/02 06:43 [pubmed]
PHST- 2023/08/02 04:01 [entrez]
PHST- 2023/07/17 00:00 [pmc-release]
AID - 1194216 [pii]
AID - 10.3389/fphar.2023.1194216 [doi]
PST - epublish
SO  - Front Pharmacol. 2023 Jul 17;14:1194216. doi: 10.3389/fphar.2023.1194216. 
      eCollection 2023.

PMID- 37244834
OWN - NLM
STAT- MEDLINE
DCOM- 20231023
LR  - 20231025
IS  - 1471-6771 (Electronic)
IS  - 0007-0912 (Linking)
VI  - 131
IP  - 2
DP  - 2023 Aug
TI  - Artificial intelligence and anaesthesia examinations: exploring ChatGPT as a 
      prelude to the future.
PG  - e36-e37
LID - S0007-0912(23)00226-X [pii]
LID - 10.1016/j.bja.2023.04.033 [doi]
FAU - Aldridge, Matthew J
AU  - Aldridge MJ
AD  - North Bristol NHS Trust, Bristol, UK. Electronic address: matt.aldridge@nhs.net.
FAU - Penders, Robert
AU  - Penders R
AD  - North Bristol NHS Trust, Bristol, UK.
LA  - eng
PT  - Letter
DEP - 20230526
PL  - England
TA  - Br J Anaesth
JT  - British journal of anaesthesia
JID - 0372541
SB  - IM
MH  - Humans
MH  - Artificial Intelligence
MH  - *Anesthesia
MH  - *Anesthesiology
OTO - NOTNLM
OT  - ChatGPT
OT  - GPT-4
OT  - anaesthesia training
OT  - artificial intelligence
OT  - examination
OT  - large language model
EDAT- 2023/05/28 01:07
MHDA- 2023/10/23 12:44
CRDT- 2023/05/27 22:00
PHST- 2023/04/14 00:00 [received]
PHST- 2023/04/22 00:00 [revised]
PHST- 2023/04/25 00:00 [accepted]
PHST- 2023/10/23 12:44 [medline]
PHST- 2023/05/28 01:07 [pubmed]
PHST- 2023/05/27 22:00 [entrez]
AID - S0007-0912(23)00226-X [pii]
AID - 10.1016/j.bja.2023.04.033 [doi]
PST - ppublish
SO  - Br J Anaesth. 2023 Aug;131(2):e36-e37. doi: 10.1016/j.bja.2023.04.033. Epub 2023 
      May 26.

PMID- 37404248
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230718
IS  - 2666-3287 (Electronic)
IS  - 2666-3287 (Linking)
VI  - 12
DP  - 2023 Sep
TI  - ChatGPT underperforms in triaging appropriate use of Mohs surgery for cutaneous 
      neoplasms.
PG  - 168-170
LID - 10.1016/j.jdin.2023.06.002 [doi]
FAU - O'Hern, Keegan
AU  - O'Hern K
AD  - Department of Dermatology, Mayo Clinic, Rochester, Minnesota.
FAU - Yang, Eilene
AU  - Yang E
AD  - Mayo Clinic Alix School of Medicine, Rochester, Minnesota.
FAU - Vidal, Nahid Y
AU  - Vidal NY
AD  - Division of Dermatologic Surgery, Mayo Clinic, Rochester, Minnesota.
LA  - eng
PT  - Journal Article
DEP - 20230609
PL  - United States
TA  - JAAD Int
JT  - JAAD international
JID - 101774762
PMC - PMC10316650
OTO - NOTNLM
OT  - ChatGPT
OT  - Mohs surgery
OT  - appropriate use criteria
OT  - artificial intelligence
OT  - dermatologic surgery
OT  - wide local excision
COIS- None disclosed.
EDAT- 2023/07/05 13:05
MHDA- 2023/07/05 13:06
PMCR- 2023/06/09
CRDT- 2023/07/05 10:34
PHST- 2023/07/05 13:06 [medline]
PHST- 2023/07/05 13:05 [pubmed]
PHST- 2023/07/05 10:34 [entrez]
PHST- 2023/06/09 00:00 [pmc-release]
AID - S2666-3287(23)00089-5 [pii]
AID - 10.1016/j.jdin.2023.06.002 [doi]
PST - epublish
SO  - JAAD Int. 2023 Jun 9;12:168-170. doi: 10.1016/j.jdin.2023.06.002. eCollection 
      2023 Sep.

PMID- 38528129
OWN - NLM
STAT- Publisher
LR  - 20240326
IS  - 1432-5241 (Electronic)
IS  - 0364-216X (Linking)
DP  - 2024 Mar 25
TI  - Exploring the Unknown: Evaluating ChatGPT's Performance in Uncovering Novel 
      Aspects of Plastic Surgery and Identifying Areas for Future Innovation.
LID - 10.1007/s00266-024-03952-z [doi]
AB  - BACKGROUND: Artificial intelligence (AI) has emerged as a powerful tool in 
      various medical fields, including plastic surgery. This study aims to evaluate 
      the performance of ChatGPT, an AI language model, in elucidating historical 
      aspects of plastic surgery and identifying potential avenues for innovation. 
      METHODS: A comprehensive analysis of ChatGPT's responses to a diverse range of 
      plastic surgery-related inquiries was performed. The quality of the AI-generated 
      responses was assessed based on their relevance, accuracy, and novelty. 
      Additionally, the study examined the AI's ability to recognize gaps in existing 
      knowledge and propose innovative solutions. ChatGPT's responses were analysed by 
      specialist plastic surgeons with extensive research experience, and 
      quantitatively analysed with a Likert scale. RESULTS: ChatGPT demonstrated a high 
      degree of proficiency in addressing a wide array of plastic surgery-related 
      topics. The AI-generated responses were found to be relevant and accurate in most 
      cases. However, it demonstrated convergent thinking and failed to generate 
      genuinely novel ideas to revolutionize plastic surgery. Instead, it suggested 
      currently popular trends that demonstrate great potential for further 
      advancements. Some of the references presented were also erroneous as they cannot 
      be validated against the existing literature. CONCLUSION: Although ChatGPT 
      requires major improvements, this study highlights its potential as an effective 
      tool for uncovering novel aspects of plastic surgery and identifying areas for 
      future innovation. By leveraging the capabilities of AI language models, plastic 
      surgeons may drive advancements in the field. Further studies are needed to 
      cautiously explore the integration of AI-driven insights into clinical practice 
      and to evaluate their impact on patient outcomes. LEVEL OF EVIDENCE V: This 
      journal requires that authors assign a level of evidence to each article. For a 
      full description of these Evidence-Based Medicine ratings, please refer to the 
      Table of Contents or the online Instructions to Authors www.springer.com/00266.
CI  - © 2024. The Author(s).
FAU - Lim, Bryan
AU  - Lim B
AUID- ORCID: 0009-0007-9647-5180
AD  - Department of Plastic Surgery, Peninsula Health, Melbourne, VIC, 3199, Australia. 
      lim.bryan58@gmail.com.
AD  - Central Clinical School, Monash University, The Alfred Centre, 99 Commercial Rd, 
      Melbourne, VIC, 3004, Australia. lim.bryan58@gmail.com.
FAU - Seth, Ishith
AU  - Seth I
AD  - Department of Plastic Surgery, Peninsula Health, Melbourne, VIC, 3199, Australia.
AD  - Central Clinical School, Monash University, The Alfred Centre, 99 Commercial Rd, 
      Melbourne, VIC, 3004, Australia.
FAU - Xie, Yi
AU  - Xie Y
AD  - Department of Plastic Surgery, Peninsula Health, Melbourne, VIC, 3199, Australia.
FAU - Kenney, Peter Sinkjaer
AU  - Kenney PS
AD  - Department of Plastic Surgery, Odense University Hospital, J. B. Winsløwsvej 4, 
      5000, Odense, Denmark.
AD  - Department of Plastic and Breast Surgery, Aarhus University Hospital, Palle 
      Juul-Jensens Boulevard 99, 8200, Aarhus, Denmark.
FAU - Cuomo, Roberto
AU  - Cuomo R
AD  - Plastic Surgery Unit, Department of Medicine, Surgery and Neuroscience, 
      University of Siena, 53100, Siena, Italy.
FAU - Rozen, Warren M
AU  - Rozen WM
AD  - Department of Plastic Surgery, Peninsula Health, Melbourne, VIC, 3199, Australia.
AD  - Central Clinical School, Monash University, The Alfred Centre, 99 Commercial Rd, 
      Melbourne, VIC, 3004, Australia.
LA  - eng
PT  - Journal Article
DEP - 20240325
PL  - United States
TA  - Aesthetic Plast Surg
JT  - Aesthetic plastic surgery
JID - 7701756
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Innovation
OT  - Plastic surgery
EDAT- 2024/03/26 06:45
MHDA- 2024/03/26 06:45
CRDT- 2024/03/26 00:21
PHST- 2023/11/03 00:00 [received]
PHST- 2024/02/21 00:00 [accepted]
PHST- 2024/03/26 06:45 [medline]
PHST- 2024/03/26 06:45 [pubmed]
PHST- 2024/03/26 00:21 [entrez]
AID - 10.1007/s00266-024-03952-z [pii]
AID - 10.1007/s00266-024-03952-z [doi]
PST - aheadofprint
SO  - Aesthetic Plast Surg. 2024 Mar 25. doi: 10.1007/s00266-024-03952-z.

PMID- 38183235
OWN - NLM
STAT- Publisher
LR  - 20240106
IS  - 1488-2361 (Electronic)
IS  - 0846-5371 (Linking)
DP  - 2024 Jan 6
TI  - Artificial Intelligence Chatbots' Understanding of the Risks and Benefits of 
      Computed Tomography and Magnetic Resonance Imaging Scenarios.
PG  - 8465371231220561
LID - 10.1177/08465371231220561 [doi]
AB  - PURPOSE: Patients may seek online information to better understand medical 
      imaging procedures. The purpose of this study was to assess the accuracy of 
      information provided by 2 popular artificial intelligence (AI) chatbots 
      pertaining to common imaging scenarios' risks, benefits, and alternatives. 
      METHODS: Fourteen imaging-related scenarios pertaining to computed tomography 
      (CT) or magnetic resonance imaging (MRI) were used. Factors including the use of 
      intravenous contrast, the presence of renal disease, and whether the patient was 
      pregnant were included in the analysis. For each scenario, 3 prompts for 
      outlining the (1) risks, (2) benefits, and (3) alternative imaging choices or 
      potential implications of not using contrast were inputted into ChatGPT and Bard. 
      A grading rubric and a 5-point Likert scale was used by 2 independent reviewers 
      to grade responses. Prompt variability and chatbot context dependency were also 
      assessed. RESULTS: ChatGPT's performance was superior to Bard's in accurately 
      responding to prompts per Likert grading (4.36 ± 0.63 vs 3.25 ± 1.03 seconds, 
      P &lt; .0001). There was substantial agreement between independent reviewer grading 
      for ChatGPT (κ = 0.621) and Bard (κ = 0.684). Response text length was not 
      statistically different between ChatGPT and Bard (2087 ± 256 characters vs 
      2162 ± 369 characters, P = .24). Response time was longer for ChatGPT (34 ± 2 vs 
      8 ± 1 seconds, P &lt; .0001). CONCLUSIONS: ChatGPT performed superior to Bard at 
      outlining risks, benefits, and alternatives to common imaging scenarios. 
      Generally, context dependency and prompt variability did not change chatbot 
      response content. Due to the lack of detailed scientific reasoning and inability 
      to provide patient-specific information, both AI chatbots have limitations as a 
      patient information resource.
FAU - Patil, Nikhil S
AU  - Patil NS
AUID- ORCID: 0000-0003-3929-0482
AD  - Michael G. DeGroote School of Medicine, McMaster University, Hamilton, ON, 
      Canada.
FAU - Huang, Ryan S
AU  - Huang RS
AD  - Temerty Faculty of Medicine, University of Toronto, Toronto, ON, Canada.
FAU - Caterine, Scott
AU  - Caterine S
AD  - Department of Radiology, McMaster University, Hamilton, ON, Canada.
FAU - Yao, Jason
AU  - Yao J
AD  - Department of Radiology, McMaster University, Hamilton, ON, Canada.
FAU - Larocque, Natasha
AU  - Larocque N
AUID- ORCID: 0000-0003-0449-9438
AD  - Department of Radiology, McMaster University, Hamilton, ON, Canada.
FAU - van der Pol, Christian B
AU  - van der Pol CB
AUID- ORCID: 0000-0002-1718-2619
AD  - Department of Radiology, McMaster University, Hamilton, ON, Canada.
FAU - Stubbs, Euan
AU  - Stubbs E
AD  - Department of Radiology, McMaster University, Hamilton, ON, Canada.
LA  - eng
PT  - Journal Article
DEP - 20240106
PL  - United States
TA  - Can Assoc Radiol J
JT  - Canadian Association of Radiologists journal = Journal l'Association canadienne 
      des radiologistes
JID - 8812910
SB  - IM
OTO - NOTNLM
OT  - Bard
OT  - CT
OT  - ChatGPT
OT  - Google
OT  - MRI
OT  - contrast
OT  - risks
COIS- Declaration of Conflicting InterestsThe author(s) declared no potential conflicts 
      of interest with respect to the research, authorship, and/or publication of this 
      article.
EDAT- 2024/01/06 10:43
MHDA- 2024/01/06 10:43
CRDT- 2024/01/06 03:29
PHST- 2024/01/06 10:43 [medline]
PHST- 2024/01/06 10:43 [pubmed]
PHST- 2024/01/06 03:29 [entrez]
AID - 10.1177/08465371231220561 [doi]
PST - aheadofprint
SO  - Can Assoc Radiol J. 2024 Jan 6:8465371231220561. doi: 10.1177/08465371231220561.

PMID- 38022227
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231201
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 10
DP  - 2023 Oct
TI  - Reliability and Usefulness of ChatGPT for Inflammatory Bowel Diseases: An 
      Analysis for Patients and Healthcare Professionals.
PG  - e46736
LID - 10.7759/cureus.46736 [doi]
LID - e46736
AB  - AIM: We aimed to evaluate the performance of Chat Generative Pre-trained 
      Transformer (ChatGPT) within the context of inflammatory bowel disease&nbsp;(IBD), 
      which is expected to become an increasingly significant health issue in the 
      future. In addition, the objective of the study was to assess whether ChatGPT 
      serves as a reliable and useful resource for both patients and healthcare 
      professionals. METHODS: For this study, 20 specific questions were identified for 
      the two main components of IBD, which are Crohn's disease (CD) and ulcerative 
      colitis (UC). The questions were divided into two sets: one set contained 
      questions directed at healthcare professionals while the second set contained 
      questions directed toward&nbsp;patients. The responses were evaluated with seven-point 
      Likert-type reliability and usefulness scales. RESULTS: The distribution of the 
      reliability and utility scores was calculated into four groups (two diseases and 
      two question sources) by averaging the mean scores from both raters.&nbsp;The highest 
      scores in both reliability and usefulness were obtained from professional sources 
      (5.00± 1.21 and 5.15±1.08, respectively). The ranking in terms of reliability and 
      usefulness, respectively, was as follows: CD questions&nbsp;(4.70±1.26 and 4.75±1.06) 
      and UC questions (4.40±1.21 and 4.55±1.31). The reliability scores of the answers 
      for the professionals were significantly higher than those for the patients (both 
      raters, p=0.032).&nbsp; Conclusion: Despite its capacity for reliability and 
      usefulness in the context of IBD, ChatGPT still has some limitations and 
      deficiencies.&nbsp;The correction of ChatGPT's deficiencies and its enhancement by 
      developers with more detailed and up-to-date information could make it a 
      significant source of information for both patients and medical professionals.
CI  - Copyright © 2023, Cankurtaran et al.
FAU - Cankurtaran, Rasim Eren
AU  - Cankurtaran RE
AD  - Department of Gastroenterology, Ankara Etlik City Hospital, Ankara, TUR.
FAU - Polat, Yunus Halil
AU  - Polat YH
AD  - Department of Gastroenterology, Ankara Training and Research Hospital, Ankara, 
      TUR.
FAU - Aydemir, Neslihan Gunes
AU  - Aydemir NG
AD  - Department of Gastroenterology, Akdeniz University Faculty of Medicine, Antalya, 
      TUR.
FAU - Umay, Ebru
AU  - Umay E
AD  - Physical Medicine and Rehabilitation, University of Health Sciences, Ankara Etlik 
      City Hospital, Ankara, TUR.
FAU - Yurekli, Oyku Tayfur
AU  - Yurekli OT
AD  - Department of Gastroenterology, Ankara Yildirim Beyazit University Faculty of 
      Medicine, Ankara, TUR.
LA  - eng
PT  - Journal Article
DEP - 20231009
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10630704
OTO - NOTNLM
OT  - artificial intelligence (ai)
OT  - chatgpt
OT  - crohn’s disease (cd)
OT  - healthcare research
OT  - inflammatory bowel diseases (ibd)
OT  - large language model
OT  - ulcerative colitis (uc)
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/11/29 18:42
MHDA- 2023/11/29 18:43
PMCR- 2023/10/09
CRDT- 2023/11/29 15:19
PHST- 2023/10/09 00:00 [accepted]
PHST- 2023/11/29 18:43 [medline]
PHST- 2023/11/29 18:42 [pubmed]
PHST- 2023/11/29 15:19 [entrez]
PHST- 2023/10/09 00:00 [pmc-release]
AID - 10.7759/cureus.46736 [doi]
PST - epublish
SO  - Cureus. 2023 Oct 9;15(10):e46736. doi: 10.7759/cureus.46736. eCollection 2023 
      Oct.

PMID- 38015610
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231215
IS  - 2291-9694 (Print)
IS  - 2291-9694 (Electronic)
VI  - 11
DP  - 2023 Nov 28
TI  - Applications of the Natural Language Processing Tool ChatGPT in Clinical 
      Practice: Comparative Study and Augmented Systematic Review.
PG  - e48933
LID - 10.2196/48933 [doi]
LID - e48933
AB  - BACKGROUND: This research integrates a comparative analysis of the performance of 
      human researchers and OpenAI's ChatGPT in systematic review tasks and describes 
      an assessment of the application of natural language processing (NLP) models in 
      clinical practice through a review of 5 studies. OBJECTIVE: This study aimed to 
      evaluate the reliability between ChatGPT and human researchers in extracting key 
      information from clinical articles, and to investigate the practical use of NLP 
      in clinical settings as evidenced by selected studies. METHODS: The study design 
      comprised a systematic review of clinical articles executed independently by 
      human researchers and ChatGPT. The level of agreement between and within raters 
      for parameter extraction was assessed using the Fleiss and Cohen κ statistics. 
      RESULTS: The comparative analysis revealed a high degree of concordance between 
      ChatGPT and human researchers for most parameters, with less agreement for study 
      design, clinical task, and clinical implementation. The review identified 5 
      significant studies that demonstrated the diverse applications of NLP in clinical 
      settings. These studies' findings highlight the potential of NLP to improve 
      clinical efficiency and patient outcomes in various contexts, from enhancing 
      allergy detection and classification to improving quality metrics in 
      psychotherapy treatments for veterans with posttraumatic stress disorder. 
      CONCLUSIONS: Our findings underscore the potential of NLP models, including 
      ChatGPT, in performing systematic reviews and other clinical tasks. Despite 
      certain limitations, NLP models present a promising avenue for enhancing health 
      care efficiency and accuracy. Future studies must focus on broadening the range 
      of clinical applications and exploring the ethical considerations of implementing 
      NLP applications in health care settings.
CI  - ©Nikolas Schopow, Georg Osterhoff, David Baur. Originally published in JMIR 
      Medical Informatics (https://medinform.jmir.org), 28.11.2023.
FAU - Schopow, Nikolas
AU  - Schopow N
AUID- ORCID: 0000-0002-6754-5692
AD  - Department for Orthopedics, Trauma Surgery and Plastic Surgery, University 
      Hospital Leipzig, Leipzig, Germany.
FAU - Osterhoff, Georg
AU  - Osterhoff G
AUID- ORCID: 0000-0001-5051-0998
AD  - Department for Orthopedics, Trauma Surgery and Plastic Surgery, University 
      Hospital Leipzig, Leipzig, Germany.
FAU - Baur, David
AU  - Baur D
AUID- ORCID: 0000-0001-8602-617X
AD  - Department for Orthopedics, Trauma Surgery and Plastic Surgery, University 
      Hospital Leipzig, Leipzig, Germany.
LA  - eng
PT  - Journal Article
DEP - 20231128
PL  - Canada
TA  - JMIR Med Inform
JT  - JMIR medical informatics
JID - 101645109
PMC - PMC10716749
OTO - NOTNLM
OT  - ChatGPT
OT  - GPT-3
OT  - GPT-4
OT  - NLP
OT  - artificial intelligence
OT  - clinical decision support systems
OT  - clinical practice
OT  - extract
OT  - extraction
OT  - health care
OT  - healthcare
OT  - language model
OT  - large language models
OT  - machine learning
OT  - natural language processing
OT  - review methodology
OT  - review methods
OT  - systematic
OT  - systematic review
OT  - text
OT  - unstructured
COIS- Conflicts of Interest: None declared.
EDAT- 2023/11/28 12:42
MHDA- 2023/11/28 12:43
PMCR- 2023/11/28
CRDT- 2023/11/28 11:54
PHST- 2023/05/11 00:00 [received]
PHST- 2023/08/25 00:00 [accepted]
PHST- 2023/06/20 00:00 [revised]
PHST- 2023/11/28 12:43 [medline]
PHST- 2023/11/28 12:42 [pubmed]
PHST- 2023/11/28 11:54 [entrez]
PHST- 2023/11/28 00:00 [pmc-release]
AID - v11i1e48933 [pii]
AID - 10.2196/48933 [doi]
PST - epublish
SO  - JMIR Med Inform. 2023 Nov 28;11:e48933. doi: 10.2196/48933.

PMID- 37566454
OWN - NLM
STAT- MEDLINE
DCOM- 20230828
LR  - 20231106
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 25
DP  - 2023 Aug 11
TI  - Ethical Considerations of Using ChatGPT in Health Care.
PG  - e48009
LID - 10.2196/48009 [doi]
LID - e48009
AB  - ChatGPT has promising applications in health care, but potential ethical issues 
      need to be addressed proactively to prevent harm. ChatGPT presents potential 
      ethical challenges from legal, humanistic, algorithmic, and informational 
      perspectives. Legal ethics concerns arise from the unclear allocation of 
      responsibility when patient harm occurs and from potential breaches of patient 
      privacy due to data collection. Clear rules and legal boundaries are needed to 
      properly allocate liability and protect users. Humanistic ethics concerns arise 
      from the potential disruption of the physician-patient relationship, humanistic 
      care, and issues of integrity. Overreliance on artificial intelligence (AI) can 
      undermine compassion and erode trust. Transparency and disclosure of AI-generated 
      content are critical to maintaining integrity. Algorithmic ethics raise concerns 
      about algorithmic bias, responsibility, transparency and explainability, as well 
      as validation and evaluation. Information ethics include data bias, validity, and 
      effectiveness. Biased training data can lead to biased output, and overreliance 
      on ChatGPT can reduce patient adherence and encourage self-diagnosis. Ensuring 
      the accuracy, reliability, and validity of ChatGPT-generated content requires 
      rigorous validation and ongoing updates based on clinical practice. To navigate 
      the evolving ethical landscape of AI, AI in health care must adhere to the 
      strictest ethical standards. Through comprehensive ethical guidelines, health 
      care professionals can ensure the responsible use of ChatGPT, promote accurate 
      and reliable information exchange, protect patient privacy, and empower patients 
      to make informed decisions about their health care.
CI  - ©Changyu Wang, Siru Liu, Hao Yang, Jiulin Guo, Yuxuan Wu, Jialin Liu. Originally 
      published in the Journal of Medical Internet Research (https://www.jmir.org), 
      11.08.2023.
FAU - Wang, Changyu
AU  - Wang C
AUID- ORCID: 0000-0003-4548-331X
AD  - Department of Medical Informatics, West China Medical School, Sichuan University, 
      Chengdu, China.
AD  - West China College of Stomatology, Sichuan University, Chengdu, China.
FAU - Liu, Siru
AU  - Liu S
AUID- ORCID: 0000-0002-5003-5354
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, TN, United States.
FAU - Yang, Hao
AU  - Yang H
AUID- ORCID: 0000-0002-3505-9403
AD  - Information Center, West China Hospital, Sichuan University, Chengdu, China.
FAU - Guo, Jiulin
AU  - Guo J
AUID- ORCID: 0009-0006-5995-8290
AD  - Information Center, West China Hospital, Sichuan University, Chengdu, China.
FAU - Wu, Yuxuan
AU  - Wu Y
AUID- ORCID: 0000-0003-1333-4627
AD  - Department of Medical Informatics, West China Medical School, Sichuan University, 
      Chengdu, China.
FAU - Liu, Jialin
AU  - Liu J
AUID- ORCID: 0000-0002-1369-4625
AD  - Department of Medical Informatics, West China Medical School, Sichuan University, 
      Chengdu, China.
AD  - Information Center, West China Hospital, Sichuan University, Chengdu, China.
AD  - Department of Otolaryngology-Head and Neck Surgery, West China Hospital, Sichuan 
      University, Chengdu, China.
LA  - eng
PT  - Journal Article
DEP - 20230811
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Reproducibility of Results
MH  - Data Collection
MH  - *Disclosure
MH  - Patient Compliance
PMC - PMC10457697
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - algorithm
OT  - artificial intelligence
OT  - artificial intelligence development
OT  - development
OT  - ethics
OT  - health care
OT  - large language models
OT  - patient privacy
OT  - patient safety
OT  - privacy
OT  - safety
COIS- Conflicts of Interest: None declared.
EDAT- 2023/08/11 12:42
MHDA- 2023/08/28 06:42
PMCR- 2023/08/11
CRDT- 2023/08/11 11:53
PHST- 2023/04/07 00:00 [received]
PHST- 2023/07/25 00:00 [accepted]
PHST- 2023/07/05 00:00 [revised]
PHST- 2023/08/28 06:42 [medline]
PHST- 2023/08/11 12:42 [pubmed]
PHST- 2023/08/11 11:53 [entrez]
PHST- 2023/08/11 00:00 [pmc-release]
AID - v25i1e48009 [pii]
AID - 10.2196/48009 [doi]
PST - epublish
SO  - J Med Internet Res. 2023 Aug 11;25:e48009. doi: 10.2196/48009.

PMID- 37636841
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230829
IS  - 0972-5229 (Print)
IS  - 1998-359X (Electronic)
IS  - 0972-5229 (Linking)
VI  - 27
IP  - 8
DP  - 2023 Aug
TI  - ChatGPT: Friend or Foe?-Utility in Trauma Triage.
PG  - 563-566
LID - 10.5005/jp-journals-10071-24498 [doi]
AB  - Artificial intelligence (AI) has been growing rapidly in the health and 
      production industry. The most recent AI program that has caught everyone's eye 
      is, Chat Generative Pre-trained Transformer (ChatGPT). It is a program based on 
      Open AI and was released in November 2022 to the public. It is a chatbot that 
      helps with analyzing and learning data from the net, based on human literature 
      and data. HOW TO CITE THIS ARTICLE: Jacob J. ChatGPT: Friend or Foe?-Utility in 
      Trauma Triage. Indian J Crit Care Med 2023;27(8):563-566.
CI  - Copyright © 2023; The Author(s).
FAU - Jacob, Jerry
AU  - Jacob J
AUID- ORCID: 0000-0003-3816-189X
AD  - Department of Emergency Medicine, M S Ramaiah Medical College, Bengaluru, 
      Karnataka, India.
LA  - eng
PT  - Journal Article
PL  - India
TA  - Indian J Crit Care Med
JT  - Indian journal of critical care medicine : peer-reviewed, official publication of 
      Indian Society of Critical Care Medicine
JID - 101208863
PMC - PMC10452764
OTO - NOTNLM
OT  - Comorbidities
OT  - Intensive care specialist
OT  - Treatment guideline
COIS- Source of support: Nil Conflict of interest: None
EDAT- 2023/08/28 06:43
MHDA- 2023/08/28 06:44
PMCR- 2023/08/01
CRDT- 2023/08/28 04:40
PHST- 2023/06/06 00:00 [received]
PHST- 2023/07/13 00:00 [accepted]
PHST- 2023/08/28 06:44 [medline]
PHST- 2023/08/28 06:43 [pubmed]
PHST- 2023/08/28 04:40 [entrez]
PHST- 2023/08/01 00:00 [pmc-release]
AID - 10.5005/jp-journals-10071-24498 [doi]
PST - ppublish
SO  - Indian J Crit Care Med. 2023 Aug;27(8):563-566. doi: 
      10.5005/jp-journals-10071-24498.

PMID- 37887080
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231029
IS  - 2039-7275 (Print)
IS  - 2039-7283 (Electronic)
IS  - 2039-7275 (Linking)
VI  - 13
IP  - 5
DP  - 2023 Sep 26
TI  - AI-Powered Renal Diet Support: Performance of ChatGPT, Bard AI, and Bing Chat.
PG  - 1160-1172
LID - 10.3390/clinpract13050104 [doi]
AB  - Patients with chronic kidney disease (CKD) necessitate specialized renal diets to 
      prevent complications such as hyperkalemia and hyperphosphatemia. A comprehensive 
      assessment of food components is pivotal, yet burdensome for healthcare 
      providers. With evolving artificial intelligence (AI) technology, models such as 
      ChatGPT, Bard AI, and Bing Chat can be instrumental in educating patients and 
      assisting professionals. To gauge the efficacy of different AI models in 
      discerning potassium and phosphorus content in foods, four AI models-ChatGPT 3.5, 
      ChatGPT 4, Bard AI, and Bing Chat-were evaluated. A total of 240 food items, 
      curated from the Mayo Clinic Renal Diet Handbook for CKD patients, were input 
      into each model. These items were characterized by their potassium (149 items) 
      and phosphorus (91 items) content. Each model was tasked to categorize the items 
      into high or low potassium and high phosphorus content. The results were 
      juxtaposed with the Mayo Clinic Renal Diet Handbook's recommendations. The 
      concordance between repeated sessions was also evaluated to assess model 
      consistency. Among the models tested, ChatGPT 4 displayed superior performance in 
      identifying potassium content, correctly classifying 81% of the foods. It 
      accurately discerned 60% of low potassium and 99% of high potassium foods. In 
      comparison, ChatGPT 3.5 exhibited a 66% accuracy rate. Bard AI and Bing Chat 
      models had an accuracy rate of 79% and 81%, respectively. Regarding phosphorus 
      content, Bard AI stood out with a flawless 100% accuracy rate. ChatGPT 3.5 and 
      Bing Chat recognized 85% and 89% of the high phosphorus foods correctly, while 
      ChatGPT 4 registered a 77% accuracy rate. Emerging AI models manifest a diverse 
      range of accuracy in discerning potassium and phosphorus content in foods 
      suitable for CKD patients. ChatGPT 4, in particular, showed a marked improvement 
      over its predecessor, especially in detecting potassium content. The Bard AI 
      model exhibited exceptional precision for phosphorus identification. This study 
      underscores the potential of AI models as efficient tools in renal dietary 
      planning, though refinements are warranted for optimal utility.
FAU - Qarajeh, Ahmad
AU  - Qarajeh A
AUID- ORCID: 0000-0003-2457-9435
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
AD  - Faculty of Medicine, University of Jordan, Amman 11942, Jordan.
FAU - Tangpanithandee, Supawit
AU  - Tangpanithandee S
AUID- ORCID: 0000-0001-6103-2338
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
AD  - Chakri Naruebodindra Medical Institute, Faculty of Medicine Ramathibodi Hospital, 
      Mahidol University, Samut Prakan 10540, Thailand.
FAU - Thongprayoon, Charat
AU  - Thongprayoon C
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
FAU - Suppadungsuk, Supawadee
AU  - Suppadungsuk S
AUID- ORCID: 0000-0003-1597-2411
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
AD  - Chakri Naruebodindra Medical Institute, Faculty of Medicine Ramathibodi Hospital, 
      Mahidol University, Samut Prakan 10540, Thailand.
FAU - Krisanapan, Pajaree
AU  - Krisanapan P
AUID- ORCID: 0000-0002-2888-881X
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
AD  - Department of Internal Medicine, Faculty of Medicine, Thammasat University, 
      Pathum Thani 12120, Thailand.
FAU - Aiumtrakul, Noppawit
AU  - Aiumtrakul N
AUID- ORCID: 0000-0003-0479-7785
AD  - Department of Medicine, John A. Burns School of Medicine, University of Hawaii, 
      Honolulu, HI 96813, USA.
FAU - Garcia Valencia, Oscar A
AU  - Garcia Valencia OA
AUID- ORCID: 0000-0003-0186-9448
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
FAU - Miao, Jing
AU  - Miao J
AUID- ORCID: 0000-0003-0642-9740
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
FAU - Qureshi, Fawad
AU  - Qureshi F
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
FAU - Cheungpasitporn, Wisit
AU  - Cheungpasitporn W
AUID- ORCID: 0000-0001-9954-9711
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN 55905, USA.
LA  - eng
PT  - Journal Article
DEP - 20230926
PL  - Switzerland
TA  - Clin Pract
JT  - Clinics and practice
JID - 101563282
PMC - PMC10605499
OTO - NOTNLM
OT  - AI technology
OT  - Bard AI
OT  - Bing Chat
OT  - CKD
OT  - ChatGPT
OT  - chronic kidney disease
OT  - dietary planning
OT  - efficacy evaluation
OT  - food assessment
OT  - healthcare providers
OT  - hyperkalemia
OT  - hyperphosphatemia
OT  - phosphorus content
OT  - potassium content
OT  - renal diets
COIS- The authors declare no conflict of interest.
EDAT- 2023/10/27 12:44
MHDA- 2023/10/27 12:45
PMCR- 2023/09/26
CRDT- 2023/10/27 06:52
PHST- 2023/08/27 00:00 [received]
PHST- 2023/09/15 00:00 [revised]
PHST- 2023/09/25 00:00 [accepted]
PHST- 2023/10/27 12:45 [medline]
PHST- 2023/10/27 12:44 [pubmed]
PHST- 2023/10/27 06:52 [entrez]
PHST- 2023/09/26 00:00 [pmc-release]
AID - clinpract13050104 [pii]
AID - clinpract-13-00104 [pii]
AID - 10.3390/clinpract13050104 [doi]
PST - epublish
SO  - Clin Pract. 2023 Sep 26;13(5):1160-1172. doi: 10.3390/clinpract13050104.

PMID- 38217966
OWN - NLM
STAT- MEDLINE
DCOM- 20240308
LR  - 20240308
IS  - 1876-2026 (Electronic)
IS  - 1876-2018 (Linking)
VI  - 93
DP  - 2024 Mar
TI  - ChatGPT is still struggling to revolutionize mental health policy.
PG  - 103906
LID - S1876-2018(23)00463-X [pii]
LID - 10.1016/j.ajp.2023.103906 [doi]
FAU - Garg, Sunny
AU  - Garg S
AD  - Department of Psychiatry, Bhagat Phool Singh Government Medical College for Women 
      Khanpur Kalan, Sonipat, Haryana, India. Electronic address: 
      docter.sunny@gmail.com.
LA  - eng
PT  - Letter
DEP - 20240102
PL  - Netherlands
TA  - Asian J Psychiatr
JT  - Asian journal of psychiatry
JID - 101517820
SB  - IM
MH  - Humans
MH  - *Health Policy
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Mental health policy
OT  - Policymakers
COIS- Declaration of Competing Interest The author have no conflict or competing 
      interests to disclose.
EDAT- 2024/01/14 12:42
MHDA- 2024/03/08 06:42
CRDT- 2024/01/13 18:09
PHST- 2023/12/26 00:00 [received]
PHST- 2023/12/31 00:00 [accepted]
PHST- 2024/03/08 06:42 [medline]
PHST- 2024/01/14 12:42 [pubmed]
PHST- 2024/01/13 18:09 [entrez]
AID - S1876-2018(23)00463-X [pii]
AID - 10.1016/j.ajp.2023.103906 [doi]
PST - ppublish
SO  - Asian J Psychiatr. 2024 Mar;93:103906. doi: 10.1016/j.ajp.2023.103906. Epub 2024 
      Jan 2.

PMID- 38555637
OWN - NLM
STAT- Publisher
LR  - 20240331
IS  - 1423-0399 (Electronic)
IS  - 0042-1138 (Linking)
DP  - 2024 Mar 30
TI  - Evaluating the Efficacy of AI Chatbots as Tutors in Urology: A Comparative 
      Analysis of Responses to the 2022 In-Service Assessment of the European Board of 
      Urology.
LID - 10.1159/000537854 [doi]
AB  - INTRODUCTION: This study assessed the potential of Large Language Models (LLMs) 
      as educational tools by evaluating their accuracy in answering questions across 
      urological subtopics. METHODS: Three LLMs (ChatGPT-3.5, ChatGPT-4, and Bing AI) 
      were examined in two testing rounds, separated by 48-hours, using 100 
      Multiple-Choice Questions (MCQs) from the 2022 European Board of Urology (EBU) 
      In-Service Assessment (ISA), covering five different subtopics. The correct 
      answer was defined as "formal accuracy" (FA) representing the designated single 
      best answer (SBA) among four options. Alternative answers selected from LLMs, 
      which may not necessarily be the SBA but are still deemed correct, were labeled 
      as "extended accuracy" (EA). Their capacity to enhance the overall accuracy rate 
      when combined with FA was examined. RESULTS: In two rounds of testing, the FAs 
      scores were achieved as follows: ChatGPT-3.5: 58% and 62%, ChatGPT-4: 63% and 
      77%, and BING AI: 81% and 73%. The incorporation of EA did not yield a 
      significant enhancement in overall performance. The achieved gains for 
      ChatGPT-3.5, ChatGPT-4, and BING AI were as a result 7% and 5%, 5% and 2%, and 3% 
      and 1%, respectively (p&gt;0.3). Within urological subtopics, LLMs showcased best 
      performance in Pediatrics/Congenital and comparatively less effectiveness in 
      Functional/BPS/Incontinence. CONCLUSION: LLMs exhibit suboptimal urology 
      knowledge and unsatisfactory proficiency for educational purposes. The overall 
      accuracy did not significantly improve when combining EA to FA. The error rates 
      remained high ranging from 16 to 35%. Proficiency levels vary substantially 
      across subtopics. Further development of medicine specific LLMs is required 
      before integration into urological training programs.
CI  - The Author(s). Published by S. Karger AG, Basel.
FAU - May, Matthias
AU  - May M
FAU - Körner-Riffard, Katharina
AU  - Körner-Riffard K
FAU - Kollitsch, Lisa
AU  - Kollitsch L
FAU - Burger, Maximilian
AU  - Burger M
FAU - Brookman-May, Sabine D
AU  - Brookman-May SD
FAU - Rauchenwald, Michael
AU  - Rauchenwald M
FAU - Marszalek, Martin
AU  - Marszalek M
FAU - Eredics, Klaus
AU  - Eredics K
LA  - eng
PT  - Journal Article
DEP - 20240330
PL  - Switzerland
TA  - Urol Int
JT  - Urologia internationalis
JID - 0417373
SB  - IM
EDAT- 2024/04/01 00:42
MHDA- 2024/04/01 00:42
CRDT- 2024/03/31 18:23
PHST- 2023/11/20 00:00 [received]
PHST- 2024/01/17 00:00 [accepted]
PHST- 2024/04/01 00:42 [medline]
PHST- 2024/04/01 00:42 [pubmed]
PHST- 2024/03/31 18:23 [entrez]
AID - 000537854 [pii]
AID - 10.1159/000537854 [doi]
PST - aheadofprint
SO  - Urol Int. 2024 Mar 30. doi: 10.1159/000537854.

PMID- 38449683
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240308
IS  - 2055-2076 (Print)
IS  - 2055-2076 (Electronic)
IS  - 2055-2076 (Linking)
VI  - 10
DP  - 2024 Jan-Dec
TI  - Exploring the proficiency of ChatGPT-4: An evaluation of its performance in the 
      Taiwan advanced medical licensing examination.
PG  - 20552076241237678
LID - 10.1177/20552076241237678 [doi]
LID - 20552076241237678
AB  - BACKGROUND: Taiwan is well-known for its quality healthcare system. The country's 
      medical licensing exams offer a way to evaluate ChatGPT's medical proficiency. 
      METHODS: We analyzed exam data from February 2022, July 2022, February 2023, and 
      July 2033. Each exam included four papers with 80 single-choice questions, 
      grouped as descriptive or picture-based. We used ChatGPT-4 for evaluation. 
      Incorrect answers prompted a "chain of thought" approach. Accuracy rates were 
      calculated as percentages. RESULTS: ChatGPT-4's accuracy in medical exams ranged 
      from 63.75% to 93.75% (February 2022-July 2023). The highest accuracy (93.75%) 
      was in February 2022's Medicine Exam (3). Subjects with the highest misanswered 
      rates were ophthalmology (28.95%), breast surgery (27.27%), plastic surgery 
      (26.67%), orthopedics (25.00%), and general surgery (24.59%). While using "chain 
      of thought," the "Accuracy of (CoT) prompting" ranged from 0.00% to 88.89%, and 
      the final overall accuracy rate ranged from 90% to 98%. CONCLUSION: ChatGPT-4 
      succeeded in Taiwan's medical licensing exams. With the "chain of thought" 
      prompt, it improved accuracy to over 90%.
CI  - © The Author(s) 2024.
FAU - Lin, Shih-Yi
AU  - Lin SY
AD  - Graduate Institute of Clinical Medical Science, College of Medicine, China 
      Medical University, Taichung, Taiwan.
AD  - Division of Nephrology and Kidney Institute, China Medical University Hospital, 
      Taichung, Taiwan. RINGGOLD: 38020
FAU - Chan, Pak Ki
AU  - Chan PK
AD  - Artificial Intelligence Center, China Medical University Hospital, Taichung, 
      Taiwan. RINGGOLD: 38020
FAU - Hsu, Wu-Huei
AU  - Hsu WH
AD  - Graduate Institute of Clinical Medical Science, College of Medicine, China 
      Medical University, Taichung, Taiwan.
AD  - Department of Chest Medicine, China Medical University Hospital, Taichung, 
      Taiwan. RINGGOLD: 38020
FAU - Kao, Chia-Hung
AU  - Kao CH
AUID- ORCID: 0000-0002-6368-3676
AD  - Graduate Institute of Clinical Medical Science, College of Medicine, China 
      Medical University, Taichung, Taiwan.
AD  - Artificial Intelligence Center, China Medical University Hospital, Taichung, 
      Taiwan. RINGGOLD: 38020
AD  - Department of Nuclear Medicine and PET Center, China Medical University Hospital, 
      Taichung, Taiwan. RINGGOLD: 38020
AD  - Department of Bioinformatics and Medical Engineering, Asia University, Taichung, 
      Taiwan.
LA  - eng
PT  - Journal Article
DEP - 20240305
PL  - United States
TA  - Digit Health
JT  - Digital health
JID - 101690863
PMC - PMC10916498
OTO - NOTNLM
OT  - ChatGPT-4
OT  - Taiwan's medical licensing exams
OT  - chain of thought
OT  - healthcare system
COIS- The authors declared no potential conflicts of interest with respect to the 
      research, authorship, and/or publication of this article.
EDAT- 2024/03/07 06:43
MHDA- 2024/03/07 06:44
PMCR- 2024/03/05
CRDT- 2024/03/07 04:05
PHST- 2024/02/20 00:00 [accepted]
PHST- 2024/03/07 06:44 [medline]
PHST- 2024/03/07 06:43 [pubmed]
PHST- 2024/03/07 04:05 [entrez]
PHST- 2024/03/05 00:00 [pmc-release]
AID - 10.1177_20552076241237678 [pii]
AID - 10.1177/20552076241237678 [doi]
PST - epublish
SO  - Digit Health. 2024 Mar 5;10:20552076241237678. doi: 10.1177/20552076241237678. 
      eCollection 2024 Jan-Dec.

PMID- 38169077
OWN - NLM
STAT- Publisher
LR  - 20240103
IS  - 1468-1293 (Electronic)
IS  - 1464-2662 (Linking)
DP  - 2024 Jan 2
TI  - The role of an artificial intelligence model in antiretroviral therapy 
      counselling and advice for people living with HIV.
LID - 10.1111/hiv.13604 [doi]
AB  - OBJECTIVES: People living with HIV may find personalized access to accurate 
      information on antiretroviral therapy (ART) challenging given the stigma and 
      costs potentially associated with attending physical consultations. Artificial 
      intelligence (AI) chatbots such as ChatGPT may help to lower barriers to 
      accessing information addressing concerns around ART initiation. However, the 
      safety and accuracy of the information provided remains to be studied. METHODS: 
      We instructed ChatGPT to answer questions that people living with HIV frequently 
      ask about ART, covering i) knowledge of and access to ART; ii) ART initiation, 
      side effects, and adherence, and iii) general sexual health practices while 
      receiving ART. We checked the accuracy of the advice against international HIV 
      clinical practice guidelines. RESULTS: ChatGPT answered all questions accurately 
      and comprehensively. It recognized potentially life-threatening scenarios such as 
      abacavir hypersensitivity reaction and gave appropriate advice. However, in 
      certain contexts, such as specific geographic locations or for pregnant 
      individuals, the advice lacked specificity to an individual's unique 
      circumstances and may be inadequate. Nevertheless, ChatGPT consistently 
      re-directed the individual to seek help from a healthcare professional to obtain 
      targeted advice. CONCLUSIONS: ChatGPT may act as a useful adjunct in the process 
      of ART counselling for people living with HIV. Improving access to information on 
      and knowledge about ART may improve access and adherence to ART and outcomes for 
      people living with HIV overall.
CI  - © 2024 British HIV Association.
FAU - Koh, Matthew Chung Yi
AU  - Koh MCY
AD  - Division of Infectious Diseases, Department of Medicine, National University 
      Hospital, National University Health System, Singapore, Singapore.
FAU - Ngiam, Jinghao Nicholas
AU  - Ngiam JN
AUID- ORCID: 0000-0002-3339-7281
AD  - Division of Infectious Diseases, Department of Medicine, National University 
      Hospital, National University Health System, Singapore, Singapore.
FAU - Yong, Joy
AU  - Yong J
AD  - Department of Pharmacy, National University Health System, Singapore, Singapore.
FAU - Tambyah, Paul Anantharajah
AU  - Tambyah PA
AD  - Division of Infectious Diseases, Department of Medicine, National University 
      Hospital, National University Health System, Singapore, Singapore.
AD  - Department of Medicine, Yong Loo Lin School of Medicine, National University of 
      Singapore, Singapore, Singapore.
AD  - Infectious Diseases Translational Research Programme, Department of Medicine, 
      Yong Loo Lin School of Medicine, National University of Singapore, Singapore, 
      Singapore.
FAU - Archuleta, Sophia
AU  - Archuleta S
AD  - Division of Infectious Diseases, Department of Medicine, National University 
      Hospital, National University Health System, Singapore, Singapore.
AD  - Department of Medicine, Yong Loo Lin School of Medicine, National University of 
      Singapore, Singapore, Singapore.
LA  - eng
PT  - Journal Article
DEP - 20240102
PL  - England
TA  - HIV Med
JT  - HIV medicine
JID - 100897392
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - anti-retroviral therapy
OT  - artificial intelligence
OT  - counselling
OT  - education
OT  - human immunodeficiency virus
EDAT- 2024/01/04 01:18
MHDA- 2024/01/04 01:18
CRDT- 2024/01/03 11:14
PHST- 2023/11/22 00:00 [received]
PHST- 2023/12/14 00:00 [accepted]
PHST- 2024/01/04 01:18 [medline]
PHST- 2024/01/04 01:18 [pubmed]
PHST- 2024/01/03 11:14 [entrez]
AID - 10.1111/hiv.13604 [doi]
PST - aheadofprint
SO  - HIV Med. 2024 Jan 2. doi: 10.1111/hiv.13604.

PMID- 38361805
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240217
IS  - 2398-8835 (Electronic)
IS  - 2398-8835 (Linking)
VI  - 7
IP  - 2
DP  - 2024 Feb
TI  - ChatGPT and mental health: Friends or foes?
PG  - e1912
LID - 10.1002/hsr2.1912 [doi]
LID - e1912
AB  - BACKGROUND: ChatGPT is an artificial intelligence (AI) language model that has 
      gained popularity as a virtual assistant because of its exceptional capacity to 
      solve problems and make decisions. However, there are some ways in which 
      technological misuse and incorrect interpretations can have potentially hazardous 
      consequences for a user's mental health. DISCUSSION: Because it lacks real-time 
      fact-checking capabilities, ChatGPT may create misleading or erroneous 
      information. Considering AI technology has the potential to influence a person's 
      thinking, we anticipate ChatGPT's future repercussions on mental health by 
      considering instances in which inappropriate usage may lead to mental disorders. 
      While several studies have demonstrated how the AI model may transform mental 
      health care and therapy, certain drawbacks, including bias and privacy 
      violations, have also been identified. CONCLUSION: Educating people and 
      organizing workshops on AI technology usage, strengthening privacy measures, and 
      updating ethical standards are crucial initiatives to prevent misuse and 
      resultant dire impacts on mental health. Longitudinal research on the potential 
      of these platforms to impact a variety of mental health problems is recommended 
      in the future.
CI  - © 2024 The Authors. Health Science Reports published by Wiley Periodicals LLC.
FAU - Kalam, Khondoker Tashya
AU  - Kalam KT
AD  - Department of Pharmacy, School of Medicine University of Asia Pacific Dhaka 
      Bangladesh.
FAU - Rahman, Jannatul Mabia
AU  - Rahman JM
AD  - Department of Electrical and Electronic Engineering University of Asia Pacific 
      Dhaka Bangladesh.
FAU - Islam, Md Rabiul
AU  - Islam MR
AUID- ORCID: 0000-0003-2820-3144
AD  - School of Pharmacy BRAC University Dhaka Bangladesh.
FAU - Dewan, Syed Masudur Rahman
AU  - Dewan SMR
AUID- ORCID: 0000-0003-1443-7150
AD  - Department of Pharmacy, School of Medicine University of Asia Pacific Dhaka 
      Bangladesh.
LA  - eng
PT  - Journal Article
DEP - 20240215
PL  - United States
TA  - Health Sci Rep
JT  - Health science reports
JID - 101728855
PMC - PMC10867692
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - depression
OT  - mental health
OT  - suicide
COIS- The authors declare no conflict of interest.
EDAT- 2024/02/16 06:42
MHDA- 2024/02/16 06:43
PMCR- 2024/02/15
CRDT- 2024/02/16 03:48
PHST- 2023/09/12 00:00 [received]
PHST- 2023/11/30 00:00 [revised]
PHST- 2024/01/31 00:00 [accepted]
PHST- 2024/02/16 06:43 [medline]
PHST- 2024/02/16 06:42 [pubmed]
PHST- 2024/02/16 03:48 [entrez]
PHST- 2024/02/15 00:00 [pmc-release]
AID - HSR21912 [pii]
AID - 10.1002/hsr2.1912 [doi]
PST - epublish
SO  - Health Sci Rep. 2024 Feb 15;7(2):e1912. doi: 10.1002/hsr2.1912. eCollection 2024 
      Feb.

PMID- 37430793
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20230711
LR  - 20230718
IS  - 1424-8220 (Electronic)
IS  - 1424-8220 (Linking)
VI  - 23
IP  - 10
DP  - 2023 May 18
TI  - Can ChatGPT Help in Electronics Research and Development? A Case Study with 
      Applied Sensors.
LID - 10.3390/s23104879 [doi]
LID - 4879
AB  - In this paper, we investigated the applicability of ChatGPT AI in electronics 
      research and development via a case study of applied sensors in embedded 
      electronic systems, a topic that is rarely mentioned in the recent literature, 
      thus providing new insight for professionals and academics. The initial 
      electronics-development tasks of a smart home project were prompted to the 
      ChatGPT system to find out its capabilities and limitations. We wanted to obtain 
      detailed information on the central processing controller units and the actual 
      sensors usable for the specific project, their specifications and recommendations 
      on the hardware and software design flow additionally. Furthermore, an extensive 
      literature survey was requested to see if the bot could offer scientific papers 
      covering the given topic. It was found that the ChatGPT responded with proper 
      recommendations on controllers. However, the suggested sensor units, the hardware 
      and software design were only partially acceptable, with occasional errors in 
      specifications and generated code. The results of the literature survey showed 
      that non-acceptable, fabricated citations (fake authors list, title, journal 
      details and DOI-Digital Object identifier) were presented by the bot. The paper 
      provides a detailed qualitative analysis, a performance analysis and critical 
      discussion of the aforementioned aspects while providing the query set, the 
      generated answers and codes as supplied data with the goal to give added value to 
      electronics researchers and developers if trying to reach out for the tools in 
      their profession.
FAU - Tafferner, Zoltán
AU  - Tafferner Z
AD  - Department of Electronics Technology, Faculty of Electrical Engineering and 
      Informatics, Budapest University of Technology and Economics, H-1111 Budapest, 
      Hungary.
FAU - Balázs, Illés
AU  - Balázs I
AUID- ORCID: 0000-0002-8619-5472
AD  - Department of Electronics Technology, Faculty of Electrical Engineering and 
      Informatics, Budapest University of Technology and Economics, H-1111 Budapest, 
      Hungary.
AD  - LTCC Technology Research Group, Łukasiewicz Research Network-Institute of 
      Microelectronics and Photonics, 02-255 Kraków, Poland.
FAU - Krammer, Olivér
AU  - Krammer O
AD  - Department of Electronics Technology, Faculty of Electrical Engineering and 
      Informatics, Budapest University of Technology and Economics, H-1111 Budapest, 
      Hungary.
FAU - Géczy, Attila
AU  - Géczy A
AD  - Department of Electronics Technology, Faculty of Electrical Engineering and 
      Informatics, Budapest University of Technology and Economics, H-1111 Budapest, 
      Hungary.
LA  - eng
PT  - Journal Article
DEP - 20230518
PL  - Switzerland
TA  - Sensors (Basel)
JT  - Sensors (Basel, Switzerland)
JID - 101204366
SB  - IM
PMC - PMC10221460
OTO - NOTNLM
OT  - ChatGPT
OT  - IoT
OT  - development
OT  - electronics
OT  - engineering
OT  - generative large language model
OT  - sensors
COIS- The authors declare no conflict of interest.
EDAT- 2023/07/11 06:42
MHDA- 2023/07/11 06:43
PMCR- 2023/05/18
CRDT- 2023/07/11 01:03
PHST- 2023/04/06 00:00 [received]
PHST- 2023/05/05 00:00 [revised]
PHST- 2023/05/12 00:00 [accepted]
PHST- 2023/07/11 06:43 [medline]
PHST- 2023/07/11 06:42 [pubmed]
PHST- 2023/07/11 01:03 [entrez]
PHST- 2023/05/18 00:00 [pmc-release]
AID - s23104879 [pii]
AID - sensors-23-04879 [pii]
AID - 10.3390/s23104879 [doi]
PST - epublish
SO  - Sensors (Basel). 2023 May 18;23(10):4879. doi: 10.3390/s23104879.

PMID- 38239420
OWN - NLM
STAT- MEDLINE
DCOM- 20240122
LR  - 20240312
IS  - 2501-2533 (Electronic)
IS  - 2457-4325 (Print)
IS  - 2457-4325 (Linking)
VI  - 67
IP  - 4
DP  - 2023 Oct-Dec
TI  - Assessing the Competence of Artificial Intelligence Programs in Pediatric 
      Ophthalmology and Strabismus and Comparing their Relative Advantages.
PG  - 389-393
LID - 10.22336/rjo.2023.61 [doi]
AB  - Objective: The aim of the study was to determine the knowledge levels of ChatGPT, 
      Bing, and Bard artificial intelligence programs produced by three different 
      manufacturers regarding pediatric ophthalmology and strabismus and to compare 
      their strengths and weaknesses. Methods: Forty-four questions testing the 
      knowledge levels of pediatric ophthalmology and strabismus were asked in ChatGPT, 
      Bing, and Bard artificial intelligence programs. Questions were grouped as 
      correct or incorrect. The accuracy rates were statistically compared. Results: 
      ChatGPT chatbot gave 59.1% correct answers, Bing chatbot gave 70.5% correct 
      answers, and Bard chatbot gave 72.7% correct answers to the questions asked. No 
      significant difference was observed between the rates of correct answers to the 
      questions in all 3 artificial intelligence programs (p=0.343, Pearson's 
      chi-square test). Conclusion: Although information about pediatric ophthalmology 
      and strabismus can be accessed using current artificial intelligence programs, 
      the answers given may not always be accurate. Care should always be taken when 
      evaluating this information.
CI  - #x00A9; The Authors.Romanian Society of Ophthalmology.
FAU - Sensoy, Eyupcan
AU  - Sensoy E
AD  - Department of Ophthalmology, Ankara Etlik City Hospital, Ankara, Turkey.
FAU - Citirik, Mehmet
AU  - Citirik M
AD  - Department of Ophthalmology, Ankara Etlik City Hospital, Ankara, Turkey.
LA  - eng
PT  - Journal Article
PL  - Romania
TA  - Rom J Ophthalmol
JT  - Romanian journal of ophthalmology
JID - 101677459
SB  - IM
MH  - Child
MH  - Humans
MH  - Artificial Intelligence
MH  - *Ophthalmology
MH  - *Strabismus/therapy
PMC - PMC10793362
OTO - NOTNLM
OT  - Bard
OT  - Bing
OT  - ChatGPT
OT  - artificial intelligence
OT  - pediatric ophthalmology
EDAT- 2024/01/19 06:42
MHDA- 2024/01/22 06:41
PMCR- 2023/10/01
CRDT- 2024/01/19 03:39
PHST- 2023/11/26 00:00 [accepted]
PHST- 2024/01/22 06:41 [medline]
PHST- 2024/01/19 06:42 [pubmed]
PHST- 2024/01/19 03:39 [entrez]
PHST- 2023/10/01 00:00 [pmc-release]
AID - RomJOphthalmol-67-389 [pii]
AID - 10.22336/rjo.2023.61 [doi]
PST - ppublish
SO  - Rom J Ophthalmol. 2023 Oct-Dec;67(4):389-393. doi: 10.22336/rjo.2023.61.

PMID- 37846274
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231020
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 9
DP  - 2023 Sep
TI  - The Significance of Artificial Intelligence Platforms in Anatomy Education: An 
      Experience With ChatGPT and Google Bard.
PG  - e45301
LID - 10.7759/cureus.45301 [doi]
LID - e45301
AB  - This study evaluated the use of two large language models (LLMs), ChatGPT and 
      Google Bard, in anatomy education. The models were asked to answer questions, 
      generate multiple-choice questions, and write articles on anatomy topics. The 
      results showed that the models were able to perform these tasks with varying 
      degrees of accuracy. ChatGPT and Google Bard did not differ significantly in 
      terms of answering questions. Both models were able to generate multiple-choice 
      questions with a high degree of accuracy. However, the performance of the models 
      in article writing was not yet at a sufficient level. The study also found that 
      the use of LLMs in medical education requires caution. This is because LLMs are 
      still under development and they can sometimes generate inaccurate or misleading 
      information. It is important to carefully evaluate the output of LLMs before 
      using them in educational settings. Overall, the study found that LLMs have the 
      potential to be valuable tools for anatomy education. However, more research is 
      needed to improve the accuracy of the models and to better understand how they 
      can be used effectively in educational settings.
CI  - Copyright © 2023, Ilgaz et al.
FAU - Ilgaz, Hasan B
AU  - Ilgaz HB
AD  - Anatomy, Hacettepe University Faculty of Medicine, Ankara, TUR.
FAU - Çelik, Zehra
AU  - Çelik Z
AD  - Anatomy, Hacettepe University Faculty of Medicine, Ankara, TUR.
LA  - eng
PT  - Journal Article
DEP - 20230915
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10576957
OTO - NOTNLM
OT  - anatomy education
OT  - artificial intelligence
OT  - chatgpt
OT  - google bard
OT  - large language models
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/10/17 06:42
MHDA- 2023/10/17 06:43
PMCR- 2023/09/15
CRDT- 2023/10/17 03:50
PHST- 2023/09/15 00:00 [accepted]
PHST- 2023/10/17 06:43 [medline]
PHST- 2023/10/17 06:42 [pubmed]
PHST- 2023/10/17 03:50 [entrez]
PHST- 2023/09/15 00:00 [pmc-release]
AID - 10.7759/cureus.45301 [doi]
PST - epublish
SO  - Cureus. 2023 Sep 15;15(9):e45301. doi: 10.7759/cureus.45301. eCollection 2023 
      Sep.

PMID- 38502320
OWN - NLM
STAT- Publisher
LR  - 20240319
IS  - 1432-1076 (Electronic)
IS  - 0340-6199 (Linking)
DP  - 2024 Mar 19
TI  - Screening/diagnosis of pediatric endocrine disorders through the artificial 
      intelligence model in different language settings.
LID - 10.1007/s00431-024-05527-1 [doi]
AB  - This study is aimed at examining the impact of ChatGPT on pediatric endocrine and 
      metabolic conditions, particularly in the areas of screening and diagnosis, in 
      both Chinese and English modes. A 40-question questionnaire covering the four 
      most common pediatric endocrine and metabolic conditions was posed to ChatGPT in 
      both Chinese and English three times each. Six pediatric endocrinologists 
      evaluated the responses. ChatGPT performed better when responding to questions in 
      English, with an unreliable rate of 7.5% compared to 27.5% for Chinese questions, 
      indicating a more consistent response pattern in English. Among the reliable 
      questions, the answers were more comprehensive and satisfactory in the English 
      mode. We also found disparities in ChatGPT's performance when interacting with 
      different target groups and diseases, with improved performance for questions 
      posed by clinicians in English and better performance for questions related to 
      diabetes and overweight/obesity in Chinese for both clinicians and patients. 
      Language comprehension, providing incomprehensive answers, and errors in key data 
      were the main contributors to the low scores, according to reviewer feedback. 
      CONCLUSION: Despite these limitations, as ChatGPT continues to evolve and expand 
      its network, it has significant potential as a practical and effective tool for 
      clinical diagnosis and treatment. WHAT IS KNOWN: • The deep learning-based 
      large-language model ChatGPT holds great promise for improving clinical practice 
      for both physicians and patients and has the potential to increase the speed and 
      accuracy of disease screening and diagnosis, as well as enhance the overall 
      efficiency of the medical process. However, the reliability and appropriateness 
      of AI model responses in specific field remains unclear. • This study focused on 
      the reliability and appropriateness of AI model responses to straightforward and 
      fundamental questions related to the four most prevalent pediatric endocrine and 
      metabolic disorders, for both healthcare providers and patients, in different 
      language scenarios. WHAT IS NEW: • The AI model performed better when responding 
      to questions in English, with more consistent, as well as more comprehensive and 
      satisfactory responses. In addition, we also found disparities in ChatGPT's 
      performance when interacting with different target groups and different diseases. 
      • Despite these limitations, as ChatGPT continues to evolve and expand its 
      network, it has significant potential as a practical and effective tool for 
      clinical diagnosis and treatment.
CI  - © 2024. The Author(s).
FAU - Ying, Lingwen
AU  - Ying L
AD  - Department of Endocrinology and Metabolism, Shanghai Children's Medical Center, 
      School of Medicine, Shanghai Jiao Tong University, Shanghai, 200127, China.
FAU - Li, Sichen
AU  - Li S
AD  - Department of Neurosurgery, Huashan Hospital, Shanghai Medical College, Fudan 
      University, Shanghai, 200040, China.
AD  - National Center for Neurological Disorders, Shanghai Key Laboratory of Brain 
      Function and Restoration and Neural Regeneration, Neurosurgical Institute of 
      Fudan University, Shanghai Clinical Medical Center of Neurosurgery, Shanghai, 
      200040, China.
FAU - Chen, Chunyang
AU  - Chen C
AD  - Faculty of Information Technology, Monash University, Clayton, VIC, 3800, 
      Australia.
FAU - Yang, Fan
AU  - Yang F
AD  - Department of Endocrinology and Metabolism, Shanghai Children's Medical Center, 
      School of Medicine, Shanghai Jiao Tong University, Shanghai, 200127, China.
FAU - Li, Xin
AU  - Li X
AD  - Department of Endocrinology and Metabolism, Shanghai Children's Medical Center, 
      School of Medicine, Shanghai Jiao Tong University, Shanghai, 200127, China.
FAU - Chen, Yao
AU  - Chen Y
AD  - Department of Endocrinology and Metabolism, Shanghai Children's Medical Center, 
      School of Medicine, Shanghai Jiao Tong University, Shanghai, 200127, China.
FAU - Ding, Yu
AU  - Ding Y
AD  - Department of Endocrinology and Metabolism, Shanghai Children's Medical Center, 
      School of Medicine, Shanghai Jiao Tong University, Shanghai, 200127, China.
FAU - Chang, Guoying
AU  - Chang G
AUID- ORCID: 0000-0003-0701-3544
AD  - Department of Endocrinology and Metabolism, Shanghai Children's Medical Center, 
      School of Medicine, Shanghai Jiao Tong University, Shanghai, 200127, China. 
      wangxiumin1019@126.com.
FAU - Li, Juan
AU  - Li J
AD  - Department of Endocrinology and Metabolism, Shanghai Children's Medical Center, 
      School of Medicine, Shanghai Jiao Tong University, Shanghai, 200127, China.
FAU - Wang, Xiumin
AU  - Wang X
AUID- ORCID: 0000-0002-2186-759X
AD  - Department of Endocrinology and Metabolism, Shanghai Children's Medical Center, 
      School of Medicine, Shanghai Jiao Tong University, Shanghai, 200127, China. 
      changguoying@126.com.
LA  - eng
PT  - Journal Article
DEP - 20240319
PL  - Germany
TA  - Eur J Pediatr
JT  - European journal of pediatrics
JID - 7603873
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Language mode
OT  - Pediatric endocrine and metabolism
OT  - Physician and patients
OT  - Screening and diagnosis
EDAT- 2024/03/19 18:42
MHDA- 2024/03/19 18:42
CRDT- 2024/03/19 12:13
PHST- 2024/02/20 00:00 [received]
PHST- 2024/03/14 00:00 [accepted]
PHST- 2024/03/12 00:00 [revised]
PHST- 2024/03/19 18:42 [medline]
PHST- 2024/03/19 18:42 [pubmed]
PHST- 2024/03/19 12:13 [entrez]
AID - 10.1007/s00431-024-05527-1 [pii]
AID - 10.1007/s00431-024-05527-1 [doi]
PST - aheadofprint
SO  - Eur J Pediatr. 2024 Mar 19. doi: 10.1007/s00431-024-05527-1.

PMID- 37385685
OWN - NLM
STAT- MEDLINE
DCOM- 20230712
LR  - 20231214
IS  - 1975-5937 (Electronic)
IS  - 1975-5937 (Linking)
VI  - 20
DP  - 2023
TI  - Comparing ChatGPT’s ability to rate the degree of stereotypes and the consistency 
      of stereotype attribution with those of medical students in New Zealand in 
      developing a similarity rating test: a methodological study.
PG  - 17
LID - 10.3352/jeehp.2023.20.17 [doi]
LID - 17
AB  - Learning about one’s implicit bias is crucial for improving one’s cultural 
      competency and thereby reducing health inequity. To evaluate bias among medical 
      students following a previously developed cultural training program targeting New 
      Zealand Māori, we developed a text-based, self-evaluation tool called the 
      Similarity Rating Test (SRT). The development process of the SRT was 
      resource-intensive, limiting its generalizability and applicability. Here, we 
      explored the potential of ChatGPT, an automated chatbot, to assist in the 
      development process of the SRT by comparing ChatGPT’s and students’ evaluations 
      of the SRT. Despite results showing non-significant equivalence and difference 
      between ChatGPT’s and students’ ratings, ChatGPT’s ratings were more consistent 
      than students’ ratings. The consistency rate was higher for non-stereotypical 
      than for stereotypical statements, regardless of rater type. Further studies are 
      warranted to validate ChatGPT’s potential for assisting in SRT development for 
      implementation in medical education and evaluation of ethnic stereotypes and 
      related topics.
FAU - Lin, Chao-Cheng
AU  - Lin CC
AD  - Department of Psychological Medicine, Dunedin School of Medicine, The University 
      of Otago, Dunedin, New Zealand.
AD  - Department of Psychiatry, National Taiwan University College of Medicine, Taipei, 
      Taiwan.
FAU - Akuhata-Huntington, Zaine
AU  - Akuhata-Huntington Z
AD  - Kōhatu Centre for Hauora Māori, Dunedin School of Medicine, The University of 
      Otago, Dunedin, New Zealand.
FAU - Hsu, Che-Wei
AU  - Hsu CW
AD  - Department of Psychological Medicine, Dunedin School of Medicine, The University 
      of Otago, Dunedin, New Zealand.
LA  - eng
PT  - Comparative Study
PT  - Journal Article
DEP - 20230612
PL  - Korea (South)
TA  - J Educ Eval Health Prof
JT  - Journal of educational evaluation for health professions
JID - 101490061
SB  - IM
MH  - Humans
MH  - *Cultural Competency/education/psychology
MH  - *Education, Medical/methods
MH  - *Maori People
MH  - New Zealand
MH  - *Students, Medical/psychology
MH  - *Artificial Intelligence
MH  - Stereotyping
MH  - *Bias, Implicit
PMC - PMC10356547
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Cultural competency
OT  - Implicit bias
OT  - Medical education
OT  - New Zealand
COIS- Conflict of interest No potential conflict of interest relevant to this article 
      was reported.
EDAT- 2023/06/30 01:06
MHDA- 2023/07/03 06:41
PMCR- 2023/06/12
CRDT- 2023/06/29 20:53
PHST- 2023/05/16 00:00 [received]
PHST- 2023/05/30 00:00 [accepted]
PHST- 2023/07/03 06:41 [medline]
PHST- 2023/06/30 01:06 [pubmed]
PHST- 2023/06/29 20:53 [entrez]
PHST- 2023/06/12 00:00 [pmc-release]
AID - jeehp.2023.20.17 [pii]
AID - jeehp-20-17 [pii]
AID - 10.3352/jeehp.2023.20.17 [doi]
PST - ppublish
SO  - J Educ Eval Health Prof. 2023;20:17. doi: 10.3352/jeehp.2023.20.17. Epub 2023 Jun 
      12.

PMID- 37285018
OWN - NLM
STAT- MEDLINE
DCOM- 20230731
LR  - 20231116
IS  - 1434-4726 (Electronic)
IS  - 0937-4477 (Print)
IS  - 0937-4477 (Linking)
VI  - 280
IP  - 9
DP  - 2023 Sep
TI  - ChatGPT's quiz skills in different otolaryngology subspecialties: an analysis of 
      2576 single-choice and multiple-choice board certification preparation questions.
PG  - 4271-4278
LID - 10.1007/s00405-023-08051-4 [doi]
AB  - PURPOSE: With the increasing adoption of artificial intelligence (AI) in various 
      domains, including healthcare, there is growing acceptance and interest in 
      consulting AI models to provide medical information and advice. This study aimed 
      to evaluate the accuracy of ChatGPT's responses to practice quiz questions 
      designed for otolaryngology board certification and decipher potential 
      performance disparities across different otolaryngology subspecialties. METHODS: 
      A dataset covering 15 otolaryngology subspecialties was collected from an online 
      learning platform funded by the German Society of Oto-Rhino-Laryngology, Head and 
      Neck Surgery, designed for board certification examination preparation. These 
      questions were entered into ChatGPT, with its responses being analyzed for 
      accuracy and variance in performance. RESULTS: The dataset included 2576 
      questions (479 multiple-choice and 2097 single-choice), of which 57% (n = 1475) 
      were answered correctly by ChatGPT. An in-depth analysis of question style 
      revealed that single-choice questions were associated with a significantly higher 
      rate (p &lt; 0.001) of correct responses (n = 1313; 63%) compared to multiple-choice 
      questions (n = 162; 34%). Stratified by question categories, ChatGPT yielded the 
      highest rate of correct responses (n = 151; 72%) in the field of allergology, 
      whereas 7 out of 10 questions (n = 65; 71%) on legal otolaryngology aspects were 
      answered incorrectly. CONCLUSION: The study reveals ChatGPT's potential as a 
      supplementary tool for otolaryngology board certification preparation. However, 
      its propensity for errors in certain otolaryngology areas calls for further 
      refinement. Future research should address these limitations to improve ChatGPT's 
      educational use. An approach, with expert collaboration, is recommended for the 
      reliable and accurate integration of such AI models.
CI  - © 2023. The Author(s).
FAU - Hoch, Cosima C
AU  - Hoch CC
AUID- ORCID: 0000-0002-3875-7389
AD  - Department of Otolaryngology, Head and Neck Surgery, School of Medicine, 
      Technical University of Munich (TUM), Ismaningerstrasse 22, 81675, Munich, 
      Germany. cosima.chiara.hoch@tum.de.
FAU - Wollenberg, Barbara
AU  - Wollenberg B
AD  - Department of Otolaryngology, Head and Neck Surgery, School of Medicine, 
      Technical University of Munich (TUM), Ismaningerstrasse 22, 81675, Munich, 
      Germany.
FAU - Lüers, Jan-Christoffer
AU  - Lüers JC
AD  - Department of Otorhinolaryngology, Head and Neck Surgery, Medical Faculty, 
      University of Cologne, 50937, Cologne, Germany.
FAU - Knoedler, Samuel
AU  - Knoedler S
AD  - Division of Plastic Surgery, Brigham and Women's Hospital, Harvard Medical 
      School, Boston, MA, 02152, USA.
AD  - Department of Plastic Surgery and Hand Surgery, Klinikum Rechts Der Isar, 
      Technical University of Munich, Munich, Germany.
FAU - Knoedler, Leonard
AU  - Knoedler L
AD  - Division of Plastic and Reconstructive Surgery, Massachusetts General Hospital, 
      Harvard Medical School, Boston, MA, 02115, USA.
FAU - Frank, Konstantin
AU  - Frank K
AD  - Ocean Clinic, Marbella, Spain.
FAU - Cotofana, Sebastian
AU  - Cotofana S
AD  - Department of Dermatology, Erasmus Hospital, Rotterdam, The Netherlands.
AD  - Centre for Cutaneous Research, Blizard Institute, Queen Mary University of 
      London, London, UK.
FAU - Alfertshofer, Michael
AU  - Alfertshofer M
AD  - Division of Hand, Plastic and Aesthetic Surgery, Ludwig-Maximilians-University 
      Munich, Munich, Germany.
LA  - eng
PT  - Journal Article
DEP - 20230607
PL  - Germany
TA  - Eur Arch Otorhinolaryngol
JT  - European archives of oto-rhino-laryngology : official journal of the European 
      Federation of Oto-Rhino-Laryngological Societies (EUFOS) : affiliated with the 
      German Society for Oto-Rhino-Laryngology - Head and Neck Surgery
JID - 9002937
SB  - IM
CIN - Eur Arch Otorhinolaryngol. 2024 Feb;281(2):1061-1063. PMID: 37955694
MH  - Humans
MH  - *Artificial Intelligence
MH  - Certification
MH  - Educational Status
MH  - *Otolaryngology
MH  - Referral and Consultation
PMC - PMC10382366
OTO - NOTNLM
OT  - AI
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Multiple-choice
OT  - Otolaryngology quiz
OT  - Single-choice
COIS- The authors have no relevant financial or non-financial interests to disclose. 
      Jan-Christoffer Lüers, M.D., Ph.D. is the developer and owner of the online 
      learning platform.
EDAT- 2023/06/07 13:10
MHDA- 2023/07/31 06:42
PMCR- 2023/06/07
CRDT- 2023/06/07 11:13
PHST- 2023/05/23 00:00 [received]
PHST- 2023/05/26 00:00 [accepted]
PHST- 2023/07/31 06:42 [medline]
PHST- 2023/06/07 13:10 [pubmed]
PHST- 2023/06/07 11:13 [entrez]
PHST- 2023/06/07 00:00 [pmc-release]
AID - 10.1007/s00405-023-08051-4 [pii]
AID - 8051 [pii]
AID - 10.1007/s00405-023-08051-4 [doi]
PST - ppublish
SO  - Eur Arch Otorhinolaryngol. 2023 Sep;280(9):4271-4278. doi: 
      10.1007/s00405-023-08051-4. Epub 2023 Jun 7.

PMID- 37339728
OWN - NLM
STAT- MEDLINE
DCOM- 20230926
LR  - 20231214
IS  - 1879-1891 (Electronic)
IS  - 0002-9394 (Linking)
VI  - 254
DP  - 2023 Oct
TI  - Performance of Generative Large Language Models on Ophthalmology Board-Style 
      Questions.
PG  - 141-149
LID - S0002-9394(23)00230-1 [pii]
LID - 10.1016/j.ajo.2023.05.024 [doi]
AB  - PURPOSE: To investigate the ability of generative artificial intelligence models 
      to answer ophthalmology board-style questions. DESIGN: Experimental study. 
      METHODS: This study evaluated 3 large language models (LLMs) with chat 
      interfaces, Bing Chat (Microsoft) and ChatGPT 3.5 and 4.0 (OpenAI), using 250 
      questions from the Basic Science and Clinical Science Self-Assessment Program. 
      Although ChatGPT is trained on information last updated in 2021, Bing Chat 
      incorporates a more recently indexed internet search to generate its answers. 
      Performance was compared with human respondents. Questions were categorized by 
      complexity and patient care phase, and instances of information fabrication or 
      nonlogical reasoning were documented. MAIN OUTCOME MEASURES: Primary outcome was 
      response accuracy. Secondary outcomes were performance in question subcategories 
      and hallucination frequency. RESULTS: Human respondents had an average accuracy 
      of 72.2%. ChatGPT-3.5 scored the lowest (58.8%), whereas ChatGPT-4.0 (71.6%) and 
      Bing Chat (71.2%) performed comparably. ChatGPT-4.0 excelled in workup-type 
      questions (odds ratio [OR], 3.89, 95% CI, 1.19-14.73, P&nbsp;=&nbsp;.03) compared with 
      diagnostic questions, but struggled with image interpretation (OR, 0.14, 95% CI, 
      0.05-0.33, P &lt; .01) when compared with single-step reasoning questions. Against 
      single-step questions, Bing Chat also faced difficulties with image 
      interpretation (OR, 0.18, 95% CI, 0.08-0.44, P &lt; .01) and multi-step reasoning 
      (OR, 0.30, 95% CI, 0.11-0.84, P&nbsp;=&nbsp;.02). ChatGPT-3.5 had the highest rate of 
      hallucinations and nonlogical reasoning (42.4%), followed by ChatGPT-4.0 (18.0%) 
      and Bing Chat (25.6%). CONCLUSIONS: LLMs (particularly ChatGPT-4.0 and Bing Chat) 
      can perform similarly with human respondents answering questions from the Basic 
      Science and Clinical Science Self-Assessment Program. The frequency of 
      hallucinations and nonlogical reasoning suggests room for improvement in the 
      performance of conversational agents in the medical domain.
CI  - Copyright © 2023 Elsevier Inc. All rights reserved.
FAU - Cai, Louis Z
AU  - Cai LZ
AD  - From the Bascom Palmer Eye Institute, Miami, Florida, USA (L.Z.C., A.S., J.S.Y., 
      N.Y., C.A.). Electronic address: louiezcai@gmail.com.
FAU - Shaheen, Abdulla
AU  - Shaheen A
AD  - From the Bascom Palmer Eye Institute, Miami, Florida, USA (L.Z.C., A.S., J.S.Y., 
      N.Y., C.A.).
FAU - Jin, Andrew
AU  - Jin A
AD  - Yale Eye Center, New Haven, Connecticut, USA (A.J.).
FAU - Fukui, Riya
AU  - Fukui R
AD  - Houston Rehabilitation Group, Houston, Texas, USA (R.F.).
FAU - Yi, Jonathan S
AU  - Yi JS
AD  - From the Bascom Palmer Eye Institute, Miami, Florida, USA (L.Z.C., A.S., J.S.Y., 
      N.Y., C.A.).
FAU - Yannuzzi, Nicolas
AU  - Yannuzzi N
AD  - From the Bascom Palmer Eye Institute, Miami, Florida, USA (L.Z.C., A.S., J.S.Y., 
      N.Y., C.A.).
FAU - Alabiad, Chrisfouad
AU  - Alabiad C
AD  - From the Bascom Palmer Eye Institute, Miami, Florida, USA (L.Z.C., A.S., J.S.Y., 
      N.Y., C.A.).
LA  - eng
PT  - Journal Article
DEP - 20230618
PL  - United States
TA  - Am J Ophthalmol
JT  - American journal of ophthalmology
JID - 0370500
SB  - IM
CIN - Am J Ophthalmol. 2023 Dec;256:200. PMID: 37541409
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Ophthalmology
MH  - Language
MH  - Hallucinations/diagnosis
MH  - Internet
EDAT- 2023/06/21 01:07
MHDA- 2023/09/26 13:43
CRDT- 2023/06/20 19:11
PHST- 2023/03/31 00:00 [received]
PHST- 2023/05/27 00:00 [revised]
PHST- 2023/05/28 00:00 [accepted]
PHST- 2023/09/26 13:43 [medline]
PHST- 2023/06/21 01:07 [pubmed]
PHST- 2023/06/20 19:11 [entrez]
AID - S0002-9394(23)00230-1 [pii]
AID - 10.1016/j.ajo.2023.05.024 [doi]
PST - ppublish
SO  - Am J Ophthalmol. 2023 Oct;254:141-149. doi: 10.1016/j.ajo.2023.05.024. Epub 2023 
      Jun 18.

PMID- 36819954
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230224
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 2
DP  - 2023 Feb
TI  - ChatGPT Output Regarding Compulsory Vaccination and COVID-19 Vaccine Conspiracy: 
      A Descriptive Study at the Outset of a Paradigm Shift in Online Search for 
      Information.
PG  - e35029
LID - 10.7759/cureus.35029 [doi]
LID - e35029
AB  - BACKGROUND: Being on the verge of a revolutionary approach to gathering 
      information, ChatGPT (an artificial intelligence (AI)-based language model 
      developed by OpenAI, and capable of producing human-like text) could be the prime 
      motive of a paradigm shift on how humans will acquire information. Despite the 
      concerns related to the use of such a promising tool in relation to the future of 
      the quality of education, this technology will soon be incorporated into web 
      search engines mandating the need to evaluate the output of such a tool. Previous 
      studies showed that dependence on some sources of online information (e.g., 
      social media platforms) was associated with higher rates of vaccination 
      hesitancy. Therefore, the aim of the current study was to describe the output of 
      ChatGPT regarding coronavirus disease 2019 (COVID-19) vaccine conspiracy beliefs. 
      and compulsory vaccination. METHODS: The current descriptive study was conducted 
      on January 14, 2023 using the ChatGPT from OpenAI (OpenAI, L.L.C.,&nbsp;San Francisco, 
      CA, USA). The output was evaluated by two authors and the degree of agreement 
      regarding the correctness, clarity, conciseness, and bias was evaluated using 
      Cohen's kappa. RESULTS: The ChatGPT responses were dismissive of conspiratorial 
      ideas about severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) origins 
      labeling it as non-credible and lacking scientific evidence. Additionally, 
      ChatGPT responses were totally against COVID-19 vaccine conspiracy statements. 
      Regarding compulsory vaccination, ChatGPT responses were neutral citing the 
      following as advantages of this strategy: protecting public health, maintaining 
      herd immunity, reducing the spread of disease, cost-effectiveness, and legal 
      obligation, and on the other hand, it cited the following as disadvantages of 
      compulsory vaccination: ethical and legal concerns, mistrust and resistance, 
      logistical challenges, and limited resources and knowledge. CONCLUSIONS: The 
      current study showed that ChatGPT could be a source of information to challenge 
      COVID-19 vaccine conspiracies. For compulsory vaccination, ChatGPT resonated with 
      the divided opinion in the scientific community toward&nbsp;such a strategy; 
      nevertheless, it detailed the pros and cons of this approach. As it currently 
      stands, the judicious use of ChatGPT could be utilized as a user-friendly source 
      of COVID-19 vaccine information that could challenge conspiracy ideas with clear, 
      concise, and non-biased content. However, ChatGPT content cannot be used as an 
      alternative to the original reliable sources of vaccine information (e.g., the 
      World Health Organization [WHO] and the Centers for Disease Control and 
      Prevention [CDC]).
CI  - Copyright © 2023, Sallam et al.
FAU - Sallam, Malik
AU  - Sallam M
AD  - Department of Pathology, Microbiology and Forensic Medicine, School of Medicine, 
      University of Jordan, Amman, JOR.
AD  - Department of Clinical Laboratories and Forensic Medicine, Jordan University 
      Hospital, Amman, JOR.
FAU - Salim, Nesreen A
AU  - Salim NA
AD  - Department of Prosthodontics, Jordan University Hospital, Amman, JOR.
FAU - Al-Tammemi, Ala'a B
AU  - Al-Tammemi AB
AD  - Infectious Disease, Applied Science Research Center, Applied Science Private 
      University, Amman, JOR.
AD  - Migration Health Division, International Organization for Migration (IOM) The UN 
      Migration Agency, Amman, JOR.
FAU - Barakat, Muna
AU  - Barakat M
AD  - School of Pharmacy, Applied Science Private University, Amman, JOR.
FAU - Fayyad, Diaa
AU  - Fayyad D
AD  - Department of Biological Sciences, Faculty of Science, Yarmouk University, Irbid, 
      JOR.
FAU - Hallit, Souheil
AU  - Hallit S
AD  - Faculty of Medicine and Medical Sciences, Holy Spirit University of Kaslik 
      (USEK), Jounieh, LBN.
FAU - Harapan, Harapan
AU  - Harapan H
AD  - Department of Epidemiology and Public Health, Syiah Kuala University, Banda Aceh, 
      IDN.
FAU - Hallit, Rabih
AU  - Hallit R
AD  - Department of Infectious Disease, School of Medicine and Medical Sciences, Holy 
      Spirit University of Kaslik (USEK), Jounieh, LBN.
FAU - Mahafzah, Azmi
AU  - Mahafzah A
AD  - Department of Pathology, Microbiology and Forensic Medicine, School of Medicine, 
      The University of Jordan, Amman, JOR.
LA  - eng
PT  - Journal Article
DEP - 20230215
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC9931398
OTO - NOTNLM
OT  - artificial intelligence in medicine
OT  - covid-19 vaccine
OT  - machine learning
OT  - mandatory vaccination
OT  - vaccine promotion
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/02/24 06:00
MHDA- 2023/02/24 06:01
PMCR- 2023/02/15
CRDT- 2023/02/23 10:09
PHST- 2023/02/15 00:00 [accepted]
PHST- 2023/02/23 10:09 [entrez]
PHST- 2023/02/24 06:00 [pubmed]
PHST- 2023/02/24 06:01 [medline]
PHST- 2023/02/15 00:00 [pmc-release]
AID - 10.7759/cureus.35029 [doi]
PST - epublish
SO  - Cureus. 2023 Feb 15;15(2):e35029. doi: 10.7759/cureus.35029. eCollection 2023 
      Feb.

PMID- 37980605
OWN - NLM
STAT- MEDLINE
DCOM- 20240318
LR  - 20240402
IS  - 1434-4726 (Electronic)
IS  - 0937-4477 (Linking)
VI  - 281
IP  - 4
DP  - 2024 Apr
TI  - Chat GPT for the management of obstructive sleep apnea: do we have a polar star?
PG  - 2087-2093
LID - 10.1007/s00405-023-08270-9 [doi]
AB  - PURPOSE: This study explores the potential of the Chat-Generative Pre-Trained 
      Transformer (Chat-GPT), a Large Language Model (LLM), in assisting healthcare 
      professionals in the diagnosis of obstructive sleep apnea (OSA). It aims to 
      assess the agreement between Chat-GPT's responses and those of expert 
      otolaryngologists, shedding light on the role of AI-generated content in medical 
      decision-making. METHODS: A prospective, cross-sectional study was conducted, 
      involving 350 otolaryngologists from 25 countries who responded to a specialized 
      OSA survey. Chat-GPT was tasked with providing answers to the same survey 
      questions. Responses were assessed by both super-experts and statistically 
      analyzed for agreement. RESULTS: The study revealed that Chat-GPT and expert 
      responses shared a common answer in over 75% of cases for individual questions. 
      However, the overall consensus was achieved in only four questions. Super-expert 
      assessments showed a moderate agreement level, with Chat-GPT scoring slightly 
      lower than experts. Statistically, Chat-GPT's responses differed significantly 
      from experts' opinions (p = 0.0009). Sub-analysis revealed areas of improvement 
      for Chat-GPT, particularly in questions where super-experts rated its responses 
      lower than expert consensus. CONCLUSIONS: Chat-GPT demonstrates potential as a 
      valuable resource for OSA diagnosis, especially where access to specialists is 
      limited. The study emphasizes the importance of AI-human collaboration, with 
      Chat-GPT serving as a complementary tool rather than a replacement for medical 
      professionals. This research contributes to the discourse in otolaryngology and 
      encourages further exploration of AI-driven healthcare applications. While 
      Chat-GPT exhibits a commendable level of consensus with expert responses, ongoing 
      refinements in AI-based healthcare tools hold significant promise for the future 
      of medicine, addressing the underdiagnosis and undertreatment of OSA and 
      improving patient outcomes.
CI  - © 2023. The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, 
      part of Springer Nature.
FAU - Mira, Felipe Ahumada
AU  - Mira FA
AD  - ENT Department, Hospital of Linares, Linares, Chile.
AD  - Young Otolaryngologists-International Federations of Oto-Rhinolaryngological 
      Societies (YO-IFOS), Paris, France.
FAU - Favier, Valentin
AU  - Favier V
AD  - ENT Department, University Hospital of Montpellier, Montpellier, France.
AD  - Young Otolaryngologists-International Federations of Oto-Rhinolaryngological 
      Societies (YO-IFOS), Paris, France.
FAU - Dos Santos Sobreira Nunes, Heloisa
AU  - Dos Santos Sobreira Nunes H
AD  - ENT and Sleep Medicine Department, Nucleus of Otolaryngology, Head and Neck 
      Surgery and Sleep Medicine of São Paulo, São Paulo, Brazil.
AD  - Young Otolaryngologists-International Federations of Oto-Rhinolaryngological 
      Societies (YO-IFOS), Paris, France.
FAU - de Castro, Joana Vaz
AU  - de Castro JV
AD  - ENT Department, Armed Forces Hospital, Lisbon, Portugal.
AD  - Young Otolaryngologists-International Federations of Oto-Rhinolaryngological 
      Societies (YO-IFOS), Paris, France.
FAU - Carsuzaa, Florent
AU  - Carsuzaa F
AD  - ENT Department, University Hospital of Poitiers, Poitiers, France.
AD  - Young Otolaryngologists-International Federations of Oto-Rhinolaryngological 
      Societies (YO-IFOS), Paris, France.
FAU - Meccariello, Giuseppe
AU  - Meccariello G
AD  - Head and Neck Department, ENT &amp; Oral Surgery Unity, G.B. Morgagni, L. Pierantoni 
      Hospital, Via Forlanini, 47121, Forlì, Italy.
FAU - Vicini, Claudio
AU  - Vicini C
AD  - Head and Neck Department, ENT &amp; Oral Surgery Unity, G.B. Morgagni, L. Pierantoni 
      Hospital, Via Forlanini, 47121, Forlì, Italy.
FAU - De Vito, Andrea
AU  - De Vito A
AD  - Head and Neck Department, ENT &amp; Oral Surgery Unity, G.B. Morgagni, L. Pierantoni 
      Hospital, Via Forlanini, 47121, Forlì, Italy.
FAU - Lechien, Jerome R
AU  - Lechien JR
AD  - Division of Laryngology and Broncho-Esophagology, Department of Otolaryngology 
      and Head and Neck Surgery, EpiCURA Hospital, UMONS Research Institute for Health 
      Sciences and Technology, University of Mons, Mons, Belgium.
AD  - Young Otolaryngologists-International Federations of Oto-Rhinolaryngological 
      Societies (YO-IFOS), Paris, France.
FAU - Chiesa-Estomba, Carlos
AU  - Chiesa-Estomba C
AD  - Department of Otorhinolaryngology, Biodonostia Research Institute, Donostia 
      University Hospital, Osakidetza, 20014, San Sebastian, Spain.
AD  - Young Otolaryngologists-International Federations of Oto-Rhinolaryngological 
      Societies (YO-IFOS), Paris, France.
FAU - Maniaci, Antonino
AU  - Maniaci A
AD  - Department of Medical and Surgical Sciences and Advanced Technologies "GF 
      Ingrassia", ENT Section, University of Catania, Piazza Università 2, 95100, 
      Catania, Italy.
AD  - Young Otolaryngologists-International Federations of Oto-Rhinolaryngological 
      Societies (YO-IFOS), Paris, France.
FAU - Iannella, Giannicola
AU  - Iannella G
AD  - Department of 'Organi di Senso', University "Sapienza", Viale Dell'Università 33, 
      00185, Rome, Italy.
AD  - Young Otolaryngologists-International Federations of Oto-Rhinolaryngological 
      Societies (YO-IFOS), Paris, France.
FAU - Rojas, Eduardo Peña
AU  - Rojas EP
AD  - Clínica Lircay, Talca, Chile.
FAU - Cornejo, Jenifer Barros
AU  - Cornejo JB
AD  - Hospital Clínico UC Christus, Santiago, Chile.
FAU - Cammaroto, Giovanni
AU  - Cammaroto G
AUID- ORCID: 0000-0002-1618-0048
AD  - Head and Neck Department, ENT &amp; Oral Surgery Unity, G.B. Morgagni, L. Pierantoni 
      Hospital, Via Forlanini, 47121, Forlì, Italy. giovanni.cammaroto@hotmail.com.
AD  - Young Otolaryngologists-International Federations of Oto-Rhinolaryngological 
      Societies (YO-IFOS), Paris, France. giovanni.cammaroto@hotmail.com.
LA  - eng
PT  - Journal Article
DEP - 20231119
PL  - Germany
TA  - Eur Arch Otorhinolaryngol
JT  - European archives of oto-rhino-laryngology : official journal of the European 
      Federation of Oto-Rhino-Laryngological Societies (EUFOS) : affiliated with the 
      German Society for Oto-Rhino-Laryngology - Head and Neck Surgery
JID - 9002937
RN  - EC 2.6.1.2 (Alanine Transaminase)
SB  - IM
MH  - Humans
MH  - Cross-Sectional Studies
MH  - Prospective Studies
MH  - Alanine Transaminase
MH  - *Clinical Decision-Making
MH  - *Sleep Apnea, Obstructive/diagnosis/therapy
OTO - NOTNLM
OT  - Chat-Gpt
OT  - Chatbot
OT  - OSA
OT  - Sleep apnea
EDAT- 2023/11/19 18:41
MHDA- 2024/03/18 06:43
CRDT- 2023/11/19 15:15
PHST- 2023/09/13 00:00 [received]
PHST- 2023/09/29 00:00 [accepted]
PHST- 2024/03/18 06:43 [medline]
PHST- 2023/11/19 18:41 [pubmed]
PHST- 2023/11/19 15:15 [entrez]
AID - 10.1007/s00405-023-08270-9 [pii]
AID - 10.1007/s00405-023-08270-9 [doi]
PST - ppublish
SO  - Eur Arch Otorhinolaryngol. 2024 Apr;281(4):2087-2093. doi: 
      10.1007/s00405-023-08270-9. Epub 2023 Nov 19.

PMID- 37890504
OWN - NLM
STAT- Publisher
LR  - 20231027
IS  - 1439-3999 (Electronic)
IS  - 0023-2165 (Linking)
DP  - 2023 Oct 27
TI  - Assessment of ChatGPT in the Prehospital Management of Ophthalmological 
      Emergencies - An Analysis of 10 Fictional Case Vignettes.
LID - 10.1055/a-2149-0447 [doi]
AB  - BACKGROUND: The artificial intelligence (AI)-based platform ChatGPT (Chat 
      Generative Pre-Trained Transformer, OpenAI LP, San Francisco, CA, USA) has gained 
      impressive popularity in recent months. Its performance on case vignettes of 
      general medical (non-ophthalmological) emergencies has been assessed - with very 
      encouraging results. The purpose of this study was to assess the performance of 
      ChatGPT on ophthalmological emergency case vignettes in terms of the main outcome 
      measures triage accuracy, appropriateness of recommended prehospital measures, 
      and overall potential to inflict harm to the user/patient. METHODS: We wrote ten 
      short, fictional case vignettes describing different acute ophthalmological 
      symptoms. Each vignette was entered into ChatGPT five times with the same wording 
      and following a standardized interaction pathway. The answers were analyzed 
      following a systematic approach. RESULTS: We observed a triage accuracy of 93.6%. 
      Most answers contained only appropriate recommendations for prehospital measures. 
      However, an overall potential to inflict harm to users/patients was present in 
      32% of answers. CONCLUSION: ChatGPT should presently not be used as a stand-alone 
      primary source of information about acute ophthalmological symptoms. As AI 
      continues to evolve, its safety and efficacy in the prehospital management of 
      ophthalmological emergencies has to be reassessed regularly.
CI  - Thieme. All rights reserved.
FAU - Knebel, Dominik
AU  - Knebel D
AD  - Department of Ophthalmology, University Hospital, Ludwigs-Maximilians-Universität 
      München, München, Germany.
FAU - Priglinger, Siegfried
AU  - Priglinger S
AD  - Department of Ophthalmology, University Hospital, Ludwigs-Maximilians-Universität 
      München, München, Germany.
FAU - Scherer, Nicolas
AU  - Scherer N
AD  - Department of Ophthalmology, University Hospital, Ludwigs-Maximilians-Universität 
      München, München, Germany.
FAU - Klaas, Julian
AU  - Klaas J
AD  - Department of Ophthalmology, University Hospital, Ludwigs-Maximilians-Universität 
      München, München, Germany.
FAU - Siedlecki, Jakob
AU  - Siedlecki J
AUID- ORCID: 0000-0002-0279-4823
AD  - Department of Ophthalmology, University Hospital, Ludwigs-Maximilians-Universität 
      München, München, Germany.
FAU - Schworm, Benedikt
AU  - Schworm B
AD  - Department of Ophthalmology, University Hospital, Ludwigs-Maximilians-Universität 
      München, München, Germany.
LA  - eng
PT  - Journal Article
TT  - ChatGPT in der präklinischen Versorgung augenärztlicher Notfälle – eine 
      Untersuchung von 10 fiktiven Fallvignetten.
DEP - 20231027
PL  - Germany
TA  - Klin Monbl Augenheilkd
JT  - Klinische Monatsblatter fur Augenheilkunde
JID - 0014133
SB  - IM
COIS- The authors declare that they have no conflict of interest.
EDAT- 2023/10/28 11:42
MHDA- 2023/10/28 11:42
CRDT- 2023/10/27 19:07
PHST- 2023/10/28 11:42 [medline]
PHST- 2023/10/28 11:42 [pubmed]
PHST- 2023/10/27 19:07 [entrez]
AID - 10.1055/a-2149-0447 [doi]
PST - aheadofprint
SO  - Klin Monbl Augenheilkd. 2023 Oct 27. doi: 10.1055/a-2149-0447.

PMID- 38531823
OWN - NLM
STAT- Publisher
LR  - 20240327
IS  - 2380-0194 (Electronic)
IS  - 2380-0186 (Linking)
DP  - 2024 Mar 21
TI  - Chat Generative Pretraining Transformer Answers Patient-focused Questions in 
      Cervical Spine Surgery.
LID - 10.1097/BSD.0000000000001600 [doi]
AB  - STUDY DESIGN: Review of Chat Generative Pretraining Transformer (ChatGPT) outputs 
      to select patient-focused questions. OBJECTIVE: We aimed to examine the quality 
      of ChatGPT responses to cervical spine questions. BACKGROUND: Artificial 
      intelligence and its utilization to improve patient experience across medicine is 
      seeing remarkable growth. One such usage is patient education. For the first time 
      on a large scale, patients can ask targeted questions and receive similarly 
      targeted answers. Although patients may use these resources to assist in 
      decision-making, there still exists little data regarding their accuracy, 
      especially within orthopedic surgery and more specifically spine surgery. 
      METHODS: We compiled 9 frequently asked questions cervical spine surgeons receive 
      in the clinic to test ChatGPT's version 3.5 ability to answer a nuanced topic. 
      Responses were reviewed by 2 independent reviewers on a Likert Scale for the 
      accuracy of information presented (0-5 points), appropriateness in giving a 
      specific answer (0-3 points), and readability for a layperson (0-2 points). 
      Readability was assessed through the Flesh-Kincaid grade level analysis for the 
      original prompt and for a second prompt asking for rephrasing at the sixth-grade 
      reading level. RESULTS: On average, ChatGPT's responses scored a 7.1/10. Accuracy 
      was rated on average a 4.1/5. Appropriateness was 1.8/3. Readability was a 1.2/2. 
      Readability was determined to be at the 13.5 grade level originally and at the 
      11.2 grade level after prompting. CONCLUSIONS: ChatGPT has the capacity to be a 
      powerful means for patients to gain important and specific information regarding 
      their pathologies and surgical options. These responses are limited in their 
      accuracy, and we, in addition, noted readability is not optimal for the average 
      patient. Despite these limitations in ChatGPT's capability to answer these 
      nuanced questions, the technology is impressive, and surgeons should be aware 
      patients will likely increasingly rely on it.
CI  - Copyright © 2024 Wolters Kluwer Health, Inc. All rights reserved.
FAU - Subramanian, Tejas
AU  - Subramanian T
AD  - Department of Orthopedic Surgery, Hospital for Special Surgery.
AD  - Weill Cornell Medicine, New York, NY.
FAU - Araghi, Kasra
AU  - Araghi K
AD  - Department of Orthopedic Surgery, Hospital for Special Surgery.
FAU - Amen, Troy B
AU  - Amen TB
AD  - Department of Orthopedic Surgery, Hospital for Special Surgery.
FAU - Kaidi, Austin
AU  - Kaidi A
AD  - Department of Orthopedic Surgery, Hospital for Special Surgery.
FAU - Sosa, Branden
AU  - Sosa B
AD  - Weill Cornell Medicine, New York, NY.
FAU - Shahi, Pratyush
AU  - Shahi P
AD  - Department of Orthopedic Surgery, Hospital for Special Surgery.
FAU - Qureshi, Sheeraz
AU  - Qureshi S
AD  - Department of Orthopedic Surgery, Hospital for Special Surgery.
AD  - Weill Cornell Medicine, New York, NY.
FAU - Iyer, Sravisht
AU  - Iyer S
AD  - Department of Orthopedic Surgery, Hospital for Special Surgery.
AD  - Weill Cornell Medicine, New York, NY.
LA  - eng
PT  - Journal Article
DEP - 20240321
PL  - United States
TA  - Clin Spine Surg
JT  - Clinical spine surgery
JID - 101675083
SB  - IM
COIS- The authors declare no conflict of interest.
EDAT- 2024/03/27 06:44
MHDA- 2024/03/27 06:44
CRDT- 2024/03/27 00:03
PHST- 2023/07/17 00:00 [received]
PHST- 2023/11/29 00:00 [accepted]
PHST- 2024/03/27 06:44 [medline]
PHST- 2024/03/27 06:44 [pubmed]
PHST- 2024/03/27 00:03 [entrez]
AID - 01933606-990000000-00280 [pii]
AID - 10.1097/BSD.0000000000001600 [doi]
PST - aheadofprint
SO  - Clin Spine Surg. 2024 Mar 21. doi: 10.1097/BSD.0000000000001600.

PMID- 37606976
OWN - NLM
STAT- MEDLINE
DCOM- 20230828
LR  - 20230908
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 25
DP  - 2023 Aug 22
TI  - Assessing the Utility of ChatGPT Throughout the Entire Clinical Workflow: 
      Development and Usability Study.
PG  - e48659
LID - 10.2196/48659 [doi]
LID - e48659
AB  - BACKGROUND: Large language model (LLM)-based artificial intelligence chatbots 
      direct the power of large training data sets toward successive, related tasks as 
      opposed to single-ask tasks, for which artificial intelligence already achieves 
      impressive performance. The capacity of LLMs to assist in the full scope of 
      iterative clinical reasoning via successive prompting, in effect acting as 
      artificial physicians, has not yet been evaluated. OBJECTIVE: This study aimed to 
      evaluate ChatGPT's capacity for ongoing clinical decision support via its 
      performance on standardized clinical vignettes. METHODS: We inputted all 36 
      published clinical vignettes from the Merck Sharpe &amp; Dohme (MSD) Clinical Manual 
      into ChatGPT and compared its accuracy on differential diagnoses, diagnostic 
      testing, final diagnosis, and management based on patient age, gender, and case 
      acuity. Accuracy was measured by the proportion of correct responses to the 
      questions posed within the clinical vignettes tested, as calculated by human 
      scorers. We further conducted linear regression to assess the contributing 
      factors toward ChatGPT's performance on clinical tasks. RESULTS: ChatGPT achieved 
      an overall accuracy of 71.7% (95% CI 69.3%-74.1%) across all 36 clinical 
      vignettes. The LLM demonstrated the highest performance in making a final 
      diagnosis with an accuracy of 76.9% (95% CI 67.8%-86.1%) and the lowest 
      performance in generating an initial differential diagnosis with an accuracy of 
      60.3% (95% CI 54.2%-66.6%). Compared to answering questions about general medical 
      knowledge, ChatGPT demonstrated inferior performance on differential diagnosis 
      (β=-15.8%; P&lt;.001) and clinical management (β=-7.4%; P=.02) question types. 
      CONCLUSIONS: ChatGPT achieves impressive accuracy in clinical decision-making, 
      with increasing strength as it gains more clinical information at its disposal. 
      In particular, ChatGPT demonstrates the greatest accuracy in tasks of final 
      diagnosis as compared to initial diagnosis. Limitations include possible model 
      hallucinations and the unclear composition of ChatGPT's training data set.
CI  - ©Arya Rao, Michael Pang, John Kim, Meghana Kamineni, Winston Lie, Anoop K Prasad, 
      Adam Landman, Keith Dreyer, Marc D Succi. Originally published in the Journal of 
      Medical Internet Research (https://www.jmir.org), 22.08.2023.
FAU - Rao, Arya
AU  - Rao A
AUID- ORCID: 0000-0003-3007-4812
AD  - Medically Engineered Solutions in Healthcare Incubator, Innovation in Operations 
      Research Center (MESH IO), Massachusetts General Hospital, Boston, MA, United 
      States.
AD  - Harvard Medical School, Boston, MA, United States.
AD  - Department of Radiology, Massachusetts General Hospital, Boston, MA, United 
      States.
FAU - Pang, Michael
AU  - Pang M
AUID- ORCID: 0000-0001-5619-9344
AD  - Medically Engineered Solutions in Healthcare Incubator, Innovation in Operations 
      Research Center (MESH IO), Massachusetts General Hospital, Boston, MA, United 
      States.
AD  - Harvard Medical School, Boston, MA, United States.
AD  - Department of Radiology, Massachusetts General Hospital, Boston, MA, United 
      States.
FAU - Kim, John
AU  - Kim J
AUID- ORCID: 0000-0003-4252-5916
AD  - Medically Engineered Solutions in Healthcare Incubator, Innovation in Operations 
      Research Center (MESH IO), Massachusetts General Hospital, Boston, MA, United 
      States.
AD  - Harvard Medical School, Boston, MA, United States.
AD  - Department of Radiology, Massachusetts General Hospital, Boston, MA, United 
      States.
FAU - Kamineni, Meghana
AU  - Kamineni M
AUID- ORCID: 0000-0002-6698-5151
AD  - Medically Engineered Solutions in Healthcare Incubator, Innovation in Operations 
      Research Center (MESH IO), Massachusetts General Hospital, Boston, MA, United 
      States.
AD  - Harvard Medical School, Boston, MA, United States.
AD  - Department of Radiology, Massachusetts General Hospital, Boston, MA, United 
      States.
FAU - Lie, Winston
AU  - Lie W
AUID- ORCID: 0009-0002-0939-7449
AD  - Medically Engineered Solutions in Healthcare Incubator, Innovation in Operations 
      Research Center (MESH IO), Massachusetts General Hospital, Boston, MA, United 
      States.
AD  - Harvard Medical School, Boston, MA, United States.
AD  - Department of Radiology, Massachusetts General Hospital, Boston, MA, United 
      States.
FAU - Prasad, Anoop K
AU  - Prasad AK
AUID- ORCID: 0000-0002-4409-6062
AD  - Medically Engineered Solutions in Healthcare Incubator, Innovation in Operations 
      Research Center (MESH IO), Massachusetts General Hospital, Boston, MA, United 
      States.
AD  - Harvard Medical School, Boston, MA, United States.
AD  - Department of Radiology, Massachusetts General Hospital, Boston, MA, United 
      States.
FAU - Landman, Adam
AU  - Landman A
AUID- ORCID: 0000-0002-2166-0521
AD  - Harvard Medical School, Boston, MA, United States.
AD  - Department of Radiology, Brigham and Women's Hospital, Boston, MA, United States.
FAU - Dreyer, Keith
AU  - Dreyer K
AUID- ORCID: 0000-0003-1207-6443
AD  - Harvard Medical School, Boston, MA, United States.
AD  - Data Science Office, Mass General Brigham, Boston, MA, United States.
FAU - Succi, Marc D
AU  - Succi MD
AUID- ORCID: 0000-0002-1518-3984
AD  - Medically Engineered Solutions in Healthcare Incubator, Innovation in Operations 
      Research Center (MESH IO), Massachusetts General Hospital, Boston, MA, United 
      States.
AD  - Harvard Medical School, Boston, MA, United States.
AD  - Department of Radiology, Massachusetts General Hospital, Boston, MA, United 
      States.
AD  - Mass General Brigham Innovation, Mass General Brigham, Boston, MA, United States.
LA  - eng
GR  - T32 GM144273/GM/NIGMS NIH HHS/United States
PT  - Evaluation Study
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
DEP - 20230822
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
UOF - medRxiv. 2023 Feb 26;:. PMID: 36865204
MH  - Humans
MH  - *Artificial Intelligence
MH  - Clinical Decision-Making
MH  - Organizations
MH  - Workflow
MH  - User-Centered Design
PMC - PMC10481210
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - GPT
OT  - Generative Pre-trained Transformer
OT  - LLMs
OT  - accuracy
OT  - artificial intelligence
OT  - chatbot
OT  - clinical decision support
OT  - clinical vignettes
OT  - decision-making
OT  - development
OT  - large language models
OT  - usability
OT  - utility
COIS- Conflicts of Interest: None declared.
EDAT- 2023/08/22 13:43
MHDA- 2023/08/23 06:42
PMCR- 2023/08/22
CRDT- 2023/08/22 11:55
PHST- 2023/05/02 00:00 [received]
PHST- 2023/07/27 00:00 [accepted]
PHST- 2023/07/26 00:00 [revised]
PHST- 2023/08/23 06:42 [medline]
PHST- 2023/08/22 13:43 [pubmed]
PHST- 2023/08/22 11:55 [entrez]
PHST- 2023/08/22 00:00 [pmc-release]
AID - v25i1e48659 [pii]
AID - 10.2196/48659 [doi]
PST - epublish
SO  - J Med Internet Res. 2023 Aug 22;25:e48659. doi: 10.2196/48659.

PMID- 38486738
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240316
IS  - 2405-8440 (Print)
IS  - 2405-8440 (Electronic)
IS  - 2405-8440 (Linking)
VI  - 10
IP  - 5
DP  - 2024 Mar 15
TI  - Evaluating human resources management literacy: A performance analysis of ChatGPT 
      and bard.
PG  - e27026
LID - 10.1016/j.heliyon.2024.e27026 [doi]
LID - e27026
AB  - This study presents a comprehensive analysis comparing the literacy levels of two 
      Generative Artificial Intelligence (GAI) tools, ChatGPT and Bard, using a dataset 
      of 134 questions from the Human Resources (HR) domain. The generated responses 
      are evaluated for accuracy, relevance, and clarity. We find that ChatGPT 
      outperforms Bard in overall accuracy (84.3% vs. 82.8%). This difference in 
      performance suggests that ChatGPT could serve as a robotic advisor in 
      transactional HR roles. In contrast, Bard may possess additional safeguards 
      against misuse in the HR function, making it less capable of generating responses 
      to certain types of questions. Statistical tests reveal that although the two 
      systems differ in their mean accuracy, relevance, and clarity of the responses, 
      the observed differences are not always statistically significant, implying that 
      both tools may be more complementary than competitive. The Pearson correlation 
      coefficients further support this by showing weak to non-existent relationships 
      in performance metrics between the two tools. Confirmation queries don't improve 
      ChatGPT or Bard's response accuracy. The study thus contributes to emerging 
      research on the utility of GAI tools in Human Resources Management and suggests 
      that involving certified HR professionals in the design phase could enhance 
      underlying language model performance.
CI  - © 2024 The Authors.
FAU - Raman, Raghu
AU  - Raman R
AD  - Amrita School of Business, Amrita Vishwa Vidyapeetham, Amritapuri, India.
FAU - Venugopalan, Murale
AU  - Venugopalan M
AD  - Amrita School of Business, Amrita Vishwa Vidyapeetham, Amritapuri, India.
FAU - Kamal, Anju
AU  - Kamal A
AD  - Amrita School of Business, Amrita Vishwa Vidyapeetham, Amritapuri, India.
LA  - eng
PT  - Journal Article
DEP - 20240303
PL  - England
TA  - Heliyon
JT  - Heliyon
JID - 101672560
PMC - PMC10937570
OTO - NOTNLM
OT  - Ethics
OT  - Generative AI
OT  - HR policy
OT  - Hiring
OT  - Human resource management
OT  - LLM
OT  - Managerial decisions
OT  - Text mining
COIS- The authors declare that they have no known competing financial interests or 
      personal relationships that could have appeared to influence the work reported in 
      this paper.
EDAT- 2024/03/15 06:44
MHDA- 2024/03/15 06:45
PMCR- 2024/03/03
CRDT- 2024/03/15 03:56
PHST- 2023/09/24 00:00 [received]
PHST- 2024/02/16 00:00 [revised]
PHST- 2024/02/22 00:00 [accepted]
PHST- 2024/03/15 06:45 [medline]
PHST- 2024/03/15 06:44 [pubmed]
PHST- 2024/03/15 03:56 [entrez]
PHST- 2024/03/03 00:00 [pmc-release]
AID - S2405-8440(24)03057-3 [pii]
AID - e27026 [pii]
AID - 10.1016/j.heliyon.2024.e27026 [doi]
PST - epublish
SO  - Heliyon. 2024 Mar 3;10(5):e27026. doi: 10.1016/j.heliyon.2024.e27026. eCollection 
      2024 Mar 15.

PMID- 37994523
OWN - NLM
STAT- Publisher
LR  - 20231123
IS  - 1538-9855 (Electronic)
IS  - 0363-3624 (Linking)
DP  - 2023 Nov 22
TI  - Reliability and Quality of the Nursing Care Planning Texts Generated by ChatGPT.
LID - 10.1097/NNE.0000000000001566 [doi]
AB  - BACKGROUND: The research on ChatGPT-generated nursing care planning texts is 
      critical for enhancing nursing education through innovative and accessible 
      learning methods, improving reliability and quality. PURPOSE: The aim of the 
      study was to examine the quality, authenticity, and reliability of the nursing 
      care planning texts produced using ChatGPT. METHODS: The study sample comprised 
      40 texts generated by ChatGPT selected nursing diagnoses that were included in 
      NANDA 2021-2023. The texts were evaluated by using a descriptive criteria form 
      and the DISCERN tool to evaluate health information. RESULTS: DISCERN total 
      average score of the texts was 45.93 ± 4.72. All texts had a moderate level of 
      reliability and 97.5% of them provided moderate quality subscale score of 
      information. A statistically significant relationship was found among the number 
      of accessible references, reliability (r = 0.408), and quality subscale score (r 
      = 0.379) of the texts (P &lt; .05). CONCLUSION: ChatGPT-generated texts exhibited 
      moderate reliability, quality of nursing care information, and overall quality 
      despite low similarity rates.
CI  - Copyright © 2023 Wolters Kluwer Health, Inc. All rights reserved.
FAU - Dağcı, Mahmut
AU  - Dağcı M
AD  - Department of Nursing, Bezmialem Vakif University, Faculty of Health Sciences, 
      Istanbul, Turkey.
FAU - Çam, Funda
AU  - Çam F
FAU - Dost, Ayşe
AU  - Dost A
AUID- ORCID: 0000-0002-4651-7254
LA  - eng
PT  - Journal Article
DEP - 20231122
PL  - United States
TA  - Nurse Educ
JT  - Nurse educator
JID - 7701902
COIS- The authors declare no conflicts of interest with respect to the authorship 
      and/or publication of this article.
EDAT- 2023/11/23 06:42
MHDA- 2023/11/23 06:42
CRDT- 2023/11/23 04:28
PHST- 2023/11/23 06:42 [medline]
PHST- 2023/11/23 06:42 [pubmed]
PHST- 2023/11/23 04:28 [entrez]
AID - 00006223-990000000-00373 [pii]
AID - 10.1097/NNE.0000000000001566 [doi]
PST - aheadofprint
SO  - Nurse Educ. 2023 Nov 22. doi: 10.1097/NNE.0000000000001566.

PMID- 37611254
OWN - NLM
STAT- MEDLINE
DCOM- 20231204
LR  - 20231213
IS  - 1572-0241 (Electronic)
IS  - 0002-9270 (Linking)
VI  - 118
IP  - 12
DP  - 2023 Dec 1
TI  - Towards AI-Augmented Clinical Decision-Making: An Examination of ChatGPT's 
      Utility in Acute Ulcerative Colitis Presentations.
PG  - 2283-2289
LID - 10.14309/ajg.0000000000002483 [doi]
AB  - This study explores the potential of OpenAI's ChatGPT as a decision support tool 
      for acute ulcerative colitis presentations in the setting of an emergency 
      department. We assessed ChatGPT's performance in determining disease severity 
      using TrueLove and Witts criteria and the necessity of hospitalization for 
      patients with ulcerative colitis, comparing results with those of expert 
      gastroenterologists. Of 20 cases, ChatGPT's assessments were found to be 80% 
      consistent with gastroenterologist evaluations and indicated a high degree of 
      reliability. This suggests that ChatGPT could provide as a clinical decision 
      support tool in assessing acute ulcerative colitis, serving as an adjunct to 
      clinical judgment.
CI  - Copyright © 2023 by The American College of Gastroenterology.
FAU - Levartovsky, Asaf
AU  - Levartovsky A
AD  - Department of Gastroenterology, Sheba Medical Center, Affiliated to Tel Aviv 
      University, Tel Aviv, Israel.
FAU - Ben-Horin, Shomron
AU  - Ben-Horin S
AD  - Department of Gastroenterology, Sheba Medical Center, Affiliated to Tel Aviv 
      University, Tel Aviv, Israel.
FAU - Kopylov, Uri
AU  - Kopylov U
AD  - Department of Gastroenterology, Sheba Medical Center, Affiliated to Tel Aviv 
      University, Tel Aviv, Israel.
FAU - Klang, Eyal
AU  - Klang E
AUID- ORCID: 0000-0002-4567-3108
AD  - Department of Diagnostic Imaging, Sheba Medical Center, Affiliated to Tel Aviv 
      University, Tel Aviv, Israel.
AD  - DeepVision Lab, Sheba Medical Center, Affiliated to Tel Aviv University, Tel 
      Aviv, Israel.
FAU - Barash, Yiftach
AU  - Barash Y
AUID- ORCID: 0000-0002-7242-1328
AD  - Department of Diagnostic Imaging, Sheba Medical Center, Affiliated to Tel Aviv 
      University, Tel Aviv, Israel.
AD  - DeepVision Lab, Sheba Medical Center, Affiliated to Tel Aviv University, Tel 
      Aviv, Israel.
LA  - eng
PT  - Journal Article
DEP - 20230823
PL  - United States
TA  - Am J Gastroenterol
JT  - The American journal of gastroenterology
JID - 0421030
SB  - IM
MH  - Humans
MH  - *Colitis, Ulcerative/diagnosis
MH  - Reproducibility of Results
MH  - Clinical Decision-Making
MH  - Emergency Service, Hospital
MH  - Artificial Intelligence
EDAT- 2023/08/23 18:42
MHDA- 2023/12/04 12:41
CRDT- 2023/08/23 16:53
PHST- 2023/06/01 00:00 [received]
PHST- 2023/08/04 00:00 [accepted]
PHST- 2023/12/04 12:41 [medline]
PHST- 2023/08/23 18:42 [pubmed]
PHST- 2023/08/23 16:53 [entrez]
AID - 00000434-202312000-00033 [pii]
AID - 10.14309/ajg.0000000000002483 [doi]
PST - ppublish
SO  - Am J Gastroenterol. 2023 Dec 1;118(12):2283-2289. doi: 
      10.14309/ajg.0000000000002483. Epub 2023 Aug 23.

PMID- 38171421
OWN - NLM
STAT- Publisher
LR  - 20240126
IS  - 1526-3231 (Electronic)
IS  - 0749-8063 (Linking)
DP  - 2024 Jan 1
TI  - ChatGPT Responses to Common Questions About Anterior Cruciate Ligament 
      Reconstruction Are Frequently Satisfactory.
LID - S0749-8063(23)01013-7 [pii]
LID - 10.1016/j.arthro.2023.12.009 [doi]
AB  - PURPOSE: To evaluate ChatGPT responses to common questions patients have 
      regarding anterior cruciate ligament (ACL) reconstruction. METHODS: Ten 
      frequently asked questions regarding ACL tears and ACL reconstruction were chosen 
      from the frequently asked questions found on the websites of major institutions. 
      These were presented to ChatGPT and responses were rated as "excellent response 
      not requiring clarification," "satisfactory requiring minimal clarification," 
      "satisfactory requiring moderate clarification," or "unsatisfactory requiring 
      substantial clarification." RESULTS: Four responses were satisfactory, requiring 
      minimal clarification, 3 were satisfactory, requiring moderate clarification, 2 
      were unsatisfactory, and 1 was excellent, requiring no clarification. 
      CONCLUSIONS: As hypothesized, ChatGPT provided generally accurate information to 
      common questions around ACL reconstruction. Although clarification often was 
      needed, responses were satisfactory for providing generalized information about 
      ACL tears and ACL reconstruction. CLINICAL RELEVANCE: ChatGPT is a promising 
      avenue for patients to learn about general background information regarding ACL 
      reconstruction, although questions specific to any planned operation need to be 
      addressed directly with an orthopaedic provider.
CI  - Copyright © 2023 Arthroscopy Association of North America. Published by Elsevier 
      Inc. All rights reserved.
FAU - Li, Lambert T
AU  - Li LT
AD  - Department of Orthopaedic Surgery, University Hospitals, Case Western Reserve 
      University, Cleveland, Ohio, U.S.A.. Electronic address: 
      Lambert.Li@uhhospitals.org.
FAU - Sinkler, Margaret A
AU  - Sinkler MA
AD  - Department of Orthopaedic Surgery, University Hospitals, Case Western Reserve 
      University, Cleveland, Ohio, U.S.A.
FAU - Adelstein, Jeremy M
AU  - Adelstein JM
AD  - Department of Orthopaedic Surgery, University Hospitals, Case Western Reserve 
      University, Cleveland, Ohio, U.S.A.
FAU - Voos, James E
AU  - Voos JE
AD  - Department of Orthopaedic Surgery, University Hospitals, Case Western Reserve 
      University, Cleveland, Ohio, U.S.A.
FAU - Calcei, Jacob G
AU  - Calcei JG
AD  - Department of Orthopaedic Surgery, University Hospitals, Case Western Reserve 
      University, Cleveland, Ohio, U.S.A.
LA  - eng
PT  - Journal Article
DEP - 20240101
PL  - United States
TA  - Arthroscopy
JT  - Arthroscopy : the journal of arthroscopic &amp; related surgery : official 
      publication of the Arthroscopy Association of North America and the International 
      Arthroscopy Association
JID - 8506498
SB  - IM
COIS- Disclosure The authors declare the following financial interests/personal 
      relationships which may be considered as potential competing interests: J.E.V. 
      reports a relationship with Arthrex that includes: speaking and lecture fees. 
      J.G.C. reports a relationship with Smith &amp; Nephew Inc that includes: speaking and 
      lecture fees. All other authors (L.T.L., M.A.S., J.M.A.) declare that they have 
      no known competing financial interests or personal relationships that could have 
      appeared to influence the work reported in this paper. Full ICMJE author 
      disclosure forms are available for this article online, as supplementary 
      material.
EDAT- 2024/01/04 11:43
MHDA- 2024/01/04 11:43
CRDT- 2024/01/03 19:11
PHST- 2023/09/24 00:00 [received]
PHST- 2023/11/13 00:00 [revised]
PHST- 2023/12/03 00:00 [accepted]
PHST- 2024/01/04 11:43 [pubmed]
PHST- 2024/01/04 11:43 [medline]
PHST- 2024/01/03 19:11 [entrez]
AID - S0749-8063(23)01013-7 [pii]
AID - 10.1016/j.arthro.2023.12.009 [doi]
PST - aheadofprint
SO  - Arthroscopy. 2024 Jan 1:S0749-8063(23)01013-7. doi: 10.1016/j.arthro.2023.12.009.

PMID- 36865144
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230303
DP  - 2023 Feb 23
TI  - Assessing the Value of ChatGPT for Clinical Decision Support Optimization.
LID - 2023.02.21.23286254 [pii]
LID - 10.1101/2023.02.21.23286254 [doi]
AB  - OBJECTIVE: To determine if ChatGPT can generate useful suggestions for improving 
      clinical decision support (CDS) logic and to assess noninferiority compared to 
      human-generated suggestions. METHODS: We supplied summaries of CDS logic to 
      ChatGPT, an artificial intelligence (AI) tool for question answering that uses a 
      large language model, and asked it to generate suggestions. We asked human 
      clinician reviewers to review the AI-generated suggestions as well as 
      human-generated suggestions for improving the same CDS alerts, and rate the 
      suggestions for their usefulness, acceptance, relevance, understanding, workflow, 
      bias, inversion, and redundancy. RESULTS: Five clinicians analyzed 36 
      AI-generated suggestions and 29 human-generated suggestions for 7 alerts. Of the 
      20 suggestions that scored highest in the survey, 9 were generated by ChatGPT. 
      The suggestions generated by AI were found to offer unique perspectives and were 
      evaluated as highly understandable and relevant, with moderate usefulness, low 
      acceptance, bias, inversion, redundancy. CONCLUSION: AI-generated suggestions 
      could be an important complementary part of optimizing CDS alerts, can identify 
      potential improvements to alert logic and support their implementation, and may 
      even be able to assist experts in formulating their own suggestions for CDS 
      improvement. ChatGPT shows great potential for using large language models and 
      reinforcement learning from human feedback to improve CDS alert logic and 
      potentially other medical areas involving complex, clinical logic, a key step in 
      the development of an advanced learning health system.
FAU - Liu, Siru
AU  - Liu S
FAU - Wright, Aileen P
AU  - Wright AP
FAU - Patterson, Barron L
AU  - Patterson BL
FAU - Wanderer, Jonathan P
AU  - Wanderer JP
FAU - Turer, Robert W
AU  - Turer RW
FAU - Nelson, Scott D
AU  - Nelson SD
FAU - McCoy, Allison B
AU  - McCoy AB
FAU - Sittig, Dean F
AU  - Sittig DF
FAU - Wright, Adam
AU  - Wright A
LA  - eng
PT  - Preprint
DEP - 20230223
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
PMC - PMC9980251
EDAT- 2023/03/04 06:00
MHDA- 2023/03/04 06:01
PMCR- 2023/03/02
CRDT- 2023/03/03 02:28
PHST- 2023/03/03 02:28 [entrez]
PHST- 2023/03/04 06:00 [pubmed]
PHST- 2023/03/04 06:01 [medline]
PHST- 2023/03/02 00:00 [pmc-release]
AID - 2023.02.21.23286254 [pii]
AID - 10.1101/2023.02.21.23286254 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2023 Feb 23:2023.02.21.23286254. doi: 
      10.1101/2023.02.21.23286254.

PMID- 37095665
OWN - NLM
STAT- MEDLINE
DCOM- 20230824
LR  - 20230824
IS  - 1546-3141 (Electronic)
IS  - 0361-803X (Linking)
VI  - 221
IP  - 3
DP  - 2023 Sep
TI  - Potential Use Cases for ChatGPT in Radiology Reporting.
PG  - 373-376
LID - 10.2214/AJR.23.29198 [doi]
AB  - Large language models (LLMs) such as ChatGPT are advanced artificial intelligence 
      models that are designed to process and understand human language. LLMs have the 
      potential to improve radiology reporting and patient engagement by automating 
      generation of the clinical history and impression of a radiology report, creating 
      layperson reports, and providing patients with pertinent questions and answers 
      about findings in radiology reports. However, LLMs are error prone, and human 
      oversight is needed to reduce the risk of patient harm.
FAU - Elkassem, Asser Abou
AU  - Elkassem AA
AD  - Department of Radiology, University of Alabama at Birmingham, JTN 452, 619 19th 
      St S, Birmingham, AL 35249-6830.
FAU - Smith, Andrew D
AU  - Smith AD
AD  - Department of Radiology, University of Alabama at Birmingham, JTN 452, 619 19th 
      St S, Birmingham, AL 35249-6830.
LA  - eng
PT  - Journal Article
DEP - 20230419
PL  - United States
TA  - AJR Am J Roentgenol
JT  - AJR. American journal of roentgenology
JID - 7708173
SB  - IM
CIN - AJR Am J Roentgenol. 2023 Sep;221(3):403. PMID: 37406203
MH  - Humans
MH  - *Artificial Intelligence
MH  - Patient Participation
MH  - *Radiology
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - health care
OT  - large language models
OT  - radiology reports
EDAT- 2023/04/25 06:42
MHDA- 2023/08/24 06:42
CRDT- 2023/04/25 01:01
PHST- 2023/08/24 06:42 [medline]
PHST- 2023/04/25 06:42 [pubmed]
PHST- 2023/04/25 01:01 [entrez]
AID - 10.2214/AJR.23.29198 [doi]
PST - ppublish
SO  - AJR Am J Roentgenol. 2023 Sep;221(3):373-376. doi: 10.2214/AJR.23.29198. Epub 
      2023 Apr 19.

PMID- 37949111
OWN - NLM
STAT- MEDLINE
DCOM- 20240101
LR  - 20240101
IS  - 1469-0691 (Electronic)
IS  - 1198-743X (Linking)
VI  - 30
IP  - 1
DP  - 2024 Jan
TI  - Extracting symptoms from free-text responses using ChatGPT among COVID-19 cases 
      in Hong Kong.
PG  - 142.e1-142.e3
LID - S1198-743X(23)00540-2 [pii]
LID - 10.1016/j.cmi.2023.11.002 [doi]
AB  - OBJECTIVES: To investigate the feasibility and performance of Chat Generative 
      Pretrained Transformer (ChatGPT) in converting symptom narratives into structured 
      symptom labels. METHODS: We extracted symptoms from 300 deidentified symptom 
      narratives of COVID-19 patients by a computer-based matching algorithm (the 
      standard), and prompt engineering in ChatGPT. Common symptoms were those with a 
      prevalence &gt;10% according to the standard, and similarly less common symptoms 
      were those with a prevalence of 2-10%. The precision of ChatGPT was compared with 
      the standard using sensitivity and specificity with 95% exact binomial CIs (95% 
      binCIs). In ChatGPT, we prompted without examples (zero-shot prompting) and with 
      examples (few-shot prompting). RESULTS: In zero-shot prompting, GPT-4 achieved 
      high specificity (0.947 [95% binCI: 0.894-0.978]-1.000 [95% binCI: 0.965-0.988, 
      1.000]) for all symptoms, high sensitivity for common symptoms (0.853 [95% binCI: 
      0.689-0.950]-1.000 [95% binCI: 0.951-1.000]), and moderate sensitivity for less 
      common symptoms (0.200 [95% binCI: 0.043-0.481]-1.000 [95% binCI: 0.590-0.815, 
      1.000]). Few-shot prompting increased the sensitivity and specificity. GPT-4 
      outperformed GPT-3.5 in response accuracy and consistent labelling. DISCUSSION: 
      This work substantiates ChatGPT's role as a research tool in medical fields. Its 
      performance in converting symptom narratives to structured symptom labels was 
      encouraging, saving time and effort in compiling the task-specific training data. 
      It potentially accelerates free-text data compilation and synthesis in future 
      disease outbreaks and improves the accuracy of symptom checkers. Focused prompt 
      training addressing ambiguous descriptions impacts medical research positively.
CI  - Copyright © 2023 European Society of Clinical Microbiology and Infectious 
      Diseases. Published by Elsevier Ltd. All rights reserved.
FAU - Wei, Wan In
AU  - Wei WI
AD  - JC School of Public Health and Primary Care, The Chinese University of Hong Kong, 
      Hong Kong Special Administrative Region, China.
FAU - Leung, Cyrus Lap Kwan
AU  - Leung CLK
AD  - JC School of Public Health and Primary Care, The Chinese University of Hong Kong, 
      Hong Kong Special Administrative Region, China.
FAU - Tang, Arthur
AU  - Tang A
AD  - Department of Information Technology, School of Science, Engineering and 
      Technology, RMIT University, Vietnam.
FAU - McNeil, Edward Braddon
AU  - McNeil EB
AD  - JC School of Public Health and Primary Care, The Chinese University of Hong Kong, 
      Hong Kong Special Administrative Region, China.
FAU - Wong, Samuel Yeung Shan
AU  - Wong SYS
AD  - JC School of Public Health and Primary Care, The Chinese University of Hong Kong, 
      Hong Kong Special Administrative Region, China.
FAU - Kwok, Kin On
AU  - Kwok KO
AD  - JC School of Public Health and Primary Care, The Chinese University of Hong Kong, 
      Hong Kong Special Administrative Region, China; Stanley Ho Centre for Emerging 
      Infectious Diseases, The Chinese University of Hong Kong, Hong Kong Special 
      Administrative Region, China; Hong Kong Institute of Asia-Pacific Studies, The 
      Chinese University of Hong Kong, Hong Kong Special Administrative Region, China; 
      Department of Infectious Disease Epidemiology, School of Public Health, Imperial 
      College London, London, United Kingdom. Electronic address: kkokwok@cuhk.edu.hk.
LA  - eng
PT  - Journal Article
DEP - 20231108
PL  - England
TA  - Clin Microbiol Infect
JT  - Clinical microbiology and infection : the official publication of the European 
      Society of Clinical Microbiology and Infectious Diseases
JID - 9516420
SB  - IM
MH  - Humans
MH  - Hong Kong/epidemiology
MH  - *COVID-19/diagnosis
MH  - Algorithms
MH  - *Biomedical Research
MH  - Disease Outbreaks
OTO - NOTNLM
OT  - ChatGPT
OT  - Entity recognition
OT  - Large language model
OT  - Symptom extraction
OT  - Symptom narratives
OT  - Symptom science
EDAT- 2023/11/11 11:44
MHDA- 2024/01/02 11:44
CRDT- 2023/11/10 19:12
PHST- 2023/06/26 00:00 [received]
PHST- 2023/11/01 00:00 [revised]
PHST- 2023/11/03 00:00 [accepted]
PHST- 2024/01/02 11:44 [medline]
PHST- 2023/11/11 11:44 [pubmed]
PHST- 2023/11/10 19:12 [entrez]
AID - S1198-743X(23)00540-2 [pii]
AID - 10.1016/j.cmi.2023.11.002 [doi]
PST - ppublish
SO  - Clin Microbiol Infect. 2024 Jan;30(1):142.e1-142.e3. doi: 
      10.1016/j.cmi.2023.11.002. Epub 2023 Nov 8.

PMID- 37546795
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231019
DP  - 2023 Jul 27
TI  - Interdisciplinary Inquiry via PanelGPT: Application to Explore Chatbot 
      Application in Sports Rehabilitation.
LID - 2023.07.23.23292452 [pii]
LID - 10.1101/2023.07.23.23292452 [doi]
AB  - BACKGROUND: ChatGPT showcases exceptional conversational capabilities and 
      extensive cross-disciplinary knowledge. In addition, it possesses the ability to 
      perform multiple roles within a single chat session. This unique 
      multi-role-playing feature positions ChatGPT as a promising tool to explore 
      interdisciplinary subjects. OBJECTIVE: The study intended to guide ChatGPT for 
      interdisciplinary exploration through simulated panel discussions. As a 
      proof-of-concept, we employed this method to evaluate the advantages and 
      challenges of using chatbots in sports rehabilitation. METHODS: We proposed a 
      model termed PanelGPT to explore ChatGPTs' knowledge graph on interdisciplinary 
      topics through simulated panel discussions. Applied to "chatbots in sports 
      rehabilitation", ChatGPT role-played both the moderator and panelists, which 
      included a physiotherapist, psychologist, nutritionist, AI expert, and an 
      athlete. We act as the audience posed questions to the panel, with ChatGPT acting 
      as both the panelists for responses and the moderator for hosting the discussion. 
      We performed the simulation using the ChatGPT-4 model and evaluated the responses 
      with existing literature and human expertise. RESULTS: Each simulation mimicked a 
      real-life panel discussion: The moderator introduced the panel and posed 
      opening/closing questions, to which all panelists responded. The experts engaged 
      with each other to address inquiries from the audience, primarily from their 
      respective fields of expertise. By tackling questions related to education, 
      physiotherapy, physiology, nutrition, and ethical consideration, the discussion 
      highlighted benefits such as 24/7 support, personalized advice, automated 
      tracking, and reminders. It also emphasized the importance of user education and 
      identified challenges such as limited interaction modes, inaccuracies in 
      emotion-related advice, assurance on data privacy and security, transparency in 
      data handling, and fairness in model training. The panelists reached a consensus 
      that chatbots are designed to assist, not replace, human healthcare professionals 
      in the rehabilitation process. CONCLUSIONS: Compared to a typical conversation 
      with ChatGPT, the multi-perspective approach of PanelGPT facilitates a 
      comprehensive understanding of an interdisciplinary topic by integrating insights 
      from experts with complementary knowledge. Beyond addressing the exemplified 
      topic of chatbots in sports rehabilitation, the model can be adapted to tackle a 
      wide array of interdisciplinary topics within educational, research, and 
      healthcare settings.
FAU - McBee, Joseph C
AU  - McBee JC
AD  - Department of Microbiology, Immunology &amp; Cell Biology, West Virginia University, 
      Morgantown, WV 26506, USA.
AD  - Department of Chemical and Biomedical Engineering, West Virginia University, 
      Morgantown, WV 26506, USA.
FAU - Han, Daniel Y
AU  - Han DY
AD  - Department of Microbiology, Immunology &amp; Cell Biology, West Virginia University, 
      Morgantown, WV 26506, USA.
FAU - Liu, Li
AU  - Liu L
AD  - College of Health Solutions, Arizona State University, Phoenix, AZ 85004, USA.
AD  - Biodesign Institute, Arizona State University, Tempe, AZ, 85281 USA.
FAU - Ma, Leah
AU  - Ma L
AD  - College of Health, Education, and Human Services, Wright State University, 
      Dayton, OH 45345, USA.
FAU - Adjeroh, Donald A
AU  - Adjeroh DA
AD  - Lane Department of Computer Science &amp; Electrical Engineering, West Virginia 
      University, Morgantown, WV 26506, USA.
FAU - Xu, Dong
AU  - Xu D
AD  - Department of Electrical Engineer and Computer Science, Christopher S. Bond Life 
      Sciences Center, University of Missouri, Columbia, MO65211, USA.
FAU - Hu, Gangqing
AU  - Hu G
AD  - Department of Microbiology, Immunology &amp; Cell Biology, West Virginia University, 
      Morgantown, WV 26506, USA.
LA  - eng
GR  - R01 LM013392/LM/NLM NIH HHS/United States
GR  - U54 GM104942/GM/NIGMS NIH HHS/United States
GR  - P20 GM121322/GM/NIGMS NIH HHS/United States
GR  - P20 GM103434/GM/NIGMS NIH HHS/United States
GR  - R01 LM013438/LM/NLM NIH HHS/United States
PT  - Preprint
DEP - 20230727
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
PMC - PMC10402232
OTO - NOTNLM
OT  - ChatGPT
OT  - chatbots
OT  - interdisciplinary inquiry
OT  - multi-role-playing
OT  - sports medicine
COIS- Competing Interests The Authors declare no Competing Financial or Non-Financial 
      Interests
EDAT- 2023/08/07 06:41
MHDA- 2023/08/07 06:42
PMCR- 2023/08/04
CRDT- 2023/08/07 04:43
PHST- 2023/08/07 06:41 [pubmed]
PHST- 2023/08/07 06:42 [medline]
PHST- 2023/08/07 04:43 [entrez]
PHST- 2023/08/04 00:00 [pmc-release]
AID - 2023.07.23.23292452 [pii]
AID - 10.1101/2023.07.23.23292452 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2023 Jul 27:2023.07.23.23292452. doi: 
      10.1101/2023.07.23.23292452.

PMID- 37088277
OWN - NLM
STAT- MEDLINE
DCOM- 20230724
LR  - 20230724
IS  - 1097-6868 (Electronic)
IS  - 0002-9378 (Linking)
VI  - 229
IP  - 2
DP  - 2023 Aug
TI  - ChatGPT outscored human candidates in a virtual objective structured clinical 
      examination in obstetrics and gynecology.
PG  - 172.e1-172.e12
LID - S0002-9378(23)00251-X [pii]
LID - 10.1016/j.ajog.2023.04.020 [doi]
AB  - BACKGROUND: Natural language processing is a form of artificial intelligence that 
      allows human users to interface with a machine without using complex codes. The 
      ability of natural language processing systems, such as ChatGPT, to successfully 
      engage with healthcare systems requiring fluid reasoning, specialist data 
      interpretation, and empathetic communication in an unfamiliar and evolving 
      environment is poorly studied. This study investigated whether the ChatGPT 
      interface could engage with and complete a mock objective structured clinical 
      examination simulating assessment for membership of the Royal College of 
      Obstetricians and Gynaecologists. OBJECTIVE: This study aimed to determine 
      whether ChatGPT, without additional training, would achieve a score at least 
      equivalent to that achieved by human candidates who sat for virtual objective 
      structured clinical examinations in Singapore. STUDY DESIGN: This study was 
      conducted in 2 phases. In the first phase, a total of 7 structured discussion 
      questions were selected from 2 historical cohorts (cohorts A and B) of objective 
      structured clinical examination questions. ChatGPT was examined using these 
      questions and responses recorded in a script. Of note, 2 human candidates (acting 
      as anonymizers) were examined on the same questions using videoconferencing, and 
      their responses were transcribed verbatim into written scripts. The 3 sets of 
      response scripts were mixed, and each set was allocated to 1 of 3 human actors. 
      In the second phase, actors were used to presenting these scripts to examiners in 
      response to the same examination questions. These responses were blind scored by 
      14 qualified examiners. ChatGPT scores were unblinded and compared with 
      historical human candidate performance scores. RESULTS: The average score given 
      to ChatGPT by 14 examiners was 77.2%. The average historical human score (n=26 
      candidates) was 73.7 %. ChatGPT demonstrated sizable performance improvements 
      over the average human candidate in several subject domains. The median time 
      taken for ChatGPT to complete each station was 2.54 minutes, well before the 10 
      minutes allowed. CONCLUSION: ChatGPT generated factually accurate and 
      contextually relevant structured discussion answers to complex and evolving 
      clinical questions based on unfamiliar settings within a very short period. 
      ChatGPT outperformed human candidates in several knowledge areas. Not all 
      examiners were able to discern between human and ChatGPT responses. Our data 
      highlight the emergent ability of natural language processing models to 
      demonstrate fluid reasoning in unfamiliar environments and successfully compete 
      with human candidates that have undergone extensive specialist training.
CI  - Copyright © 2023 The Author(s). Published by Elsevier Inc. All rights reserved.
FAU - Li, Sarah W
AU  - Li SW
AD  - Department of Obstetrics and Gynaecology, National University Hospital, 
      Singapore, Singapore.
FAU - Kemp, Matthew W
AU  - Kemp MW
AD  - Department of Obstetrics and Gynaecology, Yong Loo Lin School of Medicine, 
      National University of Singapore, Singapore, Singapore; Centre for Perinatal and 
      Neonatal Medicine, Tohoku University Hospital, Sendai, Japan; Department of 
      Obstetrics and Gynaecology, University of Western Australia, Perth, Australia; 
      Women and Infants Research Foundation, King Edward Memorial Hospital, Subiaco, 
      Western Australia, Australia.
FAU - Logan, Susan J S
AU  - Logan SJS
AD  - Department of Obstetrics and Gynaecology, National University Hospital, 
      Singapore, Singapore.
FAU - Dimri, Pooja Sharma
AU  - Dimri PS
AD  - Department of Obstetrics and Gynaecology, National University Hospital, 
      Singapore, Singapore.
FAU - Singh, Navkaran
AU  - Singh N
AD  - Department of Obstetrics and Gynaecology, National University Hospital, 
      Singapore, Singapore.
FAU - Mattar, Citra N Z
AU  - Mattar CNZ
AD  - Department of Obstetrics and Gynaecology, National University Hospital, 
      Singapore, Singapore; Department of Obstetrics and Gynaecology, Yong Loo Lin 
      School of Medicine, National University of Singapore, Singapore, Singapore.
FAU - Dashraath, Pradip
AU  - Dashraath P
AD  - Department of Obstetrics and Gynaecology, National University Hospital, 
      Singapore, Singapore; Department of Obstetrics and Gynaecology, Yong Loo Lin 
      School of Medicine, National University of Singapore, Singapore, Singapore.
FAU - Ramlal, Harshaana
AU  - Ramlal H
AD  - Department of Obstetrics and Gynaecology, National University Hospital, 
      Singapore, Singapore.
FAU - Mahyuddin, Aniza P
AU  - Mahyuddin AP
AD  - Department of Obstetrics and Gynaecology, Yong Loo Lin School of Medicine, 
      National University of Singapore, Singapore, Singapore.
FAU - Kanayan, Suren
AU  - Kanayan S
AD  - Department of Obstetrics and Gynaecology, Yong Loo Lin School of Medicine, 
      National University of Singapore, Singapore, Singapore.
FAU - Carter, Sean W D
AU  - Carter SWD
AD  - Department of Obstetrics and Gynaecology, Yong Loo Lin School of Medicine, 
      National University of Singapore, Singapore, Singapore.
FAU - Thain, Serene P T
AU  - Thain SPT
AD  - Department of Maternal-Fetal Medicine, Division of Obstetrics and Gynaecology, KK 
      Women's and Children's Hospital, Singapore, Singapore.
FAU - Fee, Erin L
AU  - Fee EL
AD  - Department of Obstetrics and Gynaecology, University of Western Australia, Perth, 
      Australia.
FAU - Illanes, Sebastian E
AU  - Illanes SE
AD  - Department of Obstetrics and Gynaecology, Yong Loo Lin School of Medicine, 
      National University of Singapore, Singapore, Singapore; Department of Obstetrics 
      and Gynecology, and Reproductive Biology Laboratory, Universidad de Los Andes, 
      Santiago, Chile; Reproductive Biology Program, Center for Biomedical Research and 
      Innovation, Universidad de los Andes, Santiago, Chile; Center of Interventional 
      Medicine for Precision and Advanced Cellular Therapy (IMPACT), Santiago, Chile; 
      Faculty of Medicine, Department of Obstetrics and Gynecology, Universidad de los 
      Andes, Santiago, Chile.
FAU - Choolani, Mahesh A
AU  - Choolani MA
AD  - Department of Obstetrics and Gynaecology, Yong Loo Lin School of Medicine, 
      National University of Singapore, Singapore, Singapore. Electronic address: 
      obgmac@nus.edu.sg.
CN  - National University of Singapore Obstetrics and Gynecology Artificial 
      Intelligence (NUS OBGYN-AI) Collaborative Group
LA  - eng
PT  - Journal Article
DEP - 20230422
PL  - United States
TA  - Am J Obstet Gynecol
JT  - American journal of obstetrics and gynecology
JID - 0370476
SB  - IM
MH  - Humans
MH  - *Gynecology/education
MH  - *Obstetrics/education
MH  - Artificial Intelligence
MH  - Clinical Competence
MH  - Educational Measurement
OTO - NOTNLM
OT  - Chat Generative Pre-trained Transformer
OT  - artificial intelligence
OT  - objective structured clinical examination
OT  - obstetrics and gynecology
OT  - postgraduate specialty training
OT  - reasoning
FIR - Rauff, Mary
IR  - Rauff M
FIR - Biswas, Arijit
IR  - Biswas A
FIR - Low, Jeffrey J H
IR  - Low JJH
FIR - Ng, Joseph S
IR  - Ng JS
FIR - Gosavi, Arundhati T
IR  - Gosavi AT
FIR - Huang, Zhongwei
IR  - Huang Z
FIR - Rajendran, Preethi
IR  - Rajendran P
FIR - Ng, Kwok Weng Roy
IR  - Ng KWR
FIR - Wong, Jeslyn J L
IR  - Wong JJL
FIR - Chan, Grace M F
IR  - Chan GMF
FIR - Lee, Kelvin Zhi Xing
IR  - Lee KZX
FIR - Yap, Jeannie J Y
IR  - Yap JJY
FIR - Ahmad, Nurulhuda
IR  - Ahmad N
FIR - Shanmugam, Shwetha
IR  - Shanmugam S
FIR - Kathirvel, Rajeswari
IR  - Kathirvel R
FIR - Mathur, Manisha
IR  - Mathur M
FIR - Lim, Whui Whui
IR  - Lim WW
FIR - Lim, Min Yu
IR  - Lim MY
EDAT- 2023/04/24 00:41
MHDA- 2023/07/24 06:42
CRDT- 2023/04/23 19:30
PHST- 2023/03/21 00:00 [received]
PHST- 2023/04/17 00:00 [revised]
PHST- 2023/04/18 00:00 [accepted]
PHST- 2023/07/24 06:42 [medline]
PHST- 2023/04/24 00:41 [pubmed]
PHST- 2023/04/23 19:30 [entrez]
AID - S0002-9378(23)00251-X [pii]
AID - 10.1016/j.ajog.2023.04.020 [doi]
PST - ppublish
SO  - Am J Obstet Gynecol. 2023 Aug;229(2):172.e1-172.e12. doi: 
      10.1016/j.ajog.2023.04.020. Epub 2023 Apr 22.

PMID- 37227477
OWN - NLM
STAT- Publisher
LR  - 20231019
IS  - 1435-702X (Electronic)
IS  - 0721-832X (Linking)
VI  - 261
IP  - 11
DP  - 2023 Nov
TI  - ChatGPT and scientific abstract writing: pitfalls and caution.
PG  - 3205-3206
LID - 10.1007/s00417-023-06123-z [doi]
FAU - Ali, Mohammad Javed
AU  - Ali MJ
AUID- ORCID: 0000-0002-6363-9202
AD  - Govindram Seksaria Institute of Dacryology, L.V. Prasad Eye Institute, Road no 2, 
      Banjara Hills, Hyderabad, -34, India. drjaved007@gmail.com.
FAU - Singh, Swati
AU  - Singh S
AD  - Ophthalmic Plastic Surgery Service, L.V. Prasad Eye Institute, Hyderabad, India.
LA  - eng
PT  - Journal Article
DEP - 20230525
PL  - Germany
TA  - Graefes Arch Clin Exp Ophthalmol
JT  - Graefe's archive for clinical and experimental ophthalmology = Albrecht von 
      Graefes Archiv fur klinische und experimentelle Ophthalmologie
JID - 8205248
SB  - IM
OTO - NOTNLM
OT  - Abstract
OT  - ChatGPT
OT  - Ethics
OT  - Ophthalmology
OT  - Publication
OT  - Scientific
EDAT- 2023/05/25 13:06
MHDA- 2023/05/25 13:06
CRDT- 2023/05/25 11:16
PHST- 2023/03/29 00:00 [received]
PHST- 2023/05/17 00:00 [accepted]
PHST- 2023/04/27 00:00 [revised]
PHST- 2023/05/25 13:06 [pubmed]
PHST- 2023/05/25 13:06 [medline]
PHST- 2023/05/25 11:16 [entrez]
AID - 10.1007/s00417-023-06123-z [pii]
AID - 10.1007/s00417-023-06123-z [doi]
PST - ppublish
SO  - Graefes Arch Clin Exp Ophthalmol. 2023 Nov;261(11):3205-3206. doi: 
      10.1007/s00417-023-06123-z. Epub 2023 May 25.

PMID- 37207982
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20231023
LR  - 20231025
IS  - 1469-0691 (Electronic)
IS  - 1198-743X (Linking)
VI  - 29
IP  - 8
DP  - 2023 Aug
TI  - A study on the performance of ChatGPT in infectious diseases clinical 
      consultation.
PG  - 1088-1089
LID - S1198-743X(23)00241-0 [pii]
LID - 10.1016/j.cmi.2023.05.017 [doi]
FAU - Sarink, Maarten J
AU  - Sarink MJ
AD  - Department of Medical Microbiology and Infectious Diseases, Erasmus University 
      Medical Center, Rotterdam, The Netherlands.
FAU - Bakker, Ingrid L
AU  - Bakker IL
AD  - Department of Medical Microbiology and Infectious Diseases, Erasmus University 
      Medical Center, Rotterdam, The Netherlands.
FAU - Anas, Adam A
AU  - Anas AA
AD  - Department of Medical Microbiology and Infectious Diseases, Erasmus University 
      Medical Center, Rotterdam, The Netherlands.
FAU - Yusuf, Erlangga
AU  - Yusuf E
AD  - Department of Medical Microbiology and Infectious Diseases, Erasmus University 
      Medical Center, Rotterdam, The Netherlands. Electronic address: 
      angga.yusuf@gmail.com.
LA  - eng
PT  - Letter
DEP - 20230518
PL  - England
TA  - Clin Microbiol Infect
JT  - Clinical microbiology and infection : the official publication of the European 
      Society of Clinical Microbiology and Infectious Diseases
JID - 9516420
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Clinical consultation
OT  - Clinical microbiology
OT  - Infectious disease
EDAT- 2023/05/20 09:42
MHDA- 2023/05/20 09:43
CRDT- 2023/05/19 19:28
PHST- 2023/03/26 00:00 [received]
PHST- 2023/05/10 00:00 [revised]
PHST- 2023/05/11 00:00 [accepted]
PHST- 2023/05/20 09:43 [medline]
PHST- 2023/05/20 09:42 [pubmed]
PHST- 2023/05/19 19:28 [entrez]
AID - S1198-743X(23)00241-0 [pii]
AID - 10.1016/j.cmi.2023.05.017 [doi]
PST - ppublish
SO  - Clin Microbiol Infect. 2023 Aug;29(8):1088-1089. doi: 10.1016/j.cmi.2023.05.017. 
      Epub 2023 May 18.

PMID- 37101311
OWN - NLM
STAT- MEDLINE
DCOM- 20230719
LR  - 20230719
IS  - 1440-1800 (Electronic)
IS  - 1320-7881 (Linking)
VI  - 30
IP  - 3
DP  - 2023 Jul
TI  - Will ChatGPT undermine ethical values in nursing education, research, and 
      practice?
PG  - e12556
LID - 10.1111/nin.12556 [doi]
FAU - Abdulai, Abdul-Fatawu
AU  - Abdulai AF
AUID- ORCID: 0000-0002-9395-8642
AD  - School of Nursing, University of British Columbia, Vancouver, British Columbia, 
      Canada.
FAU - Hung, Lillian
AU  - Hung L
AD  - School of Nursing, University of British Columbia, Vancouver, British Columbia, 
      Canada.
LA  - eng
PT  - Journal Article
DEP - 20230426
PL  - Australia
TA  - Nurs Inq
JT  - Nursing inquiry
JID - 9505881
MH  - Humans
MH  - *Education, Nursing/ethics
MH  - *Artificial Intelligence
MH  - *Nursing Research/ethics
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - ethics and values
OT  - nursing
EDAT- 2023/04/27 00:42
MHDA- 2023/07/19 06:43
CRDT- 2023/04/26 23:52
PHST- 2023/04/03 00:00 [received]
PHST- 2023/04/05 00:00 [accepted]
PHST- 2023/07/19 06:43 [medline]
PHST- 2023/04/27 00:42 [pubmed]
PHST- 2023/04/26 23:52 [entrez]
AID - 10.1111/nin.12556 [doi]
PST - ppublish
SO  - Nurs Inq. 2023 Jul;30(3):e12556. doi: 10.1111/nin.12556. Epub 2023 Apr 26.

PMID- 38483426
OWN - NLM
STAT- Publisher
LR  - 20240314
IS  - 1097-6760 (Electronic)
IS  - 0196-0644 (Linking)
DP  - 2024 Mar 12
TI  - Harnessing the Power of Generative AI for Clinical Summaries: Perspectives From 
      Emergency Physicians.
LID - S0196-0644(24)00078-7 [pii]
LID - 10.1016/j.annemergmed.2024.01.039 [doi]
AB  - STUDY OBJECTIVE: The workload of clinical documentation contributes to health 
      care costs and professional burnout. The advent of generative artificial 
      intelligence language models presents a promising solution. The perspective of 
      clinicians may contribute to effective and responsible implementation of such 
      tools. This study sought to evaluate 3 uses for generative artificial 
      intelligence for clinical documentation in pediatric emergency medicine, 
      measuring time savings, effort reduction, and physician attitudes and identifying 
      potential risks and barriers. METHODS: This mixed-methods study was performed 
      with 10 pediatric emergency medicine attending physicians from a single pediatric 
      emergency department. Participants were asked to write a supervisory note for 4 
      clinical scenarios, with varying levels of complexity, twice without any 
      assistance and twice with the assistance of ChatGPT Version 4.0. Participants 
      evaluated 2 additional ChatGPT-generated clinical summaries: a structured handoff 
      and a visit summary for a family written at an 8th grade reading level. Finally, 
      a semistructured interview was performed to assess physicians' perspective on the 
      use of ChatGPT in pediatric emergency medicine. Main outcomes and measures 
      included between subjects' comparisons of the effort and time taken to complete 
      the supervisory note with and without ChatGPT assistance. Effort was measured 
      using a self-reported Likert scale of 0 to 10. Physicians' scoring of and 
      attitude toward the ChatGPT-generated summaries were measured using a 0 to 10 
      Likert scale and open-ended questions. Summaries were scored for completeness, 
      accuracy, efficiency, readability, and overall satisfaction. A thematic analysis 
      was performed to analyze the content of the open-ended questions and to identify 
      key themes. RESULTS: ChatGPT yielded a 40% reduction in time and a 33% decrease 
      in effort for supervisory notes in intricate cases, with no discernible effect on 
      simpler notes. ChatGPT-generated summaries for structured handoffs and family 
      letters were highly rated, ranging from 7.0 to 9.0 out of 10, and most 
      participants favored their inclusion in clinical practice. However, there were 
      several critical reservations, out of which a set of general recommendations for 
      applying ChatGPT to clinical summaries was formulated. CONCLUSION: Pediatric 
      emergency medicine attendings in our study perceived that ChatGPT can deliver 
      high-quality summaries while saving time and effort in many scenarios, but not 
      all.
CI  - Copyright © 2024 American College of Emergency Physicians. Published by Elsevier 
      Inc. All rights reserved.
FAU - Barak-Corren, Yuval
AU  - Barak-Corren Y
AD  - Predictive Medicine Group, Computational Health Informatics Program, Boston 
      Children's Hospital, Boston, MA; Division of Cardiology, Children's Hospital of 
      Philadelphia, Philadelphia, PA. Electronic address: 
      yuval.barakcorren@childrens.harvard.edu.
FAU - Wolf, Rebecca
AU  - Wolf R
AD  - Emergency Medicine Boston Children's Hospital, Boston, MA.
FAU - Rozenblum, Ronen
AU  - Rozenblum R
AD  - Harvard Medical School Boston, MA; Division of General Internal Medicine and 
      Primary Care, Brigham and Women's Hospital, Boston, MA.
FAU - Creedon, Jessica K
AU  - Creedon JK
AD  - Emergency Medicine Boston Children's Hospital, Boston, MA; Harvard Medical School 
      Boston, MA.
FAU - Lipsett, Susan C
AU  - Lipsett SC
AD  - Emergency Medicine Boston Children's Hospital, Boston, MA; Harvard Medical School 
      Boston, MA.
FAU - Lyons, Todd W
AU  - Lyons TW
AD  - Emergency Medicine Boston Children's Hospital, Boston, MA; Harvard Medical School 
      Boston, MA.
FAU - Michelson, Kenneth A
AU  - Michelson KA
AD  - Ann and Robert Lurie Children's Hospital of Chicago, Chicago, IL.
FAU - Miller, Kelsey A
AU  - Miller KA
AD  - Emergency Medicine Boston Children's Hospital, Boston, MA; Harvard Medical School 
      Boston, MA.
FAU - Shapiro, Daniel
AU  - Shapiro D
AD  - Division of Pediatric Emergency Medicine, University of California, San 
      Francisco, San Francisco, CA.
FAU - Reis, Ben Y
AU  - Reis BY
AD  - Predictive Medicine Group, Computational Health Informatics Program, Boston 
      Children's Hospital, Boston, MA; Harvard Medical School Boston, MA.
FAU - Fine, Andrew M
AU  - Fine AM
AD  - Emergency Medicine Boston Children's Hospital, Boston, MA; Harvard Medical School 
      Boston, MA.
LA  - eng
PT  - Journal Article
DEP - 20240312
PL  - United States
TA  - Ann Emerg Med
JT  - Annals of emergency medicine
JID - 8002646
SB  - IM
EDAT- 2024/03/14 12:48
MHDA- 2024/03/14 12:48
CRDT- 2024/03/14 11:36
PHST- 2023/09/21 00:00 [received]
PHST- 2024/01/24 00:00 [revised]
PHST- 2024/01/29 00:00 [accepted]
PHST- 2024/03/14 12:48 [medline]
PHST- 2024/03/14 12:48 [pubmed]
PHST- 2024/03/14 11:36 [entrez]
AID - S0196-0644(24)00078-7 [pii]
AID - 10.1016/j.annemergmed.2024.01.039 [doi]
PST - aheadofprint
SO  - Ann Emerg Med. 2024 Mar 12:S0196-0644(24)00078-7. doi: 
      10.1016/j.annemergmed.2024.01.039.

PMID- 37717655
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20231128
LR  - 20240205
IS  - 1535-7732 (Electronic)
IS  - 1051-0443 (Linking)
VI  - 34
IP  - 12
DP  - 2023 Dec
TI  - Can Chat Generative Pretraining Transformer (ChatGPT) Be Used for Statistical 
      Analysis of Research Data?
PG  - 2242-2246.e2
LID - S1051-0443(23)00669-3 [pii]
LID - 10.1016/j.jvir.2023.09.010 [doi]
FAU - Jahangiri, Younes
AU  - Jahangiri Y
AD  - Department of Interventional Radiology, Corewell Health West Michigan, 100 
      Michigan St NE, Grand Rapids, MI 49503. Electronic address: 
      y.jahangiri@gmail.com.
LA  - eng
PT  - Letter
DEP - 20230917
PL  - United States
TA  - J Vasc Interv Radiol
JT  - Journal of vascular and interventional radiology : JVIR
JID - 9203369
SB  - IM
EDAT- 2023/09/18 00:41
MHDA- 2023/09/18 00:42
CRDT- 2023/09/17 19:14
PHST- 2023/07/06 00:00 [received]
PHST- 2023/09/07 00:00 [revised]
PHST- 2023/09/08 00:00 [accepted]
PHST- 2023/09/18 00:42 [medline]
PHST- 2023/09/18 00:41 [pubmed]
PHST- 2023/09/17 19:14 [entrez]
AID - S1051-0443(23)00669-3 [pii]
AID - 10.1016/j.jvir.2023.09.010 [doi]
PST - ppublish
SO  - J Vasc Interv Radiol. 2023 Dec;34(12):2242-2246.e2. doi: 
      10.1016/j.jvir.2023.09.010. Epub 2023 Sep 17.

PMID- 38168838
OWN - NLM
STAT- MEDLINE
DCOM- 20240105
LR  - 20240202
IS  - 1477-4054 (Electronic)
IS  - 1467-5463 (Print)
IS  - 1467-5463 (Linking)
VI  - 25
IP  - 1
DP  - 2023 Nov 22
TI  - Opportunities and challenges for ChatGPT and large language models in biomedicine 
      and health.
LID - 10.1093/bib/bbad493 [doi]
LID - bbad493
AB  - ChatGPT has drawn considerable attention from both the general public and domain 
      experts with its remarkable text generation capabilities. This has subsequently 
      led to the emergence of diverse applications in the field of biomedicine and 
      health. In this work, we examine the diverse applications of large language 
      models (LLMs), such as ChatGPT, in biomedicine and health. Specifically, we 
      explore the areas of biomedical information retrieval, question answering, 
      medical text summarization, information extraction and medical education and 
      investigate whether LLMs possess the transformative power to revolutionize these 
      tasks or whether the distinct complexities of biomedical domain presents unique 
      challenges. Following an extensive literature survey, we find that significant 
      advances have been made in the field of text generation tasks, surpassing the 
      previous state-of-the-art methods. For other applications, the advances have been 
      modest. Overall, LLMs have not yet revolutionized biomedicine, but recent rapid 
      progress indicates that such methods hold great potential to provide valuable 
      means for accelerating discovery and improving health. We also find that the use 
      of LLMs, like ChatGPT, in the fields of biomedicine and health entails various 
      risks and challenges, including fabricated information in its generated 
      responses, as well as legal and privacy concerns associated with sensitive 
      patient data. We believe this survey can provide a comprehensive and timely 
      overview to biomedical researchers and healthcare practitioners on the 
      opportunities and challenges associated with using ChatGPT and other LLMs for 
      transforming biomedicine and health.
CI  - © Published by Oxford University Press 2024.
FAU - Tian, Shubo
AU  - Tian S
AUID- ORCID: 0000-0001-6415-1439
AD  - National Library of Medicine, National Institutes of Health.
FAU - Jin, Qiao
AU  - Jin Q
AUID- ORCID: 0000-0002-1268-7239
AD  - National Library of Medicine, National Institutes of Health.
FAU - Yeganova, Lana
AU  - Yeganova L
AD  - National Library of Medicine, National Institutes of Health.
FAU - Lai, Po-Ting
AU  - Lai PT
AD  - National Library of Medicine, National Institutes of Health.
FAU - Zhu, Qingqing
AU  - Zhu Q
AD  - National Library of Medicine, National Institutes of Health.
FAU - Chen, Xiuying
AU  - Chen X
AD  - King Abdullah University of Science and Technology.
FAU - Yang, Yifan
AU  - Yang Y
AD  - National Library of Medicine, National Institutes of Health.
FAU - Chen, Qingyu
AU  - Chen Q
AD  - National Library of Medicine, National Institutes of Health.
FAU - Kim, Won
AU  - Kim W
AD  - National Library of Medicine, National Institutes of Health.
FAU - Comeau, Donald C
AU  - Comeau DC
AD  - National Library of Medicine, National Institutes of Health.
FAU - Islamaj, Rezarta
AU  - Islamaj R
AUID- ORCID: 0000-0001-5651-1860
AD  - National Library of Medicine, National Institutes of Health.
FAU - Kapoor, Aadit
AU  - Kapoor A
AD  - National Library of Medicine, National Institutes of Health.
FAU - Gao, Xin
AU  - Gao X
AD  - King Abdullah University of Science and Technology.
FAU - Lu, Zhiyong
AU  - Lu Z
AD  - National Library of Medicine, National Institutes of Health.
LA  - eng
GR  - K99 LM014024/LM/NLM NIH HHS/United States
GR  - 1K99LM014024/NH/NIH HHS/United States
PT  - Journal Article
PL  - England
TA  - Brief Bioinform
JT  - Briefings in bioinformatics
JID - 100912837
SB  - IM
UOF - ArXiv. 2023 Oct 17;:. PMID: 37904734
MH  - Humans
MH  - *Information Storage and Retrieval
MH  - *Language
MH  - Privacy
MH  - Research Personnel
PMC - PMC10762511
OTO - NOTNLM
OT  - ChatGPT
OT  - biomedicine and health
OT  - generative AI
OT  - large language model
OT  - opportunities and challenges
EDAT- 2024/01/04 01:18
MHDA- 2024/01/05 06:42
PMCR- 2025/01/02
CRDT- 2024/01/03 11:02
PHST- 2023/06/28 00:00 [received]
PHST- 2023/11/15 00:00 [revised]
PHST- 2023/12/06 00:00 [accepted]
PHST- 2025/01/02 00:00 [pmc-release]
PHST- 2024/01/05 06:42 [medline]
PHST- 2024/01/04 01:18 [pubmed]
PHST- 2024/01/03 11:02 [entrez]
AID - 7505071 [pii]
AID - bbad493 [pii]
AID - 10.1093/bib/bbad493 [doi]
PST - ppublish
SO  - Brief Bioinform. 2023 Nov 22;25(1):bbad493. doi: 10.1093/bib/bbad493.

PMID- 38550977
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240330
IS  - 1178-6329 (Print)
IS  - 1178-6329 (Electronic)
IS  - 1178-6329 (Linking)
VI  - 17
DP  - 2024
TI  - ChatGPT Versus Medical Professionals: Comment.
PG  - 11786329241241904
LID - 10.1177/11786329241241904 [doi]
LID - 11786329241241904
FAU - Daungsupawong, Hinpetch
AU  - Daungsupawong H
AD  - Private Academic Consultant, Phonhong, Lao People's Democratic Republic.
FAU - Wiwanitkit, Viroj
AU  - Wiwanitkit V
AD  - University Centre for Research &amp; Development Department of Pharmaceutical 
      Sciences, Chandigarh University Gharuan, Mohali, Punjab, India.
LA  - eng
PT  - Journal Article
DEP - 20240327
PL  - United States
TA  - Health Serv Insights
JT  - Health services insights
JID - 101624726
PMC - PMC10976479
OTO - NOTNLM
OT  - chatGPT
OT  - health information Technology
OT  - healthcare compliance
OT  - healthcare technology
OT  - professional
COIS- The author(s) declared no potential conflicts of interest with respect to the 
      research, authorship, and/or publication of this article.
EDAT- 2024/03/29 06:46
MHDA- 2024/03/29 06:47
PMCR- 2024/03/27
CRDT- 2024/03/29 04:19
PHST- 2024/02/08 00:00 [received]
PHST- 2024/03/09 00:00 [accepted]
PHST- 2024/03/29 06:47 [medline]
PHST- 2024/03/29 06:46 [pubmed]
PHST- 2024/03/29 04:19 [entrez]
PHST- 2024/03/27 00:00 [pmc-release]
AID - 10.1177_11786329241241904 [pii]
AID - 10.1177/11786329241241904 [doi]
PST - epublish
SO  - Health Serv Insights. 2024 Mar 27;17:11786329241241904. doi: 
      10.1177/11786329241241904. eCollection 2024.

PMID- 38215796
OWN - NLM
STAT- Publisher
LR  - 20240213
IS  - 1097-6787 (Electronic)
IS  - 0190-9622 (Linking)
DP  - 2024 Jan 10
TI  - Response to Young et&nbsp;al., "The utility of ChatGPT in generating patient-facing 
      and clinical responses for melanoma".
LID - S0190-9622(24)00060-4 [pii]
LID - 10.1016/j.jaad.2023.12.052 [doi]
FAU - Timurkaynak, Özgür
AU  - Timurkaynak Ö
AD  - Department of Dermatology, Acibadem Mehmet Ali Aydinlar University School of 
      Medicine, Istanbul, Turkey. Electronic address: ozgurtimurkaynak@hotmail.com.
FAU - Gönenli, Gökhan
AU  - Gönenli G
AD  - Department of Internal Medicine, Koç University School of Medicine, Istanbul, 
      Turkey.
LA  - eng
PT  - Letter
DEP - 20240110
PL  - United States
TA  - J Am Acad Dermatol
JT  - Journal of the American Academy of Dermatology
JID - 7907132
SB  - IM
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - artifical intellegence
OT  - dermatology
OT  - melanoma
COIS- Conflicts of interest None disclosed.
EDAT- 2024/01/13 00:42
MHDA- 2024/01/13 00:42
CRDT- 2024/01/12 19:26
PHST- 2023/10/04 00:00 [received]
PHST- 2023/12/12 00:00 [revised]
PHST- 2023/12/13 00:00 [accepted]
PHST- 2024/01/13 00:42 [pubmed]
PHST- 2024/01/13 00:42 [medline]
PHST- 2024/01/12 19:26 [entrez]
AID - S0190-9622(24)00060-4 [pii]
AID - 10.1016/j.jaad.2023.12.052 [doi]
PST - aheadofprint
SO  - J Am Acad Dermatol. 2024 Jan 10:S0190-9622(24)00060-4. doi: 
      10.1016/j.jaad.2023.12.052.

PMID- 38038222
OWN - NLM
STAT- Publisher
LR  - 20231218
IS  - 1930-7837 (Electronic)
IS  - 0022-0337 (Linking)
DP  - 2023 Dec 1
TI  - Use of ChatGPT as an educational tool to support generating structured concept 
      maps for tobacco cessation (Pilot study).
LID - 10.1002/jdd.13430 [doi]
FAU - Omar, Hanan
AU  - Omar H
AUID- ORCID: 0000-0002-4144-7170
AD  - Missouri School of Dentistry and Oral Health, A.T. Still University, Kirksville, 
      Missouri, USA.
LA  - eng
PT  - Journal Article
DEP - 20231201
PL  - United States
TA  - J Dent Educ
JT  - Journal of dental education
JID - 8000150
SB  - IM
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - concept maps
OT  - critical thinking
EDAT- 2023/12/01 12:42
MHDA- 2023/12/01 12:42
CRDT- 2023/12/01 07:03
PHST- 2023/10/24 00:00 [revised]
PHST- 2023/05/30 00:00 [received]
PHST- 2023/11/03 00:00 [accepted]
PHST- 2023/12/01 12:42 [pubmed]
PHST- 2023/12/01 12:42 [medline]
PHST- 2023/12/01 07:03 [entrez]
AID - 10.1002/jdd.13430 [doi]
PST - aheadofprint
SO  - J Dent Educ. 2023 Dec 1. doi: 10.1002/jdd.13430.

PMID- 37229911
OWN - NLM
STAT- MEDLINE
DCOM- 20230615
LR  - 20230615
IS  - 1876-2026 (Electronic)
IS  - 1876-2018 (Linking)
VI  - 85
DP  - 2023 Jul
TI  - What do psychiatry researchers feel about ChatGPT? A study based on Natural 
      Language Processing techniques.
PG  - 103626
LID - S1876-2018(23)00181-8 [pii]
LID - 10.1016/j.ajp.2023.103626 [doi]
FAU - Praveen, S V
AU  - Praveen SV
AD  - Xavier Institute of Entrepreneurship and Management, Bangalore, Karnataka, India. 
      Electronic address: praveenscissci@gmail.com.
FAU - Lohia, Radhika
AU  - Lohia R
AD  - Xavier Institute of Entrepreneurship and Management, Bangalore, Karnataka, India.
LA  - eng
PT  - Letter
DEP - 20230514
PL  - Netherlands
TA  - Asian J Psychiatr
JT  - Asian journal of psychiatry
JID - 101517820
SB  - IM
MH  - Humans
MH  - *Natural Language Processing
MH  - *Emotions
OTO - NOTNLM
OT  - ChatGPT
OT  - Ethics
OT  - Natural Language Processing
OT  - Psychiatry
OT  - Research
COIS- Declaration of Competing Interest None.
EDAT- 2023/05/26 01:05
MHDA- 2023/06/15 06:42
CRDT- 2023/05/25 18:04
PHST- 2023/04/12 00:00 [received]
PHST- 2023/05/11 00:00 [revised]
PHST- 2023/05/12 00:00 [accepted]
PHST- 2023/06/15 06:42 [medline]
PHST- 2023/05/26 01:05 [pubmed]
PHST- 2023/05/25 18:04 [entrez]
AID - S1876-2018(23)00181-8 [pii]
AID - 10.1016/j.ajp.2023.103626 [doi]
PST - ppublish
SO  - Asian J Psychiatr. 2023 Jul;85:103626. doi: 10.1016/j.ajp.2023.103626. Epub 2023 
      May 14.

PMID- 37862879
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20231216
LR  - 20231216
IS  - 1532-818X (Electronic)
IS  - 0196-0709 (Linking)
VI  - 45
IP  - 1
DP  - 2024 Jan-Feb
TI  - Performance of ChatGPT in Otolaryngology knowledge assessment.
PG  - 104082
LID - S0196-0709(23)00296-X [pii]
LID - 10.1016/j.amjoto.2023.104082 [doi]
FAU - Revercomb, Lucy
AU  - Revercomb L
AD  - Department of Otolaryngology - Head and Neck Surgery, Rutgers New Jersey Medical 
      School, Newark, NJ, USA.
FAU - Patel, Aman M
AU  - Patel AM
AD  - Department of Otolaryngology - Head and Neck Surgery, Rutgers New Jersey Medical 
      School, Newark, NJ, USA.
FAU - Choudhry, Hassaam S
AU  - Choudhry HS
AD  - Department of Otolaryngology - Head and Neck Surgery, Rutgers New Jersey Medical 
      School, Newark, NJ, USA.
FAU - Filimonov, Andrey
AU  - Filimonov A
AD  - Department of Otolaryngology - Head and Neck Surgery, Rutgers New Jersey Medical 
      School, Newark, NJ, USA. Electronic address: andreyf@njms.rutgers.edu.
LA  - eng
PT  - Letter
DEP - 20231014
PL  - United States
TA  - Am J Otolaryngol
JT  - American journal of otolaryngology
JID - 8000029
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Board certification examination
OT  - ChatGPT
OT  - Medical education
COIS- Declaration of competing interest None.
EDAT- 2023/10/21 05:42
MHDA- 2023/10/21 05:43
CRDT- 2023/10/20 18:07
PHST- 2023/08/30 00:00 [received]
PHST- 2023/09/25 00:00 [accepted]
PHST- 2023/10/21 05:43 [medline]
PHST- 2023/10/21 05:42 [pubmed]
PHST- 2023/10/20 18:07 [entrez]
AID - S0196-0709(23)00296-X [pii]
AID - 10.1016/j.amjoto.2023.104082 [doi]
PST - ppublish
SO  - Am J Otolaryngol. 2024 Jan-Feb;45(1):104082. doi: 10.1016/j.amjoto.2023.104082. 
      Epub 2023 Oct 14.

PMID- 37052880
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20231030
LR  - 20231030
IS  - 1488-2361 (Electronic)
IS  - 0846-5371 (Linking)
VI  - 74
IP  - 4
DP  - 2023 Nov
TI  - Appropriateness of Recommendations Provided by ChatGPT to Interventional 
      Radiologists.
PG  - 758-763
LID - 10.1177/08465371231170133 [doi]
FAU - Barat, Maxime
AU  - Barat M
AD  - Department of Radiology, Hopital Cochin, AP-HP, Université Paris Cité, Paris, 
      France.
FAU - Soyer, Philippe
AU  - Soyer P
AUID- ORCID: 0000-0002-5055-1682
AD  - Department of Radiology, Hopital Cochin, AP-HP, Université Paris Cité, Paris, 
      France.
FAU - Dohan, Anthony
AU  - Dohan A
AD  - Department of Radiology, Hopital Cochin, AP-HP, Université Paris Cité, Paris, 
      France.
LA  - eng
PT  - Letter
DEP - 20230413
PL  - United States
TA  - Can Assoc Radiol J
JT  - Canadian Association of Radiologists journal = Journal l'Association canadienne 
      des radiologistes
JID - 8812910
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - generative pre-trained transformer
OT  - interventional radiology
OT  - radiology
COIS- Declaration of Conflicting InterestsThe author(s) declared no potential conflicts 
      of interest with respect to the research, authorship, and/or publication of this 
      article.
EDAT- 2023/04/14 06:00
MHDA- 2023/04/14 06:01
CRDT- 2023/04/13 11:30
PHST- 2023/04/14 06:01 [medline]
PHST- 2023/04/14 06:00 [pubmed]
PHST- 2023/04/13 11:30 [entrez]
AID - 10.1177/08465371231170133 [doi]
PST - ppublish
SO  - Can Assoc Radiol J. 2023 Nov;74(4):758-763. doi: 10.1177/08465371231170133. Epub 
      2023 Apr 13.

PMID- 38336588
OWN - NLM
STAT- Publisher
LR  - 20240209
IS  - 1531-5037 (Electronic)
IS  - 0022-3468 (Linking)
DP  - 2024 Jan 14
TI  - ChatGPT: What Every Pediatric Surgeon Should Know About Its Potential Uses and 
      Pitfalls.
LID - S0022-3468(24)00010-1 [pii]
LID - 10.1016/j.jpedsurg.2024.01.007 [doi]
AB  - ChatGPT - currently the most popular generative artificial intelligence system - 
      has been revolutionizing the world and healthcare since its release in November 
      2022. ChatGPT is a conversational chatbot that uses machine learning algorithms 
      to enhance its replies based on user interactions and is a part of a broader 
      effort to develop natural language processing that can assist people in their 
      daily lives by understanding and responding to human language in a useful and 
      engaging way. Thus far, many potential applications within healthcare have been 
      described, despite its relatively recent release. This manuscript offers the 
      pediatric surgical community a primer on this new technology and discusses some 
      initial observations about its potential uses and pitfalls. Moreover, it 
      introduces the perspectives of medical journals and surgical societies regarding 
      the use of this artificial intelligence chatbot. As ChatGPT and other large 
      language models continue to evolve, it is the responsibility of the pediatric 
      surgery community to stay abreast of these changes and play an active role in 
      safely incorporating them into our field for the benefit of our patients. LEVEL 
      OF EVIDENCE: V.
CI  - Copyright © 2024 Elsevier Inc. All rights reserved.
FAU - González, Raquel
AU  - González R
AD  - Division of Pediatric Surgery, Johns Hopkins All Children's Hospital, 501 6th 
      Avenue S, Saint Petersburg, FL, 33701, USA. Electronic address: 
      rgonza35@jhmi.edu.
FAU - Poenaru, Dan
AU  - Poenaru D
AD  - McGill University, 5252 Boul. De Maissonneuve O. rm. 3E.05, Montréal, QC, H4a 
      3S5, Canada.
FAU - Woo, Russell
AU  - Woo R
AD  - Department of Surgery, Division of Pediatric Surgery, University of Hawai'i, John 
      A. Burns School of Medicine, 1319 Punahou Street, Suite 600, Honolulu, HI, 96826, 
      USA.
FAU - Trappey, A Francois 3rd
AU  - Trappey AF 3rd
AD  - Pediatric General and Thoracic Surgery, Brooke Army Medical Center, 3551 Roger 
      Brooke Dr, Fort Sam Houston, TX, 78234, USA.
FAU - Carter, Stewart
AU  - Carter S
AD  - Division of Pediatric Surgery, University of Louisville, Norton Children's 
      Hospital, 315 East Broadway, Suite 565, Louisville, KY, 40202, USA.
FAU - Darcy, David
AU  - Darcy D
AD  - Golisano Children's Hospital, University of Rochester Medical Center, 601 Elmwood 
      Avenue, Box SURG, Rochester, NY, 14642, USA.
FAU - Encisco, Ellen
AU  - Encisco E
AD  - Division of Pediatric General and Thoracic Surgery, Cincinnati Children's 
      Hospital, 3333 Burnet Ave, Cincinnati, OH, 45229, USA.
FAU - Gulack, Brian
AU  - Gulack B
AD  - Rush University Medical Center, 1653 W Congress Parkway, Kellogg, Chicago, IL, 
      60612, USA.
FAU - Miniati, Doug
AU  - Miniati D
AD  - Department of Pediatric Surgery, Kaiser Permanente Roseville, 1600 Eureka Road, 
      Building C, Suite C35, Roseville, CA, 95661, USA.
FAU - Tombash, Edzhem
AU  - Tombash E
AD  - Division of Pediatric General and Thoracic Surgery, Cincinnati Children's 
      Hospital, 3333 Burnet Ave, Cincinnati, OH, 45229, USA.
FAU - Huang, Eunice Y
AU  - Huang EY
AD  - Vanderbilt University Medical Center, Monroe Carell Jr. Children's Hospital, 2200 
      Children's Way, Suite 7100, Nashville, TN, 37232, USA.
CN  - Pediatric Surgery ChatGPT Collaborative Group
LA  - eng
PT  - Journal Article
PT  - Review
DEP - 20240114
PL  - United States
TA  - J Pediatr Surg
JT  - Journal of pediatric surgery
JID - 0052631
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Large language models
OT  - Natural language processing
OT  - Pediatric surgery
COIS- Declarations of competing interest None.
EDAT- 2024/02/10 13:18
MHDA- 2024/02/10 13:18
CRDT- 2024/02/09 21:58
PHST- 2023/08/02 00:00 [received]
PHST- 2023/12/30 00:00 [revised]
PHST- 2024/01/09 00:00 [accepted]
PHST- 2024/02/10 13:18 [medline]
PHST- 2024/02/10 13:18 [pubmed]
PHST- 2024/02/09 21:58 [entrez]
AID - S0022-3468(24)00010-1 [pii]
AID - 10.1016/j.jpedsurg.2024.01.007 [doi]
PST - aheadofprint
SO  - J Pediatr Surg. 2024 Jan 14:S0022-3468(24)00010-1. doi: 
      10.1016/j.jpedsurg.2024.01.007.

PMID- 38259300
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240124
IS  - 2253-2447 (Print)
IS  - 2253-2447 (Electronic)
IS  - 2253-2447 (Linking)
VI  - 16
DP  - 2024
TI  - ChatGPT: Is This Patient Education Tool for Urological Malignancies Readable for 
      the General Population?
PG  - 31-37
LID - 10.2147/RRU.S440633 [doi]
AB  - BACKGROUND: With widespread adoption of technological advancements in everyday 
      life, patients are now increasingly able and willing to obtain information about 
      their health conditions, treatment options, and indeed expected outcomes via the 
      convenience of any device than can access the worldwide web. This introduces 
      another aspect of patient care in the provision of healthcare for the modern 
      doctor. ChatGPT is the first of an increasing number of self learning programs 
      that have been released recently which may revolutionize and impact healthcare 
      delivery. METHODS: The aim of this study is to obtain an objective measure of the 
      readability of information provided on ChatGPT when compared with current 
      validated patient information sheets provided by government health institutions 
      in Western Australia. The same structured questions were input into the program 
      for three major urological malignancies (urothelial, renal, and prostate), with 
      the response generated evaluated with a validated readability scoring system - 
      Flesch-Kincaid reading ease score. The same scoring system was then applied to 
      current patient information sheets in circulation from Cancer Council Australia 
      and UpToDate. RESULTS: Findings in this study looking at ease of readability of 
      information provided on ChatGPT as compared to other government bodies and 
      healthcare institutions confirm that they are non-inferior and may be a useful 
      tool or adjunct to the traditional clinic based consultations. Ease of use of the 
      information generated from ChatGPT was increased further when the question was 
      modified to target an audience of 16 years of age, the average level of education 
      attained by an Australian. DISCUSSION: Future research can be done to look into 
      incorporating the use of similar technologies to increase efficiency in the 
      healthcare system and reduce healthcare costs.
CI  - © 2024 Thia and Saluja.
FAU - Thia, Ivan
AU  - Thia I
AUID- ORCID: 0009-0002-9718-4178
AD  - Department of Urology, Royal Perth Hospital, Perth, WA, Australia.
FAU - Saluja, Manmeet
AU  - Saluja M
AD  - Department of Urology, Royal Perth Hospital, Perth, WA, Australia.
LA  - eng
PT  - Journal Article
DEP - 20240116
PL  - England
TA  - Res Rep Urol
JT  - Research and reports in urology
JID - 101576971
PMC - PMC10800281
OTO - NOTNLM
OT  - ChatGPT
OT  - innovative education
OT  - patient education
OT  - urological malignancies
COIS- The authors report no conflicts of interest in this work.
EDAT- 2024/01/23 12:43
MHDA- 2024/01/23 12:44
PMCR- 2024/01/16
CRDT- 2024/01/23 10:24
PHST- 2023/10/19 00:00 [received]
PHST- 2023/12/17 00:00 [accepted]
PHST- 2024/01/23 12:44 [medline]
PHST- 2024/01/23 12:43 [pubmed]
PHST- 2024/01/23 10:24 [entrez]
PHST- 2024/01/16 00:00 [pmc-release]
AID - 440633 [pii]
AID - 10.2147/RRU.S440633 [doi]
PST - epublish
SO  - Res Rep Urol. 2024 Jan 16;16:31-37. doi: 10.2147/RRU.S440633. eCollection 2024.

PMID- 37724211
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230920
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 8
DP  - 2023 Aug
TI  - Mind + Machine: ChatGPT as a Basic Clinical Decisions Support Tool.
PG  - e43690
LID - 10.7759/cureus.43690 [doi]
LID - e43690
AB  - Background Generative artificial intelligence (AI) has integrated into various 
      industries as it has demonstrated enormous potential in automating elaborate 
      processes and enhancing complex decision-making. The ability of these chatbots to 
      critically triage, diagnose, and manage complex medical conditions, remains 
      unknown&nbsp;and requires further research. Objective This cross-sectional study 
      sought to quantitatively analyze the appropriateness of ChatGPT (OpenAI, San 
      Francisco, CA, US) in its ability to triage, synthesize differential diagnoses, 
      and generate treatment plans for nine diverse but common clinical scenarios.&nbsp; 
      Methods Various common clinical scenarios were developed. Each was input into 
      ChatGPT, and the chatbot was asked to develop diagnostic and treatment plans. 
      Five practicing physicians independently scored ChatGPT's responses to the 
      clinical scenarios.&nbsp; Results&nbsp; The average overall score for the triage ranking 
      was 4.2 (SD 0.7). The lowest overall score was for the completeness of the 
      differential diagnosis at 4.1 (0.5). The highest overall scores were seen with 
      the accuracy of the differential diagnosis, initial treatment plan, and overall 
      usefulness of the response (all with an average score of 4.4). Variance among 
      physician scores ranged from 0.24 for accuracy of the differential diagnosis to 
      0.49 for appropriateness of triage ranking.&nbsp; Discussion ChatGPT has the potential 
      to augment clinical decision-making. More extensive research, however, is needed 
      to ensure accuracy and appropriate recommendations are provided.
CI  - Copyright © 2023, Ayoub et al.
FAU - Ayoub, Marc
AU  - Ayoub M
AD  - Neurocritical Care, Northwell, Northshore University Hospital, Manhasset, USA.
AD  - Internal Medicine, Elmhurst Hospital Center, Mount Sinai School of Medicine, New 
      York, USA.
FAU - Ballout, Ahmad A
AU  - Ballout AA
AD  - Neurology, Donald and Barbara Zucker School of Medicine at Hofstra/Northwell, 
      Long Island, USA.
FAU - Zayek, Rosana A
AU  - Zayek RA
AD  - Internal Medicine, Torrance Memorial Medical Center, Torrance, USA.
FAU - Ayoub, Noel F
AU  - Ayoub NF
AD  - Otolaryngology-Head and Neck Surgery, Stanford Health Care, Palo Alto, USA.
LA  - eng
PT  - Journal Article
DEP - 20230818
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10505276
OTO - NOTNLM
OT  - artificial intelligence in healthcare
OT  - chatgpt
OT  - clinical decision support system
OT  - generative artificial intelligence
OT  - large language model
OT  - triage
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/09/19 12:42
MHDA- 2023/09/19 12:43
PMCR- 2023/08/18
CRDT- 2023/09/19 03:40
PHST- 2023/07/19 00:00 [accepted]
PHST- 2023/09/19 12:43 [medline]
PHST- 2023/09/19 12:42 [pubmed]
PHST- 2023/09/19 03:40 [entrez]
PHST- 2023/08/18 00:00 [pmc-release]
AID - 10.7759/cureus.43690 [doi]
PST - epublish
SO  - Cureus. 2023 Aug 18;15(8):e43690. doi: 10.7759/cureus.43690. eCollection 2023 
      Aug.

PMID- 37699796
OWN - NLM
STAT- MEDLINE
DCOM- 20240315
LR  - 20240315
IS  - 1758-1001 (Electronic)
IS  - 0004-5632 (Linking)
VI  - 61
IP  - 2
DP  - 2024 Mar
TI  - Can artificial intelligence replace biochemists? A study comparing interpretation 
      of thyroid function test results by ChatGPT and Google Bard to practising 
      biochemists.
PG  - 143-149
LID - 10.1177/00045632231203473 [doi]
AB  - BACKGROUND: Public awareness of artificial intelligence (AI) is increasing and 
      this novel technology is being used for a range of everyday tasks and more 
      specialist clinical applications. On a background of increasing waits for GP 
      appointments alongside patient access to laboratory test results through the NHS 
      app, this study aimed to assess the accuracy and safety of two AI tools, ChatGPT 
      and Google Bard, in providing interpretation of thyroid function test results as 
      if posed by laboratory scientists or patients. METHODS: Fifteen fictional cases 
      were presented to a team of clinicians and clinical scientists to produce a 
      consensus opinion. The cases were then presented to ChatGPT and Google Bard as 
      though from healthcare providers and from patients. The responses were 
      categorized as correct, partially correct or incorrect compared to consensus 
      opinion and the advice assessed for safety to patients. RESULTS: Of the 15 cases 
      presented, ChatGPT and Google Bard correctly interpreted only 33.3% and 20.0% of 
      cases, respectively. When queries were posed as a patient, 66.7% of ChatGPT 
      responses were safe compared to 60.0% of Google Bard responses. Both AI tools 
      were able to identify primary hypothyroidism and hyperthyroidism but failed to 
      identify subclinical presentations, non-thyroidal illness or secondary 
      hypothyroidism. CONCLUSIONS: This study has demonstrated that AI tools do not 
      currently have the capacity to generate consistently correct interpretation and 
      safe advice to patients and should not be used as an alternative to a 
      consultation with a qualified medical professional. Available AI in its current 
      form cannot replace human clinical knowledge in this scenario.
FAU - Stevenson, Emma
AU  - Stevenson E
AUID- ORCID: 0000-0002-9509-8826
AD  - Clinical Biochemistry, Gloucestershire Hospitals NHS Foundation Trust, 
      Cheltenham, UK. RINGGOLD: 2379
FAU - Walsh, Chelsey
AU  - Walsh C
AD  - Clinical Biochemistry, Gloucestershire Hospitals NHS Foundation Trust, 
      Cheltenham, UK. RINGGOLD: 2379
FAU - Hibberd, Luke
AU  - Hibberd L
AUID- ORCID: 0009-0006-5388-4921
AD  - Clinical Biochemistry, Gloucestershire Hospitals NHS Foundation Trust, 
      Cheltenham, UK. RINGGOLD: 2379
LA  - eng
PT  - Journal Article
DEP - 20230920
PL  - England
TA  - Ann Clin Biochem
JT  - Annals of clinical biochemistry
JID - 0324055
SB  - IM
MH  - Humans
MH  - *Thyroid Function Tests
MH  - *Artificial Intelligence
MH  - Search Engine
MH  - Consensus
MH  - Health Personnel
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Google Bard
OT  - chatbot
OT  - result interpretation
OT  - thyroid
COIS- Declaration of conflicting interestsThe author(s) declared no potential conflicts 
      of interest with respect to the research, authorship, and/or publication of this 
      article.
EDAT- 2023/09/13 00:42
MHDA- 2024/03/15 06:44
CRDT- 2023/09/12 22:13
PHST- 2024/03/15 06:44 [medline]
PHST- 2023/09/13 00:42 [pubmed]
PHST- 2023/09/12 22:13 [entrez]
AID - 10.1177/00045632231203473 [doi]
PST - ppublish
SO  - Ann Clin Biochem. 2024 Mar;61(2):143-149. doi: 10.1177/00045632231203473. Epub 
      2023 Sep 20.

PMID- 37001483
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20230612
LR  - 20230612
IS  - 1876-2026 (Electronic)
IS  - 1876-2018 (Linking)
VI  - 84
DP  - 2023 Jun
TI  - ChatGPT: The balance of future, honesty, and integrity.
PG  - 103571
LID - S1876-2018(23)00126-0 [pii]
LID - 10.1016/j.ajp.2023.103571 [doi]
FAU - Nuryana, Zalik
AU  - Nuryana Z
AD  - Department of Islamic Education, Universitas Ahmad Dahlan, Indonesia. Electronic 
      address: zalik.nuryana@pai.uad.ac.id.
FAU - Pranolo, Andri
AU  - Pranolo A
AD  - Department of Informatics, Universitas Ahmad Dahlan, Indonesia. Electronic 
      address: andri.pranolo@tif.uad.ac.id.
LA  - eng
PT  - Letter
DEP - 20230326
PL  - Netherlands
TA  - Asian J Psychiatr
JT  - Asian journal of psychiatry
JID - 101517820
SB  - IM
OTO - NOTNLM
OT  - Artificial Intelligence
OT  - Asian Journal of Psychiatry
OT  - Balance of future
OT  - ChatGPT
OT  - Honesty
OT  - Integrity
COIS- Conflict of Interest The authors declare no conflict of interest.
EDAT- 2023/04/01 06:00
MHDA- 2023/04/01 06:01
CRDT- 2023/03/31 18:12
PHST- 2023/03/18 00:00 [received]
PHST- 2023/03/24 00:00 [revised]
PHST- 2023/03/25 00:00 [accepted]
PHST- 2023/04/01 06:01 [medline]
PHST- 2023/04/01 06:00 [pubmed]
PHST- 2023/03/31 18:12 [entrez]
AID - S1876-2018(23)00126-0 [pii]
AID - 10.1016/j.ajp.2023.103571 [doi]
PST - ppublish
SO  - Asian J Psychiatr. 2023 Jun;84:103571. doi: 10.1016/j.ajp.2023.103571. Epub 2023 
      Mar 26.

PMID- 36971685
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20230329
LR  - 20230329
IS  - 1522-1229 (Electronic)
IS  - 1043-4046 (Linking)
VI  - 47
IP  - 2
DP  - 2023 Jun 1
TI  - Evaluating the performance of ChatGPT in medical physiology university 
      examination of phase I MBBS.
PG  - 270-271
LID - 10.1152/advan.00036.2023 [doi]
FAU - Subramani, Mahila
AU  - Subramani M
AD  - Department of Physiology, Panimalar Medical College Hospital and Research 
      Institute, Varadharajapuram, Chennai, Tamil Nadu, India.
FAU - Jaleel, Ilham
AU  - Jaleel I
AD  - Department of Physiology, Panimalar Medical College Hospital and Research 
      Institute, Varadharajapuram, Chennai, Tamil Nadu, India.
FAU - Krishna Mohan, Surapaneni
AU  - Krishna Mohan S
AD  - Departments of Biochemistry, Medical Education, Molecular Virology, Research, 
      Clinical Skills and Simulation, Panimalar Medical College Hospital and Research 
      Institute, Varadharajapuram, Chennai, Tamil Nadu, India.
LA  - eng
PT  - Letter
PL  - United States
TA  - Adv Physiol Educ
JT  - Advances in physiology education
JID - 100913944
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - chatbot
OT  - medical education
OT  - medical physiology
EDAT- 2023/03/28 06:00
MHDA- 2023/03/29 06:04
CRDT- 2023/03/27 10:33
PHST- 2023/03/29 06:04 [medline]
PHST- 2023/03/27 10:33 [entrez]
PHST- 2023/03/28 06:00 [pubmed]
AID - 10.1152/advan.00036.2023 [doi]
PST - ppublish
SO  - Adv Physiol Educ. 2023 Jun 1;47(2):270-271. doi: 10.1152/advan.00036.2023.

PMID- 37988948
OWN - NLM
STAT- MEDLINE
DCOM- 20231218
LR  - 20231218
IS  - 1095-6859 (Electronic)
IS  - 0090-8258 (Linking)
VI  - 179
DP  - 2023 Dec
TI  - Let's chat about cervical cancer: Assessing the accuracy of ChatGPT responses to 
      cervical cancer questions.
PG  - 164-168
LID - S0090-8258(23)01535-4 [pii]
LID - 10.1016/j.ygyno.2023.11.008 [doi]
AB  - OBJECTIVE: To quantify the accuracy of ChatGPT in answering commonly asked 
      questions pertaining to cervical cancer prevention, diagnosis, treatment, and 
      survivorship/quality-of-life (QOL). METHODS: ChatGPT was queried with 64 
      questions adapted from professional society websites and the authors' clinical 
      experiences. The answers were scored by two attending Gynecologic Oncologists 
      according to the following scale: 1) correct and comprehensive, 2) correct but 
      not comprehensive, 3) some correct, some incorrect, and 4) completely incorrect. 
      Scoring discrepancies were resolved by additional reviewers as needed. The 
      proportion of responses earning each score were calculated overall and within 
      each question category. RESULTS: ChatGPT provided correct and comprehensive 
      answers to 34 (53.1%) questions, correct but not comprehensive answers to 19 
      (29.7%) questions, partially incorrect answers to 10 (15.6%) questions, and 
      completely incorrect answers to 1 (1.6%) question. Prevention and 
      survivorship/QOL had the highest proportion of "correct" scores (scores of 1 or 
      2) at 22/24 (91.7%) and 15/16 (93.8%), respectively. ChatGPT performed less well 
      in the treatment category, with 15/21 (71.4%) correct scores. It performed the 
      worst in the diagnosis category with only 1/3 (33.3%) correct scores. CONCLUSION: 
      ChatGPT accurately answers questions about cervical cancer prevention, 
      survivorship, and QOL. It performs less accurately for cervical cancer diagnosis 
      and treatment. Further development of this immensely popular large language model 
      should include physician input before it can be utilized as a tool for 
      Gynecologists or recommended as a patient resource for information on cervical 
      cancer diagnosis and treatment.
CI  - Copyright © 2023 Elsevier Inc. All rights reserved.
FAU - Hermann, Catherine E
AU  - Hermann CE
AD  - New York University Langone Health, Department of Obstetrics and Gynecology, 
      Division of Gynecologic Oncology, New York, NY, United States of America. 
      Electronic address: catherine.e.hermann@gmail.com.
FAU - Patel, Jharna M
AU  - Patel JM
AD  - New York University Langone Health, Department of Obstetrics and Gynecology, 
      Division of Gynecologic Oncology, New York, NY, United States of America.
FAU - Boyd, Leslie
AU  - Boyd L
AD  - New York University Langone Health, Department of Obstetrics and Gynecology, 
      Division of Gynecologic Oncology, New York, NY, United States of America.
FAU - Growdon, Whitfield B
AU  - Growdon WB
AD  - New York University Langone Health, Department of Obstetrics and Gynecology, 
      Division of Gynecologic Oncology, New York, NY, United States of America.
FAU - Aviki, Emeline
AU  - Aviki E
AD  - New York University Langone Health Long Island, Department of Obstetrics and 
      Gynecology, Division of Gynecologic Oncology, Mineola, NY, United States of 
      America.
FAU - Stasenko, Marina
AU  - Stasenko M
AD  - New York University Langone Health, Department of Obstetrics and Gynecology, 
      Division of Gynecologic Oncology, New York, NY, United States of America.
LA  - eng
PT  - Journal Article
DEP - 20231121
PL  - United States
TA  - Gynecol Oncol
JT  - Gynecologic oncology
JID - 0365304
SB  - IM
MH  - Female
MH  - Humans
MH  - *Uterine Cervical Neoplasms/diagnosis/therapy
MH  - Quality of Life
MH  - Income
MH  - *Oncologists
MH  - *Physicians
OTO - NOTNLM
OT  - Artificial Intelligence
OT  - Cervical cancer
OT  - Cervical dysplasia
OT  - ChatGPT
OT  - HPV vaccination
COIS- Declaration of Competing Interest None of the authors have conflicts to report.
EDAT- 2023/11/22 00:42
MHDA- 2023/12/18 06:42
CRDT- 2023/11/21 18:24
PHST- 2023/08/12 00:00 [received]
PHST- 2023/10/31 00:00 [revised]
PHST- 2023/11/08 00:00 [accepted]
PHST- 2023/12/18 06:42 [medline]
PHST- 2023/11/22 00:42 [pubmed]
PHST- 2023/11/21 18:24 [entrez]
AID - S0090-8258(23)01535-4 [pii]
AID - 10.1016/j.ygyno.2023.11.008 [doi]
PST - ppublish
SO  - Gynecol Oncol. 2023 Dec;179:164-168. doi: 10.1016/j.ygyno.2023.11.008. Epub 2023 
      Nov 21.

PMID- 37651381
OWN - NLM
STAT- MEDLINE
DCOM- 20230904
LR  - 20230905
IS  - 1932-6203 (Electronic)
IS  - 1932-6203 (Linking)
VI  - 18
IP  - 8
DP  - 2023
TI  - ChatGPT- versus human-generated answers to frequently asked questions about 
      diabetes: A Turing test-inspired survey among employees of a Danish diabetes 
      center.
PG  - e0290773
LID - 10.1371/journal.pone.0290773 [doi]
LID - e0290773
AB  - Large language models have received enormous attention recently with some studies 
      demonstrating their potential clinical value, despite not being trained 
      specifically for this domain. We aimed to investigate whether ChatGPT, a language 
      model optimized for dialogue, can answer frequently asked questions about 
      diabetes. We conducted a closed e-survey among employees of a large Danish 
      diabetes center. The study design was inspired by the Turing test and 
      non-inferiority trials. Our survey included ten questions with two answers each. 
      One of these was written by a human expert, while the other was generated by 
      ChatGPT. Participants had the task to identify the ChatGPT-generated answer. Data 
      was analyzed at the question-level using logistic regression with robust variance 
      estimation with clustering at participant level. In secondary analyses, we 
      investigated the effect of participant characteristics on the outcome. A 55% 
      non-inferiority margin was pre-defined based on precision simulations and had 
      been published as part of the study protocol before data collection began. Among 
      311 invited individuals, 183 participated in the survey (59% response rate). 64% 
      had heard of ChatGPT before, and 19% had tried it. Overall, participants could 
      identify ChatGPT-generated answers 59.5% (95% CI: 57.0, 62.0) of the time, which 
      was outside of the non-inferiority zone. Among participant characteristics, 
      previous ChatGPT use had the strongest association with the outcome (odds ratio: 
      1.52 (1.16, 2.00), p = 0.003). Previous users answered 67.4% (61.7, 72.7) of the 
      questions correctly, versus non-users' 57.6% (54.9, 60.3). Participants could 
      distinguish between ChatGPT-generated and human-written answers somewhat better 
      than flipping a fair coin, which was against our initial hypothesis. Rigorously 
      planned studies are needed to elucidate the risks and benefits of integrating 
      such technologies in routine clinical practice.
CI  - Copyright: © 2023 Hulman et al. This is an open access article distributed under 
      the terms of the Creative Commons Attribution License, which permits unrestricted 
      use, distribution, and reproduction in any medium, provided the original author 
      and source are credited.
FAU - Hulman, Adam
AU  - Hulman A
AUID- ORCID: 0000-0002-3969-1000
AD  - Steno Diabetes Center Aarhus, Aarhus University Hospital, Aarhus, Denmark.
AD  - Department of Public Health, Aarhus University, Aarhus, Denmark.
FAU - Dollerup, Ole Lindgård
AU  - Dollerup OL
AUID- ORCID: 0000-0001-6924-7114
AD  - Steno Diabetes Center Aarhus, Aarhus University Hospital, Aarhus, Denmark.
FAU - Mortensen, Jesper Friis
AU  - Mortensen JF
AUID- ORCID: 0000-0001-7683-0906
AD  - Steno Diabetes Center Aarhus, Aarhus University Hospital, Aarhus, Denmark.
AD  - Department of Public Health, Aarhus University, Aarhus, Denmark.
FAU - Fenech, Matthew E
AU  - Fenech ME
AUID- ORCID: 0000-0001-9970-0215
AD  - Una Health GmbH, Hamburg, Germany.
FAU - Norman, Kasper
AU  - Norman K
AD  - Steno Diabetes Center Aarhus, Aarhus University Hospital, Aarhus, Denmark.
FAU - Støvring, Henrik
AU  - Støvring H
AUID- ORCID: 0000-0002-5821-2351
AD  - Steno Diabetes Center Aarhus, Aarhus University Hospital, Aarhus, Denmark.
AD  - Department of Public Health, University of Southern Denmark, Odense, Denmark.
FAU - Hansen, Troels Krarup
AU  - Hansen TK
AUID- ORCID: 0000-0002-0708-2868
AD  - Steno Diabetes Center Aarhus, Aarhus University Hospital, Aarhus, Denmark.
AD  - Department of Clinical Medicine, Aarhus University, Aarhus, Denmark.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20230831
PL  - United States
TA  - PLoS One
JT  - PloS one
JID - 101285081
SB  - IM
MH  - Humans
MH  - Data Collection
MH  - *Diabetes Mellitus/diagnosis/epidemiology
MH  - Cluster Analysis
MH  - Language
MH  - Denmark/epidemiology
PMC - PMC10470899
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/08/31 18:42
MHDA- 2023/09/04 06:42
PMCR- 2023/08/31
CRDT- 2023/08/31 13:35
PHST- 2023/05/02 00:00 [received]
PHST- 2023/08/16 00:00 [accepted]
PHST- 2023/09/04 06:42 [medline]
PHST- 2023/08/31 18:42 [pubmed]
PHST- 2023/08/31 13:35 [entrez]
PHST- 2023/08/31 00:00 [pmc-release]
AID - PONE-D-23-12539 [pii]
AID - 10.1371/journal.pone.0290773 [doi]
PST - epublish
SO  - PLoS One. 2023 Aug 31;18(8):e0290773. doi: 10.1371/journal.pone.0290773. 
      eCollection 2023.

PMID- 38547497
OWN - NLM
STAT- MEDLINE
DCOM- 20240401
LR  - 20240401
IS  - 2047-2986 (Electronic)
IS  - 2047-2978 (Print)
IS  - 2047-2978 (Linking)
VI  - 14
DP  - 2024 Mar 29
TI  - Evaluating ChatGPT-4.0's data analytic proficiency in epidemiological studies: A 
      comparative analysis with SAS, SPSS, and R.
PG  - 04070
LID - 10.7189/jogh.14.04070 [doi]
LID - 04070
AB  - BACKGROUND: OpenAI's Chat Generative Pre-trained Transformer 4.0 (ChatGPT-4), an 
      emerging artificial intelligence (AI)-based large language model (LLM), has been 
      receiving increasing attention from the medical research community for its 
      innovative 'Data Analyst' feature. We aimed to compare the capabilities of 
      ChatGPT-4 against traditional biostatistical software (i.e. SAS, SPSS, R) in 
      statistically analysing epidemiological research data. METHODS: We used a data 
      set from the China Health and Nutrition Survey, comprising 9317 participants and 
      29 variables (e.g. gender, age, educational level, marital status, income, 
      occupation, weekly working hours, survival status). Two researchers independently 
      evaluated the data analysis capabilities of GPT-4's 'Data Analyst' feature 
      against SAS, SPSS, and R across three commonly used epidemiological analysis 
      methods: Descriptive statistics, intergroup analysis, and correlation analysis. 
      We used an internally developed evaluation scale to assess and compare the 
      consistency of results, analytical efficiency of coding or operations, 
      user-friendliness, and overall performance between ChatGPT-4, SAS, SPSS, and R. 
      RESULTS: In descriptive statistics, ChatGPT-4 showed high consistency of results, 
      greater analytical efficiency of code or operations, and more intuitive 
      user-friendliness compared to SAS, SPSS, and R. In intergroup comparisons and 
      correlational analyses, despite minor discrepancies in statistical outcomes for 
      certain analysis tasks with SAS, SPSS, and R, ChatGPT-4 maintained high 
      analytical efficiency and exceptional user-friendliness. Thus, employing 
      ChatGPT-4 can significantly lower the operational threshold for conducting 
      epidemiological data analysis while maintaining consistency with traditional 
      biostatistical software's outcome, requiring only specific, clear analysis 
      instructions without any additional operations or code writing. CONCLUSIONS: We 
      found ChatGPT-4 to be a powerful auxiliary tool for statistical analysis in 
      epidemiological research. However, it showed limitations in result consistency 
      and in applying more advanced statistical methods. Therefore, we advocate for the 
      use of ChatGPT-4 in supporting researchers with intermediate experience in data 
      analysis. With AI technologies like LLMs advancing rapidly, their integration 
      with data analysis platforms promises to lower operational barriers, thereby 
      enabling researchers to dedicate greater focus to the nuanced interpretation of 
      analysis results. This development is likely to significantly advance 
      epidemiological and medical research.
CI  - Copyright © 2024 by the Journal of Global Health. All rights reserved.
FAU - Huang, Yeen
AU  - Huang Y
AD  - School of Public Health and Emergency Management, Southern University of Science 
      and Technology, Shenzhen, Guangdong, China.
FAU - Wu, Ruipeng
AU  - Wu R
AD  - Key Laboratory for Molecular Genetic Mechanisms and Intervention Research, On 
      High Altitude Disease of Tibet Autonomous Region, School of Medicine, Xizang 
      Minzu University, Xianyang, Xizang, China.
AD  - Key Laboratory of High Altitude Hypoxia Environment and Life Health, School of 
      Medicine, Xizang Minzu University, Xianyang, Xizang, China.
AD  - Key Laboratory of Environmental Medicine and Engineering of Ministry of 
      Education, Department of Nutrition and Food Hygiene, School of Public Health, 
      Southeast University, Nanjing, Jiangsu, China.
FAU - He, Juntao
AU  - He J
AD  - Physical and Chemical Testing Institute, Shenzhen Prevention and Treatment Center 
      for Occupational Diseases, Shenzhen, Guangdong, China.
FAU - Xiang, Yingping
AU  - Xiang Y
AD  - Occupational Hazard Assessment Institute, Shenzhen Prevention and Treatment 
      Center for Occupational Diseases, Shenzhen, Guangdong, China.
LA  - eng
PT  - Journal Article
DEP - 20240329
PL  - Scotland
TA  - J Glob Health
JT  - Journal of global health
JID - 101578780
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Data Science
MH  - Epidemiologic Studies
MH  - Research Design
MH  - *Biomedical Research
PMC - PMC10978058
COIS- Disclosure of interest: The authors completed the ICMJE Disclosure of Interest 
      Form (available upon request from the corresponding author) and disclose no 
      relevant interests.
EDAT- 2024/03/28 18:44
MHDA- 2024/04/01 06:42
PMCR- 2024/03/29
CRDT- 2024/03/28 17:13
PHST- 2024/04/01 06:42 [medline]
PHST- 2024/03/28 18:44 [pubmed]
PHST- 2024/03/28 17:13 [entrez]
PHST- 2024/03/29 00:00 [pmc-release]
AID - jogh-14-04070 [pii]
AID - 10.7189/jogh.14.04070 [doi]
PST - epublish
SO  - J Glob Health. 2024 Mar 29;14:04070. doi: 10.7189/jogh.14.04070.

PMID- 37898100
OWN - NLM
STAT- MEDLINE
DCOM- 20231127
LR  - 20231127
IS  - 1876-2026 (Electronic)
IS  - 1876-2018 (Linking)
VI  - 90
DP  - 2023 Dec
TI  - ChatGPT: Opportunities, risks and priorities for psychiatry.
PG  - 103808
LID - S1876-2018(23)00364-7 [pii]
LID - 10.1016/j.ajp.2023.103808 [doi]
AB  - The advancement of large language models such as ChatGPT, opens new possibilities 
      in psychiatry but also invites scrutiny. This paper examines the potential 
      opportunities, risks, and crucial areas of focus within this area. The active 
      engagement of the mental health community is seen as critical to ensure ethical 
      practice, equal access, and a patient-centric approach.
CI  - Copyright © 2023 Elsevier B.V. All rights reserved.
FAU - Wei, Yaohui
AU  - Wei Y
AD  - Shanghai Mental Health Center, Shanghai Jiao Tong University School of Medicine, 
      Shanghai, China; Department of Psychiatry and Psychotherapy, University Hospital 
      Rechts der Isar, Technical University of Munich, Munich, Germany.
FAU - Guo, Lei
AU  - Guo L
AD  - Shanghai Mental Health Center, Shanghai Jiao Tong University School of Medicine, 
      Shanghai, China.
FAU - Lian, Cheng
AU  - Lian C
AD  - Shanghai Mental Health Center, Shanghai Jiao Tong University School of Medicine, 
      Shanghai, China.
FAU - Chen, Jue
AU  - Chen J
AD  - Shanghai Mental Health Center, Shanghai Jiao Tong University School of Medicine, 
      Shanghai, China. Electronic address: chenjue2088@163.com.
LA  - eng
PT  - Journal Article
DEP - 20231024
PL  - Netherlands
TA  - Asian J Psychiatr
JT  - Asian journal of psychiatry
JID - 101517820
SB  - IM
MH  - Humans
MH  - *Psychiatry
MH  - Language
MH  - Mental Health
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Large language model
OT  - Psychiatry
COIS- Declaration of Competing Interest The authors declare no conflicts of interest 
      relevant to the contents of the manuscript.
EDAT- 2023/10/29 06:46
MHDA- 2023/11/27 12:42
CRDT- 2023/10/28 18:10
PHST- 2023/08/17 00:00 [received]
PHST- 2023/10/18 00:00 [revised]
PHST- 2023/10/22 00:00 [accepted]
PHST- 2023/11/27 12:42 [medline]
PHST- 2023/10/29 06:46 [pubmed]
PHST- 2023/10/28 18:10 [entrez]
AID - S1876-2018(23)00364-7 [pii]
AID - 10.1016/j.ajp.2023.103808 [doi]
PST - ppublish
SO  - Asian J Psychiatr. 2023 Dec;90:103808. doi: 10.1016/j.ajp.2023.103808. Epub 2023 
      Oct 24.

PMID- 37541814
OWN - NLM
STAT- MEDLINE
DCOM- 20230918
LR  - 20231003
IS  - 1878-4372 (Electronic)
IS  - 1360-1385 (Linking)
VI  - 28
IP  - 10
DP  - 2023 Oct
TI  - Plant blindness and diversity in AI language models.
PG  - 1095-1097
LID - S1360-1385(23)00207-8 [pii]
LID - 10.1016/j.tplants.2023.06.016 [doi]
AB  - Large language models (LLMs) will benefit science by accelerating task 
      performance. We explored whether answers generated by ChatGPT (generative 
      pretrained transformer) to questions of biology are sufficiently diverse. 'Plant 
      awareness' in ChatGPT answers was found to be highly variable, illustrating the 
      importance of scientists being involved in validating the data and methods used 
      to train artificial intelligence (AI) models.
CI  - Copyright © 2023 Elsevier Ltd. All rights reserved.
FAU - Geitmann, Anja
AU  - Geitmann A
AD  - Faculty of Agricultural and Environmental Sciences, McGill University, Montreal, 
      QC, Canada. Electronic address: geitmann.aes@mcgill.ca.
FAU - Bidhendi, Amir J
AU  - Bidhendi AJ
AD  - Faculty of Agricultural and Environmental Sciences, McGill University, Montreal, 
      QC, Canada.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20230802
PL  - England
TA  - Trends Plant Sci
JT  - Trends in plant science
JID - 9890299
SB  - IM
MH  - *Artificial Intelligence
MH  - *Language
MH  - Blindness
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence models
OT  - diversity
OT  - large language models
OT  - plant blindness
COIS- Declaration of interests The authors declare no conflicts of interest.
EDAT- 2023/08/05 05:42
MHDA- 2023/09/18 12:44
CRDT- 2023/08/04 21:53
PHST- 2023/05/23 00:00 [received]
PHST- 2023/06/13 00:00 [revised]
PHST- 2023/06/20 00:00 [accepted]
PHST- 2023/09/18 12:44 [medline]
PHST- 2023/08/05 05:42 [pubmed]
PHST- 2023/08/04 21:53 [entrez]
AID - S1360-1385(23)00207-8 [pii]
AID - 10.1016/j.tplants.2023.06.016 [doi]
PST - ppublish
SO  - Trends Plant Sci. 2023 Oct;28(10):1095-1097. doi: 10.1016/j.tplants.2023.06.016. 
      Epub 2023 Aug 2.

PMID- 37090396
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230425
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 3
DP  - 2023 Mar
TI  - Currarino Syndrome Presenting in Adulthood: A Rare Case.
PG  - e36497
LID - 10.7759/cureus.36497 [doi]
LID - e36497
AB  - Currarino syndrome or Currarino triad is a complex condition consisting of 
      congenital anomalies. The triad consists of anterior sacral mass (meningocele, 
      teratoma or dermoid/epidermoid cyst), sacral bone defect (hypoplasia, agenesis ), 
      anorectal malformation/congenital anorectal stenosis.&nbsp;This condition is named 
      after Dr Guido Currarino, an Italian-American paediatric radiologist, who first 
      described it in 1975. This needs a multidisciplinary treatment approach. We 
      describe a case of successfully managed young adult with Currarino syndrome. The 
      latest artificial intelligence tool, Chat Generative Pre-Trained Transformer 
      (ChatGPT), helped to write this case report.
CI  - Copyright © 2023, Verma et al.
FAU - Verma, Abhijit
AU  - Verma A
AD  - Department of Neurosurgery, NIMS University, Jaipur, IND.
FAU - Attry, Sanjeev
AU  - Attry S
AD  - Department of Neurosurgery, NIMS University, Jaipur, IND.
FAU - Haldenia, Kulbhushan
AU  - Haldenia K
AD  - Surgical Gastroenterology, NIMS University, Jaipur, IND.
FAU - Gupta, Vijay K
AU  - Gupta VK
AD  - Department of Neurosurgery, NIMS University, Jaipur, IND.
FAU - Bansal, Puneet
AU  - Bansal P
AD  - Department of Neurosurgery, NIMS University, Jaipur, IND.
LA  - eng
PT  - Case Reports
DEP - 20230321
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10119035
OTO - NOTNLM
OT  - anorectal anomaly
OT  - anterior sacral meningocoele
OT  - chatgpt
OT  - currarino syndrome
OT  - currarino triad
OT  - sacrococcygeal agenesis
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/04/24 06:41
MHDA- 2023/04/24 06:42
PMCR- 2023/03/21
CRDT- 2023/04/24 03:40
PHST- 2023/03/21 00:00 [accepted]
PHST- 2023/04/24 06:42 [medline]
PHST- 2023/04/24 06:41 [pubmed]
PHST- 2023/04/24 03:40 [entrez]
PHST- 2023/03/21 00:00 [pmc-release]
AID - 10.7759/cureus.36497 [doi]
PST - epublish
SO  - Cureus. 2023 Mar 21;15(3):e36497. doi: 10.7759/cureus.36497. eCollection 2023 
      Mar.

PMID- 37920024
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231103
IS  - 1551-0018 (Electronic)
IS  - 1547-1063 (Linking)
VI  - 20
IP  - 9
DP  - 2023 Aug 17
TI  - Investigating difficulties and enhancing understanding in linear algebra: 
      Leveraging SageMath and ChatGPT for (orthogonal) diagonalization and singular 
      value decomposition.
PG  - 16551-16595
LID - 10.3934/mbe.2023738 [doi]
AB  - We explored some common challenges faced by undergraduate students when studying 
      linear algebra, particularly when dealing with algorithmic thinking skills 
      required for topics such as matrix factorization, focusing on (orthogonal) 
      diagonalization and singular value decomposition (SVD). To address these 
      challenges, we introduced SageMath, a Python-based open-source computer algebra 
      system, as a supportive tool for students performing computational tasks despite 
      its static output nature. We further examined the potential of dynamic ChatGPT, 
      an AI-based chatbot, by requesting examples or problem-solving assistance related 
      to (orthogonal) diagonalization or the SVD of a specific matrix. By reinforcing 
      essential concepts in linear algebra and enhancing computational skills through 
      effective practice, mastering these topics can become more accessible while 
      minimizing mistakes. Although static in nature, SageMath proved valuable for 
      confirming calculations and handling tedious computations because of its 
      easy-to-understand syntax and accurate solutions. However, although dynamic 
      ChatGPT may not be fully reliable for solving linear algebra problems, the errors 
      it produces can serve as a valuable resource for improving critical thinking 
      skills.
FAU - Karjanto, Natanael
AU  - Karjanto N
AD  - Department of Mathematics, University College, Natural Science Campus, 
      Sungkyunkwan University, Suwon 16419, Republic of Korea.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Math Biosci Eng
JT  - Mathematical biosciences and engineering : MBE
JID - 101197794
SB  - IM
OTO - NOTNLM
OT  - (orthogonal) diagonalization
OT  - AI-based chatbot
OT  - ChatGPT
OT  - SageMath
OT  - algorithmic thinking skills
OT  - computer algebra system
OT  - linear algebra
OT  - singular value decomposition
EDAT- 2023/11/03 06:44
MHDA- 2023/11/03 06:45
CRDT- 2023/11/03 03:43
PHST- 2023/11/03 06:45 [medline]
PHST- 2023/11/03 06:44 [pubmed]
PHST- 2023/11/03 03:43 [entrez]
AID - 10.3934/mbe.2023738 [doi]
PST - ppublish
SO  - Math Biosci Eng. 2023 Aug 17;20(9):16551-16595. doi: 10.3934/mbe.2023738.

PMID- 37674966
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230908
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 8
DP  - 2023 Aug
TI  - Integrating ChatGPT in Medical Education: Adapting Curricula to Cultivate 
      Competent Physicians for the AI Era.
PG  - e43036
LID - 10.7759/cureus.43036 [doi]
LID - e43036
AB  - The rapid advancements in artificial intelligence (AI) language models, 
      particularly ChatGPT (OpenAI, San Francisco, California, United States), 
      necessitate the adaptation of medical education curricula to cultivate competent 
      physicians in the AI era. In this editorial, we discuss short-term solutions and 
      long-term adaptations for integrating ChatGPT into medical education. We 
      recommend promoting digital literacy, developing critical thinking skills, and 
      emphasizing evidence-based relevance as quick fixes. Long-term adaptations 
      include focusing on the human factor, interprofessional collaboration, continuous 
      professional development, and research and evaluation. By implementing these 
      changes, medical educators can optimize medical education for the AI era, 
      ensuring students are well prepared for a technologically advanced future in 
      healthcare.
CI  - Copyright © 2023, Jamal et al.
FAU - Jamal, Amr
AU  - Jamal A
AD  - Family and Community Medicine, King Saud University, Riyadh, SAU.
FAU - Solaiman, Mona
AU  - Solaiman M
AD  - Medical Education, King Saud University, Riyadh, SAU.
FAU - Alhasan, Khalid
AU  - Alhasan K
AD  - Pediatric Nephrology, King Saud University, Riyadh, SAU.
FAU - Temsah, Mohamad-Hani
AU  - Temsah MH
AD  - Pediatric Intensive Care Unit, King Saud University, Riyadh, SAU.
FAU - Sayed, Gary
AU  - Sayed G
AD  - Medical Education, California State University, Carson, USA.
LA  - eng
PT  - Editorial
DEP - 20230806
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10479954
OTO - NOTNLM
OT  - ai &amp; robotics in healthcare
OT  - ai in medical education
OT  - artificial intelligence
OT  - chatgpt
OT  - critical thinking
OT  - curriculum adaptation
OT  - digital literacy
OT  - interprofessional collaboration
OT  - long-term solutions
OT  - rapid solutions
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/09/07 06:43
MHDA- 2023/09/07 06:44
PMCR- 2023/08/06
CRDT- 2023/09/07 04:12
PHST- 2023/08/06 00:00 [accepted]
PHST- 2023/09/07 06:44 [medline]
PHST- 2023/09/07 06:43 [pubmed]
PHST- 2023/09/07 04:12 [entrez]
PHST- 2023/08/06 00:00 [pmc-release]
AID - 10.7759/cureus.43036 [doi]
PST - epublish
SO  - Cureus. 2023 Aug 6;15(8):e43036. doi: 10.7759/cureus.43036. eCollection 2023 Aug.

PMID- 37253791
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230602
IS  - 2374-4677 (Print)
IS  - 2374-4677 (Electronic)
IS  - 2374-4677 (Linking)
VI  - 9
IP  - 1
DP  - 2023 May 30
TI  - Large language model (ChatGPT) as a support tool for breast tumor board.
PG  - 44
LID - 10.1038/s41523-023-00557-8 [doi]
LID - 44
AB  - Large language models (LLM) such as ChatGPT have gained public and scientific 
      attention. The aim of this study is to evaluate ChatGPT as a support tool for 
      breast tumor board decisions making. We inserted into ChatGPT-3.5 clinical 
      information of ten consecutive patients presented in a breast tumor board in our 
      institution. We asked the chatbot to recommend management. The results generated 
      by ChatGPT were compared to the final recommendations of the tumor board. They 
      were also graded independently by two senior radiologists. Grading scores were 
      between 1-5 (1 = completely disagree, 5 = completely agree), and in three 
      different categories: summarization, recommendation, and explanation. The mean 
      age was 49.4, 8/10 (80%) of patients had invasive ductal carcinoma, one patient 
      (1/10, 10%) had a ductal carcinoma in-situ and one patient (1/10, 10%) had a 
      phyllodes tumor with atypia. In seven out of ten cases (70%), ChatGPT's 
      recommendations were similar to the tumor board's decisions. Mean scores while 
      grading the chatbot's summarization, recommendation and explanation by the first 
      reviewer were 3.7, 4.3, and 4.6 respectively. Mean values for the second reviewer 
      were 4.3, 4.0, and 4.3, respectively. In this proof-of-concept study, we present 
      initial results on the use of an LLM as a decision support tool in a breast tumor 
      board. Given the significant advancements, it is warranted for clinicians to be 
      familiar with the potential benefits and harms of the technology.
CI  - © 2023. The Author(s).
FAU - Sorin, Vera
AU  - Sorin V
AUID- ORCID: 0000-0003-0509-4686
AD  - Department of Diagnostic Imaging, Chaim Sheba Medical Center, Tel Hashomer, 
      Israel. verasrn@gmail.com.
AD  - Sackler School of Medicine, Tel-Aviv University, Tel-Aviv, Israel. 
      verasrn@gmail.com.
AD  - DeepVision Lab, Chaim Sheba Medical Center, Tel Hashomer, Israel. 
      verasrn@gmail.com.
FAU - Klang, Eyal
AU  - Klang E
AD  - Department of Diagnostic Imaging, Chaim Sheba Medical Center, Tel Hashomer, 
      Israel.
AD  - Sackler School of Medicine, Tel-Aviv University, Tel-Aviv, Israel.
AD  - DeepVision Lab, Chaim Sheba Medical Center, Tel Hashomer, Israel.
AD  - Sami Sagol AI Hub, ARC, Chaim Sheba Medical Center, Tel Hashomer, Israel.
FAU - Sklair-Levy, Miri
AU  - Sklair-Levy M
AD  - Department of Diagnostic Imaging, Chaim Sheba Medical Center, Tel Hashomer, 
      Israel.
AD  - Sackler School of Medicine, Tel-Aviv University, Tel-Aviv, Israel.
FAU - Cohen, Israel
AU  - Cohen I
AD  - Department of Diagnostic Imaging, Chaim Sheba Medical Center, Tel Hashomer, 
      Israel.
AD  - Sackler School of Medicine, Tel-Aviv University, Tel-Aviv, Israel.
FAU - Zippel, Douglas B
AU  - Zippel DB
AD  - Sackler School of Medicine, Tel-Aviv University, Tel-Aviv, Israel.
AD  - Department of General and Oncological Surgery- Surgery C, Chaim Sheba Medical 
      Center, Tel Hashomer, Israel.
FAU - Balint Lahat, Nora
AU  - Balint Lahat N
AD  - Sackler School of Medicine, Tel-Aviv University, Tel-Aviv, Israel.
AD  - Department of Pathology, Chaim Sheba Medical Center, Tel Hashomer, Israel.
FAU - Konen, Eli
AU  - Konen E
AD  - Department of Diagnostic Imaging, Chaim Sheba Medical Center, Tel Hashomer, 
      Israel.
AD  - Sackler School of Medicine, Tel-Aviv University, Tel-Aviv, Israel.
FAU - Barash, Yiftach
AU  - Barash Y
AUID- ORCID: 0000-0002-7242-1328
AD  - Department of Diagnostic Imaging, Chaim Sheba Medical Center, Tel Hashomer, 
      Israel.
AD  - Sackler School of Medicine, Tel-Aviv University, Tel-Aviv, Israel.
AD  - DeepVision Lab, Chaim Sheba Medical Center, Tel Hashomer, Israel.
LA  - eng
PT  - Journal Article
DEP - 20230530
PL  - United States
TA  - NPJ Breast Cancer
JT  - NPJ breast cancer
JID - 101674891
PMC - PMC10229606
COIS- The authors declare no competing interests.
EDAT- 2023/05/31 01:09
MHDA- 2023/05/31 01:10
PMCR- 2023/05/30
CRDT- 2023/05/30 23:20
PHST- 2023/03/16 00:00 [received]
PHST- 2023/05/23 00:00 [accepted]
PHST- 2023/05/31 01:10 [medline]
PHST- 2023/05/31 01:09 [pubmed]
PHST- 2023/05/30 23:20 [entrez]
PHST- 2023/05/30 00:00 [pmc-release]
AID - 10.1038/s41523-023-00557-8 [pii]
AID - 557 [pii]
AID - 10.1038/s41523-023-00557-8 [doi]
PST - epublish
SO  - NPJ Breast Cancer. 2023 May 30;9(1):44. doi: 10.1038/s41523-023-00557-8.

PMID- 38446539
OWN - NLM
STAT- MEDLINE
DCOM- 20240307
LR  - 20240323
IS  - 2292-9495 (Electronic)
IS  - 2292-9495 (Linking)
VI  - 11
DP  - 2024 Mar 6
TI  - Leveraging Generative AI Tools to Support the Development of Digital Solutions in 
      Health Care Research: Case Study.
PG  - e52885
LID - 10.2196/52885 [doi]
LID - e52885
AB  - BACKGROUND: Generative artificial intelligence has the potential to revolutionize 
      health technology product development by improving coding quality, efficiency, 
      documentation, quality assessment and review, and troubleshooting. OBJECTIVE: 
      This paper explores the application of a commercially available generative 
      artificial intelligence tool (ChatGPT) to the development of a digital health 
      behavior change intervention designed to support patient engagement in a 
      commercial digital diabetes prevention program. METHODS: We examined the 
      capacity, advantages, and limitations of ChatGPT to support digital product idea 
      conceptualization, intervention content development, and the software engineering 
      process, including software requirement generation, software design, and code 
      production. In total, 11 evaluators, each with at least 10 years of experience in 
      fields of study ranging from medicine and implementation science to computer 
      science, participated in the output review process (ChatGPT vs human-generated 
      output). All had familiarity or prior exposure to the original personalized 
      automatic messaging system intervention. The evaluators rated the 
      ChatGPT-produced outputs in terms of understandability, usability, novelty, 
      relevance, completeness, and efficiency. RESULTS: Most metrics received positive 
      scores. We identified that ChatGPT can (1) support developers to achieve 
      high-quality products faster and (2) facilitate nontechnical communication and 
      system understanding between technical and nontechnical team members around the 
      development goal of rapid and easy-to-build computational solutions for medical 
      technologies. CONCLUSIONS: ChatGPT can serve as a usable facilitator for 
      researchers engaging in the software development life cycle, from product 
      conceptualization to feature identification and user story development to code 
      generation. TRIAL REGISTRATION: ClinicalTrials.gov NCT04049500; 
      https://clinicaltrials.gov/ct2/show/NCT04049500.
CI  - ©Danissa V Rodriguez, Katharine Lawrence, Javier Gonzalez, Beatrix 
      Brandfield-Harvey, Lynn Xu, Sumaiya Tasneem, Defne L Levine, Devin Mann. 
      Originally published in JMIR Human Factors (https://humanfactors.jmir.org), 
      06.03.2024.
FAU - Rodriguez, Danissa V
AU  - Rodriguez DV
AUID- ORCID: 0000-0003-4642-6798
AD  - Department of Population Health, New York University Grossman School of Medicine, 
      New York, NY, United States.
FAU - Lawrence, Katharine
AU  - Lawrence K
AUID- ORCID: 0000-0001-5640-2138
AD  - Department of Population Health, New York University Grossman School of Medicine, 
      New York, NY, United States.
AD  - Medical Center Information Technology, Department of Health Informatics, New York 
      University Langone Health, New York, NY, United States.
FAU - Gonzalez, Javier
AU  - Gonzalez J
AUID- ORCID: 0000-0002-7562-6070
AD  - Medical Center Information Technology, Department of Health Informatics, New York 
      University Langone Health, New York, NY, United States.
FAU - Brandfield-Harvey, Beatrix
AU  - Brandfield-Harvey B
AUID- ORCID: 0009-0002-0120-6353
AD  - Department of Population Health, New York University Grossman School of Medicine, 
      New York, NY, United States.
FAU - Xu, Lynn
AU  - Xu L
AUID- ORCID: 0009-0009-8586-9955
AD  - Department of Population Health, New York University Grossman School of Medicine, 
      New York, NY, United States.
FAU - Tasneem, Sumaiya
AU  - Tasneem S
AUID- ORCID: 0000-0001-5721-1819
AD  - Department of Population Health, New York University Grossman School of Medicine, 
      New York, NY, United States.
FAU - Levine, Defne L
AU  - Levine DL
AUID- ORCID: 0009-0000-5238-3144
AD  - Department of Population Health, New York University Grossman School of Medicine, 
      New York, NY, United States.
FAU - Mann, Devin
AU  - Mann D
AUID- ORCID: 0000-0002-2099-0852
AD  - Department of Population Health, New York University Grossman School of Medicine, 
      New York, NY, United States.
AD  - Medical Center Information Technology, Department of Health Informatics, New York 
      University Langone Health, New York, NY, United States.
LA  - eng
SI  - ClinicalTrials.gov/NCT04049500
GR  - R18 DK118545/DK/NIDDK NIH HHS/United States
PT  - Clinical Study
PT  - Journal Article
DEP - 20240306
PL  - Canada
TA  - JMIR Hum Factors
JT  - JMIR human factors
JID - 101666561
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Benchmarking
MH  - Biomedical Technology
MH  - *Health Services Research
MH  - Software
PMC - PMC10955400
OTO - NOTNLM
OT  - ChatGPT
OT  - GenAI
OT  - LLM
OT  - LLMs
OT  - NLP
OT  - app
OT  - application
OT  - applications
OT  - apps
OT  - artificial intelligence
OT  - behavior change
OT  - behaviour change
OT  - developer
OT  - developers
OT  - diabetes
OT  - diabetes prevention
OT  - diabetic
OT  - digital health
OT  - digital prescription
OT  - engagement
OT  - generative
OT  - language model
OT  - language models
OT  - mHealth
OT  - mobile health
OT  - natural language processing
OT  - software
OT  - software engineering
COIS- Conflicts of Interest: None declared.
EDAT- 2024/03/06 12:43
MHDA- 2024/03/07 06:43
PMCR- 2024/03/06
CRDT- 2024/03/06 11:54
PHST- 2023/09/18 00:00 [received]
PHST- 2023/12/15 00:00 [accepted]
PHST- 2023/11/27 00:00 [revised]
PHST- 2024/03/07 06:43 [medline]
PHST- 2024/03/06 12:43 [pubmed]
PHST- 2024/03/06 11:54 [entrez]
PHST- 2024/03/06 00:00 [pmc-release]
AID - v11i1e52885 [pii]
AID - 10.2196/52885 [doi]
PST - epublish
SO  - JMIR Hum Factors. 2024 Mar 6;11:e52885. doi: 10.2196/52885.

PMID- 37907728
OWN - NLM
STAT- Publisher
LR  - 20231101
IS  - 1432-0460 (Electronic)
IS  - 0179-051X (Linking)
DP  - 2023 Oct 31
TI  - Using ChatGPT to Generate Research Ideas in Dysphagia: A Pilot Study.
LID - 10.1007/s00455-023-10623-9 [doi]
AB  - Current research in dysphagia faces challenges due to the rapid growth of 
      scientific literature and the interdisciplinary nature of the field. To address 
      this, the study evaluates ChatGPT, an AI language model, as a supplementary 
      resource to assist clinicians and researchers in generating research ideas for 
      dysphagia, utilizing recent advancements in natural language processing and 
      machine learning. The research ideas were generated through ChatGPT's command to 
      explore diverse aspects of dysphagia. A web-based survey was conducted, 45 
      dysphagia experts were asked to rank each study on a scale of 1 to 5 according to 
      feasibility, novelty, clinical implications, and relevance to current practice. A 
      total of 26 experts (58%) completed the survey. The mean (± sd) rankings of 
      research ideas were 4.03 (± 0.17) for feasibility, 3.5 (± 0.17) for potential 
      impact on the field, 3.84 (± 0.12) for clinical relevance, and 3.08 (± 0.36) for 
      novelty and innovation. Results of this study suggest that ChatGPT offers a 
      promising approach to generating research ideas in dysphagia. While its current 
      capability to generate innovative ideas appears limited, it can serve as a 
      supplementary resource for researchers.
CI  - © 2023. The Author(s), under exclusive licence to Springer Science+Business 
      Media, LLC, part of Springer Nature.
FAU - Nachalon, Yuval
AU  - Nachalon Y
AUID- ORCID: 0000-0001-6202-4647
AD  - Department of Otolaryngology, Head and Neck Surgery and Maxillofacial Surgery, 
      Tel-Aviv Sourasky Medical Center, 6 Weizman Street, 6423906, Tel-Aviv, Israel. 
      yuval.nachalon@gmail.com.
AD  - Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel. 
      yuval.nachalon@gmail.com.
FAU - Broer, Maya
AU  - Broer M
AD  - Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel.
FAU - Nativ-Zeltzer, Nogah
AU  - Nativ-Zeltzer N
AD  - Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel.
LA  - eng
PT  - Journal Article
DEP - 20231031
PL  - United States
TA  - Dysphagia
JT  - Dysphagia
JID - 8610856
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - Clinical relevance
OT  - Dysphagia
OT  - Machine learning
OT  - Natural language processing (NLP)
OT  - Research ideas
EDAT- 2023/11/01 06:43
MHDA- 2023/11/01 06:43
CRDT- 2023/11/01 00:49
PHST- 2023/07/18 00:00 [received]
PHST- 2023/09/20 00:00 [accepted]
PHST- 2023/11/01 06:43 [medline]
PHST- 2023/11/01 06:43 [pubmed]
PHST- 2023/11/01 00:49 [entrez]
AID - 10.1007/s00455-023-10623-9 [pii]
AID - 10.1007/s00455-023-10623-9 [doi]
PST - aheadofprint
SO  - Dysphagia. 2023 Oct 31. doi: 10.1007/s00455-023-10623-9.

PMID- 37698823
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231113
IS  - 2193-8245 (Print)
IS  - 2193-6528 (Electronic)
VI  - 12
IP  - 6
DP  - 2023 Dec
TI  - Artificial Intelligence-Based ChatGPT Responses for Patient Questions on Optic 
      Disc Drusen.
PG  - 3109-3119
LID - 10.1007/s40123-023-00800-2 [doi]
AB  - INTRODUCTION: Optic disc drusen (ODD) are acellular deposits in the optic nerve 
      head, which are most often benign and asymptomatic. Patients may develop visual 
      field defects and be at increased risk of ischemic co-morbidities. As ODD can be 
      difficult to distinguish from papilledema, patients are at risk of unnecessary 
      clinical workups. Patient information is a key aspect of ODD management. In this 
      study, we explored the accuracy of ChatGPT responses for typical patient 
      questions on ODD. METHODS: Two content experts reached consensus on 20 typical 
      patient questions. We retrieved five separate responses for each question from 
      ChatGPT, totaling 100 responses. Each response was evaluated on a 5-point 
      Likert-scale on accuracy by each content expert in an individual fashion. 
      RESULTS: The two experts were in fair/substantial agreement in the evaluation of 
      responses (Cronbach's alpha: 0.64). Of the 100 responses, 17 were relevant and 
      without any inaccuracies, 78 were relevant and with inaccuracies not being 
      harmful, and five were relevant and with inaccuracies potentially harmful. The 
      lowest accuracy scores were obtained for questions dealing with treatment and 
      prognosis. CONCLUSIONS: ChatGPT often provides relevant answers for patient 
      questions on ODD, but inaccuracies become potentially harmful when questions deal 
      with treatment and prognosis.
CI  - © 2023. The Author(s).
FAU - Potapenko, Ivan
AU  - Potapenko I
AD  - Department of Ophthalmology, Rigshospitalet, Valdemar Hansens Vej 3, 2600, 
      Glostrup, Denmark.
FAU - Malmqvist, Lasse
AU  - Malmqvist L
AD  - Department of Ophthalmology, Rigshospitalet, Valdemar Hansens Vej 3, 2600, 
      Glostrup, Denmark.
FAU - Subhi, Yousif
AU  - Subhi Y
AD  - Department of Ophthalmology, Rigshospitalet, Valdemar Hansens Vej 3, 2600, 
      Glostrup, Denmark.
AD  - Department of Clinical Research, University of Southern Denmark, Odense, Denmark.
FAU - Hamann, Steffen
AU  - Hamann S
AUID- ORCID: 0000-0003-4318-2716
AD  - Department of Ophthalmology, Rigshospitalet, Valdemar Hansens Vej 3, 2600, 
      Glostrup, Denmark. steffen.ellitsgaard.hamann@regionh.dk.
AD  - Department of Clinical Medicine, University of Copenhagen, Copenhagen, Denmark. 
      steffen.ellitsgaard.hamann@regionh.dk.
LA  - eng
PT  - Journal Article
DEP - 20230912
PL  - England
TA  - Ophthalmol Ther
JT  - Ophthalmology and therapy
JID - 101634502
PMC - PMC10640407
OTO - NOTNLM
OT  - Accuracy
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Optic disc drusen
OT  - Patient information
COIS- Yousif Subhi has received speakers fees from Bayer and Roche, not related to this 
      work. Ivan Potapenko, Lasse Malmqvist, and Steffen Hamann have nothing to 
      disclose.
EDAT- 2023/09/12 12:42
MHDA- 2023/09/12 12:43
PMCR- 2023/09/12
CRDT- 2023/09/12 11:24
PHST- 2023/06/09 00:00 [received]
PHST- 2023/08/21 00:00 [accepted]
PHST- 2023/09/12 12:43 [medline]
PHST- 2023/09/12 12:42 [pubmed]
PHST- 2023/09/12 11:24 [entrez]
PHST- 2023/09/12 00:00 [pmc-release]
AID - 10.1007/s40123-023-00800-2 [pii]
AID - 800 [pii]
AID - 10.1007/s40123-023-00800-2 [doi]
PST - ppublish
SO  - Ophthalmol Ther. 2023 Dec;12(6):3109-3119. doi: 10.1007/s40123-023-00800-2. Epub 
      2023 Sep 12.

PMID- 37269717
OWN - NLM
STAT- MEDLINE
DCOM- 20230616
LR  - 20230628
IS  - 1873-1244 (Electronic)
IS  - 0899-9007 (Linking)
VI  - 112
DP  - 2023 Aug
TI  - The credibility of dietary advice formulated by ChatGPT: Robo-diets for people 
      with food allergies.
PG  - 112076
LID - S0899-9007(23)00105-3 [pii]
LID - 10.1016/j.nut.2023.112076 [doi]
AB  - The introduction of ChatGPT has sparked enormous public interest in large 
      language (deep-learning) models, which have been sophisticated enough to perform 
      well on a variety of tasks. One way people are using these models is to construct 
      diets. The prompts often include food restrictions that are an obligatory part of 
      everyday life for millions of people worldwide. The aim of this study was to 
      investigate the safety and accuracy of 56 diets, constructed for hypothetical 
      individuals who are allergic to food allergens. Four levels, corresponding to the 
      "baseline" ability of ChatGPT without prompting for specifics, as well as its 
      ability to prepare appropriate diets when an individual has an adverse food 
      reaction to two allergens or solicits a low-calorie diet, were defined. Findings 
      from our study demonstrated that ChatGPT, although generally accurate, has the 
      potential to produce harmful diets. More common errors involve inaccuracies in 
      portions or calories of food, meals, or diets. We discuss here how the accuracy 
      of large language models could be increased and the trade-offs involved. We 
      propose that prompting for elimination diets can serve as one way to assess 
      differences between such models.
CI  - Copyright © 2023 The Author(s). Published by Elsevier Inc. All rights reserved.
FAU - Niszczota, Paweł
AU  - Niszczota P
AD  - Institute of International Business and Economics, Poznań University of Economics 
      and Business, Poznań, Poland; Humans &amp; AI Laboratory (HAI Lab), Poznań University 
      of Economics and Business, Poznań, Poland.
FAU - Rybicka, Iga
AU  - Rybicka I
AD  - Humans &amp; AI Laboratory (HAI Lab), Poznań University of Economics and Business, 
      Poznań, Poland; Institute of Quality Science, Poznań University of Economics and 
      Business, Poznań, Poland. Electronic address: iga.rybicka@ue.poznan.pl.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20230511
PL  - United States
TA  - Nutrition
JT  - Nutrition (Burbank, Los Angeles County, Calif.)
JID - 8802712
RN  - 0 (Allergens)
SB  - IM
MH  - Humans
MH  - *Diet
MH  - *Food Hypersensitivity
MH  - Energy Intake
MH  - Allergens
MH  - Meals
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Dietary advice
OT  - Food allergy
OT  - Nutrition
OT  - Robo-diet
COIS- Declaration of Competing Interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2023/06/04 01:08
MHDA- 2023/06/16 06:42
CRDT- 2023/06/03 18:06
PHST- 2023/02/15 00:00 [received]
PHST- 2023/04/07 00:00 [revised]
PHST- 2023/05/08 00:00 [accepted]
PHST- 2023/06/16 06:42 [medline]
PHST- 2023/06/04 01:08 [pubmed]
PHST- 2023/06/03 18:06 [entrez]
AID - S0899-9007(23)00105-3 [pii]
AID - 10.1016/j.nut.2023.112076 [doi]
PST - ppublish
SO  - Nutrition. 2023 Aug;112:112076. doi: 10.1016/j.nut.2023.112076. Epub 2023 May 11.

PMID- 37440646
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20230718
LR  - 20230718
IS  - 1095-9203 (Electronic)
IS  - 0036-8075 (Linking)
VI  - 381
IP  - 6654
DP  - 2023 Jul 14
TI  - Experimental evidence on the productivity effects of generative artificial 
      intelligence.
PG  - 187-192
LID - 10.1126/science.adh2586 [doi]
AB  - We examined the productivity effects of a generative artificial intelligence (AI) 
      technology, the assistive chatbot ChatGPT, in the context of midlevel 
      professional writing tasks. In a preregistered online experiment, we assigned 
      occupation-specific, incentivized writing tasks to 453 college-educated 
      professionals and randomly exposed half of them to ChatGPT. Our results show that 
      ChatGPT substantially raised productivity: The average time taken decreased by 
      40% and output quality rose by 18%. Inequality between workers decreased, and 
      concern and excitement about AI temporarily rose. Workers exposed to ChatGPT 
      during the experiment were 2 times as likely to report using it in their real job 
      2 weeks after the experiment and 1.6 times as likely 2 months after the 
      experiment.
FAU - Noy, Shakked
AU  - Noy S
AUID- ORCID: 0000-0002-7814-5184
AD  - Department of Economics, Massachusetts Institute of Technology, Cambridge, MA, 
      USA.
FAU - Zhang, Whitney
AU  - Zhang W
AUID- ORCID: 0000-0001-7399-0066
AD  - Department of Economics, Massachusetts Institute of Technology, Cambridge, MA, 
      USA.
LA  - eng
PT  - Journal Article
DEP - 20230713
PL  - United States
TA  - Science
JT  - Science (New York, N.Y.)
JID - 0404511
SB  - IM
EDAT- 2023/07/13 19:15
MHDA- 2023/07/17 06:42
CRDT- 2023/07/13 14:03
PHST- 2023/07/17 06:42 [medline]
PHST- 2023/07/13 19:15 [pubmed]
PHST- 2023/07/13 14:03 [entrez]
AID - 10.1126/science.adh2586 [doi]
PST - ppublish
SO  - Science. 2023 Jul 14;381(6654):187-192. doi: 10.1126/science.adh2586. Epub 2023 
      Jul 13.

PMID- 38472675
OWN - NLM
STAT- Publisher
LR  - 20240313
IS  - 1534-4681 (Electronic)
IS  - 1068-9265 (Linking)
DP  - 2024 Mar 12
TI  - Enhanced Artificial Intelligence Strategies in Renal Oncology: Iterative 
      Optimization and Comparative Analysis of GPT 3.5 Versus 4.0.
LID - 10.1245/s10434-024-15107-0 [doi]
AB  - BACKGROUND: The rise of artificial intelligence (AI) in medicine has revealed the 
      potential of ChatGPT as a pivotal tool in medical diagnosis and treatment. This 
      study assesses the efficacy of ChatGPT versions 3.5 and 4.0 in addressing renal 
      cell carcinoma (RCC) clinical inquiries. Notably, fine-tuning and iterative 
      optimization of the model corrected ChatGPT's limitations in this area. METHODS: 
      In our study, 80 RCC-related clinical questions from urology experts were posed 
      three times to both ChatGPT 3.5 and ChatGPT 4.0, seeking binary (yes/no) 
      responses. We then statistically analyzed the answers. Finally, we fine-tuned the 
      GPT-3.5 Turbo model using these questions, and assessed its training outcomes. 
      RESULTS: We found that the average accuracy rates of answers provided by ChatGPT 
      versions 3.5 and 4.0 were 67.08% and 77.50%, respectively. ChatGPT 4.0 
      outperformed ChatGPT 3.5, with a higher accuracy rate in responses (p&nbsp;&lt;&nbsp;0.05). By 
      counting the number of correct responses to the 80 questions, we then found that 
      although ChatGPT 4.0 performed better (p&nbsp;&lt;&nbsp;0.05), both versions were subject to 
      instability in answering. Finally, by fine-tuning the GPT-3.5 Turbo model, we 
      found that the correct rate of responses to these questions could be stabilized 
      at 93.75%. Iterative optimization of the model can result in 100% response 
      accuracy. CONCLUSION: We compared ChatGPT versions 3.5 and 4.0 in addressing 
      clinical RCC questions, identifying their limitations. By applying the 
      GPT-3.5&nbsp;Turbo fine-tuned model iterative training method, we enhanced AI 
      strategies in renal oncology. This approach is set to enhance ChatGPT's database 
      and clinical guidance capabilities, optimizing AI in this field.
CI  - © 2024. Society of Surgical Oncology.
FAU - Liang, Rui
AU  - Liang R
AD  - Department of Urology, The First Affiliated Hospital of Soochow University, 
      Suzhou, Jiangsu, China.
AD  - Department of Urology, South China Hospital, Medical School, Shenzhen University, 
      Shenzhen, Guangdong, China.
AD  - Department of Urology, The Third Affiliated Hospital of Shenzhen University 
      (Luohu Hospital Group), Shenzhen University, Shenzhen, Guangdong, China.
FAU - Zhao, Anguo
AU  - Zhao A
AD  - Department of Urology, South China Hospital, Medical School, Shenzhen University, 
      Shenzhen, Guangdong, China.
AD  - Department of Urology, Medical Center of Soochow University, Suzhou Dushu Lake 
      Hospital, Dushu Lake Hospital Affiliated to Soochow University, Suzhou, Jiangsu, 
      China.
FAU - Peng, Lei
AU  - Peng L
AD  - Department of Urology, South China Hospital, Medical School, Shenzhen University, 
      Shenzhen, Guangdong, China.
AD  - Department of Urology, The Third Affiliated Hospital of Shenzhen University 
      (Luohu Hospital Group), Shenzhen University, Shenzhen, Guangdong, China.
AD  - Department of Urology, Lanzhou University Second Hospital, Lanzhou, Gansu, China.
AD  - North Sichuan Medical College (University), Nanchong, Sichuan, China.
FAU - Xu, Xiaojian
AU  - Xu X
AD  - Department of Urology, The First Affiliated Hospital of Soochow University, 
      Suzhou, Jiangsu, China.
FAU - Zhong, Jianye
AU  - Zhong J
AD  - Department of Urology, South China Hospital, Medical School, Shenzhen University, 
      Shenzhen, Guangdong, China.
FAU - Wu, Fan
AU  - Wu F
AD  - Faculty of Intelligent Manufacturing and Control Engineering, Shanghai 
      Polytechnic University, Shanghai, China.
FAU - Yi, Fulin
AU  - Yi F
AD  - North Sichuan Medical College (University), Nanchong, Sichuan, China.
FAU - Zhang, Shaohua
AU  - Zhang S
AD  - Department of Urology, South China Hospital, Medical School, Shenzhen University, 
      Shenzhen, Guangdong, China. zhangshaohua@szu.edu.cn.
AD  - Department of Urology, The Third Affiliated Hospital of Shenzhen University 
      (Luohu Hospital Group), Shenzhen University, Shenzhen, Guangdong, China. 
      zhangshaohua@szu.edu.cn.
FAU - Wu, Song
AU  - Wu S
AD  - Department of Urology, South China Hospital, Medical School, Shenzhen University, 
      Shenzhen, Guangdong, China. wusong@szu.edu.cn.
AD  - Department of Urology, The Third Affiliated Hospital of Shenzhen University 
      (Luohu Hospital Group), Shenzhen University, Shenzhen, Guangdong, China. 
      wusong@szu.edu.cn.
AD  - Department of Urology, Lanzhou University Second Hospital, Lanzhou, Gansu, China. 
      wusong@szu.edu.cn.
FAU - Hou, Jianquan
AU  - Hou J
AD  - Department of Urology, The First Affiliated Hospital of Soochow University, 
      Suzhou, Jiangsu, China. xf192@163.com.
AD  - Department of Urology, Medical Center of Soochow University, Suzhou Dushu Lake 
      Hospital, Dushu Lake Hospital Affiliated to Soochow University, Suzhou, Jiangsu, 
      China. xf192@163.com.
LA  - eng
GR  - A2302048/Shenzhen Medical Research Fund(SMRF)/
GR  - 12326610/the National Natural Science Foundation of China (Tianyuan Fund for 
      Mathematics)/
GR  - 82102171/National Natural Science Foundation of China/
GR  - RCJC20200714114557005/Shenzhen Science and Technology Innovatio Commission/
PT  - Journal Article
DEP - 20240312
PL  - United States
TA  - Ann Surg Oncol
JT  - Annals of surgical oncology
JID - 9420840
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Chat generative pre-trained transformer
OT  - Fine-tuned model
OT  - GPT-3.5&nbsp;Turbo
OT  - Renal cell carcinoma
EDAT- 2024/03/13 06:46
MHDA- 2024/03/13 06:46
CRDT- 2024/03/13 01:12
PHST- 2024/01/15 00:00 [received]
PHST- 2024/02/12 00:00 [accepted]
PHST- 2024/03/13 06:46 [medline]
PHST- 2024/03/13 06:46 [pubmed]
PHST- 2024/03/13 01:12 [entrez]
AID - 10.1245/s10434-024-15107-0 [pii]
AID - 10.1245/s10434-024-15107-0 [doi]
PST - aheadofprint
SO  - Ann Surg Oncol. 2024 Mar 12. doi: 10.1245/s10434-024-15107-0.

PMID- 38306961
OWN - NLM
STAT- Publisher
LR  - 20240202
IS  - 1466-187X (Electronic)
IS  - 0142-159X (Linking)
DP  - 2024 Feb 2
TI  - Incorporating artificial intelligence into a workshop on scientific and scholarly 
      report writing for preclinical medical students.
PG  - 1-3
LID - 10.1080/0142159X.2024.2311267 [doi]
AB  - This article presents the use of an artificial intelligence (AI) tool (ChatGPT) 
      to transform a didactic lecture to an interactive workshop. The workshop on 
      scientific and scholarly report writing was conducted for preclinical medical 
      students. The functions of the AI as teaching assistance and documentation were 
      expected to support the workshop. In this workshop, the AI was used to summarise 
      and generate the summary notes based on students' inputs throughout the 
      interactive activities during the workshop. Future research should focus on 
      potential functions of AI in medical education and its impacts on student's 
      learning outcomes.
FAU - Prachnakorn, Natdanai
AU  - Prachnakorn N
AD  - School of Medicine, Walailak University, Nakhon Si Thammarat, Thailand.
FAU - Preecha, Kongsit
AU  - Preecha K
AD  - School of Medicine, Walailak University, Nakhon Si Thammarat, Thailand.
FAU - Sri-U-Thai, Thanapon
AU  - Sri-U-Thai T
AD  - School of Medicine, Walailak University, Nakhon Si Thammarat, Thailand.
FAU - Jaroenyod, Thanat
AU  - Jaroenyod T
AD  - School of Medicine, Walailak University, Nakhon Si Thammarat, Thailand.
FAU - Sawang, Kanokpitch
AU  - Sawang K
AD  - School of Medicine, Walailak University, Nakhon Si Thammarat, Thailand.
FAU - Patwong, Natthakamol
AU  - Patwong N
AD  - School of Medicine, Walailak University, Nakhon Si Thammarat, Thailand.
FAU - Wattanapisit, Apichai
AU  - Wattanapisit A
AUID- ORCID: 0000-0002-9537-8510
AD  - School of Medicine, Walailak University, Nakhon Si Thammarat, Thailand.
LA  - eng
PT  - Journal Article
DEP - 20240202
PL  - England
TA  - Med Teach
JT  - Medical teacher
JID - 7909593
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - medical education
OT  - workshop
OT  - writing
EDAT- 2024/02/03 00:42
MHDA- 2024/02/03 00:42
CRDT- 2024/02/02 18:15
PHST- 2024/02/03 00:42 [medline]
PHST- 2024/02/03 00:42 [pubmed]
PHST- 2024/02/02 18:15 [entrez]
AID - 10.1080/0142159X.2024.2311267 [doi]
PST - aheadofprint
SO  - Med Teach. 2024 Feb 2:1-3. doi: 10.1080/0142159X.2024.2311267.

PMID- 38199794
OWN - NLM
STAT- MEDLINE
DCOM- 20240304
LR  - 20240304
IS  - 1460-2350 (Electronic)
IS  - 0268-1161 (Print)
IS  - 0268-1161 (Linking)
VI  - 39
IP  - 3
DP  - 2024 Mar 1
TI  - ChatGPT: a reliable fertility decision-making tool?
PG  - 443-447
LID - 10.1093/humrep/dead272 [doi]
AB  - The internet is the primary source of infertility-related information for most 
      people who are experiencing fertility issues. Although no longer shrouded in 
      stigma, the privacy of interacting only with a computer provides a sense of 
      safety when engaging with sensitive content and allows for diverse and 
      geographically dispersed communities to connect and share their experiences. It 
      also provides businesses with a virtual marketplace for their products. The 
      introduction of ChatGPT, a conversational language model developed by OpenAI to 
      understand and generate human-like text in response to user input, in November 
      2022, and other emerging generative artificial intelligence (AI) language models, 
      has changed and will continue to change the way we interact with large volumes of 
      digital information. When it comes to its application in health information 
      seeking, specifically in relation to fertility in this case, is ChatGPT a friend 
      or foe in helping people make well-informed decisions? Furthermore, if deemed 
      useful, how can we ensure this technology supports fertility-related 
      decision-making? After conducting a study into the quality of the information 
      provided by ChatGPT to people seeking information on fertility, we explore the 
      potential benefits and pitfalls of using generative AI as a tool to support 
      decision-making.
CI  - © The Author(s) 2024. Published by Oxford University Press on behalf of European 
      Society of Human Reproduction and Embryology.
FAU - Beilby, Kiri
AU  - Beilby K
AUID- ORCID: 0000-0002-1378-5586
AD  - Education Program in Reproduction and Development, Department of Obstetrics and 
      Gynaecology, School of Clinical Sciences, Monash University, Melbourne, 
      Australia.
FAU - Hammarberg, Karin
AU  - Hammarberg K
AUID- ORCID: 0000-0002-5988-5865
AD  - Global and Women's Health, School of Public and Health and Preventative Medicine, 
      Monash University, Melbourne, Australia.
LA  - eng
GR  - Monash University/
PT  - Journal Article
PL  - England
TA  - Hum Reprod
JT  - Human reproduction (Oxford, England)
JID - 8701199
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Fertility
MH  - *Infertility/therapy
MH  - Commerce
MH  - Communication
PMC - PMC10905498
OTO - NOTNLM
OT  - ChatGPT
OT  - decision support
OT  - generative artificial intelligence
OT  - infertility treatment
OT  - online information
COIS- Neither author has any conflicts of interest to declare.
EDAT- 2024/01/11 00:42
MHDA- 2024/03/04 06:50
PMCR- 2024/01/10
CRDT- 2024/01/10 21:23
PHST- 2023/08/28 00:00 [received]
PHST- 2023/12/11 00:00 [revised]
PHST- 2024/03/04 06:50 [medline]
PHST- 2024/01/11 00:42 [pubmed]
PHST- 2024/01/10 21:23 [entrez]
PHST- 2024/01/10 00:00 [pmc-release]
AID - 7515221 [pii]
AID - dead272 [pii]
AID - 10.1093/humrep/dead272 [doi]
PST - ppublish
SO  - Hum Reprod. 2024 Mar 1;39(3):443-447. doi: 10.1093/humrep/dead272.

PMID- 37459740
OWN - NLM
STAT- MEDLINE
DCOM- 20231102
LR  - 20231102
IS  - 1532-818X (Electronic)
IS  - 0196-0709 (Linking)
VI  - 44
IP  - 6
DP  - 2023 Nov-Dec
TI  - ChatGPT in head and neck scientific writing: A precautionary anecdote.
PG  - 103980
LID - S0196-0709(23)00194-1 [pii]
LID - 10.1016/j.amjoto.2023.103980 [doi]
AB  - PURPOSE: To evaluate the accuracy of ChatGPT references in scientific writing 
      relevant to head and neck surgery. MATERIALS AND METHODS: Five commonly 
      researched keywords relevant to head and neck surgery were selected 
      (osteoradionecrosis of the jaws, oral cancer, adjuvant therapy for oral cancer, 
      TORS, and free flap reconstruction in oral cancer). The AI chatbot was then asked 
      to provide ten complete citations for each of the keywords. Two independent 
      authors reviewed the results for accuracy and assigned each article a numerical 
      score based on pre-selected criteria. RESULTS: Among 50 total references provided 
      by ChatGPT, only five (10&nbsp;%) were found to have the correct title, journal, 
      authors, year of publication, and DOI. Merely 14&nbsp;% of the presented references 
      had correct DOI. References regarding free flap reconstruction for oral cancer 
      were the least accurate from all the five categories, with no correct DOI. 
      Complete inter-rater agreement was noted while evaluating the citations. 
      CONCLUSION: Only 10&nbsp;% of the articles provided by ChatGPT, relevant to head and 
      neck surgery, were correct. A high degree of academic hallucination was noted.
CI  - Copyright © 2023 Elsevier Inc. All rights reserved.
FAU - Wu, Robin T
AU  - Wu RT
AD  - Department of Plastic and Reconstruction Surgery, Chang Gung Memorial Hospital, 
      Linkou, Taiwan; Division of Plastic and Reconstructive Surgery, Department of 
      Surgery, Stanford University Hospital, Stanford, CA, USA.
FAU - Dang, Rushil R
AU  - Dang RR
AD  - Department of Plastic and Reconstruction Surgery, Chang Gung Memorial Hospital, 
      Linkou, Taiwan; Former fellow, Maxillofacial Oncology and Reconstructive Surgery, 
      Department of Oral and Maxillofacial Surgery, Boston Medical Center, Boston, MA, 
      USA. Electronic address: rushilrd@bu.edu.
LA  - eng
PT  - Journal Article
DEP - 20230706
PL  - United States
TA  - Am J Otolaryngol
JT  - American journal of otolaryngology
JID - 8000029
SB  - IM
MH  - Humans
MH  - *Head
MH  - Neck
MH  - *Mouth Neoplasms
MH  - Combined Modality Therapy
MH  - Writing
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - Head and neck surgery
OT  - Oral cancer
COIS- Declaration of competing interest The authors have no conflict of interest to 
      declare.
EDAT- 2023/07/17 19:08
MHDA- 2023/07/17 19:09
CRDT- 2023/07/17 18:03
PHST- 2023/06/06 00:00 [received]
PHST- 2023/07/04 00:00 [accepted]
PHST- 2023/07/17 19:09 [medline]
PHST- 2023/07/17 19:08 [pubmed]
PHST- 2023/07/17 18:03 [entrez]
AID - S0196-0709(23)00194-1 [pii]
AID - 10.1016/j.amjoto.2023.103980 [doi]
PST - ppublish
SO  - Am J Otolaryngol. 2023 Nov-Dec;44(6):103980. doi: 10.1016/j.amjoto.2023.103980. 
      Epub 2023 Jul 6.

PMID- 38335017
OWN - NLM
STAT- MEDLINE
DCOM- 20240214
LR  - 20240227
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 10
DP  - 2024 Feb 9
TI  - Performance of ChatGPT on the Chinese Postgraduate Examination for Clinical 
      Medicine: Survey Study.
PG  - e48514
LID - 10.2196/48514 [doi]
LID - e48514
AB  - BACKGROUND: ChatGPT, an artificial intelligence (AI) based on large-scale 
      language models, has sparked interest in the field of health care. Nonetheless, 
      the capabilities of AI in text comprehension and generation are constrained by 
      the quality and volume of available training data for a specific language, and 
      the performance of AI across different languages requires further investigation. 
      While AI harbors substantial potential in medicine, it is imperative to tackle 
      challenges such as the formulation of clinical care standards; facilitating 
      cultural transitions in medical education and practice; and managing ethical 
      issues including data privacy, consent, and bias. OBJECTIVE: The study aimed to 
      evaluate ChatGPT's performance in processing Chinese Postgraduate Examination for 
      Clinical Medicine questions, assess its clinical reasoning ability, investigate 
      potential limitations with the Chinese language, and explore its potential as a 
      valuable tool for medical professionals in the Chinese context. METHODS: A data 
      set of Chinese Postgraduate Examination for Clinical Medicine questions was used 
      to assess the effectiveness of ChatGPT's (version 3.5) medical knowledge in the 
      Chinese language, which has a data set of 165 medical questions that were divided 
      into three categories: (1) common questions (n=90) assessing basic medical 
      knowledge, (2) case analysis questions (n=45) focusing on clinical 
      decision-making through patient case evaluations, and (3) multichoice questions 
      (n=30) requiring the selection of multiple correct answers. First of all, we 
      assessed whether ChatGPT could meet the stringent cutoff score defined by the 
      government agency, which requires a performance within the top 20% of candidates. 
      Additionally, in our evaluation of ChatGPT's performance on both original and 
      encoded medical questions, 3 primary indicators were used: accuracy, concordance 
      (which validates the answer), and the frequency of insights. RESULTS: Our 
      evaluation revealed that ChatGPT scored 153.5 out of 300 for original questions 
      in Chinese, which signifies the minimum score set to ensure that at least 20% 
      more candidates pass than the enrollment quota. However, ChatGPT had low accuracy 
      in answering open-ended medical questions, with only 31.5% total accuracy. The 
      accuracy for common questions, multichoice questions, and case analysis questions 
      was 42%, 37%, and 17%, respectively. ChatGPT achieved a 90% concordance across 
      all questions. Among correct responses, the concordance was 100%, significantly 
      exceeding that of incorrect responses (n=57, 50%; P&lt;.001). ChatGPT provided 
      innovative insights for 80% (n=132) of all questions, with an average of 2.95 
      insights per accurate response. CONCLUSIONS: Although ChatGPT surpassed the 
      passing threshold for the Chinese Postgraduate Examination for Clinical Medicine, 
      its performance in answering open-ended medical questions was suboptimal. 
      Nonetheless, ChatGPT exhibited high internal concordance and the ability to 
      generate multiple insights in the Chinese language. Future research should 
      investigate the language-based discrepancies in ChatGPT's performance within the 
      health care context.
CI  - ©Peng Yu, Changchang Fang, Xiaolin Liu, Wanying Fu, Jitao Ling, Zhiwei Yan, Yuan 
      Jiang, Zhengyu Cao, Maoxiong Wu, Zhiteng Chen, Wengen Zhu, Yuling Zhang, Ayiguli 
      Abudukeremu, Yue Wang, Xiao Liu, Jingfeng Wang. Originally published in JMIR 
      Medical Education (https://mededu.jmir.org), 09.02.2024.
FAU - Yu, Peng
AU  - Yu P
AUID- ORCID: 0009-0008-0345-5787
AD  - Department of Endocrine, The Second Affiliated Hospital of Nanchang University, 
      Jiangxi, China.
FAU - Fang, Changchang
AU  - Fang C
AUID- ORCID: 0009-0006-0794-4188
AD  - Department of Endocrine, The Second Affiliated Hospital of Nanchang University, 
      Jiangxi, China.
FAU - Liu, Xiaolin
AU  - Liu X
AUID- ORCID: 0009-0000-4824-8820
AD  - Department of Cardiology, The Eighth Affiliated Hospital of Sun Yat-sen 
      University, Shenzhen, China.
FAU - Fu, Wanying
AU  - Fu W
AUID- ORCID: 0009-0003-7778-7219
AD  - Department of Endocrine, The Second Affiliated Hospital of Nanchang University, 
      Jiangxi, China.
FAU - Ling, Jitao
AU  - Ling J
AUID- ORCID: 0000-0002-1720-8620
AD  - Department of Endocrine, The Second Affiliated Hospital of Nanchang University, 
      Jiangxi, China.
FAU - Yan, Zhiwei
AU  - Yan Z
AUID- ORCID: 0000-0002-1754-9126
AD  - College of Kinesiology, Shenyang Sport University, Shenyang, China.
FAU - Jiang, Yuan
AU  - Jiang Y
AUID- ORCID: 0000-0001-8704-3676
AD  - Department of Cardiology, Sun Yat-sen Memorial Hospital of Sun Yat-sen 
      University, Guangzhou, China.
FAU - Cao, Zhengyu
AU  - Cao Z
AUID- ORCID: 0000-0002-8372-3735
AD  - Department of Cardiology, Sun Yat-sen Memorial Hospital of Sun Yat-sen 
      University, Guangzhou, China.
FAU - Wu, Maoxiong
AU  - Wu M
AUID- ORCID: 0000-0002-6943-2763
AD  - Department of Cardiology, Sun Yat-sen Memorial Hospital of Sun Yat-sen 
      University, Guangzhou, China.
FAU - Chen, Zhiteng
AU  - Chen Z
AUID- ORCID: 0000-0002-0322-323X
AD  - Department of Cardiology, Sun Yat-sen Memorial Hospital of Sun Yat-sen 
      University, Guangzhou, China.
FAU - Zhu, Wengen
AU  - Zhu W
AUID- ORCID: 0000-0002-1280-0158
AD  - Department of Cardiology, The First Affiliated Hospital of Sun Yat-sen 
      University, Guangzhou, China.
FAU - Zhang, Yuling
AU  - Zhang Y
AUID- ORCID: 0000-0002-9071-3148
AD  - Department of Cardiology, Sun Yat-sen Memorial Hospital of Sun Yat-sen 
      University, Guangzhou, China.
FAU - Abudukeremu, Ayiguli
AU  - Abudukeremu A
AUID- ORCID: 0009-0004-7895-9761
AD  - Department of Cardiology, Sun Yat-sen Memorial Hospital of Sun Yat-sen 
      University, Guangzhou, China.
FAU - Wang, Yue
AU  - Wang Y
AUID- ORCID: 0009-0006-3194-5375
AD  - Department of Cardiology, Sun Yat-sen Memorial Hospital of Sun Yat-sen 
      University, Guangzhou, China.
FAU - Liu, Xiao
AU  - Liu X
AUID- ORCID: 0000-0002-5570-289X
AD  - Department of Cardiology, Sun Yat-sen Memorial Hospital of Sun Yat-sen 
      University, Guangzhou, China.
FAU - Wang, Jingfeng
AU  - Wang J
AUID- ORCID: 0009-0005-7309-6984
AD  - Department of Cardiology, Sun Yat-sen Memorial Hospital of Sun Yat-sen 
      University, Guangzhou, China.
LA  - eng
PT  - Journal Article
DEP - 20240209
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
SB  - IM
MH  - *Artificial Intelligence
MH  - *Clinical Medicine
MH  - Language
MH  - *Educational Measurement
PMC - PMC10891494
OTO - NOTNLM
OT  - ChatGPT
OT  - Chinese Postgraduate Examination for Clinical Medicine
OT  - artificial intelligence
OT  - clinical decision-making
OT  - medical care
OT  - medical education
OT  - medical student
OT  - performance
OT  - qualitative feedback
COIS- Conflicts of Interest: None declared.
EDAT- 2024/02/09 12:44
MHDA- 2024/02/10 22:54
PMCR- 2024/02/09
CRDT- 2024/02/09 11:53
PHST- 2023/04/26 00:00 [received]
PHST- 2023/12/11 00:00 [accepted]
PHST- 2023/10/04 00:00 [revised]
PHST- 2024/02/10 22:54 [medline]
PHST- 2024/02/09 12:44 [pubmed]
PHST- 2024/02/09 11:53 [entrez]
PHST- 2024/02/09 00:00 [pmc-release]
AID - v10i1e48514 [pii]
AID - 10.2196/48514 [doi]
PST - epublish
SO  - JMIR Med Educ. 2024 Feb 9;10:e48514. doi: 10.2196/48514.

PMID- 38310152
OWN - NLM
STAT- MEDLINE
DCOM- 20240205
LR  - 20240206
IS  - 2045-2322 (Electronic)
IS  - 2045-2322 (Linking)
VI  - 14
IP  - 1
DP  - 2024 Feb 3
TI  - Evaluating AI in medicine: a comparative analysis of expert and ChatGPT responses 
      to colorectal cancer questions.
PG  - 2840
LID - 10.1038/s41598-024-52853-3 [doi]
LID - 2840
AB  - Colorectal cancer (CRC) is a global health challenge, and patient education plays 
      a crucial role in its early detection and treatment. Despite progress in AI 
      technology, as exemplified by transformer-like models such as ChatGPT, there 
      remains a lack of in-depth understanding of their efficacy for medical purposes. 
      We aimed to assess the proficiency of ChatGPT in the field of popular science, 
      specifically in answering questions related to CRC diagnosis and treatment, using 
      the book "Colorectal Cancer: Your Questions Answered" as a reference. In general, 
      131 valid questions from the book were manually input into ChatGPT. Responses 
      were evaluated by clinical physicians in the relevant fields based on 
      comprehensiveness and accuracy of information, and scores were standardized for 
      comparison. Not surprisingly, ChatGPT showed high reproducibility in its 
      responses, with high uniformity in comprehensiveness, accuracy, and final scores. 
      However, the mean scores of ChatGPT's responses were significantly lower than the 
      benchmarks, indicating it has not reached an expert level of competence in CRC. 
      While it could provide accurate information, it lacked in comprehensiveness. 
      Notably, ChatGPT performed well in domains of radiation therapy, interventional 
      therapy, stoma care, venous care, and pain control, almost rivaling the 
      benchmarks, but fell short in basic information, surgery, and internal medicine 
      domains. While ChatGPT demonstrated promise in specific domains, its general 
      efficiency in providing CRC information falls short of expert standards, 
      indicating the need for further advancements and improvements in AI technology 
      for patient education in healthcare.
CI  - © 2024. The Author(s).
FAU - Peng, Wen
AU  - Peng W
AD  - Department of General Surgery, The First Affiliated Hospital with Nanjing Medical 
      University, Nanjing, 210029, Jiangsu, People's Republic of China.
AD  - The First School of Clinical Medicine, Nanjing Medical University, Nanjing, 
      China.
FAU - Feng, Yifei
AU  - Feng Y
AD  - Department of General Surgery, The First Affiliated Hospital with Nanjing Medical 
      University, Nanjing, 210029, Jiangsu, People's Republic of China.
AD  - The First School of Clinical Medicine, Nanjing Medical University, Nanjing, 
      China.
FAU - Yao, Cui
AU  - Yao C
AD  - Department of General Surgery, The First Affiliated Hospital with Nanjing Medical 
      University, Nanjing, 210029, Jiangsu, People's Republic of China.
AD  - The First School of Clinical Medicine, Nanjing Medical University, Nanjing, 
      China.
FAU - Zhang, Sheng
AU  - Zhang S
AD  - Department of Radiotherapy, The First Affiliated Hospital with Nanjing Medical 
      University, Nanjing, People's Republic of China.
FAU - Zhuo, Han
AU  - Zhuo H
AD  - Department of Intervention, The First Affiliated Hospital with Nanjing Medical 
      University, Nanjing, People's Republic of China.
FAU - Qiu, Tianzhu
AU  - Qiu T
AD  - Department of Oncology, The First Affiliated Hospital with Nanjing Medical 
      University, Nanjing, People's Republic of China.
FAU - Zhang, Yi
AU  - Zhang Y
AD  - Department of General Surgery, The First Affiliated Hospital with Nanjing Medical 
      University, Nanjing, 210029, Jiangsu, People's Republic of China.
AD  - The First School of Clinical Medicine, Nanjing Medical University, Nanjing, 
      China.
FAU - Tang, Junwei
AU  - Tang J
AD  - Department of General Surgery, The First Affiliated Hospital with Nanjing Medical 
      University, Nanjing, 210029, Jiangsu, People's Republic of China. 
      pepsitjw@njmu.edu.cn.
AD  - The First School of Clinical Medicine, Nanjing Medical University, Nanjing, 
      China. pepsitjw@njmu.edu.cn.
FAU - Gu, Yanhong
AU  - Gu Y
AD  - Department of Oncology, The First Affiliated Hospital with Nanjing Medical 
      University, Nanjing, People's Republic of China. guluer@163.com.
FAU - Sun, Yueming
AU  - Sun Y
AD  - Department of General Surgery, The First Affiliated Hospital with Nanjing Medical 
      University, Nanjing, 210029, Jiangsu, People's Republic of China. 
      jssym@vip.sina.com.
AD  - The First School of Clinical Medicine, Nanjing Medical University, Nanjing, 
      China. jssym@vip.sina.com.
LA  - eng
PT  - Journal Article
DEP - 20240203
PL  - England
TA  - Sci Rep
JT  - Scientific reports
JID - 101563288
SB  - IM
MH  - Humans
MH  - Reproducibility of Results
MH  - *Internal Medicine
MH  - Pain Management
MH  - Benchmarking
MH  - *Colorectal Neoplasms/diagnosis/therapy
PMC - PMC10838275
COIS- The authors declare no competing interests.
EDAT- 2024/02/04 00:42
MHDA- 2024/02/05 06:42
PMCR- 2024/02/03
CRDT- 2024/02/03 23:17
PHST- 2023/08/06 00:00 [received]
PHST- 2024/01/24 00:00 [accepted]
PHST- 2024/02/05 06:42 [medline]
PHST- 2024/02/04 00:42 [pubmed]
PHST- 2024/02/03 23:17 [entrez]
PHST- 2024/02/03 00:00 [pmc-release]
AID - 10.1038/s41598-024-52853-3 [pii]
AID - 52853 [pii]
AID - 10.1038/s41598-024-52853-3 [doi]
PST - epublish
SO  - Sci Rep. 2024 Feb 3;14(1):2840. doi: 10.1038/s41598-024-52853-3.

PMID- 38233511
OWN - NLM
STAT- MEDLINE
DCOM- 20240119
LR  - 20240201
IS  - 2045-2322 (Electronic)
IS  - 2045-2322 (Linking)
VI  - 14
IP  - 1
DP  - 2024 Jan 17
TI  - Availability of ChatGPT to provide medical information for patients with kidney 
      cancer.
PG  - 1542
LID - 10.1038/s41598-024-51531-8 [doi]
LID - 1542
AB  - ChatGPT is an advanced natural language processing technology that closely 
      resembles human language. We evaluated whether ChatGPT could help patients 
      understand kidney cancer and replace consultations with urologists. Two 
      urologists developed ten questions commonly asked by patients with kidney cancer. 
      The answers to these questions were produced using ChatGPT. The five-dimension 
      SERVQUAL model was used to assess the service quality of ChatGPT. The survey was 
      distributed to 103 urologists via email, and twenty-four urological oncologists 
      specializing in kidney cancer were included as experts with more than 20 kidney 
      cancer cases in clinic per month. All respondents were physicians. We received 24 
      responses to the email survey (response rate: 23.3%). The appropriateness rate 
      for all ten answers exceeded 60%. The answer to Q2 received the highest agreement 
      (91.7%, etiology of kidney cancer), whereas the answer to Q8 had the lowest 
      (62.5%, comparison with other cancers). The experts gave low assessment ratings 
      (44.4% vs. 93.3%, p = 0.028) in the SERVQUAL assurance (certainty of total 
      answers) dimension. Positive scores for the overall understandability of ChatGPT 
      answers were assigned by 54.2% of responders, and 70.8% said that ChatGPT could 
      not replace explanations provided by urologists. Our findings affirm that 
      although ChatGPT answers to kidney cancer questions are generally accessible, 
      they should not supplant the counseling of a urologist.
CI  - © 2024. The Author(s).
FAU - Choi, Joongwon
AU  - Choi J
AUID- ORCID: 0000-0001-5978-8179
AD  - Department of Urology, Chung-Ang University Gwangmyeong Hospital, Chung-Ang 
      University College of Medicine, Seoul, South Korea.
FAU - Kim, Jin Wook
AU  - Kim JW
AUID- ORCID: 0000-0003-4157-9365
AD  - Department of Urology, Chung-Ang University Gwangmyeong Hospital, Chung-Ang 
      University College of Medicine, Seoul, South Korea.
FAU - Lee, Yong Seong
AU  - Lee YS
AUID- ORCID: 0000-0003-0611-4554
AD  - Department of Urology, Chung-Ang University Gwangmyeong Hospital, Chung-Ang 
      University College of Medicine, Seoul, South Korea.
FAU - Tae, Jong Hyun
AU  - Tae JH
AUID- ORCID: 0000-0001-5826-3469
AD  - Department of Urology, Chung-Ang University Hospital, Chung-Ang University 
      College of Medicine, Seoul, South Korea.
FAU - Choi, Se Young
AU  - Choi SY
AUID- ORCID: 0000-0002-4615-0966
AD  - Department of Urology, Chung-Ang University Hospital, Chung-Ang University 
      College of Medicine, Seoul, South Korea.
FAU - Chang, In Ho
AU  - Chang IH
AUID- ORCID: 0000-0003-0240-1310
AD  - Department of Urology, Chung-Ang University Hospital, Chung-Ang University 
      College of Medicine, Seoul, South Korea.
FAU - Kim, Jung Hoon
AU  - Kim JH
AUID- ORCID: 0000-0002-0947-876X
AD  - Department of Urology, Chung-Ang University Gwangmyeong Hospital, Chung-Ang 
      University College of Medicine, Seoul, South Korea. simbauro80@hanmail.net.
AD  - Chung-Ang University Gwangmyeong Hospital, 110 Deokan-Ro, Gwangmyeong-Si, 
      Gyeonggi-Do, 14353, South Korea. simbauro80@hanmail.net.
LA  - eng
GR  - 2021R1F1A1048198/National Research Foundation of Korea/
PT  - Journal Article
DEP - 20240117
PL  - England
TA  - Sci Rep
JT  - Scientific reports
JID - 101563288
SB  - IM
MH  - Humans
MH  - *Carcinoma, Renal Cell
MH  - *Kidney Neoplasms/epidemiology
MH  - Patients
MH  - Ambulatory Care Facilities
MH  - Electronic Mail
PMC - PMC10794224
COIS- The authors declare no competing interests.
EDAT- 2024/01/18 00:42
MHDA- 2024/01/19 06:42
PMCR- 2024/01/17
CRDT- 2024/01/17 23:21
PHST- 2023/08/31 00:00 [received]
PHST- 2024/01/06 00:00 [accepted]
PHST- 2024/01/19 06:42 [medline]
PHST- 2024/01/18 00:42 [pubmed]
PHST- 2024/01/17 23:21 [entrez]
PHST- 2024/01/17 00:00 [pmc-release]
AID - 10.1038/s41598-024-51531-8 [pii]
AID - 51531 [pii]
AID - 10.1038/s41598-024-51531-8 [doi]
PST - epublish
SO  - Sci Rep. 2024 Jan 17;14(1):1542. doi: 10.1038/s41598-024-51531-8.

PMID- 37294147
OWN - NLM
STAT- MEDLINE
DCOM- 20230811
LR  - 20230811
IS  - 1728-7731 (Electronic)
IS  - 1726-4901 (Linking)
VI  - 86
IP  - 8
DP  - 2023 Aug 1
TI  - ChatGPT failed Taiwan's Family Medicine Board Exam.
PG  - 762-766
LID - 10.1097/JCMA.0000000000000946 [doi]
AB  - BACKGROUND: Chat Generative Pre-trained Transformer (ChatGPT), OpenAI Limited 
      Partnership, San Francisco, CA, USA is an artificial intelligence language model 
      gaining popularity because of its large database and ability to interpret and 
      respond to various queries. Although it has been tested by researchers in 
      different fields, its performance varies depending on the domain. We aimed to 
      further test its ability in the medical field. METHODS: We used questions from 
      Taiwan's 2022 Family Medicine Board Exam, which combined both Chinese and English 
      and covered various question types, including reverse questions and 
      multiple-choice questions, and mainly focused on general medical knowledge. We 
      pasted each question into ChatGPT and recorded its response, comparing it to the 
      correct answer provided by the exam board. We used SAS 9.4 (Cary, North Carolina, 
      USA) and Excel to calculate the accuracy rates for each question type. RESULTS: 
      ChatGPT answered 52 questions out of 125 correctly, with an accuracy rate of 
      41.6%. The questions' length did not affect the accuracy rates. These were 45.5%, 
      33.3%, 58.3%, 50.0%, and 43.5% for negative-phrase questions, multiple-choice 
      questions, mutually exclusive options, case scenario questions, and Taiwan's 
      local policy-related questions, with no statistical difference observed. 
      CONCLUSION: ChatGPT's accuracy rate was not good enough for Taiwan's Family 
      Medicine Board Exam. Possible reasons include the difficulty level of the 
      specialist exam and the relatively weak database of traditional Chinese language 
      resources. However, ChatGPT performed acceptably in negative-phrase questions, 
      mutually exclusive questions, and case scenario questions, and it can be a 
      helpful tool for learning and exam preparation. Future research can explore ways 
      to improve ChatGPT's accuracy rate for specialized exams and other domains.
CI  - Copyright © 2023, the Chinese Medical Association.
FAU - Weng, Tzu-Ling
AU  - Weng TL
AD  - Center for Geriatrics and Gerontology, Taipei Veterans General Hospital, Taipei, 
      Taiwan, ROC.
AD  - Institute of Public Health, School of Medicine, National Yang Ming Chiao Tung 
      University, Taipei, Taiwan, ROC.
FAU - Wang, Ying-Mei
AU  - Wang YM
AD  - Department of Medical Education and Research, Taipei Veterans General Hospital 
      Hsinchu Branch, Hsinchu, Taiwan, ROC.
AD  - Department of Pharmacy, Taipei Veterans General Hospital Hsinchu Branch, Hsinchu, 
      Taiwan, ROC.
AD  - School of Medicine, National Tsing Hua University, Hsinchu, Taiwan, ROC.
FAU - Chang, Samuel
AU  - Chang S
AD  - School of Medicine, Taipei Medical University, Taipei, Taiwan, ROC.
FAU - Chen, Tzeng-Ji
AU  - Chen TJ
AD  - Department of Family Medicine, Taipei Veterans General Hospital Hsinchu Branch, 
      Hsinchu, Taiwan, ROC.
AD  - Department of Family Medicine, Taipei Veterans General Hospital, Taipei, Taiwan, 
      ROC.
AD  - Department of Post-Baccalaureate Medicine, National Chung Hsing University, 
      Taichung, Taiwan, ROC.
FAU - Hwang, Shinn-Jang
AU  - Hwang SJ
AD  - Department of Family Medicine, En Chu Kong Hospital, New Taipei City, Taiwan, 
      ROC.
AD  - Department of Family Medicine, National Yang Ming Chiao Tung University, School 
      of Medicine, Taipei, Taiwan, ROC.
LA  - eng
PT  - Journal Article
DEP - 20230609
PL  - Netherlands
TA  - J Chin Med Assoc
JT  - Journal of the Chinese Medical Association : JCMA
JID - 101174817
SB  - IM
CIN - J Chin Med Assoc. 2023 Aug 1;86(8):775. PMID: 37314310
MH  - *Artificial Intelligence
MH  - Databases, Factual
MH  - *Family Practice
MH  - Taiwan
MH  - *Academic Performance
COIS- Conflicts of interest: Dr. Tzeng-Ji Chen and Dr. Shinn-Jang Hwang, editorial 
      board members at the Journal of the Chinese Medical Association , have no roles 
      in the peer review process or decision to publish this article. The other authors 
      declare that they have no conflicts of interest related to the subject matter or 
      materials discussed in this article.
EDAT- 2023/06/09 13:42
MHDA- 2023/08/11 06:42
CRDT- 2023/06/09 09:33
PHST- 2023/08/11 06:42 [medline]
PHST- 2023/06/09 13:42 [pubmed]
PHST- 2023/06/09 09:33 [entrez]
AID - 02118582-990000000-00224 [pii]
AID - 10.1097/JCMA.0000000000000946 [doi]
PST - ppublish
SO  - J Chin Med Assoc. 2023 Aug 1;86(8):762-766. doi: 10.1097/JCMA.0000000000000946. 
      Epub 2023 Jun 9.

PMID- 37191485
OWN - NLM
STAT- MEDLINE
DCOM- 20230622
LR  - 20230713
IS  - 1527-1315 (Electronic)
IS  - 0033-8419 (Linking)
VI  - 307
IP  - 5
DP  - 2023 Jun
TI  - Performance of ChatGPT on a Radiology Board-style Examination: Insights into 
      Current Strengths and Limitations.
PG  - e230582
LID - 10.1148/radiol.230582 [doi]
AB  - Background ChatGPT is a powerful artificial intelligence large language model 
      with great potential as a tool in medical practice and education, but its 
      performance in radiology remains unclear. Purpose To assess the performance of 
      ChatGPT on radiology board-style examination questions without images and to 
      explore its strengths and limitations. Materials and Methods In this exploratory 
      prospective study performed from February 25 to March 3, 2023, 150 
      multiple-choice questions designed to match the style, content, and difficulty of 
      the Canadian Royal College and American Board of Radiology examinations were 
      grouped by question type (lower-order [recall, understanding] and higher-order 
      [apply, analyze, synthesize] thinking) and topic (physics, clinical). The 
      higher-order thinking questions were further subclassified by type (description 
      of imaging findings, clinical management, application of concepts, calculation 
      and classification, disease associations). ChatGPT performance was evaluated 
      overall, by question type, and by topic. Confidence of language in responses was 
      assessed. Univariable analysis was performed. Results ChatGPT answered 69% of 
      questions correctly (104 of 150). The model performed better on questions 
      requiring lower-order thinking (84%, 51 of 61) than on those requiring 
      higher-order thinking (60%, 53 of 89) (P = .002). When compared with lower-order 
      questions, the model performed worse on questions involving description of 
      imaging findings (61%, 28 of 46; P = .04), calculation and classification (25%, 
      two of eight; P = .01), and application of concepts (30%, three of 10; P = .01). 
      ChatGPT performed as well on higher-order clinical management questions (89%, 16 
      of 18) as on lower-order questions (P = .88). It performed worse on physics 
      questions (40%, six of 15) than on clinical questions (73%, 98 of 135) (P = .02). 
      ChatGPT used confident language consistently, even when incorrect (100%, 46 of 
      46). Conclusion Despite no radiology-specific pretraining, ChatGPT nearly passed 
      a radiology board-style examination without images; it performed well on 
      lower-order thinking questions and clinical management questions but struggled 
      with higher-order thinking questions involving description of imaging findings, 
      calculation and classification, and application of concepts. © RSNA, 2023 See 
      also the editorial by Lourenco et al and the article by Bhayana et al in this 
      issue.
FAU - Bhayana, Rajesh
AU  - Bhayana R
AUID- ORCID: 0000-0002-8352-7953
AD  - From the University Medical Imaging Toronto, Joint Department of Medical Imaging, 
      University Health Network, Mount Sinai Hospital and Women's College Hospital, 
      University of Toronto, Toronto General Hospital, 200 Elizabeth St, Peter Mulk 
      Building, 1st Fl, Toronto, ON, Canada M5G 24C.
FAU - Krishna, Satheesh
AU  - Krishna S
AUID- ORCID: 0000-0001-6603-7621
AD  - From the University Medical Imaging Toronto, Joint Department of Medical Imaging, 
      University Health Network, Mount Sinai Hospital and Women's College Hospital, 
      University of Toronto, Toronto General Hospital, 200 Elizabeth St, Peter Mulk 
      Building, 1st Fl, Toronto, ON, Canada M5G 24C.
FAU - Bleakney, Robert R
AU  - Bleakney RR
AUID- ORCID: 0009-0000-4493-2676
AD  - From the University Medical Imaging Toronto, Joint Department of Medical Imaging, 
      University Health Network, Mount Sinai Hospital and Women's College Hospital, 
      University of Toronto, Toronto General Hospital, 200 Elizabeth St, Peter Mulk 
      Building, 1st Fl, Toronto, ON, Canada M5G 24C.
LA  - eng
PT  - Journal Article
DEP - 20230516
PL  - United States
TA  - Radiology
JT  - Radiology
JID - 0401260
SB  - IM
CIN - Radiology. 2023 Jun;307(5):e231053. PMID: 37191490
CIN - Radiology. 2023 Jun;307(5):e231330. PMID: 37338357
CIN - Radiology. 2023 Jul;308(1):e231335. PMID: 37432082
MH  - Humans
MH  - *Artificial Intelligence
MH  - Prospective Studies
MH  - Canada
MH  - Radiography
MH  - *Radiology
EDAT- 2023/05/16 13:09
MHDA- 2023/06/22 06:42
CRDT- 2023/05/16 09:52
PHST- 2023/06/22 06:42 [medline]
PHST- 2023/05/16 13:09 [pubmed]
PHST- 2023/05/16 09:52 [entrez]
AID - 10.1148/radiol.230582 [doi]
PST - ppublish
SO  - Radiology. 2023 Jun;307(5):e230582. doi: 10.1148/radiol.230582. Epub 2023 May 16.

PMID- 38455449
OWN - NLM
STAT- MEDLINE
DCOM- 20240311
LR  - 20240311
IS  - 1303-2968 (Electronic)
IS  - 1303-2968 (Linking)
VI  - 23
IP  - 1
DP  - 2024 Mar
TI  - ChatGPT Generated Training Plans for Runners are not Rated Optimal by Coaching 
      Experts, but Increase in Quality with Additional Input Information.
PG  - 56-72
LID - 10.52082/jssm.2024.56 [doi]
AB  - ChatGPT may be used by runners to generate training plans to enhance performance 
      or health aspects. However, the quality of ChatGPT generated training plans based 
      on different input information is unknown. The objective of the study was to 
      evaluate ChatGPT-generated six-week training plans for runners based on different 
      input information granularity. Three training plans were generated by ChatGPT 
      using different input information granularity. 22 quality criteria for training 
      plans were drawn from the literature and used to evaluate training plans by 
      coaching experts on a 1-5 Likert Scale. A Friedmann test assessed significant 
      differences in quality between training plans. For training plans 1, 2 and 3, a 
      median rating of &lt;3 was given 19, 11, and 1 times, a median rating of 3 was given 
      3, 5, and 8 times and a median rating of &gt;3 was given 0, 6, 13 times, 
      respectively. Training plan 1 received significantly lower ratings compared to 
      training plan 2 for 3 criteria, and 15 times significantly lower ratings compared 
      to training plan 3 (p &lt; 0.05). Training plan 2 received significantly lower 
      ratings (p &lt; 0.05) compared to plan 3 for 9 criteria. ChatGPT generated plans are 
      ranked sub-optimally by coaching experts, although the quality increases when 
      more input information are provided. An understanding of aspects relevant to 
      programming distance running training is important, and we advise avoiding the 
      use of ChatGPT generated training plans without an expert coach's feedback.
CI  - © Journal of Sports Science and Medicine.
FAU - Düking, Peter
AU  - Düking P
AD  - Department of Sports Science and Movement Pedagogy, Technische Universität 
      Braunschweig, Braunschweig, Germany.
FAU - Sperlich, Billy
AU  - Sperlich B
AD  - Integrative and Experimental Exercise Science, Department of Sport Science, 
      University of Würzburg, Würzburg, Germany.
FAU - Voigt, Laura
AU  - Voigt L
AD  - Institute of Psychology, German Sport University Cologne, Cologne, Germany.
FAU - Van Hooren, Bas
AU  - Van Hooren B
AD  - Department of Nutrition and Movement Sciences, School of Nutrition and 
      Translational Research in Metabolism (NUTRIM), Faculty of Health, Medicine and 
      Life Sciences, Maastricht University, Maastricht, The Netherlands.
FAU - Zanini, Michele
AU  - Zanini M
AD  - School of Sport, Exercise, and Health Sciences, Loughborough University, 
      Loughborough, United Kingdom.
FAU - Zinner, Christoph
AU  - Zinner C
AD  - Department of Sport, University of Applied Sciences for Police and Administration 
      of Hesse, Wiesbaden, Germany.
LA  - eng
PT  - Journal Article
DEP - 20240301
PL  - Turkey
TA  - J Sports Sci Med
JT  - Journal of sports science &amp; medicine
JID - 101174629
SB  - IM
MH  - Humans
MH  - *Mentoring
MH  - *Running
PMC - PMC10915606
OTO - NOTNLM
OT  - Artificial intelligence
OT  - data-informed training
OT  - digital health
OT  - digital training
OT  - individualization
OT  - innovation
OT  - mHealth
OT  - technology
EDAT- 2024/03/08 06:42
MHDA- 2024/03/11 06:42
PMCR- 2024/03/01
CRDT- 2024/03/08 04:00
PHST- 2023/10/13 00:00 [received]
PHST- 2023/12/19 00:00 [accepted]
PHST- 2024/03/11 06:42 [medline]
PHST- 2024/03/08 06:42 [pubmed]
PHST- 2024/03/08 04:00 [entrez]
PHST- 2024/03/01 00:00 [pmc-release]
AID - 10.52082/jssm.2024.56 [doi]
PST - epublish
SO  - J Sports Sci Med. 2024 Mar 1;23(1):56-72. doi: 10.52082/jssm.2024.56. eCollection 
      2024 Mar.
</pre>
      
    </div>
  </main>


  
  


  


</body></html>